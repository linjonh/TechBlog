---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f35313932333939372f:61727469636c652f64657461696c732f313435393839333035"
layout: post
title: "机器学习周报-文献阅读"
date: 2025-03-09 14:02:36 +0800
description: "本周阅读了题目为Design of Prediction Framework Geo-TA Utilizing Spatial and Temporal Water Quality Data Integrating Meteorological Information文章。文章提出了地理-时间注意力与交叉注意力机制（Geo-TA）框架，该框架基于GATnet，其中包括水质站的地理坐标，并使用气象数据作为额外的预测因子。"
keywords: "机器学习周报-文献阅读"
categories: ['未分类']
tags: ['机器学习', '人工智能']
artid: "145989305"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145989305
    alt: "机器学习周报-文献阅读"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145989305
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145989305
cover: https://bing.ee123.net/img/rand?artid=145989305
image: https://bing.ee123.net/img/rand?artid=145989305
img: https://bing.ee123.net/img/rand?artid=145989305
---

# 机器学习周报-文献阅读

### 摘要

本周阅读了题目为Design of Prediction Framework Geo-TA Utilizing Spatial and Temporal Water Quality Data Integrating Meteorological Information文章。文章提出了地理-时间注意力与交叉注意力机制（Geo-TA）框架，该框架基于GATnet，其中包括水质站的地理坐标，并使用气象数据作为额外的预测因子。使用Geo-TA框架的Val-Huber损失与基线模型如LSTM-CNN-ATT，MLP和TCN在预测精度方面进行比较。所有三个基线都表现出较差的性能，而Geo-TA表现出出色的预测能力。Geo-TA框架通过综合考虑水质数据、空间信息和气象数据，实现了比基线模型更高的预测精度。

### Abstract

This week, I read an article titled “Design of Prediction Framework Geo-TA Utilizing Spatial and Temporal Water Quality Data Integrating Meteorological Information.” The article proposes the Geo-TA framework, which incorporates geographical-temporal attention and cross-attention mechanisms. This framework is based on GATnet and includes the geographical coordinates of water quality monitoring stations, with meteorological data used as additional predictors. The prediction accuracy of the Geo-TA framework, evaluated using the Val-Huber loss, was compared with that of baseline models such as LSTM-CNN-ATT, MLP, and TCN. All three baseline models exhibited inferior performance, while the Geo-TA framework demonstrated outstanding predictive capabilities. By integrating water quality data, spatial information, and meteorological data, the Geo-TA framework achieved higher prediction accuracy than the baseline models.

## 1 文章内容

创新点：

1. 以往的水质预测模型仅使用单个站点数据集来预测单个水质指数。在这项研究中，我们全面考虑了复杂的时间和空间信息，从多个地点位于不同的纬度和纬度，以提高多个水质指标的预测在不同的网站。
2. 这是一个具有挑战性的任务，整合纬度和经度信息作为空间数据使用多站点数据集，占连接沿着网络，并考虑流动的方向性。Haitao等人利用Road Segment Embedding对图形边的拓扑结构进行编码，并将其嵌入到高维向量空间中[8]。本研究利用GeoEmbedding将水质监测站的地理资讯嵌入水质时间序列中。
3. 通过使用气象信息作为额外的输入，我们可以充分探索气象和水质数据之间的隐藏关系。提出了一种改进的地理转换注意力（Geo-TA）框架，用于水网时空预测模型。
4. 本研究工作通过在三个真实世界水网格数据集上的测试来验证Geo-TA模型的有效性。结果表明，Geo-TA模型的预测精度均优于几种基准模型

**数据处理**

将区域内N个水质站对应的气象数据复制N份。将原始数据转换为三维张量N × T × F，其中N表示水质监测站的数量，T表示水质站在指定时间段内观测到的样本总数。为了处理数据集中的缺失数据和错误数据，
**采用KNN（K-Nearest Neighbors）方法对数据集进行填充。**

Z-Score标准化分别应用于每个水质指标，

x
′
=
x
−
μ
δ
x'=\frac{x-\mu}{\delta}






x










′



=

















δ












x

−

μ

​

，其中，

μ
\mu





μ
为各指标的平均值，

δ
\delta





δ
为各指标的标准差。

### 1.1 模型

GEO-TA模型由三个主要部分组成：
**Geo Embedding**
、
**ST encoder**
和
**ST decoder**
，其中Geo Embedding提取空间信息，Tencoder融合多模态特征，ST decoder将融合后的特征解码为相应的水质预测目标。这三个主要部分将通过以下方式用作输入：

1. 边图

   G
   ∈
   R
   P
   ×
   1
   G ∈ R^{P×1}





   G



   ∈






   R










   P

   ×

   1
   ，由第三节D部分定义2）变换，其中P是节点图的边.
2. 水质时间序列

   X
   W
   ∈
   R
   N
   ×
   T
   ×
   F
   X^W \in R^{N×T×F}






   X









   W



   ∈






   R










   N

   ×

   T

   ×

   F
   。
3. 气象时间序列

   X
   M
   ∈
   R
   N
   ×
   T
   ×
   F
   X^M \in R^{N×T×F}






   X









   M



   ∈






   R










   N

   ×

   T

   ×

   F
   。其中N是站点维度，T是样本中的时间维度，F是特征维度。Geo Embedding执行空间信息的提取，ST编码器执行多模态特征融合，ST解码器将融合的特征解码为相关的水质预测目标。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/427a207473254865a90c3afb088b871c.png)

#### 1.1.1 Geo Embedding

Geo Embedding模块的主要任务是将水质监测站的地理信息（经纬度）转换为嵌入向量，以便在模型中使用以增强空间信息的利用。这一部分的处理流程如图所示：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/0a28f4bacdbc45b2863c6bae998b6256.png)

具体步骤如下：

**1. 构建边图（Edge Graph）**
  
水质监测站的地理位置被抽象为一个有向加权图G={V，E}，其中

V
V





V
是站点集合，

E
E





E
是站点之间的空间连接。

通过Vincenty公式计算站点之间的距离和方向，构建边图

G
∈
R
P
×
1
G\in R^{P×1}





G



∈






R










P

×

1
，其中

P
P





P
是边图顶点维度
  
**2. 图注意力网络（GAT）**

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3943a5f2600f48a683b95d358370cca2.png)

**使用图注意力网络（GAT）来学习边图中节点之间的隐含连接**
。GAT使用非谱域方法将注意力机制引入图嵌入。通过全局注意力系数聚合节点特征，充分学习模糊顶点连通性，这一思想在交通领域已经展现出其优异的性能

输入：边图

G
∈
R
P
×
1
G\in R^{P×1}





G



∈






R










P

×

1
，其中

P
=
{
p
1
,
p
2
,
.
.
.
.
.
p
k
}
P=\{p\_1,p\_2,.....p\_k\}





P



=





{


p









1

​


,




p









2

​


,



.....


p









k

​


}
表示河流的节点。

注意力系数计算：

1. 首先对节点

   p
   i
   p\_i






   p









   i

   ​

   和其邻居节点

   p
   j
   p\_j






   p









   j

   ​

   进行线性变换，得到隐藏表示：
2. 通过全连接层计算注意力系数

   e
   i
   j
   e\_{ij}






   e










   ij

   ​
3. 使用Softmax函数对注意力系数进行归一化：
4. 最终通过多头注意力机制计算节点的编码表示：

输出：地理嵌入表示

G
(
h
)
∈
R
P
×
D
G^{(h)}\in R^{P×D}






G










(

h

)



∈






R










P

×

D
，其中

D
D





D
是嵌入维度。

**3. Expand：**

输入：编码后的顶点表示

G
(
h
)
∈
R
P
×
D
G^{(h)}\in R^{P×D}






G










(

h

)



∈






R










P

×

D
  
处理：将编码后的顶点表示扩展到时间维度

T
T





T
，以匹配水质时间序列和气象时间序列的维度。
  
输出：扩展后的顶点表示

G
(
h
)
∈
R
P
×
T
×
D
G^{(h)}\in R^{P×T×D}






G










(

h

)



∈






R










P

×

T

×

D

扩展后的顶点表示
**G
(
h
)
∈
R
P
×
T
×
D
G^{(h)}\in R^{P×T×D}






G










(

h

)



∈






R










P

×

T

×

D**
：这是Geo Embedding部分的最终输出，
**将被用于STencoder部分。**

#### 1.1.2 ST encoder

STencoder是Geo-TA框架中的一个关键模块，
**该模块的目标是融合水质数据、气象数据和地理编码信息**
，捕捉多模态数据之间的长期依赖关系。

**输入数据**

**水质数据：

X
W
∈
R
N
×
T
×
F
X^W\in R^{N×T×F}






X









W



∈






R










N

×

T

×

F**
,其中N是站点数量，T是时间步长，F是特征维度
  
**气象数据：

X
M
∈
R
N
×
T
×
F
X^M\in R^{N×T×F}






X









M



∈






R










N

×

T

×

F**
，与水质数据对齐。
  
**地理编码信息：

G
(
h
)
∈
R
P
×
T
×
D
G^{(h)}\in R^{P×T×D}






G










(

h

)



∈






R










P

×

T

×

D**
,通过Geo Embedding模块得到。

**交叉注意力机制（CrossAttention）**

在STencoder中引入了两个交叉注意力机制，分别用于融合水质数据与地理编码信息、水质数据与气象数据。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b0561e61f8284080ad6f4b11a7d0d282.png)

**LSTM单元**

使用LSTM单元捕捉时间序列数据的长期依赖关系。在时间 T=t 时，LSTMCell的计算过程如下：

1. 输入门

   i
   t
   i\_t






   i









   t

   ​

   ：决定哪些信息可以从输入中写入细胞状态。
     
   ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/30f28515fdb1428aa6516ea25d0c8652.png)
2. 遗忘门

   f
   t
   f\_t






   f









   t

   ​

   ：决定哪些信息应该从细胞状态中丢弃。
     
   ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/21f2f18de14042b89c6d4bbea2894a8d.png)
3. 细胞候选值

   g
   t
   g\_t






   g









   t

   ​

   当前输入的新信息。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3c173c0a3493438baf578eb169c8a05e.png)

4. 输出门

   o
   t
   o\_t






   o









   t

   ​

   ：决定哪些信息应该从细胞状态输出。
     
   ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b619a193e3594dd392e36e6d871b53e4.png)
5. 细胞状态

   c
   t
   c\_t






   c









   t

   ​

   ：结合遗忘门和输入门的输出来更新。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6eb4da210a28443ca7c4003f52b265f0.png)

6. 隐藏状态h\_t ：基于输出门和更新后的细胞状态计算。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b9e3876f088c42d093cc901970788654.png)

其中，W 和 b 是可学习的参数，σ 是sigmoid函数，tanh 是双曲正切函数。

**交叉注意力计算：**

为了实现多模态数据的融合编码，STencoder引入了两个CrossAttention模块：

> 1.水质量与空间位置的CrossAttention：将水质数据和河流编码进行融合。
>   
> 2.水质量与气象的CrossAttention：将水质数据和气象数据进行融合。

CrossAttention的计算过程如下：

1. 线性变换：对输入数据进行线性变换以得到查询（Q）、键（K）和值（V）。
     
   首先通过全连接层计算查询（Query）、键（Key）和值（Value）：
     



   Q
   =
   F
   C
   (
   X
   1
   )
   Q=FC(X\_1)





   Q



   =





   FC

   (


   X









   1

   ​


   )
   ，

   K
   =
   F
   C
   (
   X
   2
   )
   K=FC(X\_2)





   K



   =





   FC

   (


   X









   2

   ​


   )
   ，

   V
   =
   F
   C
   (
   X
   2
   )
   V=FC(X\_2)





   V



   =





   FC

   (


   X









   2

   ​


   )
2. 计算注意力权重：通过查询和键的点积计算注意力得分，并进行缩放。
     



   A
   t
   t
   =
   s
   o
   f
   t
   m
   a
   x
   (
   Q
   K
   T
   d
   k
   )
   Att=softmax(\frac{QK^T}{\sqrt d\_k})





   A

   tt



   =





   so

   f

   t

   ma

   x

   (





















   d


   ​










   k

   ​













   Q


   K









   T

   ​


   )
   ，其中

   d
   k
   d\_k






   d









   k

   ​

   是注意力因子
3. 加权求和：将注意力得分与值进行加权求和，并通过全连接层得到最终输出。
     
   最终通过全连接层得到融合后的特征：
     



   H
   =
   F
   C
   (
   A
   t
   t
   ,
   V
   )
   H=FC(Att,V)





   H



   =





   FC

   (

   A

   tt

   ,



   V

   )

其中，FC 表示全连接层

#### 1.1.3 ST decoder

STdecoder模块的目标是将融合后的多模态特征解码为最终的水质预测结果。

**1. 输入数据**

融合特征：

H
W
P
H
∈
R
N
×
T
×
D
H^{WPH}\in R^{N×T×D}






H










W

P

H



∈






R










N

×

T

×

D
来自STencoder模块。
  
**2. LSTM解码**

使用传统的LSTM单元对融合特征进行解码，生成预测结果。

输出：预测的水质数据

Y
^
∈
R
N
×
T
×
F
\hat Y\in R^{N×T×F}












Y





^



∈






R










N

×

T

×

F
  
**3. 损失函数**

使用Huber Loss作为损失函数，计算预测值

Y
^
\hat Y












Y





^
与真实值Y之间的差异：

其中

δ
\delta





δ
是超参数，用于平衡MSE和MAE。

### 1.2 实验

使用Adam优化器和Huber Loss的损失函数训练三个数据集，其中Adam的学习率为0.02，瓦尔Huber Loss的离群值敏感度为1.0。

为了提高模型的泛化能力和降低过拟合的风险，我们采用了三重交叉验证策略，原始训练数据集被随机分为三个大小相等的部分。在每次迭代期间，选择一个部分作为验证集（用于模型评估），而将剩余的两个部分组合作为模型训练的训练集。此操作重复三次，以确保每个部分都有机会作为验证集。通过这种方法，我们能够利用所有的训练数据进行模型训练和评估，从而避免由于数据划分而造成的信息浪费。记录每次迭代的评估结果并取平均值，以提供对模型性能的总体估计。这种做法不仅提高了模型评估的可靠性，而且有助于合理估计模型对未知数据的泛化能力。

分别对北方、东南部和西部三个100epoch的数据集进行了研究，并计算了它们的Val-Huber损失和Train-Huber损失随不同时期的变化曲线如下图所示：Huber损失随时间的变化曲线。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4739e84d1605475892d2a22d79db1522.png)

利用Geo-TA框架对辽宁省北方、东南部和西部3个数据集进行训练、学习和预测。下面两张表分别列出了训练错误和验证错误。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6c1f7fc559b642c7b497c27f1ffdcbf9.png)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/64952ad125804ec4895f45bf4f3f7a11.png)

在大多数情况下，训练误差略低于验证误差，这表明模型在训练数据上表现较好，但在验证数据上可能存在一定的过拟合。例如，在北方数据集中，WT的训练MAE为0.832396，而验证MAE为0.815217，两者接近，表明模型在北方数据集上的泛化能力较好。

东南部数据集的训练和验证误差普遍较低，表明该数据集的水质预测任务相对简单，模型在该区域表现较好。
  
北方数据集的训练和验证误差较高，特别是

N
H
3
−
N
NH\_3-N





N


H









3

​




−





N
和P的误差较大，表明该区域的水质可能较为复杂，预测难度较大。
  
西部数据集的误差介于北方和东南部之间，模型在该区域的表现中等

Huber Loss 在训练数据中仅对P指标进行了记录，北方、东南部和西部的Huber Loss分别为0.021702、0.014014和0.054726。Huber Loss 的值较低，表明模型在训练数据上的预测误差较小，特别是在东南部数据集上表现最佳。

## 2 相关知识

### 2.1 Huber 损失函数

Huber Loss 是一种用于回归问题的损失函数，结合了
**均方误差（MSE）和平均绝对误差（MAE）**
的优点，能够在处理异常值时表现出更好的鲁棒性。Huber Loss 的主要特点是它对小误差使用平方损失（类似MSE），而对大误差使用线性损失（类似MAE），从而在异常值存在时不会像MSE那样对异常值过于敏感。

**Huber Loss 的数学定义**
  
Huber Loss 的公式如下：

H
u
b
e
r
L
o
s
s
(
Y
,
Y
^
)
=
{
1
2
(
Y
−
Y
^
)
2
i
f
∣
Y
−
Y
^
∣
≤
δ
δ
⋅
(
∣
Y
−
Y
^
∣
−
1
2
δ
)
o
t
h
e
r
w
i
s
e
Huber Loss(Y,\hat Y)= \begin{cases} \frac{1}{2}(Y-\hat Y)^2 \qquad if |Y-\hat Y|\le \delta \\ \delta·(|Y-\hat Y|-\frac{1}{2}\delta) \qquad otherwise \end{cases}





H

u

b

er

L

oss

(

Y

,










Y





^

)



=







{























2












1

​


(

Y



−










Y





^


)









2



i

f

∣

Y



−










Y





^

∣



≤



δ





δ

⋅



(

∣

Y



−










Y





^

∣



−















2












1

​


δ

)



o

t

h

er

w

i

se

​

Y
Y





Y
是真实值（ground truth），

Y
^
\hat Y












Y





^
是预测值。

δ
\delta





δ
是一个超参数，用于控制损失函数从平方损失切换到线性损失的阈值。

**Huber Loss 的特点：**

1. 对小误差使用平方损失：
     
   当预测值与真实值之间的差异

   ∣
   Y
   −
   Y
   ^
   ∣
   |Y-\hat Y|





   ∣

   Y



   −












   Y





   ^

   ∣
   小于等于

   δ
   \delta





   δ
   ，Huber Loss 退化为均方误差（MSE）：

   H
   u
   b
   e
   r
   L
   o
   s
   s
   (
   Y
   ,
   Y
   ^
   )
   =
   1
   2
   (
   Y
   −
   Y
   ^
   )
   2
   Huber Loss(Y,\hat Y)=\frac{1}{2}(Y-\hat Y)^2





   H

   u

   b

   er

   L

   oss

   (

   Y

   ,










   Y





   ^

   )



   =
















   2











   1

   ​


   (

   Y



   −












   Y





   ^


   )









   2
     
   **平方损失对小误差非常敏感，能够快速收敛。**
2. 对大误差使用线性损失：
     
   当预测值与真实值之间的差异

   ∣
   Y
   −
   Y
   ^
   ∣
   |Y-\hat Y|





   ∣

   Y



   −












   Y





   ^

   ∣
   大于

   δ
   \delta





   δ
   ，Huber Loss 退化为平均绝对误差（MAE）：

   H
   u
   b
   e
   r
   L
   o
   s
   s
   (
   Y
   ,
   Y
   ^
   )
   =
   δ
   ⋅
   (
   ∣
   Y
   −
   Y
   ^
   ∣
   −
   1
   2
   δ
   )
   Huber Loss(Y,\hat Y)=\delta·(|Y-\hat Y|-\frac{1}{2}\delta)





   H

   u

   b

   er

   L

   oss

   (

   Y

   ,










   Y





   ^

   )



   =





   δ

   ⋅



   (

   ∣

   Y



   −












   Y





   ^

   ∣



   −
















   2











   1

   ​


   δ

   )
     
   **线性损失对大误差（异常值）不敏感，能够减少异常值对模型训练的影响。**
3. 平滑性：
     
   Huber Loss 在

   ∣
   Y
   −
   Y
   ^
   ∣
   =
   δ
   |Y-\hat Y|=\delta





   ∣

   Y



   −












   Y





   ^

   ∣



   =





   δ
   处是连续且可导的，这使得它在优化过程中更加稳定。

**Huber Loss 的优点：**
  
1. 对异常值的鲁棒性：
  
相比于MSE，Huber Loss 对异常值不敏感，能够减少异常值对模型训练的影响。
  
相比于MAE，Huber Loss 在小误差区域仍然能够快速收敛。
  
2. 平滑性：
  
Huber Loss 在

∣
Y
−
Y
^
∣
=
δ
|Y-\hat Y|=\delta





∣

Y



−












Y





^

∣



=





δ
处是平滑的，这使得它在梯度下降优化过程中更加稳定。
  
3. 灵活性：
  
通过调整超参数

δ
\delta





δ
，可以控制 Huber Loss 的行为。当

δ
\delta





δ
趋近于0时，Huber Loss 退化为MAE；当

δ
\delta





δ
趋近于无穷大时，Huber Loss 退化为MSE。

代码示例

```
import torch
import numpy as np
import matplotlib.pyplot as plt

# Huber损失函数
def huber_loss(y_true, y_pred, delta):
    abs_error = torch.abs(y_true - y_pred)
    quadratic = torch.clamp(abs_error, max=delta)
    loss = torch.where(abs_error <= delta, 0.5 * (abs_error ** 2), delta * (abs_error - 0.5 * delta))
    return loss

# 示例数据
y_true = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)
y_pred = torch.tensor([1.1, 1.9, 3.5, 2.5, 10], dtype=torch.float32)
delta = 1.0

# 计算Huber损失
loss = huber_loss(y_true, y_pred, delta)
print("Huber损失:", loss)
print("总损失:", torch.sum(loss))

# 可视化损失函数
errors = torch.linspace(-5, 5, 100, dtype=torch.float32)
losses = huber_loss(torch.zeros_like(errors), errors, delta)

plt.plot(errors.numpy(), losses.numpy(), label="Huber Loss")
plt.axvline(x=delta, color="red", linestyle="--", label=f"Delta = {delta}")
plt.axvline(x=-delta, color="red", linestyle="--")
plt.title("Huber Loss Function")
plt.xlabel("Error")
plt.ylabel("Loss")
plt.legend()
plt.show()

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/7e6352eef452426fbcf7b4c9452e714c.png)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/2f212bba311e43a6a5109a1c64f73779.png)

### 2.2 代码

Geo Embedding 模块
  
Geo Embedding 模块使用图注意力网络（GAT）来提取地理信息。

```python
class GeoEmbedding(nn.Module):
    def __init__(self, num_nodes, embedding_dim, heads=4):
        super(GeoEmbedding, self).__init__()
        # 使用 GAT 进行地理信息嵌入
        self.gat = GATConv(in_channels=1, out_channels=embedding_dim, heads=heads)
        self.linear = nn.Linear(heads * embedding_dim, embedding_dim)

    def forward(self, edge_index, edge_attr):
        # edge_index: 图的边索引 (2, num_edges)
        # edge_attr: 边的属性 (num_edges, 1)
        x = self.gat(edge_attr, edge_index)  # GAT 输出 (num_nodes, heads * embedding_dim)
        x = self.linear(x)  # 线性变换 (num_nodes, embedding_dim)
        return x

```

STencoder 模块
  
STencoder 模块结合水质数据、气象数据和地理编码信息，使用 LSTM 和交叉注意力机制进行特征融合。

```python
class STencoder(nn.Module):
    def __init__(self, input_dim, hidden_dim, embedding_dim):
        super(STencoder, self).__init__()
        # LSTM 用于捕捉时间序列特征
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        # 交叉注意力机制
        self.cross_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4)

    def forward(self, x_water, x_meteo, geo_embedding):
        # x_water: 水质数据 (batch_size, seq_len, input_dim)
        # x_meteo: 气象数据 (batch_size, seq_len, input_dim)
        # geo_embedding: 地理编码信息 (batch_size, seq_len, embedding_dim)

        # LSTM 处理水质数据
        water_out, _ = self.lstm(x_water)  # (batch_size, seq_len, hidden_dim)

        # 交叉注意力融合水质数据和地理编码信息
        geo_embedding = geo_embedding.permute(1, 0, 2)  # (seq_len, batch_size, embedding_dim)
        water_out = water_out.permute(1, 0, 2)  # (seq_len, batch_size, hidden_dim)
        attn_output, _ = self.cross_attention(water_out, geo_embedding, geo_embedding)
        attn_output = attn_output.permute(1, 0, 2)  # (batch_size, seq_len, hidden_dim)

        return attn_output

```

STdecoder 模块
  
STdecoder 模块使用 LSTM 解码融合后的特征，生成最终的水质预测结果。

```python
class STdecoder(nn.Module):
    def __init__(self, hidden_dim, output_dim):
        super(STdecoder, self).__init__()
        # LSTM 解码器
        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)
        # 全连接层生成最终输出
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        # x: 融合后的特征 (batch_size, seq_len, hidden_dim)
        lstm_out, _ = self.lstm(x)  # (batch_size, seq_len, hidden_dim)
        output = self.fc(lstm_out)  # (batch_size, seq_len, output_dim)
        return output

```

将 Geo Embedding、STencoder 和 STdecoder 组合成完整的 Geo-TA 框架。

```python
class GeoTA(nn.Module):
    def __init__(self, num_nodes, input_dim, hidden_dim, embedding_dim, output_dim):
        super(GeoTA, self).__init__()
        self.geo_embedding = GeoEmbedding(num_nodes, embedding_dim)
        self.stencoder = STencoder(input_dim, hidden_dim, embedding_dim)
        self.stdecoder = STdecoder(hidden_dim, output_dim)

    def forward(self, x_water, x_meteo, edge_index, edge_attr):
        # 地理编码
        geo_embedding = self.geo_embedding(edge_index, edge_attr)
        geo_embedding = geo_embedding.unsqueeze(0).repeat(x_water.size(0), 1, 1)  # 扩展到 batch 维度

        # 时空编码
        encoded_features = self.stencoder(x_water, x_meteo, geo_embedding)

        # 解码生成预测结果
        predictions = self.stdecoder(encoded_features)
        return predictions

```

### 总结

Geo-TA框架通过综合考虑水质数据、空间信息和气象数据，实现了比基线模型更高的预测精度，文章提出的Geo - TA框架综合考虑水质、空间和气象数据，提高了不同污染程度下的水质预测精度。有助于水资源管理部门及时掌握水质变化，采取有效措施保护水资源和水生生物。为水质预测领域提供了新方法和思路，推动相关研究发展。