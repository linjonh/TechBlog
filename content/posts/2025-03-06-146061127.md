---
layout: post
title: "AI深度学习基础PyTorch初探"
date: 2025-03-06 10:41:53 +0800
description: "通过本阶段的学习，我们了解了PyTorch的基本概念和核心特性，掌握了张量的基本操作和神经网络的构建方法，并通过一个简单的线性回归示例进行了实践。PyTorch的灵活性和强大功能为我们后续深入学习深度学习奠定了基础。PyTorch是一个非常强大且易于使用的深度学习框架，适合初学者入门和开发者进行各种深度学习项目。希望本篇学习指南能够帮助你迈出PyTorch学习的第一步，期待你在后续的学习和实践中不断探索，利用PyTorch构建出更加优秀的模型。"
keywords: "【AI深度学习基础】PyTorch初探"
categories: ['人工智能']
tags: ['计算图', '自动求导', '深度学习', '张量', '动态计算图', '人工智能', 'Pytorch']
artid: "146061127"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146061127
    alt: "AI深度学习基础PyTorch初探"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146061127
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146061127
cover: https://bing.ee123.net/img/rand?artid=146061127
image: https://bing.ee123.net/img/rand?artid=146061127
img: https://bing.ee123.net/img/rand?artid=146061127
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     【AI深度学习基础】PyTorch初探
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="_0">
     </a>
     引言
    </h3>
    <p>
     PyTorch 是由 Facebook 开源的深度学习框架，专门针对 GPU 加速的深度神经网络编程，它的核心概念包括张量（Tensor）、计算图和自动求导机制。PyTorch作为Facebook开源的深度学习框架，凭借其
     <strong>
      动态计算图
     </strong>
     和
     <strong>
      直观的API设计
     </strong>
     ，已成为学术界和工业界的主流选择。与TensorFlow的静态图不同，PyTorch支持即时执行模式，配合强大的GPU加速能力，特别适合快速原型开发。截至2023年，PyTorch在arXiv论文中的提及率已超过60%，广泛应用于计算机视觉、自然语言处理、推荐系统等领域。
    </p>
    <p>
     核心结构图：
     <br/>
     <img alt="PyTorch核心结构" src="https://i-blog.csdnimg.cn/direct/d59179ffd544499fa80fcaf982b99849.png"/>
    </p>
    <hr/>
    <h3>
     <a id="_9">
     </a>
     一、安装指南
    </h3>
    <p>
     推荐使用Anaconda进行环境管理：
    </p>
    <pre><code class="prism language-bash"><span class="token comment"># 查看CUDA版本（需提前安装NVIDIA驱动）</span>
nvidia-smi 

<span class="token comment"># 创建虚拟环境（以CUDA 11.3为例）</span>
conda create <span class="token parameter variable">-n</span> pytorch <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.9</span>
conda <span class="token function">install</span> pytorch torchvision torchaudio <span class="token assign-left variable">cudatoolkit</span><span class="token operator">=</span><span class="token number">11.3</span> <span class="token parameter variable">-c</span> pytorch

<span class="token comment"># 验证安装</span>
python <span class="token parameter variable">-c</span> <span class="token string">"import torch; print(torch.__version__, torch.cuda.is_available())"</span>
</code></pre>
    <hr/>
    <h3>
     <a id="PyTorch_25">
     </a>
     二、PyTorch核心特性
    </h3>
    <ol>
     <li>
      <strong>
       动态计算图 vs 静态计算图
      </strong>
      <ul>
       <li>
        动态计算图：PyTorch采用动态计算图，即在运行时根据操作动态构建计算图。这种方式具有灵活性高、调试方便等优点，开发者可以随时对计算图进行修改和调整。
       </li>
       <li>
        静态计算图：与动态计算图相对，静态计算图在运行前需要先定义好计算图的结构，然后在运行时按照定义好的结构进行计算。这种方式在运行效率上可能更高，但在灵活性和调试方面相对不如动态计算图。
       </li>
      </ul>
     </li>
    </ol>
    <div class="mermaid">
     <svg class="mermaid-svg" height="166" id="mermaid-svg-CwyOOh2D4hTlbrMR" viewbox="-8 -8 408 166" width="408" xmlns="http://www.w3.org/2000/svg">
      <style>
       #mermaid-svg-CwyOOh2D4hTlbrMR {font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:16px;fill:#333;}#mermaid-svg-CwyOOh2D4hTlbrMR .error-icon{fill:#552222;}#mermaid-svg-CwyOOh2D4hTlbrMR .error-text{fill:#552222;stroke:#552222;}#mermaid-svg-CwyOOh2D4hTlbrMR .edge-thickness-normal{stroke-width:2px;}#mermaid-svg-CwyOOh2D4hTlbrMR .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg-CwyOOh2D4hTlbrMR .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg-CwyOOh2D4hTlbrMR .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg-CwyOOh2D4hTlbrMR .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg-CwyOOh2D4hTlbrMR .marker{fill:#333333;stroke:#333333;}#mermaid-svg-CwyOOh2D4hTlbrMR .marker.cross{stroke:#333333;}#mermaid-svg-CwyOOh2D4hTlbrMR svg{font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg-CwyOOh2D4hTlbrMR .label{font-family:"trebuchet ms",verdana,arial,sans-serif;color:#333;}#mermaid-svg-CwyOOh2D4hTlbrMR .cluster-label text{fill:#333;}#mermaid-svg-CwyOOh2D4hTlbrMR .cluster-label span{color:#333;}#mermaid-svg-CwyOOh2D4hTlbrMR .label text,#mermaid-svg-CwyOOh2D4hTlbrMR span{fill:#333;color:#333;}#mermaid-svg-CwyOOh2D4hTlbrMR .node rect,#mermaid-svg-CwyOOh2D4hTlbrMR .node circle,#mermaid-svg-CwyOOh2D4hTlbrMR .node ellipse,#mermaid-svg-CwyOOh2D4hTlbrMR .node polygon,#mermaid-svg-CwyOOh2D4hTlbrMR .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-svg-CwyOOh2D4hTlbrMR .node .label{text-align:center;}#mermaid-svg-CwyOOh2D4hTlbrMR .node.clickable{cursor:pointer;}#mermaid-svg-CwyOOh2D4hTlbrMR .arrowheadPath{fill:#333333;}#mermaid-svg-CwyOOh2D4hTlbrMR .edgePath .path{stroke:#333333;stroke-width:2.0px;}#mermaid-svg-CwyOOh2D4hTlbrMR .flowchart-link{stroke:#333333;fill:none;}#mermaid-svg-CwyOOh2D4hTlbrMR .edgeLabel{background-color:#e8e8e8;text-align:center;}#mermaid-svg-CwyOOh2D4hTlbrMR .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#mermaid-svg-CwyOOh2D4hTlbrMR .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-svg-CwyOOh2D4hTlbrMR .cluster text{fill:#333;}#mermaid-svg-CwyOOh2D4hTlbrMR .cluster span{color:#333;}#mermaid-svg-CwyOOh2D4hTlbrMR div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg-CwyOOh2D4hTlbrMR :root{--mermaid-font-family:"trebuchet ms",verdana,arial,sans-serif;}
      </style>
      <g>
       <g class="output">
        <g class="clusters">
        </g>
        <g class="edgePaths">
         <g class="edgePath LS-A LE-B" id="L-A-B" style="opacity: 1;">
          <path class="path" d="M108,31L114.83333333333333,31C121.66666666666667,31,135.33333333333334,31,146.33333333333334,31C157.33333333333334,31,165.66666666666666,31,169.83333333333334,31L174,31" marker-end="url(#arrowhead31)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead31" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
         <g class="edgePath LS-B LE-C" id="L-B-C" style="opacity: 1;">
          <path class="path" d="M258,31L262.1666666666667,31C266.3333333333333,31,274.6666666666667,31,283,31C291.3333333333333,31,299.6666666666667,31,303.8333333333333,31L308,31" marker-end="url(#arrowhead32)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead32" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
         <g class="edgePath LS-D LE-E" id="L-D-E" style="opacity: 1;">
          <path class="path" d="M124,127L128.16666666666666,127C132.33333333333334,127,140.66666666666666,127,150.33333333333334,127C160,127,171,127,176.5,127L182,127" marker-end="url(#arrowhead33)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead33" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
         <g class="edgePath LS-E LE-F" id="L-E-F" style="opacity: 1;">
          <path class="path" d="M250,127L255.5,127C261,127,272,127,281.6666666666667,127C291.3333333333333,127,299.6666666666667,127,303.8333333333333,127L308,127" marker-end="url(#arrowhead34)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead34" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
        </g>
        <g class="edgeLabels">
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-A' L-LE-B" id="L-L-A-B">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-B' L-LE-C" id="L-L-B-C">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-D' L-LE-E" id="L-L-D-E">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-E' L-LE-F" id="L-L-E-F">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
        </g>
        <g class="nodes">
         <g class="node default" id="flowchart-A-24" style="opacity: 1;" transform="translate(66,31)">
          <rect class="label-container" height="46" rx="0" ry="0" width="84" x="-42" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-32,-13)">
            <foreignobject height="26" width="64">
             <div style="display: inline-block; white-space: nowrap;">
              定义操作
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-B-25" style="opacity: 1;" transform="translate(216,31)">
          <rect class="label-container" height="46" rx="0" ry="0" width="84" x="-42" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-32,-13)">
            <foreignobject height="26" width="64">
             <div style="display: inline-block; white-space: nowrap;">
              即时执行
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-C-27" style="opacity: 1;" transform="translate(350,31)">
          <rect class="label-container" height="46" rx="0" ry="0" width="84" x="-42" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-32,-13)">
            <foreignobject height="26" width="64">
             <div style="display: inline-block; white-space: nowrap;">
              实时调试
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-D-28" style="opacity: 1;" transform="translate(66,127)">
          <rect class="label-container" height="46" rx="0" ry="0" width="116" x="-58" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-48,-13)">
            <foreignobject height="26" width="96">
             <div style="display: inline-block; white-space: nowrap;">
              预定义图结构
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-E-29" style="opacity: 1;" transform="translate(216,127)">
          <rect class="label-container" height="46" rx="0" ry="0" width="68" x="-34" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-24,-13)">
            <foreignobject height="26" width="48">
             <div style="display: inline-block; white-space: nowrap;">
              图优化
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-F-31" style="opacity: 1;" transform="translate(350,127)">
          <rect class="label-container" height="46" rx="0" ry="0" width="84" x="-42" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-32,-13)">
            <foreignobject height="26" width="64">
             <div style="display: inline-block; white-space: nowrap;">
              批量执行
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
        </g>
       </g>
      </g>
     </svg>
    </div>
    <p>
     特性对比表：
    </p>
    <table>
     <thead>
      <tr>
       <th>
        特性
       </th>
       <th>
        PyTorch动态图
       </th>
       <th>
        TensorFlow静态图
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        调试难度
       </td>
       <td>
        支持pdb实时调试
       </td>
       <td>
        需借助tf.debug工具
       </td>
      </tr>
      <tr>
       <td>
        灵活性
       </td>
       <td>
        支持条件分支
       </td>
       <td>
        图结构固定
       </td>
      </tr>
      <tr>
       <td>
        部署方式
       </td>
       <td>
        TorchScript转换
       </td>
       <td>
        SavedModel直接导出
       </td>
      </tr>
     </tbody>
    </table>
    <ol start="2">
     <li>
      <p>
       <strong>
        GPU加速与CUDA支持
       </strong>
      </p>
      <ul>
       <li>
        PyTorch支持GPU加速，可以通过CUDA来利用GPU的强大计算能力。开发者可以将张量和模型移动到GPU上进行计算，从而大大提高计算速度。
       </li>
       <li>
        要使用GPU加速，需要确保你的系统安装了支持CUDA的显卡，并正确安装了CUDA驱动程序和相关库。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        自动微分系统（Autograd）
       </strong>
      </p>
      <ul>
       <li>
        PyTorch的自动微分系统Autograd能够自动计算张量的梯度，这对于神经网络的训练至关重要。开发者只需要定义前向传播过程，Autograd会自动计算反向传播所需的梯度。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h3>
     <a id="Tensor_57">
     </a>
     三、核心数据结构-Tensor
    </h3>
    <h4>
     <a id="1__58">
     </a>
     1. 基础操作速查表
    </h4>
    <table>
     <thead>
      <tr>
       <th>
        操作类型
       </th>
       <th>
        代码示例
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        创建张量
       </td>
       <td>
        <code>
         torch.zeros(3,2)
        </code>
       </td>
      </tr>
      <tr>
       <td>
        随机初始化
       </td>
       <td>
        <code>
         torch.randn(3,3)
        </code>
       </td>
      </tr>
      <tr>
       <td>
        类型转换
       </td>
       <td>
        <code>
         tensor.float()
        </code>
       </td>
      </tr>
      <tr>
       <td>
        数学运算
       </td>
       <td>
        <code>
         torch.matmul(A, B)
        </code>
       </td>
      </tr>
     </tbody>
    </table>
    <h4>
     <a id="2_Numpy_66">
     </a>
     2. Numpy互操作性
    </h4>
    <pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
arr <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>arr<span class="token punctuation">)</span>  <span class="token comment"># Numpy转Tensor</span>
new_arr <span class="token operator">=</span> tensor<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># Tensor转Numpy</span>
</code></pre>
    <hr/>
    <h4>
     <a id="3__76">
     </a>
     3. 神经网络构建基础示例
    </h4>
    <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="4__92">
     </a>
     4. 激活函数选择指南
    </h4>
    <table>
     <thead>
      <tr>
       <th>
        函数类型
       </th>
       <th>
        适用场景
       </th>
       <th>
        PyTorch实现
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        ReLU
       </td>
       <td>
        隐藏层首选
       </td>
       <td>
        <code>
         nn.ReLU()
        </code>
       </td>
      </tr>
      <tr>
       <td>
        Sigmoid
       </td>
       <td>
        二分类输出层
       </td>
       <td>
        <code>
         nn.Sigmoid()
        </code>
       </td>
      </tr>
      <tr>
       <td>
        Softmax
       </td>
       <td>
        多分类输出层
       </td>
       <td>
        <code>
         nn.Softmax(dim=1)
        </code>
       </td>
      </tr>
     </tbody>
    </table>
    <hr/>
    <h3>
     <a id="_101">
     </a>
     四、线性回归完整实现
    </h3>
    <pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># 数据生成与可视化</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>X <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>X<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.8</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span>

<span class="token comment"># 模型定义</span>
model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">)</span>

<span class="token comment"># 训练过程</span>
loss_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
    
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    loss_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 结果可视化</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>loss_history<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>
</code></pre>
    <hr/>
    <h4>
     <a id="_135">
     </a>
     五、常见问题及避坑指南
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        维度不匹配错误
       </strong>
      </p>
      <pre><code class="prism language-python"><span class="token comment"># 错误示例：矩阵乘法维度不匹配</span>
A <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
B <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>A<span class="token punctuation">,</span> B<span class="token punctuation">)</span>  <span class="token comment"># 触发RuntimeError</span>
</code></pre>
      <p>
       <strong>
        解决方案
       </strong>
       ：使用
       <code>
        torch.reshape()
       </code>
       或
       <code>
        torch.unsqueeze()
       </code>
       调整维度
      </p>
     </li>
     <li>
      <p>
       <strong>
        梯度累积问题
       </strong>
      </p>
      <pre><code class="prism language-python"><span class="token comment"># 正确做法：每个batch前清空梯度</span>
<span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
     </li>
     <li>
      <p>
       <strong>
        GPU显存溢出
       </strong>
      </p>
      <ul>
       <li>
        使用
        <code>
         batch_size=32
        </code>
        逐步调试
       </li>
       <li>
        检查是否有未释放的中间变量
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h3>
     <a id="_162">
     </a>
     六、总结说明
    </h3>
    <p>
     通过本阶段的学习，我们了解了PyTorch的基本概念和核心特性，掌握了张量的基本操作和神经网络的构建方法，并通过一个简单的线性回归示例进行了实践。PyTorch的灵活性和强大功能为我们后续深入学习深度学习奠定了基础。
    </p>
    <h3>
     <a id="_165">
     </a>
     七、结语
    </h3>
    <p>
     PyTorch是一个非常强大且易于使用的深度学习框架，适合初学者入门和开发者进行各种深度学习项目。希望本篇学习指南能够帮助你迈出PyTorch学习的第一步，期待你在后续的学习和实践中不断探索，利用PyTorch构建出更加优秀的模型。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f753031343136313836342f:61727469636c652f64657461696c732f313436303631313237" class_="artid" style="display:none">
 </p>
</div>


