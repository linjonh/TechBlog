---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f35323337303835302f:61727469636c652f64657461696c732f313436313035333630"
layout: post
title: "机器学习基础4"
date: 2025-03-07 21:19:09 +08:00
description: "对于一个二分类问题，如果90%的样本属于类别A，10%的样本属于类别B，那么一个总是预测类别A的分类器就已经达到了0.9的验证精度，你需要做得比这更好。在面对一个全新的问题时，你需要设定一个可以参考的基于常识的基准，这很重要。假设你要对数字图像进行分类，而初始样本是按类别排序的，如果你将前80%作为训练集，剩余20%作为测试集，那么会导致训练集中只包含类别0～7，而测试集中只包含类别8和9。有了评估模型性能的可靠方法，你就可以监控机器学习的核心矛盾——优化与泛化之间的矛盾，以及欠拟合与过拟合之间的矛盾。"
keywords: "机器学习基础（4）"
categories: ['未分类']
tags: ['神经网络', '深度学习', '机器学习', '人工智能', 'Python']
artid: "146105360"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146105360
    alt: "机器学习基础4"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146105360
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146105360
cover: https://bing.ee123.net/img/rand?artid=146105360
image: https://bing.ee123.net/img/rand?artid=146105360
img: https://bing.ee123.net/img/rand?artid=146105360
---

# 机器学习基础（4）

### 超越基于常识的基准

除了不同的评估方法，还应该利用基于常识的基准。训练深度学习模型就好比在平行世界里按下发射火箭的按钮，你听不到也看不到。你无法观察流形学习过程，它发生在数千维空间中，即使投影到三维空间中，你也无法解释它。唯一的反馈信号就是
**验证指标**
，就像隐形火箭的高度计。特别重要的是，我们需要知道火箭是否离开了地面。发射地点的海拔高度是多少？模型似乎有15%的精度——这算是很好吗？在开始处理一个数据集之前，你总是应该选择一个简单的基准，并努力去超越它。如果跨过了这道门槛，你就知道你的方向对了——模型正在使用输入数据中的信息做出具有泛化能力的预测，你可以继续做下去。这个基准既可以是随机分类器的性能，也可以是最简单的非机器学习方法的性能。

比如对于MNIST数字分类示例，一个简单的基准是验证精度大于0.1（随机分类器）；对于IMDB示例，基准可以是验证精度大于0.5。对于路透社示例，由于类别不均衡，因此基准约为0.18～0.19。对于一个二分类问题，如果90%的样本属于类别A，10%的样本属于类别B，那么一个总是预测类别A的分类器就已经达到了0.9的验证精度，你需要做得比这更好。在面对一个全新的问题时，你需要设定一个可以参考的基于常识的基准，这很重要。如果无法超越简单的解决方案，那么你的模型毫无价值——也许你用错了模型，也许你的问题根本不能用机器学习方法来解决。这时应该重新思考解决问题的思路。

### 模型评估的注意事项

选择模型评估方法时，需要注意以下几点。
**数据代表性（data representativeness）**
。训练集和测试集应该都能够代表当前数据。假设你要对数字图像进行分类，而初始样本是按类别排序的，如果你将前80%作为训练集，剩余20%作为测试集，那么会导致训练集中只包含类别0～7，而测试集中只包含类别8和9。这个错误看起来很可笑，但非常常见。因此，将数据划分为训练集和测试集之前，通常应该随机打乱数据。

时间箭头（the arrow of time）。如果想根据过去预测未来（比如明日天气、股票走势等），那么在划分数据前不应该随机打乱数据，因为这么做会造成时间泄露（temporal leak）：模型将在未来数据上得到有效训练。对于这种情况，应该始终确保测试集中所有数据的时间都晚于训练数据。数据冗余（redundancy in your data）。如果某些数据点出现了两次（这对于现实世界的数据来说十分常见），那么打乱数据并划分成训练集和验证集，将导致训练集和验证集之间出现冗余。从效果上看，你将在部分训练数据上评估模型，这是极其糟糕的。一定要确保训练集和验证集之间没有交集。

有了评估模型性能的可靠方法，你就可以监控机器学习的核心矛盾——优化与泛化之间的矛盾，以及欠拟合与过拟合之间的矛盾。

### 改进模型拟合

为了实现完美的拟合，你必须首先实现过拟合。由于事先并不知道界线在哪里，因此你必须穿过界线才能找到它。在开始处理一个问题时，你的初始目标是构建一个具有一定泛化能力并且能够过拟合的模型。得到这样一个模型之后，你的重点将是通过降低过拟合来提高泛化能力。在这一阶段，你会遇到以下3种常见问题。

训练不开始：训练损失不随着时间的推移而减小。

训练开始得很好，但模型没有真正泛化：模型无法超越基于常识的基准。

训练损失和验证损失都随着时间的推移而减小，模型可以超越基准，但似乎无法过拟合，这表示模型仍然处于欠拟合状态。

我们来看一下如何解决这些问题，从而抵达机器学习项目的第一个重要里程碑：得到一个具有一定泛化能力（可以超越简单的基准）并且能够过拟合的模型。

### 调节关键的梯度下降参数

有时训练不开始，或者过早停止。损失保持不变。这个问题总是可以解决的——请记住，对随机数据也可以拟合一个模型。即使你的问题毫无意义，也应该可以训练出一个模型，不过模型可能只是记住了训练数据。

出现这种情况时，问题总是出在梯度下降过程的配置：优化器、模型权重初始值的分布、学习率或批量大小。所有这些参数都是相互依赖的，因此，保持其他参数不变，调节学习率和批量大小通常就足够了。我们来看一个具体的例子：训练MNIST模型，但选取一个过大的学习率（取值为1），如代码清单5-7所示。

代码清单5-7　使用过大的学习率训练MNIST模型

```python
(train_images, train_labels), _ = mnist.load_data()

train_images = train_images.reshape((60000, 28 * 28))

train_images = train_images.astype("float32") / 255

model = keras.Sequential([

    layers.Dense(512, activation="relu"),

    layers.Dense(10, activation="softmax")

])

model.compile(optimizer=keras.optimizers.RMSprop(1.),

              loss="sparse_categorical_crossentropy",

              metrics=["accuracy"])

model.fit(train_images, train_labels,

          epochs=10,

          batch_size=128,

          validation_split=0.2)

```

这个模型的训练精度和验证精度很快就达到了30%～40%，但无法超出这个范围。下面我们试着把学习率降低到一个更合理的值1e-2，如代码清单5-8所示。

代码清单5-8　使用更合理的学习率训练同一个模型

```python
model = keras.Sequential([

    layers.Dense(512, activation="relu"),

    layers.Dense(10, activation="softmax")

])

model.compile(optimizer=keras.optimizers.RMSprop(1e-2),

              loss="sparse_categorical_crossentropy",

              metrics=["accuracy"])

model.fit(train_images, train_labels,

          epochs=10,

          batch_size=128,

          validation_split=0.2)

```

现在模型可以正常训练了。

如果你自己的模型出现类似的问题，那么可以尝试以下做法。降低或提高学习率。学习率过大，可能会导致权重更新大大超出正常拟合的范围，就像前面的例子一样。学习率过小，则可能导致训练过于缓慢，以至于几乎停止。增加批量大小。如果批量包含更多样本，那么梯度将包含更多信息且噪声更少（方差更小）。最终，你会找到一个能够开始训练的配置。