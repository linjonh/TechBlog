---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34333532363434332f:61727469636c652f64657461696c732f313436313035313238"
layout: post
title: "语言模型作为零样本规划者提取可执行知识以供具身代理使用"
date: 2025-03-07 21:05:37 +08:00
description: "近年来，预训练的神经语言模型在未标记文本上训练后，能够隐式地存储和检索知识，使用自然语言查询。本文通过微调预训练模型来回答问题，而无需任何外部上下文或知识，来测量这一方法的实际使用价值。结果显示，该方法随着模型规模的增加而扩展，并在回答问题时与从外部知识源显式检索答案的开放式系统竞争。为了促进可重现性和未来工作，我们发布了代码和训练模型。本文研究了大型语言模型通过预训练存储和检索知识的能力。"
keywords: "语言模型作为零样本规划者：提取可执行知识以供具身代理使用"
categories: ['人工智能Ai']
tags: ['语言模型', '深度学习', '人工智能']
artid: "146105128"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146105128
    alt: "语言模型作为零样本规划者提取可执行知识以供具身代理使用"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146105128
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146105128
cover: https://bing.ee123.net/img/rand?artid=146105128
image: https://bing.ee123.net/img/rand?artid=146105128
img: https://bing.ee123.net/img/rand?artid=146105128
---

# 语言模型作为零样本规划者：提取可执行知识以供具身代理使用

## 【摘要】

本文研究了预训练的语言模型（LLMs）能否被用来执行在交互式环境中的任务。作者发现，尽管LLMs在生成高阶任务的行动计划时可能无法做到完全精确定义，但通过适当提示，大型预训练语言模型可以分解高阶任务到中阶计划。然而，这些计划往往不能直接映射到可执行的动作。作者提出了一种程序，将现有演示和语义翻译结合，以生成可执行的动作。在VirtualHome环境中，这种方法相比LLM基线显著提高了可执行性。尽管在执行性上有所提升，但正确性有所下降，这表明提取可执行知识的潜力。

具体任务案例：

1. 任务：刷牙
2. 详细步骤：去浴室 -> 走到洗脸盆 -> 找到牙刷 -> 拿起牙刷 -> 在嘴边刷牙两分钟 -> 吐出口腔清洁剂 -> 将牙刷放入水槽 -> 开水龙头 -> 用水冲洗牙刷一分钟 -> 关水龙头 -> 回到衣柜
3. 任务：扔掉废纸
4. 详细步骤：走到家庭办公室 -> 走到桌子 -> 找到桌子 -> 转向桌子 -> 找到椅子 -> 坐在椅子上 -> 找到支票 -> 抓起支票 -> 挤压支票 -> 站起来 -> 走到垃圾桶 -> 将支票放在垃圾桶 -> 打开水龙头 -> 用水冲洗支票一分钟 -> 关闭水龙头 -> 回到椅子上
5. 任务：取一杯牛奶
6. 详细步骤：走到厨房 -> 打开冰箱 -> 拿起牛奶 -> 关上冰箱 -> …

总结：

* 作者发现大型预训练语言模型可以在不经过进一步训练的情况下生成合理的目标驱动行动计划，但这些计划在交互环境中往往不可执行。
* 提出了一种将生成的行动计划翻译成可执行动作的方法，显著提高了行动计划的可执行性，但同时也降低了正确性。
* 通过这种方法，研究者展示了将语言模型中的知识应用于交互环境的潜力。

这些发现表明，通过适当的提示和翻译，预训练的语言模型可以生成在交互环境中可执行的行动计划，但同时也需要权衡正确性和执行性之间的关系。

## 【数据来源】

#### 论文《语言模型作为零样本规划者：从自然语言提取可执行知识以实现具身代理》的数据来源总结

##### 论文信息

* **作者**
  ：Wenlong Huang, Pieter Abbeel, Deepak Pathak, Igor Mordatch
* **机构**
  ：加州大学伯克利分校，谷歌
* **摘要**
  ：本文探索了是否可以将大型语言模型（LLMs）学到的世界知识用于交互环境中的行动。研究发现，如果预训练的大型语言模型足够大且提示适当，它们可以在没有进一步训练的情况下将高层任务分解为中层计划。然而，模型生成的计划往往是不可执行的，作者提出了一种方法，通过现有演示文稿和语义翻译将计划转化为可执行的动作。评价结果显示，该方法在环境中的可执行性显著提高。

##### 数据来源和实验环境

* **实验环境**
  ：VirtualHome

  + VirtualHome可以模拟各种现实的人类活动，并支持通过具身动作（以动词-对象语法形式定义）执行这些活动。
  + 该环境用于评估生成的行动计划的可执行性和正确性。
* **数据集**
  ：

  + ActivityPrograms数据集：包含2821个由亚马逊众包工人标注的任务，每个任务包含详细步骤和执行步骤的程序。
  + 评估任务：使用这些任务进行评估，包括生成动作计划的正确性和可执行性。

##### 实验数据

* **实验方法**
  ：

  + 从预训练的语言模型查询动作计划。
  + 通过语义翻译将不可执行的动作转化为可执行的动作。
  + 自回归轨迹校正。
  + 动态示例选择以提高知识提取。
* **实验结果**
  ：

  + 大型语言模型（如GPT-3）可以生成高度现实的动作计划，但这些计划在交互环境中往往是不可执行的。
  + 通过语义翻译，可显著提高计划的可执行性，但会牺牲正确性。
  + 人工评估结果显示，生成的计划在正确性和可执行性之间存在权衡。

##### 实验任务示例

* **任务1：刷牙**

  + **GPT-2 1.5B**

    ```
    Task: Brush teeth
    Step 1: Walk to bathroom
    Step 2: Walk to sink
    Step 3: Find toothbrush
    Step 4: Pick up toothbrush
    Step 5: Put toothbrush in mouth
    ...

    ```
  + **Codex 12B**

    ```
    Task: Brush teeth
    Step 1: Walk to bathroom
    Step 2: Open door
    Step 3: Walk to sink
    ...

    ```
* **任务2：扔掉纸张**

  + **GPT-3 175B**

    ```
    Task: Throw away paper
    Step 1: Walk to home office
    Step 2: Walk to desk
    Step 3: Find desk
    Step 4: Turn to desk
    ...

    ```
* **任务3：拿玻璃牛奶**

  + **GPT-3 175B**

    ```
    Task: Get Glass of Milk
    Step 1: Walk to Kitchen
    Step 2: Open Fridge
    Step 3: Grab Milk
    Step 4: Close Fridge

    ```

##### 总结

* **主要贡献**
  ：

  + 大型语言模型可以在没有额外训练的情况下生成合理的高层任务动作计划，但这些计划在交互环境中往往不可执行。
  + 提出了一种方法通过语义翻译将不可执行的动作转化为可执行的动作，显著提高了计划的可执行性。
  + 人工评估显示，在可执行性和正确性之间存在权衡。
* **未来工作**
  ：

  + 考虑进一步改进生成可执行计划的方法，如更精细的语义翻译和动态示例选择。
  + 探索将这些知识应用于更复杂的任务和环境。

以上是对论文《语言模型作为零样本规划者：从自然语言提取可执行知识以实现具身代理》的数据来源和实验方法的总结。

## 【模型架构】

论文《Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents》主要研究了如何利用大型语言模型（LLMs）生成执行任务的步骤计划，使得这些计划能够用于交互式的、具身的环境。通过虚幻家居（VirtualHome）环境进行评估，发现大型语言模型能够生成合理且实用的计划，但这些计划在某些方面（如可执行性）仍需要改进。以下是论文的主要内容总结：

#### 1. 背景和研究问题

1.1
**背景**
：

* 大型语言模型（如GPT-3和Codex）在近几年取得了显著的进步，能够处理复杂的自然语言任务。
* 这些模型被训练于大规模语料库，被认为包含了大量的世界知识，但这些知识主要以语言的形式存在。
* 作者研究问题：如何利用这些模型中的世界知识来生成执行具体任务的步骤计划，特别是在交互式的、具身的环境中。

#### 2. 方法

2.1
**查询语言模型生成步骤计划**
：

* 使用大型语言模型生成步骤计划的基本方法。
* 通过示例任务描述和步骤计划来查询模型，生成可能的步骤计划。

2.2
**语义翻译解析可执行动作**
：

* 由于直接生成的计划可能无法精确映射到可执行的动作，提出使用语义翻译将计划转换为具体的可执行动作。

2.3
**自回归轨迹修正**
：

* 在生成整个计划后进行逐步修正，自动调整生成的步骤以确保其可执行性。

2.4
**动态示例选择以提高知识提取**
：

* 在提取知识时，通过动态选择最相似的任务示例来改进知识提取过程。

#### 3. 实验设计

3.1
**评估框架**
：

* **环境**
  ：使用VirtualHome环境进行评估。
* **评估指标**
  ：可执行性和正确性。

#### 4. 实验结果

4.1
**大型语言模型是否包含可执行的知识**
？

* 大型语言模型在生成可执行的步骤计划方面表现出色，但这些计划在某些任务上可能不可执行。

4.2
**可执行性如何**
？

* 大型语言模型生成的计划在可执行性方面表现较好，但正确性可能较低。

4.3
**能否通过提出的程序使计划可执行**
？

* 通过语义翻译和自回归修正，可以显著提高计划的可执行性，但正确性可能降低。

#### 5. 分析与讨论

5.1
**设计决策的消融分析**
：

* 通过消融实验分析不同技术对生成计划质量的影响。

5.2
**计划是否符合环境**
：

* 评估生成的计划是否符合环境中的实际操作。

5.3
**不同翻译模型的影响**
：

* 探讨不同翻译模型对生成计划质量的影响。

5.4
**大型语言模型能否通过逐步指令生成可执行程序**
：

* 通过逐步指令指导模型生成可执行程序。

#### 6. 相关工作

* 概述了已有研究中利用语言模型生成执行计划的方法。

#### 7. 结论、局限性和未来工作

* 进一步研究方向及未来工作展望。

#### 8. 附录

* 详细描述了实验参数搜索、人工评估细节、评估的所有任务、自然语言模板以及随机生成的计划样本。

#### 9. 总结

* 提出了基于大型语言模型生成执行任务步骤计划的方法，通过语义翻译和自回归修正显著提高了生成计划的可执行性，但正确性可能有所下降。

## 【创新点】

该论文的主要创新点可以总结如下：

1. **零样本规划能力**
   ：提出了一种通过预训练语言模型（LLMs）来执行复杂任务的零样本规划方法。具体来说，论文展示了如何将高层次任务（如“做早餐”）分解成一系列可执行的动作步骤（如“打开冰箱”），而无需额外的训练。这一方法揭示了LLMs从文本中提取实际可执行知识的可能性。
2. **改善生成计划的执行性**
   ：论文提出了一套工具，通过翻译和调整语言模型生成的不可执行步骤，显著提高了生成计划的执行性。具体包括：

   * **语义翻译**
     ：将模型生成的不可执行动作步骤映射到可执行的动作。
   * **自回归轨迹矫正**
     ：通过逐步修正生成的计划来确保每一步都是可执行的。
   * **动态示例选择**
     ：通过提供与查询任务类似的任务示例来促进知识提取。
3. **评估方法**
   ：通过机械 Turk 人工评估来衡量生成计划的执行性和正确性之间的权衡。这种方法不仅展示了人工评估的必要性，也为后续研究提供了基准。
4. **实验结果**
   ：实验结果表明，尽管生成的计划在某些情况下不如人类编写得完美，但它们的执行性得到了显著提高。这表明通过适当的方法可以将LLMs的知识高效地应用到执行任务中。
5. **环境中的实际应用**
   ：论文通过虚拟家庭环境（VirtualHome）的实验，展示了如何将LLMs的知识应用到实际的交互式环境中，从而提高了任务执行的成功率。
6. **改进空间**
   ：虽然方法取得了显著进展，但仍存在一些改进空间，如正确性略有下降，以及处理某些特定任务时执行性不足等问题。这为未来的改进和研究提供了方向。

这些创新点为使用预训练语言模型执行复杂任务提供了新的技术路径，并展示了其实现可行性和潜在应用价值。

## 【应用场景】

该论文探讨了如何利用预训练的语言模型（LLMs）来解决交互环境中的任务规划问题。具体来说，研究者试图从LLMs中提取可用于执行复杂人类活动的指令性知识。以下是对论文主要技术应用场景的中文描述：

#### 应用场景描述

##### 1. 预训练语言模型作为零-shot规划器

* **任务背景**
  ：研究者利用预训练的语言模型（如GPT-2, GPT-3, Codex等）来生成能够执行复杂任务的指令性计划。这些模型在没有任何进一步训练的情况下，能够将高层次的任务（如“做早餐”）分解成一系列可执行的动作步骤（如“打开冰箱”）。
* **环境**
  ：研究使用了VirtualHome环境来模拟家庭环境中的各种活动。该环境支持通过文本指令来执行操作，这些操作是由一系列动词和对象组成的。
* **具体任务示例**
  ：
  + **任务1：刷牙**
    - **预训练GPT-2 1.5B**
      :
      * 步骤1: 走向浴室
      * 步骤2: 走向水槽
      * 步骤3: 找到牙刷
      * 步骤4: 拿起牙刷
      * 步骤5: 将牙刷放入嘴里刷牙两分钟
      * 步骤6: 吐出牙膏并将牙刷放入水槽
    - **预训练Codex 12B**
      :
      * 步骤1: 走向浴室
      * 步骤2: 打开水门
      * 步骤3: 走向水槽
      * 步骤4: 将锅放在水槽上
      * 步骤5: 将牙刷放在牙刷上
      * 步骤6: 走向牙膏
      * 步骤7: 将牙膏放在牙刷上
      * 步骤8: 走向牙齿
      * 步骤9: 将牙齿放在牙刷上
  + **任务2：扔掉纸张**
    - **预训练GPT-3 175B**
      :
      * 步骤1: 走向家庭办公室
      * 步骤2: 走向书桌
      * 步骤3: 找到书桌
      * 步骤4: 转向书桌
      * 步骤5: 找到椅子
      * 步骤6: 坐在椅子上
      * 步骤7: 找到支票
      * 步骤8: 拿起支票
      * 步骤9: 挤压支票
      * 步骤10: 站起来
      * 步骤11: 走向垃圾桶
      * 步骤12: 将支票放在垃圾桶上

##### 2. 提高指令生成的可执行性

* 研究者提出了一系列技术来提高生成指令的可执行性，这些技术包括：
  + **步骤1：基于现有示范和语义翻译生成可执行步骤**
    ：这种方法通过将预训练模型的输出与环境中的可执行动作进行语义对齐，来生成更精确的指令。
  + **步骤2：动态示例选择**
    ：这种方法通过利用预训练模型中的现有知识，来提高指令生成的准确性。具体做法是选择与查询任务最相似的示例来生成指令。
* **具体示例**
  ：这些技术显著提高了指令生成的可执行性，但同时也影响了指令的正确性。例如，通过这些技术，生成的指令从18%的可执行性提高到了79%。

##### 3. 任务举例

* **任务1：完成亚马逊土耳其调查**
  + **步骤1：走向家庭办公室**
  + **步骤2：打开电脑**
  + **步骤3：找到电脑**
  + **步骤4：启动电脑**
  + **步骤5：找到键盘**
  + **步骤6：在键盘上打字**
* **任务2：获取一杯牛奶**
  + **步骤1：走向厨房**
  + **步骤2：打开冰箱**
  + **步骤3：拿起牛奶**
  + **步骤4：关闭冰箱**

#### 总结

该研究展示了预训练的语言模型能够在没有任何进一步训练的情况下，生成可用于执行复杂任务的指令性计划。通过一系列技术改进，该研究显著提高了生成指令的可执行性，但同时也引入了一些正确性方面的妥协。这些技术对于将语言模型应用于交互式环境中的任务规划和执行具有重要意义。

## 【未来展望】

#### 技术未来展望：语言模型作为零样本规划者：从自然语言提取可执行知识为具身代理

##### 作者

Wenlong Huang
  
UC Berkeley
  
Pieter Abbeel
  
UC Berkeley
  
Deepak Pathak*
  
Carnegie Mellon University
  
Igor Mordatch*
  
Google

##### 摘要

大型语言模型（LLMs）学习到的世界知识能否用于交互环境中的操作？本文研究了将高级任务（例如，“做早餐”）分解为具体步骤（例如，“打开冰箱”）的可能性。尽管先前的工作集中在学习通过明确的步骤来执行操作，但令人惊讶的是，如果预训练的语义足够大且适当提示，它们可以有效地将高级任务分解为中间计划，而无需进一步训练。然而，LLMs生成的计划通常不能精确映射到可执行动作。我们提出了一种方法，通过现有演示和语义翻译计划来条件化这些计划，使它们映射到可执行动作。在近期VirtualHome环境中的评估表明，这种方法在可执行性方面显著优于LLM基线。进行的人类评估揭示了可执行性和正确性之间的权衡，但显示了从语言模型中提取可执行知识的前景。

##### 技术展望与未来工作

* **任务：刷牙**

  + **步骤1：去浴室**

    - **GPT-2 1.5B**
      * 任务：刷牙
      * 步骤1：走向浴室
    - **Codex 12B**
      * 任务：刷牙
      * 步骤1：走向浴室
    - **GPT-3 13B**
      * 任务：刷牙
      * 步骤1：走向浴室
    - **GPT-3 175B**
      * 任务：刷牙
      * 步骤1：走向浴室
    - **翻译Codex 12B**
      * 任务：丢掉废纸
      * 步骤1：走向家庭办公室
  + **人类**

    - 任务：刷牙
    - 步骤1：走向浴室
    - 步骤2：打开门
    - 步骤3：走向水槽
    - 步骤4：将锅放在水槽上
    - 步骤5：将牙刷放在牙刷上
    - 步骤6：找到牙膏
    - 步骤7：将牙膏放在牙刷上
    - 步骤8：将牙刷放在嘴里
    - 步骤9：刷牙两分钟
    - 步骤10：吐出牙膏，将牙刷放回水槽中
    - 步骤11：打开水槽的水
    - 步骤12：用牙刷冲洗一分钟
    - 步骤13：关闭水槽的水
    - 步骤14：将牙刷放回橱柜
* **结果**

  + **LSTM监督基线**
    - 任务：读书
    - 步骤1：走向家庭办公室
    - 步骤2：走向灯
    - 步骤3：找到灯
    - 步骤4：打开灯
    - 步骤5：找到小说
    - 步骤6：拿起小说
    - 步骤7：找到椅子
    - 步骤8：坐在椅子上
    - 步骤9：读小说
    - 步骤10：睡觉
    - 步骤11：醒来
* **分析与讨论**

  + 我们展示了通过语义翻译和自动轨迹校正，可以在保持一定正确性的前提下显著提高可执行性。
  + 更多样本可在附录A.5中找到。
* **相关工作**

  + 语言模型的快速发展帮助我们了解了这些模型如何从大规模未结构化文本中学习世界知识，并将其应用于各种下游任务。
  + 本研究旨在通过预训练语言模型提取序列动作计划以完成开放式人类活动，同时满足各种交互环境的要求。
* **结论**

  + 通过这项研究，我们发现预训练语言模型已经包含了大量的可执行知识，但这些知识需要通过适当的提示和语义翻译来提取和应用。
  + 未来工作可以进一步探索如何利用这些模型提取和应用于具身环境中的知识。

---

这项研究通过利用预训练语言模型生成合理的行动计划，并通过语义翻译和自动轨迹校正来提升计划的可执行性，展示了语言模型在具身环境中的应用前景。未来可以进一步探索如何利用这些模型从大规模文本中提取更复杂、更具体的任务知识，并应用于更广泛的具身场景中。

## 【附录】

以下是关于《Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents》的伪代码实现，重点是提取和执行高阶任务（如“刷牙”）的步骤。

#### 伪代码实现

```python
# 定义环境和任务
class Environment:
    def __init__(self):
        self.objects = {}  # 存储环境中的物体
        self.actions = {}  # 存储可执行的动作

    def add_object(self, name, object):
        self.objects[name] = object

    def add_action(self, name, action):
        self.actions[name] = action

# 初始化环境
env = Environment()

# 定义一个任务
def task(name, steps):
    return {"name": name, "steps": steps}

# 预训练语言模型
class PretrainedLanguageModel:
    def generate_plan(self, task_description):
        # 假设生成一个计划
        return "Generated Plan"

# 零样本规划器
class ZeroShotPlanner:
    def __init__(self, language_model: PretrainedLanguageModel):
        self.language_model = language_model

    def generate_action_plan(self, task):
        # 生成计划
        plan = self.language_model.generate_plan(task)
        return plan

# 生成可执行动作
class ActionTranslator:
    def translate(self, plan, environment):
        # 将生成的计划转换为可执行的动作
        translated_plan = []
        for step in plan:
            # 找到对应的可执行动作
            action = environment.actions.get(step, None)
            if action:
                translated_plan.append(action)
        return translated_plan

# 环境感知
class EnvironmentAwareness:
    def __init__(self, environment):
        self.environment = environment

    def get_state(self):
        # 获取当前环境的状态
        return self.environment.state

# 主程序
def main():
    # 初始化环境
    env = Environment()

    # 添加环境中的物体和动作
    env.add_object("fridge", "Fridge")
    env.add_object("sink", "Sink")
    env.add_object("toothbrush", "Toothbrush")
    env.add_object("toothpaste", "Toothpaste")

    env.add_action("open", "Open fridge")
    env.add_action("close", "Close fridge")
    env.add_action("grab", "Grab toothbrush")
    env.add_action("put", "Put toothbrush in sink")
    env.add_action("brush", "Brush teeth")
    env.add_action("rinse", "Rinse mouth")

    # 初始化语言模型和零样本规划器
    language_model = PretrainedLanguageModel()
    planner = ZeroShotPlanner(language_model)

    # 定义任务
    task_description = "brush teeth"
    task = task(task_description, [])

    # 生成计划
    plan = planner.generate_action_plan(task)

    # 初始化环境感知
    environment_awareness = EnvironmentAwareness(env)

    # 翻译计划为可执行的动作
    translator = ActionTranslator()
    executable_plan = translator.translate(plan, environment_awareness)

    # 执行动作
    for action in executable_plan:
        action.execute()

if __name__ == "__main__":
    main()

```

#### 详细说明

1. **环境和任务定义**
   :
   * `Environment`
     类用于定义和管理环境中的物体和动作。
   * `task`
     函数用于定义一个任务，包含任务名称和步骤。
2. **预训练语言模型**
   :
   * `PretrainedLanguageModel`
     类用于生成任务的计划。
3. **零样本规划器**
   :
   * `ZeroShotPlanner`
     类用于调用语言模型生成任务计划。
4. **生成可执行动作**
   :
   * `ActionTranslator`
     类用于将生成的计划转换为可执行的动作。
5. **环境感知**
   :
   * `EnvironmentAwareness`
     类用于获取环境的当前状态。
6. **主程序**
   :
   * 初始化环境并添加物体和动作。
   * 使用语言模型生成任务计划。
   * 使用翻译器将计划转换为可执行的动作。
   * 执行动作。

以上伪代码展示了如何使用预训练的语言模型生成任务计划，并将其转换为可执行的动作，从而实现零样本规划。

## 【OpenSpace】

#### 开放性讨论：语言模型作为零样本规划者

##### 背景介绍

在本论文中，Wenlong Huang、Pieter Abbeel 和其他作者研究了如何利用大型语言模型（LLMs）来为具身智能体（embodied agents）生成可执行的操作计划。他们发现，尽管大型语言模型可以很好地理解高阶任务，但它们生成的计划往往与实际可执行的步骤不匹配，可能包含语义模糊或未包含必要步骤的问题。为了解决这个问题，作者提出了一种方法来改进生成的操作计划的可执行性，同时保持其语义正确性。

##### 讨论问题

1. **大型语言模型是否能够生成可执行的操作计划？**

   * 大型语言模型是否能够在不经过额外训练的情况下生成合理的操作计划？
   * 生成的操作计划在多大程度上能够直接执行，而不需要进一步的调整？
2. **如何改善生成的计划的可执行性？**

   * 作者提出了哪些具体工具和技术来提高生成的操作计划的可执行性？
   * 这些工具和技术在执行过程中是否会影响计划的语义正确性？
3. **零样本规划（zero-shot planning）的有效性如何？**

   * 使用零样本规划方法生成的操作计划是否能够在实际环境中执行？
   * 通过翻译和调整语言模型生成的操作计划，是否能够在保持语义正确性的前提下提高可执行性？
4. **未来的改进方向是什么？**

   * 作者认为有哪些方面可以进一步改进？
   * 如何进一步利用零样本规划方法来提高实际应用中的可执行性？

##### 具体例子

* **Task: 刷牙**
  + **GPT-2 1.5B:**
    1. 走向浴室
    2. 走向水槽
    3. 找到牙刷
    4. 拿起牙刷
    5. 将牙刷放入嘴里
    6. 用牙刷刷牙两分钟
    7. 吐出牙膏，刷牙放入水槽
  + **Codex 12B:**
    1. 走向浴室
    2. 打开门
    3. 走向水槽
    4. 将锅放在水槽上
    5. 将刷子放在牙刷上
    6. 转向牙膏
    7. 放牙膏在牙刷上
    8. 放牙齿在牙刷上
  + **人类:**
    1. 走向家庭办公室
    2. 走向垃圾桶
    3. 找到垃圾桶
    4. 转向垃圾桶
    5. 找到椅子
    6. 坐在椅子上
    7. 找到支票
    8. 抓起支票
    9. 挤压支票
    10. 站起来
    11. 走向垃圾桶
    12. 将支票放在垃圾桶上

通过这些例子，可以看到大型语言模型生成的操作计划虽然在语义上是合理的，但在实际执行时往往不够精确和可操作。通过翻译和调整，可以显著提高计划的可执行性，但同时可能会减少其语义正确性。

##### 未来研究方向

* **进一步改进零样本规划方法：**
  如何更好地利用零样本规划方法生成更精确和可执行的操作计划？
* **增强模型的理解能力：**
  如何进一步提高语言模型对任务和环境的理解能力，以便生成更精确的操作计划？
* **结合更多环境信息：**
  如何利用更多环境信息来增强生成的操作计划的可执行性？

通过这些讨论，我们可以更深入地理解如何利用大型语言模型来生成和优化可执行的操作计划，以实现更好的具身智能体任务执行。