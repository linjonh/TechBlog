---
layout: post
title: "RAGRAG-系统的基本搭建流程ES关键词检索示例"
date: 2025-03-09 18:15:00 +0800
description: "RAG 搭建之ES检索示例，Query -> ES检索 -> Prompt -> LLM -> 回复"
keywords: "【RAG】RAG 系统的基本搭建流程（ES关键词检索示例）"
categories: ['Python']
tags: ['Python', 'Elasticsearch']
artid: "146135380"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146135380
    alt: "RAGRAG-系统的基本搭建流程ES关键词检索示例"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146135380
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146135380
cover: https://bing.ee123.net/img/rand?artid=146135380
image: https://bing.ee123.net/img/rand?artid=146135380
img: https://bing.ee123.net/img/rand?artid=146135380
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     【RAG】RAG 系统的基本搭建流程（ES关键词检索示例）
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h2>
     <a id="RAG__0">
     </a>
     RAG 系统的基本搭建流程
    </h2>
    <p>
     搭建过程：
    </p>
    <ol>
     <li>
      文档加载，并按一定条件
      <strong>
       切割
      </strong>
      成片段
     </li>
     <li>
      将切割的文本片段灌入
      <strong>
       检索引擎
      </strong>
     </li>
     <li>
      封装
      <strong>
       检索接口
      </strong>
     </li>
     <li>
      构建
      <strong>
       调用流程
      </strong>
      ：Query -&gt; 检索 -&gt; Prompt -&gt; LLM -&gt; 回复
     </li>
    </ol>
    <h3>
     <a id="1__9">
     </a>
     1. 文档的加载与切割
    </h3>
    <pre><code class="prism language-python"><span class="token comment"># !pip install --upgrade openai</span>
<span class="token comment"># 安装 pdf 解析库</span>
<span class="token comment"># !pip install pdfminer.six</span>
<span class="token keyword">from</span> pdfminer<span class="token punctuation">.</span>high_level <span class="token keyword">import</span> extract_pages
<span class="token keyword">from</span> pdfminer<span class="token punctuation">.</span>layout <span class="token keyword">import</span> LTTextContainer


<span class="token keyword">def</span> <span class="token function">extract_text_from_pdf</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> page_numbers<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> min_line_length<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''从 PDF 文件中（按指定页码）提取文字'''</span>
    paragraphs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token builtin">buffer</span> <span class="token operator">=</span> <span class="token string">''</span>
    full_text <span class="token operator">=</span> <span class="token string">''</span>
    <span class="token comment"># 提取全部文本</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> page_layout <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>extract_pages<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 如果指定了页码范围，跳过范围外的页</span>
        <span class="token keyword">if</span> page_numbers <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> i <span class="token keyword">not</span> <span class="token keyword">in</span> page_numbers<span class="token punctuation">:</span>
            <span class="token keyword">continue</span>
        <span class="token keyword">for</span> element <span class="token keyword">in</span> page_layout<span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>element<span class="token punctuation">,</span> LTTextContainer<span class="token punctuation">)</span><span class="token punctuation">:</span>
                full_text <span class="token operator">+=</span> element<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span>
    <span class="token comment"># 按空行分隔，将文本重新组织成段落</span>
    lines <span class="token operator">=</span> full_text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> text <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> min_line_length<span class="token punctuation">:</span>
            <span class="token builtin">buffer</span> <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token string">' '</span><span class="token operator">+</span>text<span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token keyword">not</span> text<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'-'</span><span class="token punctuation">)</span> <span class="token keyword">else</span> text<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">'-'</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> <span class="token builtin">buffer</span><span class="token punctuation">:</span>
            paragraphs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>
            <span class="token builtin">buffer</span> <span class="token operator">=</span> <span class="token string">''</span>
    <span class="token keyword">if</span> <span class="token builtin">buffer</span><span class="token punctuation">:</span>
        paragraphs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> paragraphs


paragraphs <span class="token operator">=</span> extract_text_from_pdf<span class="token punctuation">(</span><span class="token string">"llama2.pdf"</span><span class="token punctuation">,</span> min_line_length<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> para <span class="token keyword">in</span> paragraphs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>para<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
<span class="token comment">######</span>
<span class="token comment">##输出：</span>
Llama <span class="token number">2</span><span class="token punctuation">:</span> Open Foundation <span class="token keyword">and</span> Fine<span class="token operator">-</span>Tuned Chat Models

 Hugo Touvron∗ Louis Martin† Kevin Stone† Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev Punit Singh Koura Marie<span class="token operator">-</span>Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic Sergey Edunov Thomas Scialom∗

 GenAI<span class="token punctuation">,</span> Meta

</code></pre>
    <p>
     这段代码实现了从PDF文档中提取文本并按段落进行切割的功能，是构建RAG（检索增强生成）系统中文档处理的关键步骤。下面详细解析其工作原理和实现逻辑：
    </p>
    <hr/>
    <h4>
     <a id="1__65">
     </a>
     <strong>
      1. 环境准备
     </strong>
    </h4>
    <pre><code class="prism language-python"><span class="token comment"># !pip install --upgrade openai</span>
<span class="token comment"># !pip install pdfminer.six</span>
<span class="token keyword">from</span> pdfminer<span class="token punctuation">.</span>high_level <span class="token keyword">import</span> extract_pages
<span class="token keyword">from</span> pdfminer<span class="token punctuation">.</span>layout <span class="token keyword">import</span> LTTextContainer
</code></pre>
    <ul>
     <li>
      <strong>
       pdfminer.six
      </strong>
      ：PDF解析库，用于提取PDF中的文本和布局信息。
     </li>
     <li>
      <code>
       extract_pages
      </code>
      ：逐页解析PDF文档。
     </li>
     <li>
      <code>
       LTTextContainer
      </code>
      ：识别PDF中的文本块（段落或文字区域）。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="2__extract_text_from_pdf_78">
     </a>
     <strong>
      2. 核心函数
      <code>
       extract_text_from_pdf
      </code>
     </strong>
    </h4>
    <h5>
     <a id="_79">
     </a>
     <strong>
      输入参数
     </strong>
    </h5>
    <ul>
     <li>
      <code>
       filename
      </code>
      ：PDF文件路径。
     </li>
     <li>
      <code>
       page_numbers
      </code>
      ：指定提取的页码范围（可选）。
     </li>
     <li>
      <code>
       min_line_length
      </code>
      ：最小行长度阈值，用于过滤无意义的短行（如页码或页眉）。
     </li>
    </ul>
    <hr/>
    <h5>
     <a id="_86">
     </a>
     <strong>
      步骤解析
     </strong>
    </h5>
    <h6>
     <a id="1_87">
     </a>
     <strong>
      步骤1：逐页提取文本
     </strong>
    </h6>
    <pre><code class="prism language-python"><span class="token keyword">for</span> i<span class="token punctuation">,</span> page_layout <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>extract_pages<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> page_numbers <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> i <span class="token keyword">not</span> <span class="token keyword">in</span> page_numbers<span class="token punctuation">:</span>
        <span class="token keyword">continue</span>
    <span class="token keyword">for</span> element <span class="token keyword">in</span> page_layout<span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>element<span class="token punctuation">,</span> LTTextContainer<span class="token punctuation">)</span><span class="token punctuation">:</span>
            full_text <span class="token operator">+=</span> element<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span>
</code></pre>
    <ul>
     <li>
      遍历PDF每一页，通过
      <code>
       LTTextContainer
      </code>
      识别文本块。
     </li>
     <li>
      将文本块内容拼接为
      <code>
       full_text
      </code>
      ，并用换行符分隔不同文本块。
     </li>
    </ul>
    <h6>
     <a id="2_99">
     </a>
     <strong>
      步骤2：处理换行与断词
     </strong>
    </h6>
    <pre><code class="prism language-python">lines <span class="token operator">=</span> full_text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> text <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> min_line_length<span class="token punctuation">:</span>
        <span class="token builtin">buffer</span> <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token string">' '</span><span class="token operator">+</span>text<span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token keyword">not</span> text<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'-'</span><span class="token punctuation">)</span> <span class="token keyword">else</span> text<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">'-'</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> <span class="token builtin">buffer</span><span class="token punctuation">:</span>
        paragraphs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>
        <span class="token builtin">buffer</span> <span class="token operator">=</span> <span class="token string">''</span>
</code></pre>
    <ul>
     <li>
      <strong>
       断词处理
      </strong>
      ：若行以连字符
      <code>
       -
      </code>
      结尾，表示单词跨行，需拼接（如
      <code>
       "inter- esting"
      </code>
      合并为
      <code>
       "interesting"
      </code>
      ）。
     </li>
     <li>
      <strong>
       空格拼接
      </strong>
      ：普通行首添加空格，避免直接拼接导致单词粘连。
     </li>
    </ul>
    <h6>
     <a id="3_112">
     </a>
     <strong>
      步骤3：段落切割
     </strong>
    </h6>
    <ul>
     <li>
      当遇到短行（如空行或页眉），将
      <code>
       buffer
      </code>
      中的内容作为一个段落存入
      <code>
       paragraphs
      </code>
      。
     </li>
     <li>
      遍历结束后，检查
      <code>
       buffer
      </code>
      是否剩余内容并存入。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="3__118">
     </a>
     <strong>
      3. 代码调用示例
     </strong>
    </h4>
    <pre><code class="prism language-python">paragraphs <span class="token operator">=</span> extract_text_from_pdf<span class="token punctuation">(</span><span class="token string">"llama2.pdf"</span><span class="token punctuation">,</span> min_line_length<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> para <span class="token keyword">in</span> paragraphs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>para<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
</code></pre>
    <ul>
     <li>
      提取
      <code>
       llama2.pdf
      </code>
      中所有页的文本，过滤长度小于10的短行。
     </li>
     <li>
      打印前4个段落，验证输出效果。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="4__129">
     </a>
     <strong>
      4. 设计优缺点
     </strong>
    </h4>
    <h5>
     <a id="_130">
     </a>
     <strong>
      设计优点
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       跨页处理
      </strong>
      ：自动合并跨页的段落。
     </li>
     <li>
      <strong>
       断词修复
      </strong>
      ：处理因换行导致的单词拆分。
     </li>
     <li>
      <strong>
       灵活过滤
      </strong>
      ：通过
      <code>
       min_line_length
      </code>
      过滤无意义短行。
     </li>
    </ul>
    <h5>
     <a id="_135">
     </a>
     <strong>
      局限性
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       依赖PDF结构
      </strong>
      ：若PDF使用非标准布局（如分栏、图片内文字），提取可能不准确。
     </li>
     <li>
      <strong>
       段落切割逻辑
      </strong>
      ：依赖空行或短行分割段落，对无空行的长文本可能不够鲁棒。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="5__141">
     </a>
     <strong>
      5. 拓展建议
     </strong>
    </h4>
    <ul>
     <li>
      <strong>
       布局分析
      </strong>
      ：结合
      <code>
       LTFigure
      </code>
      或
      <code>
       LTImage
      </code>
      处理图片中的文本。
     </li>
     <li>
      <strong>
       高级分段
      </strong>
      ：使用NLP工具（如spacy）基于语义分割段落。
     </li>
     <li>
      <strong>
       并行处理
      </strong>
      ：对大文档采用多线程加速解析。
     </li>
    </ul>
    <hr/>
    <p>
     通过这段代码，可以实现基础的PDF文本提取与段落切割，为后续的向量化存储和检索增强生成（RAG）奠定基础。实际应用中需结合具体文档结构调整参数和逻辑。
    </p>
    <h3>
     <a id="2___150">
     </a>
     2. 检索引擎
    </h3>
    <p>
     先看一个最基础的ES实现
    </p>
    <pre><code class="prism language-python">pip install elasticsearch7

<span class="token comment"># 安装 NLTK（文本处理方法库）</span>

pip install nltk
</code></pre>
    <pre><code class="prism language-python"><span class="token keyword">from</span> elasticsearch7 <span class="token keyword">import</span> Elasticsearch<span class="token punctuation">,</span> helpers
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>stem <span class="token keyword">import</span> PorterStemmer
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> word_tokenize
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> stopwords
<span class="token keyword">import</span> nltk
<span class="token keyword">import</span> re

<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>simplefilter<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span>  <span class="token comment"># 屏蔽 ES 的一些Warnings</span>

nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'punkt'</span><span class="token punctuation">)</span>  <span class="token comment"># 英文切词、词根、切句等方法</span>
nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'stopwords'</span><span class="token punctuation">)</span>  <span class="token comment"># 英文停用词库</span>
nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'punkt_tab'</span><span class="token punctuation">)</span>



<span class="token keyword">def</span> <span class="token function">to_keywords</span><span class="token punctuation">(</span>input_string<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''（英文）文本只保留关键字'''</span>
    <span class="token comment"># 使用正则表达式替换所有非字母数字的字符为空格</span>
    no_symbols <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'[^a-zA-Z0-9\s]'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">,</span> input_string<span class="token punctuation">)</span>
    word_tokens <span class="token operator">=</span> word_tokenize<span class="token punctuation">(</span>no_symbols<span class="token punctuation">)</span>
    <span class="token comment"># 加载停用词表</span>
    stop_words <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>stopwords<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token string">'english'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    ps <span class="token operator">=</span> PorterStemmer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 去停用词，取词根</span>
    filtered_sentence <span class="token operator">=</span> <span class="token punctuation">[</span>ps<span class="token punctuation">.</span>stem<span class="token punctuation">(</span>w<span class="token punctuation">)</span>
                         <span class="token keyword">for</span> w <span class="token keyword">in</span> word_tokens <span class="token keyword">if</span> <span class="token keyword">not</span> w<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">in</span> stop_words<span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>filtered_sentence<span class="token punctuation">)</span>
<span class="token comment"># 此处 to_keywords 为针对英文的实现，针对中文的实现请参考 chinese_utils.py</span>
</code></pre>
    <p>
     将文本灌入检索引擎
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> os<span class="token punctuation">,</span> time

<span class="token comment"># 引入配置文件</span>
ELASTICSEARCH_BASE_URL <span class="token operator">=</span> os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">'ELASTICSEARCH_BASE_URL'</span><span class="token punctuation">)</span>
ELASTICSEARCH_PASSWORD <span class="token operator">=</span> os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">'ELASTICSEARCH_PASSWORD'</span><span class="token punctuation">)</span>
ELASTICSEARCH_NAME<span class="token operator">=</span> os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">'ELASTICSEARCH_NAME'</span><span class="token punctuation">)</span>

<span class="token comment"># 1. 创建Elasticsearch连接</span>
es <span class="token operator">=</span> Elasticsearch<span class="token punctuation">(</span>
    hosts<span class="token operator">=</span><span class="token punctuation">[</span>ELASTICSEARCH_BASE_URL<span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 服务地址与端口</span>
    http_auth<span class="token operator">=</span><span class="token punctuation">(</span>ELASTICSEARCH_NAME<span class="token punctuation">,</span> ELASTICSEARCH_PASSWORD<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 用户名，密码</span>
<span class="token punctuation">)</span>

<span class="token comment"># 2. 定义索引名称</span>
index_name <span class="token operator">=</span> <span class="token string">"teacher_demo_index111"</span>

<span class="token comment"># 3. 如果索引已存在，删除它（仅供演示，实际应用时不需要这步）</span>
<span class="token keyword">if</span> es<span class="token punctuation">.</span>indices<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>index<span class="token operator">=</span>index_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    es<span class="token punctuation">.</span>indices<span class="token punctuation">.</span>delete<span class="token punctuation">(</span>index<span class="token operator">=</span>index_name<span class="token punctuation">)</span>

<span class="token comment"># 4. 创建索引</span>
es<span class="token punctuation">.</span>indices<span class="token punctuation">.</span>create<span class="token punctuation">(</span>index<span class="token operator">=</span>index_name<span class="token punctuation">)</span>

<span class="token comment"># 5. 灌库指令</span>
actions <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token string">"_index"</span><span class="token punctuation">:</span> index_name<span class="token punctuation">,</span>
        <span class="token string">"_source"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">"keywords"</span><span class="token punctuation">:</span> to_keywords<span class="token punctuation">(</span>para<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">"text"</span><span class="token punctuation">:</span> para
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    <span class="token keyword">for</span> para <span class="token keyword">in</span> paragraphs
<span class="token punctuation">]</span>

<span class="token comment"># 6. 文本灌库</span>
helpers<span class="token punctuation">.</span>bulk<span class="token punctuation">(</span>es<span class="token punctuation">,</span> actions<span class="token punctuation">)</span>

<span class="token comment"># 灌库是异步的</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     实现关键字检索
    </p>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>query_string<span class="token punctuation">,</span> top_n<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># ES 的查询语言</span>
    search_query <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">"match"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">"keywords"</span><span class="token punctuation">:</span> to_keywords<span class="token punctuation">(</span>query_string<span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    res <span class="token operator">=</span> es<span class="token punctuation">.</span>search<span class="token punctuation">(</span>index<span class="token operator">=</span>index_name<span class="token punctuation">,</span> query<span class="token operator">=</span>search_query<span class="token punctuation">,</span> size<span class="token operator">=</span>top_n<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>hit<span class="token punctuation">[</span><span class="token string">"_source"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> hit <span class="token keyword">in</span> res<span class="token punctuation">[</span><span class="token string">"hits"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"hits"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    
results <span class="token operator">=</span> search<span class="token punctuation">(</span><span class="token string">"how many parameters does llama 2 have?"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> r <span class="token keyword">in</span> results<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
    
<span class="token comment">### 输出</span>
 <span class="token number">1.</span> Llama <span class="token number">2</span><span class="token punctuation">,</span> an updated version of Llama <span class="token number">1</span><span class="token punctuation">,</span> trained on a new mix of publicly available data<span class="token punctuation">.</span> We also increased the size of the pretraining corpus by <span class="token number">40</span><span class="token operator">%</span><span class="token punctuation">,</span> doubled the context length of the model<span class="token punctuation">,</span> <span class="token keyword">and</span> adopted grouped<span class="token operator">-</span>query attention <span class="token punctuation">(</span>Ainslie et al<span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2023</span><span class="token punctuation">)</span><span class="token punctuation">.</span> We are releasing variants of Llama <span class="token number">2</span> <span class="token keyword">with</span> 7B<span class="token punctuation">,</span> 13B<span class="token punctuation">,</span> <span class="token keyword">and</span> 70B parameters<span class="token punctuation">.</span> We have also trained 34B variants<span class="token punctuation">,</span> which we report on <span class="token keyword">in</span> this paper but are <span class="token keyword">not</span> releasing<span class="token punctuation">.</span>§
</code></pre>
    <h3>
     <a id="3_LLM_259">
     </a>
     3. LLM接口封装
    </h3>
    <pre><code class="prism language-python"><span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI
<span class="token keyword">import</span> os
<span class="token comment"># 加载环境变量</span>
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv<span class="token punctuation">,</span> find_dotenv
_ <span class="token operator">=</span> load_dotenv<span class="token punctuation">(</span>find_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 读取本地 .env 文件，里面定义了 OPENAI_API_KEY</span>

client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#%%</span>
<span class="token keyword">def</span> <span class="token function">get_completion</span><span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''封装 openai 接口'''</span>
    messages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span><span class="token punctuation">]</span>
    response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
        model<span class="token operator">=</span>model<span class="token punctuation">,</span>
        messages<span class="token operator">=</span>messages<span class="token punctuation">,</span>
        temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>  <span class="token comment"># 模型输出的随机性，0 表示随机性最小</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content
</code></pre>
    <h3>
     <a id="4_Prompt_281">
     </a>
     4. Prompt模版
    </h3>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">build_prompt</span><span class="token punctuation">(</span>prompt_template<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''将 Prompt 模板赋值'''</span>
    inputs <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
    <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> kwargs<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token builtin">all</span><span class="token punctuation">(</span><span class="token builtin">isinstance</span><span class="token punctuation">(</span>elem<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token keyword">for</span> elem <span class="token keyword">in</span> v<span class="token punctuation">)</span><span class="token punctuation">:</span>
            val <span class="token operator">=</span> <span class="token string">'\n\n'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>v<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            val <span class="token operator">=</span> v
        inputs<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> val
    <span class="token keyword">return</span> prompt_template<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>
prompt_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
你是一个问答机器人。
你的任务是根据下述给定的已知信息回答用户问题。

已知信息:
{context}

用户问：
{query}

如果已知信息不包含用户问题的答案，或者已知信息不足以回答用户的问题，请直接回复"我无法回答您的问题"。
请不要输出已知信息中不包含的信息或答案。
请用中文回答用户问题。
"""</span>
</code></pre>
    <h3>
     <a id="5_RAG_Pipeline_311">
     </a>
     5. RAG Pipeline
    </h3>
    <pre><code class="prism language-python">user_query <span class="token operator">=</span> <span class="token string">"how many parameters does llama 2 have?"</span>

<span class="token comment"># 1. 检索</span>
search_results <span class="token operator">=</span> search<span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># 2. 构建 Prompt</span>
prompt <span class="token operator">=</span> build_prompt<span class="token punctuation">(</span>prompt_template<span class="token punctuation">,</span> context<span class="token operator">=</span>search_results<span class="token punctuation">,</span> query<span class="token operator">=</span>user_query<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"===Prompt==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>

<span class="token comment"># 3. 调用 LLM</span>
response <span class="token operator">=</span> get_completion<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"===回复==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-python"><span class="token operator">==</span><span class="token operator">=</span>Prompt<span class="token operator">==</span><span class="token operator">=</span>

你是一个问答机器人。
你的任务是根据下述给定的已知信息回答用户问题。

已知信息<span class="token punctuation">:</span>
 <span class="token number">1.</span> Llama <span class="token number">2</span><span class="token punctuation">,</span> an updated version of Llama <span class="token number">1</span><span class="token punctuation">,</span> trained on a new mix of publicly available data<span class="token punctuation">.</span> We also increased the size of the pretraining corpus by <span class="token number">40</span><span class="token operator">%</span><span class="token punctuation">,</span> doubled the context length of the model<span class="token punctuation">,</span> <span class="token keyword">and</span> adopted grouped<span class="token operator">-</span>query attention <span class="token punctuation">(</span>Ainslie et al<span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2023</span><span class="token punctuation">)</span><span class="token punctuation">.</span> We are releasing variants of Llama <span class="token number">2</span> <span class="token keyword">with</span> 7B<span class="token punctuation">,</span> 13B<span class="token punctuation">,</span> <span class="token keyword">and</span> 70B parameters<span class="token punctuation">.</span> We have also trained 34B variants<span class="token punctuation">,</span> which we report on <span class="token keyword">in</span> this paper but are <span class="token keyword">not</span> releasing<span class="token punctuation">.</span>§

 In this work<span class="token punctuation">,</span> we develop <span class="token keyword">and</span> release Llama <span class="token number">2</span><span class="token punctuation">,</span> a collection of pretrained <span class="token keyword">and</span> ﬁne<span class="token operator">-</span>tuned large language models <span class="token punctuation">(</span>LLMs<span class="token punctuation">)</span> ranging <span class="token keyword">in</span> scale <span class="token keyword">from</span> <span class="token number">7</span> billion to <span class="token number">70</span> billion parameters<span class="token punctuation">.</span> Our ﬁne<span class="token operator">-</span>tuned LLMs<span class="token punctuation">,</span> called Llama <span class="token number">2</span><span class="token operator">-</span>Chat<span class="token punctuation">,</span> are optimized <span class="token keyword">for</span> dialogue use cases<span class="token punctuation">.</span> Our models outperform <span class="token builtin">open</span><span class="token operator">-</span>source chat models on most benchmarks we tested<span class="token punctuation">,</span> <span class="token keyword">and</span> based onour human evaluations <span class="token keyword">for</span> helpfulness <span class="token keyword">and</span> safety<span class="token punctuation">,</span> may be a suitable substitute <span class="token keyword">for</span> closed source models<span class="token punctuation">.</span> We provide a detailed description of our approach to ﬁne<span class="token operator">-</span>tuning <span class="token keyword">and</span> safety improvements of Llama <span class="token number">2</span><span class="token operator">-</span>Chat <span class="token keyword">in</span> order to enable the community to build on our work <span class="token keyword">and</span> contribute to the responsible development of LLMs<span class="token punctuation">.</span>

用户问：
how many parameters does llama <span class="token number">2</span> have?

如果已知信息不包含用户问题的答案，或者已知信息不足以回答用户的问题，请直接回复<span class="token string">"我无法回答您的问题"</span>。
请不要输出已知信息中不包含的信息或答案。
请用中文回答用户问题。

<span class="token operator">==</span><span class="token operator">=</span>回复<span class="token operator">==</span><span class="token operator">=</span>
Llama <span class="token number">2</span>有7B<span class="token punctuation">,</span> 13B和70B参数。
</code></pre>
    <p>
     扩展：
    </p>
    <p>
     Elasticsearch（简称ES）是一个广泛应用的开源搜索引擎:
     <a href="https://www.elastic.co/" rel="nofollow">
      https://www.elastic.co/
     </a>
    </p>
    <p>
     关于ES的安装、部署等知识，网上可以找到大量资料，例如:
     <a href="https://juejin.cn/post/7104875268166123528" rel="nofollow">
      https://juejin.cn/post/7104875268166123528
     </a>
    </p>
    <p>
     关于经典信息检索技术的更多细节，可以参考:
     <a href="https://nlp.stanford.edu/IR-book/information-retrieval-book.html" rel="nofollow">
      https://nlp.stanford.edu/IR-book/information-retrieval-book.html
     </a>
    </p>
    <h3>
     <a id="6__362">
     </a>
     6. 关键字检索的局限性
    </h3>
    <p>
     同一个语义，用词不同，可能导致检索不到有效的结果
    </p>
    <pre><code class="prism language-python"><span class="token comment"># user_query="Does llama 2 have a chat version?"</span>
user_query <span class="token operator">=</span> <span class="token string">"Does llama 2 have a conversational variant?"</span>

search_results <span class="token operator">=</span> search<span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> res <span class="token keyword">in</span> search_results<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>

</code></pre>
    <pre><code class="prism language-python"><span class="token number">1.</span> Llama <span class="token number">2</span><span class="token punctuation">,</span> an updated version of Llama <span class="token number">1</span><span class="token punctuation">,</span> trained on a new mix of publicly available data<span class="token punctuation">.</span> We also increased the size of the pretraining corpus by <span class="token number">40</span><span class="token operator">%</span><span class="token punctuation">,</span> doubled the context length of the model<span class="token punctuation">,</span> <span class="token keyword">and</span> adopted grouped<span class="token operator">-</span>query attention <span class="token punctuation">(</span>Ainslie et al<span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2023</span><span class="token punctuation">)</span><span class="token punctuation">.</span> We are releasing variants of Llama <span class="token number">2</span> <span class="token keyword">with</span> 7B<span class="token punctuation">,</span> 13B<span class="token punctuation">,</span> <span class="token keyword">and</span> 70B parameters<span class="token punctuation">.</span> We have also trained 34B variants<span class="token punctuation">,</span> which we report on <span class="token keyword">in</span> this paper but are <span class="token keyword">not</span> releasing<span class="token punctuation">.</span>§

 variants of this model <span class="token keyword">with</span> 7B<span class="token punctuation">,</span> 13B<span class="token punctuation">,</span> <span class="token keyword">and</span> 70B parameters <span class="token keyword">as</span> well<span class="token punctuation">.</span>
</code></pre>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34323433303934372f:61727469636c652f64657461696c732f313436313335333830" class_="artid" style="display:none">
 </p>
</div>


