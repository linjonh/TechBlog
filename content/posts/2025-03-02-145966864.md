---
layout: post
title: "本地部署-DeepSeek从-Ollama-配置到-Spring-Boot-集成"
date: 2025-03-02 18:17:43 +0800
description: "随着人工智能技术的迅猛发展，越来越多的开发者希望在本地环境中部署和调用 AI 模型，以满足特定的业务需求。本文将详细介绍如何在本地环境中使用 Ollama 配置 DeepSeek 模型，并在 IntelliJ IDEA 中创建一个 Spring Boot 项目来调用该模型。通过这些步骤，您将能够在本地环境中高效地运行和测试 AI 模型，提升开发效率。"
keywords: "srpingboot ai deepseek ollama"
categories: ['未分类']
tags: ['后端', 'Spring', 'Java', 'Boot']
artid: "145966864"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145966864
    alt: "本地部署-DeepSeek从-Ollama-配置到-Spring-Boot-集成"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145966864
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145966864
cover: https://bing.ee123.net/img/rand?artid=145966864
image: https://bing.ee123.net/img/rand?artid=145966864
img: https://bing.ee123.net/img/rand?artid=145966864
---

# 本地部署 DeepSeek：从 Ollama 配置到 Spring Boot 集成

### 前言

随着人工智能技术的迅猛发展，越来越多的开发者希望在本地环境中部署和调用 AI 模型，以满足特定的业务需求。本文将详细介绍如何在本地环境中使用 Ollama
配置 DeepSeek 模型，并在 IntelliJ IDEA 中创建一个 Spring Boot
项目来调用该模型。通过这些步骤，您将能够在本地环境中高效地运行和测试 AI 模型，提升开发效率。

### 详细步骤

#### 一、本地配置DeepSeek

##### 1.安装Ollama

Ollama 是一个开源平台，旨在简化大型语言模型的本地部署和管理。您可以从 [Ollama官网](https://ollama.com/
"Ollama官网")下载适用于 Windows、Linux 或 macOS 的安装包。

![](https://i-blog.csdnimg.cn/direct/06917c30fa284e85ac0eafbb6be38cda.png)

安装成功后可以使用win+R并输入cmd打开终端，接着输入ollama检查是否安装成功，如果有输出对应信息则说明安装成功了

![](https://i-blog.csdnimg.cn/direct/40ef87de31bb4a0da0b540c007d95f65.png)

##### 2.下载对应DeepSeek模型并运行

首先选中想要配置的DeepSeek版本并复制右侧指令

![](https://i-blog.csdnimg.cn/direct/611cdcfe926b4e29a9eb3bfb7b1bfbc6.png)

将指令复制到终端并进行下载对应版本的DeepSeek，下载完成之后到这个界面，就是下载成功了，可以输入一些信息进行测试

![](https://i-blog.csdnimg.cn/direct/db3fd05e5fe84b13aa64663c0ddc7cbe.png)

#### 二、SpringBoot项目调用本地DeepSeek

##### 1.创建springboot项目

具体操作如下：

  * 打开 IntelliJ IDEA，选择 "New Project"。
  * 选择 "Spring Initializr" 作为项目类型。
  * 填写项目的基本信息，如 Group、Artifact 等。
  * 在 "Dependencies" 中添加所需的依赖，例如 "Spring Web"。
  * 点击 "Create" 创建项目。

这里我添加了Web和Ollama的依赖，创建成功界面如下

![](https://i-blog.csdnimg.cn/direct/8c86b5accde8483487b7f7ff71268efb.png)

##### 2.添加deepseek对应配置信息

在application.properties中添加下面配置信息

    
    
    spring.ai.ollama.chat.options.model=deepseek-r1:1.5b
    spring.ai.ollama.base-url=http://127.0.0.1:11434
    spring.ai.ollama.chat.enabled=true
    server.port=9099

![](https://i-blog.csdnimg.cn/direct/8f433fc629d5403296548a01372d4af7.png)

##### 3.编码调用deepseek

接着创建简单controller类和service实现类，结构如图：

![](https://i-blog.csdnimg.cn/direct/a293e18ad902464b804d5cb77f4045c4.png)

对应代码如下：  
controller:

    
    
    @RestController
    public class testController {
    
        @Autowired
        private DeepSeekTestService deepSeekTestService;
    
        @RequestMapping("/ask1")
        public String speak(@RequestParam String msg){
            return deepSeekTestService.getResponse(msg);
        }
    }

service接口：

    
    
    public interface DeepSeekTestService {
        String getResponse(String message);
    }
    

service实现类

    
    
    @Service
    public class DeepSeekServiceImpl implements DeepSeekTestService {
    
        private final OllamaChatModel ollamaChatModel;
    
        public DeepSeekServiceImpl(OllamaChatModel ollamaChatModel) {
            this.ollamaChatModel = ollamaChatModel;
        }
    
        @Override
        public String getResponse(String message) {
            String response = ollamaChatModel.call(message);
            return response;
        }
    }

##### 4.测试

  
启动项目，在浏览器的url路径中输入对应信息进行测试,这样一个简单的springboot对接deepseek项目就完成了！

![](https://i-blog.csdnimg.cn/direct/845982d8e87942a7a7768ad0aecdd238.png)

![](https://i-blog.csdnimg.cn/direct/dd2dce7b925d4d1790c58f9cd1440f49.png)

好久没有更新了，绝对不是懒哈哈哈，好吧其实就是懒了，后面会继续更新一些有关Java的学习知识！还希望大家多多点赞支持，你的支持就是我的最大动力！！！



