---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34333535373638362f:61727469636c652f64657461696c732f313435343034373731"
layout: post
title: "大模型本地化部署Ollama-Open-WebUI"
date: 2025-01-31 12:36:01 +08:00
description: "Ollama实现大模型本地化部署，Open-WebUI实现图形化界面，SearXNG实现联网查询"
keywords: "open webui"
categories: ['大模型']
tags: ['语言模型', 'Ai']
artid: "145404771"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145404771
    alt: "大模型本地化部署Ollama-Open-WebUI"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145404771
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145404771
cover: https://bing.ee123.net/img/rand?artid=145404771
image: https://bing.ee123.net/img/rand?artid=145404771
img: https://bing.ee123.net/img/rand?artid=145404771
---

# 大模型本地化部署（Ollama + Open-WebUI）

## 环境准备

### 下载Ollama

下载地址：
[Ollama网址](https://ollama.com/download)

安装完成后，命令行里执行命令

```
ollama -v

```

查看是否安装成功。安装成功会显示版本信息

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/df5e589f2f014145be4b6fe2d6258922.png#pic_center)

ollama 的命令可通过
`ollama -h`
查看。

### 模型下载

可以在 Ollama 网站的 Models 里查看公开的大模型（
[网址](https://ollama.com/search)
），也可以从大模型镜像源站
[HF-Mirror](https://hf-mirror.com/)
下载。

以 Ollama 网站为例，点进一个大模型（如最近大火的 DeepSeek R1）

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/94c143a8d9794aad9158b01414ac5f61.png#pic_center)

如图右下角的
`ollama run deepseek-r1`
就是下载命令，在第一次执行该命令时，ollama 将从网站下载大模型，在下载完成后，再执行这一命令就会加载模型，并进入交互模式：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/fded0945de4547d88ed7ed5771c3a348.png#pic_center)

**注**
：大部分模型都是有
**内容审查**
的，这很多时候限制了我们的使用灵活性，可以寻找带有 abliterated 后缀的模型，这些模型被注释了审查代码。（不过本人尝试发现 abliterated 版本的实际上仍存在审查机制，会拒绝回答某些问题）

### 下载Open-WebUI

网上其他教程安装 Open-WebUI 一般都是在虚拟机 Docker 下安装的，这在 Windows 系统里很不方便。这里提供另外一种方法：首先安装 Python 3.11，然后在命令行里执行

```
pip install open-webui

```

即可完成 open-webui 的安装。

## 本地化部署的Web图形化界面

首先，需要开启 Ollama 服务，运行一个大模型，在命令行里执行

```
ollama run 大模型名

```

其中模型名可以通过
`ollama list`
查看。启用 ollama 服务后，可以使用

```
ollama ps

```

命令查看当前运行的模型进程。

随后再打开一个命令行，执行如下命令启用 open-webui 服务

```
open-webui serve

```

启动后可以在浏览器里输入以下地址，打开 Web 图形化界面：

```
localhost:8080
(本机IP):8080

```

其中
**第二个地址可以在局域网内的其他设备访问**
。

Open-WebUI 的界面如下

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/984469a9a96c49fcafe6d9b4c7af2ffc.png#pic_center)

本地化部署完成！

## 本地模型联网查询

未联网的情况下，很多问题大模型无法解决，回答也比较蠢（还会胡说），因此需要增加联网查询功能。

### 安装 Docker

安装 Docker Desktop 即可（网址
[Docker](https://www.docker.com/)
）。安装后用以下命令查询是否安装完成：

```
docker -v

```

### 安装 SearXNG

执行如下命令拉取 SearXNG （一个可以本地部署的轻量化搜索引擎）

```
docker pull searxng/searxng

```

不过这个命令由于网站无法连接，下载往往失败，可以使用镜像源：

```
docker pull docker.m.daocloud.io/searxng/searxng

```

安装完成后即可在 Docker Desktop 里查看到 SearXNG Image：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/79fc65a775274ad39b45898e6c0e8d5a.png#pic_center)

执行如下命令（最后面一串是 Image Name，注意要和你的 SearXNG 名字相同），将服务开在了端口 12345

```
docker run -d -p 12345:8080 docker.m.daocloud.io/searxng/searxng

```

随后可以在 Docker Desktop 的 Container/App 界面查看到运行的 SearXNG，显示运行在 12345 号端口。在命令行里使用

```
docker ps

```

命令也可以查看到运行中的 docker 镜像进程。

在浏览器访问 localhost:12345，可以看到 SearXNG 服务已开启。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/2eb09bc599ba438a93ed0f00bb41e22a.png#pic_center)

用默认配置的 SearXNG 很可能搜索不到东西，可以在配置里修改搜索引擎，改成大陆可以访问的那几个。

### 本地模型联网查询

在 open-webui 界面下，用户->管理员面板->设置 里面，配置搜索引擎如下，并保存设置

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5dfff535a1bc48568217aa2d810d89bf.png#pic_center)

此时询问问题，联网查询可能会报 403 错误，需要修改一个配置文件。执行

```
docker ps

```

查看 searxng 服务的 CONTAINER ID 号，随后执行以下命令（命令中的 <CONTAINER_ID> 替换为你 SearXNG 的 CONTAINER ID）

```
docker exec -it <CONTAINER_ID> sh

```

进入到镜像目录，随后进入
`/etc/searxng/`
目录，使用 vi 修改 settings.yml 文件，在 formats 下面增加一行（- json）

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/d4f7bd24d1684c66b6f1e3e611da1a19.png#pic_center)

修改文件后保存，然后 restart 容器。

---

修改 settings.yml 后，open-webui 联网查询不再报 403 错误，但可能报
`Expecting value: line 1 column 1 (char 0)`
错误（这是因为返回值格式不满足 json 格式导致的解析错误）或
`RemoteDisconnected('Remote end closed connection without response')`
错误，笔者目前还没有找到好的解决方法，日后若解决了再补上这里。

(U•ェ•*U )