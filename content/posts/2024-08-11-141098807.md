---
arturl_encode: "6874747073:3a2f2f626c6f672e6373646e2e6e65742f7a786e303830332f:61727469636c652f64657461696c732f313431303938383037"
layout: post
title: "技术前沿-Deep-Live-Cam入门部署教程-实时AI换脸开源一键免费"
date: 2024-08-11 01:01:27 +08:00
description: "最近有一个爆火的Github项目叫做 Deep-Live-Cam。它可以用 AI 技术在直播的时候，"
keywords: "deep-live-cam"
categories: ['未分类']
tags:  ["计算机视觉", "开源", "图像处理", "人工智能", "Python", "Imagen", "Github"]
artid: "141098807"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=141098807
  alt: "技术前沿-Deep-Live-Cam入门部署教程-实时AI换脸开源一键免费"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=141098807
featuredImagePreview: https://bing.ee123.net/img/rand?artid=141098807
---

# 【技术前沿】 Deep-Live-Cam入门部署教程-实时AI换脸、开源、一键、免费！

#### 文章目录

* [项目简介](#_1)
* [Deep Live Cam 部署教程](#Deep_Live_Cam__20)
* + [CPU版本如何安装？](#CPU_23)
  + - [基本安装](#_25)
    - * [1. 设置你的平台](#1__28)
      * [2. 克隆代码库](#2__35)
      * [3. 下载模型](#3__38)
      * [4. 安装依赖](#4__45)
  + [继续使用 GPU 加速](#_GPU__53)
  + - [[CoreML （Apple Silicon）](https://github.com/s0md3v/roop/wiki/2.-Acceleration#coreml-execution-provider-apple-silicon)](#CoreML_Apple_Siliconhttpsgithubcoms0md3vroopwiki2Accelerationcoremlexecutionproviderapplesilicon_70)
    - [[CoreML（Apple Legacy）](https://github.com/s0md3v/roop/wiki/2.-Acceleration#coreml-execution-provider-apple-legacy)](#CoreMLApple_Legacyhttpsgithubcoms0md3vroopwiki2Accelerationcoremlexecutionproviderapplelegacy_85)
    - [DirectML（Windows）](#DirectMLWindowshttpsgithubcoms0md3vroopwiki2Accelerationdirectmlexecutionproviderwindows_100)
    - [OpenVINO™（Intel)](#OpenVINOIntelhttpsgithubcoms0md3vroopwiki2Accelerationopenvinoexecutionproviderintel_115)
  + [如何使用？](#_130)
  + [对于摄像头模式](#_139)
* [一些可能的踩坑:](#_176)
* + [致谢](#_185)
  + [原仓库:](#_193)

## 项目简介

**最近有一个爆火的Github项目叫做 Deep-Live-Cam**
。它可以用 AI 技术在直播的时候，实时生成虚拟人脸。它的作用是让你在直播的时候，保护你的隐私，同时也可以让你看起来很酷(By 项目原作者)。这个项目特别适合那些喜欢直播又想保护自己隐私的人使用。

项目的代码托管在
[GitHub 上](https://github.com/hacksider/Deep-Live-Cam)
。通过访问这个链接，可以查看详细的代码和文档(下载后进行本地部署)。
  
**由于项目是英文的，在这里做一版中文教程，给后来人一些参考。关注
[心若为城](https://blog.csdn.net/zxn0803)
，获得Github的前沿技术。**

博主碎碎念，可跳过：
  
打算重新做做自己这个老号，高中时候开始做CSDN，那会儿写的是NOIP/NOI相关的算法东西，纯粹是写给自己看的；现在时隔多年，我也在清华站稳了脚跟，在互联网开发和量化交易领域都算是小有成就了。

接下来这个号（也许也不止这个号）应该会做三个方向:

1. AI新技术(或者不局限于AI)的抢先浏览，会向大家说明当下热点论文、热点技术的部署等，以及做一些周报或者日报。（类似于AI Weekly）
2. 量化交易相关，我在量化开发技术栈有着多年的开发经验，也拿过一些投资比赛的奖项。可以面向应届生给出就业规划，提供一些指导的同时分享一些含金量高的项目。
3. 互联网面试相关，我应该会着重于分享一些面试的底层技术面，并且尽可能和2进行一些结合，让大家同时能handle住两边的技术。

## Deep Live Cam 部署教程

### CPU版本如何安装？

#### 基本安装

这可能会在你的计算机正常工作，但速度可能会很慢。你可以按照基本安装的说明进行操作（这通常通过
**CPU**
运行）

##### 1. 设置你的平台

* python（推荐使用 3.10 版本）
* pip
* git
* [ffmpeg](https://www.youtube.com/watch?v=OlNWCpFdVMA)
* [Visual Studio 2022 (Windows）](https://visualstudio.microsoft.com/visual-cpp-build-tools/)

##### 2. 克隆代码库

```
https://github.com/hacksider/Deep-Live-Cam.git

```

##### 3. 下载模型

1. [GFPGANv1.4](https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth)
2. [inswapper_128_fp16.onnx](https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx)

然后将这两个文件放到 “
**models**
” 文件夹中

##### 4. 安装依赖

我们强烈推荐使用
`venv`
来避免问题。

```
pip install -r requirements.txt

```

完成！！！如果没有 GPU，你应该能够使用
`python run.py`
命令运行 roop。请注意，在第一次运行程序时，它会下载一些模型，这可能会根据你的网络连接速度需要一些时间。

### 继续使用 GPU 加速

1. 安装
   [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-11-8-0-download-archive)
2. 安装依赖：

```
pip uninstall onnxruntime onnxruntime-gpu
pip install onnxruntime-gpu==1.16.3

```

3. 使用以下命令来验证：

```
python run.py --execution-provider cuda

```

#### [CoreML （Apple Silicon）](https://github.com/s0md3v/roop/wiki/2.-Acceleration#coreml-execution-provider-apple-silicon)

1. 安装依赖：

```
pip uninstall onnxruntime onnxruntime-silicon
pip install onnxruntime-silicon==1.13.1

```

2. 使用以下命令验证：

```
python run.py --execution-provider coreml

```

#### [CoreML（Apple Legacy）](https://github.com/s0md3v/roop/wiki/2.-Acceleration#coreml-execution-provider-apple-legacy)

1. 安装依赖：

```
pip uninstall onnxruntime onnxruntime-coreml
pip install onnxruntime-coreml==1.13.1

```

2. 使用以下命令验证：

```
python run.py --execution-provider coreml

```

#### [DirectML（Windows）](https://github.com/s0md3v/roop/wiki/2.-Acceleration#directml-execution-provider-windows)

1. 安装依赖：

```
pip uninstall onnxruntime onnxruntime-directml
pip install onnxruntime-directml==1.15.1

```

2. 使用以下命令验证：

```
python run.py --execution-provider directml

```

#### [OpenVINO™（Intel)](https://github.com/s0md3v/roop/wiki/2.-Acceleration#openvino-execution-provider-intel)

1. 安装依赖：

```
pip uninstall onnxruntime onnxruntime-openvino
pip install onnxruntime-openvino==1.15.0

```

2. 使用以下命令验证：

```
python run.py --execution-provider openvino

```

### 如何使用？

> 注意：当你第一次运行这个程序时，它会下载一些约 300MB 大小的模型。

执行
`python run.py`
命令将启动如下窗口：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/24b6c59630ee4f088300867ad5b66db3.png)

选择一个面孔（带有所需面孔的图像）和目标图像/视频（你想替换面孔的图像/视频），然后点击
`Start`
。打开文件资源管理器并导航到你选择的输出目录。你会找到一个名为
`<video_title>`
的目录，你可以在其中实时查看帧交换。处理完成后，它会创建输出文件。这样就结束了。

### 对于摄像头模式

只需按照屏幕截图上的点击操作

1. 选择一个面孔
2. 点击 “live”
3. 等待几秒钟（通常需要 10 到 30 秒，预览才会显示）

[具体视频可以看这里](https://github.com/hacksider/Deep-Live-Cam/blob/main/demo.gif)

只需使用你喜欢的屏幕录制工具进行流式传输，如 OBS

> 注意：如果你想更换面孔，只需选择另一张图片，预览模式将会重新启动（因此请稍等片刻）。

以下是额外的命令行参数。要了解它们的作用，请查看
[此指南](https://github.com/s0md3v/roop/wiki/Advanced-Options)
。

```
options:
  -h, --help                                               显示此帮助信息并退出
  -s SOURCE_PATH, --source SOURCE_PATH                     选择源图像
  -t TARGET_PATH, --target TARGET_PATH                     选择目标图像或视频
  -o OUTPUT_PATH, --output OUTPUT_PATH                     选择输出文件或目录
  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  帧处理器（选择：face_swapper, face_enhancer, ...）
  --keep-fps                                               保持原始帧率
  --keep-audio                                             保持原始音频
  --keep-frames                                            保持临时帧
  --many-faces                                             处理每个面孔
  --video-encoder {libx264,libx265,libvpx-vp9}             调整输出视频编码器
  --video-quality [0-51]                                   调整输出视频质量
  --max-memory MAX_MEMORY                                  最大内存量（GB）
  --execution-provider {cpu} [{cpu} ...]                   可用执行提供者（选择：cpu, ...）
  --execution-threads EXECUTION_THREADS                    执行线程数量
  -v, --version                                            显示程序版本号并退出

```

如果想要 CLI 模式：使用 -s/–source 参数将使程序以 CLI 模式运行。

---

## 一些可能的踩坑:

1. 脸部出现黑色方块，解决方案:

```
pip uninstall onnxruntime onnxruntime-gpu
pip install onnxruntime-gpu==1.16.3

```

2. 运行
   `python run.py`
   黑框卡住，可能是网络设置的问题，因为一些众所周知的原因可能需要Proxy。
3. 如果是windows系统，项目整合了setup的bat文件，可以尝试用bat文件进行一键安装。

### 致谢

* [henryruhs](https://github.com/henryruhs)
  ：作为项目中不可替代的贡献者
* [ffmpeg](https://ffmpeg.org/)
  ：让视频相关操作变得简单
* [deepinsight](https://github.com/deepinsight)
  ：提供了一个制作精良的库和模型的
  [insightface](https://github.com/deepinsight/insightface)
  项目
* [havok2-htwo](https://github.com/havok2-htwo)
  ：分享了摄像头代码
* [GosuDRM](https://github.com/GosuDRM/nsfw-roop)
  ：为 roop 提供了去除敏感内容的功能
* 以及
  [所有开发者](https://github.com/hacksider/Deep-Live-Cam/graphs/contributors)
  ：为项目中使用的库做出贡献的开发者们

### 原仓库:

[Deep-Live-Cam](https://github.com/hacksider/Deep-Live-Cam)