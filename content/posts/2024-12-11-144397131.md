---
layout: post
title: "LLM在PAI-DSW上使用-vLLM-Open-WebUI-部署Qwen2.5"
date: 2024-12-11 12:10:21 +0800
description: "最近在玩LLM，听闻PAI-DSW有三个月免费试用，试了一下感觉还不错，就是有一些学习成本。刚通过vllm+open-webui成功部署了Qwen2.5-7B-Instruct，也是摸索了一段时间，记录一下以便需要使用同样方案的朋友们节省时间，迅速上手。简便起见，本文所有安装均使用pip工具，不使用docker。"
keywords: "vllm openwebui"
categories: ['未分类']
tags: ['Java']
artid: "144397131"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=144397131
    alt: "LLM在PAI-DSW上使用-vLLM-Open-WebUI-部署Qwen2.5"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=144397131
featuredImagePreview: https://bing.ee123.net/img/rand?artid=144397131
cover: https://bing.ee123.net/img/rand?artid=144397131
image: https://bing.ee123.net/img/rand?artid=144397131
img: https://bing.ee123.net/img/rand?artid=144397131
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     【LLM】在PAI-DSW上使用 vLLM + Open-WebUI 部署Qwen2.5
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="./../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="./../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     最近在玩LLM，听闻PAI-DSW有三个月免费试用，试了一下感觉还不错，就是有一些学习成本。刚通过vllm+open-webui成功部署了Qwen2.5-7B-Instruct，也是摸索了一段时间，记录一下以便需要使用同样方案的朋友们节省时间，迅速上手。
     <br/>
     简便起见，本文所有安装均使用pip工具，不使用docker。
    </p>
    <h3>
     <a id="_7">
     </a>
     总体思路
    </h3>
    <p>
     从modelscope下载模型，运行vllm serve构建服务器，然后通过Open-WebUI连接并开始对话。
    </p>
    <h3>
     <a id="PAIDSW_12">
     </a>
     PAI-DSW部署的难点
    </h3>
    <p>
     主要有两个：
    </p>
    <ol>
     <li>
      不是本机，没法方便地科学上网。特别是无法直连hugging face；
     </li>
     <li>
      镜像不能完全涵盖所需要的环境。
     </li>
     <li>
      不是本机，不能直接用浏览器打开localhost（即0.0.0.0）
     </li>
    </ol>
    <p>
     展开说一下第二点：vllm需要cuda 12以上才能使用，11.8会提示过旧；open-webui需要使用python 3.11才可以使用pip安装。然而，PAI-DSW的镜像中要么是py310+cu121，要么是py311+cu118，欲哭无泪。最后建议大家选择py310+cu121的方案，我们可以通过安装Anaconda，使用虚拟环境来部署Open-WebUI。
     <br/>
     对于第三点，原来我以为是不能直接打开的，还专门用了cpolar做透传，结果发现阿里已经想到这一点了，直接点击终端里的链接就能访问，太贴心了。
    </p>
    <h3>
     <a id="_24">
     </a>
     具体安装流程
    </h3>
    <h4>
     <a id="_27">
     </a>
     模型下载
    </h4>
    <p>
     这里建议通过modelscope下载，非常快，平均速度在300MB/s左右。
    </p>
    <h5>
     <a id="_31">
     </a>
     自动下载（略）
    </h5>
    <p>
     据我所知，你可以直接使用vllm通过modelscope下载模型，如果默认用的是hugging face可以通过在终端输入
    </p>
    <pre><code>export VLLM_USE_MODELSCOPE=True
</code></pre>
    <p>
     然后运行vllm serve，输入模型地址即可下载。但是我在vllm v0.6.1.post2没有成功，故采取手动下载方式，这样其实也不错，不麻烦。
    </p>
    <h5>
     <a id="_40">
     </a>
     手动下载（推荐）
    </h5>
    <p>
     首先安装modelscope包。由于DSW是有预装的镜像文件的，故建议使用裸python环境进行配置，省去配置的时间。
    </p>
    <pre><code>pip install -U modelscope
</code></pre>
    <p>
     然后在modelscope上打开你要下载的模型，这里以
     <a href="https://modelscope.cn/models/qwen/Qwen2.5-7B-Instruct/files" rel="nofollow">
      Qwen2.5-7B-Instruct
     </a>
     为例。点击右上角的下载模型，向下滑动到命令行下载界面，你会看到
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/4ec2933d7bc54cf5bd38b6576471adea.png">
      <br/>
      此时你可以复制并运行这条语句，然后服务器就会猛猛下载。当然，如果你想指定下载路径，可以添加–local_dir参数，例如：此时你可以复制并运行这条语句，然后服务器就会猛猛下载。当然，如果你想指定下载路径，可以添加–local_dir参数，例如：
     </img>
    </p>
    <pre><code>modelscope download --model qwen/Qwen2.5-7B-Instruct --local_dir /mnt/workspace/models/Qwen2.5
</code></pre>
    <p>
     你可以输入
    </p>
    <pre><code>modelscope download --help
</code></pre>
    <p>
     以查看更多参数。
    </p>
    <h4>
     <a id="Vllm_61">
     </a>
     Vllm部署
    </h4>
    <p>
     一样使用pip进行安装
    </p>
    <pre><code>pip install -U vllm
</code></pre>
    <p>
     这次可能有点久，等待安装完成后，输入如下命令，观察是否正常运行：这次可能有点久，等待安装完成后，输入如下命令，观察是否正常运行（注意修改模型路径）：
    </p>
    <pre><code>vllm serve YOUR/PATH/TO/MODEL --dtype auto --api-key token-abc123
</code></pre>
    <p>
     如果出现报错
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/5d63dc9e146c45d4b49a0c700c1b280e.png"/>
    </p>
    <p>
     则说明模型长度过长(32768)，通过指定–max-model-len(&lt;=18656)来指定长度，命令如下。
    </p>
    <pre><code>vllm serve models/Qwen2.5-7B-Instruct/ --dtype auto --api-key token-abc123 --max-model-len 8192
</code></pre>
    <p>
     随后，我们运行如下命令，观察openai api是否启动成功。openai api是Open-WebUI所需要使用的工具。
    </p>
    <pre><code>curl http://localhost:8000/v1/models -H "Authorization: Bearer token-abc123" | jq
</code></pre>
    <p>
     若显示“jq：未找到命令”，则使用apt install安装，然后再次运行指令。如果观察到输出
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/36e4da5ef47c4546b6b97f16cb70d2c7.png">
      <br/>
      则说明服务启动成功。我们进行下一步。
      <br/>
      （这里做个解释，通过打印输出auth_headers即可得到{‘Authorization’: ‘Bearer token-abc123’}，Bearer是不变的，后面的token根据你的参数设置而改变。）
     </img>
    </p>
    <h4>
     <a id="OpenWebUI_91">
     </a>
     Open-WebUI部署
    </h4>
    <h5>
     <a id="Anaconda_93">
     </a>
     安装Anaconda
    </h5>
    <p>
     首先，上
     <a href="https://repo.anaconda.com/archive/" rel="nofollow">
      Anaconda官方仓库
     </a>
     下载符合你设备的安装工具，这里我使用的是
     <a href="https://repo.anaconda.com/archive/Anaconda3-2024.06-1-Linux-x86_64.sh" rel="nofollow">
      https://repo.anaconda.com/archive/Anaconda3-2024.06-1-Linux-x86_64.sh
     </a>
     。然后上终端，使用wget下载：
    </p>
    <pre><code>wget https://repo.anaconda.com/archive/Anaconda3-2024.06-1-Linux-x86_64.sh
</code></pre>
    <p>
     添加操作权限并运行
    </p>
    <pre><code>chmod +x Anaconda3-2024.06-1-Linux-x86_64.sh
./Anaconda3-2024.06-1-Linux-x86_64.sh
</code></pre>
    <p>
     随后按照安装提示进行安装即可（建议同意conda init）。
    </p>
    <h5>
     <a id="OpenWebUI_108">
     </a>
     创建虚拟环境并安装Open-WebUI
    </h5>
    <p>
     前文提到，我们需要创建一个python 3.11的环境：
    </p>
    <pre><code>conda create -n oi python=3.11
</code></pre>
    <p>
     确认后回车，等待安装完成，然后激活环境并安装Open-WebUI
    </p>
    <pre><code>conda activate oi
pip install open-webui
</code></pre>
    <p>
     等待安装完成，然后运行
    </p>
    <pre><code>open-webui serve
</code></pre>
    <p>
     这个时候，不能科学上网的弊端就来了，Hugging face可能会访问超时！由于安装好了，我这里无法提供截图，语言描述一下大致的报错：非常非常长的五颜六色的报错，还有表格之类，输出很多信息，在报错的最底下会显示Network之类的字样，同时给出“huggingface.co"还有403等字样。这就是网络连接出问题了，此时我们需要使用这条语句：
    </p>
    <pre><code>export HF_ENDPOINT=https://hf-mirror.com
</code></pre>
    <p>
     用以接入到国内的镜像站。此时再次运行open-webui serve，可以看到开始下载配置，直到出现：用以接入到国内的镜像站。此时再次运行open-webui serve，可以看到开始下载配置，直到出现：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/51353de839ea4603863b7c1cd8a0bbfe.png">
      <br/>
      恭喜！你已经完成了大部分工作，距离成功仅有一步之遥！点击输出的链接http://0.0.0.0:8080即可进入open-webui
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/7df0a3d5f07648a6bc900ae3d953ab0c.png">
       <br/>
       注册并登录，我们进行最后一步。
      </img>
     </img>
    </p>
    <h5>
     <a id="_136">
     </a>
     获取模型
    </h5>
    <p>
     首先，使用你之前的参数重新运行vllm serve。等待服务完全运行起来后，会周期地进行输出，此时我们回到Open-WebUI，点击右上角头像，选择“管理员面板”，点击左上角的“设置”，然后点击外部连接：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/ef50ece7b5fb41e086cda5e5d6f27c18.png">
      <br/>
      然后将vllm的地址“http://0.0.0.0:8000/v1”替换掉默认的OpenAI API。注意加上“/v1”。输入你所配置的token密钥
      <br/>
      因为我们是vllm部署，没有用到ollama，可以将其关闭。
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/cf9a3f331f9f4b2aa224bedb007af772.png"/>
     </img>
    </p>
    <p>
     输入完成后，点击右边的刷新按钮测试连接，如果显示已验证服务器连接，则
     <strong>
      点击右下角保存。
     </strong>
     如果显示Network problem，则检查拼写，是否是写了https或打错字。
     <br/>
     点击保存后，如果弹出“保存设置成功”一类的字样，那么恭喜你，大功告成！
     <br/>
     此时回到主页面，点击左上角选择模型，就应该出现已加载的模型：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/1ee5bff4551e4d1688f863321585296e.png"/>
    </p>
    <h5>
     <a id="_149">
     </a>
     启动，并开始第一次对话！
    </h5>
    <p>
     回到Open-WebUI的主页面，选择模型，然后开始第一次对话！
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/67a4bba08b424c419a289e13bab44d31.png"/>
    </p>
    <p>
     注意，每次使用模型进行对话前，都需要先启动vllm，然后启动open webui。
     <br/>
     愉快地对话吧！
    </p>
   </div>
   <link href="./../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="./../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f37343832343132332f:61727469636c652f64657461696c732f313434333937313331" class_="artid" style="display:none">
 </p>
</div>


