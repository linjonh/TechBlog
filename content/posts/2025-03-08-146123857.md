---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34333036393230332f:61727469636c652f64657461696c732f313436313233383537"
layout: post
title: "扩散模型中三种加入条件的方式Vanilla-Guidance,Classifier-Guidance-以及-Classifier-Free-Guidance"
date: 2025-03-08 22:18:22 +0800
description: "在生成过程中，模型从一个随机噪声开始，通过多次迭代去噪，最终生成有意义的数据，比如图像。这时候，如果需要生成特定类别的数据，比如生成猫的图像而不是狗的，就需要加入条件引导，控制生成的方向。这就是条件扩散模型的作用。而Classifier-Free Guidance则是在训练时，有时告诉模型生成猫，有时不告诉任何条件，然后在推理时通过调整条件和非条件的权重来加强条件的影响，比如让条件预测的权重更大，从而生成更符合要求的猫的图像。通过理解这三种方法的差异，可根据具体任务需求选择最适合的条件引导策略。"
keywords: "扩散模型中三种加入条件的方式：Vanilla Guidance，Classifier Guidance 以及 Classifier-Free Guidance"
categories: ['Models', 'Diffusion']
tags: ['计算机视觉', '深度学习', '机器学习']
artid: "146123857"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146123857
    alt: "扩散模型中三种加入条件的方式Vanilla-Guidance,Classifier-Guidance-以及-Classifier-Free-Guidance"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146123857
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146123857
cover: https://bing.ee123.net/img/rand?artid=146123857
image: https://bing.ee123.net/img/rand?artid=146123857
img: https://bing.ee123.net/img/rand?artid=146123857
---

# 扩散模型中三种加入条件的方式：Vanilla Guidance，Classifier Guidance 以及 Classifier-Free Guidance

**扩散模型**
主要包括两个过程：
`前向扩散`
过程和
`反向去噪`
过程。前向过程逐渐给数据添加噪声，直到数据变成纯噪声；反向过程则是学习如何从噪声中逐步恢复出原始数据。在生成过程中，模型从一个随机噪声开始，通过多次迭代去噪，最终生成有意义的数据，比如图像。这时候，如果需要生成特定类别的数据，比如生成猫的图像而不是狗的，就需要加入条件引导，控制生成的方向。这就是条件扩散模型的作用。

---

Vanilla Guidance、Classifier Guidance和Classifier-Free Guidance，是在反向过程中如何利用条件信息的不同策略:

1. **Vanilla Guidance**
   : 指的是最基本的条件加入方式，也就是在模型训练时直接将条件信息（比如类别标签，时间标签）作为输入的一部分。例如，在UNet的结构中，除了输入噪声图像和时间步信息外，还会将条件向量拼接或嵌入到网络中，让模型在训练时学会根据条件生成对应的图像。这种方法可能的问题是需要大量带标签的数据，并且在推理时可以通过替换不同的条件来生成不同类别的图像。不过，可能控制的效果有限，或者需要更多的调整。
2. **Classifier Guidance**
   ：这个方法是需要预训练一个分类器，在反向过程中利用分类器的梯度来调整生成的方向，使得生成的图像符合给定的条件。具体来说，在每一步去噪的时候，不仅根据扩散模型的预测去噪，还会计算分类器对当前中间图像的梯度，将梯度信息加入到噪声预测中，从而使得生成的图像在分类器看来属于目标类别。这种方法的好处是不需要在扩散模型本身中加入条件，而是通过外部分类器来引导生成，可能更加灵活。不过缺点是需要额外训练分类器，并且分类器需要在带噪声的数据上进行训练，因为扩散过程的中间结果是有噪声的，可能影响分类器的准确性。
3. **Classifier-Free Guidance**
   ：不需要单独的分类器，而是通过训练时的条件和非条件生成来隐式地引导生成方向。具体来说，可能是在训练时随机地忽略条件信息（比如以一定概率将条件置空），让模型同时学习有条件生成和无条件生成。在推理时，通过调整条件和非条件预测的权重，来增强条件的影响。比如，将条件预测的结果和无条件预测的结果进行线性组合，从而在不需要外部分类器的情况下实现更强的条件控制。这种方法结合了两者的优点，既不需要额外的分类器，又能有效利用条件信息，但可能需要更大的模型或更复杂的训练策略。

举个例子，假设我要生成一个带有“猫”标签的图像。
  
Vanilla Guidance在训练时将“猫”的标签编码后输入到模型中，让模型在生成过程中始终考虑这个条件。
  
Classifier Guidance则是在生成过程中，每一步都使用一个已经训练好的猫分类器，对中间图像计算梯度，调整生成方向。
  
而Classifier-Free Guidance则是在训练时，有时告诉模型生成猫，有时不告诉任何条件，然后在推理时通过调整条件和非条件的权重来加强条件的影响，比如让条件预测的权重更大，从而生成更符合要求的猫的图像。

总结：

* Vanilla Guidance：在模型训练时将条件信息作为输入，直接训练条件生成模型。生成时通过输入不同的条件来控制输出。但可能缺乏对条件的强引导，导致控制不够精准。
* Classifier Guidance：在反向过程中使用预训练的分类器梯度来调整生成方向，强化条件信号。需要额外训练分类器，并且分类器需要适应带噪声的输入，但能够更精确地控制生成结果。
* Classifier-Free Guidance：在训练时同时学习有条件和无条件生成，推理时通过组合两者的预测来增强条件效果。不需要外部分类器，通过模型自身的条件和非条件预测差异来引导生成，灵活性高，效果较好，但训练时需要更多的策略（如随机丢弃条件）。

---

### **1. Vanilla Guidance（朴素引导）**

* **核心思想**
  ：在训练时直接将条件信息（如类别标签、文本描述）作为模型输入的一部分，通过端到端学习条件生成。
* **实现方式**
  ：
  + 条件信息（如类别嵌入或文本编码）通过拼接、相加或多层感知机（MLP）注入到模型的每一层（如UNet的残差块中）。
  + 模型直接学习基于条件的噪声预测，无需额外引导机制。
* **优点**
  ：
  + 实现简单，直接融入模型结构。
  + 推理时通过替换条件输入灵活控制生成内容。
* **缺点**
  ：
  + 条件控制较弱，尤其在复杂任务（如细粒度文本生成图像）中可能生成与条件无关的结果。
  + 依赖大量带标注数据，且条件信息可能未被充分建模。
* **典型应用**
  ：早期的条件扩散模型（如DDPM的类别条件生成）。

---

### **2. Classifier Guidance（分类器引导）**

* **核心思想**
  ：利用预训练的分类器梯度，在反向去噪过程中调整生成方向，使输出符合目标条件。
* **实现方式**
  ：
  + **训练阶段**
    ：扩散模型可无条件训练，同时额外训练一个噪声鲁棒的分类器（适应各时间步的噪声数据）。
  + **推理阶段**
    ：
    1. 在每一步去噪时，计算分类器对中间图像的条件概率梯度。
    2. 将梯度信息加权后注入噪声预测：
         




       ϵ
       θ
       (
       x
       t
       ,
       t
       )
       →
       ϵ
       θ
       (
       x
       t
       ,
       t
       )
       +
       s
       ⋅
       ∇
       x
       t
       log
       ⁡
       p
       ϕ
       (
       y
       ∣
       x
       t
       )
       \epsilon\_\theta(x\_t, t) \rightarrow \epsilon\_\theta(x\_t, t) + s \cdot \nabla\_{x\_t} \log p\_\phi(y \mid x\_t)






       ϵ









       θ

       ​


       (


       x









       t

       ​


       ,



       t

       )



       →






       ϵ









       θ

       ​


       (


       x









       t

       ​


       ,



       t

       )



       +





       s



       ⋅






       ∇











       x









       t

       ​


       ​




       lo
       g




       p









       ϕ

       ​


       (

       y



       ∣






       x









       t

       ​


       )
         
       其中，

       s
       s





       s
       为引导尺度，控制条件强度。
* **优点**
  ：
  + 通过梯度调整实现精准条件控制，生成质量高。
  + 扩散模型与分类器解耦，可复用预训练分类器。
* **缺点**
  ：
  + 需额外训练噪声适应的分类器，增加训练成本。
  + 分类器在强噪声下可能失效，影响引导效果。
* **典型应用**
  ：OpenAI的Guided Diffusion（2021）。

---

### **3. Classifier-Free Guidance（无分类器引导）**

* **核心思想**
  ：隐式学习条件与无条件生成的差异，通过混合预测结果增强条件控制，无需外部分类器。
* **实现方式**
  ：
  + **训练阶段**
    ：
    - 随机以概率

      p
      p





      p
      丢弃条件（替换为空白标识），使模型同时学习条件生成（

      p
      (
      y
      ∣
      x
      )
      p(y \mid x)





      p

      (

      y



      ∣





      x

      )
      ）和无条件生成（

      p
      (
      x
      )
      p(x)





      p

      (

      x

      )
      ）。
    - 例如，在文本到图像任务中，以一定概率将文本描述替换为空字符串。
  + **推理阶段**
    ：
    - 混合条件预测

      ϵ
      θ
      (
      x
      t
      ,
      t
      ,
      y
      )
      \epsilon\_\theta(x\_t, t, y)






      ϵ









      θ

      ​


      (


      x









      t

      ​


      ,



      t

      ,



      y

      )
      和无条件预测

      ϵ
      θ
      (
      x
      t
      ,
      t
      ,
      ∅
      )
      \epsilon\_\theta(x\_t, t, \emptyset)






      ϵ









      θ

      ​


      (


      x









      t

      ​


      ,



      t

      ,



      ∅

      )
      ：
        




      ϵ
      guided
      =
      ϵ
      θ
      (
      x
      t
      ,
      t
      ,
      ∅
      )
      +
      s
      ⋅
      (
      ϵ
      θ
      (
      x
      t
      ,
      t
      ,
      y
      )
      −
      ϵ
      θ
      (
      x
      t
      ,
      t
      ,
      ∅
      )
      )
      \epsilon\_\text{guided} = \epsilon\_\theta(x\_t, t, \emptyset) + s \cdot (\epsilon\_\theta(x\_t, t, y) - \epsilon\_\theta(x\_t, t, \emptyset))






      ϵ










      guided

      ​




      =






      ϵ









      θ

      ​


      (


      x









      t

      ​


      ,



      t

      ,



      ∅

      )



      +





      s



      ⋅





      (


      ϵ









      θ

      ​


      (


      x









      t

      ​


      ,



      t

      ,



      y

      )



      −






      ϵ









      θ

      ​


      (


      x









      t

      ​


      ,



      t

      ,



      ∅

      ))
        
      其中，

      s
      >
      1
      s > 1





      s



      >





      1
      时增强条件效应，

      s
      =
      1
      s=1





      s



      =





      1
      退化为普通条件生成。
* **优点**
  ：
  + 无需外部分类器，简化训练流程。
  + 通过调整引导尺度

    s
    s





    s
    灵活平衡生成质量与多样性。
* **缺点**
  ：
  + 训练时需同时建模条件与无条件生成，可能增加模型容量需求。
  + 条件丢弃概率需调优，否则影响收敛稳定性。
* **典型应用**
  ：Stable Diffusion、DALL·E 2等主流文本到图像模型。

---

### **对比总结**

| **特性** | **Vanilla Guidance** | **Classifier Guidance** | **Classifier-Free Guidance** |
| --- | --- | --- | --- |
| **是否需要分类器** | 否 | 是（噪声适应） | 否 |
| **训练复杂度** | 低（端到端条件训练） | 中（需训练分类器） | 中（条件随机丢弃策略） |
| **推理灵活性** | 低（直接替换条件） | 中（依赖分类器） | 高（通过  s s      s 调节控制强度） |
| **生成质量与条件控制** | 一般 | 高（依赖分类器质量） | 高（自适应调节） |
| **典型场景** | 简单条件生成 | 高精度条件生成（需分类器可靠） | 复杂条件生成（如文本到图像） |

---

### **选择建议**

* **数据充足且条件简单**
  ：Vanilla Guidance足够高效。
* **需高精度控制且分类器可靠**
  ：Classifier Guidance适合特定领域（如医学图像生成）。
* **通用复杂条件生成**
  ：Classifier-Free Guidance更优，已成为当前主流（如Stable Diffusion）。

通过理解这三种方法的差异，可根据具体任务需求选择最适合的条件引导策略。