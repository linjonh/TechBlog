---
arturl_encode: "68747470733a2f2f626c6f:672e6373646e2e6e65742f323330325f38303234333838372f:61727469636c652f64657461696c732f313436313831343831"
layout: post
title: "Pandas数据清洗实战之清洗猫眼电影"
date: 2025-03-11 17:09:48 +08:00
description: "Pandas数据清洗实战之清洗猫眼电影"
keywords: "Pandas数据清洗实战之清洗猫眼电影"
categories: ['数据清洗']
tags: ['数据分析', 'Python', 'Pycharm', 'Pandas']
artid: "146181481"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146181481
    alt: "Pandas数据清洗实战之清洗猫眼电影"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146181481
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146181481
cover: https://bing.ee123.net/img/rand?artid=146181481
image: https://bing.ee123.net/img/rand?artid=146181481
img: https://bing.ee123.net/img/rand?artid=146181481
---

# Pandas数据清洗实战之清洗猫眼电影

**本次案例所需要用到的模块**

|  |  |
| --- | --- |
| **pandas(文件读取保存 操作表格的模块)** |  |

**将上次Scrapy爬取下来的文件 做个数据清洗 变成我们想要的数据**

**确定目的：将此文件中的duration字段中的分钟  和publisher\_time上映去掉 只保留纯数值**

![](https://i-blog.csdnimg.cn/direct/4d8f89522d1e44a38e34026ebf7790f4.png)

**数据清洗题目如下:**

* **修复 publish\_time列中的错误数据  去除无用的数据**
* **清洗 duration 列并转为整数类型   duration 列包含冗余单位（如 分钟），需提取数字并转为整数**
* **拆分 area 列中的多地区数据  area 列用|分隔多个地区，需拆分为列表或单独列**
* **area 列用|分隔多个地区，需拆分为列表或单独列  name 列包含中英文名称，需提取中文名（如 霸王别姬）**
* **提取 name 列中的纯中文名**
* **检查并删除重复的电影条目  检查是否有完全重复的行并删除**
* **处理缺失值  检查各列是否有缺失值并填充或删除。**
* **最后保存为新的Excel文件**

### **OK 我们开始对数据进行清洗**

**首先 需要对数据内容做一个大概的了解**

```python
# 第一步 导包  取别名
import pandas as pd

# 读取文件 设置索引值为False
df = pd.read_excel('movies.xlsx', index_col=False)


# df.head() 默认可以查看前五行的数据  括号里面的参数可以中间写
# df.info() 可以查看数据的结构类型
# df.shape 可以查看几行几列
# df.descibe() 查看数据类型的信息
```

**1.修复 publish\_time列中的错误数据  去除无用的数据**
  
**我们可以采用正则去提取**

```python
# 将上映的字段去掉
df['publish_time'] = df['publish_time'].str.replace(' 上映', '', regex=False)
# 匹配纯数字 提取出来
df['publish_time'] = df['publish_time'].str.replace(r'\d+ .*?', '', regex=True)
# 去除无用的数据   这个会取到之前的时长 我们需要将其除去
df['publish_time'] = df['publish_time'].str.replace('分钟', '', regex=False)
# 转化为时间格式的数据 无法转换的数据 为NaT
df['publish_time'] = pd.to_datetime(df['publish_time'], errors='coerce')
# 设置时间的格式为 年月日
df['publish_time'] = df['publish_time'].dt.strftime('%Y-%m-%d')
# 将空值数据直接删除
df.dropna(subset='publish_time', inplace=True)
```

![](https://i-blog.csdnimg.cn/direct/004a8d0695224fac9060fc1c25a4172c.png)

**2.清洗 duration 列并转为整数类型   duration 列包含冗余单位（如 分钟），需提取数字并转为整数**

```python
# 清洗 duration 列并转为整数类型
# duration 列包含冗余单位（如 分钟），需提取数字并转为整数
# 读取这一列的数据 转换成字符串的形式 接着通过正则将分钟去除 最后转换成整型
df['duration'] = df['duration'].str.replace(' 分钟', '', regex=False).astype(int)
# Explain： 读取数据可以通过类似字典的形式 也可以通过df.列名的形式
            regex 为True表示使用正则语法
```

**3.清洗完之后 可以打印这一列的数据出来看下 是否成功**
  
![](https://i-blog.csdnimg.cn/direct/90acb7ed1dfb413a856967ed7b30d6c0.png)

**4.拆分 area 列中的多地区数据  area 列用|分隔多个地区，需拆分为列表或单独列**

```python
# 拆分 area 列中的多地区数据
# area 列用|分隔多个地区，需拆分为列表或单独列
df['area'] = df['area'].str.split('、').str.join('|')
```

**将处理完的列表重新赋值给原来的列表**

**5.**
**提取 name 列中的纯中文名**
  
![](https://i-blog.csdnimg.cn/direct/4ce842fa460c47f484d1fddb67d1048e.png)

**6.通过观察可以发现中英文 之间又-符号隔开 我们可以转换成字符串然后通过分割取前面的值**

```python
# 提取 name 列中的纯中文名
# name 列包含中英文名称，需提取中文名（如 霸王别姬）
df['name'] = df['name'].str.split(' - ').str[0]
```

![](https://i-blog.csdnimg.cn/direct/cb1048c77007401e9d879407cdd7bce8.png)

```python
print(df.iloc[0])
# 可以查看第几行的数据 0为第一行 索引取值
```

7.
**检查并删除重复的电影条目  检查是否有完全重复的行并删除**

**Explain： 重复值的定义为 两条数据完全一样才被定义为重复值**

```python
# 语法如下 使用后drop_duplicates 后面参数接的是要删除重复值的所有列
# inplace 为True 是指在原有的数据上进行保存
df.drop_duplicates(subset=df.columns, inplace=True)
```

8.
**处理缺失值  检查各列是否有缺失值并填充或删除**

```python
print(df.isnull().sum())
# 统计缺失值的个数
```

![](https://i-blog.csdnimg.cn/direct/798dfc8d61e64537ad78e03d8a02addc.png)

9.
**处理缺失值  检查各列是否有缺失值并填充或删除**

```python
df.dropna(inplace=True)
# 删除缺失值
# 如果有缺失值  可以使用该列的均值或者中位数进行填充
# df['列名'].fillna(df['列名'].mean(), inplace=True)  用均值填充
# df['列名'].fillna(df['列名'].median(), inplace=True)  用中位数填充
```

**10.最后保存为新的Excel文件**

```python
# 传入文件名 设置索引列为False  就不会生成单独一行索引
df.to_excel('clean_movies.xlsx', index=False)
```

**最后我们对比一下清洗前后的数据 后续也可以做可视化**
  
![](https://i-blog.csdnimg.cn/direct/293c0fc5f64b48d7885c0a3291bd8e07.png)

![](https://i-blog.csdnimg.cn/direct/147e39385ba7466d843a0a27e92441ae.png)

**本次的案例分享就到此结束 感谢大家的观看 您的点赞和关注是我更新的动力
  
也可以看看我之前的文章希望对你有帮助**