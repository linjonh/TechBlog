---
layout: post
title: "SeaTunnel"
date: 2025-08-26T10:24:45+0800
description: "IMDG = In-Memory Data Grid（内存数据网格）是一个开源的、分布式的内存计算平台。提供类似分布式 HashMap（IMap）、分布式队列、锁、事件监听等能力。所有数据保存在内存中，极快。节点之间通过Gossip 协议自动发现彼此，形成集群。🔥 它本身就是“去中心化”的集群协调系统，自带服务发现 + 状态共享 + 故障转移能力。IMap技术点说明数据分片（Sharding）用 Partition 分散负载，避免单点瓶颈数据备份（Replication）"
keywords: "SeaTunnel"
categories: ['未分类']
tags: ['Java']
artid: "150846947"
arturl: "https://blog.csdn.net/qq_45000512/article/details/150846947"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=150846947
    alt: "SeaTunnel"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=150846947
featuredImagePreview: https://bing.ee123.net/img/rand?artid=150846947
cover: https://bing.ee123.net/img/rand?artid=150846947
image: https://bing.ee123.net/img/rand?artid=150846947
img: https://bing.ee123.net/img/rand?artid=150846947
---



# SeaTunnel

> SeaTunnel Engine 利用 **Hazelcast 内存数据网格（IMDG）** 自带的分布式、高可用、一致性能力，将所有关键状态信息（如任务状态、资源信息）存在 `IMap` 中，由 Hazelcast 自动做数据分片 + 备份 + 故障恢复，从而**无需依赖 ZooKeeper 等外部协调服务就能实现高可用（HA）**。

---

### 🧱 一、核心概念解析

#### 1. 什么是 Hazelcast IMDG？

* **IMDG = In-Memory Data Grid（内存数据网格）**
* 是一个开源的、分布式的内存计算平台。
* 提供类似分布式 HashMap（`IMap`）、分布式队列、锁、事件监听等能力。
* 所有数据保存在内存中，**极快**。
* 节点之间通过 **Gossip 协议**自动发现彼此，形成集群。

> 🔥 它本身就是“去中心化”的集群协调系统，**自带服务发现 + 状态共享 + 故障转移能力**。

---

#### 2. 什么是 `IMap`？

* `IMap` 是 Hazelcast 提供的一个分布式 Map 接口，类似于 Java 的 `ConcurrentHashMap`。
* 但它的数据是分布在多个节点上的。

```



```

java

深色版本

```

IMap<String, JobStatus> jobStatusMap = hazelcastInstance.getMap("job-status");
jobStatusMap.put("job-1", JobStatus.RUNNING);
```

* 这个 `"job-1"` 的状态会被自动分配到某个节点上存储，并且有备份。

---

#### 3. 数据是如何分布的？—— 分区（Partitioning）

Hazelcast 将整个 `IMap` 的数据划分为 **N 个分区（默认 271 个）**，每个分区负责一部分 key。

##### 🔄 分区过程：

1. 对 key 做哈希（如 `"job-1"` → hash = 123）
2. 根据哈希值映射到某个 **主分区（Primary Partition）**
3. 该分区所在的节点就是这个 key 的**主节点**

> 💡 比如 `"job-1"` 的状态存在 Node A 上（主副本）

---

#### 4. 高可用怎么实现？—— 备份（Backup Replicas）

Hazelcast 允许为每个分区设置 **备份副本数（backup-count，默认 1）**

##### 举例：

* 分区 P1 的主节点是 Node A
* 它的备份节点是 Node B
* 所有写入 P1 的数据都会**同步复制**到 Node B

> ✅ 如果 Node A 宕机，Hazelcast 自动将 Node B 提升为新的主节点，数据不丢失！

---

### 🏗️ 二、SeaTunnel Engine 如何利用 Hazelcast 实现 HA？

#### SeaTunnel Engine 的核心状态包括：

| 状态类型 | 示例 |
| --- | --- |
| 作业元信息 | Job ID, 名称, 配置 |
| 作业运行状态 | RUNNING, FAILED, FINISHED |
| 执行图（DAG） | 拓扑结构 |
| 资源分配情况 | TaskGroup 分配在哪个 Worker 上 |
| Metrics 指标 | 吞吐量、延迟等 |

这些状态全部存储在 Hazelcast 的 `IMap` 中，比如：

```



```

java

深色版本

```

IMap<Long, JobExecutionPlan> jobs = instance.getMap("jobs");
IMap<Long, JobStatus> jobStatuses = instance.getMap("job-statuses");
IMap<String, WorkerInfo> workers = instance.getMap("workers");
```

---

### 🔄 三、HA 工作流程详解（以 Master 节点宕机为例）

假设 SeaTunnel 的 **Master 节点**（负责调度）宕机了，会发生什么？

#### 步骤 1：集群自动检测节点失效

* Hazelcast 节点之间通过心跳检测。
* 如果 Master（Node A）宕机，其他节点在几秒内发现它失联。

#### 步骤 2：触发集群重组（Split-Brain Merge）

* 剩下的节点重新选举或选出新的协调者。
* Hazelcast 内部自动完成角色切换。

#### 步骤 3：从备份中恢复状态

* 所有存在 `IMap` 中的状态数据（比如 job-statuses）都有备份。
* 新的 Master（比如 Node B）从本地或备份中读取这些状态，**继续管理任务**。

> ✅ 不需要从磁盘重新加载，也不需要外部协调（如 ZooKeeper），整个过程由 Hazelcast 自动完成！

---

### 🆚 四、对比传统架构：为什么要“去 ZooKeeper”？

| 架构 | 依赖 ZooKeeper | 不依赖 ZooKeeper（Hazelcast） |
| --- | --- | --- |
| 协调服务 | ZooKeeper 存储集群元数据 | Hazelcast 自己就是协调服务 |
| 数据存储 | 外部 CP 系统（ZK） | 内建 AP 分布式 Map（IMap） |
| 故障恢复 | 依赖 ZK 选主 + 从 ZK 恢复状态 | 自动选主 + 从 IMap 备份恢复 |
| 部署复杂度 | 需要额外部署 ZK 集群 | 只需部署 SeaTunnel + Hazelcast 节点 |
| 性能 | ZK 写入较慢（ZAB 协议） | Hazelcast 内存操作，极快 |

> ✅ SeaTunnel Engine 的设计哲学：**轻量、易部署、自包含**

---

### 🧩 五、底层原理图解（文字版）

```



```

深色版本

```

+----------------+     +----------------+     +----------------+
|   Node A       |     |   Node B       |     |   Node C       |
|                |     |                |     |                |
|  IMap:         |<--->|  IMap:         |<--->|  IMap:         |
|   job-1: RUN   |     |   job-2: FIN   |     |   backup of job-1 |
|   backup of job-2 |  |   backup of job-3 |  |   backup of job-2 |
|                |     |                |     |                |
|  Master Role   |     |                |     |                |
+-------┬--------+     +----------------+     +----------------+
        |
        | Node A 宕机
        ↓
+----------------+     +----------------+     +----------------+
|   Node B       |     |   Node C       |
|                |     |                |
|  接管 job-1    |     |                |
|  成为新 Master |     |                |
|  继续监控任务  |     |                |
+----------------+     +----------------+

✅ 任务继续运行，状态未丢失！
```

---

### 🛠️ 六、关键技术点总结

| 技术点 | 说明 |
| --- | --- |
| **数据分片（Sharding）** | 用 Partition 分散负载，避免单点瓶颈 |
| **数据备份（Replication）** | 每个分区有 1~2 个备份，防止单点故障 |
| **自动故障转移（Failover）** | 主节点宕机，备份节点自动接管 |
| **内存存储（In-Memory）** | 状态读写极快，适合高频访问 |
| **对等节点（Peer-to-Peer）** | 无固定主从，任意节点可承担 Master 角色 |
| **自包含集群管理** | 不依赖外部系统，开箱即用 |

---

### ✅ 七、结论：为什么说“无需 ZooKeeper 就能实现 HA”？

因为：

1. **状态存储 = Hazelcast IMap**
2. **数据高可用 = 分区 + 备份机制**
3. **集群协调 = Hazelcast 自身的 Gossip + 选主协议**
4. **故障恢复 = 自动从备份节点恢复状态**

> 🔥 所以，Hazelcast **既是数据存储，又是协调服务**，SeaTunnel Engine 直接复用它的能力，**天然具备高可用性**



