---
arturl_encode: "68747470733a2f2f:626c6f672e6373646e2e6e65742f4d756c7469706c655f782f:61727469636c652f64657461696c732f313436303533333230"
layout: post
title: "论文阅读笔记Learning-Fine-Grained-Bimanual-Manipulation-with-Low-Cost-Hardware"
date: 2025-03-05 21:20:12 +08:00
description: "Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware 论文阅读笔记"
keywords: "arxiv learning fine-grained bimanual manipulation with low-cost hardware"
categories: ['论文阅读笔记']
tags: ['论文阅读', '笔记', '深度学习', '机器人', '人工智能']
artid: "146053320"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146053320
    alt: "论文阅读笔记Learning-Fine-Grained-Bimanual-Manipulation-with-Low-Cost-Hardware"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146053320
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146053320
cover: https://bing.ee123.net/img/rand?artid=146053320
image: https://bing.ee123.net/img/rand?artid=146053320
img: https://bing.ee123.net/img/rand?artid=146053320
---

# 论文阅读笔记——Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware

[ALOHA 论文](https://arxiv.org/pdf/2304.13705)

> ALOHA 解决了策略中的错误可能随时间累积，且人类演示可能是非平稳的，提出了 ACT（Action Chunking with Transformers） 方法。

### Action Chunking

模仿学习中，
**compounding error**
是致使任务失败的主要原因。具体来说，当智能体（agent）在测试时遇到训练集中未见过的情况时，可能会产生预测误差。这些误差会逐步累积，导致智能体进入未知状态，最终任务失败。ALOHA 通过引入
**Action Chunking**
和
**CVAE**
（Conditional Variational Autoencoder）来解决这一问题，显著减少了错误累积的影响。

在传统的模仿学习中，策略模型通常预测
**单步动作

π
θ
(
a
t
∣
s
t
)
\pi\_\theta(a\_t|s\_t)






π









θ

​


(


a









t

​


∣


s









t

​


)**
，即根据当前状态

s
t
s\_t






s









t

​

​ 预测下一个动作

a
t
a\_t






a









t

​

。然而，这种单步预测的方式容易导致误差累积，尤其是在
**长时间任务**
中。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/caf9cdfcc1264fbfb4d3ba4cc6d374d6.png#pic_center)
  
为了减小 compounding error，引入了
**Action Chunking**
，具体来说，模型不再预测单步动作，而是预测一个动作序列。
  
具体步骤如下：

* **Chunk Size 设置**
  ：将动作序列划分为大小为 kk 的块（chunk），每 kk 步，智能体获取一次输入，并预测接下来的 k 步动作。
* **轨迹长度缩减**
  ：轨迹长度被缩小到了

  1
  k
  \frac{1}{k}

















  k












  1

  ​

  。
* **策略模型发生变化**
  ：由预测单步

  π
  θ
  (
  a
  t
  ∣
  s
  t
  )
  \pi\_\theta(a\_t|s\_t)






  π









  θ

  ​


  (


  a









  t

  ​


  ∣


  s









  t

  ​


  )
  变为

  π
  θ
  (
  a
  t
  :
  t
  +
  k
  ∣
  s
  i
  )
  \pi\_\theta(a\_{t:t+k}|s\_i)






  π









  θ

  ​


  (


  a










  t

  :

  t

  +

  k

  ​


  ∣


  s









  i

  ​


  )
  。
    
  为使轨迹更平滑，ALOHA 提出
  **temporal ensemble**
  ，对 k 个对同一动作的预测，采取加权的方式求和，权重

  w
  i
  =
  e
  x
  p
  −
  m
  ∗
  i
  w\_i = exp^{-m\*i}






  w









  i

  ​




  =





  e

  x


  p










  −

  m

  ∗

  i
  。这种方法可以有效减少动作序列中的抖动，使动作更加平滑。

### CVAE

对于
**Action Chunking**
中的
**预测**
，采取 condition + VAE 的方式训练，并采用
**encoder-decoder 架构**
（transformer）。
  
![](https://i-blog.csdnimg.cn/direct/c97b602d2b9d470bb85e651490794c27.png#pic_center)
  
输入信息包括：（此处不使用图像输入时为了加速训练）

* **CLS 分类标签**
  ：表明类别，类似 BERT 的做法。
* **关节角**
  ：机器人当前的关节状态
* **动作序列**
  ：历史动作序列
* **位置嵌入**
  ：表示时间步的位置信息
    
  不同之处这只是通过 encoder 来训练 decoder，在推理时丢弃 encoder 部分。

### 伪代码如下：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/99cf6e79e2e148bc9dad4668678b8498.png#pic_center)