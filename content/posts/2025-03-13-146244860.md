---
layout: post
title: "æ·±åº¦å­¦ä¹ é¡¹ç›®-åŸºäºDenseNetç½‘ç»œçš„ä¹³è…ºç™Œå›¾åƒè¯†åˆ«,å‡†ç¡®ç‡90,pytorchå¤ç°"
date: 2025-03-13 23:29:41 +0800
description: "ä¹³è…ºç™Œè¯†åˆ«"
keywords: "æ·±åº¦å­¦ä¹ é¡¹ç›®--åŸºäºDenseNetç½‘ç»œçš„â€œä¹³è…ºç™Œå›¾åƒè¯†åˆ«â€ï¼Œå‡†ç¡®ç‡90%+ï¼Œpytorchå¤ç°"
categories: ['åŸºäºPytorchçš„æ·±åº¦å­¦ä¹ æ¡ˆä¾‹']
tags: ['ç½‘ç»œ', 'æ·±åº¦å­¦ä¹ ', 'æœºå™¨å­¦ä¹ ', 'åˆ†ç±»', 'äººå·¥æ™ºèƒ½', 'Pytorch', 'Python']
artid: "146244860"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146244860
    alt: "æ·±åº¦å­¦ä¹ é¡¹ç›®-åŸºäºDenseNetç½‘ç»œçš„ä¹³è…ºç™Œå›¾åƒè¯†åˆ«,å‡†ç¡®ç‡90,pytorchå¤ç°"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146244860
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146244860
cover: https://bing.ee123.net/img/rand?artid=146244860
image: https://bing.ee123.net/img/rand?artid=146244860
img: https://bing.ee123.net/img/rand?artid=146244860
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     æ·±åº¦å­¦ä¹ é¡¹ç›®--åŸºäºDenseNetç½‘ç»œçš„â€œä¹³è…ºç™Œå›¾åƒè¯†åˆ«â€ï¼Œå‡†ç¡®ç‡90%+ï¼Œpytorchå¤ç°
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-tomorrow-night" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <ul>
     <li>
      <strong>
       ğŸ¨ æœ¬æ–‡ä¸º
       <a href="https://mp.weixin.qq.com/s/kV8ZsJv6cPNzJLEuhPfvXg" rel="nofollow">
        ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥
       </a>
       ä¸­çš„å­¦ä¹ è®°å½•åšå®¢
      </strong>
     </li>
     <li>
      <strong>
       ğŸ– åŸä½œè€…ï¼š
       <a href="https://mtyjkh.blog.csdn.net/" rel="nofollow">
        KåŒå­¦å•Š
       </a>
      </strong>
     </li>
    </ul>
    <p>
     <strong>
      å‰è¨€
     </strong>
    </p>
    <ul>
     <li>
      å¦‚æœè¯´æœ€ç»å…¸çš„ç¥ç»ç½‘ç»œï¼Œ
      <code>
       ResNet
      </code>
      è‚¯å®šæ˜¯ä¸€ä¸ªï¼Œä»ResNetå‘å¸ƒåï¼Œå¾ˆå¤šäººåšäº†ä¿®æ”¹ï¼Œ
      <strong>
       denseNetç½‘ç»œæ— ç–‘æ˜¯æœ€æˆåŠŸçš„ä¸€ä¸ª
      </strong>
      ï¼Œå®ƒé‡‡ç”¨
      <code>
       å¯†é›†å‹è¿æ¥ï¼Œå°†é€šé“æ•°è¿æ¥åœ¨ä¸€èµ·
      </code>
      ï¼›
     </li>
     <li>
      <strong>
       æœ¬æ–‡æ˜¯åŸºäºä¸Šä¸€ç¯‡å¤ç°DenseNet121æ¨¡å‹
      </strong>
      ï¼Œåšä¸€ä¸ª
      <mark>
       ä¹³è…ºç™Œå›¾åƒè¯†åˆ«
      </mark>
      ï¼Œæ•ˆæœè¿˜è¡Œï¼Œ
      <mark>
       å‡†ç¡®ç‡0.9+
      </mark>
      ;
     </li>
     <li>
      CNNç»å…¸ç½‘ç»œä¹‹â€œDenseNetâ€ç®€ä»‹ï¼Œæºç ç ”ç©¶ä¸å¤ç°(pytorch)ï¼š
      <a href="" rel="nofollow">
       https://blog.csdn.net/weixin_74085818/article/details/146102290?spm=1001.2014.3001.5501
      </a>
     </li>
     <li>
      <mark>
       æ¬¢è¿æ”¶è— + å…³æ³¨ï¼Œæœ¬äººå°†ä¼šæŒç»­æ›´æ–°
      </mark>
     </li>
    </ul>
    <blockquote>
     <p>
     </p>
     <p>
     </p>
    </blockquote>
    <h3>
     <a id="1_11">
     </a>
     1ã€å¯¼å…¥æ•°æ®
    </h3>
    <h4>
     <a id="1_13">
     </a>
     1ã€å¯¼å…¥åº“
    </h4>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch  
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torchvision 
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np 
<span class="token keyword">import</span> os<span class="token punctuation">,</span> PIL<span class="token punctuation">,</span> pathlib 
<span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict
<span class="token keyword">import</span> re
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>hub <span class="token keyword">import</span> load_state_dict_from_url

<span class="token comment"># è®¾ç½®è®¾å¤‡</span>
device <span class="token operator">=</span> <span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span>

device 
</code></pre>
    <pre><code>'cuda'
</code></pre>
    <h4>
     <a id="2_37">
     </a>
     2ã€æŸ¥çœ‹æ•°æ®ä¿¡æ¯å’Œå¯¼å…¥æ•°æ®
    </h4>
    <pre><code class="prism language-python">data_dir <span class="token operator">=</span> <span class="token string">"./data/"</span>

data_dir <span class="token operator">=</span> pathlib<span class="token punctuation">.</span>Path<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span>

<span class="token comment"># ç±»åˆ«æ•°é‡</span>
classnames <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\\"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> path <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span><span class="token punctuation">]</span>

classnames
</code></pre>
    <pre><code>['0', '1']
</code></pre>
    <h4>
     <a id="3_56">
     </a>
     3ã€å±•ç¤ºæ•°æ®
    </h4>
    <pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pylab <span class="token keyword">as</span> plt  
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image 

<span class="token comment"># è·å–æ–‡ä»¶åç§°</span>
data_path_name <span class="token operator">=</span> <span class="token string">"./data/0/"</span>  <span class="token comment"># ä¸æ‚£ç—…çš„</span>
data_path_list <span class="token operator">=</span> <span class="token punctuation">[</span>f <span class="token keyword">for</span> f <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>data_path_name<span class="token punctuation">)</span> <span class="token keyword">if</span> f<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'jpg'</span><span class="token punctuation">,</span> <span class="token string">'png'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token comment"># åˆ›å»ºç”»æ¿</span>
fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> ax<span class="token punctuation">,</span> img_file <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>axes<span class="token punctuation">.</span>flat<span class="token punctuation">,</span> data_path_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
    path_name <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_path_name<span class="token punctuation">,</span> img_file<span class="token punctuation">)</span>
    img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path_name<span class="token punctuation">)</span> <span class="token comment"># æ‰“å¼€</span>
    <span class="token comment"># æ˜¾ç¤º</span>
    ax<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>
    
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     â€‹
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/745cdf7408ea40c1b021135e0ccbdc63.png#pic_center"/>
    </p>
    <p>
     â€‹
    </p>
    <h4>
     <a id="4_84">
     </a>
     4ã€æ•°æ®å¯¼å…¥
    </h4>
    <pre><code class="prism language-python"><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token punctuation">,</span> datasets 

<span class="token comment"># æ•°æ®ç»Ÿä¸€æ ¼å¼</span>
img_height <span class="token operator">=</span> <span class="token number">224</span>
img_width <span class="token operator">=</span> <span class="token number">224</span> 

data_tranforms <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">[</span>img_height<span class="token punctuation">,</span> img_width<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>   <span class="token comment"># å½’ä¸€åŒ–</span>
        mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span> 
    <span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># åŠ è½½æ‰€æœ‰æ•°æ®</span>
total_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./data/"</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>data_tranforms<span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="5_106">
     </a>
     5ã€æ•°æ®åˆ’åˆ†
    </h4>
    <pre><code class="prism language-python"><span class="token comment"># å¤§å° 8 : 2</span>
train_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>total_data<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.8</span><span class="token punctuation">)</span>
test_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>total_data<span class="token punctuation">)</span> <span class="token operator">-</span> train_size 

train_data<span class="token punctuation">,</span> test_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>random_split<span class="token punctuation">(</span>total_data<span class="token punctuation">,</span> <span class="token punctuation">[</span>train_size<span class="token punctuation">,</span> test_size<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="6_116">
     </a>
     6ã€åŠ¨æ€åŠ è½½æ•°æ®
    </h4>
    <pre><code class="prism language-python">batch_size <span class="token operator">=</span> <span class="token number">64</span>

train_dl <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>
    train_data<span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
    shuffle<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

test_dl <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>
    test_data<span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
    shuffle<span class="token operator">=</span><span class="token boolean">False</span>
<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-python"><span class="token comment"># æŸ¥çœ‹æ•°æ®ç»´åº¦</span>
<span class="token keyword">for</span> data<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_dl<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data shape[N, C, H, W]: "</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"labels: "</span><span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
    <span class="token keyword">break</span>
</code></pre>
    <pre><code>data shape[N, C, H, W]:  torch.Size([64, 3, 224, 224])
labels:  tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,
        1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
        1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1])
</code></pre>
    <h3>
     <a id="2DenseNet121_149">
     </a>
     2ã€æ„å»ºDenseNet121ç½‘ç»œ
    </h3>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token comment"># å®ç°DenseBlockä¸­çš„éƒ¨ä»¶ï¼šDenseLayer</span>
<span class="token triple-quoted-string string">'''  
1ã€BN + ReLU: å¤„ç†éƒ¨åˆ†ï¼Œé¦–å…ˆè¿›è¡Œå½’ä¸€åŒ–ï¼Œç„¶ååœ¨ç”¨æ¿€æ´»å‡½æ•°ReLU
2ã€Bottlenck Layerï¼šç§°ä¸ºç“¶é¢ˆå±‚ï¼Œè¿™ä¸ªå±‚åœ¨yolov5ä¸­å¸¸ç”¨ï¼Œä½†æ˜¯yolov5ä¸­ä¸»è¦ç”¨äºç‰¹å¾æå–+ç»´åº¦é™ç»´ï¼Œè¿™é‡Œé‡‡ç”¨1 * 1å·ç§¯æ ¸ + 3 * 3çš„å·ç§¯æ ¸è¿›è¡Œå·ç§¯æ“ä½œï¼Œç›®çš„ï¼šå‡å°‘è¾“å…¥è¾“å…¥ç‰¹å¾ç»´åº¦
3ã€BN + ReLUï¼šå¯¹ ç“¶é¢ˆå±‚ æ•°æ®è¿›è¡Œå½’ä¸€åŒ–ï¼ŒReLUæ¿€æ´»å‡½æ•°ï¼Œå½’ä¸€åŒ–å¯ä»¥ç¡®ä¿æ¢¯åº¦ä¸‹é™çš„æ—¶å€™è¾ƒä¸ºå¹³ç¨³
4ã€3 * 3 ç”Ÿæˆæ–°çš„ç‰¹å¾å›¾
'''</span>
<span class="token keyword">class</span> <span class="token class-name">_DenseLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_input_features<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span> bn_size<span class="token punctuation">,</span> drop_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''  
        num_input_features: è¾“å…¥ç‰¹å¾æ•°ï¼Œä¹Ÿå°±æ˜¯é€šé“æ•°ï¼Œåœ¨DenseNetä¸­ï¼Œæ¯ä¸€å±‚éƒ½ä¼šæ¥å—ä¹‹å‰å±‚çš„è¾“å‡ºä½œä¸ºè¾“å…¥ï¼Œæ•…ï¼Œè¿™ä¸ªæ•°å€¼é€šå¸¸ä¼šéšç€ç½‘ç»œæ·±åº¦å¢åŠ è€Œå¢åŠ 
        growth_rate: å¢é•¿ç‡ï¼Œè¿™ä¸ªæ˜¯ DenseNetçš„æ ¸å¿ƒæ¦‚å¿µï¼Œå†³å®šäº†æ¯ä¸€å±‚ä¸ºå…¨å±€çŠ¶æ€è´¡çŒ®çš„ç‰¹å¾æ•°é‡ï¼Œä»–çš„ç”¨å¤„ä¸»è¦åœ¨äºå†³å®šäº†ä¸­é—´ç“¶é¢ˆå±‚çš„è¾“å‡ºé€šé“ï¼Œéœ€è¦ç»“åˆä»£ç å»ç ”ç©¶
        bn_size: ç“¶é¢ˆå±‚ä¸­è¾“å‡ºé€šé“å¤§å°ï¼Œå«ä¹‰ï¼šåœ¨ä½¿ç”¨1 * 1å·ç§¯æ ¸å»æå–ç‰¹å¾æ•°æ—¶ï¼Œç›®æ ‡é€šé“éœ€è¦æ‰©å±•åˆ°growth_rateçš„å¤šå°‘å€å€æ•°ï¼Œ bn_size * growth_rate(è¾“å‡ºç»´åº¦)
        drop_rate: ä½¿ç”¨Dropoutçš„å‚æ•°
        '''</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>_DenseLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"norm1"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_input_features<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"relu1"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># è¾“å‡ºç»´åº¦ï¼š bn_size * growth_rate, 1 * 1å·ç§¯æ ¸ï¼Œæ­¥ä¼ä¸º1ï¼Œåªèµ·åˆ°ç‰¹å¾æå–ä½œç”¨</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"conv1"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>num_input_features<span class="token punctuation">,</span> bn_size <span class="token operator">*</span> growth_rate<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"norm2"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>bn_size <span class="token operator">*</span> growth_rate<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"relu2"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># è¾“å‡ºé€šé“ï¼šgrowth_rate, ç»´åº¦è®¡ç®—ï¼šä¸å˜</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"conv2"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>bn_size <span class="token operator">*</span> growth_rate<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>drop_rate <span class="token operator">=</span> drop_rate
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        new_features <span class="token operator">=</span> <span class="token builtin">super</span><span class="token punctuation">(</span>_DenseLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># ä¼ æ’­</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>drop_rate <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            new_features <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>new_features<span class="token punctuation">,</span> p<span class="token operator">=</span>self<span class="token punctuation">.</span>drop_rate<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>  <span class="token comment"># self.training ç»§æ‰¿nn.Sequentialï¼Œæ˜¯å¦è®­ç»ƒæ¨¡å¼</span>
        <span class="token comment"># æ¨¡å‹èåˆï¼Œå³ï¼Œç‰¹å¾é€šé“èåˆï¼Œå½¢æˆæ–°çš„ç‰¹å¾å›¾</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> new_features<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># (N, C, H, W)  # å³ C1 + C2ï¼Œé€šé“ä¸Šèåˆ</span>
    
<span class="token triple-quoted-string string">'''  
DenseNetç½‘ç»œæ ¸å¿ƒç”±DenseBlockæ¨¡å—ç»„æˆï¼ŒDenseBlockç½‘ç»œç”±DenseLayerç»„æˆï¼Œä» DenseLayer å¯ä»¥çœ‹å‡ºï¼ŒDenseBlockæ˜¯
    å¯†é›†è¿æ¥ï¼Œæ¯ä¸€å±‚çš„è¾“å…¥ä¸ä»…åŒ…å«å‰ä¸€å±‚çš„è¾“å‡ºï¼Œè¿˜åŒ…å«ç½‘ç»œä¸­æ‰€æœ‰ä¹‹å‰å±‚çš„è¾“å‡º
'''</span>
<span class="token comment"># æ„å»ºDenseBlockæ¨¡å—, é€šè¿‡ä¸Šå›¾</span>
<span class="token keyword">class</span> <span class="token class-name">_DenseBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># num_layers å‡ å±‚DenseLayeræ¨¡å—</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> num_input_features<span class="token punctuation">,</span> bn_size<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span> drop_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>_DenseBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
            layer <span class="token operator">=</span> _DenseLayer<span class="token punctuation">(</span>num_input_features <span class="token operator">+</span> i <span class="token operator">*</span> growth_rate<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span> bn_size<span class="token punctuation">,</span> drop_rate<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"denselayer%d"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> layer<span class="token punctuation">)</span>
    
 
 
 <span class="token comment"># Transitionå±‚ï¼Œç”¨äºç»´åº¦å‹ç¼©</span>
 <span class="token comment"># ç»„æˆï¼šä¸€ä¸ªå·ç§¯å±‚ + ä¸€ä¸ªæ± åŒ–å±‚</span>
<span class="token keyword">class</span> <span class="token class-name">_Transition</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_init_features<span class="token punctuation">,</span> num_out_features<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>_Transition<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"norm"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_init_features<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"relu"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"conv"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>num_init_features<span class="token punctuation">,</span> num_out_features<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># é™ç»´</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"pool"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

         
<span class="token comment"># æ­å»ºDenseNetç½‘ç»œ</span>
<span class="token keyword">class</span> <span class="token class-name">DenseNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> growth_rate<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> block_config<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span> num_init_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> bn_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> 
                 compression_rate<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> drop_rate<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''  
        growth_rateã€num_init_featuresã€num_init_featuresã€drop_rate å’Œdenselayerä¸€æ ·
        block_config : å‚æ•°åœ¨ DenseNet æ¶æ„ä¸­ç”¨äºæŒ‡å®šæ¯ä¸ª Dense Block ä¸­åŒ…å«çš„å±‚æ•°, å¦‚ï¼š
                DenseNet-121: block_config=(6, 12, 24, 16) è¡¨ç¤ºç¬¬ä¸€ä¸ª Dense Block åŒ…å« 6 å±‚ï¼Œç¬¬äºŒä¸ªåŒ…å« 12 å±‚ï¼Œç¬¬ä¸‰ä¸ªåŒ…å« 24 å±‚ï¼Œç¬¬å››ä¸ªåŒ…å« 16 å±‚ã€‚
                DenseNet-169: block_config=(6, 12, 32, 32)
                DenseNet-201: block_config=(6, 12, 48, 32)
                DenseNet-264: block_config=(6, 12, 64, 48)
        compression_rate: å‹ç¼©ç»´åº¦, DenseNet ä¸­ç”¨äº Transition Layerï¼ˆè¿‡æ¸¡å±‚ï¼‰çš„ä¸€ä¸ªé‡è¦å‚æ•°ï¼Œå®ƒæ§åˆ¶äº†ä»ä¸€ä¸ª Dense Block åˆ°ä¸‹ä¸€ä¸ª Dense Block ä¹‹é—´ç‰¹å¾ç»´åº¦çš„å‹ç¼©ç¨‹åº¦
        '''</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>DenseNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># ç¬¬ä¸€å±‚å·ç§¯</span>
        <span class="token comment"># OrderedDictï¼Œè®©æ¨¡å‹å±‚æœ‰åºæ’åˆ—</span>
        self<span class="token punctuation">.</span>features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span>
            <span class="token comment"># è¾“å‡ºç»´åº¦ï¼š((w - k + 2 * p) / s) + 1</span>
            <span class="token punctuation">(</span><span class="token string">"conv0"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> num_init_features<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">"norm0"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_init_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">"relu0"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">"pool0"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># é™ç»´</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        <span class="token comment"># æ­å»ºDenseBlockå±‚</span>
        num_features <span class="token operator">=</span> num_init_features
        <span class="token comment"># num_layers: å±‚æ•°</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> num_layers <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>block_config<span class="token punctuation">)</span><span class="token punctuation">:</span>
            block <span class="token operator">=</span> _DenseBlock<span class="token punctuation">(</span>num_layers<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> bn_size<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span> drop_rate<span class="token punctuation">)</span>
            <span class="token comment"># nn.Module ä¸­featureså°è£…äº†nn.Sequential</span>
            self<span class="token punctuation">.</span>features<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"denseblock%d"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> block<span class="token punctuation">)</span>
            <span class="token triple-quoted-string string">'''  
            # è¿™ä¸ªè®¡ç®—åæ˜ äº† DenseNet ä¸­çš„ä¸€ä¸ªå…³é”®ç‰¹æ€§ï¼šæ¯ä¸€å±‚è¾“å‡ºçš„ç‰¹å¾å›¾ï¼ˆå³æ–°å¢åŠ çš„é€šé“æ•°ï¼‰ç”± growth_rate å†³å®šï¼Œ
            # å¹¶ä¸”è¿™äº›æ–°ç”Ÿæˆçš„ç‰¹å¾å›¾ä¼šè¢«ä¼ é€’ç»™è¯¥ Dense Block ä¸­çš„æ‰€æœ‰åç»­å±‚ä»¥åŠä¸‹ä¸€ä¸ª Dense Blockã€‚
            '''</span>
            num_features <span class="token operator">+=</span> num_layers <span class="token operator">*</span> growth_rate  <span class="token comment"># å åŠ ï¼Œæ¯ä¸€æ¬¡å åŠ </span>
            
            <span class="token comment"># åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨Transitionå±‚</span>
            <span class="token keyword">if</span> i <span class="token operator">!=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>block_config<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span>
                transition <span class="token operator">=</span> _Transition<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>num_features<span class="token operator">*</span>compression_rate<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># compression_rate ä½œç”¨</span>
                self<span class="token punctuation">.</span>features<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"transition%d"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transition<span class="token punctuation">)</span>
                num_features <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>num_features<span class="token operator">*</span>compression_rate<span class="token punctuation">)</span>  <span class="token comment"># æ›´æ–°ç»´åº¦</span>
        
        
        <span class="token comment"># æœ€åä¸€å±‚</span>
        self<span class="token punctuation">.</span>features<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"norm5"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_features<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>features<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"relu5"</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        <span class="token comment"># åˆ†ç±»å±‚         </span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
        
        <span class="token comment"># params initialization         </span>
        <span class="token keyword">for</span> m <span class="token keyword">in</span> self<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>             
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>         
                <span class="token triple-quoted-string string">'''
                å¦‚æœå½“å‰æ¨¡å—æ˜¯ä¸€ä¸ªäºŒç»´å·ç§¯å±‚ (nn.Conv2d)ï¼Œé‚£ä¹ˆå®ƒçš„æƒé‡ (m.weight) å°†é€šè¿‡ Kaiming æ­£æ€åˆ†å¸ƒ (kaiming_normal_) è¿›è¡Œåˆå§‹åŒ–ã€‚
                è¿™ç§åˆå§‹åŒ–æ–¹å¼ç‰¹åˆ«é€‚åˆä¸ReLUæ¿€æ´»å‡½æ•°ä¸€èµ·ä½¿ç”¨ï¼Œæœ‰åŠ©äºç¼“è§£æ·±åº¦ç½‘ç»œä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä¿ƒè¿›æœ‰æ•ˆçš„è®­ç»ƒã€‚  
                '''</span>       
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>             
            <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>      
                <span class="token triple-quoted-string string">'''  
                å¯¹äºäºŒç»´æ‰¹å½’ä¸€åŒ–å±‚ (nn.BatchNorm2d)ï¼Œåç½®é¡¹ (m.bias) è¢«åˆå§‹åŒ–ä¸º0ï¼Œè€Œå°ºåº¦å› å­ (m.weight) è¢«åˆå§‹åŒ–ä¸º1ã€‚
                è¿™æ„å‘³ç€åœ¨æ²¡æœ‰æ•°æ®ç»è¿‡çš„æƒ…å†µä¸‹ï¼Œæ‰¹å½’ä¸€åŒ–å±‚ä¸ä¼šå¯¹è¾“å…¥è¿›è¡Œé¢å¤–çš„ç¼©æ”¾æˆ–åç§»ï¼Œä¿æŒè¾“å…¥ä¸å˜ã€‚
                '''</span>           
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>                 
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>             
            <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>        
                <span class="token triple-quoted-string string">'''  
                å¯¹äºå…¨è¿æ¥å±‚ (nn.Linear)ï¼Œåªå¯¹å…¶åç½®é¡¹ (m.bias) è¿›è¡Œäº†åˆå§‹åŒ–ï¼Œè®¾ç½®ä¸º0'''</span>         
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
                
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        features <span class="token operator">=</span> self<span class="token punctuation">.</span>features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> F<span class="token punctuation">.</span>avg_pool2d<span class="token punctuation">(</span>features<span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out

model <span class="token operator">=</span> DenseNet<span class="token punctuation">(</span>num_init_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> growth_rate<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> block_config<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
</code></pre>
    <pre><code>DenseNet(
  (features): Sequential(
    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu0): ReLU(inplace=True)
    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (denseblock1): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition1): _Transition(
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock2): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition2): _Transition(
      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock3): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition3): _Transition(
      (norm): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock4): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (norm5): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu5): ReLU(inplace=True)
  )
  (classifier): Linear(in_features=832, out_features=1000, bias=True)
)
</code></pre>
    <h3>
     <a id="3_708">
     </a>
     3ã€æ¨¡å‹è®­ç»ƒ
    </h3>
    <h4>
     <a id="1_710">
     </a>
     1ã€æ„å»ºè®­ç»ƒé›†
    </h4>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>
    batch_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>
    
    train_acc<span class="token punctuation">,</span> train_loss <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span> 
    
    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
        X<span class="token punctuation">,</span> y <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        
        <span class="token comment"># è®­ç»ƒ</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        
        <span class="token comment"># æ¢¯åº¦ä¸‹é™æ³•</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment"># è®°å½•</span>
        train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_acc <span class="token operator">+=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
    train_acc <span class="token operator">/=</span> size
    train_loss <span class="token operator">/=</span> batch_size
    
    <span class="token keyword">return</span> train_acc<span class="token punctuation">,</span> train_loss
</code></pre>
    <h4>
     <a id="2_741">
     </a>
     2ã€æ„å»ºæµ‹è¯•é›†
    </h4>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>
    size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>
    batch_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>
    
    test_acc<span class="token punctuation">,</span> test_loss <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span> 
    
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
            X<span class="token punctuation">,</span> y <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        
            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        
            test_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            test_acc <span class="token operator">+=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
    test_acc <span class="token operator">/=</span> size
    test_loss <span class="token operator">/=</span> batch_size
    
    <span class="token keyword">return</span> test_acc<span class="token punctuation">,</span> test_loss
</code></pre>
    <h4>
     <a id="3_766">
     </a>
     3ã€è®¾ç½®è¶…å‚æ•°
    </h4>
    <pre><code class="prism language-python">loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># æŸå¤±å‡½æ•°     </span>
learn_lr <span class="token operator">=</span> <span class="token number">1e-4</span>             <span class="token comment"># è¶…å‚æ•°</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learn_lr<span class="token punctuation">)</span>   <span class="token comment"># ä¼˜åŒ–å™¨</span>
</code></pre>
    <h3>
     <a id="4_774">
     </a>
     4ã€æ¨¡å‹è®­ç»ƒ
    </h3>
    <p>
     é€šè¿‡å®éªŒå‘ç°ï¼Œè¿˜æ˜¯è®¾ç½®20è½®æ¬¡é™„ä»¶æœ€å¥½
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> copy

train_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
train_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
test_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
test_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

epoches <span class="token operator">=</span> <span class="token number">20</span>

best_acc <span class="token operator">=</span> <span class="token number">0</span>    <span class="token comment"># è®¾ç½®ä¸€ä¸ªæœ€ä½³å‡†ç¡®ç‡ï¼Œä½œä¸ºæœ€ä½³æ¨¡å‹çš„åˆ¤åˆ«æŒ‡æ ‡</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    epoch_train_acc<span class="token punctuation">,</span> epoch_train_loss <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dl<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span>
    
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    epoch_test_acc<span class="token punctuation">,</span> epoch_test_loss <span class="token operator">=</span> test<span class="token punctuation">(</span>test_dl<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span>

     <span class="token comment"># ä¿å­˜æœ€ä½³æ¨¡å‹åˆ° best_model     </span>
    <span class="token keyword">if</span> epoch_test_acc <span class="token operator">&gt;</span> best_acc<span class="token punctuation">:</span>         
        best_acc   <span class="token operator">=</span> epoch_test_acc         
        best_model <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
    
    train_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_train_acc<span class="token punctuation">)</span>
    train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_train_loss<span class="token punctuation">)</span>
    test_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_test_acc<span class="token punctuation">)</span>
    test_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_test_loss<span class="token punctuation">)</span>

    <span class="token comment"># è·å–å½“å‰çš„å­¦ä¹ ç‡     </span>
    lr <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'param_groups'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span>
    
    <span class="token comment"># è¾“å‡º</span>
    template <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'Epoch:{:2d}, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%, Test_loss:{:.3f}'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>template<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> epoch_train_acc<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">,</span> epoch_train_loss<span class="token punctuation">,</span> epoch_test_acc<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">,</span> epoch_test_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>

PATH <span class="token operator">=</span> <span class="token string">'./best_model.pth'</span>  <span class="token comment"># ä¿å­˜çš„å‚æ•°æ–‡ä»¶å </span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>best_model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done"</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code>Epoch: 1, Train_acc:79.3%, Train_loss:1.948, Test_acc:84.6%, Test_loss:1.079
Epoch: 2, Train_acc:85.3%, Train_loss:0.395, Test_acc:85.2%, Test_loss:0.721
Epoch: 3, Train_acc:87.3%, Train_loss:0.318, Test_acc:86.5%, Test_loss:0.526
Epoch: 4, Train_acc:89.0%, Train_loss:0.277, Test_acc:86.6%, Test_loss:0.494
Epoch: 5, Train_acc:89.0%, Train_loss:0.266, Test_acc:87.9%, Test_loss:0.400
Epoch: 6, Train_acc:89.6%, Train_loss:0.252, Test_acc:84.6%, Test_loss:0.524
Epoch: 7, Train_acc:90.3%, Train_loss:0.239, Test_acc:85.5%, Test_loss:0.445
Epoch: 8, Train_acc:90.2%, Train_loss:0.235, Test_acc:87.6%, Test_loss:0.359
Epoch: 9, Train_acc:90.0%, Train_loss:0.235, Test_acc:89.3%, Test_loss:0.298
Epoch:10, Train_acc:91.0%, Train_loss:0.220, Test_acc:89.5%, Test_loss:0.307
Epoch:11, Train_acc:90.8%, Train_loss:0.222, Test_acc:88.3%, Test_loss:0.316
Epoch:12, Train_acc:91.4%, Train_loss:0.210, Test_acc:83.3%, Test_loss:0.516
Epoch:13, Train_acc:91.5%, Train_loss:0.208, Test_acc:91.3%, Test_loss:0.247
Epoch:14, Train_acc:91.5%, Train_loss:0.206, Test_acc:90.1%, Test_loss:0.269
Epoch:15, Train_acc:92.0%, Train_loss:0.199, Test_acc:91.1%, Test_loss:0.242
Epoch:16, Train_acc:92.1%, Train_loss:0.194, Test_acc:89.4%, Test_loss:0.285
Epoch:17, Train_acc:92.4%, Train_loss:0.193, Test_acc:91.0%, Test_loss:0.229
Epoch:18, Train_acc:92.4%, Train_loss:0.188, Test_acc:88.0%, Test_loss:0.317
Epoch:19, Train_acc:92.7%, Train_loss:0.182, Test_acc:89.2%, Test_loss:0.285
Epoch:20, Train_acc:92.6%, Train_loss:0.182, Test_acc:78.5%, Test_loss:0.728
Done
</code></pre>
    <h3>
     <a id="5_844">
     </a>
     5ã€ç»“æœå¯è§†åŒ–
    </h3>
    <pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token comment">#éšè—è­¦å‘Š</span>
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span>               <span class="token comment">#å¿½ç•¥è­¦å‘Šä¿¡æ¯</span>

epochs_range <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> train_acc<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Accuracy'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> test_acc<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Test Accuracy'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Training Accuracy'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> test_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Test Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Training= Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     â€‹
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/0f433602e6034b85b2d7e68912abc034.png#pic_center"/>
    </p>
    <p>
     â€‹
    </p>
    <p>
     åœ¨20è½®æµ‹è¯•é›†å‡†ç¡®ç‡å˜åŒ–æ¯”è¾ƒå¤§ï¼Œä»è·‘çš„å‡ æ¬¡å®éªŒæ¥çœ‹ï¼Œè¿™æ¬¡æ˜¯å¶ç„¶äº‹ä»¶ï¼Œæµ‹è¯•é›†æŸå¤±ç‡åé¢ä¸€ç›´ç¨³å®šåœ¨0.3é™„ä»¶ï¼Œæµ‹è¯•å‡†ç¡®ç‡ä¸€ç›´åœ¨0.8ã€0.89ã€0.90é™„ä»¶å¾˜å¾Š
    </p>
    <h3>
     <a id="6_877">
     </a>
     6ã€æ¨¡å‹è¯„ä¼°
    </h3>
    <pre><code class="prism language-python"><span class="token comment"># å°†å‚æ•°åŠ è½½åˆ°modelå½“ä¸­ </span>
best_model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">,</span> map_location<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span> 
epoch_test_acc<span class="token punctuation">,</span> epoch_test_loss <span class="token operator">=</span> test<span class="token punctuation">(</span>test_dl<span class="token punctuation">,</span> best_model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>epoch_test_acc<span class="token punctuation">,</span> epoch_test_loss<span class="token punctuation">)</span>
</code></pre>
    <pre><code>0.9134651249533756 0.24670581874393283
</code></pre>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f37343038353831382f:61727469636c652f64657461696c732f313436323434383630" class_="artid" style="display:none">
 </p>
</div>


