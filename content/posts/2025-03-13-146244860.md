---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f37343038353831382f:61727469636c652f64657461696c732f313436323434383630"
layout: post
title: "æ·±åº¦å­¦ä¹ é¡¹ç›®-åŸºäºDenseNetç½‘ç»œçš„ä¹³è…ºç™Œå›¾åƒè¯†åˆ«,å‡†ç¡®ç‡90,pytorchå¤ç°"
date: 2025-03-13 23:29:41 +0800
description: "ä¹³è…ºç™Œè¯†åˆ«"
keywords: "æ·±åº¦å­¦ä¹ é¡¹ç›®--åŸºäºDenseNetç½‘ç»œçš„â€œä¹³è…ºç™Œå›¾åƒè¯†åˆ«â€ï¼Œå‡†ç¡®ç‡90%+ï¼Œpytorchå¤ç°"
categories: ['åŸºäºPytorchçš„æ·±åº¦å­¦ä¹ æ¡ˆä¾‹']
tags: ['ç½‘ç»œ', 'æ·±åº¦å­¦ä¹ ', 'æœºå™¨å­¦ä¹ ', 'åˆ†ç±»', 'äººå·¥æ™ºèƒ½', 'Pytorch', 'Python']
artid: "146244860"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146244860
    alt: "æ·±åº¦å­¦ä¹ é¡¹ç›®-åŸºäºDenseNetç½‘ç»œçš„ä¹³è…ºç™Œå›¾åƒè¯†åˆ«,å‡†ç¡®ç‡90,pytorchå¤ç°"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146244860
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146244860
cover: https://bing.ee123.net/img/rand?artid=146244860
image: https://bing.ee123.net/img/rand?artid=146244860
img: https://bing.ee123.net/img/rand?artid=146244860
---

# æ·±åº¦å­¦ä¹ é¡¹ç›®--åŸºäºDenseNetç½‘ç»œçš„â€œä¹³è…ºç™Œå›¾åƒè¯†åˆ«â€ï¼Œå‡†ç¡®ç‡90%+ï¼Œpytorchå¤ç°

* **ğŸ¨ æœ¬æ–‡ä¸º
  [ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥](https://mp.weixin.qq.com/s/kV8ZsJv6cPNzJLEuhPfvXg)
  ä¸­çš„å­¦ä¹ è®°å½•åšå®¢**
* **ğŸ– åŸä½œè€…ï¼š
  [KåŒå­¦å•Š](https://mtyjkh.blog.csdn.net/)**

**å‰è¨€**

* å¦‚æœè¯´æœ€ç»å…¸çš„ç¥ç»ç½‘ç»œï¼Œ
  `ResNet`
  è‚¯å®šæ˜¯ä¸€ä¸ªï¼Œä»ResNetå‘å¸ƒåï¼Œå¾ˆå¤šäººåšäº†ä¿®æ”¹ï¼Œ
  **denseNetç½‘ç»œæ— ç–‘æ˜¯æœ€æˆåŠŸçš„ä¸€ä¸ª**
  ï¼Œå®ƒé‡‡ç”¨
  `å¯†é›†å‹è¿æ¥ï¼Œå°†é€šé“æ•°è¿æ¥åœ¨ä¸€èµ·`
  ï¼›
* **æœ¬æ–‡æ˜¯åŸºäºä¸Šä¸€ç¯‡å¤ç°DenseNet121æ¨¡å‹**
  ï¼Œåšä¸€ä¸ª
  ä¹³è…ºç™Œå›¾åƒè¯†åˆ«
  ï¼Œæ•ˆæœè¿˜è¡Œï¼Œ
  å‡†ç¡®ç‡0.9+
  ;
* CNNç»å…¸ç½‘ç»œä¹‹â€œDenseNetâ€ç®€ä»‹ï¼Œæºç ç ”ç©¶ä¸å¤ç°(pytorch)ï¼š
  https://blog.csdn.net/weixin\_74085818/article/details/146102290?spm=1001.2014.3001.5501
* æ¬¢è¿æ”¶è— + å…³æ³¨ï¼Œæœ¬äººå°†ä¼šæŒç»­æ›´æ–°



### 1ã€å¯¼å…¥æ•°æ®

#### 1ã€å¯¼å…¥åº“

```python
import torch  
import torch.nn as nn
import torchvision 
import numpy as np 
import os, PIL, pathlib 
from collections import OrderedDict
import re
from torch.hub import load_state_dict_from_url

# è®¾ç½®è®¾å¤‡
device = "cuda" if torch.cuda.is_available() else "cpu"

device 

```

```
'cuda'

```

#### 2ã€æŸ¥çœ‹æ•°æ®ä¿¡æ¯å’Œå¯¼å…¥æ•°æ®

```python
data_dir = "./data/"

data_dir = pathlib.Path(data_dir)

# ç±»åˆ«æ•°é‡
classnames = [str(path).split("\\")[0] for path in os.listdir(data_dir)]

classnames

```

```
['0', '1']

```

#### 3ã€å±•ç¤ºæ•°æ®

```python
import matplotlib.pylab as plt  
from PIL import Image 

# è·å–æ–‡ä»¶åç§°
data_path_name = "./data/0/"  # ä¸æ‚£ç—…çš„
data_path_list = [f for f in os.listdir(data_path_name) if f.endswith(('jpg', 'png'))]

# åˆ›å»ºç”»æ¿
fig, axes = plt.subplots(2, 8, figsize=(16, 6))

for ax, img_file in zip(axes.flat, data_path_list):
    path_name = os.path.join(data_path_name, img_file)
    img = Image.open(path_name) # æ‰“å¼€
    # æ˜¾ç¤º
    ax.imshow(img)
    ax.axis('off')
    
plt.show()

```

â€‹
  
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/745cdf7408ea40c1b021135e0ccbdc63.png#pic_center)

â€‹

#### 4ã€æ•°æ®å¯¼å…¥

```python
from torchvision import transforms, datasets 

# æ•°æ®ç»Ÿä¸€æ ¼å¼
img_height = 224
img_width = 224 

data_tranforms = transforms.Compose([
    transforms.Resize([img_height, img_width]),
    transforms.ToTensor(),
    transforms.Normalize(   # å½’ä¸€åŒ–
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225] 
    )
])

# åŠ è½½æ‰€æœ‰æ•°æ®
total_data = datasets.ImageFolder(root="./data/", transform=data_tranforms)

```

#### 5ã€æ•°æ®åˆ’åˆ†

```python
# å¤§å° 8 : 2
train_size = int(len(total_data) * 0.8)
test_size = len(total_data) - train_size 

train_data, test_data = torch.utils.data.random_split(total_data, [train_size, test_size])

```

#### 6ã€åŠ¨æ€åŠ è½½æ•°æ®

```python
batch_size = 64

train_dl = torch.utils.data.DataLoader(
    train_data,
    batch_size=batch_size,
    shuffle=True
)

test_dl = torch.utils.data.DataLoader(
    test_data,
    batch_size=batch_size,
    shuffle=False
)

```

```python
# æŸ¥çœ‹æ•°æ®ç»´åº¦
for data, labels in train_dl:
    print("data shape[N, C, H, W]: ", data.shape)
    print("labels: ", labels)
    break

```

```
data shape[N, C, H, W]:  torch.Size([64, 3, 224, 224])
labels:  tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,
        1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,
        1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1])

```

### 2ã€æ„å»ºDenseNet121ç½‘ç»œ

```python
import torch.nn.functional as F

# å®ç°DenseBlockä¸­çš„éƒ¨ä»¶ï¼šDenseLayer
'''  
1ã€BN + ReLU: å¤„ç†éƒ¨åˆ†ï¼Œé¦–å…ˆè¿›è¡Œå½’ä¸€åŒ–ï¼Œç„¶ååœ¨ç”¨æ¿€æ´»å‡½æ•°ReLU
2ã€Bottlenck Layerï¼šç§°ä¸ºç“¶é¢ˆå±‚ï¼Œè¿™ä¸ªå±‚åœ¨yolov5ä¸­å¸¸ç”¨ï¼Œä½†æ˜¯yolov5ä¸­ä¸»è¦ç”¨äºç‰¹å¾æå–+ç»´åº¦é™ç»´ï¼Œè¿™é‡Œé‡‡ç”¨1 * 1å·ç§¯æ ¸ + 3 * 3çš„å·ç§¯æ ¸è¿›è¡Œå·ç§¯æ“ä½œï¼Œç›®çš„ï¼šå‡å°‘è¾“å…¥è¾“å…¥ç‰¹å¾ç»´åº¦
3ã€BN + ReLUï¼šå¯¹ ç“¶é¢ˆå±‚ æ•°æ®è¿›è¡Œå½’ä¸€åŒ–ï¼ŒReLUæ¿€æ´»å‡½æ•°ï¼Œå½’ä¸€åŒ–å¯ä»¥ç¡®ä¿æ¢¯åº¦ä¸‹é™çš„æ—¶å€™è¾ƒä¸ºå¹³ç¨³
4ã€3 * 3 ç”Ÿæˆæ–°çš„ç‰¹å¾å›¾
'''
class _DenseLayer(nn.Sequential):
    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):
        '''  
        num_input_features: è¾“å…¥ç‰¹å¾æ•°ï¼Œä¹Ÿå°±æ˜¯é€šé“æ•°ï¼Œåœ¨DenseNetä¸­ï¼Œæ¯ä¸€å±‚éƒ½ä¼šæ¥å—ä¹‹å‰å±‚çš„è¾“å‡ºä½œä¸ºè¾“å…¥ï¼Œæ•…ï¼Œè¿™ä¸ªæ•°å€¼é€šå¸¸ä¼šéšç€ç½‘ç»œæ·±åº¦å¢åŠ è€Œå¢åŠ 
        growth_rate: å¢é•¿ç‡ï¼Œè¿™ä¸ªæ˜¯ DenseNetçš„æ ¸å¿ƒæ¦‚å¿µï¼Œå†³å®šäº†æ¯ä¸€å±‚ä¸ºå…¨å±€çŠ¶æ€è´¡çŒ®çš„ç‰¹å¾æ•°é‡ï¼Œä»–çš„ç”¨å¤„ä¸»è¦åœ¨äºå†³å®šäº†ä¸­é—´ç“¶é¢ˆå±‚çš„è¾“å‡ºé€šé“ï¼Œéœ€è¦ç»“åˆä»£ç å»ç ”ç©¶
        bn_size: ç“¶é¢ˆå±‚ä¸­è¾“å‡ºé€šé“å¤§å°ï¼Œå«ä¹‰ï¼šåœ¨ä½¿ç”¨1 * 1å·ç§¯æ ¸å»æå–ç‰¹å¾æ•°æ—¶ï¼Œç›®æ ‡é€šé“éœ€è¦æ‰©å±•åˆ°growth_rateçš„å¤šå°‘å€å€æ•°ï¼Œ bn_size * growth_rate(è¾“å‡ºç»´åº¦)
        drop_rate: ä½¿ç”¨Dropoutçš„å‚æ•°
        '''
        super(_DenseLayer, self).__init__()
        self.add_module("norm1", nn.BatchNorm2d(num_input_features))
        self.add_module("relu1", nn.ReLU(inplace=True))
        # è¾“å‡ºç»´åº¦ï¼š bn_size * growth_rate, 1 * 1å·ç§¯æ ¸ï¼Œæ­¥ä¼ä¸º1ï¼Œåªèµ·åˆ°ç‰¹å¾æå–ä½œç”¨
        self.add_module("conv1", nn.Conv2d(num_input_features, bn_size * growth_rate, stride=1, kernel_size=1, bias=False))
        
        self.add_module("norm2", nn.BatchNorm2d(bn_size * growth_rate))
        self.add_module("relu2", nn.ReLU(inplace=True))
        # è¾“å‡ºé€šé“ï¼šgrowth_rate, ç»´åº¦è®¡ç®—ï¼šä¸å˜
        self.add_module("conv2", nn.Conv2d(bn_size * growth_rate, growth_rate, stride=1, kernel_size=3, padding=1, bias=False))
        
        self.drop_rate = drop_rate
        
    def forward(self, x):
        new_features = super(_DenseLayer, self).forward(x)  # ä¼ æ’­
        if self.drop_rate > 0:
            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)  # self.training ç»§æ‰¿nn.Sequentialï¼Œæ˜¯å¦è®­ç»ƒæ¨¡å¼
        # æ¨¡å‹èåˆï¼Œå³ï¼Œç‰¹å¾é€šé“èåˆï¼Œå½¢æˆæ–°çš„ç‰¹å¾å›¾
        return torch.cat([x, new_features], dim=1)  # (N, C, H, W)  # å³ C1 + C2ï¼Œé€šé“ä¸Šèåˆ
    
'''  
DenseNetç½‘ç»œæ ¸å¿ƒç”±DenseBlockæ¨¡å—ç»„æˆï¼ŒDenseBlockç½‘ç»œç”±DenseLayerç»„æˆï¼Œä» DenseLayer å¯ä»¥çœ‹å‡ºï¼ŒDenseBlockæ˜¯
    å¯†é›†è¿æ¥ï¼Œæ¯ä¸€å±‚çš„è¾“å…¥ä¸ä»…åŒ…å«å‰ä¸€å±‚çš„è¾“å‡ºï¼Œè¿˜åŒ…å«ç½‘ç»œä¸­æ‰€æœ‰ä¹‹å‰å±‚çš„è¾“å‡º
'''
# æ„å»ºDenseBlockæ¨¡å—, é€šè¿‡ä¸Šå›¾
class _DenseBlock(nn.Sequential):
    # num_layers å‡ å±‚DenseLayeræ¨¡å—
    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):
        super(_DenseBlock, self).__init__()
        for i in range(num_layers):
            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)
            self.add_module("denselayer%d" % (i + 1), layer)
    
 
 
 # Transitionå±‚ï¼Œç”¨äºç»´åº¦å‹ç¼©
 # ç»„æˆï¼šä¸€ä¸ªå·ç§¯å±‚ + ä¸€ä¸ªæ± åŒ–å±‚
class _Transition(nn.Sequential):
    def __init__(self, num_init_features, num_out_features):
        super(_Transition, self).__init__()
        self.add_module("norm", nn.BatchNorm2d(num_init_features))
        self.add_module("relu", nn.ReLU(inplace=True))
        self.add_module("conv", nn.Conv2d(num_init_features, num_out_features, kernel_size=1, stride=1, bias=False))
        # é™ç»´
        self.add_module("pool", nn.AvgPool2d(2, stride=2))

         
# æ­å»ºDenseNetç½‘ç»œ
class DenseNet(nn.Module):
    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16), num_init_features=64, bn_size=4, 
                 compression_rate=0.5, drop_rate=0.5, num_classes=1000):
        '''  
        growth_rateã€num_init_featuresã€num_init_featuresã€drop_rate å’Œdenselayerä¸€æ ·
        block_config : å‚æ•°åœ¨ DenseNet æ¶æ„ä¸­ç”¨äºæŒ‡å®šæ¯ä¸ª Dense Block ä¸­åŒ…å«çš„å±‚æ•°, å¦‚ï¼š
                DenseNet-121: block_config=(6, 12, 24, 16) è¡¨ç¤ºç¬¬ä¸€ä¸ª Dense Block åŒ…å« 6 å±‚ï¼Œç¬¬äºŒä¸ªåŒ…å« 12 å±‚ï¼Œç¬¬ä¸‰ä¸ªåŒ…å« 24 å±‚ï¼Œç¬¬å››ä¸ªåŒ…å« 16 å±‚ã€‚
                DenseNet-169: block_config=(6, 12, 32, 32)
                DenseNet-201: block_config=(6, 12, 48, 32)
                DenseNet-264: block_config=(6, 12, 64, 48)
        compression_rate: å‹ç¼©ç»´åº¦, DenseNet ä¸­ç”¨äº Transition Layerï¼ˆè¿‡æ¸¡å±‚ï¼‰çš„ä¸€ä¸ªé‡è¦å‚æ•°ï¼Œå®ƒæ§åˆ¶äº†ä»ä¸€ä¸ª Dense Block åˆ°ä¸‹ä¸€ä¸ª Dense Block ä¹‹é—´ç‰¹å¾ç»´åº¦çš„å‹ç¼©ç¨‹åº¦
        '''
        super(DenseNet, self).__init__()
        # ç¬¬ä¸€å±‚å·ç§¯
        # OrderedDictï¼Œè®©æ¨¡å‹å±‚æœ‰åºæ’åˆ—
        self.features = nn.Sequential(OrderedDict([
            # è¾“å‡ºç»´åº¦ï¼š((w - k + 2 * p) / s) + 1
            ("conv0", nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),
            ("norm0", nn.BatchNorm2d(num_init_features)),
            ("relu0", nn.ReLU(inplace=True)),
            ("pool0", nn.MaxPool2d(3, stride=2, padding=1))  # é™ç»´
        ]))
        
        # æ­å»ºDenseBlockå±‚
        num_features = num_init_features
        # num_layers: å±‚æ•°
        for i, num_layers in enumerate(block_config):
            block = _DenseBlock(num_layers, num_features, bn_size, growth_rate, drop_rate)
            # nn.Module ä¸­featureså°è£…äº†nn.Sequential
            self.features.add_module("denseblock%d" % (i + 1), block)
            '''  
            # è¿™ä¸ªè®¡ç®—åæ˜ äº† DenseNet ä¸­çš„ä¸€ä¸ªå…³é”®ç‰¹æ€§ï¼šæ¯ä¸€å±‚è¾“å‡ºçš„ç‰¹å¾å›¾ï¼ˆå³æ–°å¢åŠ çš„é€šé“æ•°ï¼‰ç”± growth_rate å†³å®šï¼Œ
            # å¹¶ä¸”è¿™äº›æ–°ç”Ÿæˆçš„ç‰¹å¾å›¾ä¼šè¢«ä¼ é€’ç»™è¯¥ Dense Block ä¸­çš„æ‰€æœ‰åç»­å±‚ä»¥åŠä¸‹ä¸€ä¸ª Dense Blockã€‚
            '''
            num_features += num_layers * growth_rate  # å åŠ ï¼Œæ¯ä¸€æ¬¡å åŠ 
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨Transitionå±‚
            if i != len(block_config) - 1:
                transition = _Transition(num_features, int(num_features*compression_rate)) # compression_rate ä½œç”¨
                self.features.add_module("transition%d" % (i + 1), transition)
                num_features = int(num_features*compression_rate)  # æ›´æ–°ç»´åº¦
        
        
        # æœ€åä¸€å±‚
        self.features.add_module("norm5", nn.BatchNorm2d(num_features))
        self.features.add_module("relu5", nn.ReLU(inplace=True))
        
        # åˆ†ç±»å±‚         
        self.classifier = nn.Linear(num_features, num_classes)
        
        # params initialization         
        for m in self.modules():             
            if isinstance(m, nn.Conv2d):         
                '''
                å¦‚æœå½“å‰æ¨¡å—æ˜¯ä¸€ä¸ªäºŒç»´å·ç§¯å±‚ (nn.Conv2d)ï¼Œé‚£ä¹ˆå®ƒçš„æƒé‡ (m.weight) å°†é€šè¿‡ Kaiming æ­£æ€åˆ†å¸ƒ (kaiming_normal_) è¿›è¡Œåˆå§‹åŒ–ã€‚
                è¿™ç§åˆå§‹åŒ–æ–¹å¼ç‰¹åˆ«é€‚åˆä¸ReLUæ¿€æ´»å‡½æ•°ä¸€èµ·ä½¿ç”¨ï¼Œæœ‰åŠ©äºç¼“è§£æ·±åº¦ç½‘ç»œä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä¿ƒè¿›æœ‰æ•ˆçš„è®­ç»ƒã€‚  
                '''       
                nn.init.kaiming_normal_(m.weight)             
            elif isinstance(m, nn.BatchNorm2d):      
                '''  
                å¯¹äºäºŒç»´æ‰¹å½’ä¸€åŒ–å±‚ (nn.BatchNorm2d)ï¼Œåç½®é¡¹ (m.bias) è¢«åˆå§‹åŒ–ä¸º0ï¼Œè€Œå°ºåº¦å› å­ (m.weight) è¢«åˆå§‹åŒ–ä¸º1ã€‚
                è¿™æ„å‘³ç€åœ¨æ²¡æœ‰æ•°æ®ç»è¿‡çš„æƒ…å†µä¸‹ï¼Œæ‰¹å½’ä¸€åŒ–å±‚ä¸ä¼šå¯¹è¾“å…¥è¿›è¡Œé¢å¤–çš„ç¼©æ”¾æˆ–åç§»ï¼Œä¿æŒè¾“å…¥ä¸å˜ã€‚
                '''           
                nn.init.constant_(m.bias, 0)                 
                nn.init.constant_(m.weight, 1)             
            elif isinstance(m, nn.Linear):        
                '''  
                å¯¹äºå…¨è¿æ¥å±‚ (nn.Linear)ï¼Œåªå¯¹å…¶åç½®é¡¹ (m.bias) è¿›è¡Œäº†åˆå§‹åŒ–ï¼Œè®¾ç½®ä¸º0'''         
                nn.init.constant_(m.bias, 0)
                
    def forward(self, x):
        features = self.features(x)
        out = F.avg_pool2d(features, 7, stride=1).view(x.size(0), -1)
        out = self.classifier(out)
        return out

model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 12, 16))

model.to(device)

```

```
DenseNet(
  (features): Sequential(
    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu0): ReLU(inplace=True)
    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (denseblock1): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition1): _Transition(
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock2): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition2): _Transition(
      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock3): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition3): _Transition(
      (norm): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock4): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (norm5): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu5): ReLU(inplace=True)
  )
  (classifier): Linear(in_features=832, out_features=1000, bias=True)
)

```

### 3ã€æ¨¡å‹è®­ç»ƒ

#### 1ã€æ„å»ºè®­ç»ƒé›†

```python
def train(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset)
    batch_size = len(dataloader)
    
    train_acc, train_loss = 0, 0 
    
    for X, y in dataloader:
        X, y = X.to(device), y.to(device)
        
        # è®­ç»ƒ
        pred = model(X)
        loss = loss_fn(pred, y)
        
        # æ¢¯åº¦ä¸‹é™æ³•
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # è®°å½•
        train_loss += loss.item()
        train_acc += (pred.argmax(1) == y).type(torch.float).sum().item()
        
    train_acc /= size
    train_loss /= batch_size
    
    return train_acc, train_loss

```

#### 2ã€æ„å»ºæµ‹è¯•é›†

```python
def test(dataloader, model, loss_fn):
    size = len(dataloader.dataset)
    batch_size = len(dataloader)
    
    test_acc, test_loss = 0, 0 
    
    with torch.no_grad():
        for X, y in dataloader:
            X, y = X.to(device), y.to(device)
        
            pred = model(X)
            loss = loss_fn(pred, y)
        
            test_loss += loss.item()
            test_acc += (pred.argmax(1) == y).type(torch.float).sum().item()
        
    test_acc /= size
    test_loss /= batch_size
    
    return test_acc, test_loss

```

#### 3ã€è®¾ç½®è¶…å‚æ•°

```python
loss_fn = nn.CrossEntropyLoss()  # æŸå¤±å‡½æ•°     
learn_lr = 1e-4             # è¶…å‚æ•°
optimizer = torch.optim.Adam(model.parameters(), lr=learn_lr)   # ä¼˜åŒ–å™¨

```

### 4ã€æ¨¡å‹è®­ç»ƒ

é€šè¿‡å®éªŒå‘ç°ï¼Œè¿˜æ˜¯è®¾ç½®20è½®æ¬¡é™„ä»¶æœ€å¥½

```python
import copy

train_acc = []
train_loss = []
test_acc = []
test_loss = []

epoches = 20

best_acc = 0    # è®¾ç½®ä¸€ä¸ªæœ€ä½³å‡†ç¡®ç‡ï¼Œä½œä¸ºæœ€ä½³æ¨¡å‹çš„åˆ¤åˆ«æŒ‡æ ‡

for i in range(epoches):
    model.train()
    epoch_train_acc, epoch_train_loss = train(train_dl, model, loss_fn, optimizer)
    
    model.eval()
    epoch_test_acc, epoch_test_loss = test(test_dl, model, loss_fn)

     # ä¿å­˜æœ€ä½³æ¨¡å‹åˆ° best_model     
    if epoch_test_acc > best_acc:         
        best_acc   = epoch_test_acc         
        best_model = copy.deepcopy(model)
    
    train_acc.append(epoch_train_acc)
    train_loss.append(epoch_train_loss)
    test_acc.append(epoch_test_acc)
    test_loss.append(epoch_test_loss)

    # è·å–å½“å‰çš„å­¦ä¹ ç‡     
    lr = optimizer.state_dict()['param_groups'][0]['lr']
    
    # è¾“å‡º
    template = ('Epoch:{:2d}, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%, Test_loss:{:.3f}')
    print(template.format(i + 1, epoch_train_acc*100, epoch_train_loss, epoch_test_acc*100, epoch_test_loss))

PATH = './best_model.pth'  # ä¿å­˜çš„å‚æ•°æ–‡ä»¶å 
torch.save(best_model.state_dict(), PATH)

print("Done")

```

```
Epoch: 1, Train_acc:79.3%, Train_loss:1.948, Test_acc:84.6%, Test_loss:1.079
Epoch: 2, Train_acc:85.3%, Train_loss:0.395, Test_acc:85.2%, Test_loss:0.721
Epoch: 3, Train_acc:87.3%, Train_loss:0.318, Test_acc:86.5%, Test_loss:0.526
Epoch: 4, Train_acc:89.0%, Train_loss:0.277, Test_acc:86.6%, Test_loss:0.494
Epoch: 5, Train_acc:89.0%, Train_loss:0.266, Test_acc:87.9%, Test_loss:0.400
Epoch: 6, Train_acc:89.6%, Train_loss:0.252, Test_acc:84.6%, Test_loss:0.524
Epoch: 7, Train_acc:90.3%, Train_loss:0.239, Test_acc:85.5%, Test_loss:0.445
Epoch: 8, Train_acc:90.2%, Train_loss:0.235, Test_acc:87.6%, Test_loss:0.359
Epoch: 9, Train_acc:90.0%, Train_loss:0.235, Test_acc:89.3%, Test_loss:0.298
Epoch:10, Train_acc:91.0%, Train_loss:0.220, Test_acc:89.5%, Test_loss:0.307
Epoch:11, Train_acc:90.8%, Train_loss:0.222, Test_acc:88.3%, Test_loss:0.316
Epoch:12, Train_acc:91.4%, Train_loss:0.210, Test_acc:83.3%, Test_loss:0.516
Epoch:13, Train_acc:91.5%, Train_loss:0.208, Test_acc:91.3%, Test_loss:0.247
Epoch:14, Train_acc:91.5%, Train_loss:0.206, Test_acc:90.1%, Test_loss:0.269
Epoch:15, Train_acc:92.0%, Train_loss:0.199, Test_acc:91.1%, Test_loss:0.242
Epoch:16, Train_acc:92.1%, Train_loss:0.194, Test_acc:89.4%, Test_loss:0.285
Epoch:17, Train_acc:92.4%, Train_loss:0.193, Test_acc:91.0%, Test_loss:0.229
Epoch:18, Train_acc:92.4%, Train_loss:0.188, Test_acc:88.0%, Test_loss:0.317
Epoch:19, Train_acc:92.7%, Train_loss:0.182, Test_acc:89.2%, Test_loss:0.285
Epoch:20, Train_acc:92.6%, Train_loss:0.182, Test_acc:78.5%, Test_loss:0.728
Done

```

### 5ã€ç»“æœå¯è§†åŒ–

```python
import matplotlib.pyplot as plt
#éšè—è­¦å‘Š
import warnings
warnings.filterwarnings("ignore")               #å¿½ç•¥è­¦å‘Šä¿¡æ¯

epochs_range = range(epoches)

plt.figure(figsize=(12, 3))
plt.subplot(1, 2, 1)

plt.plot(epochs_range, train_acc, label='Training Accuracy')
plt.plot(epochs_range, test_acc, label='Test Accuracy')
plt.legend(loc='lower right')
plt.title('Training Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, train_loss, label='Training Loss')
plt.plot(epochs_range, test_loss, label='Test Loss')
plt.legend(loc='upper right')
plt.title('Training= Loss')
plt.show()

```

â€‹
  
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/0f433602e6034b85b2d7e68912abc034.png#pic_center)

â€‹

åœ¨20è½®æµ‹è¯•é›†å‡†ç¡®ç‡å˜åŒ–æ¯”è¾ƒå¤§ï¼Œä»è·‘çš„å‡ æ¬¡å®éªŒæ¥çœ‹ï¼Œè¿™æ¬¡æ˜¯å¶ç„¶äº‹ä»¶ï¼Œæµ‹è¯•é›†æŸå¤±ç‡åé¢ä¸€ç›´ç¨³å®šåœ¨0.3é™„ä»¶ï¼Œæµ‹è¯•å‡†ç¡®ç‡ä¸€ç›´åœ¨0.8ã€0.89ã€0.90é™„ä»¶å¾˜å¾Š

### 6ã€æ¨¡å‹è¯„ä¼°

```python
# å°†å‚æ•°åŠ è½½åˆ°modelå½“ä¸­ 
best_model.load_state_dict(torch.load(PATH, map_location=device)) 
epoch_test_acc, epoch_test_loss = test(test_dl, best_model, loss_fn)

print(epoch_test_acc, epoch_test_loss)

```

```
0.9134651249533756 0.24670581874393283

```