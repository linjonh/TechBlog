---
layout: post
title: "更新完LPZero-Language-Model-Zero-cost-Proxy-Search-from-Zero"
date: 2025-03-07 09:55:49 +0800
description: "神经架构搜索 (NAS) 有助于自动执行有效的神经网络搜索，同时需要大量的计算资源，尤其是对于语言模型。然而，现有的 ZC 代理严重依赖于深入的专家知识和重复的反复试验成本。它旨在自动设计高效的语言模型 ZC 代理，并实现更高的排名一致性。具体来说，我们首先将现有的 ZC 代理设计整合到一个统一的框架中作为搜索空间，然后应用进化算法启发式地识别语言模型的新代理候选者。该策略旨在预先消除没有希望的代理，从而降低代理降级的风险。值得注意的是，我们的方法实现的性能排名一致性显著超过了当前代理的一致性。"
keywords: "（更新完）LPZero: Language Model Zero-cost Proxy Search from Zero"
categories: ['未分类']
tags: ['语言模型', '自然语言处理', '免训练', '人工智能', 'Nas']
artid: "146087508"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146087508
    alt: "更新完LPZero-Language-Model-Zero-cost-Proxy-Search-from-Zero"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146087508
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146087508
cover: https://bing.ee123.net/img/rand?artid=146087508
image: https://bing.ee123.net/img/rand?artid=146087508
img: https://bing.ee123.net/img/rand?artid=146087508
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     （更新完）LPZero: Language Model Zero-cost Proxy Search from Zero
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
    </h2>
    <h2>
     <img alt="" height="591" src="https://i-blog.csdnimg.cn/direct/a789dd63219040a9b44bd66203da555e.png" width="2084"/>
    </h2>
    <h2>
     <a href="https://github.com/pprp/LPZero" title="LPZero代码">
      LPZero代码
     </a>
    </h2>
    <h2>
     摘要
    </h2>
    <p>
     神经架构搜索 (NAS) 有助于自动执行有效的神经网络搜索，同时需要大量的计算资源，尤其是对于语言模型。零样本 NAS 利用零成本 (ZC) 代理来估计模型性能，从而显着降低计算需求。然而，现有的 ZC 代理严重依赖于深入的专家知识和重复的反复试验成本。此外，大多数现有的 ZC 代理都无法超越简单基线（参数数量）的性能。为了应对这些挑战，我们引入了一个称为 LPZero（语言模型零成本代理搜索）的新型框架。它旨在自动设计高效的语言模型 ZC 代理，并实现更高的排名一致性。具体来说，我们首先将现有的 ZC 代理设计整合到一个统一的框架中作为搜索空间，然后应用进化算法启发式地识别语言模型的新代理候选者。为了提高搜索过程的效率，我们引入了预测剪枝策略 (PPS)。该策略旨在预先消除没有希望的代理，从而降低代理降级的风险。在 FlexiBERT 和 GPT-2 搜索空间上进行的大量实验证明了我们算法的有效性。值得注意的是，我们的方法实现的性能排名一致性显著超过了当前代理的一致性。
    </p>
    <h2>
     1 Introduction
    </h2>
    <p>
     Zero-shot NAS 预测神经网络架构的性能，而无需实际训练，使用随机初始化的模型。这种方法能够快速高效地估计架构性能，从而消除训练过程中通常消耗的时间和资源。此外，我们观察到大多数代理无法超越基于参数数量的基准性能，如图 1 所示。这个限制提出了一个基本但至关重要的问题：如何高效、自动地为语言模型设计新的代理？
    </p>
    <p class="img-center">
     <img alt="" height="505" src="https://i-blog.csdnimg.cn/direct/e26bf856de7c42df8c93b244c803ed16.png" width="811"/>
    </p>
    <p>
     为了解答这个问题，我们将其分解为两个步骤：
    </p>
    <p>
     （1）
     <strong>
      设计一个统一的搜索空间来包含现有的 ZC 代理；
     </strong>
    </p>
    <p>
     对于第一个步骤，我们重新审视现有的 ZC 代理，如表 1 所示，设计了一个
     <strong>
      综合性的搜索空间，涵盖了当前的 ZC 代理
     </strong>
     。具体而言，这些代理根据输入类型分为六类：激活（A）、Jacobs（J）、梯度（G）、头（H）、权重（W）和 Softmax（S），如
     <strong>
      图 2
     </strong>
     所示。在这个统一的框架中，我们从这些类别中选择两种输入，记为 θ。每个输入通过 n 种一元运算 f(·) 进行转换，结果通过二元运算 g(·) 进行组合。这个过程生成了一个候选代理 φ(f, g, θ)，并进入我们的搜索空间。
     <strong>
      更多细节请参见附录 A。
     </strong>
    </p>
    <p>
     （2）
     <strong>
      使用进化算法发现新的代理。
     </strong>
    </p>
    <p>
     对于第二个步骤，我们提出了一个新颖的 LPZero 框架，代表了从零开始的语言模型代理搜索。正如
     <strong>
      图 3
     </strong>
     所示，我们最初选择 p 个候选代理来建立初始种群，并评估它们在 FlexiBERT 搜索空间中的排名一致性。通过锦标赛选择，我们识别出两个有前景的父代理（φn,m）。接下来，我们进行交叉和变异操作，生成后代代理 φq。为了评估其排名一致性 Spearman ρq，我们使用该代理对每个架构 Ωi 进行评分，并将结果与各自的真实值 gti（例如，平均准确率）进行比较。鉴于搜索空间的稀疏性，我们倡导采用预测修剪策略（PPS），旨在消除无效的代理，从而提高搜索效率。
    </p>
    <p class="img-center">
     <img alt="" height="372" src="https://i-blog.csdnimg.cn/direct/b63fd5d3c193412d8d6506cd96db1ff5.png" width="986"/>
    </p>
    <p class="img-center">
     <img alt="" height="111" src="https://i-blog.csdnimg.cn/direct/25749b2d69f74066bc1e9f514eb57c43.png" width="532"/>
    </p>
    <p class="img-center">
     <img alt="" height="160" src="https://i-blog.csdnimg.cn/direct/68b2df90ae484dab955cb3c75b5c5719.png" width="527"/>
    </p>
    <ul>
    </ul>
    <p>
     <span style="background-color:#efedf6">
      我们的主要贡献如下：
     </span>
    </p>
    <ul>
     <li>
      <span style="background-color:#efedf6">
       我们设计了一个全面且高质量的搜索空间，涵盖了大部分现有的适用于语言模型的 ZC 代理。
      </span>
     </li>
     <li>
      <span style="background-color:#efedf6">
       我们引入了从零开始的语言模型代理搜索（LPZero）框架，并结合预测修剪策略（PPS），防止代理降级，从而提高搜索效率。
      </span>
     </li>
     <li>
      <span style="background-color:#efedf6">
       在 FlexiBERT 和 GPT-2 上进行的实验验证了我们 LPZero 框架中识别的代理的优越性，表明我们提出的方法具有有效性。
      </span>
     </li>
    </ul>
    <hr/>
    <h2>
     2 Related Work
    </h2>
    <p>
     <strong>
      Zero-shot NAS
     </strong>
    </p>
    <p>
     作为一种评估候选神经网络架构准确性并且无需进行大量训练的低成本策略，已经获得了越来越多的关注。与传统的One-shot NAS方法相比，这种方法提供了更高效的计算替代方案。Zero-shot NAS的核心是其准确度排名代理，这对其有效性至关重要。尽管大多数现有的代理已经为计算机视觉（CV）任务开发，但在自然语言处理（NLP）任务中，相关的研究探索相对较少。
     <br/>
     NWOT（Mellor et al., 2021）利用不同图像的局部Jacobian值，构建了一种基于输入Jacobian相关性的模型排名指标。类似地，ZenNAS（Lin et al., 2021）通过使用输入图像的梯度范数作为排名标准来评估候选架构。此外，Zero-cost NAS（Abdelfattah et al., 2021）受到“最佳大脑损伤”（Optimal Brain Damage）原则（LeCun et al., 1989）的启发，引入了基于剪枝的度量作为零成本代理。这些度量包括GradNorm（Abdelfattah et al., 2021）、Plain（Abdelfattah et al., 2021）、SNIP（Lee et al., 2019）、GraSP（Wang et al., 2020）、Fisher（Turner et al., 2020）和Synflow（Tanaka et al., 2020）。这些代理评估网络参数的重要性，并聚合层级值来估算整体性能。
    </p>
    <p>
     <strong>
      Zero-cost Proxies for Transformer
     </strong>
    </p>
    <p>
     最近的研究（Serianni和Kalita, 2023）重新激发了零成本代理在基于Transformer的网络中的应用，这标志着该领域的重要进展。
     <strong>
      LiteTransformerSearch
     </strong>
     （Javaheripi et al., 2022）观察到，零成本代理在计算机视觉任务中表现出色，但在应用于自然语言处理时，并未超越基准方法，即解码器的参数数量。Serianni和Kalita（2023）通过
     <strong>
      FlexiBERT基准
     </strong>
     重新唤起了零成本代理在RNN和BERT-based Transformer模型中的重要性。研究提出了一系列代理，如
     <strong>
      突触多样性、突触显著性、激活距离、Jacobian余弦、注意力置信度和头部重要性
     </strong>
     ，强调了它们在无需大量训练的情况下优化架构搜索过程的潜力。
    </p>
    <p>
     <strong>
      Automatic Search for ZC Proxies
     </strong>
    </p>
    <p>
     一些研究探索了如何
     <strong>
      自动搜索零成本代理
     </strong>
     ，特别是EZNAS（Akhauri et al., 2022）和EMQ（Dong et al., 2023）。EZNAS为卷积网络引入了一个专门的搜索空间，并在多个基准测试中取得了令人称赞的表现（Ying et al., 2019；Dong和Yang, 2020）。然而，当将其应用于基于Transformer的网络时，其有效性显著下降。另一方面，EMQ（Dong et al., 2023）开发了一个专门针对混合精度量化代理的搜索空间，但它并未优化用于Transformer-based网络。相比之下，我们的LPZero框架专门为语言模型设计，特别是为Transformer架构优化，展示了更优越且更有前景的表现。
    </p>
    <p>
     <strong>
      总结：本文提出的LPZero框架在设计零成本代理并自动化搜索过程中展示了卓越的效果，尤其是在Transformer架构上，较现有的方法表现出更强的潜力和优势。
     </strong>
    </p>
    <hr/>
    <h2>
     3 Methodology
    </h2>
    <p>
     在本节中，我们设计了一个搜索空间，并详细介绍了LPZero的进化框架及其分析。
    </p>
    <h3>
     3.1 LPZero Search Space Design
    </h3>
    <p>
     大多数 AutoML 方法的搜索空间（如 Real 等人，2020；Liu 等人，2019）通常是为特定目的而专门设计的，并不适用于代理（proxy）搜索。先前的一些自动损失搜索方法（Li 等人，2021b,a；Gu 等人，2022）使用网络输出 y和真实标签 y标量）作为输入，这相对容易处理。然而，这些方法的搜索空间本身较为初级，和我们的最相似。但对于 ZC（零成本）代理搜索问题，我们需要更多可以处理标量、向量和矩阵输入的运算，从而可能导致形状不匹配的问题。
    </p>
    <p class="img-center">
     <img alt="" height="140" src="https://i-blog.csdnimg.cn/direct/bacaa9717b0145b4993e83a44cd54963.png" width="507"/>
    </p>
    <p class="img-center">
     <img alt="" height="81" src="https://i-blog.csdnimg.cn/direct/b2339f08019f4b6082b18bc9bf9f2f19.png" width="498"/>
    </p>
    <ul>
    </ul>
    <p class="img-center">
     <img alt="" height="744" src="https://i-blog.csdnimg.cn/direct/4fb0ff5708304c5b98f32b83b23c4a8e.png" width="891"/>
    </p>
    <p>
     值得注意的是，f20和 f21是两个特殊的一元运算：
    </p>
    <ul>
     <li>
      f20 表示“直通”，即不对输入进行任何修改，直接返回输入；
     </li>
     <li>
      f21表示“剪枝”操作，它会移除该分支，相当于返回空。
     </li>
    </ul>
    <h3>
     3.2 Search Algorithm
    </h3>
    <p>
     受 AutoML (He et al., 2021; Li et al., 2019) 的启发，进化算法成为我们搜索算法设计的核心机制。进化算法属于遗传算法的一个分支，它通过对种群中的个体进行生成、评估和选择，来模拟自然选择的过程，以解决优化问题。图 3 展示了我们 LPZero 框架的搜索流程。
    </p>
    <p>
     在初始化时，我们从搜索空间中
     <strong>
      均匀采样
     </strong>
     p个零成本（ZC）代理来构建初始种群。然后，我们在搜索空间上测量这些代理的排名相关性，以衡量每个代理的预测能力。接下来，在每次迭代中，我们采用锦标赛选择（tournament selection）从种群中选出占比 R的代理（默认 R=10%）作为潜在的候选者，然后从中随机选出两个个体 ϕn,ϕm 作为“父代理”（parents）。随后，这些父代理将以概率 Cr 和 Mr 分别执行
     <strong>
      交叉
     </strong>
     和
     <strong>
      变异
     </strong>
     操作，产生后代。
    </p>
    <p>
     为了验证后代的有效性，我们从搜索空间中采样 S个候选网络结构，并计算它们在“真实得分”和“代理得分”之间的排名相关性。由于搜索空间非常稀疏，包含大量无效或缺乏潜力的 ZC 代理，我们提出了
     <strong>
      Early-Stopping 策略
     </strong>
     来过滤掉这些候选代理。
    </p>
    <h4>
     Crossover and Mutation（交叉与变异）
    </h4>
    <p>
     每个算法表达式（AE）由
     <strong>
      两个分支
     </strong>
     和
     <strong>
      一个聚合节点
     </strong>
     组成。这些分支代表代理架构中的各个组成部分或操作，而聚合节点则将这两个分支的输出结合起来，形成最终的代理得分。正如图 4 所示，我们展示了交叉和变异操作的示意图。
    </p>
    <ul>
     <li>
      在
      <strong>
       交叉操作
      </strong>
      中，会从两个父 AE 中交换其“遗传信息”，以生成后代。具体而言，这个过程通过交换父 AE 的某些片段，组合出新的操作及结构。
     </li>
     <li>
      与之相对，
      <strong>
       变异操作
      </strong>
      会对单个 AE 的“遗传信息”进行随机改动，从而有可能将全新的结构引入种群。
     </li>
    </ul>
    <p class="img-center">
     <img alt="" height="211" src="https://i-blog.csdnimg.cn/direct/f8b5671c953c4b4f9cbb6352fd6a7248.png" width="312"/>
    </p>
    <h4>
     Predictive-Pruning Strategy（预测式剪枝策略）
    </h4>
    <p>
     LPZero 框架中的
     <strong>
      预测式剪枝策略
     </strong>
     （Predictive-Pruning Strategy）在应对庞大且稀疏的搜索空间时发挥了关键作用。它能够迅速识别并舍弃那些无潜力或无效的零成本（ZC）代理，从而节省计算资源并加快寻找最优解的进程。
     <strong>
      通过使用附录 B 中所述的预定义标准，该策略会评估候选代理的可行性；凡是不满足指定标准的代理都会被从种群中移除，进而缩小搜索空间，让计算资源更多地集中于更有潜力的候选者。
     </strong>
     总体而言，这种策略性筛选过程提高了 LPZero 框架的效率和有效性，加快了高质量代理架构的发现。
    </p>
    <h4>
     <span style="background-color:#fbd4d0">
      Searched ZC Proxy（搜索到的零成本代理）
     </span>
    </h4>
    <p>
     本文搜索出的 ZC 代理针对的是
     <strong>
      FlexiBERT
     </strong>
     搜索空间，也就是说它适用于衡量 BERT 或类似结构的可变深度、可变宽度等多种配置。
    </p>
    <p>
     <img alt="" height="624" src="https://i-blog.csdnimg.cn/direct/8c145e067f8d47a6ac012ab2c76b0d3d.png" width="1693"/>
    </p>
    <p>
     <img alt="" height="515" src="https://i-blog.csdnimg.cn/direct/33f765edae7547129a089088afc6f8cb.png" width="599"/>
     <img alt="" height="514" src="https://i-blog.csdnimg.cn/direct/71518d5c8df243159c13a0d4df9c785a.png" width="621"/>
    </p>
    <p>
     <img alt="" height="1065" src="https://i-blog.csdnimg.cn/direct/7819e1902a2d44b5ae61fcefd7f3165f.png" width="1644"/>
    </p>
    <ul>
     <li>
      <p>
       <strong>
        <span style="background-color:#eaf4fc">
         LPZero 框架与目标
        </span>
       </strong>
      </p>
      <ul>
       <li>
        <span style="background-color:#eaf4fc">
         该框架的核心目标是找到一个零成本代理，能够最大化其与真实网络性能排名之间的 Spearman 相关系数。
        </span>
       </li>
       <li>
        <span style="background-color:#eaf4fc">
         代理 ϕ以符号化表达式的形式存在，由一元运算和二元运算组成。
        </span>
       </li>
       <li>
        <span style="background-color:#eaf4fc">
         在搜索空间中，允许使用多种基础运算（包括可能什么也不做的“直通”以及剪枝操作），使得搜索具有极高的灵活度和可扩展性。
        </span>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        <span style="background-color:#eaf4fc">
         搜索空间设计
        </span>
       </strong>
      </p>
      <ul>
       <li>
        <span style="background-color:#eaf4fc">
         输入包括 6 类特征（Activation、Jacobs、Gradients、Head、Weight、Softmax），对应不同网络内部信息。
        </span>
       </li>
       <li>
        <span style="background-color:#eaf4fc">
         一元运算 21 个，二元运算 4 个，这些运算可以被自由组合成丰富的代理表达式。
        </span>
       </li>
       <li>
        <span style="background-color:#eaf4fc">
         理论上可组合出 26,460 种潜在代理结构，搜索空间十分庞大。
        </span>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        <span style="background-color:#eaf4fc">
         进化式搜索策略：LPZero 算法
        </span>
       </strong>
      </p>
      <ul>
       <li>
        <span style="background-color:#eaf4fc">
         通过进化算法迭代搜索：在每一代中，选取优秀代理（前 P），然后随机进行交叉（crossover）和变异（mutation）来生成新代理。
        </span>
       </li>
       <li>
        <span style="background-color:#eaf4fc">
         新生成的代理如果满足有效性（PPS 验证），则被保留到种群中，否则重新生成。
        </span>
       </li>
       <li>
        <span style="background-color:#eaf4fc">
         每代都对新产生的代理进行评估并更新种群，最终迭代到给定轮次后，输出 Spearman 值最高的代理。
        </span>
       </li>
      </ul>
     </li>
    </ul>
    <h2>
     4 Experiments
    </h2>
    <p>
     在本节中，我们首先详细介绍 LPZero 的实验设置和实现细节。随后，我们展示在 FlexiBERT 和 GPT-2 搜索空间上对排名相关性的评估结果。接着，我们在这两个搜索空间中进一步考察 LPZero 的性能表现。最后，我们通过消融实验评估进化算法、预测式剪枝策略（Predictive-Pruning Strategy, PPS）以及一元运算数量和初始种群规模等因素的影响。
    </p>
    <h5>
     4.1 实现细节
    </h5>
    <p>
     <strong>
      数据集
     </strong>
    </p>
    <ul>
     <li>
      FlexiBERT 构建于 GLUE 基准上（包含多个任务），我们采用这些任务的平均性能作为衡量排名一致性的真实指标。
     </li>
     <li>
      在 FlexiBERT 搜索空间上搜索零成本代理时，我们使用 OpenWebText 数据集。
     </li>
     <li>
      对于 GPT-2 搜索空间，我们在 WikiText-103 数据集上进行实验。
     </li>
     <li>
      在进化搜索的过程中，我们只需要一小批（mini-batch）的输入（对于 BERT 使用 128，GPT-2 使用 16）来计算输入统计量。
     </li>
    </ul>
    <p>
     <strong>
      评价标准
     </strong>
    </p>
    <ul>
     <li>
      我们使用 Kendall’s τ 和 Spearman’s ρ 来衡量零成本代理的有效性，这两个值都介于 -1（负相关）到 1（正相关）之间，0 表示无相关性。它们能定量评估代理预测与实际模型性能之间的一致程度，为比较提供了依据。
     </li>
    </ul>
    <p>
     <strong>
      搜索空间
     </strong>
    </p>
    <ul>
     <li>
      我们采用两个已有的基准作为搜索空间。
      <ul>
       <li>
        FlexiBERT 基准涵盖了大量架构，具有一定挑战性（详见附录）。
       </li>
       <li>
        GPT-2 基准则来自 WikiText-103，其中包含了超过一千个不同的架构（详见附录）。
       </li>
      </ul>
     </li>
    </ul>
    <p>
     <strong>
      进化算法设置
     </strong>
    </p>
    <ul>
     <li>
      我们的进化算法配置如下：
      <ul>
       <li>
        总迭代次数 G 设置为 1000；
       </li>
       <li>
        初始种群规模 p 设置为 80；
       </li>
       <li>
        交叉（crossover）和变异（mutation）操作的概率分别为 0.5；
       </li>
       <li>
        选择压力（即比例 RRR）为 10%；
       </li>
       <li>
        使用相同的随机种子 42 以保证可复现性；
       </li>
       <li>
        <strong>
         实验在 A6000 GPU 上进行；
        </strong>
       </li>
      </ul>
     </li>
     <li>
      为了加速进化搜索，我们在搜索过程中仅对 50 个架构进行采样来评估排名一致性。完成搜索后，我们会在两个数据集上对最终找到的代理进行性能验证：
      <ul>
       <li>
        FlexiBERT 中抽取了 500 个架构
       </li>
       <li>
        GPT-2 中抽取了 200 个架构
       </li>
      </ul>
     </li>
     <li>
      <strong>
       整个进化过程耗时大约 10 个 GPU 小时。
      </strong>
     </li>
    </ul>
    <p>
     <strong>
      训练与评估
     </strong>
    </p>
    <ul>
     <li>
      我们基于公开代码实现了 FlexiBERT 和文中表 1 所示的各种代理。
     </li>
     <li>
      同时也使用了另一份开源代码实现 GPT-2 搜索空间，并从其开源仓库中收集了基准数据。
     </li>
     <li>
      为了评估排名一致性，我们会在 FlexiBERT 基准中随机抽取 500 个架构，并在 GPT-2 基准中随机抽取 200 个架构，分别进行对比分析。
     </li>
    </ul>
    <ol>
     <li>
      <p>
       <strong>
        Figure 5
       </strong>
       （左上九个散点图）：
      </p>
      <ul>
       <li>
        每个散点图展示了
        <strong>
         GLUE 分数
        </strong>
        与
        <strong>
         不同零成本代理打分
        </strong>
        之间的相关性。横轴一般是代理打分，纵轴是真实 GLUE 分数。
       </li>
       <li>
        不同颜色的点表示在搜索空间中随机采样的不同网络架构。
       </li>
       <li>
        通过散点分布和拟合线，可以大致看出各代理与真实性能之间的相关程度。
       </li>
       <li>
        最右下方的散点图是 LPZero 的结果，可以看到点更接近某条单调趋势线，说明排名相关性更高。
       </li>
      </ul>
     </li>
    </ol>
    <p>
     <img alt="" height="1466" src="https://i-blog.csdnimg.cn/direct/6ad11b0006054ca197bb4693fb77a986.png" width="1345"/>
     <strong>
      4.2 排名评估
     </strong>
    </p>
    <p>
     <strong>
      在 FlexiBERT 上的表现
     </strong>
    </p>
    <ul>
     <li>
      正如表 3 所示，我们在 500 个来自 FlexiBERT 搜索空间的架构上，对 14 个零成本代理的 Kendall’s τ 和 Spearman’s ρ 进行了评估。
     </li>
     <li>
      其中，“参数量”作为一个基线，与大多数代理相比，它也有相当的竞争力；很多代理并未能超越该基线（这在图 1 中也有展示）。
     </li>
     <li>
      我们的 LPZero 模型在排名一致性上表现出明显优势，τ 和 ρ 分别达到了较高的数值。
     </li>
     <li>
      此外，图 5 展示了 GLUE 分数与各种零成本代理（包括我们提出的 LPZero 以及其他已有的训练无关评估方法）之间的相关性。可以看出，LPZero 的排名一致性在所有对比框架中最高。
     </li>
    </ul>
    <p>
     <strong>
      在 GPT-2 上的表现
     </strong>
    </p>
    <ul>
     <li>
      正如表 4 所示，我们在 200 个来自 GPT-2 搜索空间的架构上，对 15 个零成本代理的 Kendall’s τ 和 Spearman’s ρ 进行了评估。
     </li>
     <li>
      额外的一个代理是 “Decoder.Params”，代表 GPT-2 中解码器的参数量。
     </li>
     <li>
      LPZero 在所有 ZC 代理中取得了最优表现，τ 和 ρ 分别高达 0.87 和 0.98。
     </li>
     <li>
      相比于 FlexiBERT 搜索空间，在 GPT-2 搜索空间上，排名一致性表现得更为突出。
     </li>
    </ul>
    <h5>
     4.3 消融实验
    </h5>
    <p>
     我们对以下四个因素进行了广泛的消融研究：
    </p>
    <ol>
     <li>
      进化算法本身
     </li>
     <li>
      预测式剪枝策略（PPS）
     </li>
     <li>
      初始种群规模
     </li>
     <li>
      一元运算数量
     </li>
    </ol>
    <p>
     <strong>
      (1) 进化算法的有效性
     </strong>
    </p>
    <ul>
     <li>
      如图 6 所示，在迭代次数限定为 1000、初始种群规模为 80 的条件下，进化算法的表现远超随机搜索。
     </li>
     <li>
      这表明进化算法能够在搜索过程中带来启发式的加速，大幅提高搜索效率。
     </li>
    </ul>
    <p>
     <img alt="" height="990" src="https://i-blog.csdnimg.cn/direct/99df79588b1a4868abf0ceb80e65fb90.png" width="2374"/>
    </p>
    <ol>
     <li>
      <p>
       <strong>
        Figure 6
       </strong>
       （两条或三条曲线对比图）：
      </p>
      <ul>
       <li>
        展示了在进化搜索过程中，
        <strong>
         有无 PPS
        </strong>
        （预测式剪枝策略）以及随机搜索三种不同设置下，Spearman’s ρ 随迭代次数的变化情况。
       </li>
       <li>
        横轴是迭代次数，纵轴是 Spearman’s ρ。
       </li>
       <li>
        可以看到：
        <ul>
         <li>
          <strong>
           Evolution Search w/ PPS
          </strong>
          （有 PPS）在早期迭代就能取得更高的相关系数；
         </li>
         <li>
          <strong>
           Evolution Search w/o PPS
          </strong>
          （无 PPS）曲线起步较低，后期才逐渐逼近；
         </li>
         <li>
          <strong>
           Random Search
          </strong>
          整体表现最差，随着迭代也很难达到进化搜索的水平。
         </li>
        </ul>
       </li>
      </ul>
     </li>
    </ol>
    <p>
     <strong>
      (2) 预测式剪枝策略（PPS）的有效性
     </strong>
    </p>
    <ul>
     <li>
      图 6 也展示了预测式剪枝策略（PPS）的性能表现。
     </li>
     <li>
      结果显示，在迭代少于 400 次时，PPS 不仅能获得更高的 Spearman’s ρ，而且明显优于未使用 PPS 的进化搜索方法，说明 PPS 对提高搜索效率至关重要。
     </li>
    </ul>
    <p>
     <strong>
      (3) 初始种群规模
     </strong>
    </p>
    <ul>
     <li>
      如图 7 所示，我们对比了初始种群规模分别为 80、100 和 200 时的 Spearman’s ρ。
     </li>
     <li>
      数据表明，种群规模越大，在搜索初期的 Spearman’s ρ 越高。
     </li>
    </ul>
    <p>
     <strong>
      (4) 一元运算数量
     </strong>
    </p>
    <ul>
     <li>
      表 5 展示了对一元运算数量的消融实验。
     </li>
     <li>
      结果表明，较少的一元运算（如 2 个）能够带来最高的 Spearman’s ρ（86.48%）和最高的胜率（25.61%），说明过多的一元运算可能导致代理过度复杂化，从而影响效果。
     </li>
    </ul>
    <p class="img-center">
     <img alt="" height="112" src="https://i-blog.csdnimg.cn/direct/7fd54b4e60ee4ed2bc28b5fac1ca85b0.png" width="280"/>
    </p>
    <hr/>
    <h3>
     2. 详细总结与分析
    </h3>
    <ol>
     <li>
      <p>
       <strong>
        实验设计
       </strong>
      </p>
      <ul>
       <li>
        本文在 FlexiBERT 和 GPT-2 两个搜索空间中验证了所提出的 LPZero 代理的有效性。
       </li>
       <li>
        FlexiBERT 基准源于 GLUE 任务，GPT-2 基准源于 WikiText-103，二者都涵盖了大量不同的网络结构，用于全面测试零成本代理的排名一致性。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        主要发现
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         LPZero 在排名一致性上优于大多数已有方法
        </strong>
        ：在 FlexiBERT 上明显超越基线“参数量”，并在 GPT-2 搜索空间中达到极高的相关系数（τ = 0.87, ρ = 0.98）。
       </li>
       <li>
        <strong>
         进化算法显著优于随机搜索
        </strong>
        ：通过对比可以看出，进化算法的引入能快速筛选出更优质的代理，提升搜索效率。
       </li>
       <li>
        <strong>
         预测式剪枝策略（PPS）能进一步加速并提高性能
        </strong>
        ：在早期迭代中就能淘汰大量无效或劣质的代理，避免在这些代理上浪费计算资源。
       </li>
       <li>
        <strong>
         初始种群规模与一元运算数量
        </strong>
        ：
        <ul>
         <li>
          较大的初始种群在搜索初期就能获得更好的排名相关性；
         </li>
         <li>
          但一元运算数量过多会导致代理结构过度复杂，反而降低最终的排名效果。
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        意义与价值
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         在无须完整训练的前提下评估模型优劣
        </strong>
        ：LPZero 提供了一种快速评估大规模模型（如 BERT 或 GPT-2 变体）的方法，节省大量时间和计算成本。
       </li>
       <li>
        <strong>
         可扩展性与通用性
        </strong>
        ：进化算法和预测式剪枝策略相结合，适用于各种搜索空间和代理设计，可在不同任务中推广。
       </li>
       <li>
        <strong>
         可解释性
        </strong>
        ：通过消融研究，作者展示了影响排名相关性的关键因素（如 PPS、初始种群规模和运算数量），为后续研究提供了可行的优化方向。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h2>
     5 Conclusion
    </h2>
    <p>
     在本文中，我们提出了 LPZero 框架，这是一种创新方法，用于在无需大量训练或专家干预的情况下，为语言模型发掘代理（proxy）。我们的方法包括设计一个全面的搜索空间，涵盖了广泛的现有零成本（ZC）代理。我们利用进化算法（Evolutionary Algorithm）在这一搜索空间中高效地挖掘出潜在的 ZC 代理。为了加快搜索进程，我们实施了预测式剪枝策略（Predictive-Pruning Strategy），在过程的早期阶段就剔除不太有前途的代理。为了验证我们提出的 LPZero 的有效性，我们在 FlexiBERT 和 GPT-2 搜索空间上进行了实验，以衡量所搜索到的代理的排名一致性。实验结果表明，与之前的 ZC 代理相比，我们的 LPZero 具有更强的排名能力，并在很大程度上超越了基线。我们的研究结果为今后在语言模型零成本代理方面的探索奠定了基础。
    </p>
    <h2>
     6 Limitations
    </h2>
    <p>
     本研究对专门为 Transformer 架构设计的现有零成本（ZC）代理进行了全面回顾，并将它们整合到一个统一的框架中进行评估。通过在 FlexiBERT 和 GPT-2 搜索空间中对这些 ZC 代理进行基准测试，我们使用 Kendall’s τ 和 Spearman’s ρ 来严格评估它们的排名能力。这样一来，我们得以系统地比较它们在无需大量计算资源的前提下识别有前途的语言模型架构的有效性。我们的评估主要关注语言模型的架构层面，旨在为高效且有效的神经网络设计简化搜索过程。
    </p>
    <p>
     <strong>
      然而，需要注意的是，我们的研究主要集中在语言模型的结构设计与优化
     </strong>
     ，而对诸如推理能力、逻辑分析、高级语言生成、细腻的自然语言理解以及知识的检索与整合等具体功能领域的改进则较少关注。这些对于语言模型在真实世界应用中的性能和适用性而言至关重要的组件，并未在我们的当前框架中得到直接探讨。我们认识到这些不足之处，并认为未来仍有大量机会在这些方面进行深入研究。若将零成本代理的评估范围扩展到包括这些功能性内容，那么语言模型的实用性和全面性将会显著提升，为人工智能领域中的模型开发与评估提供更为整体的方法。
    </p>
    <h2>
     7 Ethics Statement
    </h2>
    <p>
     我们的 LPZero 框架主要关注语言模型架构的技术开发，并未直接涉及伦理或社会层面的考量。我们的工作可能会促进在 NLP 领域中对 NAS（神经网络架构搜索）的应用，为在语言模型中进行经济高效的性能评估提供了一种方式。
    </p>
    <p>
     尽管我们的重点在此，但我们也认识到，本研究的应用——旨在降低计算需求并简化语言模型开发——可能会与自然语言处理领域中更广泛的伦理问题产生交集，如数据隐私、算法偏见以及潜在的误用。我们倡导在后续研究中融入伦理考量，审视训练数据来源中的偏见，并确保语言模型的负责任部署，认识到它们在社会层面可能产生的深远影响。我们同时也承认人工智能（尤其是 ChatGPT）在改进文本材料方面展现了强大的能力与潜力。
    </p>
    <hr/>
    <h2>
     Additional
    </h2>
    <h3>
     <strong>
      A Additional Related Work（论文补充文件补充了免训练指标的进展）
     </strong>
     <br/>
     B Predefined Criteria in PPS
    </h3>
    <p>
     在数学中，理解各种运算之间的关系对于 LPZero 搜索空间具有重要影响。表 6 总结了这组运算之间的关系，并根据它们的数学交互进行分类。这些关系包括：逆函数、导数、等价、特殊情况，以及当某些运算组合在一起时可能出现的冲突。通过这一概览，我们能了解哪些运算能够彼此互补或产生冲突，从而为预测式剪枝策略（PPS）提供支持。
    </p>
    <p>
     下面对
     <strong>
      PPS（Predictive-Pruning Strategy）
     </strong>
     中的预定义准则（表 6）做一个简要说明，帮助理解其在搜索空间中进行快速检查和剪枝时的作用：
    </p>
    <p>
     <img alt="" height="298" src="https://i-blog.csdnimg.cn/direct/10eb600287f446fa811f29ef9af755ac.png" width="742"/>
    </p>
    <ol>
     <li>
      <p>
       <strong>
        为什么需要这些预定义准则
       </strong>
      </p>
      <ul>
       <li>
        在搜索空间中组合不同运算时，如果组合出现了冲突或无效的情况，模型表达式就会
        <strong>
         无法计算
        </strong>
        或
        <strong>
         含义不明
        </strong>
        。
       </li>
       <li>
        PPS 会利用这些准则在
        <strong>
         搜索或变异阶段
        </strong>
        快速检测并剪除无效的运算组合，避免浪费计算资源。
       </li>
       <li>
        同时，如果检测到一对运算可以互为逆或等价，就可能简化表达式，或者直接跳过冗余的组合。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        示例
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         log⁡\loglog 与 exp⁡\expexp
        </strong>
        互为逆：如果在同一分支中连续使用 log⁡\loglog 再 exp⁡\expexp（或反之），那么运算结果等同于原值，往往没有实际意义。PPS 可将这类“自相抵消”的组合视作冗余并剪除。
       </li>
       <li>
        <strong>
         −()-() −() 与 \sqrt{}​
        </strong>
        ：如果对一个正数先取负号，再开平方，就会产生虚数或不定值。该组合在大多数实际神经网络中
        <strong>
         不合法
        </strong>
        ，因此在搜索时可直接过滤掉。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        对搜索效率的帮助
       </strong>
      </p>
      <ul>
       <li>
        通过在搜索或变异阶段进行预判，PPS 能够
        <strong>
         大幅减少
        </strong>
        会导致无效表达式的组合，减少不必要的计算。
       </li>
       <li>
        这样一来，进化算法可以
        <strong>
         更专注于
        </strong>
        有效、有潜力的候选结构，提升搜索效率与质量。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h3>
     D Details of Search Space
    </h3>
    <h5>
    </h5>
    <h5>
     D.2 GPT-2 的细节
    </h5>
    <p>
     表 8 列出了 GPT-2 架构优化所使用的大规模搜索空间，涵盖了探索过程中的一系列超参数。它包括：
    </p>
    <ul>
     <li>
      Transformer 模型的层数 (nlayer)，表示模型的深度；
     </li>
     <li>
      模型嵌入的维度 (dmodel)，反映模型的规模和容量；
     </li>
     <li>
      前馈网络 (feed-forward) 的内部维度 (dinner)，该参数对模型在每个 Transformer 层内处理和整合信息的能力至关重要；
     </li>
     <li>
      注意力头数 (nhead)，影响模型对输入序列不同部分的关注能力；
     </li>
     <li>
      自适应输入嵌入 (adaptive input embedding) 的维度 (dembed) 及其关联的缩放因子 (k)，为管理输入表示的复杂度和效率提供了一种新颖的方法。
     </li>
    </ul>
    <p>
     值得注意的是，在该搜索空间中，dinner 的取值会自适应地至少设为 dmodel 的两倍，这是一种启发式做法，以确保前馈网络具备足够的容量，从而降低训练崩溃的风险。
    </p>
    <p>
    </p>
    <p>
     在本文的实验中，作者主要在
     <strong>
      FlexiBERT
     </strong>
     和
     <strong>
      GPT-2
     </strong>
     这两个搜索空间中验证所提出的零成本代理（ZC proxy）的排名相关性。它们的区别主要在于网络结构的可变范围、任务数据集和评估指标等方面。
    </p>
    <h4>
     D.1 FlexiBERT 的细节
    </h4>
    <ul>
     <li>
      <p>
       <strong>
        基于 BERT 架构的可变设计
       </strong>
       <br/>
       FlexiBERT 的核心思想是对原始 BERT 的多个超参数进行灵活调整，例如：
      </p>
      <ol>
       <li>
        Transformer Block 的数量（深度）
       </li>
       <li>
        每个 Block 的隐藏维度（宽度）
       </li>
       <li>
        多头注意力（Multi-Head Attention）的头数
       </li>
       <li>
        前馈网络（Feed-Forward）的维度
       </li>
       <li>
        其他细节（如激活函数类型、是否使用 LayerNorm 等）
       </li>
      </ol>
     </li>
     <li>
      <p>
       <strong>
        数据集和任务
       </strong>
      </p>
      <ol>
       <li>
        <strong>
         GLUE 任务
        </strong>
        ：FlexiBERT 基准源于 GLUE（General Language Understanding Evaluation），它包括多项 NLP 任务（如文本蕴含、情感分析等），在每个模型配置上会评估在这些任务上的平均性能，作为衡量网络优劣的“真实分数”。
       </li>
       <li>
        <strong>
         OpenWebText
        </strong>
        ：在搜索零成本代理时，为了提取激活分布、参数规模等信息，作者只需要在小批量数据上进行前向传播（无需完整训练），这里采用了 OpenWebText 数据来获取这些统计信息。
       </li>
      </ol>
     </li>
     <li>
      <p>
       <strong>
        架构规模
       </strong>
       <br/>
       FlexiBERT Benchmark 拥有 该搜索空间总共包含
       <strong>
        10,621,440
       </strong>
       种可能的架构（具体可见作者在附录中的说明），因此搜索空间相当庞大且稀疏。
      </p>
     </li>
    </ul>
    <p class="img-center">
     <img alt="" height="436" src="https://i-blog.csdnimg.cn/direct/9da0245c5cc54903ac4cae2f5f28ee3c.png" width="1012"/>
    </p>
    <h4>
     （2）GPT-2 搜索空间
    </h4>
    <ul>
     <li>
      <p>
       <strong>
        基于 GPT-2 架构的可变设计
       </strong>
      </p>
      <p>
       表 8 列出了 GPT-2 架构优化所使用的大规模搜索空间，涵盖了探索过程中的一系列超参数。它包括：
      </p>
      <ol>
       <li>
        Transformer 模型的层数 (nlayer)，表示模型的深度；
       </li>
       <li>
        模型嵌入的维度 (dmodel)，反映模型的规模和容量；
       </li>
       <li>
        前馈网络 (feed-forward) 的内部维度 (dinner)，该参数对模型在每个 Transformer 层内处理和整合信息的能力至关重要；
       </li>
       <li>
        注意力头数 (nhead)，影响模型对输入序列不同部分的关注能力；
       </li>
       <li>
        自适应输入嵌入 (adaptive input embedding) 的维度 (dembed) 及其关联的缩放因子 (k)，为管理输入表示的复杂度和效率提供了一种新颖的方法。
       </li>
      </ol>
     </li>
     <li>
      <p>
       <strong>
        数据集
       </strong>
      </p>
      <ol>
       <li>
        <strong>
         WikiText-103
        </strong>
        ：作者在该数据集上对 GPT-2 变体进行评估。与 BERT 不同，GPT-2 属于自回归语言模型，因此主要关注语言建模任务（如困惑度 Perplexity）。
       </li>
       <li>
        在搜索零成本代理时，同样只需要在小批量数据（batch size = 16）上做前向计算以提取网络激活和参数信息。
       </li>
      </ol>
     </li>
     <li>
      <p>
       <strong>
        架构规模
       </strong>
       <br/>
       该搜索空间包含了
       <strong>
        约 1054 个
       </strong>
       GPT-2 变体（来自文献中公开的基准或作者自行组合），数量虽不及 FlexiBERT 的规模庞大，但同样涵盖了相当丰富的结构变动。
      </p>
     </li>
     <li>
      <p>
       <strong>
        评估方式
       </strong>
       <br/>
       类似地，在 GPT-2 搜索空间中也会随机抽取一部分架构（文中常用 200 个）进行真实评测（如在 WikiText-103 上的困惑度），然后与代理的评分进行对比，以计算排名一致性。
      </p>
     </li>
    </ul>
    <p class="img-center">
     <img alt="" height="354" src="https://i-blog.csdnimg.cn/direct/4955a14a353a4a54856a6c7ac3d837c5.png" width="993"/>
    </p>
    <hr/>
    <h2>
     <span style="background-color:#edf6e8">
      心迹录
     </span>
    </h2>
    <p>
     <span style="background-color:#edf6e8">
      人之为病，心魔也，
     </span>
     <br/>
     <span style="background-color:#edf6e8">
      心若通达，万病自消
     </span>
     <br/>
     <span style="background-color:#edf6e8">
      面对事情时，心中不纠结
     </span>
     <br/>
     <span style="background-color:#edf6e8">
      若想要命好，精神上不受力
     </span>
     <br/>
     <span style="background-color:#edf6e8">
      其实差的大运流年是破坏你内心小宇宙的平衡
     </span>
     <br/>
     <span style="background-color:#edf6e8">
      心身互为因果
     </span>
     <br/>
     <span style="background-color:#edf6e8">
      心理状态，会影响肉身
     </span>
     <br/>
     <span style="background-color:#edf6e8">
      强健肉身，调养五脏，五脏安，则心神安
     </span>
    </p>
    <p>
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34353739353338342f:61727469636c652f64657461696c732f313436303837353038" class_="artid" style="display:none">
 </p>
</div>


