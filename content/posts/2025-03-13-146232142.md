---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f7368697a68656e675f4c692f:61727469636c652f64657461696c732f313436323332313432"
layout: post
title: "深入了解-PyTorch-中的-MaxPool2d-及其池化家族函数"
date: 2025-03-13 15:30:16 +08:00
description: "函数的原理解析"
keywords: "深入了解 PyTorch 中的 MaxPool2d 及其池化家族函数"
categories: ['Pytorch']
tags: ['人工智能', 'Pytorch', 'Python']
artid: "146232142"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146232142
    alt: "深入了解-PyTorch-中的-MaxPool2d-及其池化家族函数"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146232142
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146232142
cover: https://bing.ee123.net/img/rand?artid=146232142
image: https://bing.ee123.net/img/rand?artid=146232142
img: https://bing.ee123.net/img/rand?artid=146232142
---

# 深入了解 PyTorch 中的 MaxPool2d 及其池化家族函数

以下是一个简化的 U-Net 实现示例，使用 PyTorch 框架：里面用到了池化，所以想记录一下。

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class UNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=2):
        super(UNet, self).__init__()

        # 收缩路径
        self.enc1 = self.conv_block(in_channels, 64)
        self.enc2 = self.conv_block(64, 128)
        self.enc3 = self.conv_block(128, 256)
        self.pool = nn.MaxPool2d(2)

        # 底部
        self.bottom = self.conv_block(256, 512)

        # 扩展路径
        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.dec3 = self.conv_block(512, 256)  # 拼接后通道数为 256+256=512
        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dec2 = self.conv_block(256, 128)
        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.dec1 = self.conv_block(128, 64)

        # 输出层
        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)

    def conv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=0),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=0),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        # 收缩路径
        e1 = self.enc1(x)
        e2 = self.enc2(self.pool(e1))
        e3 = self.enc3(self.pool(e2))
        b = self.bottom(self.pool(e3))

        # 扩展路径
        d3 = self.up3(b)
        d3 = torch.cat([d3, e3], dim=1)  # 跳跃连接
        d3 = self.dec3(d3)
        d2 = self.up2(d3)
        d2 = torch.cat([d2, e2], dim=1)
        d2 = self.dec2(d2)
        d1 = self.up1(d2)
        d1 = torch.cat([d1, e1], dim=1)
        d1 = self.dec1(d1)

        # 输出
        out = self.out_conv(d1)
        return out

# 测试代码
if __name__ == "__main__":
    model = UNet(in_channels=1, out_channels=2)
    x = torch.randn(1, 1, 572, 572)  # 输入示例：单通道 572x572 图像
    y = model(x)
    print(y.shape)  # 输出：torch.Size([1, 2, 388, 388])

```

以下是一篇关于
`MaxPool2d`
函数及其家族函数的中文博客内容，适合技术爱好者或机器学习初学者阅读。我会从功能、使用场景和代码示例等方面进行介绍。

---

## 深入了解 PyTorch 中的 MaxPool2d 及其池化家族函数

在深度学习中，卷积神经网络（CNN）是处理图像、音频等高维数据的利器。而池化（Pooling）操作作为 CNN 的核心组件之一，广泛用于降维、提取特征和增强模型的鲁棒性。今天，我们以 PyTorch 中的
`MaxPool2d`
为切入点，介绍它的功能、使用方式，并顺带聊聊它的“家族成员”——其他池化函数。

### 什么是 MaxPool2d？

`MaxPool2d`
是 PyTorch 中
`torch.nn`
模块提供的一个二维最大池化（Max Pooling）函数。它通过在输入特征图上滑动一个指定大小的窗口（通常称为“池化核”），从每个窗口中提取最大值，从而实现降维和特征浓缩。

简单来说，
`MaxPool2d`
的作用是：

1. **降维**
   ：减少特征图的空间分辨率（宽和高），降低计算量。
2. **特征提取**
   ：保留最重要的特征（最大值通常代表显著特征）。
3. **增强鲁棒性**
   ：通过减少对小范围平移或变形的敏感性，提升模型的泛化能力。

在 U-Net 等网络中，
`MaxPool2d`
常出现在“收缩路径”中，用于逐步压缩特征图，为后续的深层处理做准备。

#### 定义与参数

`MaxPool2d`
的基本定义如下：

```python
torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)

```

* `kernel_size`
  ：池化窗口的大小，例如
  `2`
  或
  `(2, 2)`
  ，表示 2x2 的窗口。
* `stride`
  ：窗口滑动的步幅，默认等于
  `kernel_size`
  。
* `padding`
  ：输入边缘填充的像素数，默认值为 0。
* `dilation`
  ：控制池化窗口内元素之间的间距，默认值为 1（无间距）。
* `return_indices`
  ：若为
  `True`
  ，返回最大值的位置索引（常用于上采样，如 U-Net 的解码路径）。
* `ceil_mode`
  ：若为
  `True`
  ，输出尺寸计算时向上取整，否则向下取整。

#### 使用示例

以下是一个简单的例子：

```python
import torch
import torch.nn as nn

# 定义一个 2x2 的最大池化层，步幅为 2
pool = nn.MaxPool2d(kernel_size=2, stride=2)

# 输入张量：1个样本，1个通道，4x4 的特征图
x = torch.tensor([[[[1., 2., 3., 4.],
                    [5., 6., 7., 8.],
                    [9., 10., 11., 12.],
                    [13., 14., 15., 16.]]]])

# 应用池化
y = pool(x)
print(y)
# 输出：tensor([[[[ 6.,  8.],
#                  [14., 16.]]]])

```

在这个例子中，输入 4x4 的特征图被划分为 4 个 2x2 的区域，每个区域取最大值，输出变为 2x2。

### MaxPool2d 的家族成员

池化操作不仅仅只有最大池化，PyTorch 提供了一系列相关函数，统称为“池化家族”。它们各有特点，适用于不同场景：

#### 1. AvgPool2d - 平均池化

* **功能**
  ：计算池化窗口内的平均值，而不是最大值。
* **使用场景**
  ：适用于需要平滑特征或减少显著特征影响的任务。
* **示例**
  ：

```python
avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)
y = avg_pool(x)
print(y)
# 输出：tensor([[[[3.5000, 5.5000],
#                  [11.5000, 13.5000]]]])

```

平均池化保留了区域内的整体信息，而非突出单一最大值。

#### 2. AdaptiveMaxPool2d - 自适应最大池化

* **功能**
  ：无需指定窗口大小和步幅，只需指定目标输出尺寸，函数自动调整池化参数。
* **使用场景**
  ：当输入尺寸可变但需要固定输出尺寸时（如分类任务的最后一层）。
* **示例**
  ：

```python
adaptive_pool = nn.AdaptiveMaxPool2d((2, 2))
y = adaptive_pool(x)
print(y)
# 输出与 MaxPool2d 类似，但更灵活

```

#### 3. MaxUnpool2d - 最大反池化

* **功能**
  ：与
  `MaxPool2d`
  配合使用，利用池化时保存的索引进行上采样。
* **使用场景**
  ：常用于 U-Net 等解码路径中，恢复特征图的空间分辨率。
* **示例**
  ：

```python
pool = nn.MaxPool2d(2, stride=2, return_indices=True)
y, indices = pool(x)
unpool = nn.MaxUnpool2d(2, stride=2)
z = unpool(y, indices)

```

#### 4. 其他成员

* `AvgPool1d`
  /
  `MaxPool1d`
  ：一维池化，用于序列数据（如时间序列）。
* `AvgPool3d`
  /
  `MaxPool3d`
  ：三维池化，用于体视数据（如视频或医学图像）。

### 在 U-Net 中的应用

回到开头展示的 U-Net 代码，
`MaxPool2d`
在“收缩路径”中起到关键作用：

```python
self.pool = nn.MaxPool2d(2)  # 2x2 池化，步幅为 2
e2 = self.enc2(self.pool(e1))  # 池化后特征图尺寸减半

```

每次池化将特征图宽高减半，通道数通过卷积层增加，从而实现“深而窄”的特征提取。而在“扩展路径”中，虽然没有直接使用
`MaxUnpool2d`
，但通过
`ConvTranspose2d`
和跳跃连接实现了类似的上采样效果。

### 总结

`MaxPool2d`
是 CNN 中简单而强大的工具，它通过提取最大值实现降维和特征浓缩。它的家族成员（如
`AvgPool2d`
、
`AdaptiveMaxPool2d`
等）进一步丰富了池化操作的灵活性，满足不同任务需求。在实际应用中，选择合适的池化方法需要结合任务目标：最大池化突出显著特征，平均池化平滑信息，自适应池化则提供尺寸灵活性。

希望这篇文章能帮助你更好地理解
`MaxPool2d`
及其家族函数！

### 后记

2025年3月13日15点29分于上海，在grok 3大模型辅助下完成。