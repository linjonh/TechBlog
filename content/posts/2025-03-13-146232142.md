---
layout: post
title: "深入了解-PyTorch-中的-MaxPool2d-及其池化家族函数"
date: 2025-03-13 15:30:16 +0800
description: "函数的原理解析"
keywords: "深入了解 PyTorch 中的 MaxPool2d 及其池化家族函数"
categories: ['Pytorch']
tags: ['人工智能', 'Pytorch', 'Python']
artid: "146232142"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146232142
    alt: "深入了解-PyTorch-中的-MaxPool2d-及其池化家族函数"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146232142
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146232142
cover: https://bing.ee123.net/img/rand?artid=146232142
image: https://bing.ee123.net/img/rand?artid=146232142
img: https://bing.ee123.net/img/rand?artid=146232142
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     深入了解 PyTorch 中的 MaxPool2d 及其池化家族函数
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-github-gist" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     以下是一个简化的 U-Net 实现示例，使用 PyTorch 框架：里面用到了池化，所以想记录一下。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">class</span> <span class="token class-name">UNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>UNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 收缩路径</span>
        self<span class="token punctuation">.</span>enc1 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_block<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>enc2 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>enc3 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>

        <span class="token comment"># 底部</span>
        self<span class="token punctuation">.</span>bottom <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span>

        <span class="token comment"># 扩展路径</span>
        self<span class="token punctuation">.</span>up3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dec3 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>  <span class="token comment"># 拼接后通道数为 256+256=512</span>
        self<span class="token punctuation">.</span>up2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dec2 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>up1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dec1 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>

        <span class="token comment"># 输出层</span>
        self<span class="token punctuation">.</span>out_conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">conv_block</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 收缩路径</span>
        e1 <span class="token operator">=</span> self<span class="token punctuation">.</span>enc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        e2 <span class="token operator">=</span> self<span class="token punctuation">.</span>enc2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>e1<span class="token punctuation">)</span><span class="token punctuation">)</span>
        e3 <span class="token operator">=</span> self<span class="token punctuation">.</span>enc3<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>e2<span class="token punctuation">)</span><span class="token punctuation">)</span>
        b <span class="token operator">=</span> self<span class="token punctuation">.</span>bottom<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>e3<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 扩展路径</span>
        d3 <span class="token operator">=</span> self<span class="token punctuation">.</span>up3<span class="token punctuation">(</span>b<span class="token punctuation">)</span>
        d3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>d3<span class="token punctuation">,</span> e3<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 跳跃连接</span>
        d3 <span class="token operator">=</span> self<span class="token punctuation">.</span>dec3<span class="token punctuation">(</span>d3<span class="token punctuation">)</span>
        d2 <span class="token operator">=</span> self<span class="token punctuation">.</span>up2<span class="token punctuation">(</span>d3<span class="token punctuation">)</span>
        d2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>d2<span class="token punctuation">,</span> e2<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        d2 <span class="token operator">=</span> self<span class="token punctuation">.</span>dec2<span class="token punctuation">(</span>d2<span class="token punctuation">)</span>
        d1 <span class="token operator">=</span> self<span class="token punctuation">.</span>up1<span class="token punctuation">(</span>d2<span class="token punctuation">)</span>
        d1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>d1<span class="token punctuation">,</span> e1<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        d1 <span class="token operator">=</span> self<span class="token punctuation">.</span>dec1<span class="token punctuation">(</span>d1<span class="token punctuation">)</span>

        <span class="token comment"># 输出</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>out_conv<span class="token punctuation">(</span>d1<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out

<span class="token comment"># 测试代码</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> UNet<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">572</span><span class="token punctuation">,</span> <span class="token number">572</span><span class="token punctuation">)</span>  <span class="token comment"># 输入示例：单通道 572x572 图像</span>
    y <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># 输出：torch.Size([1, 2, 388, 388])</span>
</code></pre>
    <p>
     以下是一篇关于
     <code>
      MaxPool2d
     </code>
     函数及其家族函数的中文博客内容，适合技术爱好者或机器学习初学者阅读。我会从功能、使用场景和代码示例等方面进行介绍。
    </p>
    <hr/>
    <h2>
     <a id="_PyTorch__MaxPool2d__74">
     </a>
     深入了解 PyTorch 中的 MaxPool2d 及其池化家族函数
    </h2>
    <p>
     在深度学习中，卷积神经网络（CNN）是处理图像、音频等高维数据的利器。而池化（Pooling）操作作为 CNN 的核心组件之一，广泛用于降维、提取特征和增强模型的鲁棒性。今天，我们以 PyTorch 中的
     <code>
      MaxPool2d
     </code>
     为切入点，介绍它的功能、使用方式，并顺带聊聊它的“家族成员”——其他池化函数。
    </p>
    <h3>
     <a id="_MaxPool2d_78">
     </a>
     什么是 MaxPool2d？
    </h3>
    <p>
     <code>
      MaxPool2d
     </code>
     是 PyTorch 中
     <code>
      torch.nn
     </code>
     模块提供的一个二维最大池化（Max Pooling）函数。它通过在输入特征图上滑动一个指定大小的窗口（通常称为“池化核”），从每个窗口中提取最大值，从而实现降维和特征浓缩。
    </p>
    <p>
     简单来说，
     <code>
      MaxPool2d
     </code>
     的作用是：
    </p>
    <ol>
     <li>
      <strong>
       降维
      </strong>
      ：减少特征图的空间分辨率（宽和高），降低计算量。
     </li>
     <li>
      <strong>
       特征提取
      </strong>
      ：保留最重要的特征（最大值通常代表显著特征）。
     </li>
     <li>
      <strong>
       增强鲁棒性
      </strong>
      ：通过减少对小范围平移或变形的敏感性，提升模型的泛化能力。
     </li>
    </ol>
    <p>
     在 U-Net 等网络中，
     <code>
      MaxPool2d
     </code>
     常出现在“收缩路径”中，用于逐步压缩特征图，为后续的深层处理做准备。
    </p>
    <h4>
     <a id="_89">
     </a>
     定义与参数
    </h4>
    <p>
     <code>
      MaxPool2d
     </code>
     的基本定义如下：
    </p>
    <pre><code class="prism language-python">torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> return_indices<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre>
    <ul>
     <li>
      <code>
       kernel_size
      </code>
      ：池化窗口的大小，例如
      <code>
       2
      </code>
      或
      <code>
       (2, 2)
      </code>
      ，表示 2x2 的窗口。
     </li>
     <li>
      <code>
       stride
      </code>
      ：窗口滑动的步幅，默认等于
      <code>
       kernel_size
      </code>
      。
     </li>
     <li>
      <code>
       padding
      </code>
      ：输入边缘填充的像素数，默认值为 0。
     </li>
     <li>
      <code>
       dilation
      </code>
      ：控制池化窗口内元素之间的间距，默认值为 1（无间距）。
     </li>
     <li>
      <code>
       return_indices
      </code>
      ：若为
      <code>
       True
      </code>
      ，返回最大值的位置索引（常用于上采样，如 U-Net 的解码路径）。
     </li>
     <li>
      <code>
       ceil_mode
      </code>
      ：若为
      <code>
       True
      </code>
      ，输出尺寸计算时向上取整，否则向下取整。
     </li>
    </ul>
    <h4>
     <a id="_101">
     </a>
     使用示例
    </h4>
    <p>
     以下是一个简单的例子：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn

<span class="token comment"># 定义一个 2x2 的最大池化层，步幅为 2</span>
pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># 输入张量：1个样本，1个通道，4x4 的特征图</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">3.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token number">5.</span><span class="token punctuation">,</span> <span class="token number">6.</span><span class="token punctuation">,</span> <span class="token number">7.</span><span class="token punctuation">,</span> <span class="token number">8.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token number">9.</span><span class="token punctuation">,</span> <span class="token number">10.</span><span class="token punctuation">,</span> <span class="token number">11.</span><span class="token punctuation">,</span> <span class="token number">12.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token number">13.</span><span class="token punctuation">,</span> <span class="token number">14.</span><span class="token punctuation">,</span> <span class="token number">15.</span><span class="token punctuation">,</span> <span class="token number">16.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 应用池化</span>
y <span class="token operator">=</span> pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
<span class="token comment"># 输出：tensor([[[[ 6.,  8.],</span>
<span class="token comment">#                  [14., 16.]]]])</span>
</code></pre>
    <p>
     在这个例子中，输入 4x4 的特征图被划分为 4 个 2x2 的区域，每个区域取最大值，输出变为 2x2。
    </p>
    <h3>
     <a id="MaxPool2d__124">
     </a>
     MaxPool2d 的家族成员
    </h3>
    <p>
     池化操作不仅仅只有最大池化，PyTorch 提供了一系列相关函数，统称为“池化家族”。它们各有特点，适用于不同场景：
    </p>
    <h4>
     <a id="1_AvgPool2d___128">
     </a>
     1. AvgPool2d - 平均池化
    </h4>
    <ul>
     <li>
      <strong>
       功能
      </strong>
      ：计算池化窗口内的平均值，而不是最大值。
     </li>
     <li>
      <strong>
       使用场景
      </strong>
      ：适用于需要平滑特征或减少显著特征影响的任务。
     </li>
     <li>
      <strong>
       示例
      </strong>
      ：
     </li>
    </ul>
    <pre><code class="prism language-python">avg_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> avg_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
<span class="token comment"># 输出：tensor([[[[3.5000, 5.5000],</span>
<span class="token comment">#                  [11.5000, 13.5000]]]])</span>
</code></pre>
    <p>
     平均池化保留了区域内的整体信息，而非突出单一最大值。
    </p>
    <h4>
     <a id="2_AdaptiveMaxPool2d___141">
     </a>
     2. AdaptiveMaxPool2d - 自适应最大池化
    </h4>
    <ul>
     <li>
      <strong>
       功能
      </strong>
      ：无需指定窗口大小和步幅，只需指定目标输出尺寸，函数自动调整池化参数。
     </li>
     <li>
      <strong>
       使用场景
      </strong>
      ：当输入尺寸可变但需要固定输出尺寸时（如分类任务的最后一层）。
     </li>
     <li>
      <strong>
       示例
      </strong>
      ：
     </li>
    </ul>
    <pre><code class="prism language-python">adaptive_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> adaptive_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
<span class="token comment"># 输出与 MaxPool2d 类似，但更灵活</span>
</code></pre>
    <h4>
     <a id="3_MaxUnpool2d___152">
     </a>
     3. MaxUnpool2d - 最大反池化
    </h4>
    <ul>
     <li>
      <strong>
       功能
      </strong>
      ：与
      <code>
       MaxPool2d
      </code>
      配合使用，利用池化时保存的索引进行上采样。
     </li>
     <li>
      <strong>
       使用场景
      </strong>
      ：常用于 U-Net 等解码路径中，恢复特征图的空间分辨率。
     </li>
     <li>
      <strong>
       示例
      </strong>
      ：
     </li>
    </ul>
    <pre><code class="prism language-python">pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> return_indices<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
y<span class="token punctuation">,</span> indices <span class="token operator">=</span> pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
unpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxUnpool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
z <span class="token operator">=</span> unpool<span class="token punctuation">(</span>y<span class="token punctuation">,</span> indices<span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="4__163">
     </a>
     4. 其他成员
    </h4>
    <ul>
     <li>
      <code>
       AvgPool1d
      </code>
      /
      <code>
       MaxPool1d
      </code>
      ：一维池化，用于序列数据（如时间序列）。
     </li>
     <li>
      <code>
       AvgPool3d
      </code>
      /
      <code>
       MaxPool3d
      </code>
      ：三维池化，用于体视数据（如视频或医学图像）。
     </li>
    </ul>
    <h3>
     <a id="_UNet__167">
     </a>
     在 U-Net 中的应用
    </h3>
    <p>
     回到开头展示的 U-Net 代码，
     <code>
      MaxPool2d
     </code>
     在“收缩路径”中起到关键作用：
    </p>
    <pre><code class="prism language-python">self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># 2x2 池化，步幅为 2</span>
e2 <span class="token operator">=</span> self<span class="token punctuation">.</span>enc2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>e1<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 池化后特征图尺寸减半</span>
</code></pre>
    <p>
     每次池化将特征图宽高减半，通道数通过卷积层增加，从而实现“深而窄”的特征提取。而在“扩展路径”中，虽然没有直接使用
     <code>
      MaxUnpool2d
     </code>
     ，但通过
     <code>
      ConvTranspose2d
     </code>
     和跳跃连接实现了类似的上采样效果。
    </p>
    <h3>
     <a id="_176">
     </a>
     总结
    </h3>
    <p>
     <code>
      MaxPool2d
     </code>
     是 CNN 中简单而强大的工具，它通过提取最大值实现降维和特征浓缩。它的家族成员（如
     <code>
      AvgPool2d
     </code>
     、
     <code>
      AdaptiveMaxPool2d
     </code>
     等）进一步丰富了池化操作的灵活性，满足不同任务需求。在实际应用中，选择合适的池化方法需要结合任务目标：最大池化突出显著特征，平均池化平滑信息，自适应池化则提供尺寸灵活性。
    </p>
    <p>
     希望这篇文章能帮助你更好地理解
     <code>
      MaxPool2d
     </code>
     及其家族函数！
    </p>
    <h3>
     <a id="_183">
     </a>
     后记
    </h3>
    <p>
     2025年3月13日15点29分于上海，在grok 3大模型辅助下完成。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f7368697a68656e675f4c692f:61727469636c652f64657461696c732f313436323332313432" class_="artid" style="display:none">
 </p>
</div>


