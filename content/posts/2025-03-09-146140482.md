---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34333834393530352f:61727469636c652f64657461696c732f313436313430343832"
layout: post
title: "论文阅读VAD-Vectorized-Scene-Representation-for-Efficient-Autonomous-Driving"
date: 2025-03-09 23:17:35 +0800
description: "端到端无人驾驶框架VAD，使用map query和agent query对BEV进行特征提取"
keywords: "【论文阅读】VAD: Vectorized Scene Representation for Efficient Autonomous Driving"
categories: ['端到端无人驾驶']
tags: ['论文阅读']
artid: "146140482"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146140482
    alt: "论文阅读VAD-Vectorized-Scene-Representation-for-Efficient-Autonomous-Driving"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146140482
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146140482
cover: https://bing.ee123.net/img/rand?artid=146140482
image: https://bing.ee123.net/img/rand?artid=146140482
img: https://bing.ee123.net/img/rand?artid=146140482
---

# 【论文阅读】VAD: Vectorized Scene Representation for Efficient Autonomous Driving

### 一、介绍

VAD是华科团队设计的一个端到端无人驾驶框架，针对传统的无人驾驶框架的模块化设计的问题，该算法使用向量化的策略进行了端到端的实现。传统的模块化设计使得感知模块完全依赖于感知模块的计算结果，这一解耦实际上从规划模块的角度损失了很多的信息，诸如语义信息。VAD采用向量化的策略进行了重新设计，从实验结果上来看超过了上海实验室提出的UniAD。

### 二、方法

VAD的模型以多视角的图像作为输入，编码后提取BEV特征，该特征会被送到Transformer中提取两类特征，这两类特征后续应用到轨控模块中。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/79d8acf493b844999a2696516f54fdb5.png)

#### 3.1 Vectorized Scene Learning

这一节主要是介绍特征提取的部分。首先论文并没有介绍从多视角图像到BEV图像这个过程是如何实现的，应该是直接使用了现成的转换模型。论文直接是从得到BEV视角后开始介绍的。这一部分实际上包括了两种查询：Ageng query和Map query。这里的query实际上就是Transformer里面的那个query，我们主要就是训练这个query。

##### Map query

先给出结论， 这一个查询输入是BEV视角下的特征，输出是场景中的向量化的实例特征，可以理解为“当前场景中的物体以及哪些点归属于这些物体”。这个实例特征作者起名叫做map vector，它是一个Nm×Np×2大小的矩阵，其中Nm表示场景中物体的数目、Np为一个物体占据的点的数目，最后的2则是说它在BEV视角下的位置。这一个模块中算法主要关注三个内容：车道分割线、道路边界以及人行横道。简单来说就是通过Transformer处理之后，最后转换为一个三分类任务。

##### Agent query

与Map query类似，这一部分其实也是提取一类特征，主要是对场景中的物体的行进轨迹进行预测，这一预测会被用到后续的规划中。这一部分的输入依然是BEV视角下的特征，输出的是一个大小为Na×Nk×Tf×2的矩阵，其中Na表示场景中物体的数量，Nk表示行驶状态，Tf表示未来的时间戳，最后的2则是BEV视角下的坐标。我的理解是，这个矩阵表示了未来Tf时间内，Na个车辆的行驶状态及位置。相当于在这个模块内进行了所有交通参与者的状态预测，利用这一预测结果来约束后面轨控模块的行驶策略。

在这个模块中，稍微补习了一下Transformer的内容，在Transformer的编码器中，关键的三个值是query、key和value，其中query是我们训练的结果，key和value则是输入的变种。对于VAD中的查询模块，key和value都来源于BEV视角下的特征输入。这里的过程如下图：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/1107a96c2e29421199ce01bce50447c0.png)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/9e519c376cd14011a4174108ae2b477f.png)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/84492d3d06544406bde7a7c114b891ae.png)
  
查询的数量并不等于类别数量，查询相当于多个卷积核，只负责特征的提取，而真正影响类别数量的是最后softmax层的结构。计算Key和Value的时候，映射矩阵Wk和Wv相当于一个降维的作用，负责对齐Key、Value以及Query的维度，这两个映射矩阵也是模型需要学习的参数。计算注意力的时候，所涉及的维度变化为：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/938da212d14b4cf99124bfc48a8bfca0.png)
  
在计算注意力之前，其实就已经存在一个展平的过程，原本BEV应该是H×W×C大小的，每张图是H×W，一共有C张，在计算键值的时候就已经展平了，这样子才可以与Wk和Wv进行计算，计算之后的键值变为D个长度为H×W的向量，拼成一个二维矩阵，key首先与query进行计算，得到相关性，这一相关性与value加权求和，得到大小为Nm×D的二维矩阵，表示D个长度为Nm的向量，可以解释为Nm个关键信息，每个信息都是一个长度为D的向量。这些信息会通过MLP解码进行后处理，将D维度调整为Np×2的维度，这样子就可以恢复出地图元素的位置以及包括的点。最终变成Vm：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/eb78ffe3cfa54e1ba34399252a67bb98.png)
  
这里的query和传统transformer的query还有一些区别，最传统的transformer中输入的embedding会根据三个线性变换层转换为query、value以及key，学习的内容是三个用于变换的权重矩阵，而这里query并不是来源于输入，而是单独作为一个需要学习的参数，这个query会逐渐更新并用于其它的部分。问了一下专门搞大模型的同学，这种query属于是可学习query，这个量会作为一个参数进行调整。我理解的是在模型训练后，我们固定参数不动，在运行模型进行推理的时候会将map query和agent query作为输入，这两个query的初始值是通过特征工程等其它来源训练出来的结果，能够专门提取特定类别的特征，在此基础上每次推理都会更新两个query，这也对应流程图中的updated query。

#### 3.2 Vectorized Scene Learning

为了学习场景中的隐式特征，VAD采用了一个ego query的查询，从论文来看它应该也是一个可学习query，初始化是随机的，之后在不断推理的过程中利用更新的map query和agent query进行整合。这个过程使用的是Transformer的解码器，ego query被用作query，第一阶段ego query与map query进行融合，此时更新过的agent query会作为key和value送入解码器，除此之外还有两个预测值会经过MLP映射后作为位置编码进行叠加。整个过程的优化公式为：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5dae7894262b44c1b6754b0101a322cc.png)
  
第二阶段会继续对ego query进行融合，这个过程中第一阶段的结果Q’ego会作为query，map query会作为key和value进行融合，这一阶段唯一的区别在于计算位置编码时使用了两层的MLP。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/f997d1a712844b2b9fc2fa143cb639af.png)
  
完成这两步之后，VAD将两个query以及一些可选项进行叠加，之后作为规划头进行推理。输出的是规划的路径，这里的规划头并不复杂，是一个基于MLP的结构。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/7fb50d52948943bb8a7adfa6d7797f30.png)