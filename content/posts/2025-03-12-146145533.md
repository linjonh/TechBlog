---
arturl_encode: "68747470733a2f:2f626c6f672e6373646e2e6e65742f7379783035303430332f:61727469636c652f64657461696c732f313436313435353333"
layout: post
title: "Rabbitmq运维"
date: 2025-03-12 16:47:17 +0800
description: "其中有一个节点就已经超过超时时间了，就会想要当leader，把任期加一，并且给自己投一票，然后给每个从节点发送一个requestvote rpcs，让他们投给自己。没有赢得选举的话就还是跟随者。客户端发送请求给leader节点，那么leader节点就会在收到请求同时发送给从节点，其他节点也就记录这些请求。raft核心就是选出主节点，其他节点是从节点，主节点负责接收客户端发来的请求，将操作包装好发给从节点，领导者：选出主节点之后，主节点用于处理复制给其他从节点，给从节点发送心跳包，告诉他们现在我还是主节点。"
keywords: "Rabbitmq运维"
categories: ['Rabbitmq']
tags: ['运维', '分布式', 'Rabbitmq']
artid: "146145533"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146145533
    alt: "Rabbitmq运维"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146145533
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146145533
cover: https://bing.ee123.net/img/rand?artid=146145533
image: https://bing.ee123.net/img/rand?artid=146145533
img: https://bing.ee123.net/img/rand?artid=146145533
---

# Rabbitmq运维

## rabbitmq集群

### 多机多节点

由于多机多节点是在通过同一个局域网内，多个机器，多个服务器，每个服务器上面部署不同的rabbitmq节点。

### 单机多节点

单机多节点比如在一个机器上面部署多个rabbitmq服务，也会称之为伪节点。由于这里我们只有一个服务器，我们就使用单机多节点。

基于ubuntu的单机多节点搭建：

```
RABBITMQ_NODE_PORT=5673 RABBITMQ_SERVER_START_ARGS="-rabbitmq_management listener [{port,15673}]" RABBITMQ_NODENAME=rabbit2 rabbitmq-server -detached
RABBITMQ_NODE_PORT=5674 RABBITMQ_SERVER_START_ARGS="-rabbitmq_management listener [{port,15674}]" RABBITMQ_NODENAME=rabbit3 rabbitmq-server -detached
```

通过者两行代码开通rabbitmq的端口号，并且云服务器也要开放，并且要设置账号密码才能在web页面查看。

停滞节点并且重置

```
RABBITMQ_NODE_PORT=5673 RABBITMQ_SERVER_START_ARGS="-rabbitmq_management listener [{port,15673}]" RABBITMQ_NODENAME=rabbit2 rabbitmq-server -detached
RABBITMQ_NODE_PORT=5674 RABBITMQ_SERVER_START_ARGS="-rabbitmq_management listener [{port,15674}]" RABBITMQ_NODENAME=rabbit3 rabbitmq-server -detached
```

```
rabbitmqctl -n rabbit2 stop_app
rabbitmqctl -n rabbit2 reset
rabbitmqctl -n rabbit3 stop_app
rabbitmqctl -n rabbit3 reset
```

这里的名称需要和上面定义的名称，如果定义的名称是rabbit2，那就是rabbit2.

接着就是添加集群了。

```
rabbitmqctl -n rabbit2 join_cluster rabbit@iZf8ziwyfxxz8w9blmn9sjZ
rabbitmqctl -n rabbit3 join_cluster rabbit@iZf8ziwyfxxz8w9blmn9sjZ
```

这时候就在单机上面添加好了节点了。

![](https://i-blog.csdnimg.cn/direct/37077e060161436bb01d13e48d79e999.png)

此时可以看到节点加入成功了，但是没有成功运行。

重启rabbitmq节点。

```
rabbitmqctl -n rabbit2 start_app
rabbitmqctl -n rabbit3 start_app
```

![](https://i-blog.csdnimg.cn/direct/825e494dcded48da8d230ee3e7d38f2d.png)

此时rabbitmq的节点就已经搭建起来了。

### 宕机演示

添加集群之后我们的web账号就可以互相登录了。

![](https://i-blog.csdnimg.cn/direct/d64188b4ee3147b58c2280b26add0901.png)

在其中一个添加队列，另外两个节点也会自动添加队列。
**rabbit主节点关闭后，队列的从节点的数据也会丢失。**

#### 仲裁队列

基于raft队列实现的算法持久化，仲裁队列是基于raft一致性算法实现的队列。仲裁队列提供了队列的复制能力，保障数据的高可用性和安全性。从而一个节点宕机的时候，其他节点还是可以提供服务。

##### 共识算法：

它允许多个分布式节点就某一系列值构成某种协议，即使某个节点发生故障，共识算法也能保障数据的一致性。raft算法就是一种新的共识算法，是paxos的升级版本。

##### raft算法

用于管理和维护分布式系统的一致性算法，他是一个共识算法，对数据进行复制到其他节点，
**raft是使用quorum来实现容错的，对队列的操作必须要大于n/2节点以上的同意才可以。这里的节点就是分布式系统中的成员。**

raft核心就是选出主节点，其他节点是从节点，主节点负责接收客户端发来的请求，将操作包装好发给从节点，
**选出主节点然后日志复制，日志安全性。**

![](https://i-blog.csdnimg.cn/direct/97ec12a60a50478a8742157e5fc0ffcf.png)

1. 领导者：选出主节点之后，主节点用于处理复制给其他从节点，给从节点发送心跳包，告诉他们现在我还是主节点。
2. 跟随者：接受来自主节点的复制条目等等内容，但是不直接处理客户端请求。
3. 候选人：如果没有收到心跳包，跟随者变成候选人，然后发起投票，投票自己能不能成为领导者。没有赢得选举的话就还是跟随者。

###### 任期：

![](https://i-blog.csdnimg.cn/direct/403fc077e5114988bbec7d7dce538c4c.png)

正常选举的任期就是leader的开始到结束，但是如果没有选举出来leader，那就会进行下一轮任期，这一轮任期直接跳过重新选举。通信的时候会带上该任期，来判断。
**比如主节点挂了但是忽然又好了，但是这时候从节点已经选举出来leader，但是这时候从节点就不认你了，因为他们进入一个新的任期，只能做小弟了。**

raft算法中最主要的两类通信方式：
  
![](https://i-blog.csdnimg.cn/direct/8035803cf35e4dafa415329af4b9ab7c.png)

###### 选举过程：

如果在规定时间内没有收到leader的消息，节点就会主动要求选举。

![](https://i-blog.csdnimg.cn/direct/cc1b4cc0850a414d8ca8d5ff7a7149aa.png)

其中有一个节点就已经超过超时时间了，就会想要当leader，把任期加一，并且给自己投一票，然后给每个从节点发送一个requestvote rpcs，让他们投给自己。

1. 赢得选举。
2. 其他节点赢得选举。
3. 一段时间后没有收到投票，保持候选人状态，继续发起选举。

每个节点在任期内只有一票，先收到哪个请求，基本上就是投给那个节点。任期要大于等于自己的节点才会给你投票。
并且迅速广而告之。

![](https://i-blog.csdnimg.cn/direct/f46a3f72546842fd98a1b6b7cd353ed9.png)

当出现每个人都把票投给自己这样的情况下死机，raft采用了随机选举超时时间，来确保发生这样非常极端的情况。 比如某两个节点得票数一样，那就会进入新一轮选举，新一轮的选举两节点就会设置随机选举超时时间。

###### 日志复制

客户端发送请求给leader节点，那么leader节点就会在收到请求同时发送给从节点，其他节点也就记录这些请求。

可以在mq的web页面中设置仲裁队列。

![](https://i-blog.csdnimg.cn/direct/f2c9a8ebe2bf483098484a17d0115874.png)

客户端和mq之间通过客户端和主节点之间进行通信，主节点丢失的时候会选举出新的主节点。

#### 仲裁队列的使用

先定义queue。

```
@Bean
    public Queue quorumQueue(){
        return QueueBuilder.durable("quorum_queue").quorum().build();
        
    }
```

##### 

这时候就看见仲裁队列就已经启动好了，登录另外一个mq的web界面。这里的+2就是两个副本，也就是两个镜像。

![](https://i-blog.csdnimg.cn/direct/1f4a205c28c24deb9d64356fef235fae.png)

rabbit就是leader，仲裁队列可以显示成员和leader，但是在普通队列中却没有。当我们将某个mq服务断掉了。

![](https://i-blog.csdnimg.cn/direct/e55029c6ec874ad4803b4e354b949e14.png)

就可以看到后面的+2，变成+1。仲裁队列默认镜像数是5，也就是一个主节点，4个从节点。

### 负载均衡

当某个节点压力比较大，很容易导致节点挂掉，负载均衡可以相对平衡分配。

![](https://i-blog.csdnimg.cn/direct/cf9123c00a6846a68243ffdc7ea2a4e3.png)

使用Haproxy实现负载均衡。

#### 安装hapoxy

更新软件包。

```
sudo apt-get update
```

查找haproxy。

```
sudo apt list|grep haproxy
```

![](https://i-blog.csdnimg.cn/direct/5258f2611ef84fd2bbcfa873c8c28ec8.png)

安装haproxy。

```
sudo apt-get install haproxy
```

查看haproxy状态

```
sudo systemctl status haproxy
```

接着修改文件

```
vim /etc/haproxy/haproxy.cfg
```

然后在配置文件中添加以下内容：

```
# haproxy web 管理界面
listen stats
    bind *:8100       
    mode http
    stats enable
    stats realm Haproxy\ Statistics    
    stats uri /
    stats auth admin:admin
# 配置负载均衡
listen rabbitmq
    bind *:5670
    mode tcp
    balance roundrobin
    server  rabbitmq1 127.0.0.1:5672  check inter 5000 rise 2 fall 3
    server  rabbitmq2 127.0.0.1:5673  check inter 5000 rise 2 fall 3
    server  rabbitmq3 127.0.0.1:5674  check inter 5000 rise 2 fall 3
```

最后就是重启hapoxy。

```
sudo systemctl restart haproxy
```

#### 使用hapoxy

![](https://i-blog.csdnimg.cn/direct/5580232d76274ced9e3095c5a2520d1e.png)

把idea中的配置改成5670，这时候就可以使用该端口号进行负载均衡。

![](https://i-blog.csdnimg.cn/direct/7923b638321a4a6fb2b0ad3fc238e706.png)

如果hapoxy也挂掉了怎么办，那就要涉及到当hapoxy挂掉的时候，切换到其他节点，当然了这里我们就不过多阐述。