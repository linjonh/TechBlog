---
layout: post
title: "BM25-文本相似度算法"
date: 2025-01-17 22:08:15 +0800
description: "BM25, 下一代的TF-IDF新版的lucence不再把TF-IDF作为默认的相关性算法，而是采用"
keywords: "BM25 文本相似度算法"
categories: ['Nlp']
tags: ['无标签']
artid: "95460003"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=95460003
    alt: "BM25-文本相似度算法"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=95460003
featuredImagePreview: https://bing.ee123.net/img/rand?artid=95460003
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     BM25 文本相似度算法
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="./../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="./../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h5>
     <a id="BM25_TFIDF_0">
     </a>
     BM25, 下一代的TF-IDF
    </h5>
    <p>
     新版的lucence不再把TF-IDF作为默认的相关性算法，而是采用了BM25(BM是Best Matching的意思)。BM25是基于TF-IDF并做了改进的算法。
    </p>
    <h6>
     <a id="BM25_4">
     </a>
     BM25算法，通常用来作搜索相关性评分。
    </h6>
    <p>
     一句话概况其主要思想：对Query进行语素解析，生成语素qi；然后，对于每个搜索结果D，计算每个语素qi与D的相关性得分，最后，将qi相对于D的相关性得分进行加权求和，从而得到Query与D的相关性得分。
    </p>
    <h6>
     <a id="TFIDF_vs_BM25_7">
     </a>
     传统TF-IDF vs. BM25
    </h6>
    <p>
     传统的TF-IDF是自然语言搜索的一个基础理论，它符合信息论中的熵的计算原理，虽然作者在刚提出它时并不知道与信息熵有什么关系，但你观察IDF公式会发现，它与熵的公式是类似的。实际上IDF就是一个特定条件下关键词概率分布的交叉熵。
    </p>
    <p>
     BM25在传统TF-IDF的基础上增加了几个可调节的参数，使得它在应用上更佳灵活和强大，具有较高的实用性。
    </p>
    <p>
     BM25同样使用词频，逆文档频率以及字段长度归一化，但是每个因子的定义都有细微差别
    </p>
    <ul>
     <li>
      <p>
       TF-IDF没有考虑词频上限的问题，因为高频停用词已经被移除了）
      </p>
     </li>
     <li>
      <p>
       BM25 有一个上限，文档里出现5-10次的词会比那些只出现一两次的对相关度有显著影响），参见词频饱和度图：
       <br/>
       <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/4773c0a6dbf530e13b47f815b37bc439.png"/>
      </p>
     </li>
    </ul>
    <p>
     BM25算法的一般性公式如下：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/621f9a84e52e79a1a876fcf05774ef5e.png"/>
    </p>
    <ul>
     <li>
      Q表示Query
     </li>
     <li>
      qi表示Q解析之后的一个语素（对中文而言，我们可以把对Query的分词作为语素分析，每个词看成语素qi。）
     </li>
     <li>
      d表示一个搜索结果文档；
     </li>
     <li>
      Wi表示语素qi的权重；
     </li>
     <li>
      R(qi，d)表示语素qi与文档d的相关性得分。
     </li>
    </ul>
    <h6>
     <a id="Wi_27">
     </a>
     Wi
    </h6>
    <p>
     下面我们来看如何定义Wi。判断一个词与一个文档的相关性的权重，方法有多种，较常用的是
     <code>
      IDF
     </code>
     。这里以IDF为例，公式如下：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/d6e9a59216b3877c93956f0227de65b3.png"/>
    </p>
    <ul>
     <li>
      N为索引中的全部文档数(可以理解为一篇文章的所有句子数)
     </li>
     <li>
      n(qi)为包含了qi的文档数(可以理解为word出现在了几个句子中的句子数量)
      <br/>
      hanlp中代码实现：
     </li>
    </ul>
    <pre><code>Map&lt;String, Double&gt; idf = new TreeMap&lt;String, Double&gt;();
idf.put(word, Math.log(D - freq + 0.5) - Math.log(freq + 0.5));
</code></pre>
    <p>
     根据IDF的定义可以看出，对于给定的文档集合，
     <code>
      包含了qi的文档数越多，qi的权重则越低
     </code>
     。也就是说，当很多文档都包含了qi时，qi的区分度就不高，因此使用qi来判断相关性时的重要度就较低。
    </p>
    <h6>
     <a id="Rqid_40">
     </a>
     R（qi，d）
    </h6>
    <p>
     语素qi与文档d的相关性得分R（qi，d）。首先来看BM25中相关性得分的一般形式：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/b53c7a7ae3ac10ffe16ade9afaf4e325.png"/>
    </p>
    <ul>
     <li>
      k1，k2，b为调节因子，通常根据经验设置，一般k1=2，b=0.75；
     </li>
     <li>
      fi为qi在d中的出现频率；（可以理解为每个word在文章中的词频）
     </li>
     <li>
      qfi为qi在Query中的出现频率;（可以理解为每个word在那句话中的词频）
     </li>
     <li>
      dl为文档d的长度;
     </li>
     <li>
      avgdl为所有文档的平均长度。
     </li>
    </ul>
    <p>
     不像 TF/IDF ，BM25 有一个比较好的特性就是它提供了两个可调参数：
    </p>
    <ul>
     <li>
      k1
      <br/>
      这个参数控制着词频结果在词频饱和度中的上升速度。默认值为 1.2 。值越小饱和度变化越快，值越大饱和度变化越慢。
     </li>
     <li>
      b
      <br/>
      这个参数控制着字段长归一值所起的作用， 0.0 会禁用归一化， 1.0 会启用完全归一化。默认值为 0.75 。
     </li>
    </ul>
    <p>
     由于绝大部分情况下，qi在Query中只会出现一次，即qfi=1，因此公式可以简化为：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/7aa607cbe4961ad6cb41aa6d0fea005b.png">
      <br/>
      从K的定义中可以看到，参数b的作用是调整文档长度对相关性影响的大小。
      <code>
       b越大，K值越小，文档长度的对相关性得分的影响越大，反之越小。而文档的相对长度越长，K值将越大，则相关性得分会越小
      </code>
      。这可以理解为，当文档较长时，包含qi的机会越大，因此，同等fi的情况下，长文档与qi的相关性应该比短文档与qi的相关性弱。
     </img>
    </p>
    <p>
     综上，BM25算法的相关性得分公式可总结为：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/2d14bb2ad83a82bf2dff17e84b0a8d60.png">
      <br/>
      hanlp中的计算代码：
     </img>
    </p>
    <pre><code>score =  (idf.get(word) * tf * (k1 + 1)  / (tf + k1 * (1 - b + b * d  / avgdl)))
</code></pre>
    <p>
     附录HanLP的BM25 算法的java实现代码 ：
    </p>
    <pre><code>public class BM25
{
    /**
     * 文档句子的个数
     */
    int D;

    /**
     * 文档句子的平均长度
     */
    double avgdl;

    /**
     * 拆分为[句子[单词]]形式的文档
     */
    List&lt;List&lt;String&gt;&gt; docs;

    /**
     * 文档中每个句子中的每个词与词频
     */
    Map&lt;String, Integer&gt;[] f;

    /**
     * 文档中全部词语与出现在几个句子中
     */
    Map&lt;String, Integer&gt; df;

    /**
     * IDF
     */
    Map&lt;String, Double&gt; idf;

    /**
     * 调节因子
     */
    final static float k1 = 1.5f;

    /**
     * 调节因子
     */
    final static float b = 0.75f;

    public BM25(List&lt;List&lt;String&gt;&gt; docs)
    {
        this.docs = docs;
        D = docs.size();
        for (List&lt;String&gt; sentence : docs)
        {
            avgdl += sentence.size();
        }
        avgdl /= D;
        f = new Map[D];
        df = new TreeMap&lt;String, Integer&gt;();
        idf = new TreeMap&lt;String, Double&gt;();
        init();
    }

    /**
     * 在构造时初始化自己的所有参数
     */
    private void init()
    {
        int index = 0;
        for (List&lt;String&gt; sentence : docs)
        {
            Map&lt;String, Integer&gt; tf = new TreeMap&lt;String, Integer&gt;();
            for (String word : sentence)
            {
                Integer freq = tf.get(word);
                freq = (freq == null ? 0 : freq) + 1;
                tf.put(word, freq);
            }
            f[index] = tf;
            for (Map.Entry&lt;String, Integer&gt; entry : tf.entrySet())
            {
                String word = entry.getKey();
                Integer freq = df.get(word);
                freq = (freq == null ? 0 : freq) + 1;
                df.put(word, freq);
            }
            ++index;
        }
        for (Map.Entry&lt;String, Integer&gt; entry : df.entrySet())
        {
            String word = entry.getKey();
            Integer freq = entry.getValue();
            idf.put(word, Math.log(D - freq + 0.5) - Math.log(freq + 0.5));
        }
    }

    /**
     * 计算一个句子与一个文档的BM25相似度
     *
     * @param sentence 句子（查询语句）
     * @param index    文档（用语料库中的下标表示）
     * @return BM25 score
     */
    public double sim(List&lt;String&gt; sentence, int index)
    {
        double score = 0;
        for (String word : sentence)
        {
            if (!f[index].containsKey(word)) continue;
            int d = docs.get(index).size();
            Integer tf = f[index].get(word);
            score += (idf.get(word) * tf * (k1 + 1)
                    / (tf + k1 * (1 - b + b * d
                                                / avgdl)));
        }

        return score;
    }

    public double[] simAll(List&lt;String&gt; sentence)
    {
        double[] scores = new double[D];
        for (int i = 0; i &lt; D; ++i)
        {
            scores[i] = sim(sentence, i);
        }
        return scores;
    }
}

</code></pre>
   </div>
   <link href="./../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="./../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f71715f3230393839313035:2f61727469636c652f64657461696c732f3935343630303033" class_="artid" style="display:none">
 </p>
</div>


