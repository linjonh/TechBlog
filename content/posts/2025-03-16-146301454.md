---
layout: post
title: "论文阅读Cross-View-Fusion-for-Multi-View-Clustering"
date: 2025-03-16 21:30:54 +0800
description: "多视图聚类近年来备受关注，因其能够利用多视图的一致性与互补性信息提升聚类性能。然而，如何有效融合多视图信息并平衡其一致性与互补性，是多视图聚类面临的共性挑战。现有方法多聚焦于加权求和融合或拼接融合，但这些方式难以充分融合潜在信息，且未考虑多视图一致性与互补性的平衡。为此，本文提出一种跨视图融合多视图聚类方法（CFMVC）。具体而言，CFMVC结合深度神经网络与图卷积网络实现跨视图信息融合，充分融合多视图的特征信息与结构信息。为平衡多视图的一致性与互补性，CFMVC通过增强同类样本间的相关性以。"
keywords: "【论文阅读】Cross-View Fusion for Multi-View Clustering"
categories: ['论文阅读', '深度学习', '数据挖掘']
tags: ['论文阅读', '聚类', '深度聚类', '深度学习', '数据挖掘', '多视图聚类', '人工智能']
artid: "146301454"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146301454
    alt: "论文阅读Cross-View-Fusion-for-Multi-View-Clustering"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146301454
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146301454
cover: https://bing.ee123.net/img/rand?artid=146301454
image: https://bing.ee123.net/img/rand?artid=146301454
img: https://bing.ee123.net/img/rand?artid=146301454
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     【论文阅读】Cross-View Fusion for Multi-View Clustering
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     <img alt="" height="334" src="https://i-blog.csdnimg.cn/direct/268ac9130949460189ae643a5c4b5aa5.png" width="1620"/>
    </p>
    <p>
     论文地址：
     <a href="https://ieeexplore.ieee.org/document/10833824" rel="nofollow" title="Cross-View Fusion for Multi-View Clustering | IEEE Journals &amp; Magazine | IEEE Xplore">
      Cross-View Fusion for Multi-View Clustering | IEEE Journals &amp; Magazine | IEEE Xplore
     </a>
    </p>
    <hr/>
    <h2>
     摘要
    </h2>
    <p>
     <strong>
      多视图聚类
     </strong>
     近年来备受关注，因其能够利用多视图的一致性与互补性信息提升聚类性能。然而，如何有效融合多视图信息并平衡其一致性与互补性，是多视图聚类面临的共性挑战。现有方法多聚焦于
     <strong>
      加权求和融合
     </strong>
     或
     <strong>
      拼接融合
     </strong>
     ，但这些方式难以充分融合潜在信息，且未考虑多视图一致性与互补性的平衡。为此，本文提出一种
     <strong>
      跨视图融合多视图聚类方法（CFMVC）
     </strong>
     。
     <br/>
     具体而言，CFMVC结合
     <strong>
      深度神经网络
     </strong>
     与
     <strong>
      图卷积网络
     </strong>
     实现跨视图信息融合，充分融合多视图的特征信息与结构信息。为平衡多视图的一致性与互补性，CFMVC通过增强同类样本间的相关性以
     <strong>
      最大化一致性信息
     </strong>
     ，同时强化不同样本间的独立性以
     <strong>
      最大化互补性信息
     </strong>
     。在多个多视图数据集上的实验表明，CFMVC在多视图聚类任务中具有显著有效性。
    </p>
    <h2>
     引言
    </h2>
    <p>
     <strong>
      多视图聚类
     </strong>
     （Multi-view Clustering, MVC）作为机器学习的新范式，旨在通过多视图联合学习提取有价值的语义信息[1]–[4]。传统MVC方法主要包括：
    </p>
    <ol>
     <li>
      <p>
       <strong>
        协同训练方法
       </strong>
       （如[5]–[7]），利用先验信息或视图间知识交互最大化视图一致性；
      </p>
     </li>
     <li>
      <p>
       <strong>
        多视图子空间聚类方法
       </strong>
       （如[8]–[11]），从多子空间或潜在空间学习统一表征；
      </p>
     </li>
     <li>
      <p>
       <strong>
        多视图图聚类方法
       </strong>
       （如[12]–[14]），学习跨视图的融合图结构。
       <br/>
       然而，传统方法存在
       <strong>
        表征能力弱
       </strong>
       、
       <strong>
        计算复杂度高
       </strong>
       的问题，导致聚类性能受限。
      </p>
     </li>
    </ol>
    <p>
     近年来，
     <strong>
      深度多视图聚类方法
     </strong>
     [15]–[20]凭借深度神经网络强大的特征表征与非线关系处理能力，可从多视图中学习高表达能力表征。例如：
    </p>
    <ul>
     <li>
      <p>
       [23]设计自适应特征金字塔网络，实现空间位置与通道间的平衡融合；
      </p>
     </li>
     <li>
      <p>
       [24]提出高效图推理模块，保持特征多样性以学习判别性描述；
      </p>
     </li>
     <li>
      <p>
       [25]结合拉普拉斯正则化与多样性策略，学习一致且多样的深度潜在表征；
      </p>
     </li>
     <li>
      <p>
       [26]利用带拉普拉斯正则的自编码器构建单视图相似图并提出融合策略。
      </p>
     </li>
    </ul>
    <p>
     尽管现有深度MVC方法取得显著进展，仍面临以下挑战：
    </p>
    <ol>
     <li>
      <p>
       <strong>
        融合策略局限
       </strong>
       ：主流方法依赖
       <strong>
        加权求和
       </strong>
       [15][16]或
       <strong>
        拼接融合
       </strong>
       [19][27]，难以充分融合多视图底层信息并获取紧凑公共表征；
      </p>
     </li>
     <li>
      <p>
       <strong>
        信息平衡缺失
       </strong>
       ：多数方法仅关注一致性或互补性最大化，未平衡二者关系[27][28]。
      </p>
     </li>
    </ol>
    <p>
     针对上述问题，本文提出
     <strong>
      跨视图融合多视图聚类方法（CFMVC）
     </strong>
     （见图1），其目标包括：
    </p>
    <ol>
     <li>
      <p>
       融合多视图特征与结构信息以获取丰富语义；
      </p>
     </li>
     <li>
      <p>
       有效平衡多视图一致性与互补性。具体实现如下：
      </p>
     </li>
    </ol>
    <ul>
     <li>
      <p>
       <strong>
        跨视图信息融合模块
       </strong>
       ：结合深度神经网络与图卷积网络，逐层提取视图特征后跨视图传播特征及结构信息；
      </p>
     </li>
     <li>
      <p>
       <strong>
        平衡特征融合模块
       </strong>
       ：基于冗余缩减原理[29]，通过增强同类样本相关性
       <strong>
        最大化一致性
       </strong>
       ，同时强化异类样本独立性
       <strong>
        最大化互补性
       </strong>
       。
      </p>
     </li>
    </ul>
    <p>
     本文主要贡献包括：
    </p>
    <ol>
     <li>
      <p>
       提出深度神经网络与图卷积网络结合的跨视图信息融合模块，充分融合多视图特征与结构信息；
      </p>
     </li>
     <li>
      <p>
       设计平衡特征融合模块，通过协调一致性与互补性获取紧凑且判别性强的公共表征；
      </p>
     </li>
     <li>
      <p>
       提出新型多视图融合策略，在多视图融合与信息平衡中表现优异。实验证明CFMVC在多视图聚类任务中具有显著有效性。
      </p>
     </li>
    </ol>
    <h2>
     模型
    </h2>
    <p>
     <img alt="" height="734" src="https://i-blog.csdnimg.cn/direct/18b4552bcd6b4b4fa862ffd0122e30c2.png" width="800"/>
    </p>
    <p>
     <strong>
      所提出的CFMVC框架
     </strong>
     包含三个核心模块：
     <strong>
      跨视图信息融合
     </strong>
     、
     <strong>
      平衡特征融合
     </strong>
     与
     <strong>
      自训练聚类
     </strong>
     。其总体损失函数定义为：
    </p>
    <p>
     𝐿=𝐿𝑟𝑒𝑐+𝜆1𝐿𝑏𝑓𝑓+𝜆2𝐿𝑐𝑙𝑢
    </p>
    <p>
     其中：
    </p>
    <ul>
     <li>
      <p>
       𝐿𝑟𝑒𝑐为
       <strong>
        重构损失
       </strong>
       ，用于约束数据重建精度；
      </p>
     </li>
     <li>
      <p>
       𝐿𝑏𝑓𝑓为
       <strong>
        平衡特征融合模块的损失
       </strong>
       ，用于协调多视图一致性与互补性信息；
      </p>
     </li>
     <li>
      <p>
       𝐿𝑐𝑙𝑢为
       <strong>
        聚类损失
       </strong>
       ，优化聚类目标；
      </p>
     </li>
     <li>
      <p>
       𝜆1​ 与 𝜆2为权衡参数，调节不同损失的贡献权重。
      </p>
     </li>
    </ul>
    <hr/>
    <h4>
     <strong>
      A. 跨视图信息融合模块（CIF）
     </strong>
    </h4>
    <p>
     本模块旨在通过融合多视图的
     <strong>
      特征信息
     </strong>
     与
     <strong>
      结构信息
     </strong>
     ，生成富含语义的跨视图融合表征。具体流程如下：
    </p>
    <h5>
     <strong>
      1. 结构信息提取
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       基于原始数据 𝑋𝑚，采用
       <strong>
        K近邻（KNN）方法
       </strong>
       构建邻接矩阵 𝐴𝑚：
      </p>
      <ul>
       <li>
        <p>
         计算样本间相似度
         <img alt="" height="48" src="https://i-blog.csdnimg.cn/direct/446b347f33d94ad4ac7174cf9351543d.png" width="218">
          ，选择相似度最高的 𝑘 个样本作为邻居节点；
         </img>
        </p>
       </li>
       <li>
        <p>
         构建KNN图并生成邻接矩阵 𝐴𝑚。
        </p>
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <strong>
      2. 特征信息提取
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       使用自编码器（Autoencoder）逐层提取视图特征：
      </p>
      <ul>
       <li>
        <p>
         编码器第 𝑙 层特征表示为 𝐻(𝑚,𝑙)=𝐸𝑚(𝑋𝑚;𝜃𝑒𝑚)，捕获层级特异性信息；
        </p>
       </li>
       <li>
        <p>
         解码器重建数据 𝑋^𝑚=𝐷𝑚(𝐻(𝑚,𝑙);𝜃𝑑𝑚)，重构损失定义为：
        </p>
       </li>
      </ul>
      <img alt="" height="138" src="https://i-blog.csdnimg.cn/direct/7708c1c3a37e4fd38f84e10ecab8c8ca.png" width="796"/>
     </li>
    </ul>
    <h5>
     <strong>
      3. 跨视图信息传递
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        结构信息融合
       </strong>
       ：融合双视图的邻接矩阵（含自连接 𝐴~𝑚=𝐴𝑚+𝐼）以增强全局结构表征：
      </p>
      <img alt="" height="64" src="https://i-blog.csdnimg.cn/direct/e0813713b8b7404ab579197139a2e76d.png" width="542"/>
     </li>
     <li>
      <p>
       <strong>
        特征信息融合
       </strong>
       ：将自编码器第 𝑙 层特征 𝐻(𝑚,𝑙)与图卷积网络（GCN）的层级表示 𝑍(𝑙) 结合：
      </p>
      <img alt="" height="74" src="https://i-blog.csdnimg.cn/direct/ab0ff1756b8d4257b0bc728ea60ef42d.png" width="592">
       <p>
        其中 𝛼为
        <strong>
         传递算子
        </strong>
        ，用于耦合自编码器与GCN。
       </p>
      </img>
     </li>
    </ul>
    <h5>
     <strong>
      4. 层级传播与对称融合
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       融合后的邻接矩阵 𝐴^与特征表示 𝑍~(𝑙) 输入至下一层GCN：
      </p>
      <img alt="" height="80" src="https://i-blog.csdnimg.cn/direct/b6b6aee659d84495a5ad8d998763db91.png" width="650">
       <p>
        其中 𝜎为激活函数，𝐷~ 为度矩阵，𝑊 为可训练权重。
       </p>
      </img>
     </li>
     <li>
      <p>
       <strong>
        对称输出
       </strong>
       ：以双视图互为输入进行对称融合，最终输出跨视图融合表征 𝑍1与 𝑍2。
      </p>
     </li>
    </ul>
    <h4>
     <strong>
      B. 平衡特征融合模块
     </strong>
    </h4>
    <p>
     受文献[29]启发，本文扩展
     <strong>
      冗余缩减原理
     </strong>
     以平衡多视图的
     <strong>
      一致性
     </strong>
     与
     <strong>
      互补性
     </strong>
     信息。具体实现如下：
    </p>
    <ol>
     <li>
      <p>
       <strong>
        样本相关性计算
       </strong>
       <br/>
       计算跨视图融合表征 𝑍1​ 与 𝑍2 的
       <strong>
        样本相关性矩阵
       </strong>
       𝐶∈𝑅𝑛×𝑛：​​​​​​​
       <img alt="" height="110" src="https://i-blog.csdnimg.cn/direct/d871e4d634214616ae75a8163f88fd3b.png" width="650">
        其中 𝐶𝑖𝑗表示 𝑍1​ 中第 𝑖 个样本与 𝑍2​ 中第 𝑗个样本的
        <strong>
         余弦相似度
        </strong>
        。
       </img>
      </p>
     </li>
     <li>
      <p>
       <strong>
        平衡损失函数
       </strong>
       <br/>
       通过优化目标使相关性矩阵 𝐶 逼近单位矩阵 𝐼：
      </p>
      <img alt="" height="102" src="https://i-blog.csdnimg.cn/direct/88b4fc9bda3240aebd81f93bdcaec98b.png" width="760">
       <ul>
        <li>
         <p>
          <strong>
           第一项
          </strong>
          ：强制对角元素 𝐶𝑖𝑖→1，通过
          <strong>
           最大化同类样本相似度
          </strong>
          增强视图间一致性；
         </p>
        </li>
        <li>
         <p>
          <strong>
           第二项
          </strong>
          ：强制非对角元素 𝐶𝑖𝑗→0，通过
          <strong>
           最小化异类样本相似度
          </strong>
          提升视图间互补性。
         </p>
        </li>
       </ul>
      </img>
     </li>
     <li>
      <p>
       <strong>
        公共表征生成
       </strong>
       <br/>
       线性融合 𝑍1​ 与 𝑍2​ 得到平衡后的公共表征：
      </p>
      <img alt="" height="100" src="https://i-blog.csdnimg.cn/direct/f279849512434fbcabe830686a77adff.png" width="514"/>
     </li>
    </ol>
    <hr/>
    <h4>
     <strong>
      C. 自训练聚类模块
     </strong>
    </h4>
    <p>
     为构建
     <strong>
      聚类友好空间
     </strong>
     ，基于KL散度设计聚类损失函数：
    </p>
    <ol>
     <li>
      <p>
       <strong>
        软分配概率
       </strong>
       <br/>
       采用
       <strong>
        学生t分布
       </strong>
       度量样本 𝑧𝑖zi​ 与聚类中心 𝜇𝑗的相似性：
      </p>
      <img alt="" height="144" src="https://i-blog.csdnimg.cn/direct/e86e679bc7664fd296fcd2ad436a3e0b.png" width="650"/>
     </li>
     <li>
      <p>
       <strong>
        目标分布优化
       </strong>
       <br/>
       通过
       <strong>
        高频增强策略
       </strong>
       生成辅助目标分布 𝑝𝑖𝑗：
      </p>
      <img alt="" height="116" src="https://i-blog.csdnimg.cn/direct/01bfd666f21540e784eee66133732945.png" width="536"/>
     </li>
     <li>
      <p>
       <strong>
        KL散度损失
       </strong>
       <br/>
       通过最小化 𝑝𝑖𝑗 与 𝑞𝑖𝑗的KL散度优化聚类：
      </p>
      <img alt="" height="104" src="https://i-blog.csdnimg.cn/direct/c73ad3d68dab4232b45e84b9d641cf2f.png" width="684"/>
      <p>
       此过程迫使样本向聚类中心紧致聚集，最终获得适合聚类的公共表征。
      </p>
     </li>
    </ol>
    <h2>
     实验
    </h2>
    <p>
     <img alt="" height="514" src="https://i-blog.csdnimg.cn/direct/6dcff9afe65c47ab8bfe57d266b25626.png" width="1490"/>
    </p>
    <hr/>
    <p>
     从跨视图的角度出发解决视图信息融合问题。
    </p>
    <p>
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f64756e64756e6d6d2f:61727469636c652f64657461696c732f313436333031343534" class_="artid" style="display:none">
 </p>
</div>


