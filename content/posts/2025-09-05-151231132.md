---
layout: post
title: "分布式专题1.1-Redis单机主从哨兵集群部署"
date: 2025-09-05T21:27:49+0800
description: "Redis 部署（单机、主从、哨兵、集群）、文件目录、配置文件"
keywords: "分布式专题——1.1 Redis单机、主从、哨兵、集群部署"
categories: ['分布式专题']
tags: ['架构', '数据库', '分布式', 'Redis', 'Java']
artid: "151231132"
arturl: "https://blog.csdn.net/kongbaidemumu/article/details/151231132"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=151231132
    alt: "分布式专题1.1-Redis单机主从哨兵集群部署"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=151231132
featuredImagePreview: https://bing.ee123.net/img/rand?artid=151231132
cover: https://bing.ee123.net/img/rand?artid=151231132
image: https://bing.ee123.net/img/rand?artid=151231132
img: https://bing.ee123.net/img/rand?artid=151231132
---



# 分布式专题——1.1 Redis单机、主从、哨兵、集群部署


[#『Java分布式系统开发：从理论到实践』征文活动#](https://activity.csdn.net/writing?id=10939)

## 1 Redis 部署

* 下面演示在 Linux 环境下部署 Redis7。

### 1.1 单机部署

#### 1.1.1 检查安装 gcc 环境

* Redis 是由 C 语言编写的，它的运行需要 C 环境，因此我们需要先安装 gcc；

  ```cmd
  # 关闭防⽕墙
  systemctl stop firewalld.service
  # 查看防火墙状态
  firewall-cmd --state
  # 卸载防⽕墙
  yum remove firewalld
  # 检查版本
  gcc --version
  # 安装 gcc
  yum install gcc

  ```

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/8e0a64989b45443c93be74628a3e2b3a.png)

#### 1.1.2 下载安装 Redis

```cmd
# 安装应⽤养成良好习惯，⽂件归类
mkdir -p /opt/software/redis

# 进⼊redis⽂件夹，使⽤wget下载
cd /opt/software/redis
wget https://download.redis.io/redis-stable.tar.gz

# 解压下载的redis包
tar -xzf redis-stable.tar.gz
# 进⼊redis-stable⽬录
cd redis-stable
# 使⽤ make install 编译并安装
make install
# 安装完成后 /usr/local/bin 会⽣成相应的服务，检查是否成功⽣成
ll /usr/local/bin

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/8306c957d1a0453390002f787a256799.png)

* redis-benchmark：性能测试⼯具
* redis-check-aof：修复有问题的 AOF 文件
* redis-check-rdb：修复有问题的 RDB 文件
* redis-sentinel：Redis 集群使用
* redis-server：Redis 服务器启动命令
* redis-cli：客户端，操作入口

#### 1.1.3 启动 Redis

* 接下来就可以用`/opt/software/redis/redis-stable/src`或`/usr/local/bin`目录下的`redis-server`启动 Redis 服务了：

  ```cmd
  # Redis 源码路径下启动
  ./src/redis-server
  # 或者在 usr/local/bin 路径下启动
  redis-server

  ```

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/2259772f0a0346dc842d1763c3e398a3.png)

#### 1.1.4 配置 Redis

* 前面的启动方式无法再后台运行，退出之后会直接关闭 Redis 服务，所以还需要针对 Redis 做一些设置：

  ```cmd
  # 修改当前⽬录下的 reids.conf ⽂件
  vim redis.conf

  ```

  + 如果使用`vim`指令打开后没有行号，可以在打开后输入`:set number`；
* 需要修改的内容如下：

  ```properties
  # 87⾏，修改bin，* -::*表示⽀持远程连接
  bind * -::*
  # 309⾏，开启守护进程，后台运⾏
  daemonize yes
  # 355⾏，指定⽇志⽂件⽬录
  logfile /opt/software/redis/redis-stable/redis.log
  # 510⾏，指定⼯作⽬录
  dir /opt/software/redis
  # 1044⾏，给默认⽤户设置密码，主要是使⽤ redis-cli 连接 redis-server 时，需要通过密码校验
  requirepass 13shi@San
  # 111⾏，允许远程连接 如果不设置密码必须将此设置关闭
  protected-mode no

  ```
* 修改完成后，使用配置文件启动 Redis，并使用`redis-cli`指令测试连接，由于在配置文件中配置了安全密码，所以连接后需要先验证密码，否则会报错；

  ```cmd
  redis-server redis.conf
  redis-cli
  auth 13shi@San

  ```

#### 1.1.5 退出或关闭 Redis

```cmd
# 退出Redis
quit
# 关闭Redis
redis-cli shutdown

```

### 1.2 主从部署（Master-Slave Replication）

#### 1.2.1 简介

* 主从复制，是指将⼀台 Redis 服务器的数据，复制到其他的 Redis 服务器；

  + 前者称为主节点（Master），后者称为从节点（Slave）；
  + 数据的复制是单向的，只能由主节点到从节点；
  + ⼀个主节点可以有多个从节点（或没有从节点），但⼀个从节点只能有⼀个主节点；

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/ed47488ed6f145b2816660a6d06377e5.png)
* 作用：

  + 数据冗余：主从复制实现了数据的热备份，是持久化之外的⼀种数据冗余方式；
  + 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；
  + 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写 Redis 数据时应用去连接主节点，读 Redis 数据时应用去连接从节点），分担服务器负载。尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高 Redis 服务器的并发量；
  + 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是 Redis 高可用的基础。

#### 1.2.2 部署实现

* 整体架构图：

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4c8349efc39f4602b32ea14308c0d86e.png)
* 主节点不需要做任何改变，从节点都需要修改配置加上主节点信息；

  ```properties
  # 添加主节点信息
  replicaof 192.168.75.129 6379

  ```

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6a4a519e7fd14a15ba02fcb2282b8fd8.png)
* 配置完成后，可以从主节点查看从节点信息；

  ```cmd
  # 主节点查看从节点信息
  info Replication

  ```

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a07913eccc6543269b266d7deabdd599.png)

#### 1.2.3 缺点

* **复制延时，信号衰减**。由于所有的写操作都是先在 master 上操作，然后同步更新到 slave 上，所以从 master 同步到 slave 机器上有⼀定的延迟，当系统很繁忙的时候，延迟问题会更加严重，slave 机器数量的增加也会使这个问题更加严重；
* **master挂了如何办？**默认情况下，需要人工干预。

### 1.3 哨兵部署（Sentinel）

* Redis 的主从复制主要用于实现数据的冗余备份和读分担，并没有提供高可用性。因此在系统高可用方面，单纯的主从架构无法很好地保证整个系统高可用。

#### 1.3.1 原理

* Redis 哨兵模式是通过在独立的哨兵节点上运行特定的哨兵进程来实现的。这些哨兵进程监控主从节点的状态，并在发现故障时自动完成故障发现和转移，并通知应用方，实现高可用性；

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b87fb8ef753e4a4983d9cb1e6119f06f.png)

#### 1.3.2 哨兵

* 在启动时，每个哨兵节点会执行选举过程，其中⼀个哨兵节点被选为领导者（leader），负责协调其他哨兵节点；
* **Leader 选举过程**：
  + 每个在线的哨兵节点都可以成为领导者，每个哨兵节点会向其它哨兵发`is-master-down-by-addr`命令，征求判断并要求将自己设置为领导者；
  + 当其它哨兵收到此命令时，可以同意或者拒绝它成为领导者；如果哨兵发现自己的得票数`>= num(sentinels)/2+1`时，将成为领导者，如果没有超过，继续选举；
* **监控主从节点**：哨兵节点通过发送命令周期性地检查主从节点的健康状态，包括主节点是否在线、从节点是否同步等。如果哨兵节点发现主节点不可用，它会触发⼀次故障转移；
* **故障转移**：⼀旦主节点被判定为不可用，哨兵节点会执行故障转移操作。它会从当前的从节点中选出一个新的主节点，并将其他从节点切换到新的主节点。这样，系统可以继续提供服务而无需人工介入；
* **故障转移过程**：由 Sentinel 节点定期监控发现主节点是否出现了故障，Sentinel 会向 master 发送心跳 PING 来确认 master 是否存活，如果 master 在“⼀定时间范围”内不回应 PONG 或者是回复了⼀个错误消息，那么这个 Sentinel 节点会主观地（单方面地）认为这个 master 已经不可用了；
* **确认主节点**：
  + 过滤掉不健康的（下线或断线）
  + 没有回复哨兵 PING 响应的从节点
  + 选择从节点优先级最高的
  + 选择复制偏移量最大，偏移量大代表该从节点的数据与主节点同步得最完整
  + 当主节点出现故障， 由领导者负责处理主节点的故障转移
* **客户端重定向**：哨兵节点会通知客户端新主节点的位置，使其能够与新的主节点建立连接并发送请求。这确保了客户端可以无缝切换到新的主节点，继续进行操作；
* 此外，哨兵节点还负责监控从节点的状态。如果从节点出现故障，哨兵节点可以将其下线，并在从节点恢复正常后重新将其加入集群。

#### 1.3.3 主观下线 VS 可观下线

* 当一个主节点下线被其监控的哨兵节点发现时，该哨兵节点会主观认为该主节点下线了，这就是**主观下线**了；
* 随后哨兵节点会通过指令`sentinel is-masterdown-by-addr`寻求其它哨兵节点对该主节点的判断（即“询问其它哨兵节点是否检测到该主节点下线了”），若认为该主节点下线的哨兵节点超过`quorum`（选举）个数，此时就可以认为该主节点确实有问题，这就是**客观下线**。

#### 1.3.4 部署实现&故障模拟

* 整体架构图：

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4ff7279a339947c49e211cc63a946338.png)
* 3 个机器都需要修改`sentinel.conf`配置，配置完成之后先从主节点开始启动哨兵；

  ```properties
  # 6⾏，关闭保护模式
  protected-mode no
  # 15⾏，指定sentinel为后台启动
  daemonize yes
  # 34⾏，指定⽇志存放路径
  logfile /opt/software/redis/redis-stable/sentinel.log
   # 73⾏，指定数据库存放路径
  dir /opt/software/redis 
  # 93⾏，指定该哨兵节点监控192.168.75.129:6379这个主节点，该主节点的名称是mymaster，2表示⾄少需要2个哨兵节点同意，才能判定主节点故障并进⾏故障转移
  sentinel monitor mymaster 192.168.75.129 6379 2
  # 134⾏，判定服务器下线的时间周期，默认30000毫秒（30秒）
  sentinel down-after-milliseconds mymaster 30000
  # 234⾏，故障节点的最⼤超时时间为180000（180秒）
  sentinel failover-timeout mymaster 180000 

  ```
* 启动后检查哨兵状态：

  ```cmd
  redis-cli -p 26379 info sentinel

  ```
* 故障模拟：

  ```cmd
  # 在ip地址结尾为129的机器上杀掉主节点的进程
  ps aux | grep redis
  # 也可以用 redis-cli shutdown 直接停掉主节点服务

  ```

  ```cmd
  # 观察哨兵⽇志，129 主节点下线，重新选举131为主节点
  tail -f sentinel.log

  ```

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/f7402104d7c24d27bab27c164a087908.png)

  ```cmd
  # 重新启动 129 服务 并观察⽇志：129 加⼊主从，此时主节点为131服务
  redis-server redis.conf
  tail -f sentinel.log
  redis-cli -p 26379 info sentinel
  # 观察哨兵⽇志
  tail -f sentinel.log

  ```

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/764381a767834295a90934c3da60f5af.png)

  ```cmd
  # 在ip地址结尾为131的机器上查看Redis状态，可以发现其已经成为了主节点
  redis-cli info replication

  ```

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/1e05723e3aa14ece83c8ac0b7a47fe4d.png)
* 当触发了哨兵选举之后，其会在后台更改`redis.conf`与`sentinel.conf`，可以检查每台机器的文件末尾的数据：

  ```cmd
  cat redis.conf
  cat sentinel.conf

  ```

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/432516adadd34cf5983f26798ad19053.png)

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/8de0aa2473c74bb3959fd7e59bf6c22c.png)

#### 1.3.5 使用建议

* 哨兵节点的数量应为多个，哨兵本身应该集群，保证⾼可⽤
* 哨兵节点数应该是奇数
* 各个哨兵结点的配置应⼀致
* 如果哨兵节点部署在 Docker 等容器里面，尤其要注意端口号的正确映射

#### 1.3.6 缺点：无法保证数据零丢失

* **复制延迟**：在主从复制中，从节点的数据是从主节点异步复制过来的。这意味着在主节点故障时，从节点可能还没有完全同步导最新的数据，从而导致数据丢失；
* **故障检测和转移时间**：Sentinel 检测到主节点故障并执行故障转移需要⼀定的时间。在这段时间内，主节点可能已经接收了⼀些写操作，但这些操作尚未被复制到从节点；
* **网络分区**：在发生网络分区（网络分裂）的情况下，一部分从节点可能与主节点失去联系。如果此时主节点继续处理写操作，那么在网络恢复之前，这些操作可能不会被复制到从节点；
* **多个从节点同时故障**：如果所有的从节点同时故障或在故障转移之前与主节点失联，那么在主节点故障时，将没有可用的从节点来提升为主节点。

### 1.4 集群部署（Cluster）

#### 1.4.1 简介

* Redis 集群是 Redis 的⼀种分布式运行模式，它通过分片（sharding）来提供数据的自动分区和管理，从而实现数据的高可用性和可扩展性；
* 在集群模式下，数据被分割成多个部分（称为**槽**或 Slots），分布在多个 Redis 节点上；
* 集群中的节点分为主节点和从节点：主节点负责读写请求和集群信息的维护，从节点只进行主节点数据和状态信息的复制；
* **数据分区**：

  + 数据分区（或称数据分片）是集群最核心的功能。 集群将数据分散到多个节点，一方面突破了 Redis 单机内存大小的限制，存储容量大大增加；
  + 另⼀方面每个主节点都可以对外提供读服务和写服务，大大提高了集群的响应能力；
  + 例如：

    - 如果单机内存太大，`bgsave`和`bgrewriteaof`的 fork 操作可能导致主进程阻塞；

      > Redis 的主工作线程是**单线程**的。这意味着任何阻塞主线程的操作都会导致整个实例暂时无法处理请求；
      >
      > * **bgsave**：用于在后台创建当前数据的 RDB 快照（持久化到磁盘）；
      > * **bgrewriteaof**：用于在后台重写 AOF 日志文件，以优化和压缩它；
      >
      > 这两个命令都带有 `bg` (background) 前缀，意味着 Redis 会尝试在后台执行它们，以避免阻塞主线程。其工作流程是：
      >
      > 1. 主进程调用 `fork()` 系统调用，创建一个**子进程**；
      > 2. 这个子进程拥有主进程**此时刻**内存数据的完整副本；
      > 3. 子进程负责将数据写入磁盘（RDB或AOF），而主进程继续处理客户端请求；
      >
      > **问题出在 `fork()` 这一步：**
      >
      > * 在操作系统中，`fork()` 系统调用在正常情况下是高效的，因为它使用了**写时复制（Copy-On-Write, COW）** 机制。子进程与父进程共享内存页，只有当父进程（Redis主进程）或子进程修改了某一块数据时，操作系统才会真正复制那一块内存；
      > * 但是，**当单机内存非常大时（例如几百GB），`fork()` 操作本身可能会非常耗时**。因为即使有写时复制，内核也需要为子进程创建完整的页表（page tables）来映射所有这些内存。这是一个与总内存量相关的 O(n) 操作；
      > * 这个创建页表的过程会**阻塞** Redis 的主进程。内存越大，阻塞的时间就越长（可能达到秒级甚至更久）。在这期间，Redis 无法处理任何请求，导致服务中断；
    - 主从环境下，进行主机切换时可能导致从节点长时间无法提供服务；

      > 假设主节点（Master）宕机了，哨兵（Sentinel）或集群模式会自动将一个从节点（Slave）提升为新的主节点，其他从节点需要转而从**这个新的主节点**进行数据同步；
      >
      > **问题在于第一次同步（全量复制）：**当一个从节点需要与新的主节点同步时，如果它本身没有数据或者数据差距太大，它需要执行一次**全量复制**：
      >
      > 1. 新的主节点会为自己当前的数据创建一个 RDB 快照（这就会触发一次 `bgsave`）；
      > 2. 正如第一个问题所述，如果新主节点的内存很大，这次 `fork` 可能耗时很长，导致**新主节点自身在创建RDB期间服务不稳定**；
      > 3. 更重要的是，**从节点**在接收和加载这个巨大的 RDB 文件时，整个过程是阻塞的。它会先清空自身旧数据，然后将 RDB 文件全部加载到内存。这个过程非常耗时，且在此期间**从节点无法对外提供任何读服务**（因为它的数据是旧的且不一致的）；
      >
      > 所以，“从节点长时间无法提供服务”指的是它在全量同步新数据的过程中处于不可用状态；
    - 在全量复制场景下主节点的复制可能会造成缓冲区溢出；

      > 主节点在通过 `bgsave` 生成 RDB 文件并将其发送给从节点的同时，**主节点自身还在持续不断地处理新的客户端写请求**；
      >
      > 为了保证数据一致性，从节点在加载 RDB 文件期间，主节点需要将这段时间内产生的**所有新写命令**都缓存起来。这个缓存区域就是**复制缓冲区（Replication Buffer）**；
      >
      > 当从节点加载完 RDB 文件后，主节点会再将复制缓冲区里积压的命令发送给从节点，从节点执行这些命令后，就能追赶上主节点的最新状态；
      >
      > **问题在于：**
      >
      > * 如果 RDB 文件非常大（因为内存大），传输和加载耗时就很长；
      > * 在这段漫长的时间里，如果主节点的写请求非常频繁（高写入负载），复制缓冲区可能会被迅速填满；
      > * 一旦复制缓冲区被写满，主节点会**断开与从节点的复制连接**。这将导致全量复制失败，从节点可能需要重新尝试连接并再次开始全量复制过程，从而陷入一个恶性循环；
* **高可用**：集群支持主从复制和主节点的自动故障转移（与哨兵类似），当任⼀节点发生故障时，集群仍然可以对外提供服务。

#### 1.4.2 哈希槽

* Redis 集群引入了**哈希槽**的概念；
* Redis 集群有16384 个哈希槽（编号0-16383），集群的每个节点负责⼀部分哈希槽；
* 每个 Key 通过 CRC16 校验后对 16384 取余，会得到一个值，根据该值来决定这个 Key 会被放置到哪个哈希槽。也可以通过这个值，找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作；
* 以 3 个节点组成的集群为例：
  + 节点 A 包含 0 到 5460 号哈希槽节点，B 包含 5461 到 10922 号哈希槽节点，C 包含 10923 到 16383 号哈希槽；
  + Redis 集群的主从复制模型集群中有上面这 A、B、C 三个节点，如果节点 B 下线了，整个集群就会因缺少 5461-10922 这个范围的槽而不可使用；
  + 为每个节点各添加⼀个从节点 A1、B1、C1，此时整个集群便有三个 master 节点和三个 slave 节点；
  + 节点 B 下线后，集群选举 B1 为主节点继续服务。当 B 和 B1 都下线后，集群将不可用。

#### 1.4.3 部署实现

##### 1.4.3.1 环境简述

* Redis Cluster 被配置为三主三从模式。这意味着每台服务器上的两个 Redis 节点中，⼀个节点作为主库（master），另⼀个作为从库（slave）；

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/1f9dad250f5b4e16b812bec97295bf24.png)

##### 1.4.3.2 Redis 集群配置准备

```cmd
# 创建集群配置文件夹（3台机器都是一样的操作）
mkdir -p /opt/software/redis/redis-stable/cluster
mkdir -p /opt/software/redis/cluster
vim ./cluster/redis_6379.conf
vim ./cluster/redis_6380.conf

# 启动 Redis 服务相关
redis-server ./cluster/redis_6379.conf
redis-server ./cluster/redis_6380.conf

# 检查服务
ps aux | grep redis

# 创建三主三从集群模式，每一个主节点带一个从节点
redis-cli --cluster create --cluster-replicas 1 192.168.75.129:6379 192.168.75.129:6380 192.168.75.131:6379 192.168.75.131:6380 192.168.75.132:6379 192.168.75.132:6380

# 查看集群信息
redis-cli cluster info

# 查看单个节点信息
redis-cli info replication

# 查看集群节点身份信息
redis-cli cluster nodes

# 停止redis服务
redis-cli -p 6379 shutdown
redis-cli -p 6380 shutdown

```

* 6379（即每台机器的主节点）配置：

  ```cmd
  # 允许所有的IP地址
  bind * -::*
  # 后台运行
  daemonize yes
  # 允许远程连接
  protected-mode no
  # 开启集群模式
  cluster-enabled yes
  # 集群节点超时时间
  cluster-node-timeout 5000
  # 配置数据存储目录
  dir "/opt/software/redis/cluster"
  # 开启AOF持久化
  appendonly yes

  # 端口
  port 6379
  # log日志
  logfile "/opt/software/redis/redis-stable/cluster/redis6379.log"
  # 集群配置文件
  cluster-config-file nodes-6379.conf
  # AOF文件名
  appendfilename "appendonly6379.aof"
  # RBD文件名
  dbfilename "dump6379.rdb"

  ```
* 6380（即每台机器的从节点）配置：

  ```cmd
  # 允许所有的IP地址
  bind * -::*
  # 后台运行
  daemonize yes
  # 允许远程连接
  protected-mode no
  # 开启集群模式
  cluster-enabled yes
  # 集群节点超时时间
  cluster-node-timeout 5000
  # 配置数据存储目录
  dir "/opt/software/redis/cluster"
  # 开启AOF持久化
  appendonly yes

  # 端口
  port 6380
  # log日志
  logfile "/opt/software/redis/redis-stable/cluster/redis6380.log"
  # 集群配置文件
  cluster-config-file nodes-6380.conf
  # AOF文件名
  appendfilename "appendonly6380.aof"
  # RBD文件名
  dbfilename "dump6380.rdb"

  ```
* 每台重启 Redis：

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/fb6f4b0f38d145379a0cb34d4a321d9f.png)
* 再次执行创建三主三从集群模式：

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b671b6a89186408995cd849e61ca7ad3.png)

##### 1.4.3.3 Redis 集群数据读写

* 在 131:6379 的主节点进行写数据。直接连接读写可能会出现以下问题，因为不同节点的槽位不同，返回的结果就提示我们要去 132:6379 进行写入数据；

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/9fbd96e8a8ef4efaa5480b55b605d616.png)
* 不过也可以开启路由规则，给`redis-cli`加上`-c`：

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/f4e6fe2990d34c7c9eef20ece55a95f4.png)

##### 1.4.3.4 模拟故障转移

```cmd
# 将 129 机器的主节点下线
redis-cli -p 6379 shutdown
# 查看 129 机器从节点的⼯作⽇志，131:6380节点被选举为主节点
cat redis6380.log

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e4b66456b09f481e907e37031dc635b7.png)

```cmd
# 再切换到132机器上查看当前集群节点信息，131:6380已经升为主节点
redis-cli cluster nodes

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/335158cb53fa431bb86ec86ef59fed06.png)

```cmd
# 再重新启动129.6379服务
redis-server ./cluster/redis_6379.conf
# 查看129.6379的节点信息，其变为了从节点
redis-cli -p 6379 info replication

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/0ad17f24d1be4c108efab075326f08ed.png)

```cmd
# 再到131.6380机器上查看⽇志，129.6379重新加⼊集群
cat redis6380.log

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/11ed014ed9c84d7b9ed99c53d32ff2a4.png)

## 2 文件目录

* 手动创建：

  ```cmd
  # Redis应⽤
  /opt/software/redis/
  # Redis应⽤根⽬录
  /opt/software/redis/redis-stable
  # Redis集群应⽤⽂件⽬录（⽇志，快照等信息）
  /opt/software/redis/cluster
  # Redis集群配置⽂件存放路径
  /opt/software/redis/redis-stable/cluster

  ```

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e39ec328aa4444e296a53129c7ec0d79.png)

## 3 配置文件

### 3.1 单机部署配置

* 所在目录：`/opt/software/redis/redis-stable`

  ```properties
  # 绑定所有可用网络接口（IPv4和IPv6），允许来自任何地址的连接
  bind * -::*

  # 禁用保护模式，允许远程连接（生产环境建议启用并配置密码）
  protected-mode no

  # 设置Redis服务监听端口为6379（默认端口）
  port 6379

  # TCP连接队列长度，高并发场景可适当调高
  tcp-backlog 511

  # 客户端空闲超时时间（秒），0表示永不超时
  timeout 0

  # TCP keepalive间隔时间（秒），用于检测死连接
  tcp-keepalive 300

  # 以守护进程方式运行（后台运行）
  daemonize yes

  # 进程ID文件存储路径
  pidfile /var/run/redis_6379.pid

  # 日志级别：notice（生产环境推荐）
  loglevel notice

  # 日志文件输出路径
  logfile /opt/software/redis/redis-stable/redis.log

  # 设置数据库数量（默认16个，编号0-15）
  databases 16

  # 启动时不显示Redis logo
  always-show-logo no

  # 启用进程标题设置
  set-proc-title yes

  # 进程标题格式：包含服务名、监听地址和模式
  proc-title-template "{title} {listen-addr} {server-mode}"

  # 设置空字符串使用默认字节比较排序
  locale-collate ""

  # RDB保存失败时停止写入操作（确保数据一致性）
  stop-writes-on-bgsave-error yes

  # RDB文件启用压缩（节省磁盘空间）
  rdbcompression yes

  # RDB文件启用CRC64校验和（数据完整性检查）
  rdbchecksum yes

  # RDB持久化数据文件名
  dbfilename dump.rdb

  # 主从同步时不删除RDB文件
  rdb-del-sync-files no

  # 工作目录（持久化文件和日志存放路径）
  dir /opt/software/redis

  # 从节点在与主节点失联时继续响应旧数据
  replica-serve-stale-data yes

  # 从节点默认只读（防止数据不一致）
  replica-read-only yes

  # 启用无盘复制（主节点直接通过socket发送RDB到从节点）
  repl-diskless-sync yes

  # 无盘复制等待时间（秒），等待更多从节点连接
  repl-diskless-sync-delay 5

  # 无盘复制最大从节点数量（0表示无限制）
  repl-diskless-sync-max-replicas 0

  # 禁用TCP_NODELAY（启用后减少复制延迟但增加带宽）
  repl-disable-tcp-nodelay no

  # 从节点优先级（哨兵选主时使用，值越小优先级越高）
  replica-priority 100

  # ACL日志最大长度（记录认证相关事件）
  acllog-max-len 128

  # 内存满时是否异步驱逐Key（避免阻塞）
  lazyfree-lazy-eviction no

  # 过期Key是否异步删除
  lazyfree-lazy-expire no

  # 服务删除Key时是否异步处理（如RENAME命令）
  lazyfree-lazy-server-del no

  # 从节点加载RDB时是否异步清空数据
  replica-lazy-flush no

  # 用户DEL命令是否异步处理
  lazyfree-lazy-user-del no

  # FLUSHDB/FLUSHALL是否异步执行
  lazyfree-lazy-user-flush no

  # 是否调整Redis进程的OOM评分（避免被系统杀死）
  oom-score-adj no

  # OOM评分调整值（不同角色配置）
  oom-score-adj-values 0 200 800

  # 禁用透明大页（避免延迟波动）
  disable-thp yes

  # 禁用AOF持久化（仅使用RDB）
  appendonly no

  # AOF文件名（当启用AOF时有效）
  appendfilename "appendonly.aof"

  # AOF文件目录名（当启用AOF时有效）
  appenddirname "appendonlydir"

  # AOF同步策略：每秒同步（性能与安全折中）
  appendfsync everysec

  # AOF重写期间是否禁止fsync（避免磁盘IO竞争）
  no-appendfsync-on-rewrite no

  # AOF重写触发条件：当前AOF文件比上次重写后增大100%
  auto-aof-rewrite-percentage 100

  # AOF重写最小文件大小：64MB
  auto-aof-rewrite-min-size 64mb

  # 是否加载被截断的AOF文件（服务器崩溃时可能产生）
  aof-load-truncated yes

  # 启用AOF重写时使用RDB preamble（结合RDB和AOF优势）
  aof-use-rdb-preamble yes

  # 是否在AOF中记录时间戳（兼容性考虑）
  aof-timestamp-enabled no

  # 慢查询日志阈值（微秒），10000表示10毫秒
  slowlog-log-slower-than 10000

  # 慢查询日志最大记录条数
  slowlog-max-len 128

  # 延迟监控阈值（微秒），0表示禁用
  latency-monitor-threshold 0

  # 键空间通知配置（空表示禁用）
  notify-keyspace-events ""

  # Hash类型使用listpack的最大元素数量
  hash-max-listpack-entries 512

  # Hash类型使用listpack的最大元素值长度
  hash-max-listpack-value 64

  # List类型使用listpack的最大大小（-2表示默认值）
  list-max-listpack-size -2

  # List类型压缩深度（0表示不压缩）
  list-compress-depth 0

  # Set类型使用listpack的最大元素数量
  set-max-listpack-entries 128

  # Set类型使用listpack的最大元素值长度
  set-max-listpack-value 64

  # Zset类型使用listpack的最大元素数量
  zset-max-listpack-entries 128

  # Zset类型使用listpack的最大元素值长度
  zset-max-listpack-value 64

  # HyperLogLog稀疏结构最大字节数
  hll-sparse-max-bytes 3000

  # Stream类型单个节点最大字节数
  stream-node-max-bytes 4096

  # Stream类型单个节点最大条目数
  stream-node-max-entries 100

  # 启用主动rehashing（降低内存使用但增加CPU开销）
  activerehashing yes

  # 普通客户端输出缓冲区限制（0表示无限制）
  client-output-buffer-limit normal 0 0 0

  # 从节点客户端输出缓冲区限制（256MB硬限制，60秒软限制）
  client-output-buffer-limit replica 256mb 64mb 60

  # Pub/Sub客户端输出缓冲区限制（32MB硬限制，60秒软限制）
  client-output-buffer-limit pubsub 32mb 8mb 60

  # 后台任务执行频率基准值（1-500）
  hz 10

  # 动态调整hz值（根据客户端数量自适应）
  dynamic-hz yes

  # AOF重写期间增量同步fsync（减少磁盘压力）
  aof-rewrite-incremental-fsync yes

  # RDB保存期间增量同步fsync
  rdb-save-incremental-fsync yes

  # 启用jemalloc后台线程进行内存整理
  jemalloc-bg-thread yes

  ```

### 3.2 主从部署配置

* 所在目录：`/opt/software/redis/redis-stable`；
* 129:6379 主节点配置：同`2.2.1 单机 Redis 配置文件`；
* 131:6379 从节点配置：

  ```properties
  # 绑定所有可用网络接口（IPv4和IPv6），允许来自任何地址的连接
  bind * -::*

  # 禁用保护模式，允许远程连接（生产环境建议启用并配置密码）
  protected-mode no

  # 设置Redis服务监听端口为6379（默认端口）
  port 6379

  # TCP连接队列长度，高并发场景可适当调高
  tcp-backlog 511

  # 客户端空闲超时时间（秒），0表示永不超时
  timeout 0

  # TCP keepalive间隔时间（秒），用于检测死连接
  tcp-keepalive 300

  # 以守护进程方式运行（后台运行）
  daemonize yes

  # 进程ID文件存储路径
  pidfile /var/run/redis_6379.pid

  # 日志级别：notice（生产环境推荐）
  loglevel notice

  # 日志文件输出路径
  logfile /opt/software/redis/redis-stable/redis.log

  # 设置数据库数量（默认16个，编号0-15）
  databases 16

  # 启动时不显示Redis logo
  always-show-logo no

  # 启用进程标题设置
  set-proc-title yes

  # 进程标题格式：包含服务名、监听地址和模式
  proc-title-template "{title} {listen-addr} {server-mode}"

  # 设置空字符串使用默认字节比较排序
  locale-collate ""

  # RDB保存失败时停止写入操作（确保数据一致性）
  stop-writes-on-bgsave-error yes

  # RDB文件启用压缩（节省磁盘空间）
  rdbcompression yes

  # RDB文件启用CRC64校验和（数据完整性检查）
  rdbchecksum yes

  # RDB持久化数据文件名
  dbfilename dump.rdb

  # 主从同步时不删除RDB文件
  rdb-del-sync-files no

  # 工作目录（持久化文件和日志存放路径）
  dir /opt/software/redis

  # 指定主节点复制配置（从节点配置，IP为192.168.75.129，端口6379）
  replicaof 192.168.75.129 6379

  # 从节点在与主节点失联时继续响应旧数据
  replica-serve-stale-data yes

  # 从节点默认只读（防止数据不一致）
  replica-read-only yes

  # 启用无盘复制（主节点直接通过socket发送RDB到从节点）
  repl-diskless-sync yes

  # 无盘复制等待时间（秒），等待更多从节点连接
  repl-diskless-sync-delay 5

  # 无盘复制最大从节点数量（0表示无限制）
  repl-diskless-sync-max-replicas 0

  # 从节点加载RDB方式：disabled表示完全下载后再加载（避免数据不一致）
  repl-diskless-load disabled

  # 禁用TCP_NODELAY（启用后减少复制延迟但增加带宽）
  repl-disable-tcp-nodelay no

  # 从节点优先级（哨兵选主时使用，值越小优先级越高）
  replica-priority 100

  # ACL日志最大长度（记录认证相关事件）
  acllog-max-len 128

  # 内存满时是否异步驱逐Key（避免阻塞）
  lazyfree-lazy-eviction no

  # 过期Key是否异步删除
  lazyfree-lazy-expire no

  # 服务删除Key时是否异步处理（如RENAME命令）
  lazyfree-lazy-server-del no

  # 从节点加载RDB时是否异步清空数据
  replica-lazy-flush no

  # 用户DEL命令是否异步处理
  lazyfree-lazy-user-del no

  # FLUSHDB/FLUSHALL是否异步执行
  lazyfree-lazy-user-flush no

  # 是否调整Redis进程的OOM评分（避免被系统杀死）
  oom-score-adj no

  # OOM评分调整值（不同角色配置）
  oom-score-adj-values 0 200 800

  # 禁用透明大页（避免延迟波动）
  disable-thp yes

  # 禁用AOF持久化（仅使用RDB）
  appendonly no

  # AOF文件名（当启用AOF时有效）
  appendfilename "appendonly.aof"

  # AOF文件目录名（当启用AOF时有效）
  appenddirname "appendonlydir"

  # AOF同步策略：每秒同步（性能与安全折中）
  appendfsync everysec

  # AOF重写期间是否禁止fsync（避免磁盘IO竞争）
  no-appendfsync-on-rewrite no

  # AOF重写触发条件：当前AOF文件比上次重写后增大100%
  auto-aof-rewrite-percentage 100

  # AOF重写最小文件大小：64MB
  auto-aof-rewrite-min-size 64mb

  # 是否加载被截断的AOF文件（服务器崩溃时可能产生）
  aof-load-truncated yes

  # 启用AOF重写时使用RDB preamble（结合RDB和AOF优势）
  aof-use-rdb-preamble yes

  # 是否在AOF中记录时间戳（兼容性考虑）
  aof-timestamp-enabled no

  # 慢查询日志阈值（微秒），10000表示10毫秒
  slowlog-log-slower-than 10000

  # 慢查询日志最大记录条数
  slowlog-max-len 128

  # 延迟监控阈值（微秒），0表示禁用
  latency-monitor-threshold 0

  # 键空间通知配置（空表示禁用）
  notify-keyspace-events ""

  # Hash类型使用listpack的最大元素数量
  hash-max-listpack-entries 512

  # Hash类型使用listpack的最大元素值长度
  hash-max-listpack-value 64

  # List类型使用listpack的最大大小（-2表示默认值）
  list-max-listpack-size -2

  # Set类型使用intset编码的最大元素数量（仅限整数集合）
  set-max-intset-entries 512

  # Set类型使用listpack的最大元素数量
  set-max-listpack-entries 128

  # Set类型使用listpack的最大元素值长度
  set-max-listpack-value 64

  # Zset类型使用listpack的最大元素数量
  zset-max-listpack-entries 128

  # Zset类型使用listpack的最大元素值长度
  zset-max-listpack-value 64

  # HyperLogLog稀疏结构最大字节数
  hll-sparse-max-bytes 3000

  # Stream类型单个节点最大字节数
  stream-node-max-bytes 4096

  # Stream类型单个节点最大条目数
  stream-node-max-entries 100

  # 启用主动rehashing（降低内存使用但增加CPU开销）
  activerehashing yes

  # 普通客户端输出缓冲区限制（0表示无限制）
  client-output-buffer-limit normal 0 0 0

  # 从节点客户端输出缓冲区限制（256MB硬限制，60秒软限制）
  client-output-buffer-limit replica 256mb 64mb 60

  # Pub/Sub客户端输出缓冲区限制（32MB硬限制，60秒软限制）
  client-output-buffer-limit pubsub 32mb 8mb 60

  # 后台任务执行频率基准值（1-500）
  hz 10

  # 动态调整hz值（根据客户端数量自适应）
  dynamic-hz yes

  # AOF重写期间增量同步fsync（减少磁盘压力）
  aof-rewrite-incremental-fsync yes

  # RDB保存期间增量同步fsync
  rdb-save-incremental-fsync yes

  # 启用jemalloc后台线程进行内存整理
  jemalloc-bg-thread yes

  ```
* 132:6379 从节点配置：同上。

### 3.3 哨兵部署配置

* 所在目录：`/opt/software/redis/redis-stable`；
* 主从配置无需修改，直接配置 Sentinel 文件，3 个机器配置相同：

  ```properties
  # 禁用保护模式，允许远程连接Sentinel（生产环境建议配合防火墙使用）
  protected-mode no

  # Sentinel监听端口，默认26379
  port 26379

  # 以守护进程方式运行（后台运行）
  daemonize yes

  # Sentinel进程ID文件存储路径
  pidfile /var/run/redis-sentinel.pid

  # 日志级别：notice（生产环境推荐）
  loglevel notice

  # Sentinel日志文件输出路径
  logfile /opt/software/redis/redis-stable/sentinel.log

  # 工作目录（存储运行时文件）
  dir /opt/software/redis

  # 监控名为mymaster的主节点，IP为192.168.75.129，端口6379，法定人数为2
  sentinel monitor mymaster 192.168.75.129 6379 2

  # 主节点无响应30000毫秒（30秒）后判定为下线
  sentinel down-after-milliseconds mymaster 30000

  # ACL日志最大长度（记录认证相关事件）
  acllog-max-len 128

  # 故障转移时同时同步的新从节点数量（1表示逐个同步）
  sentinel parallel-syncs mymaster 1

  # 故障转移超时时间（毫秒），180000表示3分钟
  sentinel failover-timeout mymaster 180000

  # 禁止通过SENTINEL SET命令修改脚本相关配置（增强安全性）
  sentinel deny-scripts-reconfig yes

  # 禁用主机名解析（直接使用IP地址，避免DNS解析问题）
  SENTINEL resolve-hostnames no

  # 禁用主机名公告（使用IP地址进行通信）
  SENTINEL announce-hostnames no

  # 主节点重启后立即判定为下线（0表示不等待）
  SENTINEL master-reboot-down-after-period mymaster 0

  ```

### 3.4 集群部署配置

* 所在目录：`/opt/software/redis/redis-stable/cluster`；
* 6379 主节点：

  ```properties
  # 允许所有的IP地址
  bind * -::*
  # 后台运行
  daemonize yes
  # 允许远程连接
  protected-mode no
  # 开启集群模式
  cluster-enabled yes
  # 集群节点超时时间
  cluster-node-timeout 5000
  # 配置数据存储目录
  dir "/opt/software/redis/cluster"
  # 开启AOF持久化
  appendonly yes

  # 端口
  port 6379
  # log日志
  logfile "/opt/software/redis/redis-stable/cluster/redis6379.log"
  # 集群配置文件
  cluster-config-file nodes-6379.conf
  # AOF文件名
  appendfilename "appendonly6379.aof"
  # RBD文件名
  dbfilename "dump6379.rdb"

  ```
* 6380 从节点：

  ```properties
  # 允许所有的IP地址
  bind * -::*
  # 后台运行
  daemonize yes
  # 允许远程连接
  protected-mode no
  # 开启集群模式
  cluster-enabled yes
  # 集群节点超时时间
  cluster-node-timeout 5000
  # 配置数据存储目录
  dir "/opt/software/redis/cluster"
  # 开启AOF持久化
  appendonly yes

  # 端口
  port 6380
  # log日志
  logfile "/opt/software/redis/redis-stable/cluster/redis6380.log"
  # 集群配置文件
  cluster-config-file nodes-6380.conf
  # AOF文件名
  appendfilename "appendonly6380.aof"
  # RBD文件名
  dbfilename "dump6380.rdb"

  ```



