---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34313632373634322f:61727469636c652f64657461696c732f313436303431303339"
layout: post
title: "CBNet一种用于目标检测的复合骨干网架构之论文阅读"
date: 2025-03-14 17:41:37 +08:00
description: "现代顶级性能的目标检测器在很大程度上依赖于骨干网络，而骨干网络的进步通过探索更高效的网络结构带来了持续的性能提升。本文提出了一种新颖且灵活的。。。CBNet 对于不同骨干网络和检测器头部设计具有较强的泛化能力。在无需对复合骨干网络进行额外预训练的情况下，CBNet 可适用于各种骨干（如基于 CNN 和基于 Transformer 的）以及大多数主流检测器的头部设计（如单阶段与两阶段、基于锚框与非锚框）。"
keywords: "CBNet：一种用于目标检测的复合骨干网架构之论文阅读"
categories: ['深度学习论文阅读']
tags: ['论文阅读', '目标检测', '架构']
artid: "146041039"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146041039
    alt: "CBNet一种用于目标检测的复合骨干网架构之论文阅读"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146041039
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146041039
cover: https://bing.ee123.net/img/rand?artid=146041039
image: https://bing.ee123.net/img/rand?artid=146041039
img: https://bing.ee123.net/img/rand?artid=146041039
---

# CBNet：一种用于目标检测的复合骨干网架构之论文阅读

## 摘要

现代顶级性能的目标检测器在很大程度上依赖于骨干网络，而骨干网络的进步通过探索更高效的网络结构带来了持续的性能提升。本文提出了一种新颖且灵活的
**骨干框架——CBNet**
，
**该框架利用现有的开源预训练骨干网络，在预训练-微调范式下构建高性能检测器**
。
**具体而言，CBNet 架构将多个相同的骨干网络组合在一起，通过复合连接进行互联。它能够整合多个相同骨干网络中的高层和低层特征，并逐步扩大感受野，从而更有效地实现目标检测**
。
**我们还为基于 CBNet 的检测器提出了一种辅助监督的更优训练策略**
。CBNet 对于不同骨干网络和检测器头部设计具有较强的泛化能力。在无需对复合骨干网络进行额外预训练的情况下，CBNet 可适用于各种骨干（如基于 CNN 和基于 Transformer 的）以及大多数主流检测器的头部设计（如单阶段与两阶段、基于锚框与非锚框）。实验结果强有力地证明，与单纯增加网络深度和宽度相比，CBNet 为构建高性能骨干网络提供了一种更高效、有效且资源友好的方法。特别是，我们的 CB-Swin-L 在 COCO test-dev 数据集上，在单模型单尺度测试协议下，实现了 59.4% 框 AP 和 51.6% 掩模 AP，显著优于 Swin-L 达到的最新状态（57.7% 框 AP 和 50.2% 掩模 AP），同时将训练时间降低了 6 倍。通过多尺度测试，我们将当前最佳的单模型结果推向了新纪录——在不使用额外训练数据的情况下，框 AP 达到 60.1%，掩模 AP 达到 52.3%。代码已开源，详见：https://github.com/VDIGPKU/CBNetV2

## 引言

目标检测旨在从任意图像中定位属于预定义类别集合的每个目标实例。它在自动驾驶、智能视频监控、遥感等众多应用中发挥着重要作用。近年来，随着深度卷积网络的快速发展[2]，目标检测取得了巨大进展，并涌现出一系列优秀的检测器，如 SSD [3]、YOLO [4]、Faster R-CNN [5]、RetinaNet [6]、ATSS [7]、Mask R-CNN [8]、Cascade R-CNN [9] 等。

通常，在基于神经网络（NN）的检测器中，骨干网络用于提取基本特征以进行目标检测，并且大多数情况下最初是为图像分类设计的，并在 ImageNet [10] 上进行预训练。直观来看，骨干网络提取的特征越具代表性，其宿主检测器的性能就越优异。为了获得更高的检测精度，主流检测器采用了更深、更宽的骨干网络（例如，从移动端模型[11][12]和
**ResNet [13]，到 ResNeXt [14] 和 Res2Net [15]**
）。
**近年来，基于 Transformer [16][17] 的骨干网络也展现出了极具前景的性能。总体而言，在大规模骨干网络预训练的推动下，目标检测领域呈现出更有效的多尺度特征表示趋势**
。

受基于预训练大规模骨干网络的检测器优异表现的启发，我们希望进一步提升性能，利用现有的精心设计的骨干架构及其预训练权重来构建高性能检测器。
**虽然可以设计一种新的改进型骨干网络，但这需要大量的专业知识和计算资源。一方面，设计新骨干架构需要丰富的专家经验，并经历大量的尝试和错误。另一方面，预训练一个新的骨干网络（尤其是大规模模型）需要在 ImageNet 上进行大量计算，成本高昂，使得在预训练-微调范式下提升检测性能变得更加困难。此外，虽然可以通过从零开始训练检测器来省去预训练的成本，但这需要更多的计算资源和训练技巧[18]。**

本文提出了一种简单而新颖的组合方法，在预训练-微调范式下利用现有的预训练骨干网络。与大多数专注于模块化设计并需要在 ImageNet 上预训练以增强特征表示的方法不同，我们在无需额外预训练的情况下，提高了现有骨干网络的特征表达能力。
**如图 1 所示，我们的方法被称为 复合骨干网络（CBNet），它将多个相同的骨干网络组合在一起。具体而言，CBNet 通过复合连接将多个并行骨干（称为辅助骨干和主骨干）连接起来**
。从图 1 的左侧到右侧，辅助骨干的每个阶段的输出会传递到其后续并行骨干的低层阶段，最终，主骨干的特征被输入到检测器的颈部和检测头，用于边界框回归和分类。与单纯加深或加宽网络不同，CBNet 通过整合多个骨干网络的高层和低层特征，并逐步扩大感受野，实现了更有效的目标检测。值得注意的是，CBNet 的每个复合骨干均由现有的开源预训练骨干的权重初始化（例如，CB-ResNet50 由 ResNet50 [13] 的权重初始化，而 ResNet50 的权重可从开源社区获取）。此外，为了进一步挖掘 CBNet 的潜力，我们提出了一种针对辅助骨干的监督训练策略，在不影响推理速度的情况下提升检测精度。特别地，我们还提出了一种剪枝策略，在不牺牲精度的前提下降低模型复杂度。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a08ead5e785e4b6180740219387c7fff.png)

我们提出了 CBNet 的两个版本。第一个版本 CBNetV1 [1] 仅连接了并行骨干的相邻阶段，实现了一种简单的复合骨干，易于理解和复现。第二个版本 CBNetV2 结合了更密集的高级复合策略、辅助监督以及剪枝策略，充分挖掘了 CBNet 在目标检测任务中的潜力。实验结果表明，CBNetV2 在性能上明显优于 CBNetV1。

我们在具有挑战性的 MS COCO 基准测试 [19] 上进行了实验，验证了我们框架的有效性。实验结果表明，CBNet 对不同骨干网络和检测器头部设计具有很强的泛化能力，使我们能够训练出显著优于基于更大骨干网络的检测器。具体来说，CBNet 可应用于多种骨干网络，从基于卷积的 [13]、[14]、[15] 到基于 Transformer 的 [20]。与原始骨干网络相比，CBNet 能将它们的性能提升 3.4%∼3.5% AP，证明了所提 CBNet 的有效性。在模型复杂度相当的情况下，我们的 CBNet 仍可提升 1.1%∼2.1% AP，这表明组合后的骨干比预训练的更宽、更深网络更高效。此外，CBNet 可以灵活地集成到主流检测器中（例如 RetinaNet [6]、ATSS [7]、Faster R-CNN [5]、Mask R-CNN [8]、Cascade R-CNN 以及 Cascade Mask R-CNN [9]），并始终使这些检测器的性能提升 3%∼3.8% AP，展示了其对各种检测器头部设计的强适应性。
**另外，CBNet 与特征增强网络 [21]、[22] 以及模型集成方法 [23] 均可兼容**
。值得注意的是，它提供了一个通用且资源友好的框架，以推动高性能检测器的准确性上限。在不做额外修饰的情况下，我们的 CB-Swin-L 在 COCO test-dev 上以单模型、单尺度测试条件下实现了无与伦比的 59.4% 框 AP 和 51.6% 掩模 AP，超越了最新的状态（即 Swin-L 所获得的 57.7% 框 AP 和 50.2% 掩模 AP），同时将训练时间缩短了 6 倍。通过多尺度测试，我们将当前最佳的单模型结果推向了新的记录：60.1% 框 AP 和 52.3% 掩模 AP。

本文的主要贡献如下： • 我们提出了一种通用、高效且有效的框架——CBNet（组合骨干网络），用于构建高性能目标检测骨干网络，而无需额外的预训练。 • 我们提出了密集高级组合（Dense Higher-Level Composition, DHLC）策略、辅助监督以及剪枝策略，以在预训练-微调范式下高效利用现有预训练权重进行目标检测。 • 我们的 CB-Swin-L 在 COCO 上以比 Swin-L 缩短 6 倍的训练时间内，实现了单模型、单尺度测试的新纪录；通过多尺度测试，我们的方法在不使用额外训练数据的情况下达到了目前已知的最佳结果。

## 相关工作

### 目标检测

目标检测旨在从输入图像中定位预定义类别集合中的每个目标实例。随着卷积神经网络（CNN）的快速发展，基于深度学习的目标检测器形成了一种流行范式：首先，骨干网络（通常为分类任务设计并在 ImageNet 上预训练）从输入图像中提取基础特征；随后，颈部（例如，特征金字塔网络 [25]）对来自骨干的多尺度特征进行增强，最后检测头根据位置和类别信息预测目标的边界框。

基于检测头的不同设计，通用目标检测的前沿方法大致可分为两大类。第一类包括一阶段检测器，如 YOLO [4]、SSD [3]、RetinaNet [6]、NAS-FPN [26]、EfficientDet [27] 以及 [28]；第二类则包括两阶段检测器，如 Faster R-CNN [5]、FPN [25]、Mask R-CNN [8]、Cascade R-CNN [9] 以及 Libra R-CNN [29]。

近年来，由于 FPN [25] 和 focal loss [6] 的出现，学术界开始关注无锚检测器，从而催生了更为优雅的端到端检测器。一方面，FSAF [30]、FCOS [31]、ATSS [7] 以及 GFL [32] 采用基于中心的无锚方法对 RetinaNet 进行改进；另一方面，CornerNet [33]、CenterNet [34] 与 FoveaBox [35] 则采用基于关键点的方法检测目标边界框。除了上述基于 CNN 的检测器外，Transformer [16] 也被用于目标检测，其中 DETR [36] 通过结合 CNN 与 Transformer 编码器—解码器提出了一种完全端到端的检测器。

更近来，神经架构搜索（NAS）被应用于自动搜索特定检测器的架构。NAS-FPN [26]、NAS-FCOS [37] 和 SpineNet [38] 利用强化学习控制架构采样，并获得了令人鼓舞的结果；SM-NAS [39] 则采用进化算法和部分顺序剪枝方法搜索检测器各部分的最佳组合；AutoFPN [40] 使用基于梯度的方法搜索最佳检测器；而 OPANAS [41] 则采用单次方法搜索出高效的颈部结构以提升目标检测性能。

### B. 用于目标检测的骨干网络

从 AlexNet [2] 开始，主流检测器已经采用了更深更宽的骨干网络，如 VGG [42]、ResNet [13]、DenseNet [43]、ResNeXt [14] 以及 Res2Net [15]。由于骨干网络通常为分类任务而设计，无论是在 ImageNet 上预训练后再在特定检测数据集上微调，还是在检测数据集上从头训练，都需要大量的计算资源，并且优化较为困难。

近年来，出现了两种设计较为非凡的骨干网络——DetNet [44] 和 FishNet [45]，它们专门针对检测任务而设计。然而，这些网络在用于检测任务之前，仍然需要先为分类任务进行预训练。Res2Net [15] 通过在粒度层面表示多尺度特征，在目标检测中取得了令人印象深刻的成果。HRNet [21] 则保持了高分辨率表示，并在人类姿态估计、语义分割以及目标检测中都获得了有希望的结果。

除了手动设计骨干网络架构之外，DetNAS [46] 和 Joint-DetNAS [47] 利用神经架构搜索（NAS）来寻找更适合目标检测的骨干，从而降低了手动设计的成本。Swin Transformer [20] 和 PVT [17] 则利用 Transformer 模块构建骨干网络，尽管需要昂贵的预训练，但同样取得了令人印象深刻的成果。众所周知，设计和预训练一个全新且健壮的骨干网络需要大量计算成本。

作为替代方案，我们提出了一种更加经济高效的解决方案，即
**通过将多个相同的现有骨干网络**
（例如 ResNet [13]、ResNeXt [14]、Res2Net [15]、HRNet [21] 以及 Swin Transformer …）进行组合，以构建更强大的目标检测骨干网络。

### C. 循环卷积神经网络

不同于传统 CNN 的前馈架构，循环卷积神经网络（RCNN）[24] 在每个卷积层中引入了循环连接，以增强模型对上下文信息的整合能力。如图 3 所示，我们提出的 Composite Backbone Network（CBNet）与展开式 RCNN [24] 存在一些相似之处，但它们有很大不同。首先，CBNet 中平行阶段之间的连接是单向的，而 RCNN 中是双向的。其次，在 RCNN 中，不同时间步的平行阶段共享参数权重，而在所提出的 CBNet 中，各个 backbone 阶段是相互独立的。此外，如果将 RCNN 用作检测器的 backbone，则需要在 ImageNet 上进行预训练；相比之下，CBNet 不需要额外的预训练，因为它直接使用现有的预训练权重。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/162bbd1943ea4b24aa96996ff15e244a.png)

### D. 模型集成

众所周知，结合多个不同预测器可以带来更准确的预测结果，例如，集成方法被认为是许多机器学习挑战的最先进解决方案。模型集成通过训练多个不同的模型并通过后处理将它们的预测结果进行组合，从而提高单一模型的预测性能 [48]，[49]。
**模型集成有两个关键特性：模型多样性和投票机制**
。模型多样性指的是采用不同架构或训练技术的模型需要分别训练，其在模型集成中的重要性已经得到了充分证明 [50]，[51]，[52]，[53]。大多数集成方法需要投票策略来比较不同模型的输出并优化最终的预测结果 [23]。就这两个特性而言，我们的 CBNet 与模型集成大为不同。事实上，CBNet 受益于采用相同 backbone 的分组，通过联合训练以循环方式增强特征；而且，最终预测时直接使用主导 backbone 的输出，而无需与其他 backbone 的输出进行组装。更多实际的分析可以参考第四部分第 E2 节。

在实践中，当前主流的目标检测基准（如 MS COCO [19] 或 OpenImage [54]）的领先方法往往依赖于模型集成 [55]，[56]，[57]，[58]，[59]，[60]。例如，[60] 分别训练了 28 个具有不同架构、检测头、数据拆分、类别采样策略、增强策略和监督方式的模型，并通过集成方法聚合这些检测器的输出。[23] 则提出了概率排序感知集成（Probabilistic Ranking Aware Ensemble, PRAE），该方法可以对来自不同检测器的边界框置信度进行优化。我们的 CBNet 与此类模型集成方法兼容，就像其他传统的 backbone 一样。更多细节可以在第四部分第 F6 节中找到。

### E. 我们的方法

**我们的网络将多个相同的 backbone 并行组合在一起。它整合了多个相同 backbone 的高层次和低层次特征，并逐步扩大感受野，以更高效地实现目标检测**
。本文是在我们之前的会议论文 [1] 的基础上进行了大幅扩展，并在最近开发的最先进的目标检测框架下获得了结果。与 [1] 相比，主要技术创新体现在三个方面：

我们对 [1] 中提出的网络（称为 CBNetV1）进行了扩展，
**并引入了三项修改：一种专门的训练方法、更优的组合策略以及剪枝策略，分别用于优化训练过程、更高效地增强特征表达能力以及降低 CBNetV2 的模型复杂度**
。
  
我们展示了 CBNetV2 对各种 backbone 和检测器架构中 head 设计的强大泛化能力。
  
我们证明了 CBNetV2 相对于 CBNetV1 的优越性，并在目标检测任务中呈现了 CBNetV2 的最先进成果。

## 提出的方法

本节将详细阐述所提出的 CBNet。在 III-A 节和 III-B 节中，我们分别描述了其基本架构和变体；在 III-C 节中，我们提出了基于 CBNet 的检测器的训练策略；在 III-D 节中，我们简要介绍了剪枝策略；在 III-E 节中，我们总结了 CBNet 的检测框架。

### A.CBNet架构

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/8099e7807ea9422592907623597bd920.png)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a08ead5e785e4b6180740219387c7fff.png)

### B、可能得符合策略

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/28a894bd07c84046990ba97b3c25f5a0.png)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6c9133aa639447c6912e5a4471b31fbf.png)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a08ab8691d1849fcb7240e626b488c1f.png)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a72a42ec839a48aba5265a2de8cf5a9a.png)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b0d95d7d7abb4b7587aad96fd71676f7.png)

### C. 辅助监督

虽然增加网络深度通常能带来性能提升 [13]，但正如图像分类中的情况 [61] 所示，它可能会引入额外的优化难题。文献 [62]、[63] 提出了在中间层引入辅助分类器，以改善极深网络的收敛性。在原始的 CBNet 中，尽管组合骨干网络是并行排列的，但后续的骨干（例如图 4.a 中的主骨干）通过与前一个骨干（例如图 4.a 中的辅助骨干）之间的相邻连接来加深网络。为了更好地训练基于 CBNet 的检测器，我们
**提出利用辅助颈部和检测头对辅助骨干进行监督，生成其初步结果，从而提供额外的正则化**
。

当 K=2 时，我们的带监督 CBNet 示意如图 4.b 所示。除了利用主骨干特征训练检测头 1 的原始损失外，另一个检测头 2 以辅助骨干的特征作为输入，从而产生辅助监督。请注意，
**检测头 1 与检测头 2 共享权重，两个颈部也同样共享权重**
。辅助监督有助于优化整个学习过程，而主骨干的原始损失则承担了主要责任。我们为辅助监督设置了权重，以实现平衡，总损失定义为：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/8515009d6d644f06bab68d47c532aba5.png)
  
其中，L₍Lead₎ 是主骨干的损失，L₍Assist₎ᶦ 是第 i 个辅助骨干的损失，而 λᵢ 是对应的损失权重。

**在推理阶段，我们舍弃辅助监督分支，仅使用 CBNet 中主骨干的输出特征（如图 4.b 所示），因此辅助监督不会影响推理速度**
。
  
)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/56abfddbd3f749c2b2f83adb7a0382a4.png)

### D.CBNet的剪枝策略

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/1cf4f97d25404343995859d8609ea9a8.png)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/bf7e8e88424f4f6c9868029ef8086bbf.png)

### E. 基于 CBNet 的检测网络架构

CBNet 可直接应用于各种现成的检测器，无需对网络结构进行额外修改。实际上，我们将主骨干与功能网络（例如 FPN [25] 和检测头）相连接，如图 1 所示展示了 CBNet 的推理阶段。需要注意的是，我们提出了两个版本的 CBNet。
**第一个版本，命名为 CBNetV1 [1]，仅采用 AHLC 组合策略，实现了一个简单易懂的组合骨干；而另一个版本 CBNetV2 则结合了 DHLC 组合策略、辅助监督以及特殊剪枝策略，以充分挖掘 CBNet 在目标检测中的潜力**
。我们在接下来的 Sec. IV 中通过实验证明了 CBNetV2 相较于 CBNetV1 的优越性。在本文后续实验中，如无特别说明，CBNet 均指 CBNetV2。

## 实验

在本节中，我们通过大量实验对我们的 CBNet 进行了评估。在 IV-A 节中，我们详细介绍了实验设置；在 IV-B 节中，我们将 CBNet 与最先进的检测方法进行了比较；在 IV-C 节中，我们展示了该方法在不同骨干和检测器上的通用性；在 IV-E 节中，我们展示了 CBNet 与 DCN 以及模型集成的兼容性；在 IV-F 节中，我们进行了大量消融实验以研究框架的各个组成部分。

### A. 实现细节

数据集与评估指标：
  
我们的实验在 COCO [19] 基准上进行。训练阶段使用 118k 张训练图像，消融实验则在 5k 张 minival 图像上进行。同时，我们还报告了 test-dev 中 20k 张图像的结果，以便与最新方法（SOTA）进行比较。评估时采用 COCO 检测评估标准中的指标，包括在 IoU 阈值从 0.5 到 0.95 不同尺度下的平均精度（AP）。

训练与推理细节：
  
我们的实验基于开源检测工具箱 MMDetection [71]。在消融实验和简单对比中（若无特别说明），我们将训练和推理阶段的输入尺寸调整为 800×500。我们选择 Faster R-CNN（采用 ResNet50 [13] 和 FPN [25]）作为基线。我们使用 SGD 优化器，初始学习率为 0.02，动量为 0.9，权重衰减设置为 10⁻⁴。我们训练检测器 12 个 epoch，在第 8 和 11 个 epoch 时将学习率降低 10 倍。
**数据增强仅采用随机翻转，batch size 设为 16**
。需要注意的是，对于特殊骨干（例如 Swin Transformer [20],[72]、HRNet [21]、PVT [17]、PVTv2 [73] 以及 DetectoRS [74]）的实验，均按照原论文中的超参数设置进行，而未做特别强调。检测器的推理速度（FPS，即每秒帧数）均在一台配备 1 块 V100 GPU 的机器上测量。

为了与最新检测器进行比较，
**我们采用了多尺度训练 [75]（短边尺寸调整至 400~1400，长边最大为 1600）和更长的训练计划（详细信息见 IV-B 节）。在推理阶段，我们使用阈值为 0.001 的 Soft-NMS [76]，且输入尺寸设置为 1600×1400**
。本文中未特别说明的所有其他超参数均遵循 MMDetection 的设置。

### B. 与最新方法的比较

我们将我们的方法与最前沿的检测器进行了比较。根据训练时是否使用实例分割标注，我们将结果分为目标检测（表 I）和实例分割（表 II）。
**按照 [20] 的方法（Swin Transform），我们对 Cascade R-CNN、Cascade Mask R-CNN 和 HTC 的检测头进行了改进：在每个边界框检测头中添加了四个卷积层 [77]，并用 GIoU 损失 [78] 替换了 Smooth L1 损失 [79]**
。

#### 1) 目标检测

对于仅使用边界框标注训练的检测器，我们将其分为两类：基于锚框的方法和基于无锚方法（见表 I）。我们选择 ATSS [7] 作为基于无锚方法的代表，选择 Cascade R-CNN 作为基于锚框方法的代表。

基于无锚方法（Anchor-free）：
  
配备 ATSS 的 CB-Res2Net101-DCN 训练 20 个 epoch，在第 16 和 19 个 epoch 时将学习率衰减 10 倍。值得注意的是，我们的 CB-Res2Net101-DCN 在单尺度测试协议下实现了 52.8% 的 AP，超越了先前的无锚方法 [7]、[30]、[31]、[32]、[36]、[37]、[64]。

基于锚框方法（Anchor-based）：
  
我们的 CB-Res2Net101-DCN 实现了 55.6% 的 AP，优于其他基于锚框的检测器 [26]、[27]、[38]、[39]、[40]、[41]、[66]、[80]。
**值得一提的是，我们的 CBNet 仅训练了 32 个 epoch（前 20 个 epoch 进行常规训练，后 12 个 epoch 使用随机权重平均（Stochastic Weights Averaging, SWA）[81] 进行训练）**
，相比 EfficientDet 和 YOLOv4，训练时间分别缩短了 16 倍和 12 倍。

表1：与COCO测试开发的最新结果的比较。我们的CB-Res2Net101-DCN比以前的无锚点和基于锚点的检测器实现更高的bboxAP，同时使用相当或更少的训练epoch。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b35d9e3f7724414aba4a65676a0aed54.png)

#### 2) 实例分割

我们进一步将我们的方法与最先进的实例分割方法 [20]、[68]、[69]、[70] 进行了比较（见表 II），其中训练时使用了边界框和实例分割标注。按照 [20] 的方法，我们分别提供了在常规 ImageNet-1K 和 ImageNet-22K 预训练的骨干网络上的实验结果，以展示 CBNet 的高性能表现。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/1699a9d5ac6f43409f8444afcf67a12e.png)

基于 ImageNet-1K 预训练的结果：
  
按照 [20]，我们对 CB-Swin-S 采用 3x 训练计划（训练 36 个 epoch，并在第 27 和 33 个 epoch 使学习率衰减 10 倍）。
  
在 COCO minival 集上，基于 Cascade Mask R-CNN 的 CB-Swin-S 在边界框检测和实例分割任务中分别达到了 56.3% box AP 和 48.6% mask AP，相比 Swin-B，在模型大小相似、训练协议相同的情况下，分别提升了 +4.4% box AP 和 +3.6% mask AP。此外，CB-Swin-S 在 COCO test-dev 上的检测结果为 56.9% box AP 和 49.1% mask AP，优于其他基于 ImageNet-1K 预训练的骨干网络的检测器。

基于 ImageNet-22K 预训练的结果：
  
我们的 CB-Swin-B 在 COCO minival 上的单尺度测试结果为 58.4% box AP 和 50.7% mask AP，比 Swin-L（HTC++）[20] 分别高出 1.3% box AP 和 1.2% mask AP，同时参数数量减少了 17%，训练时间缩短了 3.6 倍。
  
尤其是，在仅训练 12 个 epoch（比 Swin-L 短 6 倍）的情况下，我们的 CB-Swin-L 在 COCO test-dev 上达到了 59.4% box AP 和 51.6% mask AP，超越了之前的最佳方法。通过多尺度测试，我们进一步将当前最佳结果推至 60.1% box AP 和 52.3% mask AP。

这些结果表明，CBNet 提出了一种高效、有效且资源友好的框架，用于构建高性能检测器。

### C. CBNet 的泛化能力(对主流骨干架构的泛化能力、对 Swin Transformer 的泛化能力和对特殊骨干网络的泛化能力)

CBNet 通过并行组合多个骨干网络来扩展感受野，而不是简单地增加网络的深度。为了证明我们的设计策略的通用性，我们在不同的骨干网络和检测器头部设计上进行了实验。

1. 对主流骨干架构的泛化能力
     
   有效性（Effectiveness）：
     
   为了验证 CBNet 的有效性，我们在 Faster R-CNN 结合不同骨干网络的情况下进行了实验。如表 III 所示，对于基于 CNN 的骨干网络（例如 ResNet、ResNeXt-32x4d 和 Res2Net），我们的 CBNet 方法可以使基线性能提高 3.4% 以上的 AP。
     
   ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c5cbc3e294bd49a794eb08d3344c140a.png)

高效性（Efficiency）：
  
由于 CBNet 采用了复合骨干网络，与基线模型相比，其参数量有所增加。为了更好地评估其效率，我们与更深或更宽的骨干网络进行了对比。如表 IV 所示，在参数数量和推理速度相当的情况下，CBNet 分别使 ResNet101、ResNeXt101-32x4d 和 Res2Net101 的 AP 提高了 1.7%、2.1% 和 1.1%。此外，CB-ResNeXt50-32x4d 的 AP 比 ResNeXt101-64x4d 高 1.1%，而参数量仅为后者的 70%。实验结果表明，我们的复合骨干架构比单纯增加网络的深度和宽度更高效、更有效。
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b930ac6f2155444f84f3fce07ba36dc9.png)

2. 对 Swin Transformer 的泛化能力
     
   Transformer 在数据建模中以自注意力机制建模远程依赖关系而闻名，Swin Transformer [20] 是近年来最具代表性的模型之一。我们在 Swin Transformer 上进行了实验，以验证 CBNet 的模型泛化能力。为了公平对比，我们采用与 [20] 相同的训练策略，包括多尺度训练（短边调整至 480~800，长边最大 1333）、AdamW 优化器（初始学习率 0.0001，权重衰减 0.05，batch size 为 16）以及 3x 训练计划（36 个 epoch）。

如表 V 所示，随着 Swin Transformer 深度和宽度的增加，模型精度逐步提高，并在 Swin-S 处趋于饱和。Swin-B 仅比 Swin-S 提高了 0.1% AP，但参数量却增加了 3800 万。当采用 CB-Swin-T，我们相较于 Swin-T 分别提高了 3.1% box AP 和 2.5% mask AP。值得注意的是，我们的 CB-Swin-T 比更深更宽的 Swin-B 高出 1.7% box AP 和 1.2% mask AP，同时模型复杂度更低（例如，计算量 FLOPs：CB-Swin-T 836G vs. Swin-B 975G，参数量 113.8M vs. 145.0M，FPS 6.5 vs. 5.9）。这些结果表明，CBNet 不仅可以改进基于卷积的架构，还能提升 Transformer 架构的检测能力，并比单纯增加网络的深度和宽度更有效地提高高性能检测器的上限。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/94b28e2ac70146adb231c21e5a00c8d3.png)
  
3) 对特殊骨干网络的泛化能力
  
为了进一步验证 CBNet 对不同骨干网络的泛化能力，我们在 CBNet 结合不同的骨干网络（包括 MobileNetV2 [72]、HRNet [21]、PVT [17] 和 PVTv2 [73]）的情况下进行了实验。为了公平对比，我们选用了公开可用的预训练骨干网络，并严格遵循 MMDetection [82] 的实验设置（包括检测器的选择、训练及推理细节）。实验结果如表 VI 所示：

轻量级模型（MobileNetV2）： 在 YOLOV3 [83] 检测器上，我们的 CB-MobileNetV2 相比 MobileNetV2 提高了 3.1% AP，且比 MobileNetV2(1.4x) 高 1% AP，模型复杂度相当。
  
高分辨率特征模型（HRNet）： 我们的 CB-HRNetv2p w32 相比 HRNetv2p w32 提高了 2.4% AP，且比 HRNetv2p w48 高 0.6% AP，参数量更少。
  
基于 Transformer 的全局特征提取网络（PVT）： 在 RetinaNet 检测器上，我们的 CB-PVT-Small 相比 PVT-Small 提高了 3% AP，且比 PVT-Large 高 0.8% AP，而参数量仅为 PVT-Large 的 83%。此外，我们的 CB-PVTv2-B2 相比 PVTv2-B2 提高了 3.1% AP，且比 PVTv2-B5 高 1.6% AP，而参数量仅为 PVTv2-B5 的 66%。
  
这些结果表明，CBNet 能够提升各种不同类型的骨干网络，在参数量和计算量相当甚至更少的情况下，取得更优的检测性能，从而证明了 CBNet 的有效性和高效性。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4d573beb5e0e4e49ace413b564c4543f.png)

4. 对主流检测器的适配能力
     
   我们通过将 CBNet 应用于主流检测器（包括 RetinaNet、ATSS、Faster R-CNN、Mask R-CNN 和 Cascade R-CNN）来评估其适配能力。这些检测器涉及不同的检测头设计（例如，两阶段 vs. 单阶段、基于锚框 vs. 无锚框）。如表 VII 所示，我们的 CBNet 使所有主流目标检测器的 AP 提高了 3% 以上。此外，Mask R-CNN 在实例分割任务中的准确率也提高了 2.9% AP。这些实验结果表明，CBNet 具备出色的适配能力，能够适用于各种不同设计的检测头，从而进一步验证了 CBNet 在不同检测框架中的泛化能力。
     
   ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e4c75853c24348b08e38a19c3fd2e20e.png)

### D. 与相关工作对比（与DetectoRS对比）

目前有几种相关的检测器，例如 DetectoRS [74] 采用复合骨干网络和 FPN，而 Joint-DetNAS [47] 采用搜索策略优化模型缩放方案。我们对 CBNet 与这两种方法进行了对比实验。

**Joint-DetNAS [47] 结合了神经架构搜索（NAS）、剪枝和知识蒸馏来优化检测器**
。同样地，我们的 CBNet 也采用了剪枝策略，但更专注于使用复合策略对骨干网络进行扩展。由于 CBNet 具有较强的泛化能力，它可以提升高性能检测器的性能（例如 YOLOX [84]）。如表 VIII 所示，我们的 CB-CSPNet-L 相比 CSPNet-L [84] 提高了 2.6% AP，且比 CSPNet-X 高 1.1% AP，而参数量仅为后者的 85%。此外，我们进一步将 CBNet 应用于现有的手工设计检测器（YOLOX），并与采用先进知识蒸馏训练策略的 Joint-DetNAS 进行对比。实验结果表明，CBNet 以 118 GFLOPs 实现了 52% AP，明显优于 Joint-DetNAS（基于 X101-FPN），其 266 GFLOPs 仅实现 45.7% AP。需要注意的是，
**由于 CBNet 主要专注于骨干网络的架构设计，而 Joint-DetNAS 关注整个检测器的架构和训练联合优化，因此二者之间难以进行完全公平的对比**
。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3ed8b405d99247b8974f23cc4f57a642.png)
  
**DetectoRS [74] 采用与 CBNet 类似的设计，但 DetectoRS 同时组合了骨干网络和 FPN**
。我们在 Faster R-CNN 结合不同骨干网络的情况下对比了 CBNetV2 和 DetectoRS，实验结果见表 IX。在相同的训练策略下（输入尺寸为 1333 × 800），CBNet 以更少的 FLOPs 实现了相当或更高的 AP。特别是，
**在使用 Swin-Tiny 作为骨干网络的情况下，我们的 CBNet 比 DetectoRS 高 0.8% AP，而计算量（FLOPs）仅为后者的 84%。**
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c0d3a04564674e8f9d19f1ecf3b8c3ca.png)

### E. CBNet 的兼容性（与可变形卷积、与模型集成的兼容性）

1. 与可变形卷积的兼容性
     
   可变形卷积（Deformable Convolution, DCN）[22] 通过增强 CNN 处理变形的能力，广泛应用于高精度目标检测器（例如，在 Faster R-CNN ResNet50 上简单加入 DCN，就能使 AP 从 34.6% 提高到 37.4%）。为了验证 CBNet 与 DCN 的兼容性，我们在 ResNet 和 ResNeXt 结合 Faster R-CNN 的情况下进行了实验。如表 X 所示，DCN 在 CBNet 上依然有效，带来了 2.3% ~ 2.7% AP 的提升。这一提升幅度甚至超过了 ResNet152（提升 2.0% AP）和 ResNeXt101-64x4d（提升 1.3% AP）的增益。

进一步分析表明，CB-ResNet50-DCN 分别比 ResNet50-DCN 和更深的 ResNet152-DCN 提高了 3.0% 和 0.6% AP。此外，CB-ResNet50-32x4d-DCN 分别比 ResNet50-32x4d-DCN 和更深更宽的 ResNeXt101-64x4d-DCN 提高了 3.7% 和 1.3% AP。
**实验结果表明，CBNet 与 DCN 具有良好的兼容性，二者的效果可以叠加，不会相互冲突**
。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/7935476b7bbd4f208246304cdedb2506.png)
  
2) 与模型集成的兼容性
  
模型集成（Model Ensemble）通过训练多个不同的模型，并在推理阶段结合它们的预测结果，以提高整体性能 [48], [49]。概率排序感知集成（Probabilistic Ranking Aware Ensemble, PRAE）[23] 通过优化不同检测器的置信度排名，比其他目标检测集成方法取得了更显著的性能提升。例如，将 Faster R-CNN ResNet50 和 Faster R-CNN ReNeXt50 进行集成，可将单一模型的最佳 AP 从 36.3% 提高到 37.3%。然而，仅仅组合两个相同的检测器（例如两个 Faster R-CNN ResNeXt50）并不会提升性能（仍为 36.3% AP）。

为了验证 CBNet 对模型集成方法 PRAE 的兼容性，我们在传统骨干网络（ResNet、ResNeXt、Res2Net）及其对应的 CBNet 变体上进行了实验，所有模型均结合 Faster R-CNN。实验结果（见表 XI）表明，PRAE 在 CBNet 组装的检测器上依然有效，可提升 0.8% ~ 1.7% AP，与其在传统骨干网络上的效果一致。此外，我们的 CBNet 相比 PRAE 更有效。例如，Faster R-CNN CB-R50 实现了 38.0% AP，高于 Faster R-CNN ResNet50 和 Faster R-CNN ReNeXt50 集成后的 37.3% AP。

**这些结果表明，CBNet 与模型集成方法可以相互兼容，二者的效果可以叠加，不会相互冲突**
。同时，CBNet 由于采用了多个相同骨干网络的组合，因此本质上可以视为一个单一的检测器/模型，而非多个独立模型的集成。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6a1a3ead9683496fbce974d20ff58e23.png)

### F. 消融实验

我们对提出的 CBNet 进行了多种设计选择的消融实验。为简单起见，除非特别说明，所有准确率结果均基于 COCO 验证集，输入尺寸为 800 × 500。

#### 1）不同复合策略的有效性

我们在 Faster R-CNN CB-ResNet50 体系结构上进行了实验，以比较图 2 中提出的复合策略，包括 SLC、AHLC、ALLC、DHLC 和 FCC。实验结果见表 XII。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/657d6734d1d24a149e7d65714e6dbabb.png)
  
SLC：与单一骨干网络的基线相比，准确率略有提高（35% vs. 34.6% AP）。由于两个骨干网络相同阶段提取的特征相似，SLC 仅能学习到比单一骨干稍多的语义信息。
  
AHLC：相比基线提高 1.4% AP，验证了第 III-B2 节的动机，即前一个骨干网络的高层特征增强了后一个骨干网络的表示能力。
  
ALLC：相比基线下降 2.2% AP。我们推测，将辅助骨干网络的低层特征直接添加到主骨干的高层特征会削弱后者的表示能力。
  
DHLC：相比基线提升 2.7% AP（从 34.6% 提升到 37.3% AP）。增加更多高低层连接在一定程度上丰富了特征的表示能力。
  
FCC：获得最佳性能（37.4% AP），但推理速度比 DHLC 慢 7%（19.9 vs. 21.4 FPS）。
  
综上，FCC 和 DHLC 取得了最好的效果。考虑到计算复杂度，
**我们推荐 DHLC 作为 CBNet 的默认复合策略**
。实验表明，仅仅增加参数数量或添加骨干网络并不一定能获得更好的结果，而复合连接方式起着关键作用。这些结果验证了 DHLC 复合策略的有效性和非平凡性。

需要注意的是，CBNetV1（[1]）与本文在 DHLC 和 AHLC 方面的表现略有差异，这是由于它们基于不同的深度学习平台（CAFFE vs. PyTorch），使用了不同的模型初始化策略，导致性能不同。
**表 XIII 进一步比较了 DHLC 和 AHLC 在不同骨干网络上的表现。DHLC 在 ResNet101 和 ResNeXt101-64x4d 上分别比 AHLC 高 0.8% AP 和 1.1% AP，证明了 DHLC 在不同骨干网络上的通用性**
。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c4aaf47519844e3583a51a0d9661539a.png)

此外，我们通过代理任务的
**网格搜索来寻找更优的复合策略**
。为了降低搜索成本，我们简化了搜索空间，仅搜索复合骨干网络中的 x3、x4、x5 级别的连接，并使用 COCO 训练集的 1/5 进行训练（输入尺寸 800 × 500）。最终，我们训练了 512 个检测器，花费 205 GPU 天。
**搜索得到的最优策略是简化的 DHLC(s3)，去掉了前一个骨干网络 x4 到后一个骨干网络 x3 的输入连接**
。该策略取得了 37.3% AP，与我们手工设计的 DHLC（37.3% AP）表现相当，进一步验证了高到低连接的必要性。

#### 2）辅助监督权重的影响

关于辅助监督的实验结果见表 XIV。为了简化实验，我们在 CBNet 上使用 DHLC 复合策略进行实验。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/f4c585ff221341ed82d24521cc650678.png)

第一种情况是 Faster R-CNN CB-ResNet50 作为基线模型；
  
第二种情况是 CB-ResNet50-K3（K=3）作为基线，其中公式 (8) 中的辅助骨干网络权重 λ 设为零。
  
对于 K=2，当 λ1 设为 0.5 时，基线模型的 AP 提高了 0.8%。对于 K=3，当 λ1 和 λ2 分别设为 {0.5, 1.0} 时，AP 提高了 1.8%。实验结果验证了辅助监督是一种有效的训练策略，可以提升 CBNet 的性能。

#### 3）剪枝策略的效率

如图 6a 所示，使用剪枝策略后，我们的 CB-ResNet50 系列和 CB-ResNet50-K3 系列相比，在 FLOPs 与准确率的权衡上表现更优。这表明剪枝策略的有效性。

特别地，与 s4 相比，s3 的 FLOPs 减少了 10%，但准确率仅下降了 0.1%。这是因为在检测器训练过程中，被剪枝的阶段权重是固定的，因此剪枝并不会明显影响检测精度。因此，当计算速度和存储成本较为关键时，我们建议对 CBNet 中第 2, 3, …, K 个骨干网络的固定阶段进行剪枝。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/cf20333c199d4691b6874c8fd4ff8dc3.png)

#### 4）CBNet 中骨干网络的数量

为了进一步探索 CBNet 在构建高性能检测器方面的能力，我们通过调整骨干网络的数量（K=1,2,3,4,5）来评估 CBNet 的效率，并将其与 ResNet 系列进行比较（见图 6b）。

实验表明，随着模型复杂度的增加，检测精度不断提高。相比 ResNet152，当 K=2 时，我们的方法在计算成本更低的情况下取得了更高的准确率。同时，增加 K 到 3、4、5 时，准确率进一步提高。CBNet 提供了一种高效的方法来提升模型性能，而不仅仅是简单地增加骨干网络的深度或宽度。

#### 5）CBNetV1 和 CBNetV2 的比较

为了公平比较 CBNetV1（[1]）和 CBNetV2，我们依次将 DHLC 复合策略、辅助监督和剪枝策略应用于 CBNetV1，其中 AHLC 为默认复合策略（表 XV）。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/267c44a8aff54028bd571aa611b5b083.png)
  
CBNetV1 相比 Faster R-CNN ResNet50 基线提高 1.4% AP。
  
CBNetV1 的加速版本（s2 剪枝版本）推理速度从 22.4 FPS 提升到 26.6 FPS，但准确率下降了 0.4% AP。
  
在 CBNetV1 的基础上，辅助监督带来了 0.9% AP 的提升。
  
DHLC 复合策略相较 CBNetV1 默认策略（AHLC）提升了 1.3% AP。
  
结合 DHLC 和辅助监督后，相比基线有 2.1% AP 的显著提升。
  
通过剪枝（s3 版本），CBNetV2 在提升 AP（38.0% vs. 36.0%）的同时，推理速度更快（23.3 vs. 22.4 FPS）。
  
实验表明，DHLC 复合策略会降低检测器推理速度，但剪枝策略有效提升了 CBNetV2 的推理速度。

#### 6）CBNet 中使用相同骨干网络的重要性

为了验证 CBNet 中使用相同骨干网络的必要性，我们使用 ResNet50、ResNet101、Res2Net50 和 Res2Net101 进行组合实验（表 XVI）。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/8ec13c549590482f81bee60b33051d9c.png)
  
结果表明，使用相同骨干网络的 CBNet 具有更好的检测精度和更少的参数量。例如，CB-ResNet50 在 AP 和参数量上均优于 ResNet50-C-ResNet101 和 ResNet101-C-ResNet50。
  
**即使是来自不同家族的骨干网络，使用相同的骨干网络仍然比混合使用不同网络的效果更好**
。
  
实验结果表明，提高复合模型的多样性并不是 CBNet 最有效的方式。这可能是因为不同的骨干网络需要不同的优化策略，导致学习到的特征差异较大，难以联合训练。CBNet 的目标是让每个骨干网络学习到相似的特征，前面的骨干网络越强，主骨干输出的特征就越具代表性。因此，使用相同的骨干网络进行组合是 CBNet 最优的训练策略，这也与注重多样性的模型集成方法有所不同。

## 结论

在本文中，我们提出了一种新颖且灵活的主干网络框架，称为 复合主干网络（Composite Backbone Network，CBNet），以提升先进目标检测器的性能。

CBNet 由一系列具有相同网络结构的主干网络并行组成，采用 密集高层级复合策略（Dense Higher-Level Composition, DHLC） 和 辅助监督（Auxiliary Supervision），共同构建了一个稳健的表征能力强的主干网络，在 **预训练-微调（Pre-training Fine-tuning）**范式下利用现有的预训练主干网络。

CBNet 具有较强的泛化能力，适用于不同的主干网络和检测器架构的头部设计。大量实验表明，CBNet 兼容多种主干网络，包括基于 CNN（如 ResNet、ResNeXt、Res2Net）和基于 Transformer（如 Swin-Transformer）的网络。同时，相较于简单地增加网络深度和宽度，CBNet 更加 高效且有效。

此外，CBNet 可以灵活地集成到大多数主流检测器中，包括：

单阶段（One-stage）检测器（如 RetinaNet）；
  
双阶段（Two-stage）检测器（如 Faster R-CNN、Mask R-CNN、Cascade R-CNN 和 Cascade Mask R-CNN）；
  
基于 Anchor 的检测器（如 Faster R-CNN）；
  
基于 Anchor-Free 的检测器（如 ATSS）。
  
CBNet 还与 特征增强网络（如 DCN 和 HRNet）以及 模型集成方法兼容。实验表明，以上检测器的性能均提升了 超过 3% AP。

特别地，我们提出的 CB-Swin-L 在 COCO test-dev 数据集上取得了 59.4% 的 box AP 和 51.6% 的 mask AP，刷新了单模型单尺度的最佳成绩。在多尺度测试 条件下，无需额外训练数据，我们进一步达到了 60.1% box AP 和 52.3% mask AP 的最新最优结果。