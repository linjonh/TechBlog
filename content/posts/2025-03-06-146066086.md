---
layout: post
title: "机器学习深度学习基本概念logistic-regression和softmax"
date: 2025-03-06 12:38:17 +0800
description: "softmax用来处理多分类问题：比如llm在generate的时候，每个batch里面的一个样本的一个一次generate就是softmax生成一个大小为vocab_size的向量的概率分布，然后再采样。当W·x趋近于负无穷时sigmoid输出接近于0，当趋近于正无穷时，接近于1，来生成分类预测的概率。逻辑回归（logistic regression）的核心：sigmoid函数。softmax函数输出每个类别的概率，概率总和为1。逻辑回归用来处理二分类问题。对数损失作为损失函数。"
keywords: "机器学习深度学习基本概念：logistic regression和softmax"
categories: ['未分类']
tags: ['人工智能']
artid: "146066086"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146066086
    alt: "机器学习深度学习基本概念logistic-regression和softmax"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146066086
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146066086
cover: https://bing.ee123.net/img/rand?artid=146066086
image: https://bing.ee123.net/img/rand?artid=146066086
img: https://bing.ee123.net/img/rand?artid=146066086
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     机器学习深度学习基本概念：logistic regression和softmax
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     逻辑回归用来处理二分类问题
    </p>
    <p>
     softmax用来处理多分类问题：比如llm在generate的时候，每个batch里面的一个样本的一个一次generate就是softmax生成一个大小为vocab_size的向量的概率分布，然后再采样
    </p>
    <p>
     逻辑回归（logistic regression）的核心：sigmoid函数
    </p>
    <p>
     <img alt="" height="272" src="https://i-blog.csdnimg.cn/direct/d27bb5109c36469d807f74120bb4d088.png" width="524"/>
    </p>
    <p>
     <img alt="" height="213" src="https://i-blog.csdnimg.cn/direct/159202b171194c59957998f77ebfb1a4.png" width="320"/>
    </p>
    <p>
     当W·x趋近于负无穷时sigmoid输出接近于0，当趋近于正无穷时，接近于1，来生成分类预测的概率
    </p>
    <p>
     <img alt="" height="239" src="https://i-blog.csdnimg.cn/direct/eb22360e26414f30aa2f8a23442251b8.png" width="937"/>
    </p>
    <p>
     损失函数：
    </p>
    <p>
     <img alt="" height="350" src="https://i-blog.csdnimg.cn/direct/847b9b74b52c484dbd72d5e5c42f2c7c.png" width="969"/>
    </p>
    <p>
     对数损失作为损失函数
    </p>
    <p>
    </p>
    <p>
     softmax：
    </p>
    <p>
     <img alt="" height="450" src="https://i-blog.csdnimg.cn/direct/33a54d25aaf446d8abd60e088cc057eb.png" width="970"/>
    </p>
    <p>
     softmax函数输出每个类别的概率，概率总和为1
    </p>
    <p>
     损失函数：
    </p>
    <p>
     <img alt="" height="480" src="https://i-blog.csdnimg.cn/direct/9fe33087c83f4b9d800b679097534ee8.png" width="1125"/>
    </p>
    <p>
     <strong>
      log-softmax
     </strong>
    </p>
    <p>
     <img alt="" height="345" src="https://i-blog.csdnimg.cn/direct/9b9e20fa31434017b2a76cbedce3eaf8.png" width="870"/>
    </p>
   </div>
  </div>
 </article>
 <p alt="6874747073:3a2f2f626c6f672e6373646e2e6e65742f4252454b4f4a492f:61727469636c652f64657461696c732f313436303636303836" class_="artid" style="display:none">
 </p>
</div>


