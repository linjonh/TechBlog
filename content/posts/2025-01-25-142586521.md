---
layout: post
title: "全新Llama-3.2系列性能提升明显,但真的是最优选择吗已测试"
date: 2025-01-25 08:00:00 +0800
description: "令人兴奋的消息，Meta发布了Lllam3.2系列模型，当前的基准显示，Llama 3.2 在各种基"
keywords: "llama3.2 qwen2.5"
categories: ['未分类']
tags: ['大语言模型', '大模型应用', '人工智能', 'Llm', 'Llama', 'Llama', 'Ai']
artid: "142586521"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=142586521
  alt: "全新Llama-3.2系列性能提升明显,但真的是最优选择吗已测试"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=142586521
featuredImagePreview: https://bing.ee123.net/img/rand?artid=142586521
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     全新Llama 3.2系列：性能提升明显，但真的是最优选择吗？（已测试)
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     令人兴奋的消息，Meta发布了Lllam3.2系列模型，当前的基准显示，Llama 3.2 在各种基准测试中表现优于 Claude3.5 Haiku 以及 GPT-4o-mini；加上前几天的Qwen2.5，
     <strong>
      现在开源的模型正在一步步缩小和闭源模型之间的差距，这很棒。
     </strong>
    </p>
    <p>
     这是他们的第1次开源多模态大模型，总共有4个；其中两个是视觉模型（11B、90B）。90B可能是目前最大的视觉模型了，我记得前面一个比较大的是
     <strong>
      Qwen2 VL 72B。
     </strong>
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/0012ee21deec731830a89824a4dc4ad0.png"/>
    </p>
    <p>
     剩下的两个是1B和3B的，这些模型专为边缘计算和移动设备优化，支持 128k 令牌，擅长任务如摘要和遵循指令，针对各种处理器进行了优化。
    </p>
    <p>
     Llama3.2作为Llama3.1的替代品，它是经过优化的，速度、准确性提高，特别擅长图像标题、视觉问答，甚至图像文本检索。
    </p>
    <p>
     在这个演示视频中，你可以看到 Llama 3.2 模型能够准确分析和分类收据数据，随后以表格的形式展示结果，这正是 Llama 3.2 真正发光的地方。
    </p>
    <p>
     轻量级模型（10 亿和 30 亿模型）是专为设备使用场景设计的，这些模型通过剪枝以及不同类型的蒸馏技术创建。剪枝是通过系统地移除网络的一部分来减少模型大小，同时保留性能，它应用于 Llama 3.1 的 180 亿参数模型。
    </p>
    <p>
     另一种技术蒸馏则涉及从更大模型（如 80 亿和 700 亿参数的 Llama 3.1 系列）向较小模型转移知识，这通过在预训练过程中使用它们的输出作为目标来实现。这一过程将使新的 10 亿和 30 亿参数模型在保持强性能的同时变得更高效、更紧凑，这是 Meta 发布的一项非常酷的策略。
    </p>
    <p>
     这些模型使开发者能够构建个性化的本地代理应用程序，确保数据始终留在设备上。我认为这是支持工具调用的最小SLLM，这真是很酷。
    </p>
    <p>
     不同的模型适用于不同的场景，做端侧场景的人可能正在疯狂的搜索这样的小型SOTA模型。
    </p>
    <p>
     如果我们看看视觉基准，可以看到 11B 模型的表现类似于 Haiku，而 90B 模型的表现则类似于 GPT-4o-mini；他们都支持图像推理用例，比如文档级理解，包括图表和图形、图像标注以及基于自然语言描述精准定位图像中的物体。
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/3b5b10bad2ce2dd9ab6934d243ee811c.png"/>
    </p>
    <p>
     同时，小型模型的表现与 Gemma 2 和 Phi 3.5 相当，没有什么太大的突破。
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/a4880dec1fe384ad114b019e8fd06726.png"/>
    </p>
    <p>
     在他们的一系列分享中，网友热议的亮点包括但不限于：
    </p>
    <p>
     他们在 Hugging Face 上分享了模型权重，较小的模型也可以在 Ollama 上获得，但视觉模型却没有。不过，这些模型现在可以在 Together AI 上使用，所以我打算通过他们 测试一下，因为他们提供了一些免费积分。让我们开始测试吧。
    </p>
    <p>
     5片这种产品有多少卡路里 ?（应该是100）
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/b4d6be8d03d35d364be18fc0a3687c90.png"/>
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/4b198ae43cfb6a5c127157d21945370a.png"/>
    </p>
    <p>
     11B、 90B 都通过了,
    </p>
    <p>
     把上面的第一个基准测试转成csv
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/1de919d01dc5311955f1cc6c3040b5f5.png"/>
    </p>
    <p>
     两个模型都做到了，也没有什么数值上的错误
    </p>
    <p>
     使用HTML,CSS,JS制作一个精确的副本，将所有代码放在一个文件中。
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/53ad13e83c363e5202248a9a7a1802fc.png"/>
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/eb1707b09e015f708ba0f56d6dc93fc5.png"/>
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/110aafa89ca62485b337abd4adaa7fcc.png"/>
    </p>
    <p>
     似乎完全不太相似哈，90B(上)，11B（下）。
    </p>
    <p>
     下面这个问题是我新找出来的，没想到 …
    </p>
    <p>
     图片里有多少种水果?哪种水果最小，哪种水果最酸?它们具体放在哪里?
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/40fa2bc0f355c214ccc1b07038092fae.jpeg"/>
    </p>
    <p>
     看90B
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/33b95026a1c16d4061c3a4e55ec6f2eb.png"/>
    </p>
    <p>
     他说只有6种而实际上其实有7种，不过他说的大概位置是对的，只可惜最小的应该是葡萄，最酸的应该是柠檬。
    </p>
    <p>
     看11B：
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/e0c7d2caf107e4d05aa56a1960279f62.png"/>
    </p>
    <p>
     够敷衍的，我的天，他答案中是有正确答案的，可惜刚好说反了，而且令人可气的是他说位置都放在木栏里。这这这，你要说他不对吧他好像又对了，但是对又不怎么对，如果你要强行说他聪明：突然我都觉得他已经超越了一个维度，非常圆滑的跳出了这个判域，
    </p>
    <p>
     诶，难道他不在木篮里吗，你能怎么反驳？hhh
    </p>
    <p>
     不过我突然不死心了，我又连着测了两轮90B：
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/edd364516b415b1740bfb98f6e9a5ab1.png"/>
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/b0c5707ec20a2d64cd8f7a1567533c99.png"/>
    </p>
    <p>
     好吧，位置能找到（还能精确到行列数），数量摇摆不定，关于酸度，大小。。。尤其是大小，难道葡萄比较小这个认知都没有吗。
    </p>
    <p>
     画面中有什么，最引人注目的是什么，它有多少，有什么东西隐藏的东西吗？
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/387918b5eff7d33435c5407ba45cb32d.jpeg"/>
    </p>
    <p>
     90B：
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/5563d3ca0bbac57150f2540dfc10c81a.png"/>
    </p>
    <p>
     回答的还不错，水印说错了一些，应该是699pic.com，不过那水印人眼也挺难看的。
    </p>
    <p>
     11B:
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/8e498f982d3eb3b75c7995c1ba1e507e.png"/>
    </p>
    <p>
     水印瞎编的，石头提醒了一次还是多数了一块。
    </p>
    <p>
     下面：回答图片中的两个问题，
    </p>
    <p>
     让他“戴”一下人类遇到这些验证码时候的痛苦面具
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/fa642acbb42851ac85ca75ac6764cdb3.png"/>
    </p>
    <p>
     11B
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/91cfbd66b7b6246625df96c080431e0a.png"/>
    </p>
    <p>
     怎么还加了紫茄子，这都分不清吗
    </p>
    <p>
     90B
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/382abf1ec3fd4536989d93518861e612.png"/>
    </p>
    <p>
     都说错了，但是看起来11b更会乱说一些。
    </p>
    <p>
     OCR识别手稿
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/55b283f809a37dfc0135f0fa9d4ae39b.png"/>
    </p>
    <p>
     11B:
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/1b3d06a539cd60df1e44ee91f34314b3.png"/>
    </p>
    <p>
     90B:
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/65d27aace2bbf86576ba529d9acd971a.png"/>
    </p>
    <p>
     都识别都比较完美，堪比我本地的白描了，哈哈哈。
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/a9d423e05561240501d340996e00b1ee.png"/>
    </p>
    <p>
     总的来说，虽然这几款模型都还不错，回答一些问题中也表现了一些较理想的效果，但我在测试的过程中，遇到Llama 3.2对于问题的审查很严格，好几次让他创建其他网页截图代码都不通过，或者其他有关的图片问题直接不回答。
    </p>
    <p>
     Qwen 2 VL 72B 与 Llama 3.2 90B 模型相当，意味着一个更小的模型可以做到 90B 所做的事情，而且它的审查更少。11B 模型相对而言幻觉更多，Pixol 在这个领域要好得多，甚至 Qwen 2 VL 7B 也更好。
    </p>
    <p>
     总之，Quen 2 VL 72B 可能仍然是视觉任务的最佳模型，Llama3.2 这些模型还不够好，而且它们比竞争对手大，却提供较低的结果，当然你可以去做更多的测试。
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/d30a496bf7b3ea4c2c2bf30f0af58b99.jpeg"/>
     <br/>
     ​
    </p>
    <h3>
     <a id="_143">
     </a>
     如何学习大模型
    </h3>
    <p>
     现在社会上大模型越来越普及了，已经有很多人都想往这里面扎，但是却找不到适合的方法去学习。
    </p>
    <p>
     作为一名资深码农，初入大模型时也吃了很多亏，踩了无数坑。现在我想把我的经验和知识分享给你们，帮助你们学习AI大模型，能够解决你们学习中的困难。
    </p>
    <p>
     我已将重要的AI大模型资料包括市面上AI大模型各大白皮书、AGI大模型系统学习路线、AI大模型视频教程、实战学习，等录播视频免费分享出来，需要的小伙伴可以扫取。
    </p>
    <img src="https://img-blog.csdnimg.cn/img_convert/c9199bff347dc4b8f73b568b5d6d38b4.jpeg"/>
    <p>
     <strong>
      一、AGI大模型系统学习路线
     </strong>
    </p>
    <p>
     很多人学习大模型的时候没有方向，东学一点西学一点，像只无头苍蝇乱撞，我下面分享的这个学习路线希望能够帮助到你们学习AI大模型。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/direct/a8136a7d40614dff8a585c17e63c0d3e.png"/>
    </p>
    <p>
     <strong>
      二、AI大模型视频教程
     </strong>
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/direct/4710d75c5e794fe5acd76c9dc3c9b568.png"/>
    </p>
    <p>
     <strong>
      三、AI大模型各大学习书籍
     </strong>
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/direct/8e88cca417324c0a8e714f01e64376f9.png"/>
    </p>
    <p>
     <strong>
      四、AI大模型各大场景实战案例
     </strong>
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/direct/59b4a9db64e44ea781bfdc2774f1c0ba.png"/>
    </p>
    <p>
     <strong>
      五、结束语
     </strong>
    </p>
    <p>
     学习AI大模型是当前科技发展的趋势，它不仅能够为我们提供更多的机会和挑战，还能够让我们更好地理解和应用人工智能技术。通过学习AI大模型，我们可以深入了解深度学习、神经网络等核心概念，并将其应用于自然语言处理、计算机视觉、语音识别等领域。同时，掌握AI大模型还能够为我们的职业发展增添竞争力，成为未来技术领域的领导者。
    </p>
    <p>
     再者，学习AI大模型也能为我们自己创造更多的价值，提供更多的岗位以及副业创收，让自己的生活更上一层楼。
    </p>
    <p>
     <strong>
      因此，学习AI大模型是一项有前景且值得投入的时间和精力的重要选择。
     </strong>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f707974686f6e313233345f2f:61727469636c652f64657461696c732f313432353836353231" class_="artid" style="display:none">
 </p>
</div>
