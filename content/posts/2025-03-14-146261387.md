---
layout: post
title: "DataWhale-大语言模型-GPT和DeepSeek模型介绍"
date: 2025-03-14 17:05:19 +0800
description: "本课程围绕中国人民大学高瓴人工智能学院赵鑫教授团队出品的《大语言模型》书籍展开，覆盖大语言模型训练与使用的全流程，从预训练到微调与对齐，从使用技术到评测应用，帮助学员全面掌握大语言模型的核心技术。并且，课程内容基于大量的代码实战与讲解，通过实际项目与案例，学员能将理论知识应用于真实场景，提升解决实际问题的能力。课程地址：https://www.datawhale.cn/learn/summary/107赵鑫教授团队：http://aibox.ruc.edu.cn/"
keywords: "DataWhale 大语言模型 - GPT和DeepSeek模型介绍"
categories: ['未分类']
tags: ['语言模型', '人工智能', 'Gpt']
artid: "146261387"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146261387
    alt: "DataWhale-大语言模型-GPT和DeepSeek模型介绍"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146261387
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146261387
cover: https://bing.ee123.net/img/rand?artid=146261387
image: https://bing.ee123.net/img/rand?artid=146261387
img: https://bing.ee123.net/img/rand?artid=146261387
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     DataWhale 大语言模型 - GPT和DeepSeek模型介绍
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     本课程围绕中国人民大学高瓴人工智能学院赵鑫教授团队出品的《大语言模型》书籍展开，覆盖大语言模型训练与使用的全流程，从预训练到微调与对齐，从使用技术到评测应用，帮助学员全面掌握大语言模型的核心技术。并且，课程内容基于大量的代码实战与讲解，通过实际项目与案例，学员能将理论知识应用于真实场景，提升解决实际问题的能力。
    </p>
    <p>
     课程地址：https://www.datawhale.cn/learn/summary/107
    </p>
    <p>
     赵鑫教授团队：http://aibox.ruc.edu.cn/
    </p>
    <p>
     课程学习地址：
     <a href="https://www.datawhale.cn/learn/content/107/3267" rel="nofollow" title="Datawhale-学用 AI,从此开始">
      Datawhale-学用 AI,从此开始
     </a>
    </p>
    <p>
     视频地址：
     <a href="https://www.bilibili.com/video/BV1VhRKYEENT?vd_source=9f2d252c81af9097ef70bb0c9b830406&amp;spm_id_from=333.788.videopod.sections" rel="nofollow" title="《大语言模型》1.3 GPT+DeepSeek模型介绍_哔哩哔哩_bilibili">
      《大语言模型》1.3 GPT+DeepSeek模型介绍_哔哩哔哩_bilibili
     </a>
    </p>
    <p>
     <img alt="" height="1239" src="https://i-blog.csdnimg.cn/direct/c2e6d9bf130b459cbc78535bbe891408.png" width="2623"/>
    </p>
    <p>
    </p>
    <h2>
     GPT（Generative Pre-trained Transformer）系列模型是由OpenAI开发的一系列基于Transformer架构的预训练语言模型。以下是GPT系列模型的发展历程：
    </h2>
    <p>
     <br/>
     1. GPT (2018)
     <br/>
     发布时间：2018年6月
     <br/>
     特点：GPT是基于Transformer的解码器模型，采用了无监督预训练和有监督微调两阶段训练方法。预训练使用了大量未标注的文本数据，微调则针对特定任务进行。
     <br/>
     能力：GPT能够生成连贯的文本，并在多种自然语言处理任务中表现出色。
     <br/>
     2. GPT-2 (2019)
     <br/>
     发布时间：2019年2月
     <br/>
     特点：GPT-2是GPT的升级版，拥有更多的参数（1.5亿到15亿）和更大的数据集。OpenAI最初计划逐步释放模型的不同版本，但由于对模型可能被滥用的担忧，最终决定直接发布了完整模型。
     <br/>
     能力：GPT-2在文本生成方面表现更加出色，能够生成更加连贯和有深度的文本。
     <br/>
     3. GPT-3 (2020)
     <br/>
     发布时间：2020年5月
     <br/>
     特点：GPT-3是一个巨大的语言模型，拥有1750亿个参数，是当时最大的语言模型。GPT-3展示了显著的学习和泛化能力，能够在多种任务上仅通过少量示例就能实现很好的性能。
     <br/>
     能力：GPT-3能够进行翻译、回答问题、写文章、编写代码等，其能力范围远远超出了传统的语言模型。
     <br/>
     4. GPT-3.5 (2022)
     <br/>
     发布时间：2022年
     <br/>
     特点：GPT-3.5是GPT-3的改进版，虽然参数数量没有显著增加，但在指令遵循和上下文学习方面有了显著提升。GPT-3.5采用了基于人类反馈的强化学习（RLHF）技术来训练模型。
     <br/>
     能力：GPT-3.5在理解复杂指令和生成更加人性化的文本方面有了显著进步。
     <br/>
     5. GPT-4 (2023)
     <br/>
     发布时间：2023年3月
     <br/>
     特点：GPT-4是一个多模态模型，不仅能够处理文本，还能处理图像输入。GPT-4在理解和生成文本方面有了更大的提升，同时减少了错误和偏见。
     <br/>
     能力：GPT-4在多种任务上表现出色，包括数学、逻辑推理、文本理解等，并且在视觉输入的处理上也展现了能力。
     <br/>
     GPT系列模型的发展展示了深度学习和自然语言处理领域的快速进步，特别是在模型规模、预训练技术和应用范围方面的突破。随着模型能力的增强，关于其潜在影响、伦理问题和监管的讨论也越来越多。
    </p>
    <p>
    </p>
    <p>
    </p>
    <h2>
     DeepSeek系列模型的技术演变是一个引人注目的过程，涵盖了从基础架构优化到混合专家架构的革新，再到强化学习训练的多个阶段。
    </h2>
    <p>
     <br/>
     DeepSeek-V1（2024年1月）
     <br/>
     技术特点：DeepSeek-V1采用了Gshard MoE架构，并解决了相关的工程训练问题。它引入了专家级的损失计算均衡方式，以应对分布式训练中的高通信成本。
     <br/>
     参数规模：模型总参数约为1.89B，激活参数量为0.24B。
     <br/>
     性能：在代码、数学和推理领域超越了LLaMA-2 70B，并在与GPT-3.5的对比中表现出更优异的性能。
     <br/>
     DeepSeek-V2（2024年5月）
     <br/>
     技术特点：DeepSeek-V2将模型规模扩展到百亿MoE，并解决了各种负载均衡问题，实现了高效训练。同时，引入了MLA（混合局部注意力）以优化推理效率。
     <br/>
     参数规模：模型总参数约为236B，激活参数量为21B。
     <br/>
     DeepSeek-V3
     <br/>
     技术特点：DeepSeek-V3进一步扩展了模型规模，并引入了多令牌预测和无辅助损失的负载均衡策略，实现了更高的性能和更低的训练成本。
     <br/>
     DeepSeek-R1
     <br/>
     技术特点：DeepSeek-R1通过强化学习和冷启动数据显著提升了模型的推理能力。此外，它还通过蒸馏技术将推理能力扩展到小型模型。
     <br/>
     创新：这一阶段的模型在架构设计、训练算法和推理效率上实现了质的飞跃。
     <br/>
     总结
     <br/>
     DeepSeek系列模型的发展历程体现了从基础架构优化到混合专家架构的革新，再到强化学习训练的逐步演进。每一代模型都在解决前一代模型的局限性，同时引入新的技术和优化策略，以提升性能和效率。这一过程不仅展示了人工智能领域的快速发展，也体现了大模型研究的重要性和潜力。
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="6874747073:3a2f2f626c6f672e6373646e2e6e65742f737072696e67352f:61727469636c652f64657461696c732f313436323631333837" class_="artid" style="display:none">
 </p>
</div>


