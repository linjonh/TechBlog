---
layout: post
title: "Matlab多种算法解决未来杯B的多分类问题"
date: 2025-03-14 15:48:57 +0800
description: "本文使用 MATLAB 实现了 8 种分类模型，并进行了训练、预测和评估。通过混淆矩阵和精度可视化，帮助选择最优模型。我们将 80% 的数据用于训练，20% 用于验证。我们选取 8 种常见分类模型，并存储预测结果。将预测结果保存为 Excel 文件。"
keywords: "Matlab多种算法解决未来杯B的多分类问题"
categories: ['未分类']
tags: ['算法', '机器学习', '未来杯', '数学建模', '分类', '人工智能', 'Matlab']
artid: "146259239"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146259239
    alt: "Matlab多种算法解决未来杯B的多分类问题"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146259239
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146259239
cover: https://bing.ee123.net/img/rand?artid=146259239
image: https://bing.ee123.net/img/rand?artid=146259239
img: https://bing.ee123.net/img/rand?artid=146259239
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Matlab多种算法解决未来杯B的多分类问题
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h3>
     <strong>
      1. 读取数据
     </strong>
    </h3>
    <p>
     首先，我们从 Excel 文件中读取训练集和测试集：
    </p>
    <h3>
     <strong>
      2. 训练集划分
     </strong>
    </h3>
    <p>
     我们将 80% 的数据用于训练，20% 用于验证。
    </p>
    <h3>
     <strong>
      3. 训练多个模型
     </strong>
    </h3>
    <p>
     我们选取 8 种常见分类模型，并存储预测结果。
    </p>
    <pre><code class="language-Matlab">for i = 1:length(modelNames)
    switch modelNames{i}
        case 'Multinomial Logistic Regression'
            B = mnrfit(X_train, Y_train, 'model', 'nominal');
            predProb = mnrval(B, X_test);
            [~, predictions{i}] = max(predProb, [], 2);
            predProb_val = mnrval(B, X_val);
            [~, val_predictions] = max(predProb_val, [], 2);
        
        case 'Decision Tree'
            model = fitctree(X_train, Y_train);
            predictions{i} = predict(model, X_test);
            val_predictions = predict(model, X_val);
        
        case 'Random Forest'
            model = fitcensemble(X_train, Y_train, 'Method', 'Bag');
            predictions{i} = predict(model, X_test);
            val_predictions = predict(model, X_val);
        
        case 'SVM'
            model = fitcecoc(X_train, Y_train);
            predictions{i} = predict(model, X_test);
            val_predictions = predict(model, X_val);
        
        case 'KNN'
            model = fitcknn(X_train, Y_train);
            predictions{i} = predict(model, X_test);
            val_predictions = predict(model, X_val);
        
        case 'BP Neural Network'
            model = feedforwardnet(15);
            model = train(model, X_train', full(ind2vec(Y_train')));
            nnOutput = model(X_test')';
            [~, predictions{i}] = max(nnOutput, [], 2);
            nnOutput_val = model(X_val')';
            [~, val_predictions] = max(nnOutput_val, [], 2);
        
        case 'GBM'
            model = fitcensemble(X_train, Y_train, 'Method', 'AdaBoostM2');
            predictions{i} = predict(model, X_test);
            val_predictions = predict(model, X_val);
        
        case 'AdaBoost'
            model = fitcensemble(X_train, Y_train, 'Method', 'AdaBoostM2');
            predictions{i} = predict(model, X_test);
            val_predictions = predict(model, X_val);
    end
</code></pre>
    <h3>
     <strong>
      4. 结果输出
     </strong>
    </h3>
    <h4>
     <strong>
      （1）存储预测结果
     </strong>
    </h4>
    <p>
     将预测结果保存为 Excel 文件。
    </p>
    <h4>
     <strong>
      （2）模型评估
     </strong>
    </h4>
    <p>
     使用
     <strong>
      混淆矩阵
     </strong>
     和
     <strong>
      精度计算
     </strong>
     评估模型。
    </p>
    <h3>
     <strong>
      5. 结果分析
     </strong>
    </h3>
    <ul>
     <li>
      <strong>
       逻辑回归
      </strong>
      ：适用于线性可分数据，易解释但精度有限。
     </li>
     <li>
      <strong>
       决策树
      </strong>
      ：易于理解但容易过拟合。
     </li>
     <li>
      <strong>
       随机森林
      </strong>
      ：更稳定，适用于高维数据。
     </li>
     <li>
      <strong>
       SVM
      </strong>
      ：适用于小样本数据，但计算成本较高。
     </li>
     <li>
      <strong>
       KNN
      </strong>
      ：简单但计算量大，适用于小规模数据。
     </li>
     <li>
      <strong>
       BP 神经网络
      </strong>
      ：可处理复杂关系，但训练时间长。
     </li>
     <li>
      <strong>
       GBM
      </strong>
      和
      <strong>
       AdaBoost
      </strong>
      ：适用于非线性关系，但超参数调优重要。
     </li>
    </ul>
    <h3>
     <strong>
      总结
     </strong>
    </h3>
    <p>
     本文使用 MATLAB 实现了 8 种分类模型，并进行了训练、预测和评估。通过混淆矩阵和精度可视化，帮助选择最优模型。
    </p>
    <p>
     完整代码：
    </p>
    <pre><code class="language-Matlab">% 导入训练集
trainData = readtable('train.xlsx');
X = table2array(trainData(:, 1:end-1)); % 特征
Y = trainData{:, end}; % 类别（多分类）

% 导入测试集 (没有标签的测试集)
testData = readtable('test.xlsx');
X_test = table2array(testData(:, 1:end)); % 测试集特征

% 分割数据集：80% 用于训练，20% 用于验证
cv = cvpartition(size(X, 1), 'HoldOut', 0.2);
X_train = X(training(cv), :); % 80%的训练数据
Y_train = Y(training(cv), :);
X_val = X(test(cv), :); % 20%的验证数据
Y_val = Y(test(cv), :);

% 确保 Y_train 和 Y_val 是数值类型
if iscategorical(Y_train)
    Y_train = double(Y_train); % 转换为数值型
end
if iscategorical(Y_val)
    Y_val = double(Y_val); % 转换为数值型
end

% 确保 X_train 和 X_test 的列数一致
disp(size(X_train)); % 打印 X_train 的大小
disp(size(X_test));  % 打印 X_test 的大小

% 定义模型名称
modelNames = {'Multinomial Logistic Regression', 'Decision Tree', 'Random Forest', ...
              'SVM', 'KNN', 'BP Neural Network', 'GBM', 'AdaBoost'};
models = cell(length(modelNames), 1); % 用于存储模型
predictions = cell(length(modelNames), 1); % 用于存储测试集的预测结果

% 循环遍历每个模型
for i = 1:length(modelNames)
    switch modelNames{i}
        case 'Multinomial Logistic Regression'
            % 多分类逻辑回归
            B = mnrfit(X_train, Y_train, 'model', 'nominal');
            predProb = mnrval(B, X_test); % 预测类别概率
            [~, predictions{i}] = max(predProb, [], 2); % 返回概率最大类别
            
            % 在验证集上进行预测
            predProb_val = mnrval(B, X_val); % 在验证集上进行预测
            [~, val_predictions] = max(predProb_val, [], 2);
        
        case 'Decision Tree'
            % 决策树
            model = fitctree(X_train, Y_train);
            predictions{i} = predict(model, X_test);
            val_predictions = predict(model, X_val); % 在验证集上进行预测
        
        case 'Random Forest'
            % 随机森林
            model = fitcensemble(X_train, Y_train, 'Method', 'Bag');
            predictions{i} = predict(model, X_test);
            val_predictions = predict(model, X_val); % 在验证集上进行预测
        
        case 'SVM'
            % SVM 用于多分类
            model = fitcecoc(X_train, Y_train); % 使用 fitcecoc 来处理多分类
            predictions{i} = predict(model, X_test);
            val_predictions = predict(model, X_val); % 在验证集上进行预测
        
        case 'KNN'
            % K-近邻
            model = fitcknn(X_train, Y_train);
            predictions{i} = predict(model, X_test);
            val_predictions = predict(model, X_val); % 在验证集上进行预测
        
        case 'BP Neural Network'
            % BP 神经网络
            model = feedforwardnet(15); % 10为隐藏层神经元个数
            model = train(model, X_train', full(ind2vec(Y_train'))); % ind2vec用于多类
            nnOutput = model(X_test')'; % 输出神经网络预测结果
            [~, predictions{i}] = max(nnOutput, [], 2); % 选择概率最高的类
            nnOutput_val = model(X_val')'; % 在验证集上进行预测
            [~, val_predictions] = max(nnOutput_val, [], 2); % 选择概率最高的类
        
        case 'GBM'
            % 梯度提升（GBM） - 使用适合多分类的 AdaBoostM2
            model = fitcensemble(X_train, Y_train, 'Method', 'AdaBoostM2'); 
            predictions{i} = predict(model, X_test);
            val_predictions = predict(model, X_val); % 在验证集上进行预测


        
        case 'AdaBoost'
            % AdaBoost
            model = fitcensemble(X_train, Y_train, 'Method', 'AdaBoostM2');
            predictions{i} = predict(model, X_test);
            val_predictions = predict(model, X_val); % 在验证集上进行预测
    end
    
    % 输出每个模型的预测结果为 Excel 文件
    results = table(predictions{i}, 'VariableNames', {'Predictions'});
    writetable(results, ['XXX_' modelNames{i} '_trainend.xlsx']);
    
    % 将预测类别标签添加到测试集最后一列
    testResults = testData;
    testResults.Predictions = predictions{i}; % 添加预测结果列
    writetable(testResults, ['XXX_' modelNames{i} '_test_with_predictions.xlsx']);
    
    % 在验证集上评估模型的精度
    figure;
    cm = confusionchart(Y_val, val_predictions); % 使用Y_val进行混淆矩阵计算
    title(['Confusion Matrix - ' modelNames{i} ' (Validation Set)']);
    
    % 计算并显示精度
    accuracy = sum(diag(cm.NormalizedValues)) / sum(cm.NormalizedValues(:));
    fprintf('%s Validation Accuracy: %.2f%%\n', modelNames{i}, accuracy * 100);
    
    % 可视化精度
    figure;
    bar(accuracy);
    title(['Validation Accuracy of ' modelNames{i}]);
    xlabel('Model');
    ylabel('Accuracy');
    xticks(1);
    xticklabels({modelNames{i}});
end
</code></pre>
    <p>
     产生：
    </p>
    <p>
     <img alt="" height="515" src="https://i-blog.csdnimg.cn/direct/f3770208c4a44e838f03968960318dfe.png" width="632"/>
    </p>
    <p>
     Multinomial Logistic Regression Validation Accuracy: 92.16%
     <br/>
     Decision Tree Validation Accuracy: 80.39%
     <br/>
     Random Forest Validation Accuracy: 90.20%
     <br/>
     SVM Validation Accuracy: 94.12%
     <br/>
     KNN Validation Accuracy: 92.16%
     <br/>
     BP Neural Network Validation Accuracy: 88.24%
     <br/>
     GBM Validation Accuracy: 84.31%
     <br/>
     AdaBoost Validation Accuracy: 84.31%
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f7375626a656374363235527562656e2f:61727469636c652f64657461696c732f313436323539323339" class_="artid" style="display:none">
 </p>
</div>


