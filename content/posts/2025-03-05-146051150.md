---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34313337303833332f:61727469636c652f64657461696c732f313436303531313530"
layout: post
title: "李宏毅机器学习课程笔记05-卷积神经网络Convolutional-Neural-NetworkCNN"
date: 2025-03-05 19:58:15 +08:00
description: "Full Connected Layer弹性最大  => Full Connected的network可以选择看一张图片还是看图片的部分，如果需要看图片的部分只需要将weight设置成0不需要看整张图，只需要看图片的一小部分就可侦测出重要的Pattern=> 这一小部分被称为=> 弹性会变小Model的弹性很高时容易导致弹性很好可以做各式各样的事情但没办法在每个任务表现很好。CNN存在。"
keywords: "李宏毅机器学习课程笔记05 | 卷积神经网络Convolutional Neural Network(CNN)"
categories: ['机器学习']
tags: ['笔记', '机器学习', 'Cnn']
artid: "146051150"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146051150
    alt: "李宏毅机器学习课程笔记05-卷积神经网络Convolutional-Neural-NetworkCNN"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146051150
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146051150
cover: https://bing.ee123.net/img/rand?artid=146051150
image: https://bing.ee123.net/img/rand?artid=146051150
img: https://bing.ee123.net/img/rand?artid=146051150
---

# 李宏毅机器学习课程笔记05 | 卷积神经网络Convolutional Neural Network(CNN)

**本章提要**

1. 为什么设计NetWork的架构设计会让Network结果做得更好。
2. 透过CNN，看NetWork架构的设计有什么想法。

### Image Classification

在下面的讨论里，假设输入的图片大小是100*100的，这里的目标是分类，我们将每一个图片表示为
`One-Hot`
的向量，将其称为

y
^
\hat y












y





^

​

。

> 目前做影响辨识的时候，往往都有这样的假设。如果输入的不一样，常见的处理方式是把所有图片都先Rescale成大小一样

模型通过
`soft-max`
后输出为

y
′
y'






y










′
，我们希望

y
′
y'






y










′
和

y
^
\hat y












y





^

​

的
`Cross Entropy`
越小越好。

![](https://i-blog.csdnimg.cn/img_convert/2920215aed74da88b05885d12411fcc0.png)

**补充1**
：soft-max的作用

①归一化
`normalization`
每一个分量，并且和为1。

② 原本大的值跟小的值的
**差距更大**

**补充2：**
cross-entropy loss function 是在机器学习中比较常见的一种损失函数。

#### 问题：怎么将一张图片当作一个模型的输入

对于机器来说，一张图片其实是一个三维的
`Tensor`
(维度大于2的矩阵就是
`Tensor`
)。其中一维表示图片的宽、另外一维表示图片的高、最后一维表示图片的
`Channel`
数目。

图片中每个像素都是由RGB三个颜色所组成，3个
`Channel`
就代表了RGB的三个颜色，也就是说3个
`Channel`
表示一个像素点。长*宽表示图片的像素数量。

将三维
`Tensor`
拉直后丢到一个
`Network`
里，拉直后的向量维度为
`100*100*3`
，每一维是某个
`pixel`
像素的某个颜色强度。

![](https://i-blog.csdnimg.cn/img_convert/e26a5c912b5508908e1823ceddce48a6.png)

#### 全连接网络Fully Connected Network

我们之前课程学习的网络是全连接网络，每一个
`Neuron`
跟每一个特征都有一个权重
`Weight`
。在本例中输入向量的每一个维度都是一个特征，那么每一个
`Neuron`
跟输入向量的每一个数值都有一个
`Weight`
。

假设第一层的
`Neuron`
数目有1000个，这里的特征有100*100*3，那么一共有

3
∗
1
0
7
3*10^7





3



∗





1


0









7
个
`Weight`
。

**之前的例子补充理解**

其实当天的观看人数可以和前几天的有关，模型可以表示为

=
b
+
∑
i
s
i
g
m
o
i
d
(
b
i
+
∑
j
w
i
j
x
j
)
=b+\sum_isigmoid(b_i+\sum_jw_{ij}x_j)





=





b



+






∑









i

​




s

i

g

m

o

i

d

(


b









i

​




+






∑









j

​





w










ij

​



x









j

​


)
i是不同的function函数数量，j表示当前日期的前j天，

w
i
j
w_{ij}






w










ij

​

第i个sigmoid给第j个特征的权重。
  
![](https://i-blog.csdnimg.cn/img_convert/5d833d20ebe3412d616ffdd4899d980d.png)

**问题：模型的参数过多，可以增加模型的弹性，同时也增加了Overfitting的风险**

之前学习的例子，方便理解

**补充说明**
：为什么模型参数越多，增加Overfitting的风险

![](https://i-blog.csdnimg.cn/img_convert/d526f3ea1be26551bc4e189d9820c401.png)

#### 版本1神经元角度：观察1 Receptive Field

影像辨识的类神经网络的
`Neuron`
任务就是侦测输入的图片里有没有出现一些特别重要的
`Pattren`
，这个
`Pattern`
代表了某种物件。

![](https://i-blog.csdnimg.cn/img_convert/864bc5dfcf9349f8c7c16f614a7a0c5c.png)

**识别的目标变成了**
：让
`Neuron`
判断有没有某种
`Pattern`
出现

不需要每个
`Neuron`
都去看一整张图(连接所有特征)，也就是说对于每个
`Neuron`
其实不需要将整个图片当作输入，只需要把图片的一小部分当作输入就足够让它们侦测某些特别关键的
`Pattern`
。

##### Typical Setting

在CNN中会设定一个
`Receptive Field`
区域，每一个
`Neuron`
都只关心自己的
`Receptive Field`
里面发生的事情。

假设下图中
`Receptive Field`
有3(长)*3(宽)*3(深)数值，下图蓝色
`neuron`
只需要关心这个范围就可以了。将这3
*3*
3的数值拉直成27维向量(27个特征)作为neuron的输入，
`Neuron`
会给每一维一个
`weight`
，所以这里有3*3*3=27个
`weight`
(每一维是某个
`pixel`
像素的某个颜色强度，可以看成一个特征)

![](https://i-blog.csdnimg.cn/img_convert/4ae993e807244218b250e6fe669fab63.png)

**问题**
：如何选出
`Receptive Field`
?

自己设置
  
1.每个
`Neuron`
的守卫区域可以重叠

2.不同的
`Neuron`
可以守卫同一个区域

> 每一个
> `Receptive Field`
> 区域的大小可不可以不一样？ => 可以不一样
>
> 有些
> `Pattern`
> 可能只会在蓝色的 Channel出现，可不可以只考虑一个Channel => 可以
>
> 怎么确保一个
> `Pattern`
> 没有被拆分给不同的
> `Neuron`

**Typical Setting**
：最经典的设计是什么样的？

1. 会看所有的Channel(RGB一起)，而不是单一颜色 => 所以在描述
   `Receptive Field`
   时只需要将宽高(被称为kernel size)，因为深度就是3。

一般
`kernel size`
不会设太大，影像辨识中一般3*3就足够了

2. 同一个
   `Receptive Field`
   会有一组
   `Neuron`
   去守备这个范围，比如64或者128 => 使用一组的
   `Neuron`
   为了识别不同的模式
3. 将一个
   `Receptive Field`
   往其他方向移动一点(移动范围被称为
   `stride`
   )制造一个新的
   `Receptive Field`
   =>
   `stride`
   是一个超参数，需要自己调大小，一般不会设置太大，通常设置为1或者2

希望不同的
`Receptive Field`
之间有重叠(高度重叠)，某个
`Pattern`
可能被拆分给不同的
`Neuron`
。如果
`Receptive Field`
没有重叠，那么会没有
`Neuron`
去侦测它。

**问题**
：如果一个范围为3*3，移动到最右侧时部分区域超出影像范围怎么办？

**解决办法**
：超出的部分采用Padding补值，可以补0或者采用其他策略补值

![](https://i-blog.csdnimg.cn/img_convert/882bc6c9ce85bc28873c49febd401a2c.png)

#### 版本1神经元角度：观察2 parameter sharing共享参数

观察到：同一个
`Pattern`
可能出现在图片的不同区域

![](https://i-blog.csdnimg.cn/img_convert/2a7e46c1567a1591c96c31316c4656e5.png)

不管在哪里，
`Pattern`
都应该在某一个
`Neuron`
的
`Receptive Field`
区域，所以鸟嘴都会被侦测出来。 => 这些侦测鸟嘴的
`Neuron`
做的事情是一样的，只是守备的范围不一样。

每一个守备范围都去放一个侦测鸟嘴的
`Neuron`
吗？

**结果**
：让不同
`Receptive Field`
的
`Neuron`
共享参数，两个
`Neuron`
的
`Weight`
完全一样

![](https://i-blog.csdnimg.cn/img_convert/3789ddecd6ef8ec0da3cc4458673c30c.png)

不会让两个守备一模一样范围的Neuron共享参数，因为它们的输出肯定是一样的(输入和参数都一样)

**问题**
：共享参数后只能检测一种
`Pattern`
吗？

**解答**
：多个神经元对同一个
`Receptive Field`
进行侦测，其中一个神经元因为共享了参数所以具备检测鸟嘴的能力

**在影像辨识中常见的参数共享方式**
：怎么共享是自己决定的

共享参数的神经元被叫做
`filter`
(一组weight)

![](https://i-blog.csdnimg.cn/img_convert/03b6159ec3f80be5e07d121ef77c54e1.png)

#### 总结 Convolutional Layer的好处

Full Connected Layer弹性最大 => Full Connected的network可以选择看一张图片还是看图片的部分，如果需要看图片的部分只需要将
`weight`
设置成0

不需要看整张图，只需要看图片的一小部分就可侦测出重要的
`Pattern`
=> 这一小部分被称为
`Receptive Field`
=> 弹性会变小

![](https://i-blog.csdnimg.cn/img_convert/19a06e50d0ec7bf4a8f7d85a0e4b5aae.png)

Model的弹性很高时容易导致
`Overfitting`
，
`Full Connected Layer`
弹性很好可以做各式各样的事情但没办法在每个任务表现很好。

CNN存在
`Larger model bias`
(模型的限制变大不灵活或者理解成模型的弹性变小) => CNN专门为影像设计的(Receptive Field+ Parameter Sharing)，模型的限制也是为了更好的融合影像特征，所以在影像上效果很好。

#### Convolutional Layer的版本2：filter角

`Convolution`
里面有很多
`Filter`
，每个
`Filter`
的大小为3
*3*
`channel`
的
`tensor`
。每个
`Filter`
的作用是抓取某个
`Pattern`

* 如果是彩色图片，channel=3(RGB)
* 如果是黑白图片，channel=1(black and white)

![](https://i-blog.csdnimg.cn/img_convert/758a7af2997d517ca03b28b9335ec3ff.png)

**问题**
：Filter怎么在图片中抓取Pattern？

假设Channel=1 => 黑白图

假设Filter里的参数已知 => 实际上
`Tensor`
里面的数值是
`Model`
里面的
`Parameter`
，这里的数值其实是未知的，要通过训练训练集找出。

**解**

1.先将Filter1(3*3*1)放在图片的左上角

2.将Filter里的九个值跟图片左上角范围内的9个值相乘(9个参数与特征相乘)，然后结果累加起来(向量内积)。 => 模型中的

∑
w
x
\sum wx





∑



w

x

3.将Filter1右移
`Stride`
步(如果扫完就先往下移算完继续往右)， 重复过程2。

4.图片全部扫完

![](https://i-blog.csdnimg.cn/img_convert/2c9ab5a6882aa1a3ec5d2ef485fa08f5.png)

开始
`Filter2`
，
`Filter2`
侦察中间1列都为1的Pattern，重复上述过程。

![](https://i-blog.csdnimg.cn/img_convert/53e9ab17f608e833770fc49ca45d0493.png)

每一个Filter都会给出一组数字，比如Filter1给出一组橙色的数字，Filter2给出一组蓝色的数字。这组数字被称为
`Feature Map`
。

**第一层的Convolutional Layer**
=> 输入图片，输出
`Feature Map`

我们将一张图片通过一个
`Convolutional Layer`
，产生了一个
`Feature Map`
。假设有64个filters，那么产生的
`Feature Map`
就有64组数字。

可以将生成
`Feature Map`
看成一张新的图片，只是图片的Channel=64(64组数据的叠加？类似RGB图的Channel=3)

**第二层的Convolutional Layer**
=> 输入
`Feature Map`

第二层的
`Convolutional Layer`
里面也有一堆Filter，由于我们将第一层生成的
`Feature Map`
看成了一张新的图片，那么第二次的
`Convolutional Layer`
将识别
`Feature Map`
里的
`Pattern`
。

这里的Filter大小也设为3*3*channel(这里3*3是自定义的)，channel必须为64(因为新图片的channel=64) =>
**Convolution Layer里filters设置的channel要和输入图片的channel相同**

![](https://i-blog.csdnimg.cn/img_convert/fdcd992d9c0abd3997e3fa2b06d23966.png)

**问题**
：如果filter的大小一直设置为3*3，会不会让Network没有办法看较大范围的Pattern呢？

第二次Convolution layer的filter大小设为3
*3，其实在原图上考虑的是5*
5的范围 => Network叠的越深同样是3*3的filter其实看的原图范围越来越大。

![](https://i-blog.csdnimg.cn/img_convert/3f81722ae616158dc68911d95d68f2f0.png)

#### comparison of Two Stories

`Convolution`
：将filter扫过一张图片这件事被称为
`Convolution`

1. 版本1里讲守备不同Receptive Field的
   `Neuron`
   会共用参数，这里共用的参数是版本2里的
   `filter`

![](https://i-blog.csdnimg.cn/img_convert/946255aebf8502d73a79b17d0df773a9.png)

> 卷积运算中也有Bias ，一般忽视

2. 在版本1中，不同的
   `Neuron`
   可以
   `share weight`
   去守备不同的区域，
   `share weight`
   这件事就是版本2的
   `filter`
   扫过一张图

守备不同Receptive Field的Neuron可以共享参数来识别不同范围的特定pattern，相当于版本2中同一个filter不断的移动扫过整张图片来识别特定的pattern。 => 版本2中的filter就是共用参数的neuron

#### 总结：Convolutional Layer

| **-** | **Neuron Version Story** | **Filter Version Story** |
| --- | --- | --- |
| 观察1：不需要看整张图片 | Neuron只看图片一小部分 => Neuron只守备 `Receptive Field` 区域 | 有一组filter，每个filter只侦测一个小的pattern |
| 观察2：同样的Pattern可能出现在图片的不同地方 | Neuron间可以共享参数 | 1个filter都要扫过一整张图 |

卷积核就是filter，一个卷积核用来筛选出一种频域特征

#### Convolutional Layer用于影像辨识的观察3：Pooling

**观察**
：把一张较大的图片做
`Subsampling`
二次抽样，比如将偶数的Column和奇数的row去掉，图片变为原来的

1
4
\frac{1}{4}

















4












1

​

，不会影响图片里的内容

![](https://i-blog.csdnimg.cn/img_convert/92b8d9f9fdc2012738ef95ae81b36bdb.png)

##### pooling - Max Pooling

pooling本身没有参数，所以它不是一个Layer，它没有要学习的参数。pooling比较像是一个Activation Funciton，类似Sigmoid、ReLU，不需要从训练资料中学习什么，只是一个行为固定的操作。

Pooling有很多版本，这里介绍
`Max pooling`

**Max Pooling的运作原理**

每个filter都产生一组数字，将这组数字分组(怎么分组自己决定)。比如以下例子就是2*2个数字一组，每一组里面选一个代表。

`Max Pooling`
方法是选择最大的一个为代表

> 具体的选择方法是自己定的，有各式各样pooling的方法，比如：mean pooling方法是选平均

![](https://i-blog.csdnimg.cn/img_convert/162ce8dd7fa03e17c1ceaabb91acbf57.png)

##### Convolutional Layers + Pooling

`Convolution`
之后往往会搭配
`Pooling`
，Pooling做的事情就是将图片变小。 => channel不变，长宽变小

![](https://i-blog.csdnimg.cn/img_convert/89f03ffdcdfc16875a14a28fa5009a9d.png)

在实际的操作上，一般
`Convolution`
和
`Pooling`
交替使用，比如几次
`Convolution`
后接一次
`Pooling`

`Pooling`
目的是
**减少运算量**
，但由于较少了图片信息可能会对影响模型性能。 如果运算资源足够，很多 Network 的架构设计往往就不做 Pooling，全Convolution。

##### The whole CNN => pooling可有可无

将输出(矩阵)
`Flatten`
扁平化成一个向量，再把这个向量作为
`Full Connected Layer`
的输入，可能还会有

`softmax`
最终得到影响辨识的结果。

![](https://i-blog.csdnimg.cn/img_convert/5f7d29f45c086f633c8a3075597771df.png)

#### CNN最常见的应用之一： Alpha Go

下围棋是一个分类的问题，由
`Network`
去预测下一步落在哪里最好。

`Network`
的输入是棋牌上黑子、白字的位置，输出是下一步落子的位置。

**问题**
：怎么讲棋盘上黑子、白字的位置表示成一个向量作为
`Network`
的输入？

棋盘有19*19个位置，将棋盘表示为19*19维的向量(拉直后)。黑棋为1、白棋为-1，没有棋为0。

将其输入到网络中后，由网络预测19*19 classes中，选择哪个位置最好。

**问题**
：可以用
`Full-connected network`
解决，但使用CNN的效果最好，为什么？

**解**
：可以将棋盘看成一张19*19的图片，图片上每一个Pixel像素代表棋盘上可以落子的位置。每一个棋盘上的Pixel用48个Channel描述，48个数字来描述那个位置发生了什么。

![](https://i-blog.csdnimg.cn/img_convert/df32198e6cbc7193e27439ee6c6bfb12.png)

##### 与影像辨识比较

**共同点**

**问题**
：为什么CNN可以用在下围棋上

**解**
：围棋和影像有共同的特点

1. 不用看全局，只需要看小部分
2. Pattern会出现在棋盘的不同位置出现

**不同点**
：下围棋是个精细的任务，没有使用
`Pooling`

#### CNN近年来的应用：语音，文字处理NLP

语音和NLP中
`Receptive Field`
的设置与影像识别中是不一样的，需要结合语音和文字的特性设计
`Receptive Field`

![](https://i-blog.csdnimg.cn/img_convert/ec277d799eb8943c77df0d3e0d8b331d.png)

#### To Learn More：CNN的缺陷——空间变换 ⇒data augmentation

CNN没办法处理影像放大、缩小、旋转的问题。 => 在做影像辨识时，往往都需要做
`Data Augmentation`

`Data Augmentation`
：将训练资料的每一张图片都截一小部分放大，让CNN看过不同大小的
`Pattern`
。将图片旋转，让CNN看物体旋转以后的样子…

network架构
`spacial transformer Layer`
可以处理这个问题

![](https://i-blog.csdnimg.cn/img_convert/2959da73e712640d57946c7ac69b5430.png)

> CNN是按像素识别的
>
> pooling的放大缩小是成比例放缩，这里的放大缩小类似剪裁。