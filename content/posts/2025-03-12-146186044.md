---
layout: post
title: "hive-中可能产生小文件的场景"
date: 2025-03-12 09:28:29 +0800
description: "在 MapReduce 任务中，如果 Reduce 任务数设置过多，且每个 Reduce 任务处理的数据量较小，会导致生成大量小文件。操作中，如果分组字段的基数（Cardinality）较高，且每个分组的数据量较小，会导致每个分组生成一个小文件。使用动态分区插入数据时，如果分区数量较多且每个分区的数据量较小，会导致每个分区生成一个小文件。使用分桶表时，如果分桶数设置过多且每个分桶的数据量较小，会导致生成小文件。分区字段有大量不同的值，且每个分区的数据量较小，会生成大量小文件。"
keywords: "hive 中可能产生小文件的场景"
categories: ['未分类']
tags: ['数据仓库', 'Hive', 'Hadoop']
artid: "146186044"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146186044
    alt: "hive-中可能产生小文件的场景"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146186044
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146186044
cover: https://bing.ee123.net/img/rand?artid=146186044
image: https://bing.ee123.net/img/rand?artid=146186044
img: https://bing.ee123.net/img/rand?artid=146186044
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     hive 中可能产生小文件的场景
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     在 Hive 中，
     <strong>
      小文件
     </strong>
     是指文件大小远小于 HDFS 块大小（通常为 128 MB 或 256 MB）的文件。小文件过多会导致 NameNode 内存压力增大、查询性能下降以及资源浪费。以下是 Hive 中可能产生小文件的常见场景：
    </p>
    <hr/>
    <h3>
     <strong>
      1. 高频插入数据
     </strong>
    </h3>
    <h4>
     <strong>
      场景描述
     </strong>
    </h4>
    <ul>
     <li>
      <p>
       使用
       <code>
        INSERT INTO
       </code>
       或
       <code>
        INSERT OVERWRITE
       </code>
       语句频繁插入少量数据。
      </p>
     </li>
     <li>
      <p>
       每次插入操作都会生成一个新的文件。
      </p>
     </li>
    </ul>
    <h4>
     <strong>
      示例
     </strong>
    </h4>
    <pre><code class="language-sql">INSERT INTO TABLE example_table VALUES (1, 'Alice');
INSERT INTO TABLE example_table VALUES (2, 'Bob');</code></pre>
    <ul>
     <li>
      <p>
       每次插入都会生成一个小文件。
      </p>
     </li>
    </ul>
    <hr/>
    <h3>
     <strong>
      2. 动态分区插入
     </strong>
    </h3>
    <h4>
     <strong>
      场景描述
     </strong>
    </h4>
    <ul>
     <li>
      <p>
       使用动态分区插入数据时，如果分区数量较多且每个分区的数据量较小，会导致每个分区生成一个小文件。
      </p>
     </li>
    </ul>
    <h4>
     <strong>
      示例
     </strong>
    </h4>
    <pre><code class="language-sql">INSERT OVERWRITE TABLE partitioned_table PARTITION (dt)
SELECT id, name, dt FROM source_table;</code></pre>
    <ul>
     <li>
      <p>
       如果
       <code>
        dt
       </code>
       分区字段有大量不同的值，且每个分区的数据量较小，会生成大量小文件。
      </p>
     </li>
    </ul>
    <hr/>
    <h3>
     <strong>
      3. 使用
      <code>
       GROUP BY
      </code>
      或
      <code>
       DISTINCT
      </code>
     </strong>
    </h3>
    <h4>
     <strong>
      场景描述
     </strong>
    </h4>
    <ul>
     <li>
      <p>
       在
       <code>
        GROUP BY
       </code>
       或
       <code>
        DISTINCT
       </code>
       操作中，如果分组字段的基数（Cardinality）较高，且每个分组的数据量较小，会导致每个分组生成一个小文件。
      </p>
     </li>
    </ul>
    <h4>
     <strong>
      示例
     </strong>
    </h4>
    <pre><code class="language-sql">INSERT OVERWRITE TABLE grouped_table
SELECT key, COUNT(*) 
FROM source_table 
GROUP BY key;</code></pre>
    <ul>
     <li>
      <p>
       如果
       <code>
        key
       </code>
       的基数较高，且每个
       <code>
        key
       </code>
       的数据量较小，会生成大量小文件。
      </p>
     </li>
    </ul>
    <hr/>
    <h3>
     <strong>
      4. 使用
      <code>
       UNION ALL
      </code>
     </strong>
    </h3>
    <h4>
     <strong>
      场景描述
     </strong>
    </h4>
    <ul>
     <li>
      <p>
       使用
       <code>
        UNION ALL
       </code>
       合并多个查询结果时，如果每个查询的结果数据量较小，会导致生成多个小文件。
      </p>
     </li>
    </ul>
    <h4>
     <strong>
      示例
     </strong>
    </h4>
    <pre><code class="language-sql">INSERT OVERWRITE TABLE union_table
SELECT * FROM table_a
UNION ALL
SELECT * FROM table_b;</code></pre>
    <ul>
     <li>
      <p>
       如果
       <code>
        table_a
       </code>
       和
       <code>
        table_b
       </code>
       的数据量较小，会生成多个小文件。
      </p>
     </li>
    </ul>
    <hr/>
    <h3>
     <strong>
      5. 使用
      <code>
       CREATE TABLE AS SELECT
      </code>
      (CTAS)
     </strong>
    </h3>
    <h4>
     <strong>
      场景描述
     </strong>
    </h4>
    <ul>
     <li>
      <p>
       使用
       <code>
        CREATE TABLE AS SELECT
       </code>
       创建新表时，如果源表的数据分布不均匀或数据量较小，会导致生成小文件。
      </p>
     </li>
    </ul>
    <h4>
     <strong>
      示例
     </strong>
    </h4>
    <pre><code class="language-sql">CREATE TABLE new_table AS
SELECT * FROM source_table;</code></pre>
    <ul>
     <li>
      <p>
       如果
       <code>
        source_table
       </code>
       的数据量较小或分布不均匀，会生成小文件。
      </p>
     </li>
    </ul>
    <hr/>
    <h3>
     <strong>
      6. 使用
      <code>
       MAPREDUCE
      </code>
      任务
     </strong>
    </h3>
    <h4>
     <strong>
      场景描述
     </strong>
    </h4>
    <ul>
     <li>
      <p>
       在 MapReduce 任务中，如果 Reduce 任务数设置过多，且每个 Reduce 任务处理的数据量较小，会导致生成大量小文件。
      </p>
     </li>
    </ul>
    <h4>
     <strong>
      示例
     </strong>
    </h4>
    <pre><code class="language-sql">SET hive.exec.reducers.bytes.per.reducer = 1000000; -- 每个 Reducer 处理 1 MB 数据
INSERT OVERWRITE TABLE reduced_table
SELECT key, COUNT(*) 
FROM source_table 
GROUP BY key;</code></pre>
    <ul>
     <li>
      <p>
       如果数据量较小且 Reducer 数量过多，会生成大量小文件。
      </p>
     </li>
    </ul>
    <hr/>
    <h3>
     <strong>
      7. 使用
      <code>
       STORED AS SEQUENCEFILE
      </code>
      或
      <code>
       TEXTFILE
      </code>
     </strong>
    </h3>
    <h4>
     <strong>
      场景描述
     </strong>
    </h4>
    <ul>
     <li>
      <p>
       使用
       <code>
        SEQUENCEFILE
       </code>
       或
       <code>
        TEXTFILE
       </code>
       格式存储数据时，如果数据量较小，容易生成小文件。
      </p>
     </li>
    </ul>
    <h4>
     <strong>
      示例
     </strong>
    </h4>
    <pre><code class="language-sql">CREATE TABLE textfile_table (
    id INT,
    name STRING
) STORED AS TEXTFILE;</code></pre>
    <ul>
     <li>
      <p>
       如果插入的数据量较小，会生成小文件。
      </p>
     </li>
    </ul>
    <hr/>
    <h3>
     <strong>
      8. 使用
      <code>
       BUCKETING
      </code>
     </strong>
    </h3>
    <h4>
     <strong>
      场景描述
     </strong>
    </h4>
    <ul>
     <li>
      <p>
       使用分桶表时，如果分桶数设置过多且每个分桶的数据量较小，会导致生成小文件。
      </p>
     </li>
    </ul>
    <h4>
     <strong>
      示例
     </strong>
    </h4>
    <pre><code class="language-sql">CREATE TABLE bucketed_table (
    id INT,
    name STRING
) CLUSTERED BY (id) INTO 100 BUCKETS;</code></pre>
    <ul>
     <li>
      <p>
       如果数据量较小且分桶数过多，会生成大量小文件。
      </p>
     </li>
    </ul>
    <hr/>
    <h3>
     <strong>
      9. 使用
      <code>
       INSERT INTO
      </code>
      追加数据
     </strong>
    </h3>
    <h4>
     <strong>
      场景描述
     </strong>
    </h4>
    <ul>
     <li>
      <p>
       使用
       <code>
        INSERT INTO
       </code>
       追加数据时，如果每次追加的数据量较小，会导致生成小文件。
      </p>
     </li>
    </ul>
    <h4>
     <strong>
      示例
     </strong>
    </h4>
    <pre><code class="language-sql">INSERT INTO TABLE example_table VALUES (1, 'Alice');
INSERT INTO TABLE example_table VALUES (2, 'Bob');</code></pre>
    <ul>
     <li>
      <p>
       每次插入都会生成一个小文件。
      </p>
     </li>
    </ul>
    <hr/>
    <h3>
     <strong>
      10. 使用
      <code>
       MERGE
      </code>
      或
      <code>
       UPDATE
      </code>
      操作
     </strong>
    </h3>
    <h4>
     <strong>
      场景描述
     </strong>
    </h4>
    <ul>
     <li>
      <p>
       在支持 ACID 的 Hive 表中，使用
       <code>
        MERGE
       </code>
       或
       <code>
        UPDATE
       </code>
       操作时，可能会生成大量小文件。
      </p>
     </li>
    </ul>
    <h4>
     <strong>
      示例
     </strong>
    </h4>
    <pre><code class="language-sql">MERGE INTO acid_table AS target
USING source_table AS source
ON target.id = source.id
WHEN MATCHED THEN UPDATE SET target.name = source.name;</code></pre>
    <ul>
     <li>
      <p>
       每次更新操作可能会生成新的小文件。
      </p>
     </li>
    </ul>
    <hr/>
    <h3>
     <strong>
      小文件的危害
     </strong>
    </h3>
    <ol>
     <li>
      <p>
       <strong>
        NameNode 压力
       </strong>
       :
      </p>
      <ul>
       <li>
        <p>
         小文件过多会占用大量 NameNode 内存，影响 HDFS 性能。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        查询性能下降
       </strong>
       :
      </p>
      <ul>
       <li>
        <p>
         小文件会增加 MapReduce 任务的启动开销，降低查询性能。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        资源浪费
       </strong>
       :
      </p>
      <ul>
       <li>
        <p>
         小文件会占用额外的存储空间和计算资源。
        </p>
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h3>
     <strong>
      解决方法
     </strong>
    </h3>
    <ol>
     <li>
      <p>
       <strong>
        合并小文件
       </strong>
       :
      </p>
      <ul>
       <li>
        <p>
         使用
         <code>
          hive.merge.mapfiles
         </code>
         和
         <code>
          hive.merge.mapredfiles
         </code>
         参数自动合并小文件。
        </p>
       </li>
       <li>
        <p>
         示例:
        </p>
        <pre><code class="language-sql">SET hive.merge.mapfiles = true;
SET hive.merge.mapredfiles = true;
SET hive.merge.size.per.task = 256000000; -- 256 MB</code></pre>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        调整 Reduce 任务数
       </strong>
       :
      </p>
      <ul>
       <li>
        <p>
         通过
         <code>
          hive.exec.reducers.bytes.per.reducer
         </code>
         参数控制每个 Reducer 处理的数据量。
        </p>
       </li>
       <li>
        <p>
         示例:
        </p>
        <pre><code class="language-sql">SET hive.exec.reducers.bytes.per.reducer = 256000000; -- 256 MB</code></pre>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        使用分区和分桶
       </strong>
       :
      </p>
      <ul>
       <li>
        <p>
         合理设计分区和分桶策略，避免生成过多小文件。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        定期合并小文件
       </strong>
       :
      </p>
      <ul>
       <li>
        <p>
         使用
         <code>
          ALTER TABLE
         </code>
         命令或工具（如
         <code>
          hadoop fs -getmerge
         </code>
         ）定期合并小文件。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        使用 ORC 或 Parquet 格式
       </strong>
       :
      </p>
      <ul>
       <li>
        <p>
         列式存储格式（如 ORC、Parquet）具有更高的压缩率和查询性能，适合存储大规模数据
        </p>
       </li>
      </ul>
     </li>
    </ol>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f36333332323132322f:61727469636c652f64657461696c732f313436313836303434" class_="artid" style="display:none">
 </p>
</div>


