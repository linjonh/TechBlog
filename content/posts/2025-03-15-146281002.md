---
layout: post
title: "浅谈AI落地之-加速训练"
date: 2025-03-15 17:01:04 +0800
description: "曾在游戏世界挥洒创意，也曾在前端和后端的浪潮间穿梭，如今，而立的我仰望AI的璀璨星空，心潮澎湃，步履不停！愿你我皆乘风破浪，逐梦星辰！"
keywords: "浅谈AI落地之-加速训练"
categories: ['未分类']
tags: ['人工智能']
artid: "146281002"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146281002
    alt: "浅谈AI落地之-加速训练"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146281002
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146281002
cover: https://bing.ee123.net/img/rand?artid=146281002
image: https://bing.ee123.net/img/rand?artid=146281002
img: https://bing.ee123.net/img/rand?artid=146281002
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     浅谈AI落地之-加速训练
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h4>
     前言
    </h4>
    <p>
     曾在游戏世界挥洒创意，也曾在前端和后端的浪潮间穿梭，如今，而立的我仰望AI的璀璨星空，心潮澎湃，步履不停！愿你我皆乘风破浪，逐梦星辰！
    </p>
    <h4>
    </h4>
    <h4>
     混合精度：
    </h4>
    <p>
     FL32是目前模型存储数据一个比较普遍的格式。有时候过于浪费，根本用不着那么多。所以如果有一种方法能动态调整存储数据的大小，就能节省不少显存占用，从来提高批次大小，加速学习。
    </p>
    <p>
     混合精度简单简单的来说，就是用FL16+FL32来代替原来的清一色FL32数据。具体实现是，在初始化好scaler以后，在遍历批次中的数据的时候，使用autocast自动对前向传播和损失处理混合精度。然后再使用梯度缩放器来缩放损失，并反向传播。
    </p>
    <pre><code class="language-python">from torch.cuda.amp import GradScaler, autocast

scaler = GradScaler()
# 使用autocast自动处理混合精度
with autocast():
    out = model(**data)  # 前向传播
    loss = out['loss']  # 获取损失
# 使用梯度缩放器来缩放损失，并反向传播
optimizer.zero_grad()
scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()</code></pre>
    <p>
    </p>
    <h4>
    </h4>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f5261794c6f6265436f64652f:61727469636c652f64657461696c732f313436323831303032" class_="artid" style="display:none">
 </p>
</div>


