---
layout: post
title: "bert模型笔记"
date: 2025-03-06 23:51:40 +0800
description: "1.各预训练模型说明BERT模型在英文数据集上提供了两种大小的模型，Base和Large。Uncased是意味着输入的词都会转变成小写，cased是意味着输入的词会保存其大写（在命名实体识别等项目上需要）。Multilingual是支持多语言的，最后一个是中文预训练模型。在这里我们选择BERT-Base，Uncased。下载下来之后是一个zip文件，解压后有ckpt文件，一个模型参数的json文件，一个词汇表txt文件。..."
keywords: "bert模型笔记"
categories: ['未分类']
tags: ['笔记', '人工智能', 'Bert']
artid: "121513578"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=121513578
    alt: "bert模型笔记"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=121513578
featuredImagePreview: https://bing.ee123.net/img/rand?artid=121513578
cover: https://bing.ee123.net/img/rand?artid=121513578
image: https://bing.ee123.net/img/rand?artid=121513578
img: https://bing.ee123.net/img/rand?artid=121513578
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     bert模型笔记
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="./../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="./../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h2>
     <a id="1_0">
     </a>
     1.各预训练模型说明
    </h2>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/6ba337cec60b72faee277e5823305141.png">
      <br/>
      BERT模型在英文数据集上提供了两种大小的模型，Base和Large。Uncased是意味着输入的词都会转变成小写，cased是意味着输入的词会保存其大写（在命名实体识别等项目上需要）。Multilingual是支持多语言的，最后一个是中文预训练模型。
     </img>
    </p>
    <pre><code>在这里我们选择BERT-Base，Uncased。下载下来之后是一个zip文件，解压后有ckpt文件，一个模型参数的json文件，一个词汇表txt文件。
</code></pre>
    <h2>
     <a id="2_7">
     </a>
     2.参数错误
    </h2>
    <pre><code>当输出出现 args = parser.parse_args()标红时，将 args = parser.parse_args() 替换为：args, unknown = parser.parse_known_args()
</code></pre>
    <h2>
     <a id="3tfpytorchchinese_L12_H768_A12_10">
     </a>
     3.命令行转换模型（tf到pytorch）chinese_L-12_H-768_A-12
    </h2>
    <pre><code>安装：pip install pytorch-pretrained-bert
解压地址：export BERT_BASE_DIR=/path/to/bert/chinese_L-12_H-768_A-12
</code></pre>
    <p>
     （地址拼接）转换模型：pytorch_pretrained_bert convert_tf_checkpoint_to_pytorch $BERT_BASE_DIR/bert_model.ckpt $BERT_BASE_DIR/bert_config.json $BERT_BASE_DIR/pytorch_model.bin
    </p>
    <h2>
     <a id="4bert_15">
     </a>
     4.bert模型的标签
    </h2>
    <pre><code>标签默认为0，1，2...n的方式标注，否则需转换。
</code></pre>
   </div>
   <link href="./../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="./../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f35323538323731302f:61727469636c652f64657461696c732f313231353133353738" class_="artid" style="display:none">
 </p>
</div>


