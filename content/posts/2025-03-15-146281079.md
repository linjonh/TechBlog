---
layout: post
title: "Spark-中explode用法"
date: 2025-03-15 20:00:38 +0800
description: "【代码】Spark 中explode用法。"
keywords: "Spark 中explode用法"
categories: ['未分类']
tags: ['大数据', 'Spark', 'Scala']
artid: "146281079"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146281079
    alt: "Spark-中explode用法"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146281079
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146281079
cover: https://bing.ee123.net/img/rand?artid=146281079
image: https://bing.ee123.net/img/rand?artid=146281079
img: https://bing.ee123.net/img/rand?artid=146281079
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Spark 中explode用法
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     <strong>
      在 Apache Spark 中，
      <code>
       explode
      </code>
      是一个用于处理数组或映射（Map）类型数据的函数。它的作用是将数组或映射中的每个元素拆分为单独的行，同时复制其他列的值。
      <code>
       explode
      </code>
      是 Spark SQL 中非常常用的函数之一，特别适合处理嵌套数据结构。
     </strong>
    </p>
    <hr/>
    <h4>
     <strong>
      <code>
       explode
      </code>
      的用法
     </strong>
    </h4>
    <h5>
     <strong>
      1. 语法
     </strong>
    </h5>
    <pre><code class="language-Scala">import org.apache.spark.sql.functions.explode


//数组一列展开成一列
val explodedDF = df.withColumn("new_column", explode(col("array_column")))
或
val explodedDF = df.select(explode(col("array_column")).as("new_column"))


//映射一列展开成多列
val explodedDF = df
    .select(
       explode(col("map_column")).as(Seq("new_column_1","new_column_2"))
      )</code></pre>
    <h5>
     <strong>
      2. 作用
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        如果
        <code>
         array_column
        </code>
        是一个数组，
        <code>
         explode
        </code>
        会将数组中的每个元素拆分为一行。
       </strong>
      </p>
     </li>
     <li>
      <p>
       <strong>
        如果
        <code>
         map_column
        </code>
        是一个映射（Map），
        <code>
         explode
        </code>
        会将映射中的每个键值对拆分为一行，输出两列：第一列是键（key），第二列是值（value）。因此，你需要为这两列分别指定别名。
       </strong>
      </p>
     </li>
     <li>
      <p>
       <strong>
        其他列的值会被复制到每一行。
       </strong>
      </p>
     </li>
    </ul>
    <hr/>
    <h4>
     <strong>
      示例
     </strong>
    </h4>
    <h5>
     <strong>
      示例 1：展开数组
     </strong>
    </h5>
    <p>
     <strong>
      假设有一个 DataFrame，其中一列是数组类型：
     </strong>
    </p>
    <pre><code class="language-Scala">import org.apache.spark.sql.{SparkSession, Row}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

// 创建 SparkSession
val spark = SparkSession.builder()
  .appName("Explode Example")
  .master("local[*]")
  .getOrCreate()

// 创建数据
val data = Seq(
  Row("Alice", Seq("Java", "Scala")),
  Row("Bob", Seq("Python", "C++")),
  Row("Charlie", Seq("Spark", "Hadoop"))
)

// 定义模式
val schema = new StructType()
  .add(StructField("name", StringType, nullable = false))
  .add(StructField("skills", ArrayType(StringType), nullable = true))

// 创建 DataFrame
val df = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)

// 使用 explode 展开数组列
val explodedDF = df.withColumn("skill", explode(col("skills")))

// 显示结果
explodedDF.show()</code></pre>
    <p>
     <strong>
      输出：
     </strong>
    </p>
    <pre><code class="language-Scala">+-------+------------+------+
|   name|      skills| skill|
+-------+------------+------+
|  Alice|[Java, Scala]|  Java|
|  Alice|[Java, Scala]| Scala|
|    Bob|[Python, C++]|Python|
|    Bob|[Python, C++]|   C++|
|Charlie|[Spark, Hadoop]| Spark|
|Charlie|[Spark, Hadoop]|Hadoop|
+-------+------------+------+</code></pre>
    <ul>
     <li>
      <p>
       <strong>
        <code>
         skills
        </code>
        列是一个数组，
        <code>
         explode
        </code>
        将其拆分为多行。
       </strong>
      </p>
     </li>
     <li>
      <p>
       <strong>
        其他列（如
        <code>
         name
        </code>
        ）的值被复制到每一行。
       </strong>
      </p>
     </li>
    </ul>
    <hr/>
    <h5>
     <strong>
      示例 2：展开映射（Map）
     </strong>
    </h5>
    <p>
     <strong>
      假设有一个 DataFrame，其中一列是映射类型：
     </strong>
    </p>
    <pre><code class="language-Scala">// 创建数据
val data = Seq(
  Row("Alice", Map("Java" -&gt; 5, "Scala" -&gt; 3)),
  Row("Bob", Map("Python" -&gt; 4, "C++" -&gt; 2))
)

// 定义模式
val schema = new StructType()
  .add(StructField("name", StringType, nullable = false))
  .add(StructField("skill_level", MapType(StringType, IntegerType), nullable = true))

// 创建 DataFrame
val df = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)

// 使用 explode 展开映射列，并为新生成的两列分别指定别名
val explodedDF = df.select(
  col("name"),
  col("skill_level"),
  explode(col("skill_level")).as(Seq("skill", "level"))
)

// 显示结果
explodedDF.show()</code></pre>
    <p>
     <strong>
      输出：
     </strong>
    </p>
    <pre><code class="language-Scala">+-----+--------------------+------+-----+
| name|         skill_level| skill|level|
+-----+--------------------+------+-----+
|Alice|[Java -&gt; 5, Scala...|  Java|    5|
|Alice|[Java -&gt; 5, Scala...| Scala|    3|
|  Bob|[Python -&gt; 4, C++...|Python|    4|
|  Bob|[Python -&gt; 4, C++...|   C++|    2|
+-----+--------------------+------+-----+</code></pre>
    <ul>
     <li>
      <p>
       <strong>
        <code>
         skill_level
        </code>
        列是一个映射，
        <code>
         explode
        </code>
        将其拆分为多行，每行包含一个键（skill）值（level）对，再把这个键值对拆成两列：skill，level。
       </strong>
      </p>
     </li>
    </ul>
    <p>
    </p>
    <h4>
     <strong>
      展开数组为多列的情况
     </strong>
    </h4>
    <p>
     <strong>
      示例 3：展开数组为多列（结构体）
     </strong>
    </p>
    <p>
     <strong>
      如果数组中的每个元素是一个结构体（
      <code>
       StructType
      </code>
      ），你可以直接展开并选择结构体中的字段。
     </strong>
    </p>
    <p>
     <strong>
      假设有一个 DataFrame，其中一列是包含结构体的数组：
     </strong>
    </p>
    <pre><code class="language-Scala">import org.apache.spark.sql.{SparkSession, Row}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

// 创建 SparkSession
val spark = SparkSession.builder()
  .appName("Explode Array of Structs")
  .master("local[*]")
  .getOrCreate()

// 定义数据
val data = Seq(
  Row("Alice", Seq(Row("Java", 5), Row("Scala", 3))),
  Row("Bob", Seq(Row("Python", 4), Row("C++", 2)))
)

// 定义模式
val schema = new StructType()
  .add("name", StringType)
  .add("skills", ArrayType(new StructType()
    .add("skill", StringType)
    .add("level", IntegerType)
  ))

// 创建 DataFrame
val df = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)

// 展开数组，并选择结构体中的字段
val explodedDF = df
  .withColumn("skill", explode(col("skills"))) // 展开数组
  .select(
    col("name"),
    col("skill.skill").as("skill_name"), // 选择结构体中的字段
    col("skill.level").as("skill_level")
  )

// 显示结果
explodedDF.show()</code></pre>
    <p>
     <strong>
      输出：
     </strong>
    </p>
    <pre><code class="language-Scala">+-----+----------+-----------+
| name|skill_name|skill_level|
+-----+----------+-----------+
|Alice|      Java|          5|
|Alice|     Scala|          3|
|  Bob|    Python|          4|
|  Bob|       C++|          2|
+-----+----------+-----------+</code></pre>
    <h4>
     <strong>
      示例 4： 展开数组为多列（非结构体）
     </strong>
    </h4>
    <p>
     <strong>
      如果数组中的元素是简单类型（如字符串或整数），并且你希望将数组展开为多列，可以使用
      <code>
       posexplode
      </code>
      函数。
      <code>
       posexplode
      </code>
      会返回元素及其索引。
     </strong>
    </p>
    <p>
     <strong>
      假设有一个 DataFrame，其中一列是字符串数组：
     </strong>
    </p>
    <pre><code class="language-Scala">import org.apache.spark.sql.{SparkSession, Row}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

// 创建 SparkSession
val spark = SparkSession.builder()
  .appName("Explode Array to Multiple Columns")
  .master("local[*]")
  .getOrCreate()

// 定义数据
val data = Seq(
  Row("Alice", Seq("Java", "Scala")),
  Row("Bob", Seq("Python", "C++"))
)

// 定义模式
val schema = new StructType()
  .add("name", StringType)
  .add("skills", ArrayType(StringType))

// 创建 DataFrame
val df = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)

// 使用 posexplode 展开数组，并选择索引和值
val explodedDF = df
  .select(
    col("name"),
    posexplode(col("skills")).as(Seq("skill_index","skill_name"))
  )

// 显示结果
explodedDF.show()</code></pre>
    <p>
     <strong>
      输出：
     </strong>
    </p>
    <pre><code class="language-Scala">+-----+-----------+----------+
| name|skill_index|skill_name|
+-----+-----------+----------+
|Alice|          0|      Java|
|Alice|          1|     Scala|
|  Bob|          0|    Python|
|  Bob|          1|       C++|
+-----+-----------+----------+</code></pre>
    <hr/>
    <h4>
     <strong>
      注意事项
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        空数组或空映射：
       </strong>
      </p>
      <ul>
       <li>
        <p>
         <strong>
          如果数组或映射为空，
          <code>
           explode
          </code>
          会将该行从结果中移除。
         </strong>
        </p>
       </li>
       <li>
        <p>
         <strong>
          如果需要保留空值，可以使用
          <code>
           explode_outer
          </code>
          。
         </strong>
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        性能：
       </strong>
      </p>
      <ul>
       <li>
        <p>
         <strong>
          <code>
           explode
          </code>
          会增加数据量，可能导致性能问题，尤其是在数据量较大时。
         </strong>
        </p>
       </li>
       <li>
        <p>
         <strong>
          使用
          <code>
           explode
          </code>
          后，建议检查数据分布和分区情况。
         </strong>
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        嵌套结构：
       </strong>
      </p>
      <ul>
       <li>
        <p>
         <strong>
          如果数据是嵌套的（如数组中的数组），可能需要多次使用
          <code>
           explode
          </code>
          。
         </strong>
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        <code>
         explode
        </code>
        的输出列数：
       </strong>
      </p>
      <ul>
       <li>
        <p>
         <strong>
          如果展开的是数组，
          <code>
           explode
          </code>
          输出 1 列。
         </strong>
        </p>
       </li>
       <li>
        <p>
         <strong>
          如果展开的是映射（Map），
          <code>
           explode
          </code>
          输出 2 列（键和值）。
         </strong>
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        别名数量必须匹配：
       </strong>
      </p>
      <ul>
       <li>
        <p>
         <strong>
          如果
          <code>
           explode
          </code>
          输出 2 列，必须在
          <code>
           AS
          </code>
          子句中提供 2 个别名。
         </strong>
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        指定别名的方式：
       </strong>
      </p>
      <ul>
       <li>
        <p>
         <strong>
          使用
          <code>
           as(Seq("alias1", "alias2"))
          </code>
          。
         </strong>
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        使用
        <code>
         posexplode
        </code>
        可以同时获取数组元素的索引和值。
       </strong>
      </p>
     </li>
    </ol>
    <hr/>
    <h4>
     <strong>
      <code>
       explode_outer
      </code>
      的用法
     </strong>
    </h4>
    <p>
     <strong>
      <code>
       explode_outer
      </code>
      是
      <code>
       explode
      </code>
      的变体，它会保留空数组或空映射的行。
     </strong>
    </p>
    <pre><code class="language-Scala">val explodedDF = df.withColumn("skill", explode_outer(col("skills"))))</code></pre>
    <hr/>
    <h4>
     <strong>
      总结
     </strong>
    </h4>
    <ul>
     <li>
      <p>
       <strong>
        <code>
         explode
        </code>
        用于将数组或映射列拆分为多行。
       </strong>
      </p>
     </li>
     <li>
      <p>
       <strong>
        结合
        <code>
         select
        </code>
        或
        <code>
         withColumn
        </code>
        使用，可以灵活处理嵌套数据。
       </strong>
      </p>
     </li>
     <li>
      <p>
       <strong>
        如果需要保留空值，可以使用
        <code>
         explode_outer
        </code>
        。
       </strong>
      </p>
     </li>
    </ul>
    <p>
     <strong>
      希望这个解释对你有帮助！如果还有其他问题，欢迎继续提问。
     </strong>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f36333332323132322f:61727469636c652f64657461696c732f313436323831303739" class_="artid" style="display:none">
 </p>
</div>


