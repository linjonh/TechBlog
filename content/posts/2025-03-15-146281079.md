---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f36333332323132322f:61727469636c652f64657461696c732f313436323831303739"
layout: post
title: "Spark-中explode用法"
date: 2025-03-15 20:00:38 +0800
description: "【代码】Spark 中explode用法。"
keywords: "Spark 中explode用法"
categories: ['未分类']
tags: ['大数据', 'Spark', 'Scala']
artid: "146281079"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146281079
    alt: "Spark-中explode用法"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146281079
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146281079
cover: https://bing.ee123.net/img/rand?artid=146281079
image: https://bing.ee123.net/img/rand?artid=146281079
img: https://bing.ee123.net/img/rand?artid=146281079
---

# Spark 中explode用法

**在 Apache Spark 中，
`explode`
是一个用于处理数组或映射（Map）类型数据的函数。它的作用是将数组或映射中的每个元素拆分为单独的行，同时复制其他列的值。
`explode`
是 Spark SQL 中非常常用的函数之一，特别适合处理嵌套数据结构。**

---

#### **`explode` 的用法**

##### **1. 语法**

```Scala
import org.apache.spark.sql.functions.explode


//数组一列展开成一列
val explodedDF = df.withColumn("new_column", explode(col("array_column")))
或
val explodedDF = df.select(explode(col("array_column")).as("new_column"))


//映射一列展开成多列
val explodedDF = df
    .select(
       explode(col("map_column")).as(Seq("new_column_1","new_column_2"))
      )
```

##### **2. 作用**

* **如果
  `array_column`
  是一个数组，
  `explode`
  会将数组中的每个元素拆分为一行。**
* **如果
  `map_column`
  是一个映射（Map），
  `explode`
  会将映射中的每个键值对拆分为一行，输出两列：第一列是键（key），第二列是值（value）。因此，你需要为这两列分别指定别名。**
* **其他列的值会被复制到每一行。**

---

#### **示例**

##### **示例 1：展开数组**

**假设有一个 DataFrame，其中一列是数组类型：**

```Scala
import org.apache.spark.sql.{SparkSession, Row}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

// 创建 SparkSession
val spark = SparkSession.builder()
  .appName("Explode Example")
  .master("local[*]")
  .getOrCreate()

// 创建数据
val data = Seq(
  Row("Alice", Seq("Java", "Scala")),
  Row("Bob", Seq("Python", "C++")),
  Row("Charlie", Seq("Spark", "Hadoop"))
)

// 定义模式
val schema = new StructType()
  .add(StructField("name", StringType, nullable = false))
  .add(StructField("skills", ArrayType(StringType), nullable = true))

// 创建 DataFrame
val df = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)

// 使用 explode 展开数组列
val explodedDF = df.withColumn("skill", explode(col("skills")))

// 显示结果
explodedDF.show()
```

**输出：**

```Scala
+-------+------------+------+
|   name|      skills| skill|
+-------+------------+------+
|  Alice|[Java, Scala]|  Java|
|  Alice|[Java, Scala]| Scala|
|    Bob|[Python, C++]|Python|
|    Bob|[Python, C++]|   C++|
|Charlie|[Spark, Hadoop]| Spark|
|Charlie|[Spark, Hadoop]|Hadoop|
+-------+------------+------+
```

* **`skills`
  列是一个数组，
  `explode`
  将其拆分为多行。**
* **其他列（如
  `name`
  ）的值被复制到每一行。**

---

##### **示例 2：展开映射（Map）**

**假设有一个 DataFrame，其中一列是映射类型：**

```Scala
// 创建数据
val data = Seq(
  Row("Alice", Map("Java" -> 5, "Scala" -> 3)),
  Row("Bob", Map("Python" -> 4, "C++" -> 2))
)

// 定义模式
val schema = new StructType()
  .add(StructField("name", StringType, nullable = false))
  .add(StructField("skill_level", MapType(StringType, IntegerType), nullable = true))

// 创建 DataFrame
val df = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)

// 使用 explode 展开映射列，并为新生成的两列分别指定别名
val explodedDF = df.select(
  col("name"),
  col("skill_level"),
  explode(col("skill_level")).as(Seq("skill", "level"))
)

// 显示结果
explodedDF.show()
```

**输出：**

```Scala
+-----+--------------------+------+-----+
| name|         skill_level| skill|level|
+-----+--------------------+------+-----+
|Alice|[Java -> 5, Scala...|  Java|    5|
|Alice|[Java -> 5, Scala...| Scala|    3|
|  Bob|[Python -> 4, C++...|Python|    4|
|  Bob|[Python -> 4, C++...|   C++|    2|
+-----+--------------------+------+-----+
```

* **`skill_level`
  列是一个映射，
  `explode`
  将其拆分为多行，每行包含一个键（skill）值（level）对，再把这个键值对拆成两列：skill，level。**

#### **展开数组为多列的情况**

**示例 3：展开数组为多列（结构体）**

**如果数组中的每个元素是一个结构体（
`StructType`
），你可以直接展开并选择结构体中的字段。**

**假设有一个 DataFrame，其中一列是包含结构体的数组：**

```Scala
import org.apache.spark.sql.{SparkSession, Row}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

// 创建 SparkSession
val spark = SparkSession.builder()
  .appName("Explode Array of Structs")
  .master("local[*]")
  .getOrCreate()

// 定义数据
val data = Seq(
  Row("Alice", Seq(Row("Java", 5), Row("Scala", 3))),
  Row("Bob", Seq(Row("Python", 4), Row("C++", 2)))
)

// 定义模式
val schema = new StructType()
  .add("name", StringType)
  .add("skills", ArrayType(new StructType()
    .add("skill", StringType)
    .add("level", IntegerType)
  ))

// 创建 DataFrame
val df = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)

// 展开数组，并选择结构体中的字段
val explodedDF = df
  .withColumn("skill", explode(col("skills"))) // 展开数组
  .select(
    col("name"),
    col("skill.skill").as("skill_name"), // 选择结构体中的字段
    col("skill.level").as("skill_level")
  )

// 显示结果
explodedDF.show()
```

**输出：**

```Scala
+-----+----------+-----------+
| name|skill_name|skill_level|
+-----+----------+-----------+
|Alice|      Java|          5|
|Alice|     Scala|          3|
|  Bob|    Python|          4|
|  Bob|       C++|          2|
+-----+----------+-----------+
```

#### **示例 4： 展开数组为多列（非结构体）**

**如果数组中的元素是简单类型（如字符串或整数），并且你希望将数组展开为多列，可以使用
`posexplode`
函数。
`posexplode`
会返回元素及其索引。**

**假设有一个 DataFrame，其中一列是字符串数组：**

```Scala
import org.apache.spark.sql.{SparkSession, Row}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

// 创建 SparkSession
val spark = SparkSession.builder()
  .appName("Explode Array to Multiple Columns")
  .master("local[*]")
  .getOrCreate()

// 定义数据
val data = Seq(
  Row("Alice", Seq("Java", "Scala")),
  Row("Bob", Seq("Python", "C++"))
)

// 定义模式
val schema = new StructType()
  .add("name", StringType)
  .add("skills", ArrayType(StringType))

// 创建 DataFrame
val df = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)

// 使用 posexplode 展开数组，并选择索引和值
val explodedDF = df
  .select(
    col("name"),
    posexplode(col("skills")).as(Seq("skill_index","skill_name"))
  )

// 显示结果
explodedDF.show()
```

**输出：**

```Scala
+-----+-----------+----------+
| name|skill_index|skill_name|
+-----+-----------+----------+
|Alice|          0|      Java|
|Alice|          1|     Scala|
|  Bob|          0|    Python|
|  Bob|          1|       C++|
+-----+-----------+----------+
```

---

#### **注意事项**

1. **空数组或空映射：**

   * **如果数组或映射为空，
     `explode`
     会将该行从结果中移除。**
   * **如果需要保留空值，可以使用
     `explode_outer`
     。**
2. **性能：**

   * **`explode`
     会增加数据量，可能导致性能问题，尤其是在数据量较大时。**
   * **使用
     `explode`
     后，建议检查数据分布和分区情况。**
3. **嵌套结构：**

   * **如果数据是嵌套的（如数组中的数组），可能需要多次使用
     `explode`
     。**
4. **`explode`
   的输出列数：**

   * **如果展开的是数组，
     `explode`
     输出 1 列。**
   * **如果展开的是映射（Map），
     `explode`
     输出 2 列（键和值）。**
5. **别名数量必须匹配：**

   * **如果
     `explode`
     输出 2 列，必须在
     `AS`
     子句中提供 2 个别名。**
6. **指定别名的方式：**

   * **使用
     `as(Seq("alias1", "alias2"))`
     。**
7. **使用
   `posexplode`
   可以同时获取数组元素的索引和值。**

---

#### **`explode_outer` 的用法**

**`explode_outer`
是
`explode`
的变体，它会保留空数组或空映射的行。**

```Scala
val explodedDF = df.withColumn("skill", explode_outer(col("skills"))))
```

---

#### **总结**

* **`explode`
  用于将数组或映射列拆分为多行。**
* **结合
  `select`
  或
  `withColumn`
  使用，可以灵活处理嵌套数据。**
* **如果需要保留空值，可以使用
  `explode_outer`
  。**

**希望这个解释对你有帮助！如果还有其他问题，欢迎继续提问。**