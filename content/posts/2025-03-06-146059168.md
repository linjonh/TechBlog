---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34333231343430322f:61727469636c652f64657461696c732f313436303539313638"
layout: post
title: "TRPO中的Hessian-Free-Optimization两次梯度反向传播计算海森矩阵"
date: 2025-03-06 09:31:32 +08:00
description: "两次梯度反向传播计算海森矩阵"
keywords: "TRPO中的Hessian-Free Optimization（两次梯度反向传播计算海森矩阵）"
categories: ['未分类']
tags: ['论文阅读', '矩阵']
artid: "146059168"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146059168
    alt: "TRPO中的Hessian-Free-Optimization两次梯度反向传播计算海森矩阵"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146059168
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146059168
cover: https://bing.ee123.net/img/rand?artid=146059168
image: https://bing.ee123.net/img/rand?artid=146059168
img: https://bing.ee123.net/img/rand?artid=146059168
---

# TRPO中的Hessian-Free Optimization（两次梯度反向传播计算海森矩阵）

### 1.优点

* 无需显式构建和存储海森矩阵，大大降低了计算和存储成本。在深度学习中的大型神经网络，参数数量可能达到数百万甚至更多，避免显式计算海森矩阵可以使训练过程在计算资源有限的情况下仍然能够高效进行。
* 通过两次梯度反向传播计算海森矩阵向量积可以很好地利用Pytorch等框架的自动微分机制，使得计算过程更加便捷和准确。

### 2.推导

![](https://i-blog.csdnimg.cn/direct/539c9fa5dcfc4e3e8aa805f308d21a9e.png)
，
![](https://i-blog.csdnimg.cn/direct/9c2cbbe6e127467686b3a459afff4946.png)
，
![](https://i-blog.csdnimg.cn/direct/b9f035755c2a43d49c5fa0731e0142c0.png)
是平均KL散度的海森矩阵。

![](https://i-blog.csdnimg.cn/direct/137dae6110cd4ee6b598b1671dc28991.png)

首先，计算
![](https://i-blog.csdnimg.cn/direct/69e2abf1e940486592d9c950cf62a47b.png)
关于
![](https://i-blog.csdnimg.cn/direct/50b54b129d0e4e8db52d57a41ef827e3.png)
的梯度
![](https://i-blog.csdnimg.cn/direct/503afe6694304c059d3dbd3a8499843a.png)
：

![](https://i-blog.csdnimg.cn/direct/7b97de74b25e44ab911fa47717ad7147.png)

然后计算
![](https://i-blog.csdnimg.cn/direct/46ba1ee365ac45c29e6adae9dfc63430.png)
和
![](https://i-blog.csdnimg.cn/direct/0c56cfcb0e4d4d8a80302fa141ff258c.png)
的点积

![](https://i-blog.csdnimg.cn/direct/913c692c59734dde8002f1dc937bc8a9.png)

最后计算
![](https://i-blog.csdnimg.cn/direct/49fd3862322b4928b75c49719345fecb.png)
关于
![](https://i-blog.csdnimg.cn/direct/5a7d50424a274be6b03437b38c264b36.png)
的梯度

![](https://i-blog.csdnimg.cn/direct/267c95992a3d44c5a1c047b7dd10fd1f.png)