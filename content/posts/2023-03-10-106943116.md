---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f32383030323734372f:61727469636c652f64657461696c732f313036393433313136"
layout: post
title: "Android音视频开发一学习规划"
date: 2023-03-10 01:05:56 +0800
description: "目录序言学习规划音视频内容序言公司的项目有涉及到音视频的开发，但都是已经开发完的，想去看懂代码，但却"
keywords: "android音视频开发 pdf"
categories: ['Android']
tags: ['Java', 'Android']
artid: "106943116"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=106943116
    alt: "Android音视频开发一学习规划"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=106943116
featuredImagePreview: https://bing.ee123.net/img/rand?artid=106943116
---

# Android音视频开发（一）学习规划

#### 目录

* + - [序言](#_1)
    - [学习规划](#_3)
    - [音视频内容](#_6)

#### 序言

公司的项目有涉及到音视频的开发，但都是已经开发完的，想去看懂代码，但却无从下手，因为自己对音视频只有一个模糊的概念，所以从这个文章开始，从零入门，要把音视频弄懂，然后自己写一个demo。

#### 学习规划

目前的确没有比较系统的教程或者书籍，网上的博客文章也都是比较零散的，查找了很多资料，制定了一个学习路线。（Android音视频开发的学习系列文章主要是参考了Jhuster前辈的博客）
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/bb0078e49e2e1a865ef8624fc470998e.png)

#### 音视频内容

**核心：**
  
音视频技术=封装技术+视频压缩编码技术+音频压缩编码技术+流媒体协议技术

播放流程: 获取流–>解码–>播放
  
录制播放流程: 录制音频视频–>剪辑–>编码–>上传服务器
  
直播流程: 录制音视频–>编码–>流媒体传输–>服务器—>流媒体传输到其他app–>解码–>播放

几个重要的环节：
  
录制音视频 AudioRecord/MediaRecord
  
音视频编辑 mp4parser或ffmpeg
  
音视频编码 aac&h264
  
上传大文件 网络框架,进度监听,断点续传
  
流媒体传输 流媒体传输协议rtmp rtsp hls
  
音视频解码 aac&h264（MPEG-4Part10，h264的功能分为两层：视频编解码层（VCL）和网络提取层（NAL））
  
渲染播放 MediaPlayer
  
视频编辑可行性开源方案
  
ffmpeg(功能强大，包含libavcodec(音视频解码库)和libavformat（音视频格式转换库）)
  
MediaCodec （android自带）
  
ijkplayer (bilibili开源的)
  
mp4parser （软解软编音视频混合）
  
Vitamio

**具体实现**
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/547ae8cc10a84941a2c2b32a67bb28dc.png)
  
**采集**

采集，在音视频开发中主要针对的是数据从哪里来的问题。图像、视频的可视化数据来自摄像头这毫无疑问，而音频数据则是来自麦克风，关于采集的知识点涉及到如下内容：

系统的摄像头采集接口是什么，怎么用 ？
  
如：Windows：DirectShow，Linux：V4L2，Android：Camera

系统的摄像头采集的参数怎么配置，都是什么含义 ？
  
如：分辨率、帧率、预览方向、对焦、闪光灯 等

系统的摄像头输出的图像/视频数据，是什么格式，不同格式有什么区别 ？
  
如：图片：JPEG，视频数据：NV21，NV12，I420 等

系统的麦克风采集接口是什么，怎么用 ？
  
如：Windows：DirectShow，Linux：ALSA & OSS，Android：AudioRecord，iOS：Audio Unit 等

系统的麦克风采集参数怎么配置，都是什么含义 ？
  
如：采样率，通道号，位宽 等

系统的麦克风输出的音频数据，是什么格式？
  
如：PCM

**渲染：**

渲染，在音视频开发中主要针对的是数据展现的问题。我们知道，图像、视频最终都是要绘制到视图（View层）上面，而音频最终都是要输出到扬声器，因此，做音视频渲染，就要掌握如下的技术知识：

系统提供了哪些 API 可以绘制一张图片或者一帧 YUV 图像数据的 ？
  
如：
  
Windows：DirectDraw, Direct3D, GDI，OpenGL 等
  
Linux： GDI， OpenGL 等
  
Android：ImageView，SurfaceView，TextureView，OpenGL 等
  
系统提供了哪些 API 可以播放一个 mp3 或者 pcm 数据 ？
  
如：
  
Windows：DirectSound 等
  
Linux：ALSA & OSS 等
  
Android：AudioTrack 等

**处理：**
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/088e0c68e02afbc43bf52fba653ee4f2.png)

针对图像和音视频的处理，实现方式除了使用系统的 API，大多数也会使用一些优秀的第三方库，通过掌握这些第三方库的原理和使用方法，基本上就可以满足日常音视频处理工作了，这些库包括但不限于：
  
图像处理：OpenGL，OpenCV，libyuv，ffmpeg 等
  
视频编解码：x264，OpenH264，ffmpeg 等
  
音频处理：speexdsp，ffmpeg 等
  
音频编解码：libfaac，opus，speex，ffmpeg 等

**传输：**

传输，在音视频开发中主要针对的是数据共享的问题，采集完并处理数据以后，我们如何快速传输数据这一难题又摆在了面前，试想如果一个以音视频为主导业务的APP如果在播放过程中非常卡顿的话，用户体验那会是非常糟糕的。因此，解决传输的问题也就摆在了我们的面前。那么，数据究竟如何实现传输共享呢 ？共享，实现细则最重要的一点，就是协议，因此需要具体掌握的协议如下：

打包，音视频在传输前怎么打包，如：FLV，ts，mpeg4 等
  
直播推流，有哪些常见的协议，如：RTMP，RTSP 等
  
直播拉流，有哪些常见的协议，如：RTMP，HLS，HDL，RTSP 等
  
基于 UDP 的协议有哪些？如：RTP/RTCP，QUIC 等

**补充**
  
**编码格式**
  
H.264:低码率，高质量，高容错
  
开源实现：openh264、x264

H.265：能达到H.264两倍之压缩率，可支持4k分辨率，最高到8k。
  
开源实现：libde265、x265、vp9

对比：
  
H.265对H.264在码率节省上有较大的优势，在相同RSNR下分别节省了48.3%和75.8%。
  
H.264在编码时间上有聚到优势，对比VP9和H.265,H.265是vp9的6倍，vp9是H.264的将近40倍。

**推送协议**
  
1.RTMP
  
Real Time Messaging Protocol(实时消息传输协议)，基于 TCP，设计用来进行实时数据通信。
  
RTMP是目前主流的流媒体传输协议，广泛用于直播领域，市面上绝大多数直播产品都采用了这个协议。

2.HLS
  
http live streaming是由Apple公司定义的基于http的流媒体实时传输协议，可实现流媒体的直播和点播，主要用于ios系统。
  
原理是将整个流分为多个小的文件来下载，每次只下载 个。客户端只要不停的按顺序播放从服务器获取到的 件，就实现了直播。
  
分段推送的特点，决定了HLS的延迟一般会高于普通的流媒体直播协议。

3.WebRTC
  
web real time communication（网页即时通信），是一个支持网页浏览器进行实时语音或者视频对话的API。