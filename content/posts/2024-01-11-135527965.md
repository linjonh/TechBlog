---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71713833393031393331312f:61727469636c652f64657461696c732f313335353237393635"
layout: post
title: "开源模型应用落地-解锁大语言模型的无限潜能"
date: 2024-01-11 14:23:55 +0800
description: "本文档提供一系列开源大语言模型的落地应用教程，涵盖Qwen、B"
keywords: "开源模型应用落地-langchain高阶-集成vllm-qwen1.5-openai-compatible server"
categories: ['开源模型实际应用落地']
tags: ['语言模型', '自然语言处理', '深度学习', '安全', '人工智能', 'Milvus', 'Langchain']
artid: "135527965"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=135527965
    alt: "开源模型应用落地-解锁大语言模型的无限潜能"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=135527965
featuredImagePreview: https://bing.ee123.net/img/rand?artid=135527965
---

# 开源模型应用落地-解锁大语言模型的无限潜能

## **一、背景**

在当今社会，实际应用比纯粹理解原理和概念更为重要。即使您对某个领域的原理和概念有深入的理解，但如果无法将其应用于实际场景并受制于各种客观条件，那么与其一开始就过于深入，不如先从基础开始，实际操作后再逐步深入探索。
  
在这种实践至上的理念下，或许我可以为您提供一种直接的、实际操作的方法。希望能借助我的经验，为各位朋友带来一些有帮助的建议，例如：
  

**1、您是否也在迫不及待地期待在AI时代中展示自己的能力？
  
2、您是否一直在研究如何使用开源大语言模型？
  
3、您是否一直在寻找将AI与业务结合的方向？
  
4、您是否一直在寻找模型推理加速及降本增效的方法？
  
5、您是否一直在努力整合来自互联网上碎片化的资料？
  
6、您是否花费成百上千元购买网上的课程但却收获甚少？**
  
无论您是在学习中还是工作时有类似的困惑，我坚信您可以从我的文章里得到很多收获。

---

## **二、项目架构**

简化后的示意图如下：

![](https://i-blog.csdnimg.cn/blog_migrate/97030c012dfd4a57047134f15c170aa6.png)

## **三、总览**

通过实际案例，我们将为大家呈现一系列文章，帮助您了解如何将开源模型与业务整合。这些文章将引导您深入掌握该过程。

### **3.1. 初级入门系列**

#### 3.1.1. 开源模型应用落地- **QWen** 模型试炼-系列

[开源模型应用落地-qwen模型小试-入门篇（一）](https://blog.csdn.net/qq839019311/article/details/135553446 "开源模型应用落地-qwen模型小试-入门篇（一）")

重点：在windows环境下，使用transformer调用Qwen-1\_8B-Chat模型

[开源模型应用落地-qwen模型小试-入门篇（二）](https://blog.csdn.net/qq839019311/article/details/135599828 "开源模型应用落地-qwen模型小试-入门篇（二）")

重点：在windows环境下，使用transformer设置模型参数/System Prompt/历史对话

[开源模型应用落地-qwen模型小试-入门篇（三）](https://blog.csdn.net/qq839019311/article/details/135625869 "开源模型应用落地-qwen模型小试-入门篇（三）")

重点：在linux环境下，使用transformer调用Qwen-1\_8B-Chat模型

[开源模型应用落地-qwen模型小试-入门篇（四）](https://blog.csdn.net/qq839019311/article/details/135672748 "开源模型应用落地-qwen模型小试-入门篇（四）")

重点：使用gradio，构建Qwen-1\_8B-Chat模型的测试界面

[开源模型应用落地-qwen模型小试-入门篇（五）](https://blog.csdn.net/qq839019311/article/details/135681362 "开源模型应用落地-qwen模型小试-入门篇（五）")

重点：使用modelscope api调用Qwen-1\_8B-Chat模型，实现非流式/流式输出

[开源模型应用落地-qwen模型小试-调用qwen1.5新模型-进阶篇（六）](https://blog.csdn.net/qq839019311/article/details/136295363 "开源模型应用落地-qwen模型小试-调用qwen1.5新模型-进阶篇（六）")

重点：Qwen1.5系列模型的新特性及使用方式

[开源模型应用落地-qwen模型小试-调用Lora模型-进阶篇（七）](https://blog.csdn.net/qq839019311/article/details/136709202 "开源模型应用落地-qwen模型小试-调用Lora模型-进阶篇（七）")

重点：调用微调后的qwen-7b-chat模型

[开源模型应用落地-qwen模型小试-合并Lora模型-进阶篇（八）](https://blog.csdn.net/qq839019311/article/details/136738166 "开源模型应用落地-qwen模型小试-合并Lora模型-进阶篇（八）")

重点：将qwen-7b-chat基座模型与Lora模型进行合并

[开源模型应用落地-qwen模型小试-Zero/One/Few Shot-进阶篇（九）](https://blog.csdn.net/qq839019311/article/details/136849976 "开源模型应用落地-qwen模型小试-Zero/One/Few Shot-进阶篇（九）")

重点：深入理解Zero/One/Few-Shot,让模型可以更好地处理新任务

[开源模型应用落地-qwen模型小试-function call（十）](https://charles.blog.csdn.net/article/details/138726234 "开源模型应用落地-qwen模型小试-function call（十）")

重点：如何使用qwen1.5-7b-chat，正确调用function call

[开源模型应用落地-qwen模型小试-Qwen-Agent（十一）](https://charles.blog.csdn.net/article/details/138725019 "开源模型应用落地-qwen模型小试-Qwen-Agent（十一）")

重点：在qwen1.5-7b-chat模型下，利用Qwen-Agent构建智能代理，以理解和响应用户查询

[开源模型应用落地-qwen模型小试-调用Qwen2-7B-Instruct-进阶篇（十二）](https://charles.blog.csdn.net/article/details/139603164 "开源模型应用落地-qwen模型小试-调用Qwen2-7B-Instruct-进阶篇（十二）")

重点：掌握Qwen2系列模型的新特性及使用方式

[开源模型应用落地-模型量化-Qwen1.5-7B-Chat-GPTQ-Int8（一）](https://charles.blog.csdn.net/article/details/139001380 "开源模型应用落地-模型量化-Qwen1.5-7B-Chat-GPTQ-Int8（一）")

重点：理解GPTQ模型量化技术，以低成本体验大语言模型的魅力

[开源模型应用落地-模型量化-Qwen1.5-7B-Chat-AWQ（二）](https://charles.blog.csdn.net/article/details/138970526 "开源模型应用落地-模型量化-Qwen1.5-7B-Chat-AWQ（二）")

重点：理解AWQ模型量化技术，以低成本体验大语言模型的魅力

[开源模型应用落地-模型量化-AWQ vs GPTQ（三）](https://charles.blog.csdn.net/article/details/139006876 "开源模型应用落地-模型量化-AWQ vs GPTQ（三）")

重点：分析GPTQ和AWQ模型量化技术之间的差异

[开源模型应用落地-Qwen1.5-MoE-1/3的激活参数量达到7B模型的性能](https://charles.blog.csdn.net/article/details/139027760 " 开源模型应用落地-Qwen1.5-MoE-1/3的激活参数量达到7B模型的性能")

重点：使用Qwen1.5-MoE-A2.7B，体验更快的推理速度

[开源模型应用落地-Gradio正确集成Fastapi-助力模型交互-入门篇（一）](https://charles.blog.csdn.net/article/details/139103560 "开源模型应用落地-Gradio正确集成Fastapi-助力模型交互-入门篇（一）")

重点：正确集成Gradio和Fastapi两大技术框架

[开源模型应用落地-Gradio正确集成Fastapi-助力模型交互-实践篇（二）](https://charles.blog.csdn.net/article/details/139116482 "开源模型应用落地-Gradio正确集成Fastapi-助力模型交互-实践篇（二）")

重点：实践qwen1.5-7b-chat模型，同时提供界面交互和接口服务两种能力

#### 3.1.2. 开源模型应用落地- **BaiChuan** 模型试炼-系列

[开源模型应用落地-baichuan模型小试-入门篇（一）](https://blog.csdn.net/qq839019311/article/details/136701664 "开源模型应用落地-baichuan模型小试-入门篇（一）")

重点：在windows环境下，使用transformer调用Baichuan2-7B-Chat模型

[开源模型应用落地-baichuan2模型小试-入门篇（二）](https://blog.csdn.net/qq839019311/article/details/136744427 "开源模型应用落地-baichuan2模型小试-入门篇（二）")

重点：在windows环境下，使用transformer设置模型参数/System Prompt/历史对话

[开源模型应用落地-baichuan2模型小试-入门篇（三）](https://blog.csdn.net/qq839019311/article/details/137140557 "开源模型应用落地-baichuan2模型小试-入门篇（三）")

重点：在linux环境下，使用transformer调用Baichuan2-7B-Chat模型

#### 3.1.3. 开源模型应用落地 - **ChatGLM** 模型试 炼-系列

[开源模型应用落地-chatglm3-6b模型小试-入门篇（一）](https://blog.csdn.net/qq839019311/article/details/137233634?spm=1001.2014.3001.5502 "开源模型应用落地-chatglm3-6b模型小试-入门篇（一）")

重点：在windows环境下，使用transformer调用chatglm3-6b模型

[开源模型应用落地-chatglm3-6b模型小试-入门篇（二）](https://blog.csdn.net/qq839019311/article/details/137242757 "开源模型应用落地-chatglm3-6b模型小试-入门篇（二）")

重点：在windows环境下，使用transformer设置模型参数/System Prompt/历史对话

[开源模型应用落地-chatglm3-6b模型小试-入门篇（三）](https://blog.csdn.net/qq839019311/article/details/137341625 "开源模型应用落地-chatglm3-6b模型小试-入门篇（三）")

重点：在linux环境下，使用transformer调用chatglm3-6b模型

[开源模型应用落地-chatglm3-6b-批量推理-入门篇（四）](https://blog.csdn.net/qq839019311/article/details/137559702 "开源模型应用落地-chatglm3-6b-批量推理-入门篇（四）")

重点：在低成本下，连续批处理提升LLM推理吞吐量，减少延迟

[开源模型应用落地-chatglm3-6b-zero/one/few-shot-入门篇（五）](https://blog.csdn.net/qq839019311/article/details/137606189 "开源模型应用落地-chatglm3-6b-zero/one/few-shot-入门篇（五）")

重点：在Zero-Shot/One-Shot/Few-Shot场景下，ChatGLM3-6B的推理表现

[开源模型应用落地-chatglm3-6b-function call-入门篇（六）](https://blog.csdn.net/qq839019311/article/details/137647996 "开源模型应用落地-chatglm3-6b-function call-入门篇（六）")

重点：在ChatGLM3-6B模型下，实现Function Call

[开源模型应用落地-chatglm3-6b-gradio-入门篇（七）](https://blog.csdn.net/qq839019311/article/details/137777260 "开源模型应用落地-chatglm3-6b-gradio-入门篇（七）")

重点：使用gradio搭建AI交互界面

[开源模型应用落地-chatglm3-6b-streamlit-入门篇（八）](https://blog.csdn.net/qq839019311/article/details/137867113 "开源模型应用落地-chatglm3-6b-streamlit-入门篇（八）")

重点：使用streamlit搭建AI交互界面

[开源模型应用落地-chatglm3-6b-模型输出违禁词检测（九](https://blog.csdn.net/qq839019311/article/details/137880202 "开源模型应用落地-chatglm3-6b-模型输出违禁词检测（九")
）

重点：识别模型输出是否命中违禁词

[开源模型应用落地-chatglm3-6b-集成langchain（十）](https://blog.csdn.net/qq839019311/article/details/138130092 "开源模型应用落地-chatglm3-6b-集成langchain（十）")

重点：LangChain与ChatGLM3结合，提高对话系统的性能和用户体验

#### 3.1.4. 开源模型应用落地- **KnowLM** 模 型试炼-系列

[开源模型应用落地-KnowLM模型小试-入门篇（一）](https://blog.csdn.net/qq839019311/article/details/135778887 "开源模型应用落地-KnowLM模型小试-入门篇（一）")

重点：调用KnowLM模型，实现知识抽取

[开源模型应用落地-KnowLM模型小试-入门篇（二）](https://blog.csdn.net/qq839019311/article/details/135820984 "开源模型应用落地-KnowLM模型小试-入门篇（二）")

重点：优化模型参数，提高知识提取效率和质量

### **3.2. 高级进阶系列**

#### 3.2.1. 开源模型应用落地- **向量数据库** 小试 -入门篇系列

[开源模型应用落地-工具使用篇-向量数据库（三）](https://blog.csdn.net/qq839019311/article/details/136153709 "开源模型应用落地-工具使用篇-向量数据库（三）")

重点：Milvus Lite向量数据库的基本使用

[开源模型应用落地-工具使用篇-向量数据库进阶（四）](https://blog.csdn.net/qq839019311/article/details/136170245 "开源模型应用落地-工具使用篇-向量数据库进阶（四）")

重点：Milvus Lite向量数据库的进阶使用

#### 3.2.2. 开源模型应用落地- **qwen-7b-chat** 与 **vllm** 实 现推理加速的正确姿势系列

[开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（一）](https://blog.csdn.net/qq839019311/article/details/135499951 "  开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（一）")

重点：qwen-7b-chat集成vllm

[开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（二）](https://blog.csdn.net/qq839019311/article/details/135502875 "开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（二）")

重点：gunicorn+flask构建AI服务

[开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（三）](https://blog.csdn.net/qq839019311/article/details/135509560 "开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（三）")

重点：supervisor提升服务的稳定性

[开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（四）](https://blog.csdn.net/qq839019311/article/details/135523969 " 开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（四）")

重点：鉴权和限流提升AI服务的安全性和稳定性

[开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（五）](https://blog.csdn.net/qq839019311/article/details/135531364 "开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（五）")

重点：定时任务处理隐藏盲点

[开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（六）](https://blog.csdn.net/qq839019311/article/details/135546864 "开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（六）")

重点：改变模型自我认知

[开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（七）](https://blog.csdn.net/qq839019311/article/details/135550666 "开源模型应用落地-qwen-7b-chat与vllm实现推理加速的正确姿势（七）")

重点：AI服务性能优化

[开源模型应用落地-qwen1.5-7b-chat与vllm实现推理加速的正确姿势（八）](https://blog.csdn.net/qq839019311/article/details/136359272 "开源模型应用落地-qwen1.5-7b-chat与vllm实现推理加速的正确姿势（八）")

重点：qwen1.5-7b-chat集成vllm

[开源模型应用落地-qwen1.5-7b-chat与vllm实现推理加速的正确姿势（九）](https://blog.csdn.net/qq839019311/article/details/136394629 "开源模型应用落地-qwen1.5-7b-chat与vllm实现推理加速的正确姿势（九）")

重点：qwen1.5-7b-chat集成vllm，构建与OpenAI-API兼容的API服务

[开源模型应用落地-Qwen2-7B-Instruct与vllm实现推理加速的正确姿势（十）](https://charles.blog.csdn.net/article/details/139592157 "开源模型应用落地-Qwen2-7B-Instruct与vllm实现推理加速的正确姿势（十）")

重点：Qwen2-7B-Instruct集成vllm，流式输出

[开源模型应用落地-Qwen2-7B-Instruct与vllm-单机多卡-RTX 4090双卡（十一）](https://charles.blog.csdn.net/article/details/140987825?spm=1001.2014.3001.5502 "开源模型应用落地-Qwen2-7B-Instruct与vllm-单机多卡-RTX 4090双卡（十一）")

重点：4090单机双卡部署vllm，并集成qwen2-7b-instruct

[开源模型应用落地-Qwen2-7B-Instruct-GPTQ-Int4与vllm-单机多卡-RTX 4090双卡（十二）](https://charles.blog.csdn.net/article/details/140990466 " 开源模型应用落地-Qwen2-7B-Instruct-GPTQ-Int4与vllm-单机多卡-RTX 4090双卡（十二）")

重点：4090单机双卡部署vllm，并集成qwen2-7b-instruct-gptq-int4

[开源模型应用落地-Qwen2-7B-Instruct与vllm-单机多卡-RTX 4090双卡-基准测试（十三）](https://charles.blog.csdn.net/article/details/140995291 "开源模型应用落地-Qwen2-7B-Instruct与vllm-单机多卡-RTX 4090双卡-基准测试（十三）")
  
重点：​​​​​​​4090单机双卡部署vllm和qwen2-7b-instruct，执行基准测试

[开源模型应用落地-Meta-Llama-3.1-8B-Instruct与vllm-单机多卡-RTX 4090双卡（十四）](https://charles.blog.csdn.net/article/details/141020851 "开源模型应用落地-Meta-Llama-3.1-8B-Instruct与vllm-单机多卡-RTX 4090双卡（十四）")
  
重点：4090单机双卡部署vllm，并集成meta-llama-3.1-8b-instruct

[开源模型应用落地-Qwen2-7B-Instruct-Lora与vllm-单机多卡-RTX 4090双卡（十五）](https://charles.blog.csdn.net/article/details/141063367 "开源模型应用落地-Qwen2-7B-Instruct-Lora与vllm-单机多卡-RTX 4090双卡（十五）")
​​​​​​​
  
重点：4090单机双卡部署vllm，并集成qwen2-7b-instruct和Lora权重

#### 3.2.3. 开源模型应用落地- **业务整合** 系列

[开源模型应用落地-业务整合篇-多种方式调用AI服务（一）](https://blog.csdn.net/qq839019311/article/details/135622528 "开源模型应用落地-业务整合篇-多种方式调用AI服务（一）")

重点：使用HttpURLConnection/OkHttp/HttpClient多种方式调用AI服务

[开源模型应用落地-业务整合篇-构建WebSocket服务（二）](https://blog.csdn.net/qq839019311/article/details/135648720 "开源模型应用落地-业务整合篇-构建WebSocket服务（二）")

重点：使用Netty库快速构建WebSocket服务，实现客户端与AI服务交互

[开源模型应用落地-业务整合篇-Springboot集成Netty（三）](https://blog.csdn.net/qq839019311/article/details/135748368 "开源模型应用落地-业务整合篇-Springboot集成Netty（三）")

重点：spring boot集成netty服务，实现用户界面交互

[开源模型应用落地-业务整合篇-构建websocket校验机制（四）](https://blog.csdn.net/qq839019311/article/details/135773511 "开源模型应用落地-业务整合篇-构建websocket校验机制（四）")

重点：构建websocket身份校验机制，避免无效连接

[开源模型应用落地-业务整合篇-构建websocket心跳机制（五）](https://blog.csdn.net/qq839019311/article/details/135817286 "开源模型应用落地-业务整合篇-构建websocket心跳机制（五）")

重点：构建websocket心跳机制，及时释放一些无效的连接

#### 3.2.4. 开源模型应用落地- **业务优化** 系列

[开源模型应用落地-业务优化篇（一）](https://blog.csdn.net/qq839019311/article/details/135851421 "开源模型应用落地-业务优化篇（一）")

重点：使用线程池提升处理效率

[开源模型应用落地-业务优化篇（二）](https://blog.csdn.net/qq839019311/article/details/135954121 " 开源模型应用落地-业务优化篇（二）")

重点：使用Redis队列和分布式锁实现请求排队

[开源模型应用落地-业务优化篇（三）](https://blog.csdn.net/qq839019311/article/details/135970965 "开源模型应用落地-业务优化篇（三）")

重点：使用SLB实现AI服务水平扩容

[开源模型应用落地-业务优化篇（四）](https://blog.csdn.net/qq839019311/article/details/136011411 "开源模型应用落地-业务优化篇（四）")

重点：多级数据缓存概述

[开源模型应用落地-业务优化篇（五）](https://blog.csdn.net/qq839019311/article/details/136041720 "开源模型应用落地-业务优化篇（五）")

重点：使用HanLP进行词性标注，并使用Redis作为一级缓存

[开源模型应用落地-业务优化篇（六）](https://blog.csdn.net/qq839019311/article/details/136210398 "开源模型应用落地-业务优化篇（六）")

重点：使用向量数据库作为二级缓存，来为AI服务减负，提升处理效率

[开源模型应用落地-业务优化篇（七）](https://blog.csdn.net/qq839019311/article/details/136324026 "开源模型应用落地-业务优化篇（七）")

重点：使用RocketMQ提升处理效率

[开源模型应用落地-业务优化篇（八）](https://blog.csdn.net/qq839019311/article/details/136617573 " 开源模型应用落地-业务优化篇（八）")

重点：统计问题的请求频次，实现热门问题的实时缓存

#### 3.2.5. 开源模型应用落地- **安全合规** 系列

[开源模型应用落地-安全合规篇-用户输入合规性检测（一）](https://blog.csdn.net/qq839019311/article/details/136255005 "开源模型应用落地-安全合规篇-用户输入合规性检测（一）")

重点：使用DFA算法检测用户输入内容的合法性

[开源模型应用落地-安全合规篇-用户输入合规性检测（二）](https://blog.csdn.net/qq839019311/article/details/136631658 "开源模型应用落地-安全合规篇-用户输入合规性检测（二）")

重点：使用腾讯云文本内容安全服务检测用户输入内容的合法性

[开源模型应用落地-安全合规篇-模型输出合规性检测（三）](https://blog.csdn.net/qq839019311/article/details/136804205 "开源模型应用落地-安全合规篇-模型输出合规性检测（三）")

重点：使用腾讯云文本内容安全服务检测模型输出内容的合法性

#### 3.2.6. 开源模型应用落地-大模型应用框架LangChain系列

[开源模型应用落地-LangChain试炼-Zero/One/Few Shot](https://blog.csdn.net/qq839019311/article/details/137674159 "开源模型应用落地-LangChain试炼-Zero/One/Few Shot")

重点：基于LangChain框架，体验Zero/One/Few-Shot的使用

[开源模型应用落地-LangChain高阶-QWen1.5-外部实时数据](https://blog.csdn.net/qq839019311/article/details/137794373 "开源模型应用落地-LangChain高阶-QWen1.5-外部实时数据")

重点：通过LangChain调用外部“心知天气”服务，并将结果返回给QWen1.5模型处理

[开源模型应用落地-LangChain高阶-知识图谱助力记忆增强](https://blog.csdn.net/qq839019311/article/details/138066690 "开源模型应用落地-LangChain高阶-知识图谱助力记忆增强")

重点：通过知识图谱为模型提供丰富的语义信息和外部记忆支持

[开源模型应用落地-LangChain高阶-事件回调-合规校验](https://blog.csdn.net/qq839019311/article/details/138164690 "开源模型应用落地-LangChain高阶-事件回调-合规校验")

重点：通过事件回调机制，实现用户输入和模型输出的合规检测

[开源模型应用落地-LangChain试炼-CPU调用QWen1.5（一）](https://blog.csdn.net/qq839019311/article/details/137771084?spm=1001.2014.3001.5501 "开源模型应用落地-LangChain试炼-CPU调用QWen1.5（一）")

重点：基于LangChain框架，通过CPU调用本地qwen1.5-7b-chat模型

[开源模型应用落地-LangChain高阶-GPU调用QWen1.5（二）](https://blog.csdn.net/qq839019311/article/details/137782254 "开源模型应用落地-LangChain高阶-GPU调用QWen1.5（二）")

重点：基于LangChain框架，通过GPU调用本地qwen1.5-7b-chat模型

[开源模型应用落地-LangChain高阶-集成vllm-QWen1.5（一）](https://blog.csdn.net/qq839019311/article/details/138117633 "开源模型应用落地-LangChain高阶-集成vllm-QWen1.5（一）")

重点：LangChain与vllm、QWen1.5模型结合，提高对话系统的性能和用户体验

[开源模型应用落地-LangChain高阶-集成vllm-QWen1.5（二）](https://blog.csdn.net/qq839019311/article/details/138157891 "开源模型应用落地-LangChain高阶-集成vllm-QWen1.5（二）")

重点：LangChain与vllm、QWen1.5模型结合，提高对话系统的性能和用户体验

[开源模型应用落地-LangChain高阶-集成vllm-QWen1.5-OpenAI-Compatible Server（三）](https://blog.csdn.net/qq839019311/article/details/138216889 "开源模型应用落地-LangChain高阶-集成vllm-QWen1.5-OpenAI-Compatible Server（三）")

重点：LangChain集成vllm，构建与OpenAI-API兼容的API服务

[开源模型应用落地-LangChain高阶-Tools工具-ShellTool（一）](https://blog.csdn.net/qq839019311/article/details/138280648 "开源模型应用落地-LangChain高阶-Tools工具-ShellTool（一）")

重点：通过使用LangChain提供的ShellTool工具，让LLM与本地文件系统进行交互

[开源模型应用落地-LangChain高阶-Tools工具-WolframAlpha（二）](https://blog.csdn.net/qq839019311/article/details/138358852 "开源模型应用落地-LangChain高阶-Tools工具-WolframAlpha（二）")

重点：通过使用LangChain提供的WolframAlpha工具，实现在线计算知识引擎和智能搜索。

[开源模型应用落地-LangChain高阶-Tools工具-GoogleSerperAPIWrapper（三）](https://blog.csdn.net/qq839019311/article/details/138387832 "开源模型应用落地-LangChain高阶-Tools工具-GoogleSerperAPIWrapper（三）")

重点：通过使用LangChain提供的GoogleSerperAPIWrapper工具，实现在线实时搜索

[开源模型应用落地-LangChain高阶-Tools工具-集成agents（四）](https://blog.csdn.net/qq839019311/article/details/138441855 "开源模型应用落地-LangChain高阶-Tools工具-集成agents（四）")

重点：将代理串联工具，将大语言模型的能力和本地、云服务能力结合

[开源模型应用落地-LangChain高阶-Tools工具-Multi-Agent（五）](https://blog.csdn.net/qq839019311/article/details/138471568 "开源模型应用落地-LangChain高阶-Tools工具-Multi-Agent（五）")

重点：串联多个agents协同合作，高效完成复杂任务

[开源模型应用落地-LangChain高阶-智能体探究-agent类型（一）](https://charles.blog.csdn.net/article/details/140182678 "开源模型应用落地-LangChain高阶-智能体探究-agent类型（一）")

重点：智能体入门，学习前三种agent类型，学习前三种agent类型，包括ZERO\_SHOT\_REACT\_DESCRIPTION/CHAT\_ZERO\_SHOT\_REACT\_DESCRIPTION/CONVERSATIONAL\_REACT\_DESCRIPTION

[开源模型应用落地-LangChain高阶-智能体探究-agent类型（二）](https://charles.blog.csdn.net/article/details/140208184 "开源模型应用落地-LangChain高阶-智能体探究-agent类型（二）")

重点：智能体入门，学习后三种agent类型，包括CHAT\_CONVERSATIONAL\_REACT\_DESCRIPTION/OPENAI\_FUNCTIONS/STRUCTURED\_CHAT\_ZERO\_SHOT\_REACT\_DESCRIPTION

[开源模型应用落地-LangChain高阶-智能体探究-ReadOnlySharedMemory共享记忆（三）](https://charles.blog.csdn.net/article/details/140297518 "开源模型应用落地-LangChain高阶-智能体探究-ReadOnlySharedMemory共享记忆（三）")
​​​​​​​

重点：ReadOnlySharedMemory（只读共享内存）用于存储历史信息，并以只读的方式提供给其他组件使用

[开源模型应用落地-LangChain试炼-LCEL-表达式语言（一）](https://charles.blog.csdn.net/article/details/139468417 "开源模型应用落地-LangChain试炼-LCEL-表达式语言（一）")

重点：学习LangChain表达式语言，帮助您更方便地构建复杂的应用程序

[开源模型应用落地-LangChain高阶-LCEL-表达式语言（二）](https://charles.blog.csdn.net/article/details/139523356 "开源模型应用落地-LangChain高阶-LCEL-表达式语言（二）")

重点：学习LangChain表达式语言的高级用法，包括：批量推理，异步输出，异步调用

[开源模型应用落地-LangChain高阶-LCEL-表达式语言（三）](https://charles.blog.csdn.net/article/details/139528129 "开源模型应用落地-LangChain高阶-LCEL-表达式语言（三）")

重点：学习LangChain表达式语言的高级用法，包括：链接一切可运行的内容

[开源模型应用落地-LangChain高阶-LCEL-表达式语言（四）](https://charles.blog.csdn.net/article/details/139544990 "开源模型应用落地-LangChain高阶-LCEL-表达式语言（四）")

重点：学习LangChain表达式语言的高级用法，包括：格式化输入和输出、多任务并行化处理

[开源模型应用落地-LangChain高阶-LCEL-表达式语言（五）](https://charles.blog.csdn.net/article/details/139565172 "开源模型应用落地-LangChain高阶-LCEL-表达式语言（五）")

重点：学习LangChain表达式语言的高级用法，包括：绑定运行时参数，设置停止词，绑定OpenAI functions 或tools

[开源模型应用落地-LangChain高阶-LCEL-表达式语言（六）](https://charles.blog.csdn.net/article/details/139690594 "开源模型应用落地-LangChain高阶-LCEL-表达式语言（六）")

重点：学习LangChain表达式语言的高级用法，包括： 运行自定义函数，接收可运行配置

[开源模型应用落地-LangChain高阶-LCEL-表达式语言（七）](https://charles.blog.csdn.net/article/details/139723683 "开源模型应用落地-LangChain高阶-LCEL-表达式语言（七）")

重点：学习LangChain表达式语言的高级用法，包括：传递输入，即实现在不改变或添加额外键的情况下改变键值。

[开源模型应用落地-LangChain高阶-LCEL-表达式语言（八）](https://charles.blog.csdn.net/article/details/139918395 "开源模型应用落地-LangChain高阶-LCEL-表达式语言（八）")

重点：学习LangChain表达式语言的高级用法，包括：向链状态添加值

[开源模型应用落地-LangChain高阶-记忆组件-ConversationBufferMemory正确使用（一）](https://charles.blog.csdn.net/article/details/140666606 "开源模型应用落地-LangChain高阶-记忆组件-ConversationBufferMemory正确使用（一）")

重点：学习如何正确使用ConversationBufferMemory组件

[开源模型应用落地-LangChain高阶-记忆组件-ConversationBufferWindowMemory正确使用（二）](https://charles.blog.csdn.net/article/details/140669668 "        开源模型应用落地-LangChain高阶-记忆组件-ConversationBufferWindowMemory正确使用（二）")

重点：学习如何正确使用ConversationBufferWindowMemory组件

[开源模型应用落地-LangChain高阶-记忆组件-ConversationEntityMemory正确使用（三）](https://charles.blog.csdn.net/article/details/140691187 "开源模型应用落地-LangChain高阶-记忆组件-ConversationEntityMemory正确使用（三）")

重点：学习如何正确使用ConversationEntityMemory组件

[开源模型应用落地-LangChain高阶-记忆组件-ConversationKGMemory正确使用（四）](https://blog.csdn.net/qq839019311/article/details/140772145 "开源模型应用落地-LangChain高阶-记忆组件-ConversationKGMemory正确使用（四）")

重点：学习如何正确使用ConversationKGMemory组件

[开源模型应用落地-LangChain高阶-记忆组件-ConversationSummaryMemory正确使用（五）](https://charles.blog.csdn.net/article/details/140825133 "开源模型应用落地-LangChain高阶-记忆组件-ConversationSummaryMemory正确使用（五）")

重点：学习如何正确使用ConversationSummaryMemory组件

[开源模型应用落地-LangChain高阶-记忆组件-ConversationSummaryBufferMemory正确使用（六）](https://charles.blog.csdn.net/article/details/140828611 "        开源模型应用落地-LangChain高阶-记忆组件-ConversationSummaryBufferMemory正确使用（六）")

重点：学习如何正确使用ConversationTokenBufferMemory组件

[开源模型应用落地-LangChain高阶-记忆组件-ConversationTokenBufferMemory正确使用（七）](https://charles.blog.csdn.net/article/details/140889388 "        开源模型应用落地-LangChain高阶-记忆组件-ConversationTokenBufferMemory正确使用（七）")

重点：学习如何正确使用ConversationTokenBufferMemory组件

[开源模型应用落地-LangChain高阶-记忆组件-RedisChatMessageHistory正确使用（八）](https://charles.blog.csdn.net/article/details/141130023 "开源模型应用落地-LangChain高阶-记忆组件-RedisChatMessageHistory正确使用（八）")

重点：学习如何正确使用RedisChatMessageHistory组件

[开源模型应用落地-LangChain高阶-记忆组件-FileChatMessageHistory正确使用（九）](https://charles.blog.csdn.net/article/details/141170741 "开源模型应用落地-LangChain高阶-记忆组件-FileChatMessageHistory正确使用（九）")

重点：学习如何正确使用FileChatMessageHistory组件

#### 3.2.7. 开源模型应用落地-大模型应用框架LangSmith系列

[开源模型应用落地-LangSmith试炼-入门初体验（一）](https://charles.blog.csdn.net/article/details/139045113 "开源模型应用落地-LangSmith试炼-入门初体验（一）")

重点：使用LangSmith的Trace进行模型的开发和调试

[开源模型应用落地-LangSmith试炼-入门初体验-数据集管理（二）](https://charles.blog.csdn.net/article/details/139155896 "开源模型应用落地-LangSmith试炼-入门初体验-数据集管理（二）")

重点：使用LangSmith更好地管理数据，提高了数据的组织性和可访问性。

[开源模型应用落地-LangSmith试炼-入门初体验-数据集评估（三）](https://charles.blog.csdn.net/article/details/139198336 "开源模型应用落地-LangSmith试炼-入门初体验-数据集评估（三）")

重点：学习Evaluate功能，评估和衡量在多样化数据上的性能和完整性

[开源模型应用落地-LangSmith试炼-入门初体验-获取用户反馈（四）](https://charles.blog.csdn.net/article/details/139242711 "开源模型应用落地-LangSmith试炼-入门初体验-获取用户反馈（四）")

重点：学习Human feedback功能，帮助用户从应用程序中捕获用户反馈，并将其与跟踪记录关联起来

[开源模型应用落地-LangSmith试炼-入门初体验-监控和自动化（五）](https://charles.blog.csdn.net/article/details/139362299 "开源模型应用落地-LangSmith试炼-入门初体验-监控和自动化（五）")

重点：学习Monitoring and automations功能，帮助开发者更好地管理和优化LangChain应用程序，提高其性能、可靠性和用户体验。

[开源模型应用落地-LangSmith试炼-入门初体验-Prompts（六）](https://charles.blog.csdn.net/article/details/139390235 "开源模型应用落地-LangSmith试炼-入门初体验-Prompts（六）")

重点：通过学习Prompts功能，用户可以上传、浏览、检索和管理提示（Prompt），使开发过程更加流畅。

#### 3.2.8. 开源模型应用落地-大模型应用框架LlamaIndex系列

[开源模型应用落地-LlamaIndex学习之旅-LLMs-集成OpenAI（一）](https://charles.blog.csdn.net/article/details/141640806 "开源模型应用落地-LlamaIndex学习之旅-LLMs-集成OpenAI（一）")

重点：LlamaIndex集成OpenAI

[开源模型应用落地-LlamaIndex学习之旅-LLMs-集成OpenAI（二）](https://charles.blog.csdn.net/article/details/141683847 "开源模型应用落地-LlamaIndex学习之旅-LLMs-集成OpenAI（二）")

重点：LlamaIndex集成OpenAI

### **3.3. 深度优化系列**

#### 3.3.1. 开源模型应落地- QWen模型 **微调** 系列

[开源模型应用落地-qwen-7b-chat-LoRA微调（一）](https://blog.csdn.net/qq839019311/article/details/137070492 "开源模型应用落地-qwen-7b-chat-LoRA微调（一）")

重点：使用官方正确方式微调qwen-7b-chat模型

[开源模型应用落地-qwen1.5-7b-chat-LoRA微调（二）](https://blog.csdn.net/qq839019311/article/details/137097181 "开源模型应用落地-qwen1.5-7b-chat-LoRA微调（二）")

重点：使用官方正确方式微调qwen1.5-7b-chat模型

[开源模型应用落地-qwen-7b-chat-LoRA微调-Firefly（三）](https://blog.csdn.net/qq839019311/article/details/137145216 "开源模型应用落地-qwen-7b-chat-LoRA微调-Firefly（三）")

重点：使用第三方开源Firefly框架微调qwen-7b-chat模型

[开源模型应用落地-qwen1.5-7b-chat-LoRA微调-Firefly（四）](https://blog.csdn.net/qq839019311/article/details/137151767 "开源模型应用落地-qwen1.5-7b-chat-LoRA微调-Firefly（四）")

重点：使用第三方开源Firefly框架微调qwen1.5-7b-chat模型

[开源模型应用落地-qwen2-7b-instruct-LoRA微调-LLaMA-Factory-单机多卡-RTX 4090双卡（五）](https://charles.blog.csdn.net/article/details/141032393?spm=1001.2014.3001.5502 "开源模型应用落地-qwen2-7b-instruct-LoRA微调-LLaMA-Factory-单机多卡-RTX 4090双卡（五）")

重点：使用LLaMA-Factory高效微调qwen2-7b-instruct

[开源模型应用落地-qwen2-7b-instruct-LoRA微调&模型合并-LLaMA-Factory-单机多卡-RTX 4090双卡（六）](https://charles.blog.csdn.net/article/details/141255541?spm=1001.2014.3001.5502 "开源模型应用落地-qwen2-7b-instruct-LoRA微调&模型合并-LLaMA-Factory-单机多卡-RTX 4090双卡（六）")

重点：使用LLaMA-Factory合并微调后的模型权重

[开源模型应用落地-qwen2-7b-instruct-LoRA微调-Axolotl-单机多卡-RTX 4090双卡（七）](https://charles.blog.csdn.net/article/details/141265337?spm=1001.2014.3001.5502 "开源模型应用落地-qwen2-7b-instruct-LoRA微调-Axolotl-单机多卡-RTX 4090双卡（七）")

重点：使用Axolotl高效微调qwen2-7b-instruct

[开源模型应用落地-qwen2-7b-instruct-LoRA微调-LLaMA-Factory-单机单卡-V100（八）](https://charles.blog.csdn.net/article/details/141391066?spm=1001.2014.3001.5502 "开源模型应用落地-qwen2-7b-instruct-LoRA微调-LLaMA-Factory-单机单卡-V100（八）")

重点：使用LLaMA-Factory高效微调qwen2-7b-instruct

[开源模型应用落地-qwen2-7b-instruct-LoRA微调-Axolotl-单机单卡-V100（九）](https://charles.blog.csdn.net/article/details/141434421?spm=1001.2014.3001.5502 "开源模型应用落地-qwen2-7b-instruct-LoRA微调-Axolotl-单机单卡-V100（九）")

重点：使用Axolotl高效微调qwen2-7b-instruct

[开源模型应用落地-qwen2-7b-instruct-LoRA微调&模型合并-Axolotl-单机单卡-V100（十）](https://charles.blog.csdn.net/article/details/141461396?spm=1001.2014.3001.5502 "开源模型应用落地-qwen2-7b-instruct-LoRA微调&模型合并-Axolotl-单机单卡-V100（十）")

重点：使用Axolotl合并微调后的模型权重

[开源模型应用落地-qwen2-7b-instruct-LoRA推理&Gradio-Axolotl-单机单卡-V100（十一）](https://charles.blog.csdn.net/article/details/141464315?spm=1001.2014.3001.5502 "开源模型应用落地-qwen2-7b-instruct-LoRA推理&Gradio-Axolotl-单机单卡-V100（十一）")
​​​​​​​

重点：使用Axolotl对Lora模型进行推理

[开源模型应用落地-qwen2-7b-instruct-LoRA微调-ms-swift-单机单卡-V100（十二）](https://charles.blog.csdn.net/article/details/141716583 "开源模型应用落地-qwen2-7b-instruct-LoRA微调-ms-swift-单机单卡-V100（十二）")

重点：使用ms-swift高效微调qwen2-7b-instruct

[开源模型应用落地-qwen2-7b-instruct-LoRA微调&合并-ms-swift-单机单卡-V100（十三）](https://charles.blog.csdn.net/article/details/141722958 "开源模型应用落地-qwen2-7b-instruct-LoRA微调&合并-ms-swift-单机单卡-V100（十三）")

重点：使用ms-swift合并微调后的模型权重

[开源模型应用落地-qwen2-7b-instruct-LoRA微调-ms-swift-单机多卡-RTX 4090双卡（十四）](https://charles.blog.csdn.net/article/details/141783404 "开源模型应用落地-qwen2-7b-instruct-LoRA微调-ms-swift-单机多卡-RTX 4090双卡（十四）")

重点：使用ms-swift高效微调qwen2-7b-instruct

[开源模型应用落地-qwen2-7b-instruct-LoRA微调&合并-ms-swift-单机多卡-RTX 4090双卡（十五）](https://charles.blog.csdn.net/article/details/141784088 "开源模型应用落地-qwen2-7b-instruct-LoRA微调&合并-ms-swift-单机多卡-RTX 4090双卡（十五）")

重点：使用ms-swift合并微调后的模型权重

[开源模型应用落地-qwen2-7b-instruct-LoRA微调-unsloth（让微调起飞）-单机单卡-V100（十六）](https://charles.blog.csdn.net/article/details/142178136 "开源模型应用落地-qwen2-7b-instruct-LoRA微调-unsloth（让微调起飞）-单机单卡-V100（十六）")

重点：使用unsloth高效微调qwen2-7b-instruct

[开源模型应用落地-qwen2-7b-instruct-LoRA微调-unsloth（让微调起飞）-单机单卡-V100（十七）](https://charles.blog.csdn.net/article/details/142207397 "开源模型应用落地-qwen2-7b-instruct-LoRA微调-unsloth（让微调起飞）-单机单卡-V100（十七）")
​​​​​​​

重点：使用unsloth合并微调后的模型权重

[开源模型应用落地-qwen1.5-7b-chat-LoRA微调代码拆解](https://blog.csdn.net/qq839019311/article/details/137428525 "开源模型应用落地-qwen1.5-7b-chat-LoRA微调代码拆解")

重点：深度剖析官方qwen1.5-7b-chat模型微调代码

#### 3.3.2. 开源模型应用落地- **qwen1.5-7b-chat** 与 **sglang** 实 现推理加速的正确姿势系列

[开源模型应用落地-qwen1.5-7b-chat与sglang实现推理加速的正确姿势（一）](https://charles.blog.csdn.net/article/details/137498993 "开源模型应用落地-qwen1.5-7b-chat与sglang实现推理加速的正确姿势（一）")

重点：qwen1.5-7b-chat集成sglang，实现5倍加速

[开源模型应用落地-qwen1.5-7b-chat与sglang实现推理加速的正确姿势（二）](https://charles.blog.csdn.net/article/details/137503307 "开源模型应用落地-qwen1.5-7b-chat与sglang实现推理加速的正确姿势（二）")

重点：sglang性能优化，让其跑的更快

#### 3.3.3. 开源模型应用落地 -模型 **记忆增强** 系列

[开源模型应用落地-模型记忆增强-概念篇（一）](https://charles.blog.csdn.net/article/details/138613290 "开源模型应用落地-模型记忆增强-概念篇（一）")

重点：理解增强大语言模型的记忆能力的方法

[开源模型应用落地-模型记忆增强-向量数据库准备-实践篇（二）](https://blog.csdn.net/qq839019311/article/details/138620623?spm=1001.2014.3001.5501 "开源模型应用落地-模型记忆增强-向量数据库准备-实践篇（二）")

重点：实践使用长期记忆模块增强大语言模型的记忆能力

[开源模型应用落地-模型记忆增强-提升向量检索准确率-实践篇（三）](https://charles.blog.csdn.net/article/details/138706507 "开源模型应用落地-模型记忆增强-提升向量检索准确率-实践篇（三）")

重点：使用长期记忆模块增强大语言模型的记忆能力，优化向量检索准确率

[开源模型应用落地-模型记忆增强-整合AI服务-QWen1.5-7B-Chat（四）](https://charles.blog.csdn.net/article/details/139143460 "开源模型应用落地-模型记忆增强-整合AI服务-QWen1.5-7B-Chat（四）")

重点：业务流程（AI服务）集成长期记忆模块，提升用户对话体验

### **3.4. 知识巩固系列**

#### 3.4.1.开源模型应用落地-项目回顾系列

[开源模型应用落地-知识巩固-如何正确搭建生产级AI服务（一）](https://charles.blog.csdn.net/article/details/139350021 "开源模型应用落地-知识巩固-如何正确搭建生产级AI服务（一）")

重点：将大语言模型集成至vLLM能够带来显著的性能优化和稳定性提升,为用户提供更快捷、更高效的AI服务体验

### **3.5. 加餐系列**

#### 3.5.1.开源模型应用落地-音频模型应用探索

[开源模型应用落地-语音转文本-whisper模型-AIGC应用探索（一）](https://charles.blog.csdn.net/article/details/139298289 "开源模型应用落地-语音转文本-whisper模型-AIGC应用探索（一）")

重点：学习OpenAI开源的Whisper语音识别模型，帮助用户将语音转换成文字

[开源模型应用落地-语音转文本-whisper模型-AIGC应用探索（二）](https://charles.blog.csdn.net/article/details/139321677 "开源模型应用落地-语音转文本-whisper模型-AIGC应用探索（二）")

重点：学习OpenAI开源的Whisper语音识别模型，并集成FastAPI对外提供语音识别服务

[开源模型应用落地-语音转文本-whisper模型-AIGC应用探索（三）](https://charles.blog.csdn.net/article/details/139424984 "开源模型应用落地-语音转文本-whisper模型-AIGC应用探索（三）")

重点：通过官方推荐的方法调用OpenAI 开放的Whisper语音识别模型

[开源模型应用落地-语音转文本-openai-STT服务-AIGC应用探索（四）](https://charles.blog.csdn.net/article/details/139411954 "开源模型应用落地-语音转文本-openai-STT服务-AIGC应用探索（四）")

重点：学习OpenAI付费的语音识别服务，实现将语音转换成文本

[开源模型应用落地-音乐生成模型-MusicGen深度使用-AIGC应用探索（五）](https://charles.blog.csdn.net/article/details/139626190 "开源模型应用落地-音乐生成模型-MusicGen深度使用-AIGC应用探索（五）")

重点：学习音乐生成模型，让我们能够探索到音乐创作的全新边界和可能性

[开源模型应用落地-音乐生成模型-suno/bark深度使用-AIGC应用探索（六）](https://charles.blog.csdn.net/article/details/139749773 "开源模型应用落地-音乐生成模型-suno/bark深度使用-AIGC应用探索（六）")

重点：学习suno/bark音乐生成模型，让我们能够探索到音乐创作的全新边界和可能性

[开源模型应用落地-音乐生成模型-suno/bark深度使用-AIGC应用探索（七）](https://charles.blog.csdn.net/article/details/139800590 "开源模型应用落地-音乐生成模型-suno/bark深度使用-AIGC应用探索（七）")

重点：优化模型参数，生成更多样化的音乐，并且支持处理更长的文本输入,生成更长的音乐作品。