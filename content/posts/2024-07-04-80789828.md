---
arturl_encode: "68747470733a2f2f626c6f67:2e6373646e2e6e65742f77656978696e5f3432333234343731:2f61727469636c652f64657461696c732f3830373839383238"
layout: post
title: "数据库去重和查询指定记录区间数据"
date: 2024-07-04 16:46:21 +08:00
description: "PostgreSQL数据库的去重与查询制定区间的记录数1、查询前N条记录数在PostgreSQL数据"
keywords: "区间数据去重计数"
categories: ['数据库相关']
tags: ['无标签']
artid: "80789828"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=80789828
    alt: "数据库去重和查询指定记录区间数据"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=80789828
featuredImagePreview: https://bing.ee123.net/img/rand?artid=80789828
---

# 数据库去重和查询指定记录区间数据

**PostgreSQL

数据库的去重与查询制定区间的记录数**

**1、查询前N条记录数**

在PostgreSQL数据库数据库中有一个limit函数用来查询前多少条

SELECT * from  ag_actv  LIMIT 1050

我们得到是 ag_actv 表中的1050行记录

**2、查询指定区间的记录数（如1000-1050）**

顺着这个思路的话我们就可得到指定区间的记录数，比如我们要查询1000到1050条之间的50条记录，我们可以先获取1050条就作为一个临时表，再从此表中查询，并让其主键id不等于前1000条记录中的id

SELECT * from  (SELECT * from ag_actv   LIMIT 1050) sq WHERE sq.seq_num  not in  (SELECT seq_num  from ag_actv  LIMIT 1000)

**3、去重查询**

1、所有数据全部重复的话直接使用DISTINCT去重

2 如果是主键id不同，只是记录中的某几个数据相同时，我们就需要采用分组统计来实现去重的操作

![](https://i-blog.csdnimg.cn/blog_migrate/9215c7e1eeea37d753973343d4c2a09b.png)

上图中sid为主键

我们发现造成重复的是后面name,sex,class三列。

于是我们就用分组函数以这三列作为分组的条件

SELECT max(sid),name,sex,class FROM studentWHERE 1=1  GROUP BY name,sex,class 于是乎得到如下结果集

![](https://i-blog.csdnimg.cn/blog_migrate/533c790ad2e514ceb0e8cc63d96e202c.png)

**Oracle

数据库的去重与查询指定区间的记录数**

1、       查询前N条记录（ROWNUM<=100）

select * FROM HVDN WhereROWNUM<=100

2、       查询指定的记录数（1000-1050）条记录数

思路：首先查询表中前1050条记录，并显示出与之对应的行数，和信息数（注意：表一定要取别名，并用h.*来去表中的信息）

SELECT * from (SELECT rownum as num,h.* FROM HVDN h Where ROWNUM<=1050)  ss

where ss.num>1000 and ss.num<=1050

去重的方法所有数据库基本相同，找出重复的列在根据这些列（用GROUP BY函数）分组。

可能不一定是最好的方法，但是基本可实现，如有更好的方法请加以指正。