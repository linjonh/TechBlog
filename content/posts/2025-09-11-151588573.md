---
layout: post
title: "You-Only-Look-Once"
date: 2025-09-11T21:05:10+0800
description: "相比传统方法，YOLO 以“端到端”的方式一次性预测所有物体的位置和类别，速度非常快，因此被广泛用于自动驾驶、监控、机器人视觉等场景。是的，YOLOv5 提供了官方的 Docker 镜像，您可以轻松地在 Docker 容器中运行 YOLOv5，包括。好的，我们先确认你的摄像头在本地（宿主机）能正常工作，而不涉及 Docker。：为了持久化训练结果和模型，建议将容器的输出目录挂载到本地磁盘。，现在在容器内可以直接运行 YOLOv5 的训练和推理脚本。：如果您的系统支持 GPU，可以在运行容器时添加。"
keywords: "You Only Look Once"
categories: ['未分类']
tags: ['Python']
artid: "151588573"
arturl: "https://blog.csdn.net/is0815/article/details/151588573"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=151588573
    alt: "You-Only-Look-Once"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=151588573
featuredImagePreview: https://bing.ee123.net/img/rand?artid=151588573
cover: https://bing.ee123.net/img/rand?artid=151588573
image: https://bing.ee123.net/img/rand?artid=151588573
img: https://bing.ee123.net/img/rand?artid=151588573
---



# You Only Look Once

### YOLO 也是一种著名的 目标检测算法（You Only Look Once）。

它能在一张图片或一段视频中快速、准确地识别并定位出多个目标物体。

相比传统方法，YOLO 以“端到端”的方式一次性预测所有物体的位置和类别，速度非常快，因此被广泛用于自动驾驶、监控、机器人视觉等场景

高度流行、社区活跃版本

| 版本 | 流行程度 | 原因/说明 |
| --- | --- | --- |
| **YOLOv5** | ⭐⭐⭐⭐⭐ | PyTorch 实现，易用、易部署，工业界和科研都广泛使用 |
| **YOLOv8** | ⭐⭐⭐⭐⭐ | 高精度、高速度，支持多平台部署，文档完善，社区活跃 |
| **YOLOv7** | ⭐⭐⭐⭐ | 高帧率、适合视频监控，科研和工业应用广泛 |

### Linux 部署

可以把 **快速部署 YOLO** 理解成几个简单步骤：安装环境 → 获取模型 → 推理 → 可选加速。下面我整理了一个实用入门指南。

---

#### **1️⃣ 安装环境**

```bash
# 克隆 YOLO 仓库
git clone https://github.com/ultralytics/yolov5.git
cd yolov5

# 安装依赖
pip install -U pip
pip install -r requirements.txt

```

> 包含 PyTorch、OpenCV 等必要依赖。

---

#### **2️⃣ 下载预训练模型**

YOLO 提供多种预训练模型：

| 模型 | 特点 |
| --- | --- |
| yolov5s | 小型，速度快 |
| yolov5m | 中型，精度中等 |
| yolov5l | 大型，精度较高 |
| yolov5x | 超大，精度最高 |

示例下载 yolov5s：

```bash
wget https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt

```

---

#### **3️⃣ 推理使用**

使用 Python 脚本即可快速运行：

```python
import torch

# 加载模型
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)

# 推理单张图片
img = 'data/images/bus.jpg'
results = model(img)

# 显示结果
results.show()

# 保存检测结果
results.save('runs/detect/')

```

> `results.render()` 返回带框的图像，可用于自定义显示。

---

#### **4️⃣ 视频/摄像头实时检测**

```python
import cv2

cap = cv2.VideoCapture(0)  # 打开摄像头
while True:
    ret, frame = cap.read()
    if not ret:
        break
    results = model(frame)
    cv2.imshow('YOLOv5 Detection', results.render()[0])
    if cv2.waitKey(1) & 0xFF == 27:  # ESC退出
        break
cap.release()
cv2.destroyAllWindows()

```

---

#### **5️⃣ 可选：加速部署（ONNX/TensorRT）**

如果要在嵌入式或高性能平台部署：

```bash
# 导出 ONNX 模型
python export.py --weights yolov5s.pt --img 640 --batch 1 --device 0 --include onnx

```

> 然后可使用 TensorRT、OpenVINO 等工具加速推理。

---

#### **6️⃣ 总结流程**

1. 安装环境 → PyTorch + YOLOv5
2. 下载预训练模型
3. 运行 Python 脚本推理
4. （可选）部署到摄像头/视频
5. （可选）导出 ONNX/TensorRT 提升速度

---

✅ **小贴士**：

* 先安装linux navida 显卡驱动
* 测试和学习用 `yolov5s` 就够了，轻量快速。
* 工业部署或高精度需求可以用 `yolov5l` 或 `yolov5x`。

---

### docker 部署

是的，YOLOv5 提供了官方的 Docker 镜像，您可以轻松地在 Docker 容器中运行 YOLOv5，包括 `yolov5s` 模型。

---

#### 🧱 官方 Docker 镜像

Ultralytics 官方提供的 YOLOv5 Docker 镜像地址为：

* Docker Hub 页面：[ultralytics/yolov5](https://hub.docker.com/r/ultralytics/yolov5)
* GitHub Wiki 快速入门指南：[Docker Quickstart](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart)

---

#### 🚀 快速部署步骤

#### 1. 拉取 Docker 镜像

在终端中运行以下命令：

```bash
docker pull ultralytics/yolov5:latest

```

这将下载最新版本的 YOLOv5 镜像。

#### 2. 运行 Docker 容器

启动一个交互式容器：

```bash
docker run --ipc=host -it ultralytics/yolov5:latest

```

如果需要访问本地数据集，可以使用以下命令：

```bash
docker run --ipc=host -it -v "$(pwd)"/datasets:/usr/src/datasets ultralytics/yolov5:latest

```

这将把当前目录下的 `datasets` 文件夹挂载到容器内的 `/usr/src/datasets` 路径。

#### 3. 使用 YOLOv5

在容器中，您可以执行以下命令来使用 YOLOv5：

* 训练模型：

```bash
  python train.py

```

* 验证模型：

```bash
  python val.py --weights yolov5s.pt

```

* 进行推理：

```bash
  python detect.py --weights yolov5s.pt --source path/to/images

```

* 导出模型：

```bash
  python export.py --weights yolov5s.pt --include onnx coreml tflite

```

---

#### 💡 小贴士

* **GPU 加速**：如果您的系统支持 GPU，可以在运行容器时添加 `--gpus all` 参数，以启用 GPU 加速。
* **挂载本地目录**：使用 `-v` 参数将本地目录挂载到容器内，方便访问数据集和保存结果。
* **持久化数据**：为了持久化训练结果和模型，建议将容器的输出目录挂载到本地磁盘。

---

你现在 **系统里还没有安装 NVIDIA 驱动**，所以 `nvidia-smi` 找不到命令，也无法在 Docker 中使用 GPU。你需要先安装 NVIDIA 驱动，然后再配置 Docker GPU 支持。

下面给你一个 **Ubuntu 系统安装流程**（假设你用的是 Ubuntu 22.04/24.04）：

---

### **1️⃣ 安装 NVIDIA 驱动**

#### 推荐安装最新稳定版（535 系列）：

```bash
sudo apt update
sudo apt install nvidia-utils-535 nvidia-driver-535

```

> `nvidia-driver-535` 会安装对应驱动，`nvidia-utils-535` 提供 `nvidia-smi` 工具。

#### 安装完成后重启系统：

```bash
sudo reboot

```

---

#### **2️⃣ 验证 NVIDIA 驱动**

重启后，检查 GPU 是否可用：

```bash
nvidia-smi

```

* 如果显示 GPU 信息和驱动版本，说明安装成功
* 如果报错，需要确认显卡型号和驱动匹配

---

#### **3️⃣ 安装 NVIDIA Container Toolkit**

Docker 才能在容器中访问 GPU：

```bash
# 添加 NVIDIA Docker 仓库
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt-get update

# 安装 nvidia-docker2
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker

```

---

#### **4️⃣ 测试 Docker GPU**

```bash
sudo docker run --rm --gpus all nvidia/cuda:12.1-base nvidia-smi

```

* 输出 GPU 信息表示配置成功

---

#### **5️⃣ 运行 YOLOv5 Docker**

```bash
sudo docker run --ipc=host -it --gpus all ultralytics/yolov5:latest

```

> 现在容器里就可以使用 GPU 了。

---

✅ **总结**

* 你目前没有安装 NVIDIA 驱动，需要先安装驱动和 utils
* 安装完成后，再安装 NVIDIA Docker 支持
* 最后就可以在 Docker 容器里用 YOLOv5 GPU 运行

---

### 

太好了，你已经成功进入了 **YOLOv5 Docker 容器**，现在在容器内可以直接运行 YOLOv5 的训练和推理脚本。

---

### 🔹 容器内常用命令示例

#### 1️⃣ 测试推理（检测图片）

```bash
python detect.py --weights yolov5s.pt --source data/images/bus.jpg

```

* `--weights yolov5s.pt`：使用预训练模型
* `--source`：输入图片/视频路径
* 输出结果默认保存在 `runs/detect/exp`

---

#### 2️⃣ 查看推理结果

```bash
ls runs/detect/exp

```

* 可以看到带检测框的图片

---

#### 3️⃣ 使用本地数据集（挂载卷）

如果你想用宿主机的数据集：

```bash
exit  # 先退出容器
sudo docker run --ipc=host -it -v /home/link/datasets:/usr/src/app/datasets ultralytics/yolov5:latest

```

* `/home/link/datasets`：宿主机数据集路径
* `/usr/src/app/datasets`：容器内访问路径

然后在容器内：

```bash
python detect.py --weights yolov5s.pt --source datasets/my_image.jpg

```

---

#### 4️⃣ 训练模型（CPU 上）

```bash
python train.py --img 640 --batch 4 --epochs 10 --data coco128.yaml --weights yolov5s.pt

```

* `--batch 4`：CPU 上批量不能太大，否则内存吃满
* `--img 640`：输入图片大小
* `--epochs 10`：训练轮数

> 注意：CPU 上训练大模型很慢，建议只测试小模型 `yolov5s` 或做少量 epoch 测试

---

#### 5️⃣ 导出模型

```bash
python export.py --weights yolov5s.pt --include onnx

```

* 可将 PyTorch 模型导出为 ONNX，便于部署

---

#### 🔹 小贴士

* 你现在是 root 用户，在容器内对文件操作很方便
* CPU 上训练速度慢，推理可以正常使用
* 建议先做 **小数据集或预训练模型推理** 测试

---

### 使用摄像头

好的，我们先确认你的摄像头在本地（宿主机）能正常工作，而不涉及 Docker。下面我给你几个方法：

---

#### 1. 使用 `ls /dev/video*` 查看摄像头设备

在终端输入：

```bash
ls /dev/video*

```

* 输出类似 `/dev/video0` 表示系统识别到一个摄像头。
* 如果有多个摄像头，可能会有 `/dev/video1`、`/dev/video2`。

---

#### 2. 使用 `cheese` 查看摄像头

`cheese` 是 Linux 下的摄像头预览工具。

```bash
sudo apt update
sudo apt install cheese -y
cheese

```

* 打开后就能看到摄像头画面。
* 如果能看到画面，说明摄像头正常工作。

---

#### 3. 使用 OpenCV 测试摄像头

如果你想用 Python 简单测试：

```python
import cv2

cap = cv2.VideoCapture(0)  # 0 表示第一个摄像头

if not cap.isOpened():
    print("无法打开摄像头")
    exit()

while True:
    ret, frame = cap.read()
    if not ret:
        print("无法读取视频帧")
        break

    cv2.imshow('Camera Test', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

```

* 运行后会弹出窗口显示摄像头画面。
* 按 `q` 退出。

---

直接在 Docker 里用 YOLOv5 进行实时摄像头检测了。

下面是一个完整示例命令（保证摄像头、共享内存和结果挂载都正常）：

```bash
sudo docker run --ipc=host -it \
--device=/dev/video0:/dev/video0 \
-v /home/link/yolov5_results:/usr/src/app/runs/detect \
ultralytics/yolov5:latest \
python detect.py --source 0 --weights yolov5s.pt --conf 0.25

```

#### 参数说明：

* `--ipc=host` → 共享内存，提高 PyTorch 性能，避免内存不足报错
* `--device=/dev/video0:/dev/video0` → 容器可以访问宿主机摄像头
* `-v ~/yolov5_results:/usr/src/app/runs/detect` → 挂载结果目录
* `--source 0` → 使用默认摄像头
* `--weights yolov5s.pt` → 使用轻量级模型（检测速度快）
* `--conf 0.25` → 置信度阈值

---

运行后：

* 会弹出摄像头实时检测窗口
* 检测结果会保存在 `~/yolov5_results`

---



