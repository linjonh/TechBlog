---
arturl_encode: "68747470:733a2f2f626c6f672e6373646e2e6e65742f6379687973722f:61727469636c652f64657461696c732f313436323535303536"
layout: post
title: "大数据-spark3.5安装部署之local模式"
date: 2025-03-14 13:20:17 +0800
description: "spark，一个数据处理框架和计算引擎。local模式即本地模式，就是不需要任何其他节点资源就可以在本地执行spark代码的环境。用于练习演示。"
keywords: "大数据-spark3.5安装部署之local模式"
categories: ['未分类']
tags: ['大数据']
artid: "146255056"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146255056
    alt: "大数据-spark3.5安装部署之local模式"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146255056
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146255056
cover: https://bing.ee123.net/img/rand?artid=146255056
image: https://bing.ee123.net/img/rand?artid=146255056
img: https://bing.ee123.net/img/rand?artid=146255056
---

# 大数据-spark3.5安装部署之local模式

spark，一个数据处理框架和计算引擎。

下载

![](https://i-blog.csdnimg.cn/direct/b6108f6cd3494c06a2e201eaa24d1860.png)

![](https://i-blog.csdnimg.cn/direct/45eea3aa53e34baa917bd633dc84bf17.png)

local模式即本地模式，就是不需要任何其他节点资源就可以在本地执行spark代码的环境。用于练习演示。

## 上传解压

使用PortX将文件上传至/opt

![](https://i-blog.csdnimg.cn/direct/3bd59492502f4bb68c6cb534ffb6b00d.png)

进入/opt目录，创建目录module，解压文件至/opt/module

![](https://i-blog.csdnimg.cn/direct/d680ae3912bc4c66a7778794d5a8c6b2.png)

进入module，并修改名称

![](https://i-blog.csdnimg.cn/direct/77c5ca3cd1924b19b631b53574e25790.png)

## **配置jdk**

启动spark前要安装jdk，上传jdk文件

![](https://i-blog.csdnimg.cn/direct/f5cc599b9d934fa289854f75828de375.png)

解压

tar zxvf jdk-8u271-linux-x64.tar.gz

![](https://i-blog.csdnimg.cn/direct/e04691403b2b4691810b661ddcebadd8.png)

配置环境变量

以root用户配置环境变量

cd ~

![](https://i-blog.csdnimg.cn/direct/8d7883f8dfb248c7a83067e3c666a0db.png)

![](https://i-blog.csdnimg.cn/direct/8814997130124345943372718cc165f3.png)

保存后，以root用户，执行source .profle，使更改生效，并验证。

![](https://i-blog.csdnimg.cn/direct/f5ba8aa0fb1546b7be44d282d921837d.png)

## **启动查看**

进入spark-local，执行命令bin/spark-shell 启动spark，如下所示则成功启动

![](https://i-blog.csdnimg.cn/direct/20b2ab1357fb4480af23ebb64142865c.png)

启动成功后，可以通过浏览器访问WebUI监控页面

http://ip:4040

![](https://i-blog.csdnimg.cn/direct/d76c5e85b93e4a1c92b35e73c7fa37e6.png)

## 交互操作

使用命令行或者提交作业的方式，与spark进行交互。

### 命令行

进入spark目录中的data文件夹，添加test.txt文件

![](https://i-blog.csdnimg.cn/direct/c7d540bee239423a964ad3f8b3bfcb66.png)

vi test.txt

![](https://i-blog.csdnimg.cn/direct/69a9c7ff4d61401aacb0f7bedc71f470.png)

进入spark-standalone/bin目录，执行./spark-shell，启动命令行，执行以下内容

sc.textFile("../data/test.txt").flatMap(\_.split(" ")).map((\_,1)).reduceByKey(\_+\_).collect

![](https://i-blog.csdnimg.cn/direct/ee649bd1c8cf45d28a6859028fc60731.png)

退出Ctrl+c或者输入:quit后回车

### **提交应用**

对于公司大数据的批量处理或周期性数据分析/处理任务，通常采用编写好的Spark程序，并通过Spark-submit指令的方式提交给Spark集群进行具体的任务计算。

bin/spark-submit \

--class org.apache.spark.examples.SparkPi \

--master local[2] \

./examples/jars/spark-examples\_2.12-3.5.5.jar \

10

![](https://i-blog.csdnimg.cn/direct/878ad64fa81f4a15a0bb33e8a320d5cd.png)

![](https://i-blog.csdnimg.cn/direct/805e37b980f94693be40dd132e78038d.png)

![](https://i-blog.csdnimg.cn/direct/4a110d73b9284abea974bfb3726a2c86.png)

备注：路径等信息如下，示例代码都位于spark目录中。

![](https://i-blog.csdnimg.cn/direct/ceaeacd2805d42dca5673834c224a62f.png)