---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34323435313235312f:61727469636c652f64657461696c732f313035323135313339"
layout: post
title: "大数据hadoop学习4-通过JAVA-程序对Hadoop文件系统HDFS进行相应操作判断文件是否存在写入文本文件上传本次文件到HDFS读取HDFS文件内容"
date: 2022-10-09 17:38:45 +08:00
description: "大数据hadoop学习【4】-----利用JAVA API对Hadoo"
keywords: "java上传文件到hdfs代码运行结果"
categories: ['大数据基础Hadoop']
tags: ['Linux', 'Java', 'Hdfs', 'Hadoop']
artid: "105215139"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=105215139
    alt: "大数据hadoop学习4-通过JAVA-程序对Hadoop文件系统HDFS进行相应操作判断文件是否存在写入文本文件上传本次文件到HDFS读取HDFS文件内容"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=105215139
featuredImagePreview: https://bing.ee123.net/img/rand?artid=105215139
---

# 大数据hadoop学习【4】-----通过JAVA 程序对Hadoop文件系统HDFS进行相应操作(判断文件是否存在、写入文本文件、上传本次文件到HDFS、读取HDFS文件内容)

#### 大数据hadoop学习【4】-----利用JAVA API对Hadoop文件系统HDFS进行相应操作目录

* [一、运行Hadoop,并建立eclipse相应java工程项目](#Hadoopeclipsejava_3)
* + [1、运行Hadoop](#1Hadoop_4)
  + [2、建立eclipse项目](#2eclipse_19)
* [二、编写java程序判定文件是否存在](#java_23)
* + [1、在创建的java项目中新建java类](#1javajava_24)
  + [2、编写判定文件是否存在的java程序](#2java_27)
  + [3、运行结果](#3_55)
* [三、编写java程序将Linux本地文件上传到HDFS文件系统](#javaLinuxHDFS_65)
* + [1、准备好相应的Linux本地文件](#1Linux_66)
  + [2、编写相应的java代码](#2java_72)
  + [3、运行结果如下](#3_99)
  + [4、通过相应HDFS文件操作命令，查看本地文件是否上传成功](#4HDFS_102)
* [四、编写java程序将文本文件写入HDFS文件](#javaHDFS_115)
* + [1、编写完成功能的java程序代码](#1java_116)
  + [2、程序的运行结果](#2_145)
  + [3、通过相应HDFS文件操作命令，查看文件是否写入成功](#3HDFS_148)
* [五、编写java程序读取HDFS文本文件内容](#javaHDFS_161)
* + [1、在HDFS文件系统中准备对应的文本文件](#1HDFS_162)
  + [2、编写对应功能的java程序](#2java_179)
  + [3、程序运行结果如下](#3_209)

  
**在进行hadoop学习时，首先需要对HDFS文件系统有一定的理解，其次，我们需要对HDFS文件系统进行操作，这和linux文件操作是类似的，只不过在不同的架构上面，HDFS是hadoop的专用文件系统，用来存储hadoop的相应文件，与本地文件进行区分！
  
本次博客，林君学长主要带大家了解如何利用java程序对hadoop上面的HDFS进行相应的操作，已达到我们需要的对应目的**

## 一、运行Hadoop,并建立eclipse相应java工程项目

### 1、运行Hadoop

1)、在本地用户上面切换为hadoop用户

```bash
su - hadoop

```

2）、进入hadoop运行环境

```bash
cd /usr/local/hadoop

```

3)、运行hadoop

```bash
./sbin/start-dfs.sh
jps

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/41d93a52ce4e5fbc9c2031d5fd427487.png)

### 2、建立eclipse项目

1）、打开eclipse，进行项目包的创建
  

file->New->java project
  
之前创建好的，可以用之前的java项目包哦！

## 二、编写java程序判定文件是否存在

### 1、在创建的java项目中新建java类

在项目中右击->New->class
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/d99979c800056c96408f6a666d973252.png)

### 2、编写判定文件是否存在的java程序

1）、判断文件是否存在的java程序如下：

```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
public class Hdfs {
	public static void main(String[] args){
        try{
            String fileName = "test";
            Configuration conf = new Configuration();
            conf.set("fs.defaultFS", "hdfs://localhost:9000");
            conf.set("fs.hdfs.impl", "org.apache.hadoop.hdfs.DistributedFileSystem");
            FileSystem fs = FileSystem.get(conf);
            if(fs.exists(new Path(fileName))){
                System.out.println("文件存在");
            }else{
                System.out.println("文件不存在");
            }
 
        }catch (Exception e){
            e.printStackTrace();
        }
    }
}

```

上面可以看，我们判断的文件名为
test
,在本地是不存在的，所以运行结果肯定是文件不存在！
  
**请注意修改自己的类名！**

### 3、运行结果

1）、原来代码的运行结果如下所示：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/dcb38cda29f3bc0867b64f45a946b033.png)
  
2）、修改文件名，将HDFS中已经有的文件写入，判断文件是否存在
  
1.将路径修改如下：

```java
String fileName = "/user/hadoop/input/my.txt";

```

2.运行结果如下所示：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/5c8217421d5c677234baee3dc17c6c73.png)

## 三、编写java程序将Linux本地文件上传到HDFS文件系统

### 1、准备好相应的Linux本地文件

1）、林君学长自己的本地文件如下所示：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/1d2b2c2df1fa542f94a8e94d6b98cb81.png)
  
2）、文件内容如下所示：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/104d21f110ae43f65e3d29f4fabd5463.png)

### 2、编写相应的java代码

1）、将Linux本地文件上传到HDFS文件系统的java程序如下所示：

```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
public class LinuxToHdfs {
	public static void main(String[] args) {
        Configuration conf = new Configuration();
        conf.set("fs.defaultFS", "hdfs://localhost:9000");
        conf.set("fs.hdfs.impl", "org.apache.hadoop.hdfs.DistributedFileSystem");
        String localDir = "/home/chenlin/lenovo/hadoopTest.txt";//本地路径
        String hdfsDir = "/user/hadoop/input/";//HDFS文件路径
        try{
            Path localPath = new Path(localDir);
            Path hdfsPath = new Path(hdfsDir);
            FileSystem hdfs = FileSystem.get(conf);
            hdfs.copyFromLocalFile(localPath,hdfsPath);
            System.out.println("上传成功");
        }catch(Exception e){
            e.printStackTrace();
        }
    }
}

```

> 该程序的功能是：将本地路径
> home/chenlin/lenovo/hadoopTest.txt
> 的文件上传到HDFS中路径为/user/hadoop/input/的目录下面

### 3、运行结果如下

1）、程序的运行结果：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/b6ed8cadf0c64fc52a44e8131324cafe.png)

### 4、通过相应HDFS文件操作命令，查看本地文件是否上传成功

1)、用ls命令查看是否上传到hdfs文件系统中去

```bash
./bin/hdfs dfs -ls /user/hadoop/input

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/8deb5ed74017901e6ac80a8527ee45c2.png)
  
可以看到，该文件内容已经上传到我们的HDFS文件系统中去了！
  
2)、用cat命令查看文件内容，是否与我们本地ubuntu系统下的文件内容一样

```bash
 ./bin/hdfs dfs -cat /user/hadoop/input/hadoopTest.txt

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/4bba92e2b83ea29320a3520a9ed0fb40.png)
  
可以看到，文件内容和本地文件内容完全一样！

## 四、编写java程序将文本文件写入HDFS文件

### 1、编写完成功能的java程序代码

1）、将文本写入HDFS文件的java代码如下所示：

```java
import org.apache.hadoop.conf.Configuration;  
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.Path;
public class InputFile {
	public static void main(String[] args) { 
		try {
                Configuration conf = new Configuration();  
                conf.set("fs.defaultFS","hdfs://localhost:9000");
                conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
                FileSystem fs = FileSystem.get(conf);
                byte[] buff = "this is my first hadoop test".getBytes(); // 要写入的内容
                String filename = "/user/hadoop/input/test.txt"; //要写入的文件名
                FSDataOutputStream os = fs.create(new Path(filename));
                os.write(buff,0,buff.length);
                System.out.println("Create:"+ filename);
                os.close();
                fs.close();
        } catch (Exception e) {  
                e.printStackTrace();  
        }  
   }  
}

```

> 上面程序的功能是将文本文件test.txt，写入HDFS文件系统中的input目录下面

### 2、程序的运行结果

1）、该java程序的运行结果如下所示：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/9eccc82fe569ef4c4710588afd6b7bae.png)

### 3、通过相应HDFS文件操作命令，查看文件是否写入成功

1）、通过ls命令，在input中查看是否有该文件，如下所示：

```bash
./bin/hdfs dfs -ls /user/hadoop/input

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/dc28f2c37a98673d657c5cd8d6be49c1.png)
  
可以看到，文本文件已经创建了
  
2）、通过cat命名查看我们的test.txt文件内容，如下所示：

```bash
./bin/hdfs dfs -cat /user/hadoop/input/test.txt

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/b29d1c44725eb2168b9555837e7343d6.png)
  
可以看到，我们需要写入的内容已经写入我们的文件里面了，那么我们写入文件到HDFS文件系统中的程序就实现了哦！

## 五、编写java程序读取HDFS文本文件内容

### 1、在HDFS文件系统中准备对应的文本文件

1）、在最开始打开的终端创建
test.txt
文件

```bash
touch test.txt

```

2)、打开test.txt文件

```bash
gedit test.txt

```

3）、文件内容如下所示：

```java
this is my first hadoop tset

```

3)、将本地文件上传到HDFS文件系统中的input目录：

```bash
./bin/hdfs dfs -put ./test.txt  /user/hadoop/input

```

### 2、编写对应功能的java程序

1）、读取HDFS文本文件内容的java程序代码如下所示：

```java
import java.io.BufferedReader;
import java.io.InputStreamReader;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.FSDataInputStream;
public class OutFile {
	public static void main(String[] args) {
        try {
                Configuration conf = new Configuration();
                conf.set("fs.defaultFS","hdfs://localhost:9000");                      
				conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
                FileSystem fs = FileSystem.get(conf);
                Path file = new Path("/user/hadoop/input/test.txt"); 
                FSDataInputStream getIt = fs.open(file);
                BufferedReader d = new BufferedReader(new InputStreamReader(getIt));
                String content = d.readLine(); //读取文件一行
                System.out.println(content);
                d.close(); //关闭文件
                fs.close(); //关闭hdfs
        } catch (Exception e) {
                e.printStackTrace();
        }
    }
}

```

> 该程序是读取HDFS文件中路径为
> /user/hadoop/input/test.txt
> 的文件内容！

### 3、程序运行结果如下

1）、该java程序的运行结果如下所示：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/6efb5396dc60dc87168ebc11162dee05.png)
  
由上面可以看出，我们的文件内容已经从HDFS文件系统中读取出来了，与我们tset.txt的文件内容一模一样，程序功能完美实现啦！
  
**以上就是本次博客的全部内容，对本次博客的阅读，希望对大家可以理解如何通过java程序实现对HDFS文件系统的相应操作哦！遇到问题的小伙伴请在评论区留言，林君学长看到了会给大家解答的，这个学长不太冷！**
  
*陈一月的又一天编程岁月^ \_ ^*