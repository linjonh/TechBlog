---
layout: post
title: "Python爬虫从人民网提取视频链接的完整指南"
date: 2025-03-12 16:30:50 +0800
description: "网络爬虫（Web Crawler）是一种自动化的程序，用于在互联网上浏览网页并收集信息。它通过模拟浏览器的行为，发送HTTP请求，获取网页内容，然后解析HTML代码以提取所需数据。Python因其强大的库支持和简洁的语法，成为实现网络爬虫的首选语言之一。在本文中，我们将使用Python的urllib库和库来完成爬虫的开发。本文通过一个实际案例，详细介绍了如何使用Python构建一个从人民网提取视频链接的爬虫程序。我们从基础的网络请求到HTML解析，再到最终提取视频链接，逐步实现了整个爬虫的开发过程。"
keywords: "素材链接提取"
categories: ['Python']
tags: ['音视频', '爬虫', '开发语言', '大数据', 'Python']
artid: "146208625"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146208625
    alt: "Python爬虫从人民网提取视频链接的完整指南"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146208625
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146208625
cover: https://bing.ee123.net/img/rand?artid=146208625
image: https://bing.ee123.net/img/rand?artid=146208625
img: https://bing.ee123.net/img/rand?artid=146208625
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Python爬虫：从人民网提取视频链接的完整指南
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/img_convert/487a0577ee4ef91f68c66bdbfa5a3f8c.jpeg"/>
    </p>
    <p>
     无论是用于数据分析、内容提取还是资源收集，Python爬虫都因其高效性和易用性而备受开发者青睐。本文将通过一个实际案例——从人民网提取视频链接，详细介绍如何使用Python构建一个完整的爬虫程序。我们将涵盖从基础的网络请求到HTML解析，再到最终提取视频链接的全过程。
    </p>
    <h3>
     <a id="_4">
     </a>
     一、爬虫技术概述
    </h3>
    <p>
     网络爬虫（Web Crawler）是一种自动化的程序，用于在互联网上浏览网页并收集信息。它通过模拟浏览器的行为，发送HTTP请求，获取网页内容，然后解析HTML代码以提取所需数据。Python因其强大的库支持和简洁的语法，成为实现网络爬虫的首选语言之一。在本文中，我们将使用Python的
     <code>
      urllib
     </code>
     库和
     <code>
      BeautifulSoup
     </code>
     库来完成爬虫的开发。
    </p>
    <h3>
     <a id="_7">
     </a>
     二、开发环境准备
    </h3>
    <p>
     在开始编写爬虫之前，需要确保你的开发环境已经安装了以下必要的库：
    </p>
    <ol>
     <li>
      Python：推荐使用Python 3.8及以上版本。
     </li>
     <li>
      urllib：Python内置的网络请求库。
     </li>
     <li>
      BeautifulSoup：用于解析HTML和XML文档的库。
     </li>
    </ol>
    <h3>
     <a id="_14">
     </a>
     三、目标网站分析
    </h3>
    <p>
     本次爬虫的目标是人民网（
     <a href="http://www.people.com.xn--cn" rel="nofollow">
      http://www.people.com.cn），一个提供丰富新闻和多媒体内容的网站。我们的目标是从该网站的某个页面中提取视频链接。为了实现这一目标，我们需要分析页面的HTML结构，找到视频标签所在的区域。
     </a>
     ,-o84fuiob11pqsg7ms1j1voxtec0e8hn68iixgz25fbhrynu8y2i.xn–ciqg59bxdo7yn0x7qc1j35pgxehra140lda49l705a7mrq35b97hu68bu8j8tf0ra.xn–,html,-9m7inp7v45at3wtoar5inwtqscbyx8v0aoyav9a248dchav0hna8372em1ola75z484cvguhh7eq0bf31gtlzckzc88mf3a./)
    </p>
    <h4>
     <a id="1_HTML_17">
     </a>
     1. 分析HTML结构
    </h4>
    <p>
     在开始编写爬虫之前，首先需要了解目标页面的HTML结构。打开目标页面，右键点击页面中的视频元素，选择“检查”（Inspect），查看视频标签的HTML代码。通常，视频链接会被包含在
     <code>
      &lt;video&gt;
     </code>
     标签或
     <code>
      &lt;source&gt;
     </code>
     标签中，类似于以下结构：
    </p>
    <p>
     HTML复制
    </p>
    <pre><code class="prism language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>video</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>source</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://example.com/video.mp4<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>video/mp4<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>video</span><span class="token punctuation">&gt;</span></span>
</code></pre>
    <p>
     预览
    </p>
    <h4>
     <a id="2_URL_30">
     </a>
     2. 确定目标URL
    </h4>
    <p>
     为了简化示例，我们假设目标页面的URL为
     <code>
      http://www.people.com.cn/somepage.html
     </code>
     。在实际应用中，你需要根据具体需求替换为正确的页面地址。
    </p>
    <h3>
     <a id="_33">
     </a>
     四、爬虫实现步骤
    </h3>
    <h4>
     <a id="1__34">
     </a>
     1. 发起网络请求
    </h4>
    <p>
     使用
     <code>
      urllib.request
     </code>
     库发起网络请求，获取目标页面的HTML内容。以下是实现代码：
    </p>
    <p>
     Python复制
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> urllib<span class="token punctuation">.</span>request

<span class="token keyword">def</span> <span class="token function">fetch_html</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        <span class="token comment"># 发起网络请求</span>
        response <span class="token operator">=</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>urlopen<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
        <span class="token comment"># 读取响应内容</span>
        html_content <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> html_content
    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"请求失败：</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>e<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token comment"># 示例URL</span>
url <span class="token operator">=</span> <span class="token string">"http://www.people.com.cn/somepage.html"</span>
html_content <span class="token operator">=</span> fetch_html<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
<span class="token keyword">if</span> html_content<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"HTML内容获取成功！"</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="2_HTML_60">
     </a>
     2. 解析HTML内容
    </h4>
    <p>
     获取到HTML内容后，接下来需要解析页面结构，提取视频链接。我们将使用
     <code>
      BeautifulSoup
     </code>
     库来完成这一任务。以下是解析HTML并提取视频链接的代码：
    </p>
    <p>
     Python复制
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

<span class="token keyword">def</span> <span class="token function">extract_video_links</span><span class="token punctuation">(</span>html_content<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 创建BeautifulSoup对象</span>
    soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>html_content<span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span>
    <span class="token comment"># 查找所有的&lt;video&gt;标签</span>
    videos <span class="token operator">=</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token string">'video'</span><span class="token punctuation">)</span>
    video_links <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token comment"># 遍历&lt;video&gt;标签，提取视频链接</span>
    <span class="token keyword">for</span> video <span class="token keyword">in</span> videos<span class="token punctuation">:</span>
        video_url <span class="token operator">=</span> video<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'source'</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">'type'</span><span class="token punctuation">:</span> <span class="token string">'video/mp4'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> video_url<span class="token punctuation">:</span>
            video_links<span class="token punctuation">.</span>append<span class="token punctuation">(</span>video_url<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'src'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> video_links

<span class="token comment"># 提取视频链接</span>
video_links <span class="token operator">=</span> extract_video_links<span class="token punctuation">(</span>html_content<span class="token punctuation">)</span>
<span class="token keyword">if</span> video_links<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"提取到的视频链接："</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> link <span class="token keyword">in</span> video_links<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>link<span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"未找到视频链接。"</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="3__93">
     </a>
     3. 处理代理服务器
    </h4>
    <p>
     在实际应用中，目标网站可能会限制爬虫的访问频率或IP地址。为了绕过这些限制，可以使用代理服务器。以下是配置代理服务器的代码示例：
    </p>
    <p>
     Python复制
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> urllib<span class="token punctuation">.</span>request

<span class="token keyword">def</span> <span class="token function">fetch_html_with_proxy</span><span class="token punctuation">(</span>url<span class="token punctuation">,</span> proxy_host<span class="token punctuation">,</span> proxy_port<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 创建代理处理器</span>
    proxy_handler <span class="token operator">=</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>ProxyHandler<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span>
        <span class="token string">'http'</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f'http://</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>proxy_host<span class="token punctuation">}</span></span><span class="token string">:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>proxy_port<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span>
        <span class="token string">'https'</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f'https://</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>proxy_host<span class="token punctuation">}</span></span><span class="token string">:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>proxy_port<span class="token punctuation">}</span></span><span class="token string">'</span></span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token comment"># 创建开启器</span>
    opener <span class="token operator">=</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>build_opener<span class="token punctuation">(</span>proxy_handler<span class="token punctuation">)</span>
    <span class="token comment"># 使用开启器发起请求</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        response <span class="token operator">=</span> opener<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span>
        html_content <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> html_content
    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"请求失败：</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>e<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token comment"># 示例代理服务器</span>
proxy_host <span class="token operator">=</span> <span class="token string">"ip.16yun.cn"</span>
proxy_port <span class="token operator">=</span> <span class="token number">31111</span>

<span class="token comment"># 使用代理服务器获取HTML内容</span>
html_content <span class="token operator">=</span> fetch_html_with_proxy<span class="token punctuation">(</span>url<span class="token punctuation">,</span> proxy_host<span class="token punctuation">,</span> proxy_port<span class="token punctuation">)</span>
<span class="token keyword">if</span> html_content<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"通过代理服务器获取HTML内容成功！"</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="4__128">
     </a>
     4. 完整代码实现
    </h4>
    <p>
     将上述代码片段整合后，完整的爬虫程序如下：
    </p>
    <p>
     Python复制
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> urllib<span class="token punctuation">.</span>request
<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

<span class="token keyword">def</span> <span class="token function">fetch_html_with_proxy</span><span class="token punctuation">(</span>url<span class="token punctuation">,</span> proxy_host<span class="token punctuation">,</span> proxy_port<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 创建代理处理器</span>
    proxy_handler <span class="token operator">=</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>ProxyHandler<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span>
        <span class="token string">'http'</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f'http://</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>proxy_host<span class="token punctuation">}</span></span><span class="token string">:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>proxy_port<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span>
        <span class="token string">'https'</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f'https://</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>proxy_host<span class="token punctuation">}</span></span><span class="token string">:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>proxy_port<span class="token punctuation">}</span></span><span class="token string">'</span></span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token comment"># 创建开启器</span>
    opener <span class="token operator">=</span> urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>build_opener<span class="token punctuation">(</span>proxy_handler<span class="token punctuation">)</span>
    <span class="token comment"># 使用开启器发起请求</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        response <span class="token operator">=</span> opener<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span>
        html_content <span class="token operator">=</span> response<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> html_content
    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"请求失败：</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>e<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token keyword">def</span> <span class="token function">extract_video_links</span><span class="token punctuation">(</span>html_content<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 创建BeautifulSoup对象</span>
    soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>html_content<span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span>
    <span class="token comment"># 查找所有的&lt;video&gt;标签</span>
    videos <span class="token operator">=</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token string">'video'</span><span class="token punctuation">)</span>
    video_links <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token comment"># 遍历&lt;video&gt;标签，提取视频链接</span>
    <span class="token keyword">for</span> video <span class="token keyword">in</span> videos<span class="token punctuation">:</span>
        video_url <span class="token operator">=</span> video<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'source'</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">'type'</span><span class="token punctuation">:</span> <span class="token string">'video/mp4'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> video_url<span class="token punctuation">:</span>
            video_links<span class="token punctuation">.</span>append<span class="token punctuation">(</span>video_url<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'src'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> video_links

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token comment"># 目标URL</span>
    url <span class="token operator">=</span> <span class="token string">"http://www.people.com.cn/somepage.html"</span>
    <span class="token comment"># 代理服务器配置</span>
    proxy_host <span class="token operator">=</span> <span class="token string">"ip.16yun.cn"</span>
    proxy_port <span class="token operator">=</span> <span class="token number">31111</span>

    <span class="token comment"># 获取HTML内容</span>
    html_content <span class="token operator">=</span> fetch_html_with_proxy<span class="token punctuation">(</span>url<span class="token punctuation">,</span> proxy_host<span class="token punctuation">,</span> proxy_port<span class="token punctuation">)</span>
    <span class="token keyword">if</span> html_content<span class="token punctuation">:</span>
        <span class="token comment"># 提取视频链接</span>
        video_links <span class="token operator">=</span> extract_video_links<span class="token punctuation">(</span>html_content<span class="token punctuation">)</span>
        <span class="token keyword">if</span> video_links<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"提取到的视频链接："</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> link <span class="token keyword">in</span> video_links<span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span>link<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"未找到视频链接。"</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"获取HTML内容失败。"</span><span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="_191">
     </a>
     五、注意事项
    </h3>
    <ol>
     <li>
      遵守法律法规：在使用爬虫技术时，必须遵守相关法律法规，尊重网站的版权和隐私政策。禁止爬取未经授权的内容。
     </li>
     <li>
      避免频繁请求：为了不给目标网站造成过大压力，建议合理控制爬虫的请求频率。可以通过设置延时（如
      <code>
       time.sleep()
      </code>
      ）来降低请求频率。
     </li>
     <li>
      处理异常情况：网络请求可能会因多种原因失败，如网络超时、目标页面不存在等。在代码中应妥善处理这些异常情况，确保程序的稳定性。
     </li>
     <li>
      动态页面处理：如果目标页面是通过JavaScript动态加载的，
      <code>
       urllib
      </code>
      和
      <code>
       BeautifulSoup
      </code>
      可能无法直接获取到完整的内容。此时可以考虑使用
      <code>
       Selenium
      </code>
      等工具来模拟浏览器行为。
     </li>
    </ol>
    <h3>
     <a id="_197">
     </a>
     六、总结
    </h3>
    <p>
     本文通过一个实际案例，详细介绍了如何使用Python构建一个从人民网提取视频链接的爬虫程序。我们从基础的网络请求到HTML解析，再到最终提取视频链接，逐步实现了整个爬虫的开发过程。通过使用
     <code>
      urllib
     </code>
     和
     <code>
      BeautifulSoup
     </code>
     库，我们可以高效地完成数据提取任务。同时，我们也介绍了如何配置代理服务器以应对可能的访问限制。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f5a5f7375676572372f:61727469636c652f64657461696c732f313436323038363235" class_="artid" style="display:none">
 </p>
</div>


