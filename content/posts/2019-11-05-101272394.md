---
arturl_encode: "68747470733a2f2f:626c6f672e6373646e2e6e65742f77616e673733353031392f:61727469636c652f64657461696c732f313031323732333934"
layout: post
title: "浅谈电商类目预测"
date: 2019-11-05 09:19:41 +08:00
description: "类目预测_类目预测能力"
keywords: "类目预测能力"
categories: ['自然语言处理', '深度学习']
tags: ['类目预测', '电商']
artid: "101272394"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=101272394
    alt: "浅谈电商类目预测"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=101272394
featuredImagePreview: https://bing.ee123.net/img/rand?artid=101272394
---

# 浅谈电商类目预测

总结一下过去一年时间内做的电商类目预测。

#### 电商类目体系

在电商场景下，商品会挂在不同的类别下，每个商品一般仅对应一个类别，例如商品“秋季新款韩版小清新短款亮片卫衣女高腰个性宽松百搭连帽长袖上衣”会挂在类目“卫衣”下。同时电商的类目体系是一个树结构，包含父节点和子节点等；
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/0b8a877ba33975d46e24f8bc10d02568.png)
  
蘑菇街类目体系：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/e04543e2598c71ef02c5cc9ad2f3c363.png)
  
结构体系类似，都是多级类目，叶子类目是商品所属的最小类目。

#### query类目预测

用户搜索时，需要根据用户的输入文本，预测用户意图。对应于电商搜索，用户输入文本后，首先要预测的就是文本与商品类目的关系，预测的结果将作用在后续多个模块，对整个用户的搜索结果影响较大。
  
要识别用户的输入意图，可以从多个方面切入；一方面是历史用户搜索点击行为，另一方面是文本本身的相关性。
  
电商搜索场景下，每个用户在发起一次搜索后，将经历多个阶段。首先是QR阶段(query rewrite)，可以理解为对query进行分析，分别有文本分词、文本纠错、丢词、品牌识别、同义词扩展、类目预测、同义query扩展等，将分析的结果转化为搜索引擎可以识别的语言——布尔语言(AND|OR|NOT)；第二步，因为电商平台商品非常多，百万、千万、上亿的商品，如何保证召回的商品与输入文本最相近呢？输入文本与商品标题全匹配+类目预测进行粗排+商品静态分，文本全匹配和类目预测保证基本的商品与输入文本相关性，商品静态分保证商品质量，通过简单排序模型取topn个比较相关的商品；第三步，此时商品依然较多，仅能保证商品与文本基本相关，却无法保证商品是用户感兴趣的。所以，用户个性化排序，也称精排做最后排序，使商品排序效率最大化。在第三步中，为了防止个性化排序突破搜索意图相关性，一般可以将类目预测得分较低的商品排在后面，保证头部商品的排序相关性。
  
类目预测query相关性，保证商品召回的相关性，提升用户的搜索体验。但针对搜索query的类目预测存在较多的问题：

1. query长度较短，包含信息太少。
2. 一个query往往不一定只与一个类目相关，其可能与多个类目相关
3. 长尾搜索query较多，较难统计归类
4. 类目上流量马太效应严重，存在较多类目流量较少。
5. 类目一般分为多级，越靠近叶子节点，预测难度越大。
6. 类目间存在重叠情况，本身区分难度较大。例如毛衣和针织衫

#### 类目预测模型选择

##### 人工方式

第一种方式，也是最粗暴的方式，直接采用人工对query进行配置。通过从电商app或pc搜索中拉取日志信息，分析得到top 热门搜索query，对这些query进行人工相关类目配置，保证下次用户搜索时类目正确；也可以通过query下用户的类目点击，统计分析得到query最相关的类目，人工审核后确定一一对应关系。
  
毕竟2000块可以解决的问题，没必要花2W块，初期可以采用这种方式，保证大多数用户的搜索。

##### 统计文本类目相关性

这个方法的出发点为：每个词与类目的相关性不同，或者说每个词相关的类目有限且权重不一。
  
基于这个假设，可以计算出每个词与类目的相关性得分，值域一般控制在[0,1]，0代表不相关，1代表非常相关。
  
这部分的工作相当于特征选择，特征即为词，选择重要的词。词的重要性由词在类目中的聚集性决定，即词若只在少数几个类目中出现，则词的辨别性越强，重要性越高。
  
选择方法

1. 点互信息PMI：

   p
   m
   i
   (
   x
   ,
   y
   )
   =
   l
   o
   g
   p
   (
   x
   ,
   y
   )
   p
   (
   x
   )
   p
   (
   y
   )
   pmi(x,y)=log\frac{p(x,y)}{p(x)p(y)}





   p

   m

   i

   (

   x

   ,



   y

   )



   =





   l

   o

   g












   p

   (

   x

   )

   p

   (

   y

   )











   p

   (

   x

   ,



   y

   )

   ​

   x,y分别代表词和类目，

   p
   (
   x
   ,
   y
   )
   p(x,y)





   p

   (

   x

   ,



   y

   )
   表示两者共同出现的概率，

   p
   (
   x
   )
   p(x)





   p

   (

   x

   )
   代表词属性的概率，

   p
   (
   y
   )
   p(y)





   p

   (

   y

   )
   代表类目y出现的概率。
2. 卡方分布

   x
   2
   x^2






   x









   2
   检验，详细信息可参考：
   [特征选择-卡方检测](https://blog.csdn.net/qfnu_cjt_wl/article/details/53408476)
3. tf-dc：这个是浏览博客时偶然发现的方法[^1]
     




   d
   c
   (
   t
   )
   =
   1
   −
   H
   (
   t
   )
   ∣
   C
   ∣
   =
   1
   +
   ∑
   i
   =
   1
   ∣
   C
   ∣
   f
   (
   t
   ,
   c
   i
   )
   f
   (
   t
   )
   l
   o
   g
   f
   (
   t
   ,
   c
   i
   )
   f
   (
   t
   )
   l
   o
   g
   ∣
   C
   ∣
   dc(t)=1-\frac{H(t)}{|C|}=1+\frac{\sum\_{i=1}^{|C|}\frac{f(t,c\_i)}{f(t)}log\frac{f(t,c\_i)}{f(t)}}{log|C|}





   d

   c

   (

   t

   )



   =





   1



   −
















   ∣

   C

   ∣











   H

   (

   t

   )

   ​




   =





   1



   +
















   l

   o

   g

   ∣

   C

   ∣












   ∑










   i

   =

   1






   ∣

   C

   ∣

   ​
















   f

   (

   t

   )












   f

   (

   t

   ,


   c









   i

   ​


   )

   ​


   l

   o

   g













   f

   (

   t

   )












   f

   (

   t

   ,


   c









   i

   ​


   )

   ​


   ​

     
   其中

   d
   c
   (
   t
   )
   dc(t)





   d

   c

   (

   t

   )
   表示词的重要性，

   ∣
   C
   ∣
   |C|





   ∣

   C

   ∣
   表示类目数量，

   f
   (
   t
   ,
   c
   i
   )
   f(t,c\_i)





   f

   (

   t

   ,




   c









   i

   ​


   )
   表示词与类目出现次数，

   f
   (
   t
   )
   f(t)





   f

   (

   t

   )
   表示词出现次数，采用信息熵的概率计算词的重要性。
     
   其中
     




   f
   (
   t
   ,
   c
   i
   )
   f
   (
   t
   )
   l
   o
   g
   f
   (
   t
   ,
   c
   i
   )
   f
   (
   t
   )
   \frac{f(t,c\_i)}{f(t)}log\frac{f(t,c\_i)}{f(t)}
















   f

   (

   t

   )











   f

   (

   t

   ,




   c









   i

   ​


   )

   ​


   l

   o

   g












   f

   (

   t

   )











   f

   (

   t

   ,




   c









   i

   ​


   )

   ​

     
   可表示为词与类目

   c
   i
   c\_i






   c









   i

   ​

   的相关性，为信息熵。
     
   当然还有较多的方法，此处不一一列举。
     
   最终可形成如图所示格式，即每个词与类目的关系及权重
     
   ![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/fc1e30718128eb8e88036b3750a40490.png)
     
   计算上述词和类目的重要性，最终得到的是每个商品词与类目的关联性和关联度；线上用户搜类目预测时，可对商品query进行分词，将分词后每个term分别召回相关的类目，多个term的召回结果按类目维度求和，得到当前query的相关类目和相关得分。

##### 简单deep模型

随着深度学习的火热，deep model具有更好的泛化效果，在类目预测上同样可以尝试。首先抽象一下类目预测的任务，将其抽象为一个分类任务，输入文本为query，预测可能相关的类目。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/2339458da0ff255b94104878021149d9.png#pic_center)
  
问题抽象完毕，下面就是构建模型的思路：
  
1.样本构建
  
2.模型选择
  
3.线上落地
  
4.模型异常处理

1. 样本构建
     
   在实践过程中，样本并非直接取商品搜索中query点击的类目作为训练样本，而是采用商品title和对应的类目作为分类训练样本。之所以这么做出于以下几点考虑：
     
   线上query点击类目数据噪声太多，小类目下的点击数据较少
     
   title中天然存在文本-cid的pair对，方便
     
   title中存在关键词与类目的关联关系
     
   线上数据如果不能很好的清洗，模型将切向与热门类目和query，泛化性能较差
     
   基于以上几点考虑，暂时采用商品title数据。此处其实为后续的优化留出了较大空间，后续的模型也确实将线上query数据清洗后作为训练数据，后面会讲到。
2. 模型选择
     
   此处因为业务迭代的原因，模型并未考虑较为复杂的结构，直接采用简单cnn或lstm进行训练。
3. 线上落地
     
   线上类目预测要求实时性较高，考虑到每天70%以上的query可以从日志信息中获取，故将类目预测分为线下和线上部分。
     
   线下：将热门query通过模型直接预测生成相关类目，导入到线上，query可直接查表获取类目结果
     
   线上：针对长尾query，对query进行类目预测，返回预测结果
4. 模型异常处理
     
   没有一个模型可以应对所以的情况，所以模型必然存在预测错的情况，需要增加一个干预机制，我们希望干预越来越少。
     
   对线下预测结果，可以做更多的管控，例如query可召回商品类目分布情况，类目下商品数量多的大概率是相关类目；热门query在线上的点击情况。
     
   最后，针对线上情况，我们开发了一套干预平台，方便对query结果直接调整。

##### 语义相关性匹配模型

先不说语义相关性匹配模型是什么，先来回溯一下类目搜索想要达成的目标、电商类目预测的特点。
  
为什么要做类目预测？因为要预测用户当前搜索的商品意图；那么用户的商品意图是什么样的？理想情况下用户搜索商品时，明确表达想要找的是什么商品。但这是理想情况下，真实的用户搜索是非明确的，特别是女士(无性别歧视)更倾向于输入关键词，开始逛，男士可能目的性更强一些，所以用户的商品意图是非明确的。用户可能会搜索”外套“，但是他并没有想好是牛仔外套，还是毛呢外套，又或是件风衣，所以更多搜索的类目意图是多面的(很重要，很重要，很重要)。
  
确立用户的意图是多面这个前提，就要确定哪些类目经常是相互关联的。这里为什么要人为去做确定，而不是让模型自己去学，这是因为线上的数据样本马太效应非常严重，致使较多的类目曝光量较低，所以人为构建反而是一种打破当前马太的好方法。
  
基于以上两点来看上述方法，弊端就较为明显：1.无法很好的确定用户意图的多方面性；2. query搜索的泛化效果不好；由此，我们提出基于语义相关性匹配的类目预测模型。
  
**模型抽象**
  
模型输入一个文本，预测结果为多个，这个是一个多标签分类任务。借鉴相关性匹配模型，我们构建模型结构如下
  
![抽象模型结构](https://i-blog.csdnimg.cn/blog_migrate/c6048738556810360e1d82013a49ee94.png#pic_center)

相关性论文中的模型结构 [3][4]：
  
![相关性论文模型结构](https://i-blog.csdnimg.cn/blog_migrate/43d372bd360a43db83432d99e7a18d6b.png#pic_center)
  
线上使用的模型
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/79526b1f9968bb468f2aa14c8828fc59.png#pic_center)
  
模型结构输入为query和类目信息，两者分别经过embedding层、双向lstm层、attention层、MLP层，最后输出为两者相关的概率得分。
  
query输入：线上用户搜索query，经过分词后映射为wordid
  
category info：类目全路径的文本信息+类目id，文本信息经过分词后映射为wordid。
  
attention结构：图中类目侧经过bilstm输出每步的向量，而query侧只输出最后step的向量，将query向量与类目矩阵进行attention相关性计算，计算得到类目词的attention score，进而得到类目的向量表达。
  



V
q
c
V\_{qc}






V










q

c

​

：query 向量和类目向量concat。

**样本构建**

1. 结合电商搜索场景下，用户搜索query后，引擎通过索引召回商品，召回的商品类目是一个相对较小的范围，而线上用户点击较多的类目为正样本，其他类目为负样本，生成query-类目全路径文本pair对，label为0/1。
2. 行为较少的类目样本构造；线上点击和搜索马太效应严重，故可取得数据的类目有限。少行为的类目，我们对其title进行随机采样，生成qeury，title本身所在类目全路径文本，构成正样本；负样本类目随机采样。
3. 为了提高非明确语义的搜索泛化性；将点击类目的兄弟类目不作为负样本进行训练，这是因为很多query，如“外套”，“衣服”，“上装”无法明确到某个类目，预测结果较泛。
4. 构建虚拟类目树；将同含义类目，因为一些规则区分开的，重新归为一类，预测是其不作为负样本。例如“毛衣”和“针织衫”，“连衣裙”和“大码连衣裙”

**线上预测**
  
模型上线具有较多的问题：

1. 模型因采用attention结构，线上预测rt较大
2. query的待预测类目集合无法确定；因为query与多个类目相关，但又不能与所有类目都计算一遍，取相关的
     
   经过探索，将模型结构设计为双塔方式，其中类目矩阵生成部分可以离线生成，无需线上实时预测，线上预测部分只有query和attention部分。针对待预测类目过多的问题，采用上文提到的方法二，统计文本与类目的相关性，粗排相关类目，选择topK进行预测。两者结合下，既可以有效降低rt，也对query待预测类目集合的损失降低了。这里为什么说是有损的呢？因为通过词召回，并不能等同与引擎召回，两者之间是有损的。最后，线上预测流程如下：
     
   ![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/af400e1e53439525e7f0361bcba1a3c1.png#pic_center)

#### 思考

1. 模型和样本是否可以继续优化？
     
   这是肯定的。样本方面可以增加词的权重信息，将不重要的词在预处理阶段或让模型学到；类目侧的特征目前仅用到文本信息，例如价格、季节偏好等都可尝试；模型方面，随着各类语言模型的诞生，transformer，bert等可以尝试。
2. 个性化
     
   类目预测是否可以做个性化？我认为是可以的，只是空间不是很大，且需要后续排序逻辑配合。空间不大是因为待透出的类目往往数量不多，3~5已经算多的了。需要排序配合是因为一旦透出的商品中出现其他类目或者类目得分变化，排序逻辑是否可以更好的推荐，还是出现badcase，这是需要统一配合的。那个性化的空间在哪里？假设用户最近在为父亲买羽绒服，一直在搜索中老年羽绒服，那么是否当他搜索“羽绒服”时，可以适当的多透出一些“中老年羽绒服”。

#### 参考

1. https://zedom1.top/2018/06/01/16%20VSM/
2. https://yq.aliyun.com/articles/420506
3. Deeply Supervised Semantic Model for Click-Through Rate Prediction in Sponsored Search
4. Learning Deep Structured Semantic Models for Web Search using Clickthrough Data