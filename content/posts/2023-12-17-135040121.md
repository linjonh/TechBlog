---
arturl_encode: "68747470733a2f2f626c:6f672e6373646e2e6e65742f65766572796461796e6577732f:61727469636c652f64657461696c732f313335303430313231"
layout: post
title: "Mistral携微软引爆小语言模型潮Mistral中杯代码能力完胜GPT-4,成本暴降23"
date: 2023-12-17 00:12:06 +08:00
description: "有博主对比了开源的Mistral-medium和GPT-4的代码生成能力，结果显示，Mistral-"
keywords: "mistral模型 中文"
categories: ['未分类']
tags: ['语言模型', '人工智能', 'Microsoft']
artid: "135040121"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=135040121
  alt: "Mistral携微软引爆小语言模型潮Mistral中杯代码能力完胜GPT-4,成本暴降23"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=135040121
featuredImagePreview: https://bing.ee123.net/img/rand?artid=135040121
---

# Mistral携微软引爆「小语言模型」潮！Mistral中杯代码能力完胜GPT-4，成本暴降2/3

###### **【导读】** 小模型的风潮，最近愈来愈盛，Mistral和微软分别有所动作。而网友实测发现，Mistral-medium的代码能力竟然完胜了GPT-4，而所花成本还不到三分之一。

最近，「小语言模型」忽然成为热点。

本周一，刚刚完成4.15亿美元融资的法国AI初创公司Mistral，发布了Mixtral 8x7B模型。

![图片](https://i-blog.csdnimg.cn/blog_migrate/50620a04c0beab10086f4db9192ed40c.png)

这个开源模型尽管尺寸不大，小到足以在一台内存100GB以上的电脑上运行，然而在某些基准测试中却能和GPT-3.5打平，因此迅速在开发者中赢得了一片称赞。

之所以叫Mixtral 8x7B，是因为它结合了为处理特定任务而训练的各种较小模型，从而提高了运行效率。

这种「稀疏专家混合」模型并不容易实现，据说OpenAI在今年早些时候因为无法让MoE模型正常运行，而不得不放弃了模型的开发。

紧接着，就在第二天，微软又发布了全新版本的Phi-2小模型。

![图片](https://i-blog.csdnimg.cn/blog_migrate/b2c128fdaf8f64ce4d9a99656fac3da4.png)

跟Mistral的70亿参数比，Phi-2小到可以在手机上跑，只有27亿参数。相比之下，GPT-4的参数达到了一万亿。

Phi-2在精心挑选的数据集上进行了训练，数据集的质量足够高，因此即使手机的计算能力有限，也能确保模型生成准确的结果。

虽然还不清楚微软或其他软件制造商将如何使用小型模型，但最明显的好处，就是降低了大规模运行AI应用的成本，并且极大地拓宽了生成式AI技术的应用范围。

这是一件大事。

Mistral-medium代码生成完胜GPT-4

最近，Mistral-medium已经开放内测。

有博主对比了开源的Mistral-medium和GPT-4的代码生成能力，结果显示，Mistral-medium比GPT-4的代码能力更强，然而成本却只需GPT-4的3成！

![图片](https://i-blog.csdnimg.cn/blog_migrate/53e65c934f2520e167a01f2416dcb7c0.png)

总价来说就是：

1）Mistral会始终完成工作，完成度很高；

2）不会在冗长的解释性输出上浪费token；

3）提供的建议非常具体。

第一题，「编写用于生成斐波那契素数的PyTorch数据集的cuda优化代码」。

Mistral-Medium生成的代码严肃、完整。

![图片](https://i-blog.csdnimg.cn/blog_migrate/916bc4cba1b40881531cf1dad8d46da5.png)

![图片](https://i-blog.csdnimg.cn/blog_migrate/a3196ef300ea42ed66bd406af8f2552f.png)

![图片](https://i-blog.csdnimg.cn/blog_migrate/ac68583fb6ea8bc2c90edbe6440545ba.png)

而GPT-4生成的代码，就差强人意了。

浪费了很多token，却没有输出有用的信息。

![图片](https://i-blog.csdnimg.cn/blog_migrate/e9dc9009c8e4b6efbd5651408ab38069.png)

然后，GPT-4只给出了骨架代码，并没有具体的相关代码。

![图片](https://i-blog.csdnimg.cn/blog_migrate/563105ad5a0d53a12e4ce805344e4afa.png)

第二道题：「编写高效的Python代码，将大约10亿个大型Apache HTTP访问文件摄取到 SqlLite数据库中，并使用它来生成对sales.html和product.html的访问直方图」。

Mistral的输出非常精彩，虽然log不是CSV格式的，但修改起来很容易。

![图片](https://i-blog.csdnimg.cn/blog_migrate/8f8180d93a27d48a2693a1dd8de3dfe4.png)

![图片](https://i-blog.csdnimg.cn/blog_migrate/0dcca917ee6b78d7c8c52f5dfc6ab017.png)

![图片](https://i-blog.csdnimg.cn/blog_migrate/4d9ac94a7f8f03407da5cb60088736ab.png)

GPT-4依旧拉跨。

![图片](https://i-blog.csdnimg.cn/blog_migrate/0efdb074e506f890c8e4f1e64520a87c.png)

![图片](https://i-blog.csdnimg.cn/blog_migrate/a5701834739657ea6d8e7afca8d863a4.png)

![图片](https://i-blog.csdnimg.cn/blog_migrate/a947c05a317d7690a4de8e0ec80e83f4.png)

此前，这位博主测试过多个代码生成模型，GPT-4一直稳居第一。

而现在，把它拉下宝座的强劲对手Mistral-medium终于出现了。

虽然只发布了两个例子，但博主测试了多个问题，结果都差不多。

他建议：鉴于Mistral-medium在代码生成质量上有更好的体验，应该把它整合到各地的代码copilot中。

![图片](https://i-blog.csdnimg.cn/blog_migrate/1b01c89448efd29c29028dc3d7663300.png)

有人按照每1000token算出了输入和输出的成本，发现Mistral-medium比起GPT-4直接降低了70%！

![图片](https://i-blog.csdnimg.cn/blog_migrate/223aa9ad054276987b434935ece62eea.png)

的确，节省了70%的token费用，可不是一件小事。甚至还可以通过不冗长的输出，来进一步节省成本。

![图片](https://i-blog.csdnimg.cn/blog_migrate/38e1a0612a7a21ff262ddc1a93236abd.png)

参考资料：

https://www.theinformation.com/articles/the-rise-of-small-language-models-and-reinforcement-learning

https://twitter.com/deliprao/status/1734997263024329157