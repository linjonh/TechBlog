---
layout: post
title: "目标检测Anchor-based-与-Anchor-free-"
date: 2025-03-10 22:01:18 +0800
description: "anchor-free和anchor-based是两种不同的目标检测方法，区别在于是否使用预定义的anchor框来匹配真实的目标框。anchor-based方法使用不同大小和形状的anchor框来回归和分类目标，例如faster rcnn、retinanet和yolo等。anchor-free，例如fcos、atss和cornernet等。anchor-free方法比anchor-based方法更简单和灵活，但可能存在召回率或定位精度低的问题。"
keywords: "anchor free 和anchor based"
categories: ['未分类']
tags: ['计算机视觉', '目标检测', '人工智能']
artid: "146164914"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146164914
    alt: "目标检测Anchor-based-与-Anchor-free-"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146164914
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146164914
cover: https://bing.ee123.net/img/rand?artid=146164914
image: https://bing.ee123.net/img/rand?artid=146164914
img: https://bing.ee123.net/img/rand?artid=146164914
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     目标检测Anchor-based 与 Anchor-free
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h3>
     一.二者对比
    </h3>
    <p>
     anchor-free和anchor-based是两种不同的目标检测方法，区别在于是否使用预定义的anchor框来匹配真实的目标框。 anchor-based方法使用不同大小和形状的anchor框来回归和分类目标，例如faster rcnn、retinanet和yolo等。anchor-free，例如fcos、atss和cornernet等。anchor-free方法比anchor-based方法更简单和灵活，但可能存在召回率或定位精度低的问题。
    </p>
    <h4>
     anchor-based
    </h4>
    <p>
     深度学习目标检测通常都被建模成对一些候选区域进行分类和回归的问题。在单阶段检测器中，这些候选区域就是通过滑窗方式产生的 anchor；在两阶段检测器中，候选区域是 RPN 生成的 proposal，但是 RPN 本身仍然是对滑窗方式产生的 anchor 进行分类和回归。
    </p>
    <h4>
     anchor-free
    </h4>
    <p>
     anchor-free是通过另外一种手段来解决检测问题的。同样分为两个子问题，即确定物体中心和对四条边框的预测。预测物体中心时，将中心预测融入到类别预测的 target 里面，也可以预测一个 soft 的 centerness score。对于四条边框的预测，则比较一致，都是预测该像素点到 ground truth 框的四条边距离，不过会使用一些 trick 来限制 regress 的范围。
    </p>
    <h3>
     优缺点
    </h3>
    <h4>
     anchor-based
    </h4>
    <p>
     anchor based的优点是可以产生密集的anchor box，使得网络可以直接进行目标分类和边界框回归，提高了目标召回能力，尤其对小目标检测有明显的提升。
    </p>
    <p>
     anchor based的缺点是需要设定很多超参数，如尺度、长宽比等，这些参数很难设计，并且会影响检测性能。另外，anchor based的方法也会产生很多冗余的框，增加了计算量和内存消耗。
    </p>
    <h4>
     anchor-free
    </h4>
    <p>
     anchor free的优点是不需要预设anchor，只需要对不同尺度的特征图的目标中心点和宽高进行回归，减少了耗时和算力。同时，anchor free的方法也可以避免一些由于anchor设置不合理导致的漏检或重复检测问题。
    </p>
    <p>
     anchor free的缺点是由于每个位置只预测一个框，可能会导致一些重叠或遮挡区域无法被检测到。另外，anchor free的方法也需要一些特殊的损失函数或结构来提高精度和稳定性。
    </p>
    <h3>
     二.基于FCOS的anchor-free目标检测方法
    </h3>
    <p>
     文章上来首先介绍了anchor-based类算法所存在的一些固有的不足：
    </p>
    <ul>
     <li>
      anchor-based类算法的检测性能受到框的尺度、宽高比以及数量的影响比较大，例如使用RetinaNet通过精细的调整这些超参数在
      <a href="https://zhida.zhihu.com/search?content_id=445836743&amp;content_type=Answer&amp;match_order=1&amp;q=COCO&amp;zhida_source=entity" rel="nofollow" title="COCO">
       COCO
      </a>
      上可以得到4%AP的提升。
     </li>
     <li>
      在不同的检测任务中，由于数据集的不同，这些与anchor相关的超参数均需要重新设计，普适性较差。
     </li>
     <li>
      为了尽可能精确的匹配图像中的物体，需要成千上万预设的anchor，导致正负样本的极度不均衡。
     </li>
     <li>
      训练过程中，对于box的匹配需要计算所有的IOU值，计算复杂度较高。
     </li>
    </ul>
    <p>
     针对以上提到的anchor-based算法的一些问题，anchor-free系列算法不使用预设的anchor来完成目标检测。其中
     <a href="https://zhida.zhihu.com/search?content_id=445836743&amp;content_type=Answer&amp;match_order=1&amp;q=cornernet&amp;zhida_source=entity" rel="nofollow" title="cornernet">
      cornernet
     </a>
     系列的算法（cornernet，
     <a href="https://zhida.zhihu.com/search?content_id=445836743&amp;content_type=Answer&amp;match_order=1&amp;q=centernet&amp;zhida_source=entity" rel="nofollow" title="centernet">
      centernet
     </a>
     ，
     <a href="https://zhida.zhihu.com/search?content_id=445836743&amp;content_type=Answer&amp;match_order=1&amp;q=extremenet&amp;zhida_source=entity" rel="nofollow" title="extremenet">
      extremenet
     </a>
     ）使用关键点检测的方案完成目标检测，但是这种方法需要较为复杂的后处理；
     <a href="https://zhida.zhihu.com/search?content_id=445836743&amp;content_type=Answer&amp;match_order=1&amp;q=DenseBox&amp;zhida_source=entity" rel="nofollow" title="DenseBox">
      DenseBox
     </a>
     算法在通用的目标检测中适应性不好。本文的FCOS算法使用语义分割的思想，逐像素点来完成目标检测。
    </p>
    <h2>
     三.方法详解
    </h2>
    <p>
     FCOS算法的网络架构如下图所示，使用
     <a href="https://zhida.zhihu.com/search?content_id=445836743&amp;content_type=Answer&amp;match_order=1&amp;q=FPN&amp;zhida_source=entity" rel="nofollow" title="FPN">
      FPN
     </a>
     实现多层特征图的融合。
    </p>
    <p>
     最终每个检测头依旧包含类别分类以及边界框回归分支。其中分类分支包含
     <a href="https://zhida.zhihu.com/search?content_id=445836743&amp;content_type=Answer&amp;match_order=1&amp;q=CenterNess&amp;zhida_source=entity" rel="nofollow" title="CenterNess">
      CenterNess
     </a>
     的分支主要用来解决大量低质量预测框的问题，具体的原因以及操作方式，下边再说。
    </p>
    <p>
     <img alt="" height="422" src="https://i-blog.csdnimg.cn/direct/fe8cfe0fc5c44f34b233fa50e8b31479.png" width="966"/>
    </p>
    <h3>
     正负样本确定
    </h3>
    <p>
     如果一个像素点落入了GT中，那么其就是正样本，其类别为此GT的类别。否则就是负样本。
     <strong>
      （这里就可以看出，对于一个GT会有大量预测框的中心点远离GT中心点的低质量预测框，这也就是centerness需要解决的问题）
     </strong>
    </p>
    <p>
     针对一个落入GT中的像素点（x， y），其回归分支的预测值是什么呢？
    </p>
    <p>
     <img alt="" height="266" src="https://i-blog.csdnimg.cn/direct/6a1b023416124683be36295cbf567e40.png" width="931"/>
    </p>
    <p>
     正如公式所示，其回归分支的预测值，就是回归(x, y)与GT的左、上、右、下的距离。这里为了保证回归目标的非负，依然使用指数函数exp()进行处理。
    </p>
    <p>
     在匹配的过程中，会遇到如下图所示的一种情况，就是一个像素点同时落在多个GT中该如何处理呢？
    </p>
    <p>
     <strong>
      大部分重叠都是发生在目标大小差别比较大
     </strong>
     的情况，FCOS通过限定对于不同尺度特征图的检测框的大小来避免这种重复区域的出现。
    </p>
    <p>
     从FCOS网络结构图中，我么们可以看出FCOS使用$P_3, P_4, P_5, P_6, P_7$ 这几个特征层来进行预测，因此为了解决目标大小差别较大的情况下重叠区域的出现。根据下边的公式，如果某个像素点满足如下的条件，那么这个像素点在第i层特征层中就会被作认为是负样本，不参与回归计算。 $$ max(l; t; r; b) &gt; m_i $$
    </p>
    <p>
     $$ 或者max(l; t; r; b) &lt; m_{i-1} $$
    </p>
    <p>
     其中，$m_i$作为第i层特征图的最大检测尺寸。
    </p>
    <p>
     <strong>
      如果在同一层中依然出现重叠的区域怎么办呢？这是FCOS简单的会使用最小区域来作为回归目标。
     </strong>
    </p>
    <h3>
     <strong>
      CenterNess
     </strong>
    </h3>
    <p>
     上文提到预测结果会出现很多的低质量预测框（其中心点离GT的中心点较远），因此为解决这个问题，使用centerness，其公式如下：
    </p>
    <p>
     <img alt="" height="174" src="https://i-blog.csdnimg.cn/direct/8543901470834774b58da837f373aff6.png" width="956"/>
    </p>
    <p>
     从公式可以看出，当预测的框，离中心点越近时，centerness趋近于1，越远趋近于0。因此centerness使用bce损失来进行优化。
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34363435343636392f:61727469636c652f64657461696c732f313436313634393134" class_="artid" style="display:none">
 </p>
</div>


