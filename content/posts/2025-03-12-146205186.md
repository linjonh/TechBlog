---
layout: post
title: "PyTorch中torch.nntorchsummary和torch.nn.functional库作用详解"
date: 2025-03-12 17:05:20 +0800
description: "库名主要用途特点torch.nn构建和管理神经网络结构封装可学习参数，模块化设计，支持复杂模型实现无状态操作（激活、损失等）灵活、无需实例化类，适合动态计算可视化模型结构和参数统计调试维度匹配，优化模型设计参考资料torch.nn官方文档、使用案例安装与使用指南functional与nn对比分析。"
keywords: "PyTorch中torch.nn、torchsummary和torch.nn.functional库作用详解"
categories: ['未分类']
tags: ['人工智能', 'Pytorch', 'Python']
artid: "146205186"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146205186
    alt: "PyTorch中torch.nntorchsummary和torch.nn.functional库作用详解"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146205186
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146205186
cover: https://bing.ee123.net/img/rand?artid=146205186
image: https://bing.ee123.net/img/rand?artid=146205186
img: https://bing.ee123.net/img/rand?artid=146205186
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     PyTorch中torch.nn、torchsummary和torch.nn.functional库作用详解
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     以下是对PyTorch中
     <code>
      torch.nn
     </code>
     、
     <code>
      torchsummary
     </code>
     和
     <code>
      torch.nn.functional
     </code>
     库作用的总结，结合了搜索结果中的关键信息：
    </p>
    <hr/>
    <h4>
     <a id="1_torchnn__4">
     </a>
     1.
     <strong>
      <code>
       torch.nn
      </code>
      库
     </strong>
    </h4>
    <p>
     <strong>
      作用
     </strong>
     ：PyTorch中构建神经网络的核心模块，提供预定义层、参数管理、模型结构定义等功能。
     <br/>
     <strong>
      核心功能
     </strong>
     ：
    </p>
    <ul>
     <li>
      <strong>
       模块化网络构建
      </strong>
      ：
      <br/>
      通过类（如
      <code>
       nn.Linear
      </code>
      、
      <code>
       nn.Conv2d
      </code>
      ）定义神经网络层，支持可学习参数（如权重和偏置）的自动管理。
     </li>
     <li>
      <strong>
       模型基类
       <code>
        nn.Module
       </code>
      </strong>
      ：
      <br/>
      所有自定义模型的基类，需重写
      <code>
       __init__
      </code>
      （定义层）和
      <code>
       forward
      </code>
      （定义前向传播逻辑）方法。
     </li>
     <li>
      <strong>
       参数管理
      </strong>
      ：
      <br/>
      通过
      <code>
       nn.Parameter
      </code>
      封装可训练参数，支持梯度计算和优化器更新。
     </li>
     <li>
      <strong>
       预定义层与容器
      </strong>
      ：
      <br/>
      提供全连接层（
      <code>
       nn.Linear
      </code>
      ）、卷积层（
      <code>
       nn.Conv2d
      </code>
      ）、池化层（
      <code>
       nn.MaxPool2d
      </code>
      ）等，以及容器类（如
      <code>
       nn.Sequential
      </code>
      ）简化模型串联。
     </li>
     <li>
      <strong>
       训练与评估模式切换
      </strong>
      ：
      <br/>
      通过
      <code>
       model.train()
      </code>
      和
      <code>
       model.eval()
      </code>
      控制Dropout、BatchNorm等层的不同行为。
     </li>
    </ul>
    <p>
     <strong>
      典型应用场景
     </strong>
     ：
    </p>
    <ul>
     <li>
      定义包含可学习参数的层（如卷积、全连接层）
     </li>
     <li>
      构建复杂的自定义模型结构
     </li>
     <li>
      管理模型参数和训练状态
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="2_torchnnfunctional__25">
     </a>
     2.
     <strong>
      <code>
       torch.nn.functional
      </code>
      库
     </strong>
    </h4>
    <p>
     <strong>
      作用
     </strong>
     ：提供无状态的
     <strong>
      函数式操作
     </strong>
     ，适用于无需参数或动态计算的神经网络组件。
     <br/>
     <strong>
      核心功能
     </strong>
     ：
    </p>
    <ul>
     <li>
      <strong>
       激活函数
      </strong>
      ：
      <br/>
      如
      <code>
       F.relu
      </code>
      、
      <code>
       F.sigmoid
      </code>
      ，直接作用于张量，无需实例化类。
     </li>
     <li>
      <strong>
       损失函数
      </strong>
      ：
      <br/>
      如
      <code>
       F.cross_entropy
      </code>
      、
      <code>
       F.mse_loss
      </code>
      ，适用于自定义损失计算逻辑。
     </li>
     <li>
      <strong>
       卷积与池化操作
      </strong>
      ：
      <br/>
      如
      <code>
       F.conv2d
      </code>
      、
      <code>
       F.max_pool2d
      </code>
      ，需手动传入权重参数，灵活性更高。
     </li>
     <li>
      <strong>
       其他操作
      </strong>
      ：
      <br/>
      归一化（如
      <code>
       F.layer_norm
      </code>
      ）、Dropout（
      <code>
       F.dropout
      </code>
      ）、张量变换（如
      <code>
       F.pad
      </code>
      ）等。
     </li>
    </ul>
    <p>
     <strong>
      与
      <code>
       torch.nn
      </code>
      的区别
     </strong>
     ：
    </p>
    <ul>
     <li>
      <strong>
       无状态性
      </strong>
      ：
      <code>
       functional
      </code>
      函数无内置参数，需手动管理权重（若有）；
      <code>
       nn
      </code>
      模块通过类封装参数。
     </li>
     <li>
      <strong>
       适用场景
      </strong>
      ：
      <ul>
       <li>
        <code>
         functional
        </code>
        ：动态计算、无参数操作（如激活函数）
       </li>
       <li>
        <code>
         nn
        </code>
        ：需要参数持久化的层（如全连接层）
       </li>
      </ul>
     </li>
    </ul>
    <p>
     <strong>
      示例
     </strong>
     ：
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 使用functional实现激活函数和池化</span>
x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>  
x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
</code></pre>
    <hr/>
    <h4>
     <a id="3_torchsummary__52">
     </a>
     3.
     <strong>
      <code>
       torchsummary
      </code>
      库
     </strong>
    </h4>
    <p>
     <strong>
      作用
     </strong>
     ：可视化神经网络模型结构，提供层级参数统计和输出形状信息。
     <br/>
     <strong>
      核心功能
     </strong>
     ：
    </p>
    <ul>
     <li>
      <strong>
       模型结构可视化
      </strong>
      ：
      <br/>
      输出每层的类型、输出形状、参数数量，并统计总参数量和模型大小。
     </li>
     <li>
      <strong>
       调试辅助
      </strong>
      ：
      <br/>
      检查输入输出维度是否匹配，优化模型设计。
     </li>
     <li>
      <strong>
       兼容性
      </strong>
      ：
      <br/>
      支持CPU和GPU设备，需指定输入数据的维度。
     </li>
    </ul>
    <p>
     <strong>
      使用示例
     </strong>
     ：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> torchsummary <span class="token keyword">import</span> summary
model <span class="token operator">=</span> MyModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
summary<span class="token punctuation">(</span>model<span class="token punctuation">,</span> input_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 输入为3通道224x224图像</span>
</code></pre>
    <p>
     <strong>
      输出示例
     </strong>
     ：
    </p>
    <pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 224, 224]           9,408
              ReLU-2         [-1, 64, 224, 224]               0
         MaxPool2d-3         [-1, 64, 112, 112]               0
...
================================================================
Total params: 61,326
Trainable params: 61,326
Non-trainable params: 0
----------------------------------------------------------------
</code></pre>
    <hr/>
    <h4>
     <a id="_86">
     </a>
     总结对比
    </h4>
    <table>
     <thead>
      <tr>
       <th>
        库名
       </th>
       <th>
        主要用途
       </th>
       <th>
        特点
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        <code>
         torch.nn
        </code>
       </td>
       <td>
        构建和管理神经网络结构
       </td>
       <td>
        封装可学习参数，模块化设计，支持复杂模型
       </td>
      </tr>
      <tr>
       <td>
        <code>
         torch.nn.functional
        </code>
       </td>
       <td>
        实现无状态操作（激活、损失等）
       </td>
       <td>
        灵活、无需实例化类，适合动态计算
       </td>
      </tr>
      <tr>
       <td>
        <code>
         torchsummary
        </code>
       </td>
       <td>
        可视化模型结构和参数统计
       </td>
       <td>
        调试维度匹配，优化模型设计
       </td>
      </tr>
     </tbody>
    </table>
    <p>
     <strong>
      参考资料
     </strong>
     ：
    </p>
    <ul>
     <li>
      <code>
       torch.nn
      </code>
      官方文档、使用案例
     </li>
     <li>
      <code>
       torchsummary
      </code>
      安装与使用指南
     </li>
     <li>
      <code>
       functional
      </code>
      与
      <code>
       nn
      </code>
      对比分析
     </li>
    </ul>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f:2f626c6f672e6373646e2e6e65742f7661726461383839392f:61727469636c652f64657461696c732f313436323035313836" class_="artid" style="display:none">
 </p>
</div>


