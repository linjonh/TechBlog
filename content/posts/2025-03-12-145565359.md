---
layout: post
title: "llamaindex实现企业级RAG应用一"
date: 2025-03-12 14:21:06 +0800
description: "查询引擎可以通过()的方式一步构建完成，但若要实现更复杂的RAG流程，则需要我们精准控制query_engine的内部细节，这里我们手动构建一个。2.1 自定义响应器通俗地说，查询引擎=检索器+响应器，检索器可灵活操作的代码不多，这里仅构建响应器# 自定义响应器\"根据以下上下文信息：\\n\"\"使用中文回答以下问题\\n \"\"问题: {query_str}\\n\"\"答案: \"self,) -> None:# 必须实现的接口# 必须实现的接口, 更新提示词# 生成响应的接口self,"
keywords: "llamaindex实现企业级RAG应用（一）"
categories: ['未分类']
tags: ['自然语言处理', '深度学习', '人工智能', 'Transformer']
artid: "145565359"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145565359
    alt: "llamaindex实现企业级RAG应用一"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145565359
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145565359
cover: https://bing.ee123.net/img/rand?artid=145565359
image: https://bing.ee123.net/img/rand?artid=145565359
img: https://bing.ee123.net/img/rand?artid=145565359
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     llamaindex实现企业级RAG应用（一）
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     在上一篇文章中
     <a href="https://blog.csdn.net/weixin_42479327/article/details/139574507?spm=1001.2014.3001.5502">
      使用Qwen2进行RAG代码实践
     </a>
     ，手动实现了一版简易的RAG应用，在实际工作中通常都用会使用langchain或llamaindex架构来搭建rag应用，并且会非常复杂。
    </p>
    <p>
     RAG是个很神奇的应用，可以很简单，也可以很复杂。在llamaindex官网给的案例，5行代码就可以构建RAG应用，但要真正实现企业级RAG应用，则需要花费大量时间去调优。本文通过一个复杂的项目案例，记录下工作中常用到的优化方法。
    </p>
    <p>
     项目代码：
     <br/>
     <a href="https://github.com/yblir/LegalKnowledgeRAG">
      https://github.com/yblir/LegalKnowledgeRAG
     </a>
    </p>
    <h2>
     <a id="__7">
     </a>
     一 项目说明
    </h2>
    <p>
     RAG 是一种基于大模型的知识密集型应用，以数据查询与对话任务为主要形式。对于复杂需求的场景，比如几十个不同类型法律知识文档, 如果使用经典的 RAG 应用，通过知识块+向量+top_K 检索来获得上下文，让大模型给出答案，那么显然是不现实的，因为不同文档间内容属性不同，粗暴地与在不同的文档间匹配向量相似度，很容易检索出不相关的答案。
    </p>
    <p>
     经典的 RAG 应用在回答文档相关的事实性问题上，在大部分时间可以工作得不错，但是知识应用并不总是这种类型的，比如无法基于向量检索简单地生成文档的摘要与总结，也无法胜任一些跨文档回答问题或者需要结合其他工具复合应用的工作。
    </p>
    <p>
     所以，本项目使用Data Agent作为主架构来实现。 Data Agent在 RAG 的基础上引入自我规划与使用工具的能力，从而具备了完成大模型驱动的、更丰富的数据读写任务的能力，提升RAG问答能力。因此，本文结合Agent, 实现一版RAG法律知识问答的项目。当然也可以使用路由查询引擎来代替Agent 实现接近的功能。不过路由查询引擎与Agent 是有区别的，路由查询引擎在大部分时候仅起到选择工具与转发问题的作用，并不会多次迭代，而Agent 则会观察工具返回的结果，有可能使用多个工具通过多次迭代来完成任务。
     <br/>
     项目整体流程如下：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/ab8a904b68994f47b9f490f91bdfcdda.png"/>
    </p>
    <p>
     需要的模块主要包括以下 3 个。
     <br/>
     （1）后端 Agent 模块：这是系统的核心模块，用于给已有的多文档知识构
     <br/>
     造索引与查询引擎，并以查询引擎作为工具创建上层的 Agent。
     <br/>
     （2）后端 API 模块：这是提供给前端 UI 应用直接访问的 API。
     <br/>
     （3）前端 UI 应用：这是一个简单的支持连续对话的前端 ChatBot，能够与后端 API 模块实现交互。
    </p>
    <p>
     本文主要关注后端（Agent 模块与 API 模块），在整体架构中，我们自底向上推进。
    </p>
    <h2>
     <a id="__26">
     </a>
     二 自定义查询引擎
    </h2>
    <p>
     查询引擎可以通过
     <strong>
      vector_index.as_query_engine
     </strong>
     ()的方式一步构建完成，但若要实现更复杂的RAG流程，则需要我们精准控制query_engine的内部细节，这里我们手动构建一个。
    </p>
    <p>
     2.1 自定义响应器
     <br/>
     通俗地说，查询引擎=检索器+响应器，检索器可灵活操作的代码不多，这里仅构建响应器
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 自定义响应器</span>
<span class="token keyword">class</span> <span class="token class-name">CustomSynthesizer</span><span class="token punctuation">(</span>BaseSynthesizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    my_prompt <span class="token operator">=</span> <span class="token punctuation">(</span>
        <span class="token string">"根据以下上下文信息：\n"</span>
        <span class="token string">"---------------------\n"</span>
        <span class="token string">"{context_str}\n"</span>
        <span class="token string">"---------------------\n"</span>
        <span class="token string">"使用中文回答以下问题\n "</span>
        <span class="token string">"问题: {query_str}\n"</span>
        <span class="token string">"答案: "</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
            self<span class="token punctuation">,</span>
            llm<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>LLMPredictorType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_input_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>CustomSynthesizer<span class="token punctuation">.</span>my_prompt<span class="token punctuation">)</span>

    <span class="token comment"># 必须实现的接口</span>
    <span class="token keyword">def</span> <span class="token function">_get_prompts</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> PromptDictType<span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_input_prompt<span class="token punctuation">.</span>text

    <span class="token comment"># 必须实现的接口, 更新提示词</span>
    <span class="token keyword">def</span> <span class="token function">_update_prompts</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> prompts<span class="token punctuation">:</span> PromptDictType<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>_input_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>prompts<span class="token punctuation">.</span>text<span class="token punctuation">)</span>

    <span class="token comment"># 生成响应的接口</span>
    <span class="token keyword">def</span> <span class="token function">get_response</span><span class="token punctuation">(</span>
            self<span class="token punctuation">,</span>
            query_str<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span>
            text_chunks<span class="token punctuation">:</span> Sequence<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token operator">**</span>response_kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> RESPONSE_TEXT_TYPE<span class="token punctuation">:</span>
        context_str <span class="token operator">=</span> <span class="token string">"\n\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>n <span class="token keyword">for</span> n <span class="token keyword">in</span> text_chunks<span class="token punctuation">)</span>
        <span class="token comment"># 此处可以自定义任何响应逻辑</span>
        response <span class="token operator">=</span> self<span class="token punctuation">.</span>_llm<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>_input_prompt<span class="token punctuation">,</span>
                query_str<span class="token operator">=</span>query_str<span class="token punctuation">,</span>
                context_str<span class="token operator">=</span>context_str<span class="token punctuation">,</span>
                <span class="token operator">**</span>response_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">return</span> response

    <span class="token comment"># 响应接口的异步版本</span>
    <span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">aget_response</span><span class="token punctuation">(</span>
            self<span class="token punctuation">,</span>
            query_str<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span>
            text_chunks<span class="token punctuation">:</span> Sequence<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token operator">**</span>response_kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> RESPONSE_TEXT_TYPE<span class="token punctuation">:</span>
        context_str <span class="token operator">=</span> <span class="token string">"\n\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>n <span class="token keyword">for</span> n <span class="token keyword">in</span> text_chunks<span class="token punctuation">)</span>
        response <span class="token operator">=</span> <span class="token keyword">await</span> self<span class="token punctuation">.</span>_llm<span class="token punctuation">.</span>apredict<span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>_input_prompt<span class="token punctuation">,</span>
                query_str<span class="token operator">=</span>query_str<span class="token punctuation">,</span>
                context_str<span class="token operator">=</span>context_str<span class="token punctuation">,</span>
                <span class="token operator">**</span>response_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">return</span> response
</code></pre>
    <p>
     2.2 自定义大模型
    </p>
    <p>
     RAG的核心是对大模型能力的调用，在llamaindex中可以通过内置的vllm和ollama等部署工具直接使用，当然也可以自定义一份，这样的好处是可以使用本地微调且还没被llamaindex支持的大模型，为项目进行定制化开发。这里使用vllm部署模型。
    </p>
    <p>
     另外还有嵌入模型可以自定义，这里不演示。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">CustomVllmLLM</span><span class="token punctuation">(</span>CustomLLM<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""自定义大模型, 模型是huggingface格式"""</span>
    <span class="token comment"># self.vllm_model字段必须先在此声明才能用</span>
    vllm_model<span class="token punctuation">:</span> vllm<span class="token punctuation">.</span>Vllm <span class="token operator">=</span> Field<span class="token punctuation">(</span>default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">"VLLM 模型实例"</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model_path<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"模型路径不存在"</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>vllm_model <span class="token operator">=</span> vllm<span class="token punctuation">.</span>Vllm<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

    <span class="token comment"># 实现metadata 接口</span>
    <span class="token decorator annotation punctuation">@property</span>
    <span class="token keyword">def</span> <span class="token function">metadata</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> LLMMetadata<span class="token punctuation">:</span>
        <span class="token keyword">return</span> LLMMetadata<span class="token punctuation">(</span>
                model_name<span class="token operator">=</span><span class="token string">'vllm_model'</span>
        <span class="token punctuation">)</span>

    <span class="token comment"># 实现complete 接口</span>
    <span class="token decorator annotation punctuation">@llm_completion_callback</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">complete</span><span class="token punctuation">(</span>
            self<span class="token punctuation">,</span> prompt<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> CompletionResponse<span class="token punctuation">:</span>
        response <span class="token operator">=</span> self<span class="token punctuation">.</span>vllm_model<span class="token punctuation">.</span>complete<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        <span class="token keyword">return</span> CompletionResponse<span class="token punctuation">(</span>
                text<span class="token operator">=</span>response<span class="token punctuation">.</span>text
        <span class="token punctuation">)</span>

    <span class="token comment"># 实现stream_complete 接口</span>
    <span class="token decorator annotation punctuation">@llm_completion_callback</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">stream_complete</span><span class="token punctuation">(</span>
            self<span class="token punctuation">,</span> prompt<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> CompletionResponseGen<span class="token punctuation">:</span>
        response <span class="token operator">=</span> <span class="token string">""</span>
        model_response <span class="token operator">=</span> self<span class="token punctuation">.</span>vllm_model<span class="token punctuation">.</span>complete<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>

        <span class="token keyword">for</span> token <span class="token keyword">in</span> model_response<span class="token punctuation">.</span>text<span class="token punctuation">:</span>
            response <span class="token operator">+=</span> token
            <span class="token keyword">yield</span> CompletionResponse<span class="token punctuation">(</span>text<span class="token operator">=</span>response<span class="token punctuation">,</span> delta<span class="token operator">=</span>token<span class="token punctuation">)</span>
</code></pre>
    <p>
     2.3 自定义查询引擎
     <br/>
     totooooooo,此处插图。
     <br/>
     自定义好响应器和大模型后，就可以合成查询引擎了。查询引擎有两种，分别是单次查询引擎和多轮对话引擎，实际项目中常用的是对话引擎。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> custom_components <span class="token keyword">import</span> CustomVllmLLM<span class="token punctuation">,</span> CustomSynthesizer


<span class="token comment"># 单次查询引擎</span>
<span class="token comment"># 对chat_engine =vector_index.as_query_engine()的自定义操作</span>
<span class="token keyword">class</span> <span class="token class-name">OnceQueryEngine</span><span class="token punctuation">(</span>CustomQueryEngine<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 此处直接使用大模型组件，而不是响应生成器</span>
    <span class="token comment"># llm: Ollama = Field(default=None, description="llm")</span>
    llm<span class="token punctuation">:</span> vllm<span class="token punctuation">.</span>Vllm <span class="token operator">=</span> Field<span class="token punctuation">(</span>default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">"llm"</span><span class="token punctuation">)</span>
    retriever<span class="token punctuation">:</span> BaseRetriever <span class="token operator">=</span> Field<span class="token punctuation">(</span>default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">"retriever"</span><span class="token punctuation">)</span>
    qa_prompt<span class="token punctuation">:</span> PromptTemplate <span class="token operator">=</span> Field<span class="token punctuation">(</span>default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">"提示词"</span><span class="token punctuation">)</span>
    synthesizer<span class="token punctuation">:</span> CustomSynthesizer <span class="token operator">=</span> Field<span class="token punctuation">(</span>default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">"自定义响应器"</span><span class="token punctuation">)</span>

    qa_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
            <span class="token string">"根据以下上下文回答输入问题：\n"</span>
            <span class="token string">"---------------------\n"</span>
            <span class="token string">"{context_str}\n"</span>
            <span class="token string">"---------------------\n"</span>
            <span class="token string">"回答以下问题，不要编造\n"</span>
            <span class="token string">"我的问题: {query_str}\n"</span>
            <span class="token string">"答案: "</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> retriever<span class="token punctuation">:</span> BaseRetriever<span class="token punctuation">,</span> llm<span class="token punctuation">:</span> CustomVllmLLM<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>retriever <span class="token operator">=</span> retriever
        <span class="token comment"># self.llm = llm</span>
        self<span class="token punctuation">.</span>synthesizer <span class="token operator">=</span> CustomSynthesizer<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">custom_query</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> query_str<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        nodes <span class="token operator">=</span> self<span class="token punctuation">.</span>retriever<span class="token punctuation">.</span>retrieve<span class="token punctuation">(</span>query_str<span class="token punctuation">)</span>
        <span class="token comment"># 用检索出的Node 构造上下文</span>
        context_str <span class="token operator">=</span> <span class="token string">"\n\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>n<span class="token punctuation">.</span>node<span class="token punctuation">.</span>get_content<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> n <span class="token keyword">in</span> nodes<span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token comment"># 用上下文与查询问题组装Prompt,然后调用大模型组件响应生成</span>
        <span class="token comment"># response = self.llm.complete(</span>
        <span class="token comment">#         OnceQueryEngine.qa_prompt.format(</span>
        <span class="token comment">#               context_str=context_str, query_str=query_str</span>
        <span class="token comment">#         )</span>
        <span class="token comment"># )</span>

        <span class="token comment"># 使用自定义响应器完成响应生成</span>
        response <span class="token operator">=</span> self<span class="token punctuation">.</span>synthesizer<span class="token punctuation">.</span>get_response<span class="token punctuation">(</span>
                query_str<span class="token operator">=</span>query_str<span class="token punctuation">,</span>
                text_chunks<span class="token operator">=</span>context_str
        <span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token builtin">str</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>


<span class="token comment"># 对话查询引擎</span>
<span class="token comment"># 对chat_engine = vector_index.as_chat_engine(chat_mode="condense_question")自定义操作</span>
<span class="token keyword">class</span> <span class="token class-name">ChatQueryEngine</span><span class="token punctuation">:</span>
    custom_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
            <span class="token triple-quoted-string string">"""
            请根据以下的历史对话记录和新的输入问题，重写一个新的问题，使其能够捕捉对话中的
            所有相关上下文。
            &lt;Chat History&gt;
            {chat_history}
            &lt;Follow Up Message&gt;
            {question}
            &lt;Standalone question&gt;
            """</span>
    <span class="token punctuation">)</span>
    <span class="token comment"># 历史对话记录</span>
    custom_chat_history <span class="token operator">=</span> <span class="token punctuation">[</span>
        ChatMessage<span class="token punctuation">(</span>
                role<span class="token operator">=</span>MessageRole<span class="token punctuation">.</span>USER<span class="token punctuation">,</span>
                content<span class="token operator">=</span><span class="token string">"我们来讨论一些有关法律知识的问题"</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
        ChatMessage<span class="token punctuation">(</span>role<span class="token operator">=</span>MessageRole<span class="token punctuation">.</span>ASSISTANT<span class="token punctuation">,</span> content<span class="token operator">=</span><span class="token string">"好的"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> retriever<span class="token punctuation">:</span> BaseRetriever<span class="token punctuation">,</span> llm<span class="token punctuation">:</span> vllm<span class="token punctuation">.</span>Vllm<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>once_query_engine <span class="token operator">=</span> OnceQueryEngine<span class="token punctuation">(</span>retriever<span class="token punctuation">,</span> llm<span class="token punctuation">)</span>
        <span class="token comment"># 这种对话模式在理解历史对话记录的基础上将当前输入的问题重写成一</span>
        <span class="token comment"># 个独立的、具备完整语义的问题，然后通过查询引擎获得答案</span>
        self<span class="token punctuation">.</span>custom_chat_engine <span class="token operator">=</span> CondenseQuestionChatEngine<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span>
                query_engine<span class="token operator">=</span>self<span class="token punctuation">.</span>once_query_engine<span class="token punctuation">,</span>
                <span class="token comment"># 对话引擎基于查询引擎构造</span>
                condense_question_prompt<span class="token operator">=</span>ChatQueryEngine<span class="token punctuation">.</span>custom_prompt<span class="token punctuation">,</span>  <span class="token comment"># 设置重写问题的 Prompt 模板</span>
                chat_history<span class="token operator">=</span>ChatQueryEngine<span class="token punctuation">.</span>custom_chat_history<span class="token punctuation">,</span>
                <span class="token comment"># 携带历史对话记录</span>
                verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>custom_chat_engine<span class="token punctuation">.</span>chat_repl<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    vllm_model <span class="token operator">=</span> vllm<span class="token punctuation">.</span>Vllm<span class="token punctuation">(</span><span class="token string">'/media/xk/D6B8A862B8A8433B/data/qwen2_05b'</span><span class="token punctuation">)</span>
    <span class="token comment"># vllm_model = CustomVllmLLM('/media/xk/D6B8A862B8A8433B/data/qwen2_05b')</span>
    s <span class="token operator">=</span> CustomSynthesizer<span class="token punctuation">(</span>vllm_model<span class="token punctuation">)</span>
    res <span class="token operator">=</span> s<span class="token punctuation">.</span>get_prompts<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">)</span>
    s<span class="token punctuation">.</span>update_prompts<span class="token punctuation">(</span>PromptTemplate<span class="token punctuation">(</span><span class="token string">'fdsffds'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>get_prompts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    chat_engine <span class="token operator">=</span> ChatQueryEngine<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>custom_chat_engine
    chat_engine<span class="token punctuation">.</span>chat_repl<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <h2>
     <a id="__250">
     </a>
     三 数据加载与构建索引
    </h2>
    <p>
     我们的目标是从多个法律文档中检索有用的知识，与问题合并后一起送入大模型获得答案。
     <br/>
     为实现这一目的，我们有以下问题需要解决：
    </p>
    <ol>
     <li>
      如何读取多个不同类型的文档
     </li>
     <li>
      不同文档间知识差异很大，如交通法与刑法，如何根据问题正确检索出与问题最相关的上下文？
     </li>
    </ol>
    <p>
     下图是从原始文档到向量索引的构建过程，从2.3可以知道向量索引与检索器和查询引擎的关系，下图也有简单体现。向量索引有多种类型，最常见的是向量存储索引，下图展示就是向量存储索引。除此还有很多其他索引，比如文档摘要索引，对象索引，知识图谱索引 . . .,存在即合理，每种索引都有独特用途，也有很多复杂参数项，这也是llamaindex架构的优势，对数据操作极为精细。
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/854763f3ac26457c9259fc2f7e8a5f85.png"/>
    </p>
    <p>
     这里从路径加载数据，存在在chromadb向量库中，并构建了3种类型的向量索引。
    </p>
    <pre><code class="prism language-python"><span class="token comment"># Settings.llm=</span>
<span class="token comment"># 在vector_store_index = VectorStoreIndex(node, storage_context=storage_context)时会隐式调用</span>
Settings<span class="token punctuation">.</span>embed_model <span class="token operator">=</span> OllamaEmbedding<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"milkey/dmeta-embedding-zh:f16"</span><span class="token punctuation">)</span>
<span class="token comment"># 创建持久化的Chroma客户端</span>
chroma <span class="token operator">=</span> chromadb<span class="token punctuation">.</span>PersistentClient<span class="token punctuation">(</span>path<span class="token operator">=</span><span class="token string">"./chroma_db"</span><span class="token punctuation">)</span>
chroma<span class="token punctuation">.</span>heartbeat<span class="token punctuation">(</span><span class="token punctuation">)</span>

collection <span class="token operator">=</span> chroma<span class="token punctuation">.</span>get_or_create_collection<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"legal_knowledge_rag"</span><span class="token punctuation">)</span>
<span class="token comment"># vector_store = ChromaVectorStore(chroma_collection=collection)</span>
<span class="token comment"># 创建向量存储</span>
vector_store <span class="token operator">=</span> ChromaVectorStore<span class="token punctuation">(</span>chroma_collection<span class="token operator">=</span>collection<span class="token punctuation">)</span>


<span class="token comment"># 创建存储上下文, 准备向量存储索引</span>
<span class="token comment"># storage_context = StorageContext.from_defaults(vector_store=vector_store)</span>


<span class="token comment"># 所有文件都从这里读取</span>
<span class="token keyword">class</span> <span class="token class-name">VectorIndex</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># if not os.path.exists(file_paths):</span>
        <span class="token comment">#     raise ValueError('文件路径不存在')</span>
        <span class="token comment"># self.nodes = self.read_data(file_paths)</span>
        <span class="token keyword">pass</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">read_data</span><span class="token punctuation">(</span>file_path<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># nodes = {}</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>file_path<span class="token punctuation">}</span></span><span class="token string"> is not file'</span></span><span class="token punctuation">)</span>

        <span class="token comment"># 获得不带后缀的文件名</span>
        <span class="token comment"># file_name = file_path.split(os.sep)[-1].split('.')[0]</span>
        document <span class="token operator">=</span> SimpleDirectoryReader<span class="token punctuation">(</span>input_files<span class="token operator">=</span><span class="token punctuation">[</span>file_path<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 创建句子分割器, 对文档进行分割</span>
        spliter <span class="token operator">=</span> SentenceSplitter<span class="token punctuation">(</span>chunk_size<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
        <span class="token comment"># 从句子分割器获得节点数据</span>
        node <span class="token operator">=</span> spliter<span class="token punctuation">.</span>get_nodes_from_documents<span class="token punctuation">(</span>document<span class="token punctuation">)</span>

        <span class="token comment"># node_embedding = embed_model(node)</span>
        <span class="token comment"># vector_store.add(node_embedding)</span>
        <span class="token comment"># return {file_name: node}</span>

        <span class="token keyword">return</span> node

    <span class="token keyword">def</span> <span class="token function">create_vector_index</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> file_path<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 获得不带后缀的文件名</span>
        file_name <span class="token operator">=</span> file_path<span class="token punctuation">.</span>split<span class="token punctuation">(</span>os<span class="token punctuation">.</span>sep<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        node <span class="token operator">=</span> self<span class="token punctuation">.</span>read_data<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>

        <span class="token comment"># 将切分好的数据保存在向量库中,使用时直接从库中取</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"../chroma_db/vector_store_index/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>file_name<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'create vector index: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>file_name<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
            storage_context <span class="token operator">=</span> StorageContext<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span>vector_store<span class="token operator">=</span>vector_store<span class="token punctuation">)</span>
            <span class="token comment"># 向量存储索引, 只支持一种检索模式，就是根据向量的语义相似度来进行检索,</span>
            <span class="token comment"># 对应的检索器类型为VectorIndexRetriever</span>
            vector_store_index <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">(</span>node<span class="token punctuation">,</span> storage_context<span class="token operator">=</span>storage_context<span class="token punctuation">)</span>
            vector_store_index<span class="token punctuation">.</span>storage_context<span class="token punctuation">.</span>persist<span class="token punctuation">(</span>persist_dir<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"../chroma_db/vector_store_index/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>file_name<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'load vector index: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>file_name<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
            storage_context <span class="token operator">=</span> StorageContext<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span>
                    persist_dir<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"../chroma_db/vector_store_index/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>file_name<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">,</span>
                    vector_store<span class="token operator">=</span>vector_store
            <span class="token punctuation">)</span>
            vector_store_index <span class="token operator">=</span> load_index_from_storage<span class="token punctuation">(</span>storage_context<span class="token operator">=</span>storage_context<span class="token punctuation">)</span>

        <span class="token keyword">return</span> vector_store_index

    <span class="token keyword">def</span> <span class="token function">create_keyword_index</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> file_path<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 获得不带后缀的文件名</span>
        file_name <span class="token operator">=</span> file_path<span class="token punctuation">.</span>split<span class="token punctuation">(</span>os<span class="token punctuation">.</span>sep<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        node <span class="token operator">=</span> self<span class="token punctuation">.</span>read_data<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>

        <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"../chroma_db/keyword_index/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>file_name<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'create keyword index: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>file_name<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
            <span class="token comment"># 构造关键词表索引</span>
            kw_index <span class="token operator">=</span> KeywordTableIndex<span class="token punctuation">(</span>node<span class="token punctuation">)</span>
            kw_index<span class="token punctuation">.</span>storage_context<span class="token punctuation">.</span>persist<span class="token punctuation">(</span>persist_dir<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"../chroma_db/keyword_index/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>file_name<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'load keyword index: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>file_name<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
            storage_context <span class="token operator">=</span> StorageContext<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span>persist_dir<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"../chroma_db/keyword_index/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>file_name<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
            <span class="token comment"># 返回关键词检索器</span>
            kw_index <span class="token operator">=</span> load_index_from_storage<span class="token punctuation">(</span>storage_context<span class="token operator">=</span>storage_context<span class="token punctuation">)</span>

        <span class="token keyword">return</span> kw_index

    <span class="token keyword">def</span> <span class="token function">create_summary_index</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> file_path<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> llm<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 获得不带后缀的文件名</span>
        <span class="token comment"># file_name = file_path.split(os.sep)[-1].split('.')[0]</span>
        node <span class="token operator">=</span> self<span class="token punctuation">.</span>read_data<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>

        <span class="token comment"># 文档摘要索引与向量存储索引的最大区别是，其不提供直接对基础Node</span>
        <span class="token comment"># 进行语义检索的能力，而是提供在文档摘要层进行检索的能力，然后映射到基础Node。</span>
        <span class="token keyword">if</span> llm <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            summary<span class="token operator">=</span>DocumentSummaryIndex<span class="token punctuation">(</span>node<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            summary<span class="token operator">=</span>DocumentSummaryIndex<span class="token punctuation">(</span>node<span class="token punctuation">,</span>llm<span class="token operator">=</span>llm<span class="token punctuation">)</span>

        <span class="token keyword">return</span> summary
</code></pre>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34323437393332372f:61727469636c652f64657461696c732f313435353635333539" class_="artid" style="display:none">
 </p>
</div>


