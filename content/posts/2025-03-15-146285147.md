---
layout: post
title: "Spark-中agg的用法"
date: 2025-03-15 20:48:18 +0800
description: "【代码】Spark 中agg的用法。"
keywords: "Spark 中agg的用法"
categories: ['未分类']
tags: ['大数据', '分布式', 'Spark', 'Scala']
artid: "146285147"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146285147
    alt: "Spark-中agg的用法"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146285147
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146285147
cover: https://bing.ee123.net/img/rand?artid=146285147
image: https://bing.ee123.net/img/rand?artid=146285147
img: https://bing.ee123.net/img/rand?artid=146285147
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Spark 中agg的用法
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     <strong>
      在 Spark 中，
      <code>
       agg
      </code>
      是用于对 DataFrame 进行聚合操作的函数。它可以同时对多个列应用多个聚合函数，并返回一个新的 DataFrame。
      <code>
       agg
      </code>
      通常与
      <code>
       groupBy
      </code>
      结合使用，用于对分组后的数据进行聚合操作。
     </strong>
    </p>
    <p>
     <strong>
      以下是
      <code>
       agg
      </code>
      的详细用法和示例。
     </strong>
    </p>
    <hr/>
    <h4>
     <strong>
      1.
      <code>
       agg
      </code>
      的基本用法
     </strong>
    </h4>
    <h5>
     <strong>
      语法
     </strong>
    </h5>
    <pre><code class="language-Scala">val aggregatedDF = df.agg(
  F.sum("column1").as("total_column1"),
  F.avg("column2").as("average_column2")
)</code></pre>
    <ul>
     <li>
      <p>
       <strong>
        <code>
         F.sum("column1")
        </code>
        ：对
        <code>
         column1
        </code>
        列求和。
       </strong>
      </p>
     </li>
     <li>
      <p>
       <strong>
        <code>
         F.avg("column2")
        </code>
        ：对
        <code>
         column2
        </code>
        列计算平均值。
       </strong>
      </p>
     </li>
     <li>
      <p>
       <strong>
        <code>
         as("alias")
        </code>
        ：为聚合结果指定别名。
       </strong>
      </p>
     </li>
    </ul>
    <hr/>
    <h4>
     <strong>
      2.
      <code>
       agg
      </code>
      与
      <code>
       groupBy
      </code>
      结合使用
     </strong>
    </h4>
    <p>
     <strong>
      <code>
       agg
      </code>
      通常与
      <code>
       groupBy
      </code>
      结合使用，用于对分组后的数据进行聚合操作。
     </strong>
    </p>
    <h5>
     <strong>
      示例
     </strong>
    </h5>
    <p>
     <strong>
      假设有一个 DataFrame，包含用户的姓名、部门和工资：
     </strong>
    </p>
    <pre><code class="language-Scala">import org.apache.spark.sql.{SparkSession, functions =&gt; F}

val spark = SparkSession.builder()
  .appName("Agg Example")
  .master("local[*]")
  .getOrCreate()

// 示例数据
val data = Seq(
  ("Alice", "HR", 3000),
  ("Bob", "IT", 4000),
  ("Charlie", "HR", 3500),
  ("David", "IT", 4500),
  ("Eva", "Finance", 5000)
)

// 创建 DataFrame
val df = spark.createDataFrame(data).toDF("name", "department", "salary")

// 按部门分组，并计算工资总和、平均工资、最高工资和最低工资
val aggregatedDF = df.groupBy("department").agg(
  F.sum("salary").as("total_salary"),
  F.avg("salary").as("average_salary"),
  F.max("salary").as("max_salary"),
  F.min("salary").as("min_salary")
)

// 显示结果
aggregatedDF.show()</code></pre>
    <p>
     <strong>
      输出：
     </strong>
    </p>
    <pre><code class="language-Scala">+----------+------------+--------------+----------+----------+
|department|total_salary|average_salary|max_salary|min_salary|
+----------+------------+--------------+----------+----------+
|        HR|        6500|        3250.0|      3500|      3000|
|        IT|        8500|        4250.0|      4500|      4000|
|   Finance|        5000|        5000.0|      5000|      5000|
+----------+------------+--------------+----------+----------+</code></pre>
    <ul>
     <li>
      <p>
       <strong>
        <code>
         groupBy("department")
        </code>
        ：按部门分组。
       </strong>
      </p>
     </li>
     <li>
      <p>
       <strong>
        <code>
         agg
        </code>
        ：对每个部门计算工资总和、平均工资、最高工资和最低工资。
       </strong>
      </p>
     </li>
    </ul>
    <hr/>
    <h4>
     <strong>
      3.
      <code>
       agg
      </code>
      的多种聚合函数
     </strong>
    </h4>
    <p>
     <strong>
      <code>
       agg
      </code>
      可以同时应用多个聚合函数。以下是一些常用的聚合函数：
     </strong>
    </p>
    <table>
     <thead>
      <tr>
       <th>
        <strong>
         聚合函数
        </strong>
       </th>
       <th>
        <strong>
         描述
        </strong>
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        <strong>
         <code>
          F.sum("column")
         </code>
        </strong>
       </td>
       <td>
        <strong>
         对列求和
        </strong>
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         <code>
          F.avg("column")
         </code>
        </strong>
       </td>
       <td>
        <strong>
         计算列的平均值
        </strong>
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         <code>
          F.min("column")
         </code>
        </strong>
       </td>
       <td>
        <strong>
         计算列的最小值
        </strong>
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         <code>
          F.max("column")
         </code>
        </strong>
       </td>
       <td>
        <strong>
         计算列的最大值
        </strong>
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         <code>
          F.count("column")
         </code>
        </strong>
       </td>
       <td>
        <strong>
         统计列的非空值数量
        </strong>
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         <code>
          F.collect_list("column")
         </code>
        </strong>
       </td>
       <td>
        <strong>
         将列的值收集为列表
        </strong>
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         <code>
          F.collect_set("column")
         </code>
        </strong>
       </td>
       <td>
        <strong>
         将列的值收集为集合（去重）
        </strong>
       </td>
      </tr>
     </tbody>
    </table>
    <h5>
     <strong>
      示例
     </strong>
    </h5>
    <p>
     <strong>
      统计每个部门的员工数量、工资总和、平均工资、最高工资、最低工资，以及员工姓名列表：
     </strong>
    </p>
    <pre><code class="language-Scala">val aggregatedDF = df.groupBy("department").agg(
  F.count("name").as("employee_count"),
  F.sum("salary").as("total_salary"),
  F.avg("salary").as("average_salary"),
  F.max("salary").as("max_salary"),
  F.min("salary").as("min_salary"),
  F.collect_list("name").as("employees")
)

aggregatedDF.show(truncate = false)</code></pre>
    <p>
     <strong>
      输出：
     </strong>
    </p>
    <pre><code class="language-Scala">+----------+--------------+------------+--------------+----------+----------+----------------------+
|department|employee_count|total_salary|average_salary|max_salary|min_salary|employees             |
+----------+--------------+------------+--------------+----------+----------+----------------------+
|HR        |2             |6500        |3250.0        |3500      |3000      |[Alice, Charlie]      |
|IT        |2             |8500        |4250.0        |4500      |4000      |[Bob, David]          |
|Finance   |1             |5000        |5000.0        |5000      |5000      |[Eva]                 |
+----------+--------------+------------+--------------+----------+----------+----------------------+</code></pre>
    <hr/>
    <h4>
     <strong>
      4. 全局聚合（不分组）
     </strong>
    </h4>
    <p>
     <strong>
      如果不使用
      <code>
       groupBy
      </code>
      ，
      <code>
       agg
      </code>
      会对整个 DataFrame 进行全局聚合。
     </strong>
    </p>
    <h5>
     <strong>
      示例
     </strong>
    </h5>
    <p>
     <strong>
      计算所有员工的工资总和、平均工资、最高工资和最低工资：
     </strong>
    </p>
    <pre><code class="language-Scala">val globalAggDF = df.agg(
  F.sum("salary").as("total_salary"),
  F.avg("salary").as("average_salary"),
  F.max("salary").as("max_salary"),
  F.min("salary").as("min_salary")
)

globalAggDF.show()</code></pre>
    <p>
     <strong>
      输出：
     </strong>
    </p>
    <pre><code class="language-Scala">+------------+--------------+----------+----------+
|total_salary|average_salary|max_salary|min_salary|
+------------+--------------+----------+----------+
|       20000|        4000.0|      5000|      3000|
+------------+--------------+----------+----------+</code></pre>
    <hr/>
    <h4>
     <strong>
      5. 多列分组和聚合
     </strong>
    </h4>
    <p>
     <strong>
      可以对多列进行分组，并对多列应用聚合函数。
     </strong>
    </p>
    <h5>
     <strong>
      示例
     </strong>
    </h5>
    <p>
     <strong>
      假设有一个 DataFrame，包含用户的姓名、部门、职位和工资：
     </strong>
    </p>
    <pre><code class="language-Scala">val data = Seq(
  ("Alice", "HR", "Manager", 3000),
  ("Bob", "IT", "Developer", 4000),
  ("Charlie", "HR", "Analyst", 3500),
  ("David", "IT", "Developer", 4500),
  ("Eva", "Finance", "Manager", 5000)
)

val df = spark.createDataFrame(data).toDF("name", "department", "role", "salary")

// 按部门和职位分组，并计算工资总和和平均工资
val multiGroupDF = df.groupBy("department", "role").agg(
  F.sum("salary").as("total_salary"),
  F.avg("salary").as("average_salary")
)

multiGroupDF.show()</code></pre>
    <p>
     <strong>
      输出：
     </strong>
    </p>
    <pre><code class="language-Scala">+----------+---------+------------+--------------+
|department|     role|total_salary|average_salary|
+----------+---------+------------+--------------+
|        HR|  Manager|        3000|        3000.0|
|        IT|Developer|        8500|        4250.0|
|        HR|  Analyst|        3500|        3500.0|
|   Finance|  Manager|        5000|        5000.0|
+----------+---------+------------+--------------+</code></pre>
    <hr/>
    <h4>
     <strong>
      6. 使用表达式字符串
     </strong>
    </h4>
    <p>
     <strong>
      除了使用函数外，
      <code>
       agg
      </code>
      还支持使用表达式字符串。
     </strong>
    </p>
    <h5>
     <strong>
      示例
     </strong>
    </h5>
    <pre><code class="language-Scala">val aggregatedDF = df.groupBy("department").agg(
  "salary" -&gt; "sum",
  "salary" -&gt; "avg",
  "salary" -&gt; "max",
  "salary" -&gt; "min"
)

aggregatedDF.show()</code></pre>
    <p>
     <strong>
      输出：
     </strong>
    </p>
    <pre><code class="language-Scala">+----------+-----------+-----------+-----------+-----------+
|department|sum(salary)|avg(salary)|max(salary)|min(salary)|
+----------+-----------+-----------+-----------+-----------+
|        HR|       6500|     3250.0|       3500|       3000|
|        IT|       8500|     4250.0|       4500|       4000|
|   Finance|       5000|     5000.0|       5000|       5000|
+----------+-----------+-----------+-----------+-----------+</code></pre>
    <hr/>
    <h4>
     <strong>
      总结
     </strong>
    </h4>
    <ul>
     <li>
      <p>
       <strong>
        <code>
         agg
        </code>
        用于对 DataFrame 进行聚合操作，通常与
        <code>
         groupBy
        </code>
        结合使用。
       </strong>
      </p>
     </li>
     <li>
      <p>
       <strong>
        可以同时应用多个聚合函数，并为结果指定别名。
       </strong>
      </p>
     </li>
     <li>
      <p>
       <strong>
        支持全局聚合（不分组）和多列分组聚合。
       </strong>
      </p>
     </li>
     <li>
      <p>
       <strong>
        可以使用函数或表达式字符串定义聚合操作。
       </strong>
      </p>
     </li>
    </ul>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f36333332323132322f:61727469636c652f64657461696c732f313436323835313437" class_="artid" style="display:none">
 </p>
</div>


