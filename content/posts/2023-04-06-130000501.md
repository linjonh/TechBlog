---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f33393338383431302f:61727469636c652f64657461696c732f313330303030353031"
layout: post
title: "Chat-RECInstructRecLLM大模型用于推荐系统"
date: 2023-04-06 22:39:10 +08:00
description: "文章探讨了LLM（大型语言模型）如何增强推荐系统，提出Chat-REC方法，利用ChatGPT进行交"
keywords: "大模型 推荐系统"
categories: ['深度学习', '推荐系统']
tags: ['预训练', '深度学习', '大模型', '人工智能', 'Chatgpt']
artid: "130000501"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=130000501
    alt: "Chat-RECInstructRecLLM大模型用于推荐系统"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=130000501
featuredImagePreview: https://bing.ee123.net/img/rand?artid=130000501
---

# Chat-REC、InstructRec（LLM大模型用于推荐系统）

当众多chat-xxx和xxxGPT喷涌而出的时候，博主就在等它被做到推荐系统的这一天。本篇博文将简要看看一些文章的具体做法。

**Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender System**
  
先上地址，

* https://arxiv.org/abs/2303.14524

**LLM+推荐系统的结合点在哪？**
  
虽然大型语言模型LLM已经证明了它们用于解决各种应用任务的巨大潜力，但它和推荐系统的结合点在哪？

* 推荐系统旨在根据用户的偏好和行为向用户推荐项目。传统上，这些系统都依赖于用户数据，如点击流和购买历史等等。
* NLP在扩大推荐系统用户数据的范围方面是有价值的。比如NLP技术可以用于分析用户生成的内容，如评论和社交媒体帖子，以深入了解用户的偏好和兴趣，提高整体用户体验和参与度。

然而，传统的推荐系统仍然面临着巨大的挑战，如
**缺少交互性、可解释性，缺乏反馈机制，以及冷启动和跨域推荐**
等长期问题。但LLM的出现为这些挑战提供了一个很有前途的解决方案。

* LLM可以生成更自然和可解释的建议，从而可以解决冷启动问题，并执行跨领域推荐。
* LLM具有更强的交互性和反馈机制，完全可以增强整体用户体验。
* 通过利用海量参数所承载的内部知识，LLM可以依靠外部检索器以进一步提高推荐系统的性能 。

推荐系统任务被制定为基于提示的自然语言任务，其中user-item信息和相应的特征与个性化的提示模板集成作为模型输入。然而，在目前的研究中，LLM仍然作为模型的一部分需要参与训练（不过博主个人观点并不觉得这是比较大的缺点，利用通用模型的能力+小部分参数训练到垂直领域效果一定更有保证，更多可以参考博主之前的文章门）。

* [提示学习用于推荐系统问题（PEPLER，P5，PRL）](https://nakaizura.blog.csdn.net/article/details/124558817)
* [提示学习用于推荐系统问题（PPR，PFRec）](https://nakaizura.blog.csdn.net/article/details/126572223)

在这篇文章中，作者介绍了一种新的方法来做
**会话推荐系统**
（从而能与LLM更紧密的结合），它具有交互式和可解释的能力，即LLMs 增强传统推荐的范式 Chat-Rec（ChatGPT Augmented Recommender System），不需要训练（
**本质就是直接拿chatGPT做接口，设计预/后处理**
），而是只依赖于上下文学习，从而产生更有效的结果。

* 使用LLM增强的推荐系统，有利于在对话过程中了解用户的偏好。
* 在对话的每一步之后，可以迭代用户偏好，更新候选推荐结果。
* 此外，用户与产品之间的偏好是紧密链接的，从而允许更好的跨领域产品推荐。

Chat-Rec的模型结构如下图所示，

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/3f26a39086dade0f38a2ee847c269101.png#pic_center)

左边是用户和 ChatGPT 之间的对话。中间是Chat-Rec的主要贡献，即链接推荐系统和 ChatGPT。右边是策略执行具体过程，即

* 对于一个用户query：“你能推荐一些动作片给我吗？”。
* 确定这个query是否是一个推荐任务【ChatGPT来判断】
* + 如果是推荐任务，则使用该输入来执行“推荐动作电影”模块。但由于推荐空间是巨大的，所以该模块需要分为两个步骤：1推荐系统产生一个少量的候选得到top20的推荐结果，2然后再进行重新排序和调整【ChatGPT来重排】，以生成top5的最终输出。这种方法可以确保向用户展示一个更小、更相关的物品集，增加他们找到自己喜欢的东西的可能性。
* + 如果不是推荐任务，如用户询问“为什么会推荐你会推荐fargo电影给我”。系统将使用电影标题、历史记录交互和用户配置文件作为输入来执行对推荐模块的解释【ChatGPT来生成解释】。

由于ChatGPT的输入是自然语言文本，所以中间模块的主要目标就是如何利用用户与物品的历史交互、用户档案、用户查询和对话历史 （如果有的话）等等多个输入ChatGPT来生成一个自然语言段落，以捕捉用户的查询和推荐信息。

* User-item history interactions：用户与物品的历史交互，指的是用户过去与物品的互动，比如他们点击过的物品，购买过的物品，或者评价过的物品。
* User profile：用户画像，其中包含关于用户的人口统计和偏好信息，如年龄、性别、地点和兴趣。
* User query

  Q
  i
  Q_i






  Q









  i

  ​

  ：查询句子，可能是推荐任务也可能是通用任务。
* History of dialogue

  H
  <
  i
  H_{<i}






  H










  <

  i

  ​

  ：用户和chatGPT之间的所有上下文对话。

对于topk推荐任务来说，生成的prompt例子是：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/36d28c25badd06de50c88bbcee4c3d7d.png#pic_center)
  
对于评分任务来说，生成的prompt例子是：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/b9a1fa4636a1acf549765b3065f9e474.png#pic_center)

---

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/2f774a2af8522a085efcae3cf60adab8.png#pic_center)
  
**如何解决冷启动**
  
大模型中拥有很多知识，利用商品的文字描述就能够借助LLM的力量来帮助推荐系统缓解新项目的冷启动问题，即没有大量用户互动也可以得到embedding。

如上图所示，最上展示了两种chatGPT难以执行推荐场景：

* 1 让不能联网的chatGPT推荐2023最新的动作电影；
* 2 让chatGPT推荐一个它知识储备中没有的动作电影。

因此，作者们的做法是离线利用LLM来生成相应的embedding表征并进行缓存。从而在当chatGPT遇到新的物品推荐时，会首先计算离线商品特征和用户query特征之间的相似性，然后检索最相关商品一起输入到 ChatGPT 进行推荐。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/a168aa7b7294451749babd0f65cc5fca.png#pic_center)

**如何解决跨域推荐**
  
类似的，LLM中的知识可以很方便对不同领域的商品有认知，如电影，音乐和书籍等等，并且还能够分清楚在不同领域产品之间的关系。

因此，如上图所示，作者们的做法是直接依靠chatGPT啦，把上下文对话输入一起编码进chatGPT的输入后，就能在用户询问关于其他类型作品的建议时，实现跨域推荐，如对书籍、电视剧、播客和视频游戏进行推荐。

---

**实验**
  
backbone选了GPT-3 和 GPT-3.5 系列中的三个模型

* gpt-3.5-turbo，即chatGPT。
* text-davinci-003。
* text-davinci-002。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/de413a1e21c266e5bc5e37d996df0d11.png#pic_center)
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/86544e81d7a5cf743680232aceba513b.png#pic_center)

从top5推荐和评分预测这个俩结果上来看，似乎text-davinci-003才是最好的。。

可能说明基础表征能力够了，对这俩任务来说是足够的。不过作者没有其他任务的实验结果，比如上面说的冷启动、跨域、可解释似乎都无，继续观望吧。

---

**InstructRec**
  
补一篇InstructRec，先上地址：

* paper：Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach
* arxiv：https://arxiv.org/pdf/2305.07001.pdf

motivation主要在于，利用LLM的用户推荐可以方便用户的偏好或需求可以用自然语言描述来表达，因此instruct tuning是非常适合的方案。

因此，作者在开源LLM（3B的 Flan-T5-XL）进行指令调优来适应推荐系统。模型流程如下图所示，用户直接给出instructions如“I prefer”，然后历史记录和用户指定将一起输入formulation模块中生成模型能够理解的instructions形式，然后输入到大模型中，最后可以完成各种任务如sequential recommendation、product search、personalized search等。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/af49809a0f516014c44d80bdc318f3f6.png#pic_center)
  
因此，该工作最重要的模块就是通用指令的设计，以全面地描述用户的偏好、意图、任务形式。

* 偏好（Preference）。指用户偏好。其中隐式偏好用商品标题而非id，显式偏好用用户query中的明确表达（如用户评论），而不是之前的评分或点赞。
* 意图（Intention）。指用户对某些类型的物品的需求。模糊的意图如“给我儿子的一些礼物”、具体的意图如“蓝色、便宜、iPhone13”）。
* 任务形式（Task Form）。要做到统一的推荐系统的话，需要有适应各种任务的能力。
    
  Pointwise。某个候选商品是否适合用户，那么直接用用户需求和商品特征来匹配。
    
  Pairwise。让LLM从item pairs中选择更合适的一个即可。
    
  Matching。召回模块，LLM从整个商品语料库中生成候选集合。
    
  Reranking。排序模块，LLM从候选中重排序商品。

各个维度如下图所示：

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/2b78f30324dc601824d93d3c1226f254.png#pic_center)
  
根据指令格式和作者们手动设计了39个指令模板，就可以通过交互数据来生成指令数据了。作者们使用自动提示策略，利用GPT-3.5来生成指令，即通过输入每个用户的历史互动和评论，然后生成个性化的指令。最后生成了共252K条指令。