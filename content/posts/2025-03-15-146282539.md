---
layout: post
title: "K8S下nodelocaldns-crash问题导致域名请求响应缓慢"
date: 2025-03-15 19:43:38 +0800
description: "实际上这个问题并不是应用的问题，是平台搭建的时候就有问题，但是仅仅是nodelocaldns并不影响最终的结果，毕竟coredns还是正常的，所以仅仅是超时，对于业务研发人员，K8S里面的逻辑是不可见的，所以问题很难解决，最终需要应用分析，抓包和基础设施层共同配合才能解决问题。"
keywords: "K8S下nodelocaldns crash问题导致域名请求响应缓慢"
categories: ['架构设计', 'Kubernates', 'K']
tags: ['容器', 'Kubernetes', 'Docker']
artid: "146282539"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146282539
    alt: "K8S下nodelocaldns-crash问题导致域名请求响应缓慢"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146282539
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146282539
cover: https://bing.ee123.net/img/rand?artid=146282539
image: https://bing.ee123.net/img/rand?artid=146282539
img: https://bing.ee123.net/img/rand?artid=146282539
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     K8S下nodelocaldns crash问题导致域名请求响应缓慢
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     前言
    </h2>
    <p>
     最近做项目，有业务出现偶发的部署导致响应很慢的情况，据了解，业务使用域名访问，相同的nginx代理，唯一的区别就是K8S重新部署了。那么问题大概率出现在容器平台，毕竟业务是重启几次正常，偶尔一次很慢，又并不是不能返回。这里就很奇特，现象是少部分节点和请求超时，并不是失败。
    </p>
    <h2>
     排查过程
    </h2>
    <p>
     出现问题，根据端到端的全链路原则
    </p>
    <h3>
     应用检查
    </h3>
    <p>
     第一时间排查了应用本身，应用是Java写的，所以通过jstack -l pid
    </p>
    <p>
     <img alt="" height="128" src="https://i-blog.csdnimg.cn/direct/002aa3306faf422c8263617f93b1be1e.png" width="623"/>
    </p>
    <p>
     这里出现IPV6了，实际上基本使用都是IPV4，当然IPV6也在普及，毕竟IP数量大。
    </p>
    <p>
     发现应用大面积的出现类似dns解析的线程栈，那么可以断定问题出在域名解析环节。
    </p>
    <h3>
     抓包
    </h3>
    <p>
     而此时 通过抓包，发现pod在做域名解析时，调用node节点的localdns出现clash状态
    </p>
    <p>
     笔者本地抓包：wireshark：sudo chown 用户名:admin /dev/bpf*（伯克利包过滤器）
    </p>
    <p>
     如果是服务器，则执行tcpdump：tcpdump -i any -s0 port 53 -w app.cap
    </p>
    <blockquote>
     <p>
      tcpdump命令：
     </p>
     <p>
      -s number 表示需要截取报文字节数（tcpdump默认只会截取前96个字节），如果是0的话，表示截取报文全部内容
     </p>
     <p>
      -i 指定网卡，any表示所有
     </p>
     <p>
      port 指定端口
     </p>
     <p>
      host 指定ip
     </p>
     <p>
      -w app.cap 写入xxx文件
     </p>
     <p>
      当然也可以指定协议，不指定默认所有协议
     </p>
    </blockquote>
    <p>
     域名一般是80端口，所以这里写的80，笔者本地dockerdesktop默认没有localdns的，且coredns正常。
    </p>
    <p>
     <img alt="" height="88" src="https://i-blog.csdnimg.cn/direct/c7a88f8dfcf243329257535978908557.png" width="1976"/>
    </p>
    <p>
     以访问qq网站为例，这里就localdns正常，如果异常，那么抓包就会发现
    </p>
    <p>
     cluster.local的解析报错情况。此时重启nodelocaldns即可正常。
    </p>
    <h3>
     nodelocaldns
    </h3>
    <p>
     <code>
      NodeLocal DNSCache
     </code>
     是一套 DNS 本地缓存解决方案。
     <strong>
      NodeLocal DNSCache 通过在集群节点上运行一个 DaemonSet 来提高集群 DNS 性能和可靠性
     </strong>
     。
    </p>
    <p>
     <img alt="" height="410" src="https://i-blog.csdnimg.cn/direct/a828f65ce794428fb0f4a7dfeee98308.png" width="492"/>
    </p>
    <p>
     根据官方文档：
     <a href="https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/nodelocaldns/" rel="nofollow" title="在 Kubernetes 集群中使用 NodeLocal DNSCache | Kubernetes">
      在 Kubernetes 集群中使用 NodeLocal DNSCache | Kubernetes
     </a>
    </p>
    <p>
     通过日志查询使用iptables还是ipvs
    </p>
    <pre><code>kubectl logs -n kube-system $(kubectl get pods -n kube-system | grep kube-proxy | awk '{print $1}')  
</code></pre>
    <p>
     日志
    </p>
    <pre><code class="language-bash">huahua@huahuadeMacBook-Pro kube % kubectl logs -n kube-system $(kubectl get pods -n kube-system | grep kube-proxy | awk '{print $1}')

I0315 09:17:47.935227       1 server_others.go:72] "Using iptables proxy"
I0315 09:17:48.037793       1 server.go:1050] "Successfully retrieved node IP(s)" IPs=["192.168.65.3"]
I0315 09:17:48.037978       1 conntrack.go:118] "Set sysctl" entry="net/netfilter/nf_conntrack_tcp_timeout_established" value=86400
I0315 09:17:48.038086       1 conntrack.go:118] "Set sysctl" entry="net/netfilter/nf_conntrack_tcp_timeout_close_wait" value=3600
I0315 09:17:48.197513       1 server.go:652] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0315 09:17:48.197663       1 server_others.go:168] "Using iptables Proxier"
I0315 09:17:48.203123       1 server_others.go:503] "Detect-local-mode set to ClusterCIDR, but no cluster CIDR defined"
I0315 09:17:48.203166       1 server_others.go:529] "Defaulting to no-op detect-local"
I0315 09:17:48.203182       1 server_others.go:503] "Detect-local-mode set to ClusterCIDR, but no cluster CIDR defined"
I0315 09:17:48.203198       1 server_others.go:529] "Defaulting to no-op detect-local"
I0315 09:17:48.203847       1 proxier.go:246] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0315 09:17:48.207807       1 server.go:865] "Version info" version="v1.29.1"
I0315 09:17:48.207983       1 server.go:867] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0315 09:17:48.215566       1 config.go:188] "Starting service config controller"
I0315 09:17:48.215736       1 shared_informer.go:311] Waiting for caches to sync for service config
I0315 09:17:48.215774       1 config.go:97] "Starting endpoint slice config controller"
I0315 09:17:48.215795       1 config.go:315] "Starting node config controller"
I0315 09:17:48.215803       1 shared_informer.go:311] Waiting for caches to sync for node config
I0315 09:17:48.215827       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0315 09:17:48.316912       1 shared_informer.go:318] Caches are synced for node config
I0315 09:17:48.316968       1 shared_informer.go:318] Caches are synced for service config
I0315 09:17:48.317142       1 shared_informer.go:318] Caches are synced for endpoint slice config</code></pre>
    <p>
     可以看到笔者本地使用的iptables，当然ipvs性能更强，实际生产应该使用ipvs
    </p>
    <p>
     Using iptables proxy
    </p>
    <p>
     根据官方文档，笔者使用iptables安装的node-local-dns
    </p>
    <p>
     <img alt="" height="54" src="https://i-blog.csdnimg.cn/direct/94e0d72066ab43be868109cfa57956c4.png" width="421">
     </img>
    </p>
    <p>
     笔者试着干掉localdns，但是因为是deamonset，干掉又自动重建了pod，复现也很简单，把配置写错运行nodelocaldns，比如网上出现的循环解析dns的IP，pod就会处于
     <strong>
      CrashLoopBackOff
     </strong>
     状态，重建不成功，发现问题后，修改相应配置即可解决。
    </p>
    <h2>
     总结
    </h2>
    <p>
     实际上这个问题并不是应用的问题，是平台搭建的时候就有问题，但是仅仅是nodelocaldns并不影响最终的结果，毕竟coredns还是正常的，所以仅仅是超时，对于业务研发人员，K8S里面的逻辑是不可见的，所以问题很难解决，最终需要应用分析，抓包和基础设施层共同配合才能解决问题。
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f:2f626c6f672e6373646e2e6e65742f66656e676c6c6c6c652f:61727469636c652f64657461696c732f313436323832353339" class_="artid" style="display:none">
 </p>
</div>


