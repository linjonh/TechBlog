---
arturl_encode: "68747470:733a2f2f626c6f672e6373646e2e6e65742f706b7831393933:2f61727469636c652f64657461696c732f3831363639363833"
layout: post
title: "音视频的同步机制"
date: 2024-11-29 17:28:50 +08:00
description: "1.   音视频同步的原理 2.  音视频同步的较正方法 3.  音视频同步时遇到的问题声明：以下所"
keywords: "播出同步机制"
categories: ['音视频原理']
tags: ['无标签']
artid: "81669683"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=81669683
    alt: "音视频的同步机制"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=81669683
featuredImagePreview: https://bing.ee123.net/img/rand?artid=81669683
---

# 音视频的同步机制

1.   音视频同步的原理

2.  音视频同步的较正方法

3.  音视频同步时遇到的问题

声明：以下所有内容均为转载

1.原文转自：
<http://bbs.chinavideo.org/viewthread.php?tid=1183&extra=page%3D1%26amp%3Bfilter%3Ddigest&page=1>

下面贴出部分：

音视频同步这一块，我一直不是很了解，很想尝试一下，下面是在qq群上向诸位前人请教的会话记录，因为对我这样的初学者很有帮助，所以粘贴至此，以作备份，再次感谢热心回答问题的人，尤其是(不做好人！)^\_^；
  
  
2006-10-25 10:21:06  dophin
  
有人有实时编码时对音视频进行录制时，音视频如何同步的相关资料么？有相关网站也可以哈，我实在找不到相关资料了。。。
  
2006-10-25 10:25:42  dophin
  
或者具体一点的也行，比如音视频到底是如何同步的，有书籍介绍也可以啊，先谢了哈。。。。
  
(人众人)  2006-10-25 10:21:45
  
通过时间戳
  
(人众人)  2006-10-25 10:21:49
  
我也在研究这个问题
  
( 新左派)  2006-10-25 10:21:56
  
以音频时间为主
  
(人众人)  2006-10-25 10:22:01
  
对
  
(不做好人！)  2006-10-25 10:22:08
  
新左派讲对了。
  
(不做好人！)  2006-10-25 10:22:14
  
声音图象交错发送。
  
( 新左派)  2006-10-25 10:22:43
  
视频解码时，按当前播放时间找到对应的视频帧
  
(不做好人！)  2006-10-25 10:22:44
  
可以一个音频包有N个图象。就在这一个音频包完成的过程中按帧率显示图象。
  
(dophin)  2006-10-25 10:28:39
  
嗯，那么音频又是以什么为主呢？毕竟，音频的播放也是和时间有关系的，音频在播放时就是只管自己播放就行么？
  
(不做好人！)  2006-10-25 10:24:05
  
声卡有时间同步处理机制的。
  
(不做好人！)  2006-10-25 10:24:32
  
我以前的电脑主板如果驱动没有装好。声音就非常快。结果图象也是一闪就过去了。
  
( 新左派)  2006-10-25 10:24:47
  
声音正常解码与播放啊
  
(不做好人！)  2006-10-25 10:25:05
  
是WINDOWS MEDIAPLAYER播放的。只有驱动装好了。能正确驱动的时候声卡有时钟同步功能的。
  
( 新左派)  2006-10-25 10:25:14
  
只是视频的解码需要参照当前的声音的时间
  
(不做好人！)  2006-10-25 10:25:16
  
所以声音和图象交错，
  
( 新左派)  2006-10-25 10:25:36
  
声音播放时，是不用管什么的，就是单独的声音解码
  
(dophin)  2006-10-25 10:32:16
  
哦，我现在大脑中大致有点模型了，就是音频只管自己播放就行，视频根据自己本身带的时间戳与但前系统时间和音频时间进行比较，然后解码播放，如此实现同步，这么理解对么？
  
(不做好人！)  2006-10-25 10:28:00
  
你是用什么系统？
  
(dophin)  2006-10-25 10:33:26
  
声音和图像交错是什么意思？这两个不是开两个线程完成的么？不存在交错问题啊，即使存在，也是操作系统级的吧 ？
  
(不做好人！)  2006-10-25 10:28:35
  
AVVVVVVVVVVVVVVVAVVVVVVVVVVVVVVV
  
(dophin)  2006-10-25 10:33:42
  
我得，linux。。。
  
(不做好人！)  2006-10-25 10:28:52
  
当你放A的时候，直接交给声卡。
  
(不做好人！)  2006-10-25 10:29:30
  
中间的V就是前后两个声音包的相差时间，你就算出平均速度
  
(dophin)  2006-10-25 10:35:35
  
算出 平均速度后，得出每sec放几帧，然后播放v，是这样么？
  
(不做好人！)  2006-10-25 10:30:54
  
对
  
(不做好人！)  2006-10-25 10:31:01
  
你声音有一个采样率吧。
  
(dophin)  2006-10-25 10:36:02
  
对，有，
  
(不做好人！)  2006-10-25 10:31:23
  
这就可以算出前后一个声音的时间了对不？
  
(不做好人！)  2006-10-25 10:31:36
  
比如44.1K/S
  
(dophin)  2006-10-25 10:36:36
  
对，
  
(不做好人！)  2006-10-25 10:31:56
  
那你从DSP中读取22.05K的数据是不是0.5?
  
(dophin)  2006-10-25 10:37:05
  
是，
  
(不做好人！)  2006-10-25 10:32:29
  
那在这段0.5秒钟的时间内你获取了15帧的数据。那你是不是0.5/15=0.03333秒钟就刷新一副图。
  
(dophin)  2006-10-25 10:37:49
  
没错。
  
(不做好人！)  2006-10-25 10:32:55
  
然后你再读取下一个声音和图象包。再这样搞。就可以了啦。不过前提条件你采集必须是同步的。
  
(不做好人！)  2006-10-25 10:33:11
  
对了。你是用嵌入式的吗？
  
(不做好人！)  2006-10-25 10:33:25
  
这个是以声音为基础的。
  
(不做好人！)  2006-10-25 10:34:04
  
还有一种是设置时钟，计算你的帧率来设置前后帧的时间，中间有误差就延时或者是跳跃一下。声音就另外单独管理。
  
(不做好人！)  2006-10-25 10:34:21
  
看看ffmpeg 的fplay.c，里面的源程序讲得很详细了。
  
(dophin)  2006-10-25 10:40:12
  
我的不是embedded
  
(dophin)  2006-10-25 10:40:24
  
就是普通pc机，
  
(不做好人！)  2006-10-25 10:36:08
  
哦。那你看fplay.c吧。里面很详细的有声音和图象的同步。虽然简单了一点。但麻雀虽小五脏俱全。
  
(dophin)  2006-10-25 10:41:54
  
哦，太好了，采集这一块，我基本明白了，播放我想也应该差不多，我自己试试看看，太感谢了你了哈。。。^\_^
  
(不做好人！)  2006-10-25 10:37:14
  
别谢谢我。
  
(不做好人！)  2006-10-25 10:37:24
  
不过我做的方法是按照fplay.c里面的做的。
  
(dophin)  2006-10-25 10:42:23
  
好的，我马上就看看fplay。c，以前没有看是因为感觉他的播放效果不如mplayer，
  
(不做好人！)  2006-10-25 10:38:06
  
这个是简化了的啦。当然比不上mplayer

2.

mplayer播放时的大循环过程为：
  
while(!mpctx->eof){
  
fill\_audio\_out\_buffers();//音频stream的读取，解码，播放
  
update\_video(&blit\_frame);//视频stream的读取，解码，过滤处理
  
sleep\_until\_update(&time\_frame, &aq\_sleep\_time);//计算延迟时间并睡眠等待
  
mpctx->video\_out->flip\_page()；//视频的播放
  
adjust\_sync\_and\_print\_status(frame\_time\_remaining, time\_frame);//根据音视频的PTS做同步矫正处理
  
}
  
  
音视频同步方法为
  
1）音频播放playsize = mpctx->audio\_out->play(sh\_audio->a\_out\_buffer, playsize,  playflags);  后，根据数据大小算出时间并累计
  
mpctx->delay += playback\_speed*playsize/(double)ao\_data.bps;
  
2）视频解码前，用累计延迟时间剪掉本祯视频的时间mpctx->delay -= frame\_time;
  
3）计算声音延迟时间*time\_frame = delay - mpctx->delay / playback\_speed;
  
其中float delay = mpctx->audio\_out->get\_delay();为距当前声音OUTPUT BUF里数据被全部播放完为止所需的时间。
  
4）播放视频同步完成，所以视频的播放是完全根据声卡最后的数据输出来同步的。
  
5）计算出当前音视频PTS差double AV\_delay = a\_pts - audio\_delay - v\_pts;再算出矫正值x = (AV\_delay + timing\_error * playback\_speed) * 0.1f;最后把矫正的时间加到延迟累计中mpctx->delay+=x;。

3.

这几天搞文件回放，视频格式是H264，音频是PCM，使用FFMPEG来读取音视频，然后用ffmpeg来解码显示，所有的一切还算顺利，但音视频同步花了我很多时间，总也搞不清楚为什么会差很多。音视频同步的原理当然是根据音频的pts来控制视频的播放，也就是说在视频解码一帧后，是否显示以及显示多长时间是通过该帧的PTS与同时正在播放的音频的PTS比较而来的，如果音频的PTS较大，则视频显示完毕准备下一帧的解码显示，否则等待。
  
具体实现时遇到的问题一：没办法得到正在播放的音频帧的PTS，因为进行音频播放使用的DirectSound，而对于DirectSound我只能得到当前拷入DirectSound的缓存的帧的PTS，而无法得到正在播放的PTS，如果得不到正在播放的帧的PTS的话，那同步肯定是不可能的了。在网上找资料好象也没找到有用的，最后突然想到由于音频帧的大小与时间成正比，那么DirectSound的缓存中的数据所需要的播放时间就可以计算得出，再根据当前正在拷入的音频帧的PTS，就可以得到正在播放的帧的PTS，再用这个就可以正确同步视频帧的显示了。
  
问题二：根据上面的方法处理后还是出现不同步的现象，为什么这样我也是百思不得其解，后来才发现是等待机制有问题，原来我是用Sleep()来做等待的，但实际上Sleep()的误差很大的，网上有说有15MS，做音视频同步肯定是不行的了，经过不断的google，找到一份代码：
  
void MySleep(int interval)
  
{
  
LARGE\_INTEGER litmp;
  
LONGLONG QPart1,QPart2;
  
double dfMinus, dfFreq, dfTim;
  
QueryPerformanceFrequency(&litmp);
  
dfFreq = (double)litmp.QuadPart;// 获得计数器的时钟频率
  
QueryPerformanceCounter(&litmp);
  
QPart1 = litmp.QuadPart;// 获得初始值

do
  
{
  
QueryPerformanceCounter(&litmp);
  
QPart2 = litmp.QuadPart;//获得中止值
  
dfMinus = (double)(QPart2-QPart1);
  
dfTim = dfMinus / dfFreq;// 获得对应的时间值，单位为秒
  
}while(dfTim<0.001 * interval);
  
}
  
可以达到精度比较高的等待，从效果看，也可以达到音视频同步。
  
本以为问题到这就算结束了，但程序运行的时候怎么发现机器这么慢呀，看了下CPU占用率，达到100%。很显然使用这个做等待是不行的了。
  
于是继续google，网上有说timesetevent什么的，我没有试。感觉麻烦了些。后来想到以前看过的一篇用WaitForSingleObject来做定时让某段代码执行的，于是试了试，一试之下立即发现效果明显，CPU占用率一下子回到了个位数。更改后的代码如下：
  
void MySleep(int interval)
  
{
  
HANDLE evt;
  
evt = CreateEvent(NULL, TRUE, FALSE, NULL);
  
WaitForSingleObject(evt, interval);
  
CloseHandle(evt);
  
}

转自：
<http://blog.csdn.net/allentangtg/article/details/6873681>