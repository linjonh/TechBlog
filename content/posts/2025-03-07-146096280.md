---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f35353834333932312f:61727469636c652f64657461696c732f313436303936323830"
layout: post
title: "深度学习网格搜索实战"
date: 2025-03-07 15:06:09 +08:00
description: "还是使用房价数据集进行实战。因为模型简单，使用超参数搜索的时候速度快。"
keywords: "深度学习网格搜索实战"
categories: ['Pytorch']
tags: ['深度学习', '人工智能']
artid: "146096280"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146096280
    alt: "深度学习网格搜索实战"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146096280
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146096280
cover: https://bing.ee123.net/img/rand?artid=146096280
image: https://bing.ee123.net/img/rand?artid=146096280
img: https://bing.ee123.net/img/rand?artid=146096280
---

# 深度学习网格搜索实战

还是使用房价数据集进行实战。因为模型简单，使用超参数搜索的时候速度快。

在之前的回归代码的基础上加入for循环：

```python
for lr in [1e-2, 3e-2, 3e-1, 1e-3]: # 把参数组合放在这，参数代表学习率
    #每次拿一个参数就要重新实例化一个模型
    epoch = 100
    model = NeuralNetwork()

    # 1. 定义损失函数 采用MSE损失
    loss_fct = nn.MSELoss()
    # 2. 定义优化器 采用SGD
    # Optimizers specified in the torch.optim package
    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)

    # 3. early stop
    early_stop_callback = EarlyStopCallback(patience=10, min_delta=1e-3)

    model = model.to(device)
    record = training(
        model, 
        train_loader, 
        val_loader, 
        epoch, 
        loss_fct, 
        optimizer, 
        early_stop_callback=early_stop_callback,
        eval_step=len(train_loader)
        )
    print("lr: {}".format(lr))
    plot_learning_curves(record)
    model.eval()
    loss = evaluating(model, val_loader, loss_fct)
    print(f"loss:     {loss:.4f}")
```

效果：

![](https://i-blog.csdnimg.cn/direct/a2bbc31e07bf4e9985ae4c86e768b35e.png)
![](https://i-blog.csdnimg.cn/direct/ddbb8f1ed0ec4557b0be774f7c82ede2.png)

![](https://i-blog.csdnimg.cn/direct/9fe2251033a8403ab0dfe37d66f6139d.png)
![](https://i-blog.csdnimg.cn/direct/ae16d4e599734d4699677e41600e5f68.png)