---
layout: post
title: "kafka小白基础知识"
date: 2025-02-24 10:27:08 +0800
description: "Kafka 是一个开源的分布式流处理平台，最初由 LinkedIn 开发，后来贡献给了 Apache 软件基金会。它被设计用于处理实时数据流，具有高吞吐量、可扩展性、持久性和容错性等特点。Kafka 主要用于构建实时数据管道和流式应用程序，如日志收集、消息系统、事件驱动架构等。"
keywords: "kafka小白基础知识"
categories: ['未分类']
tags: ['分布式', 'Kafka']
artid: "145822177"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145822177
    alt: "kafka小白基础知识"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145822177
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145822177
cover: https://bing.ee123.net/img/rand?artid=145822177
image: https://bing.ee123.net/img/rand?artid=145822177
img: https://bing.ee123.net/img/rand?artid=145822177
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     kafka小白基础知识
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h3>
     一、Kafka 入门
    </h3>
    <h4>
     （一）Kafka 简介
    </h4>
    <p>
     Kafka 是一个开源的分布式流处理平台，最初由 LinkedIn 开发，后来贡献给了 Apache 软件基金会。它被设计用于处理实时数据流，具有高吞吐量、可扩展性、持久性和容错性等特点。Kafka 主要用于构建实时数据管道和流式应用程序，如日志收集、消息系统、事件驱动架构等。
    </p>
    <h4>
     （二）核心概念
    </h4>
    <ol>
     <li>
      <strong>
       主题（Topic）
      </strong>
      ：Kafka 中的消息以主题为单位进行分类，类似于数据库中的表。生产者将消息发送到特定的主题，消费者从主题中读取消息。
     </li>
     <li>
      <strong>
       分区（Partition）
      </strong>
      ：每个主题可以被划分为多个分区，分区是 Kafka 实现高吞吐量和可扩展性的关键。消息在分区内是有序的，但在整个主题中不一定有序。
     </li>
     <li>
      <strong>
       生产者（Producer）
      </strong>
      ：负责将消息发送到 Kafka 主题的应用程序。生产者可以根据需要选择将消息发送到特定的分区。
     </li>
     <li>
      <strong>
       消费者（Consumer）
      </strong>
      ：从 Kafka 主题中读取消息的应用程序。消费者可以以组的形式存在，同一个组内的消费者共同消费主题中的消息，每个分区只能被组内的一个消费者消费。
     </li>
     <li>
      <strong>
       代理（Broker）
      </strong>
      ：Kafka 集群中的每个服务器节点称为代理。代理负责存储和管理分区的数据，并处理生产者和消费者的请求。
     </li>
    </ol>
    <h4>
     （三）安装与启动
    </h4>
    <h5>
     1. 下载 Kafka
    </h5>
    <p>
     从 Apache Kafka 官方网站（
     <a href="https://kafka.apache.org/downloads" rel="nofollow" title="Apache Kafka">
      Apache Kafka
     </a>
     ）下载最新版本的 Kafka。
    </p>
    <h5>
     2. 解压文件
    </h5>
    <p>
     bash
    </p>
    <pre><code>tar -zxvf kafka_2.13 - 3.4.0.tgz
cd kafka_2.13 - 3.4.0
</code></pre>
    <h5>
     3. 单机安装与启动
    </h5>
    <h6>
     启动 ZooKeeper
    </h6>
    <p>
     Kafka 使用 ZooKeeper 来管理集群的元数据，首先启动 ZooKeeper：
    </p>
    <p>
     bash
    </p>
    <pre><code>bin/zookeeper-server-start.sh config/zookeeper.properties
</code></pre>
    <h6>
     启动 Kafka 代理
    </h6>
    <p>
     bash
    </p>
    <pre><code>bin/kafka-server-start.sh config/server.properties
</code></pre>
    <h5>
     4. 集群安装与启动
    </h5>
    <h6>
     环境准备
    </h6>
    <p>
     假设我们要搭建一个包含 3 个节点的 Kafka 集群，节点的 IP 地址分别为
     <code>
      192.168.111.2
     </code>
     、
     <code>
      192.168.111.3
     </code>
     、
     <code>
      192.168.111.4
     </code>
     。在每个节点上都需要完成 Kafka 的下载和解压操作。
    </p>
    <h6>
     修改配置文件
    </h6>
    <p>
     在每个节点上修改
     <code>
      config/server.properties
     </code>
     文件：
    </p>
    <ul>
     <li>
      <strong>
       节点 1（192.168.111.2）
      </strong>
     </li>
    </ul>
    <p>
     properties
    </p>
    <pre><code>broker.id=0
listeners=PLAINTEXT://192.168.111.2:9092
advertised.listeners=PLAINTEXT://192.168.111.2:9092
zookeeper.connect=192.168.111.2:2181,192.168.111.3:2181,192.168.111.4:2181
</code></pre>
    <ul>
     <li>
      <strong>
       节点 2（192.168.111.3）
      </strong>
     </li>
    </ul>
    <p>
     properties
    </p>
    <pre><code>broker.id=1
listeners=PLAINTEXT://192.168.111.3:9092
advertised.listeners=PLAINTEXT://192.168.111.3:9092
zookeeper.connect=192.168.111.2:2181,192.168.111.3:2181,192.168.111.4:2181
</code></pre>
    <ul>
     <li>
      <strong>
       节点 3（192.168.111.4）
      </strong>
     </li>
    </ul>
    <p>
     properties
    </p>
    <pre><code>broker.id=2
listeners=PLAINTEXT://192.168.111.4:9092
advertised.listeners=PLAINTEXT://192.168.111.4:9092
zookeeper.connect=192.168.111.2:2181,192.168.111.3:2181,192.168.111.4:2181
</code></pre>
    <p>
     配置说明：
    </p>
    <ul>
     <li>
      <code>
       broker.id
      </code>
      ：每个 Kafka 代理的唯一标识符，不能重复。
     </li>
     <li>
      <code>
       listeners
      </code>
      ：代理监听的地址和端口。
     </li>
     <li>
      <code>
       advertised.listeners
      </code>
      ：对外公布的地址和端口，用于生产者和消费者连接。
     </li>
     <li>
      <code>
       zookeeper.connect
      </code>
      ：ZooKeeper 集群的连接地址。
     </li>
    </ul>
    <h6>
     启动 ZooKeeper 集群
    </h6>
    <p>
     在每个节点上启动 ZooKeeper：
    </p>
    <p>
     bash
    </p>
    <pre><code>bin/zookeeper-server-start.sh config/zookeeper.properties
</code></pre>
    <h6>
     启动 Kafka 集群
    </h6>
    <p>
     在每个节点上启动 Kafka 代理：
    </p>
    <p>
     bash
    </p>
    <pre><code>bin/kafka-server-start.sh config/server.properties
</code></pre>
    <h4>
     （四）创建主题
    </h4>
    <p>
     使用 Kafka 提供的命令行工具创建一个主题：
    </p>
    <p>
     bash
    </p>
    <pre><code>bin/kafka-topics.sh --create --topic test_topic --bootstrap-server 192.168.111.2:9092 --partitions 3 --replication-factor 1
</code></pre>
    <ul>
     <li>
      <code>
       --topic
      </code>
      ：指定主题名称
     </li>
     <li>
      <code>
       --bootstrap-server
      </code>
      ：指定 Kafka 代理的地址
     </li>
     <li>
      <code>
       --partitions
      </code>
      ：指定主题的分区数
     </li>
     <li>
      <code>
       --replication-factor
      </code>
      ：指定分区的副本数
     </li>
    </ul>
    <h4>
     （五）发送和接收消息
    </h4>
    <h5>
     1. 启动生产者
    </h5>
    <p>
     bash
    </p>
    <pre><code>bin/kafka-console-producer.sh --topic test_topic --bootstrap-server 192.168.111.2:9092
</code></pre>
    <p>
     在控制台输入消息，按回车键发送。
    </p>
    <h5>
     2. 启动消费者
    </h5>
    <p>
     bash
    </p>
    <pre><code>bin/kafka-console-consumer.sh --topic test_topic --from-beginning --bootstrap-server 192.168.111.2:9092
</code></pre>
    <p>
     <code>
      --from-beginning
     </code>
     表示从主题的开头开始消费消息。
    </p>
    <h3>
     二、Kafka 的安全性
    </h3>
    <h4>
     （一）身份验证
    </h4>
    <p>
     Kafka 支持多种身份验证机制，如 SSL/TLS、SASL（Simple Authentication and Security Layer）等。
    </p>
    <h5>
     1. SSL/TLS 身份验证
    </h5>
    <ul>
     <li>
      <strong>
       配置步骤
      </strong>
      ：
      <ul>
       <li>
        生成证书和密钥，包括 CA 证书、服务器证书和客户端证书。
       </li>
       <li>
        在 Kafka 代理的
        <code>
         server.properties
        </code>
        中配置 SSL 相关参数，如
        <code>
         listeners
        </code>
        、
        <code>
         ssl.keystore.location
        </code>
        、
        <code>
         ssl.keystore.password
        </code>
        等。
       </li>
       <li>
        在生产者和消费者的配置中也需要配置相应的 SSL 参数，如
        <code>
         security.protocol=SSL
        </code>
        、
        <code>
         ssl.truststore.location
        </code>
        、
        <code>
         ssl.truststore.password
        </code>
        等。
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     2. SASL 身份验证
    </h5>
    <p>
     SASL 提供了多种认证机制，如 PLAIN、GSSAPI（用于 Kerberos 认证）等。以 PLAIN 机制为例：
    </p>
    <ul>
     <li>
      <strong>
       配置步骤
      </strong>
      ：
      <ul>
       <li>
        在 Kafka 代理的
        <code>
         server.properties
        </code>
        中配置 SASL 相关参数，如
        <code>
         listeners=SASL_PLAINTEXT://:9092
        </code>
        、
        <code>
         sasl.enabled.mechanisms=PLAIN
        </code>
        等。
       </li>
       <li>
        创建用户和密码文件，并在
        <code>
         server.properties
        </code>
        中指定文件路径。
       </li>
       <li>
        生产者和消费者配置相应的 SASL 参数，如
        <code>
         security.protocol=SASL_PLAINTEXT
        </code>
        、
        <code>
         sasl.mechanism=PLAIN
        </code>
        等。
       </li>
      </ul>
     </li>
    </ul>
    <h4>
     （二）授权
    </h4>
    <p>
     Kafka 可以通过 ACL（Access Control List）来控制用户对主题、分区等资源的访问权限。
    </p>
    <h5>
     配置步骤
    </h5>
    <ul>
     <li>
      <strong>
       启用 ACL
      </strong>
      ：在 Kafka 代理的
      <code>
       server.properties
      </code>
      中设置
      <code>
       authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
      </code>
      。
     </li>
     <li>
      <strong>
       创建 ACL 规则
      </strong>
      ：使用 Kafka 提供的命令行工具
      <code>
       kafka-acls.sh
      </code>
      来创建和管理 ACL 规则。例如，允许用户
      <code>
       user1
      </code>
      对主题
      <code>
       test_topic
      </code>
      进行读写操作：
     </li>
    </ul>
    <p>
     bash
    </p>
    <pre><code>bin/kafka-acls.sh --authorizer-properties zookeeper.connect=192.168.111.2:2181 --add --allow-principal User:user1 --operation Read --operation Write --topic test_topic
</code></pre>
    <h4>
     （三）数据加密
    </h4>
    <p>
     Kafka 可以使用 SSL/TLS 对数据进行加密传输，确保数据在网络传输过程中的安全性。配置 SSL/TLS 加密的步骤与 SSL/TLS 身份验证类似，主要是在代理、生产者和消费者的配置中设置相关的 SSL 参数。
    </p>
    <h3>
     三、Kafka 的特性
    </h3>
    <h4>
     （一）高吞吐量
    </h4>
    <p>
     Kafka 的设计目标之一是实现高吞吐量的数据处理。它采用了批量处理、顺序读写磁盘、零拷贝等技术，能够在短时间内处理大量的消息。例如，在一个高并发的日志收集场景中，Kafka 可以轻松应对每秒数万条甚至更多的日志消息。
    </p>
    <h4>
     （二）可扩展性
    </h4>
    <p>
     Kafka 可以通过增加代理节点来扩展集群的规模，以应对不断增长的数据量和并发请求。新的代理节点可以无缝加入集群，并且 Kafka 会自动进行分区的重新分配，确保数据的均匀分布。
    </p>
    <h4>
     （三）持久性和容错性
    </h4>
    <p>
     Kafka 将消息持久化存储在磁盘上，并且支持消息的多副本复制。每个分区可以有多个副本，分布在不同的代理节点上。当某个代理节点出现故障时，其他副本可以继续提供服务，保证数据的可用性和持久性。
    </p>
    <h4>
     （四）分布式特性
    </h4>
    <p>
     Kafka 是一个分布式系统，各个代理节点之间通过 ZooKeeper 进行协调和管理。生产者和消费者可以分布式部署，并行地进行消息的生产和消费，提高系统的整体性能和可靠性。
    </p>
    <h3>
     四、保障 Kafka 数据一致性
    </h3>
    <h4>
     （一）副本机制
    </h4>
    <p>
     Kafka 通过副本机制来保障数据的一致性和可用性。每个分区可以有多个副本，其中一个副本作为领导者（Leader），负责处理所有的读写请求；其他副本作为追随者（Follower），从领导者副本同步数据。
    </p>
    <h5>
     工作原理
    </h5>
    <ul>
     <li>
      生产者将消息发送到领导者副本，领导者副本将消息写入本地日志，并向追随者副本进行同步。
     </li>
     <li>
      追随者副本从领导者副本拉取消息，并写入本地日志。当追随者副本确认收到消息后，会向领导者副本发送确认信息。
     </li>
     <li>
      领导者副本只有在收到大多数副本（超过半数）的确认信息后，才会向生产者返回消息写入成功的响应。
     </li>
    </ul>
    <h4>
     （二）ISR（In-Sync Replicas）机制
    </h4>
    <p>
     ISR 是指与领导者副本保持同步的追随者副本集合。Kafka 通过 ISR 机制来确保数据的一致性和可用性。
    </p>
    <h5>
     工作原理
    </h5>
    <ul>
     <li>
      领导者副本会定期检查追随者副本的同步状态，如果某个追随者副本的同步延迟超过一定阈值，领导者副本会将其从 ISR 中移除。
     </li>
     <li>
      只有当消息被写入 ISR 中的所有副本后，才被认为是已提交的消息。消费者只能消费已提交的消息，从而保证了数据的一致性。
     </li>
    </ul>
    <h4>
     （三）acks 参数
    </h4>
    <p>
     生产者在发送消息时，可以通过设置
     <code>
      acks
     </code>
     参数来控制消息的确认机制，从而影响数据的一致性。
    </p>
    <h5>
     参数取值及含义
    </h5>
    <ul>
     <li>
      <code>
       acks=0
      </code>
      ：生产者发送消息后，不需要等待任何确认信息，直接认为消息发送成功。这种方式吞吐量最高，但可能会丢失消息，数据一致性最差。
     </li>
     <li>
      <code>
       acks=1
      </code>
      ：生产者发送消息后，只需要等待领导者副本确认收到消息，就认为消息发送成功。这种方式在一定程度上保证了数据的一致性，但如果领导者副本在消息同步给追随者副本之前出现故障，可能会丢失消息。
     </li>
     <li>
      <code>
       acks=all
      </code>
      或
      <code>
       acks=-1
      </code>
      ：生产者发送消息后，需要等待 ISR 中的所有副本都确认收到消息，才认为消息发送成功。这种方式数据一致性最高，但吞吐量相对较低。
     </li>
    </ul>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34343832313830352f:61727469636c652f64657461696c732f313435383232313737" class_="artid" style="display:none">
 </p>
</div>


