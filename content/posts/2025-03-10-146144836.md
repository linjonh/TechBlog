---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f36393430323437372f:61727469636c652f64657461696c732f313436313434383336"
layout: post
title: "DeepSeek本地化部署与跨域访问架构构建"
date: 2025-03-10 12:36:53 +08:00
description: "本文针对DeepSeek数据库的本地化部署及其跨域访问架构构建进行了探讨。本地化部署通过将数据库直接安装在用户本地服务器上，有效提升了数据处理的响应速度与安全性。同时，构建跨域访问架构，采用先进的加密技术和身份认证机制，确保数据在不同网络域间传输的安全性。该架构支持高效的数据共享与协作，优化了业务流程，为多组织间的数据整合与业务协同提供了坚实基础，极大提升了整体数据处理能力和系统可用性。"
keywords: "共享本地大模型"
categories: ['未分类']
tags: ['局域网', '公网Ip', 'Ollama', 'Deepseek']
artid: "146144836"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146144836
    alt: "DeepSeek本地化部署与跨域访问架构构建"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146144836
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146144836
cover: https://bing.ee123.net/img/rand?artid=146144836
image: https://bing.ee123.net/img/rand?artid=146144836
img: https://bing.ee123.net/img/rand?artid=146144836
---

# DeepSeek本地化部署与跨域访问架构构建

## 1. DeepSeek本地部署基础环境

> 1. 部署 Ollama 推理框架
> 2. 获取并加载 DeepSeek 大语言模型
> 3. 配置图形化用户界面 (GUI)
> 4. 构建本地知识库并集成

鉴于上述四个步骤已在之前的博客中详尽阐述，为避免重复，以下内容将不再赘述，仅作概要性描述

## 2. 局域网共享大模型配置

在局域网环境下，通过单机部署
**DeepSeek-r1**
(或其他预训练模型) 及本地知识库，并配置相应的网络服务，实现局域网内其他主机对该模型推理服务及知识库的访问。

**1. 启动局域网访问权限**

默认Ollama仅允许本地访问，需修改环境变量实现局域网共享：

* 创建用户环境变量

  1. WIN+R打开输入cmd，以管理身份启动CMD终端，执行如下两个命令创建用户和系统变量，系统多个“ /m”。

     ```bash
     setx OLLAMA_HOST "0.0.0.0"
     setx OLLAMA_ORIGINS "*"

     ```

     ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/f368c1a6fb5f461ca0723ef8e7a5af51.png)
* 创建系统环境变量

  1. 在电脑设置中搜索找到“编辑系统环境变量”并打开 编辑系统环境变量。
  2. 在系统属性面板中点击环境变量，点击新建系统变量。
  3. 新建系统变量名为：OLLAMA\_HOST ,值设置为0.0.0.0 。
       
     ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6d4cb63a55414e7a9a60d942954d642a.png)
  4. 再次新建系统变量名称为：OLLAMA ORIGINS ，值设为：“ * ” 。
       
     ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/433452f637a34aafb307715485718f5a.png)
  5. 电脑右下角右键退出Ollama 程序后重新手动启动Ollama程序。
     ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/632504cf0c92498db74736d73f2380e6.png)

**2. 局域网访问本地大模型配置**

在同一局域网下的其他用户访问当前本地部署。无论是使用
**Page Assist、Anything LLM、Chatbox**
或
**Cherry Studio**
进行部署，都需要在主机与被访问主机上安装对应用的部署工具。

主机
**ip**
地址查询，在
**CMD**
中 直接输入：
**ipconfig**
回车即可显示。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a543ebba7d0046bb9faad1611b8ec7bf.png)

### 2.1 浏览器插件

> `Page Assist浏览器插件安装与配置`

1. 首先打开Chrome浏览器，进入应用商店
     
   ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/91db050811b5430984d5093f500b548e.png)
2. 在顶部搜索框中搜索Page Assist
     
   ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/77e6f805d5244a9cbd1b65dae35fd04d.png)
3. 点击添加至Chrome

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/25d0a929609a47c0af426e9f5cf45fcf.png)

* 在弹出的提示框中点击添加扩展程序
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/159ada3123e243d4bea23e5da62b159f.png)
    
  添加后在浏览器右上角的扩展程序图标中打开它即可看到Web UI界面了
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/25383afd8ced409496b38abf32780210.png)
* **被访问主机设置(Server)**
  、：点击右上角设置，找到Ollama设置地址为
  `http://[主机IP]:11434`
  。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/d881106c9b68497e8b14539a77615be6.png)
* **访问主机设置(Client)**
  ：访问主机将127.0.0.1 改为被访问主机IP 地址，如：192.168.50.80，端口默认11434 即可。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c4242a593881454497ef96aaa4d50f0a.png)

### 2.2 客户端工具

**Anything LLM、Chatbox**
或
**Cherry Studio**
进行部署，配置
**API**
地址为
`http://[主机IP]:11434/v1`
，选择对应模型即可交互。

* **被访问主机设置**
  ：默认Api ：http://localhost:11434，保持默认即可
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e6d1e57ffcd249b49b4fb5f78b00120b.png)
* **访问主机设置**
  ：访问主机将
  **localhost**
  改为被访问主机
  **IP**
  地址，如：192.168.50.80，端口默认11434 即可。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b8ea4bd9ef434e07be9c8907acf5c506.png)
* Anything LLM工具设置同上
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5681a339661d4988826b9e25a895da81.png)

## 3. 跨域公网访问大模型

一台主机本地部署了
**DeepSeek-r1**
（或其他模型）以及数据（知识）库后，通过公网（外网）异地访问这台主机的大模型和数据，进行内网穿透设置，工具
**cpolar**
或
**路由侠**
。

**1. 被访问主机安装路由侠**

* 这里以路由侠为例，选择适合自己系统下载安装。

  ```shell
  # 路由侠地址：
  https://www.luyouxia.com/
  # cpolar地址：
  https://www.cpolar.com/

  ```

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3c2b4f5d670c47f6a67a9291ab3d3234.png#pic_center)
    
  2. 启动安装程序进行安装。
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b6c02e2dce454d5eb7d7267bee1ecd62.png)
    
  3. 注册路由侠账户，并登录账户
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/594f76a448f844b0a3171f70148a9fd0.png)

**2. 路由侠配置**

* 启动软件后，设置点击内网映射。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6ea5f660f0a44e0c899b3fd7206c42cf.png)
* 点击添加映射 ，并进行配置
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a9783ce80dc14ff9a81447ed8a5179b3.png#pic_center)
* 选择原生端口——开始创建。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/2068535125f749fa81d7a1af9b461623.png)
* 配置公网地址：设置端口为Ollama 端口，然后点击创建。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/ab986cc8b0f745e89740326e79d485bb.png#pic_center)
* 创建完成后即显示创建的映射内容，右键复制地址，接下来将复制的地址粘贴到对应部署的工具中。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/9ebca9b03c90410cb9ef9600e6f2fffb.png)

### 3.1 访问端设置

#### 3.1.1 浏览器插件部署

* **Page Assist**
  访问端设置：将复制的地址粘贴在
  **Ollama 设置**
  ——Ollama URL 中保存，重启浏览器。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/544ea772fe534aae8c028da9b4d2fbc9.png#pic_center)

#### 3.1.2 客户端工具

* **Cherry studio**
  访问端设置：在设置——模型服务——Ollama——
  **API地址**
  中粘贴地址，再添加模型设置后重启
  **Cherry studio**
  。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/7be0586a35334e3d87374ec26355b02b.png#pic_center)
* **AnythingLlm**
  访问端设置：首选项——Ollama——Ollama URL 中粘贴复制的地址，设置完成后设置后重启AnythingLlm。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/8428520f1a764353987e5797b6ad3a7c.png#pic_center)

**注：
`提示错误 Ollama call failed with status code 403`
:**

> 检查环境变量——用户变量及系统变量是否有Ollama的变量设置。