---
layout: post
title: "网络爬虫简介"
date: 2025-03-15 20:17:26 +0800
description: "网络爬虫的简介和浏览器分析工具"
keywords: "网络爬虫【简介】"
categories: ['爬虫']
tags: ['爬虫']
artid: "146284580"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146284580
    alt: "网络爬虫简介"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146284580
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146284580
cover: https://bing.ee123.net/img/rand?artid=146284580
image: https://bing.ee123.net/img/rand?artid=146284580
img: https://bing.ee123.net/img/rand?artid=146284580
---

# 网络爬虫【简介】

[#新星杯·14天创作挑战营·第9期#](https://activity.csdn.net/writing?id=10858)

> 我叫补三补四，很高兴见到大家，欢迎一起学习交流和进步
>
> ![](https://i-blog.csdnimg.cn/direct/9c322daac7244f74877268e8b41b510a.gif)
>
> 今天来讲一讲爬虫

## 一、网络爬虫的定义

  
网络爬虫（Web
Crawler），又称为网络蜘蛛、网络机器人等，是一种按照一定规则自动抓取互联网信息的程序或脚本。它通过模拟浏览器的行为，发送HTTP请求获取网页内容，并从中提取有用信息。网络爬虫广泛应用于搜索引擎、大数据分析、学术研究等领域，是互联网信息采集的重要工具。

##  
二、网络爬虫的类型

  
网络爬虫主要分为通用网络爬虫和定向网络爬虫两大类。

###  
（一）通用网络爬虫

  
通用网络爬虫，又称全网爬虫，旨在从互联网上尽可能多地抓取网页信息，覆盖各种类型和主题的网站。其特点包括：

1\. 覆盖范围广：不局限于特定领域，目标是构建全面的网页索引。

2\. 遵循规则：通常遵循robots.txt协议，尊重网站的抓取规则。

3\. 并行工作：由于数据量巨大，通常采用并行爬取的方式。

通用网络爬虫的实现原理主要包括以下几个模块：

• 初始URL集合：作为爬取的起点。

• URL队列：存储待爬取的网页链接。

• 页面爬行模块：通过HTTP请求获取网页内容。

• 页面分析模块：解析网页，提取其中的链接和内容。

• 页面数据库：存储爬取到的网页。

• 链接过滤模块：避免重复抓取相同的网页。

通用网络爬虫通常采用深度优先或广度优先的搜索策略。

###  
（二）定向网络爬虫

  
定向网络爬虫，又称聚焦网络爬虫或主题网络爬虫，是有选择地抓取与特定主题相关的网页。其特点包括：

1\. 目标明确：专注于特定领域或主题，如科技新闻、医学研究等。

2\. 节省资源：由于目标明确，不需要遍历整个互联网，因此在存储和计算资源的消耗上相对较少。

定向网络爬虫的实现原理与通用网络爬虫类似，但增加了内容评价和链接评价模块。其核心在于通过特定的策略和算法选择要抓取的网页，通常会使用机器学习或自然语言处理技术来判断网页内容是否符合预定主题。

##  
三、常见的搜索策略

  
网络爬虫在抓取网页时，通常会采用以下几种搜索策略：

###  
（一）深度优先搜索（DFS）

  
深度优先搜索的基本方法是按照深度由低到高的顺序，依次访问下一级网页链接，直到不能再深入为止。爬虫在完成一个爬行分支后返回到上一链接节点，继续搜索其他链接。这种策略适合垂直搜索或站内搜索，但可能会导致资源浪费。

###  
（二）广度优先搜索（BFS）

  
广度优先搜索按照网页内容目录层次深浅来爬行页面，优先抓取较浅层次的页面。当同一层次中的页面爬行完毕后，再深入下一层继续爬行。这种策略能够有效控制爬行深度，避免陷入无穷深层分支。

###  
（三）最佳优先搜索（Best-First Search）

  
最佳优先搜索是一种基于启发式的搜索策略，它通过评估每个节点的重要性来决定下一步的抓取顺序。例如，可以基于页面与主题的相关性、链接质量等因素进行评估。这种方法能够更高效地抓取有价值的信息，尤其适用于定向网络爬虫。

##  
开发者工具

在从事编程开发的人员，其实浏览器也是其必备的开发工具

在找到目标网页以后我们可以使用快捷键F12，也可以通过在网页右键选择检查或者用组合键ctrl+shift+I来打开开发者工具

![](https://i-blog.csdnimg.cn/direct/4f096a7451324b46960acf91a0ef7646.jpeg)

开发者工具的界面共有9个标签页，分别是：Elements、Console、Sources、Network、Performance、Memory、Application、Security和Audits。

如果是用于爬虫分析的话，熟练掌握Elements和Network标签就能满足大部分的爬虫需求。

### Elements标签

在Elements标签中允许从浏览器的角度看页面，也就是说可以看到Chrome渲染页面所需要的HTML、CSS和DOM（Document Object
Model）对象，也可以编辑内容更改页面的显示效果。

![](https://i-blog.csdnimg.cn/direct/3dfc506cb77f490eaa7baebbb29aca2e.jpeg)

Elements标签分成两个部分，其中区域1用于显示页面的HTML信息，当选中某一行的内容时，区域2会显示当前选中的css样式，并且允许对元素的css样式进行查看和编辑，computed显示当前选中的边距属性，边框属性，Event
Listeners是整个网页事件触发的JavaScript

![](https://i-blog.csdnimg.cn/direct/3fd08d13278a4c11904f12d6275704d3.jpeg)

通过单击Event
Listeners下的某个JavaScript会自动跳转到Sources标签，显示当前JavaScript的源码，这个功能可快速找到JavaScript代码所在的位置，对分析JavaScript起到快速定位作用。

### Network标签

从network当中可以看到页面向服务器请求的信息，请求的大小，以及请求花费的时间

![](https://i-blog.csdnimg.cn/direct/216fb73c10594094a689f53281539e4e.jpeg)

network标签主要包含五个区域：

#### 1.功能区

• 记录开关：红色圆点表示是否开启网络日志记录，灰色为未开启，红色为已开启。

• 清除日志：清除当  
前所有网络请求记录。

• 屏幕捕获：开启后会记录页面在不同时间下的快照。

• 过滤器开关：开启后可显示筛选区。

• 快速查找：用于快速查找特定请求。

• 显示设置：包括是否使用更大的区域显示请求记录、是否显示Overview等。

• 分组显示：勾选后可按表单名称对网络请求进行分组。

• 保留日志：勾选后，页面刷新不会清空之前的请求记录。

• 禁用缓存：当打开开发者工具时生效，页面资源不会存入缓存。

• 离线模式：用于测试离线状态下的页面表现。

• 网络限速：模拟不同网络条件，如弱网。

####  
2.筛选区

•
提供多种预定义的筛选选项，如ALL（显示所有请求）、XHR（AJAX异步请求）、JS（JavaScript文件）、CSS（样式表文件）、Img（图片）、Media（媒体文件）、Font（字体文件）、Doc（HTML文档）、WS（WebSocket请求）等。

• 还可以输入自定义条件进行筛选。

####  
3.时间轴区（Overview）

• 以时间轴的形式展示页面加载过程，包括DOMContentLoaded和load事件的触发时间。

• 可以通过滑动鼠标滚轮查看不同时间点的加载情况。

####  
4.主显示区

• 显示所有网络请求的详细列表，包括以下列：

• Name：请求资源的名称。

• Status：HTTP状态码。

• Type：请求资源的MIME类型。

• Initiator：发起请求的对象或进程。

• Size：服务器返回的响应大小。

• Time：请求的总持续时间。

• Waterfall：各请求相关活动的直观分析图。

•
点击某个请求的名称，可以查看该请求的详细信息，包括Headers（请求头和响应头）、Preview（预览）、Response（响应内容）、Cookies（Cookie信息）、Timing（请求生命周期各阶段时间）等。

####  
5.信息汇总区

• 显示当前页面加载的总请求数、数据传输量、加载时间等信息。

• 包括DOMContentLoaded和load事件的触发时间及其在时间轴上的标记。

#### Requests Table

5个区域中，Requests
Table是核心部分，主要作用是记录每个请求信息。但每次网站出现刷新时，请求列表都会清空并记录最新的请求信息，如用户登录后发生304跳转，就会清空跳转之前的请求信息并捕捉跳转后的请求信息。对于每条请求信息，可以单击查看该请求的详细信息：

![](https://i-blog.csdnimg.cn/direct/19c27fb780ce45a98f80dea29b795e9e.jpeg)

> 每条请求信息划分为以下5个标签。  
>  ● Headers：该请求的HTTP头信息。  
>  ● Preview：根据所选择的请求类型（JSON、图片、文本）显示相应的预览。  
>  ● Response：显示HTTP的Response信息。  
>  ● Cookies：显示HTTP的Request和Response过程中的Cookies信息。  
>  ● Timing：显示请求在整个生命周期中各部分花费的时间。

关于Headers的内容如下：  
Headers 标签通常分为以下几个部分：

  
1.请求方法和URL

• Request Method：显示请求的HTTP方法（如GET、POST、PUT、DELETE等）。

• Request URL：显示请求的完整URL。

• Request HTTP Version：显示使用的HTTP版本（如HTTP/1.1、HTTP/2等）。

  
2.请求头（Request Headers）  
请求头是由客户端发送给服务器的头信息，它包含了关于请求的元数据。常见的请求头包括：

• Accept：客户端可接受的响应内容类型（如`text/html`、`application/json`等）。

• Accept-Encoding：客户端可接受的内容编码方式（如`gzip`、`deflate`等）。

• Accept-Language：客户端偏好的语言（如`zh-CN`）。

• Authorization：用于身份验证的凭据（如Basic Auth、Bearer Token等）。

• Content-Length：请求体的长度（仅在POST或PUT请求中出现）。

• Content-Type：请求体的内容类型（如`application/json`、`application/x-www-form-
urlencoded`等）。

• Cookie：客户端存储的Cookie信息。

• Host：请求的主机名。

• Origin：发起请求的源（用于CORS跨域请求）。

• Referer：请求的来源页面。

• User-Agent：客户端的浏览器或设备信息。

  
3.响应头（Response Headers）  
响应头是由服务器返回给客户端的头信息，它包含了关于响应的元数据。常见的响应头包括：

• Access-Control-Allow-Origin：允许访问资源的源（用于CORS跨域请求）。

• Cache-Control：缓存策略（如`no-cache`、`max-age`等）。

• Content-Encoding：响应体的内容编码方式（如`gzip`）。

• Content-Length：响应体的长度。

• Content-Type：响应体的内容类型（如`text/html`、`application/json`等）。

• Date：服务器生成响应的时间。

• ETag：资源的唯一标识符，用于缓存验证。

• Expires：响应过期时间。

• Last-Modified：资源最后修改时间。

• Location：重定向目标URL。

• Set-Cookie：服务器设置的Cookie信息。

• Server：服务器软件信息。

  
4.请求体（Request Payload）  
对于POST或PUT请求，Headers 标签还会显示请求体的内容。这通常用于查看发送到服务器的数据，例如表单数据、JSON对象等。

  
5.查询参数（Query String Parameters）  
如果请求URL中包含查询参数（如`?key=value`），Headers 标签会将这些参数列出，方便开发者查看。

  
\---

Headers 标签的作用

1\. 调试请求和响应：通过查看Headers，可以确认请求是否正确发送，以及服务器是否返回了预期的响应。

2\. 优化性能：通过分析缓存头（如`Cache-Control`、`ETag`等），可以优化页面的缓存策略，减少重复请求。

3\. 排查跨域问题：通过查看`Access-Control-Allow-Origin`等头信息，可以排查CORS跨域问题。

4\. 验证身份认证：通过检查`Authorization`头，可以确认身份认证信息是否正确传递。

5\. 分析内容编码：通过查看`Content-Encoding`和`Content-Type`，可以确认资源是否被正确压缩和解析。

  
\---

示例  
假设你发起一个GET请求，Headers标签可能显示如下内容：

  
请求方法和URL

    
    
    GET /api/data HTTP/1.1

请求头

    
    
    Host: example.com
    Connection: keep-alive
    Accept: application/json
    User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.93 Safari/537.36
    Accept-Encoding: gzip, deflate, br
    Accept-Language: zh-CN,zh;q=0.9
    Cookie: sessionid=1234567890

响应头

    
    
    HTTP/1.1 200 OK
    Content-Type: application/json
    Content-Length: 256
    Cache-Control: max-age=3600
    Date: Sat, 15 Oct 2023 12:34:56 GMT
    Set-Cookie: sessionid=9876543210; Path=/; HttpOnly

请求体（如果适用）  
如果是一个POST请求，可能会显示：

    
    
    Request Payload:
    {
      "username": "user",
      "password": "pass"
    }

## 网站分析步骤：

分析网站的步骤如下：  
步骤01 找出数据来源，大部分数据来源于Doc、XHR和JS标签。  
步骤02 找到数据所在的请求，分析其请求链接、请求方式和请求参数。  
步骤03
查找并确定请求参数来源。有时候某些请求参数是通过另外的请求生成的，比如请求A的参数id是通过请求B所生成的，那么要获取请求A的数据，就要先获取请求B的数据作为A的请求参数。



