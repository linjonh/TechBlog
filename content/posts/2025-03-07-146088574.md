---
layout: post
title: "如何收集-Kubernetes-集群的日志"
date: 2025-03-07 10:20:11 +0800
description: "如何收集 Kubernetes 集群的日志？是否用过 EFK（Elasticsearch+Fluentd+Kibana）？  "
keywords: "如何收集 Kubernetes 集群的日志"
categories: ['运维']
tags: ['运维', 'Kubernetes']
artid: "146088574"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146088574
    alt: "如何收集-Kubernetes-集群的日志"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146088574
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146088574
cover: https://bing.ee123.net/img/rand?artid=146088574
image: https://bing.ee123.net/img/rand?artid=146088574
img: https://bing.ee123.net/img/rand?artid=146088574
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     如何收集 Kubernetes 集群的日志
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h4>
     <strong>
      一、Kubernetes 日志收集核心方案
     </strong>
    </h4>
    <h5>
     <strong>
      1. EFK Stack（Elasticsearch + Fluentd + Kibana）
     </strong>
    </h5>
    <p>
     •
     <strong>
      适用场景
     </strong>
     ：企业级日志分析、复杂查询需求、长期日志存储。
    </p>
    <p>
     •
     <strong>
      组件作用
     </strong>
     ：
    </p>
    <p>
     •
     <strong>
      Fluentd
     </strong>
     ：日志收集器（部署为 DaemonSet，每个 Node 运行一个实例）。
    </p>
    <p>
     •
     <strong>
      Elasticsearch
     </strong>
     ：日志存储与索引（支持分布式、高并发）。
    </p>
    <p>
     •
     <strong>
      Kibana
     </strong>
     ：可视化仪表盘（日志搜索、图表展示）。
    </p>
    <h5>
     <strong>
      2. Loki（轻量级替代方案）
     </strong>
    </h5>
    <p>
     •
     <strong>
      适用场景
     </strong>
     ：中小型集群、低成本运维、简化日志存储。
    </p>
    <p>
     •
     <strong>
      组件作用
     </strong>
     ：
    </p>
    <p>
     •
     <strong>
      Loki
     </strong>
     ：类似 Elasticsearch 的日志聚合引擎，但专注于日志存储（压缩率高）。
    </p>
    <p>
     •
     <strong>
      Promtail
     </strong>
     ：轻量级日志收集器（替代 Fluentd）。
    </p>
    <p>
     •
     <strong>
      Grafana
     </strong>
     ：集成 Loki 作为日志存储后端，复用现有监控仪表盘。
    </p>
    <h5>
     <strong>
      3. 其他方案
     </strong>
    </h5>
    <p>
     •
     <strong>
      Stackdriver
     </strong>
     ：GCP 官方云服务。
    </p>
    <p>
     •
     <strong>
      Datadog
     </strong>
     ：SaaS 日志分析平台。
    </p>
    <p>
     •
     <strong>
      Filebeat + Elasticsearch
     </strong>
     ：适用于简单场景。
    </p>
    <hr/>
    <h4>
     <strong>
      二、EFK Stack 配置步骤
     </strong>
    </h4>
    <h5>
     <strong>
      1. 部署 EFK 组件
     </strong>
    </h5>
    <pre># 1. 安装 Fluentd（DaemonSet）
kubectl apply -f https://github.com/fluent/fluentd-kubernetes-daemonset/releases/latest/fluentd-daemonset.yaml
​
# 2. 安装 Elasticsearch
kubectl apply -f https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.10.0.yaml
​
# 3. 安装 Kibana
kubectl apply -f https://artifacts.elastic.co/downloads/kibana/kibana-7.10.0.yaml</pre>
    <h5>
     <strong>
      2. 配置 Fluentd 收集日志
     </strong>
    </h5>
    <p>
     •
     <strong>
      默认配置
     </strong>
     ：Fluentd 会自动收集 Node 日志和容器日志。
    </p>
    <p>
     •
     <strong>
      自定义收集规则
     </strong>
     （例如收集特定 Pod 日志）：
    </p>
    <pre>  # 创建 ConfigMap
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: fluentd-config
    namespace: kube-system
  data:
    fluentd.conf: |
      &lt;source&gt;
        @type tail
        path /var/log/containers/*.log
        pos_file /var/log/fluentd-containers.log
        tag kubernetes.*
        read_from_head true
      &lt;/source&gt;
​
      # 自定义收集规则：收集 my-app 的日志
      &lt;source&gt;
        @type tail
        path /var/log/pods/my-app_default_*.log
        pos_file /var/log/fluentd-myapp.log
        tag my-app.log
        read_from_head true
      &lt;/source&gt;</pre>
    <pre>  # 应用配置
  kubectl apply -f fluentd-config.yaml
​
  # 重启 Fluentd DaemonSet
  kubectl delete daemonset fluentd-daemonset -n kube-system
  kubectl apply -f https://github.com/fluent/fluentd-kubernetes-daemonset/releases/latest/fluentd-daemonset.yaml</pre>
    <hr/>
    <h4>
     <strong>
      三、EFK 核心配置详解
     </strong>
    </h4>
    <h5>
     <strong>
      1. Fluentd 日志过滤与转发
     </strong>
    </h5>
    <pre># 示例：通过过滤器仅收集 Error 级别日志
&lt;filter kubernetes.**&gt;
  @type grep
  match =&gt; "^ERROR"
&lt;/filter&gt;
​
&lt;match my-app.log&gt;
  @type elasticsearch
  hostnames elasticsearch
  port 9200
  logstash_format true
  flush_interval 10s
&lt;/match&gt;</pre>
    <h5>
     <strong>
      2. Elasticsearch 索引管理
     </strong>
    </h5>
    <pre># 创建索引模板（优化日志存储）
PUT /_template/kubernetes-logs
{
  "index_patterns": ["kubernetes-logs-*"],
  "settings": {
    "number_of_shards": 1,
    "replicas": 1
  },
  "mappings": {
    "properties": {
      "@timestamp": { "type": "date" }
    }
  }
}</pre>
    <hr/>
    <h4>
     <strong>
      四、日志收集验证
     </strong>
    </h4>
    <h5>
     <strong>
      1. 检查日志是否进入 Elasticsearch
     </strong>
    </h5>
    <pre># 查看 Elasticsearch 索引
curl -X GET "http://elasticsearch:9200/_cat/indices?v"
​
# 搜索特定日志
curl -X GET "http://elasticsearch:9200/kubernetes-logs-*/_search?q=message:%22ERROR%22"</pre>
    <h5>
     <strong>
      2. 在 Kibana 中配置可视化
     </strong>
    </h5>
    <ol>
     <li>
      <p>
       访问 Kibana Web UI（通过 Service 暴露）。
      </p>
     </li>
     <li>
      <p>
       创建 Index Pattern：选择
       <code>
        kubernetes-logs-*
       </code>
       。
      </p>
     </li>
     <li>
      <p>
       构建仪表盘：
      </p>
     </li>
    </ol>
    <p>
     • 日志统计：按 Pod 名称、容器名称分组。
     <br/>
     • 实时监控：展示错误日志趋势图。
    </p>
    <hr/>
    <h4>
     <strong>
      五、EFK vs Loki 对比
     </strong>
    </h4>
    <table>
     <thead>
      <tr>
       <th>
        维度
       </th>
       <th>
        EFK Stack
       </th>
       <th>
        Loki
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        <strong>
         存储成本
        </strong>
       </td>
       <td>
        高（Elasticsearch 需要大量磁盘）
       </td>
       <td>
        低（压缩率高达 10:1）
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         查询性能
        </strong>
       </td>
       <td>
        强（支持复杂 SQL-like 查询）
       </td>
       <td>
        较弱（专为日志设计）
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         部署复杂度
        </strong>
       </td>
       <td>
        高（需管理 3 个组件）
       </td>
       <td>
        低（仅需 Loki 和 Promtail）
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         社区生态
        </strong>
       </td>
       <td>
        成熟（支持丰富插件）
       </td>
       <td>
        快速增长（云原生友好）
       </td>
      </tr>
     </tbody>
    </table>
    <hr/>
    <h4>
     <strong>
      六、生产环境优化建议
     </strong>
    </h4>
    <h5>
     <strong>
      1. 日志分级存储
     </strong>
    </h5>
    <p>
     •
     <strong>
      短期日志
     </strong>
     （最近 7 天）：存储在 Elasticsearch。
    </p>
    <p>
     •
     <strong>
      长期日志
     </strong>
     （超过 7 天）：归档至 AWS S3 或 Azure Blob Storage。
    </p>
    <h5>
     <strong>
      2. 性能调优
     </strong>
    </h5>
    <p>
     •
     <strong>
      Elasticsearch 分片
     </strong>
     ：根据集群规模设置合理分片数。
    </p>
    <p>
     •
     <strong>
      Fluentd 缓冲区
     </strong>
     ：增加
     <code>
      buffer_chunk_limit
     </code>
     和
     <code>
      flush_interval
     </code>
     避免日志丢失。
    </p>
    <h5>
     <strong>
      3. 安全加固
     </strong>
    </h5>
    <p>
     •
     <strong>
      RBAC 权限
     </strong>
     ：限制 Kibana 只能访问特定 Namespace。
    </p>
    <p>
     •
     <strong>
      TLS 加密
     </strong>
     ：启用 Elasticsearch 和 Kibana 的 HTTPS 通信。
    </p>
    <hr/>
    <h4>
     <strong>
      七、替代方案：Loki 部署
     </strong>
    </h4>
    <h5>
     <strong>
      1. 安装 Loki
     </strong>
    </h5>
    <pre>kubectl apply -f https://github.com/grafana/loki/releases/latest/deploy.yaml</pre>
    <h5>
     <strong>
      2. 安装 Promtail
     </strong>
    </h5>
    <pre>kubectl apply -f https://github.com/grafana/loki/releases/latest/deploy-promtail.yaml</pre>
    <h5>
     <strong>
      3. 验证日志收集
     </strong>
    </h5>
    <pre># 查看 Loki 日志存储
kubectl logs -n loki -l app=loki --container=query-frontend
​
# 在 Grafana 中添加 Loki 数据源
grafana-url: http://grafana:3000
data-source: loki</pre>
    <hr/>
    <h4>
     <strong>
      总结
     </strong>
    </h4>
    <p>
     •
     <strong>
      推荐 EFK
     </strong>
     ：适合需要复杂查询、企业级分析的场景。
    </p>
    <p>
     •
     <strong>
      推荐 Loki
     </strong>
     ：适合中小型集群、注重成本和易用性的场景。
    </p>
    <p>
     •
     <strong>
      其他选择
     </strong>
     ：云厂商日志服务（如 AWS CloudWatch、Azure Monitor）适合混合云环境。
    </p>
    <p>
     无论选择哪种方案，建议结合
     <strong>
      Prometheus + Alertmanager
     </strong>
     实现日志异常的实时告警。
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f:2f626c6f672e6373646e2e6e65742f626c747975323030302f:61727469636c652f64657461696c732f313436303838353734" class_="artid" style="display:none">
 </p>
</div>


