---
arturl_encode: "68747470733a2f:2f626c6f672e6373646e2e6e65742f626c747975323030302f:61727469636c652f64657461696c732f313436303838353734"
layout: post
title: "如何收集-Kubernetes-集群的日志"
date: 2025-03-07 10:20:11 +0800
description: "如何收集 Kubernetes 集群的日志？是否用过 EFK（Elasticsearch+Fluentd+Kibana）？  "
keywords: "如何收集 Kubernetes 集群的日志"
categories: ['运维']
tags: ['运维', 'Kubernetes']
artid: "146088574"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146088574
    alt: "如何收集-Kubernetes-集群的日志"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146088574
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146088574
cover: https://bing.ee123.net/img/rand?artid=146088574
image: https://bing.ee123.net/img/rand?artid=146088574
img: https://bing.ee123.net/img/rand?artid=146088574
---

# 如何收集 Kubernetes 集群的日志

#### **一、Kubernetes 日志收集核心方案**

##### **1. EFK Stack（Elasticsearch + Fluentd + Kibana）**

•
**适用场景**
：企业级日志分析、复杂查询需求、长期日志存储。

•
**组件作用**
：

•
**Fluentd**
：日志收集器（部署为 DaemonSet，每个 Node 运行一个实例）。

•
**Elasticsearch**
：日志存储与索引（支持分布式、高并发）。

•
**Kibana**
：可视化仪表盘（日志搜索、图表展示）。

##### **2. Loki（轻量级替代方案）**

•
**适用场景**
：中小型集群、低成本运维、简化日志存储。

•
**组件作用**
：

•
**Loki**
：类似 Elasticsearch 的日志聚合引擎，但专注于日志存储（压缩率高）。

•
**Promtail**
：轻量级日志收集器（替代 Fluentd）。

•
**Grafana**
：集成 Loki 作为日志存储后端，复用现有监控仪表盘。

##### **3. 其他方案**

•
**Stackdriver**
：GCP 官方云服务。

•
**Datadog**
：SaaS 日志分析平台。

•
**Filebeat + Elasticsearch**
：适用于简单场景。

---

#### **二、EFK Stack 配置步骤**

##### **1. 部署 EFK 组件**

```
# 1. 安装 Fluentd（DaemonSet）
kubectl apply -f https://github.com/fluent/fluentd-kubernetes-daemonset/releases/latest/fluentd-daemonset.yaml
​
# 2. 安装 Elasticsearch
kubectl apply -f https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.10.0.yaml
​
# 3. 安装 Kibana
kubectl apply -f https://artifacts.elastic.co/downloads/kibana/kibana-7.10.0.yaml
```

##### **2. 配置 Fluentd 收集日志**

•
**默认配置**
：Fluentd 会自动收集 Node 日志和容器日志。

•
**自定义收集规则**
（例如收集特定 Pod 日志）：

```
  # 创建 ConfigMap
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: fluentd-config
    namespace: kube-system
  data:
    fluentd.conf: |
      <source>
        @type tail
        path /var/log/containers/*.log
        pos_file /var/log/fluentd-containers.log
        tag kubernetes.*
        read_from_head true
      </source>
​
      # 自定义收集规则：收集 my-app 的日志
      <source>
        @type tail
        path /var/log/pods/my-app_default_*.log
        pos_file /var/log/fluentd-myapp.log
        tag my-app.log
        read_from_head true
      </source>
```

```
  # 应用配置
  kubectl apply -f fluentd-config.yaml
​
  # 重启 Fluentd DaemonSet
  kubectl delete daemonset fluentd-daemonset -n kube-system
  kubectl apply -f https://github.com/fluent/fluentd-kubernetes-daemonset/releases/latest/fluentd-daemonset.yaml
```

---

#### **三、EFK 核心配置详解**

##### **1. Fluentd 日志过滤与转发**

```
# 示例：通过过滤器仅收集 Error 级别日志
<filter kubernetes.**>
  @type grep
  match => "^ERROR"
</filter>
​
<match my-app.log>
  @type elasticsearch
  hostnames elasticsearch
  port 9200
  logstash_format true
  flush_interval 10s
</match>
```

##### **2. Elasticsearch 索引管理**

```
# 创建索引模板（优化日志存储）
PUT /_template/kubernetes-logs
{
  "index_patterns": ["kubernetes-logs-*"],
  "settings": {
    "number_of_shards": 1,
    "replicas": 1
  },
  "mappings": {
    "properties": {
      "@timestamp": { "type": "date" }
    }
  }
}
```

---

#### **四、日志收集验证**

##### **1. 检查日志是否进入 Elasticsearch**

```
# 查看 Elasticsearch 索引
curl -X GET "http://elasticsearch:9200/_cat/indices?v"
​
# 搜索特定日志
curl -X GET "http://elasticsearch:9200/kubernetes-logs-*/_search?q=message:%22ERROR%22"
```

##### **2. 在 Kibana 中配置可视化**

1. 访问 Kibana Web UI（通过 Service 暴露）。
2. 创建 Index Pattern：选择
   `kubernetes-logs-*`
   。
3. 构建仪表盘：

• 日志统计：按 Pod 名称、容器名称分组。
  
• 实时监控：展示错误日志趋势图。

---

#### **五、EFK vs Loki 对比**

| 维度 | EFK Stack | Loki |
| --- | --- | --- |
| **存储成本** | 高（Elasticsearch 需要大量磁盘） | 低（压缩率高达 10:1） |
| **查询性能** | 强（支持复杂 SQL-like 查询） | 较弱（专为日志设计） |
| **部署复杂度** | 高（需管理 3 个组件） | 低（仅需 Loki 和 Promtail） |
| **社区生态** | 成熟（支持丰富插件） | 快速增长（云原生友好） |

---

#### **六、生产环境优化建议**

##### **1. 日志分级存储**

•
**短期日志**
（最近 7 天）：存储在 Elasticsearch。

•
**长期日志**
（超过 7 天）：归档至 AWS S3 或 Azure Blob Storage。

##### **2. 性能调优**

•
**Elasticsearch 分片**
：根据集群规模设置合理分片数。

•
**Fluentd 缓冲区**
：增加
`buffer_chunk_limit`
和
`flush_interval`
避免日志丢失。

##### **3. 安全加固**

•
**RBAC 权限**
：限制 Kibana 只能访问特定 Namespace。

•
**TLS 加密**
：启用 Elasticsearch 和 Kibana 的 HTTPS 通信。

---

#### **七、替代方案：Loki 部署**

##### **1. 安装 Loki**

```
kubectl apply -f https://github.com/grafana/loki/releases/latest/deploy.yaml
```

##### **2. 安装 Promtail**

```
kubectl apply -f https://github.com/grafana/loki/releases/latest/deploy-promtail.yaml
```

##### **3. 验证日志收集**

```
# 查看 Loki 日志存储
kubectl logs -n loki -l app=loki --container=query-frontend
​
# 在 Grafana 中添加 Loki 数据源
grafana-url: http://grafana:3000
data-source: loki
```

---

#### **总结**

•
**推荐 EFK**
：适合需要复杂查询、企业级分析的场景。

•
**推荐 Loki**
：适合中小型集群、注重成本和易用性的场景。

•
**其他选择**
：云厂商日志服务（如 AWS CloudWatch、Azure Monitor）适合混合云环境。

无论选择哪种方案，建议结合
**Prometheus + Alertmanager**
实现日志异常的实时告警。