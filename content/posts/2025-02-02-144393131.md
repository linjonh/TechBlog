---
arturl_encode: "68747470733a2f2f626c6f:672e6373646e2e6e65742f323430315f38353337353239382f:61727469636c652f64657461696c732f313434333933313331"
layout: post
title: "学术最前沿2024最新深度多模态数据融合综述来袭"
date: 2025-02-02 18:48:18 +08:00
description: "多模态人工智能 (Multimodal AI) 通常涉及各种类型的数据（例如，图像、文本或从不同传感"
keywords: "多模态数据融合研究进展"
categories: ['未分类']
tags: ['算法', '机器人', '大数据', '人工智能', 'Prompt']
artid: "144393131"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=144393131
  alt: "学术最前沿2024最新深度多模态数据融合综述来袭"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=144393131
featuredImagePreview: https://bing.ee123.net/img/rand?artid=144393131
---

# 学术最前沿！2024最新深度多模态数据融合综述来袭！

**论文链接**
:

https://dl.acm.org/doi/10.1145/3649447

ACM Comput. Surv.

#### 简介

多模态人工智能 (Multimodal AI) 通常涉及各种类型的数据（例如，图像、文本或从不同传感器收集的数据）、特征工程（例如，提取、组合/融合）和决策。随着架构变得越来越复杂，多模态神经网络可以将特征提取、特征融合和决策过程集成到一个模型中。这些过程之间的界限越来越模糊。融合所基于的传统多模态数据融合分类法（例如，早期/晚期融合）已不再适合现代深度学习时代。因此，基于所使用的主流技术，本文提出了一种新的细粒度分类法，将最先进 (SOTA) 模型分为五类：
**编码器-解码器方法**
、
**注意力机制方法**
、
**图神经网络方法**
、
**生成神经网络方法**
和其
**他基于约束的方法**
。大多数现有的多模态数据融合综述仅关注一项特定任务，结合两种特定模态。与其他方法不同，本综述涵盖了更广泛的模态组合，包括视觉 + 语言（例如视频、文本）、视觉 + 传感器（例如图像、激光雷达）等，以及它们对应的任务（例如视频字幕、物体检测）。此外，还提供了这些方法之间的比较，以及该领域的挑战和未来方向。

#### 研究动机及贡献

![](https://img-blog.csdnimg.cn/img_convert/706c832e1465e458f3cc5deeecc33221.png)
图 4. 传统分类法将融合方法分为三类。

多模态数据融合方法传统上分为四类，如图4所示，包括
**早期融合、中期融合、晚期融合和混合融**
合：

（1）早期融合：将从每种模态获得的原始数据或预处理数据融合在一起，然后发送到模型；

（2）中期融合：将从不同模态提取的特征融合在一起，并发送到模型进行决策；

（3）后期融合（也称为“决策融合”）：将从每种模态获得的单独决策融合在一起形成最终预测，例如多数投票或加权平均值，或基于单独决策的元 ML 模型。

（4）混合融合：早期、中期和晚期融合的组合。随着大量多模态数据的出现，对更先进的方法（VS 精心挑选的融合方式）的需求空前增长。

然而，这种传统的融合分类只能为多模态数据融合提供基本指导。为了从多模态数据中提取更丰富的表征，DNN 的架构变得越来越复杂，不再单独、独立地从每个模态中提取特征。相反，表征学习、模态融合和决策在大多数情况下是交织在一起的。因此，无需精确指定多模态数据融合发生在网络的哪个部分。融合多模态数据的方法已经从传统的显式方法（例如早期融合、中期融合和后期融合）转变为更隐式的方法。

![](https://img-blog.csdnimg.cn/img_convert/0a455f82ba69736ba8270d2552263989.png)
图5.本文提出的深度多模态数据融合模型的细粒度分类图。

因此，本文对深度多模态数据融合进行了全面的概述和分类。本综述的贡献有三方面：

* 提供了一种新颖的深度多模态数据融合模型的细粒度分类法，不同于现有的根据早期、中期、晚期和混合融合等传统分类法对融合方法进行分类的调查。文中探索了最新进展，并将
  **SOTA 融合方法分为五类：编码器-解码器方法、注意力机制方法、GNN 方法、GenNN 方法和其他基于约束的方法**
  ，如图5所示。
* 对由各种模态组成的深度多模态数据融合进行了全面的回顾，包括视觉+语言、视觉+其他传感器等。现有的综述通常侧重于单一任务（如多模态物体识别）和两种模态的一种特定组合（如 RGB+深度数据），而本综述的范围更广，涵盖了各种模态及其相应的任务，包括多模态物体分割、多模态情感分析、VQA 和视频字幕等。
* 探索了深度多模态数据融合的新趋势，并比较和对比 SOTA 模型。一些过时的方法，如深度信念网络，被排除在本综述之外。然而，大型预训练模型，即深度学习的后起之秀，被纳入了本综述中，例如基于 Transformer 的预训练模型。

#### 基于编码器-解码器的融合方法

由于编码器-解码器模型网络架构具有强大的表示学习能力和良好的灵活性，近年来编码器-解码器被越来越多的深度多模态数据融合模型采用。基于模态和任务的差异，多模态数据融合模型的架构差异很大。本文总结了编码器-解码器融合方法的一般思想，并摒弃了一些无法推广的任务特定融合策略。编码器-解码器融合的一般结构如图6所示。我们可以看出，从
**不同个体模态获得的高级特征被投影到潜在空间中。然后，任务特定解码器将从输入多模态数据中学习到的潜在表示生成预测**
。在现实场景中，这种结构存在大量变体。我们将它们分为3个子类：原始数据级融合、分层特征融合和决策级融合。

![](https://img-blog.csdnimg.cn/img_convert/7490f800681ac1d22312d343e121f251.png)
图 6.融合多模态数据的编码器-解码器方法的一般结构。每个编码器的输入数据可以是每个模态的原始数据或每个模态的特征。编码器可以是独立的，也可以共享权重。解码器可以包含上采样或下采样操作，具体取决于特定任务。

#### 基于注意力机制的融合方法

注意力机制已成为多模态数据融合任务的主要工具之一。基于注意力机制的多模态模型可分为三类：

![](https://img-blog.csdnimg.cn/img_convert/3169625247f7270b38cc01bc68cd2eda.png)
图 10。不同注意力机制和融合架构的说明。（a）显示了专注于模态内关系的注意力机制。（b）显示了专注于模态间关系的注意力机制。（c）显示了基于 Transformer 的架构，包括模态内自注意力和模态间交叉注意力。

##### 模态内自注意力

总体结构如图10 (a) 所示。该方法的动机是迫使模型利用模态内关系。注意操作可以是基于点积的，也可以是基于加法门的，等等。这意味着，对于给定的模态，注意操作仅考虑来自该特定模态的数据。在 Transformer 模型中，用于注意计算的键 (K)、查询 (Q) 和值 (V) 张量是相同的，并且都来自相同的模态或序列，如图10 © 左侧所示。这确保了注意过程只集中在每个单一模态的数据上，从而可以对模态内关系进行有针对性的、不加稀释的分析。该方法通常用于多模态任务。

模态内自注意力机制具有诸多优势，包括灵活性、易于实现和相对较低的计算成本，这主要是因为它避免了辨别不同模态之间的差异和利用不同模态之间的相关性所需的复杂分析。然而，由于
**只关注模态内关系，这种方法可能会忽略不同模态之间可以提高模型性能的宝贵互补性**
。

##### 跨模态交叉注意

总体结构如图10 （b）所示。作为模态内自注意力的补充，模态间交叉注意力机制侧重于挖掘不同模态之间的关系。注意力分数是使用多模态数据计算的。这意味着每个注意操作都会考虑来自多个模态的数据。在 Transformer 模型的背景下，注意力计算中使用的查询（Q）张量以及键（K）和值（V）张量来自两个或多个不同的模态或序列，如图10 （c）右侧所示。由于某些模态流可以比其他模态流包含更多当前任务的信息，因此获得的注意权重可以仅适用于信息量更大的模态。它将为一个模态产生一个以另一个模态为条件的注意力池特征。

模态间交叉注意力机制虽然功能强大，但在实际应用中也存在一些挑战。模态间交叉注意力的本质是管理和利用不同模态之间的关系，这本身就会带来计算和结构复杂性。
**随着模态数量的增加，这种复杂性会变得尤为明显，需要更多的计算资源和更复杂的管理。同时，模态间交叉注意力机制的有效性与其处理的模态的质量和相关性密切相关。因此，质量差或不一致的模态会严重阻碍注意力机制的最佳性能，导致结果不佳**
。

##### 基于 Transformer 的方法

基于 Transformer 的大型预训练模型在许多多模态数据融合任务中占据主导地位，例如 interBERT和 videoBERT。如图10 © 所示。在编码器中，有堆叠的自注意力块，其中 K，Q，V缩放点积注意力机制的输入来自同一个张量，以探索输入的模态内关系。在解码器中，有堆叠的自注意力块和交叉注意力块，其中 K，Q，V来自不同的模态，例如Q来自第二种模态，而 K,V 来自第一种模态。这些自注意力和交叉注意力模块有助于模型有效地捕捉多模态内部和之间的关系。目前，
**基于 Transformer 的大型预训练模型可以分为两类：（1）单 Transformer 架构：在这种架构中，来自不同模态的输入数据将由单个编码器或多个堆叠编码器联合处理**
，例如 VideoBERT、HERO、NExT-GPT、ClipBERT和 DeCEMBERT；（2）
**多 Transformers 架构：在这种架构中，来自不同模态的输入数据将由特定于模态的 Transformers 分别编码，然后进行联合建模**
，例如 X-llm、UniVL 和 ActBERT。大型预训练模型能够学习多模态的综合表示并在下游任务上获得有竞争力的表现。然而，目前大多数大型预训练模型都集中在视觉语言领域。对于其他类型的模态，大型预训练模型的资源仍然有限。 表1总结并展示了最先进的大型预训练模型。

![](https://img-blog.csdnimg.cn/img_convert/8a4f6bdbc0d78cb1a5d52e4989ddd9d6.png)

#### 基于图神经网络的融合

基于编码器-解码器的融合和基于注意力的融合方法在从欧几里得空间内的数据中捕获隐藏模式方面取得了巨大成功。然而，它们很难处理从非欧几里得领域生成的数据，这些数据以具有复杂关系和对象间相互依赖关系的图来表示。
**图卷积网络( GCN ) 利用适用于图形数据的卷积层来聚合来自相邻节点的信息，从而促进跨模态的空间局部特征融合**
。另一个值得注意的子类型是图注意力网络( GAT )，它将注意力机制引入到图结构中。通过动态衡量相邻节点的重要性，GAT 可以更精确地关注图中的相关部分，通过捕获不同数据源之间的复杂模式和关系来增强融合过程。
![](https://img-blog.csdnimg.cn/img_convert/f75a764db9a6bf5244c2aeddeeb5412b.png)
图 11.基于 GNN 的多模态数据融合与集成的图示。（a）显示了基于 GNN 的多模态数据融合的总体架构。（b）显示了多模态数据的集成如何在图形构建过程中发生。

将 GNN 应用于多模态数据融合的一般策略可分为两类：

##### 个体模态的表征学习

可视化效果如图11 (a)所示。在该策略中，GNN 仅用于从图数据中提取新的表示，这意味着由非图结构化数据组成的子分支将不使用 GNN 进行特征提取。然后，将从不同模态中学习到的表示整合在一起。

##### 融合数据的表征学习

可视化结果如图11 (b) 所示。该融合策略的关键操作是图构建。一般来说，与之前的可以有多个子网络或子模态分支的策略不同，该策略在表示学习过程之前在图构建中融合多模态数据。

与其他融合方法相比，
**基于 GNN 的融合模型的优势**
包括：(1) 能够通过深度学习技术直接处理图结构数据，而无需将数据投影到欧几里得空间；(2)
**能够直观地利用图结构数据中节点之间的关系，并可以扩展到利用多模态问题中的模态内和模态间关系**
。然而，
**基于 GNN 的融合模型的缺点是，图构建过程通常高度依赖于对特定输入数据和任务特征的先验知识**
。它耗时耗空间，不易推广。到目前为止，我们回顾了基于编码器-解码器的融合、基于注意力的融合和基于 GNN 的融合。它们都可以利用不同模态之间的关系来提高多模态网络的性能。然而，这种融合方法难以处理缺失数据问题。

#### 基于生成神经网络的融合

GenNN 是深度学习领域的基础支柱，尤其适用于以数据生成、重建和建模为中心的任务。这些网络旨在捕获和复制数据的底层分布，使其对从图像合成到时间序列预测等大量应用都具有重要价值。鉴于其生成能力，生成模型在真实数据稀缺、嘈杂或不完整的情况下发挥了重要作用，提供了一种补充和增强现有数据集的强大机制。
**该类模型可以根据其他模态合成缺失的模态**
。 总体思路如图12所示。

![](https://img-blog.csdnimg.cn/img_convert/d682ad01882998365fc7696e2eb1c4cb.png)
图 12.基于 GenNN 的方法的总体架构。

基于 GenNN 的模型可用于解决多模态任务中的缺失数据问题，也可作为正则化器来利用多模态之间的语义相关性。然而，
**当涉及到利用多模态之间的模态内和模态间关系来提高模型性能时，基于 GenNN 的网络的架构灵活性相对较低，并且需要大量的训练技能**
。在这方面，注意力机制在科学界引起了更多的关注。由于注意力机制具有很强的揭示不同模态间内部和相互关系的能力，它已被广泛应用于多模态数据融合。

#### 其他基于约束的方法

上面回顾的大多数融合策略都是基于联合表示的，这意味着输入的多模态数据将被映射到一个共同的潜在空间中。该模型将学习输入数据的联合表示。然而，还有另一种方法，称为基于协调表示的框架，它在一定约束条件下学习每种模态的分离但协调的表示。

如图13 (a) 所示，协调表征架构分别处理各个模态，但对它们施加某些相似性约束，以将它们带入协调空间 。可以使用典型相关分析( CCA ) 约束、余弦距离约束、L2 距离约束或其他约束将学习到的每种模态表征相互比较。这些相似性约束将作为损失函数中的正则化项。

![](https://img-blog.csdnimg.cn/img_convert/231a82cc680415ee18f1a7abbb7d8e31.png)
图 13.（a）显示了具有某些约束的协调表示框架的可视化，以保持学习到的表示在语义上一致。（b）显示了侧重于模态间和模态内关系的张量融合机制。

**这些基于表示的协调融合的主要缺点之一是它们适用于输入模态为 2/3 的情况。当模态数量大于 3 时，网络架构可能过于复杂，性能无法得到保证。**

5种融合方法的比较结果总结在表2中。与 GenNN 和其他基于约束的方法只能在少数（例如 2）种模态上表现良好不同，基于编码器-解码器的方法和基于注意力机制的方法可以轻松推广到三种或更多种模态。此外，这两类方法可以很好地协同工作。

![](https://img-blog.csdnimg.cn/img_convert/7bd8e041da996d7310c340a016f2b2f1.png)

表3，对不同任务中融合方法的详细定量比较，并突出显示了每个任务中的最佳表现。

![](https://img-blog.csdnimg.cn/img_convert/25164cdbc247474f437b4e80412129aa.png)

#### 应用和数据集

目前，科学界和工业界有大量与深度多模态数据融合相关的应用。随着模态多样性的增加，多模态数据融合的下游任务类型也在不断增加。这里选择了一些与多模态数据融合相关的热门应用，并将它们分为三类：视觉与语言、视觉与传感器和其他。这些任务的数据集总结如表4所示：

![](https://img-blog.csdnimg.cn/img_convert/47cdb43312b282c4ade75f9ae0f614de.png)

#### 未来研究方向

未来方向 基于深度学习的多模态数据融合在近十年中发展迅速。然而，仍然存在一些研究空白：

##### 缺失模态挑战

在实际场景中，模态问题分为两类：模态缺失问题和模态噪声问题。模态缺失问题是指在多模态样本中至少一种模态缺失。模态噪声问题是指至少一种模态的数据有噪声或未对齐。大多数 SOTA 方法都基于数据集中不存在数据缺失问题的假设。许多基于这一假设的 SOTA 深度数据融合模型只有在理想条件下才能工作良好。

##### 缺乏数据

多模态数据融合是人工智能的一个新兴研究领域。目前公开的多模态数据集仍然有限。众所周知，基于深度学习的模型的性能通常取决于训练过程中使用的样本数量。高质量、大规模的数据集将极大地帮助模型学习到所观察到的对象或活动的准确、全面的表示。因此，创建更大、更高质量的多模态数据集是推动该领域发展的关键任务之一。

##### 缺乏大型预训练模型

大型预训练模型能够学习更全面的多模态表示。通过迁移学习，训练有素的大型预训练模型在下游任务上的表现可以比针对特定任务设计的模型更具竞争力。然而，目前现有的大型预训练多模态模型仅专注于 CV 和 NLP 的跨学科领域。未来，为其他跨学科领域创建大型预训练多模态模型可能是多模态数据融合的一个潜在方向。

##### 模型的可解释性

尽管数据驱动方法在不同学科中取得了令人难以置信的成功，但深度学习模型的一些缺点限制了它们的适用性。例如，它通常需要大量的训练数据和密集的计算资源来学习理想的映射，而这在通信降级或能源受限的环境中几乎不可用。此外，DNN 通常被设计为黑匣子，无法解释如何理解和表征预测结果和置信区间。

## 如何学习AI大模型 ？

#### “最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。

这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。

我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。

我意识到有很多经验和知识值得分享给大家，故此将并将重要的AI大模型资料包括
**AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。【保证100%免费】🆓**

## CSDN粉丝独家福利

这份完整版的 AI 大模型学习资料已经上传CSDN，朋友们如果需要可以
**扫描下方二维码**
&
**点击下方CSDN官方认证链接**
免费领取
**【保证100%免费】**
  
![](https://img-blog.csdnimg.cn/img_convert/889b2f9e52944e7410c04936159de6cb.jpeg)
  
读者福利：
[👉👉CSDN大礼包：《最新AI大模型学习资源包》免费分享 👈👈](https://mp.weixin.qq.com/s/6Gojoxcdpe4s8EDPev2r0A)

（👆👆👆安全链接，放心点击）

对于0基础小白入门：

> 如果你是零基础小白，想快速入门大模型是可以考虑的。
>
> 一方面是学习时间相对较短，学习内容更全面更集中。
>   
> 二方面是可以根据这些资料规划好学习计划和方向。

#### 👉1.大模型入门学习思维导图👈

要学习一门新的技术，作为新手一定要先学习成长路线图，方向不对，努力白费。

对于从来没有接触过AI大模型的同学，我们帮你准备了详细的学习成长路线图&学习规划。可以说是最科学最系统的学习路线，大家跟着这个大的方向学习准没问题。
**（全套教程文末领取哈）**
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/1a01ecf96fb142ae925bedad049ca7ba.png#pic_center)

#### 👉2.AGI大模型配套视频👈

很多朋友都不喜欢晦涩的文字，我也为大家准备了视频教程，每个章节都是当前板块的精华浓缩。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/50ece67c703340608cbfaf2daeea1358.png#pic_center)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/bd4618f1675b4870a7299d0212047e25.png)

#### 👉3.大模型实际应用报告合集👈

这套包含640份报告的合集，涵盖了AI大模型的理论研究、技术实现、行业应用等多个方面。无论您是科研人员、工程师，还是对AI大模型感兴趣的爱好者，这套报告合集都将为您提供宝贵的信息和启示。
**（全套教程文末领取哈）**

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/dc21268d8e9c4bda953ab1687bbca43d.png#pic_center)

#### 👉4.大模型落地应用案例PPT👈

光学理论是没用的，要学会跟着一起做，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。
**（全套教程文末领取哈）**

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a7511f74c1e14c4dbd1c846267399c2b.png#pic_center)

#### 👉5.大模型经典学习电子书👈

随着人工智能技术的飞速发展，AI大模型已经成为了当今科技领域的一大热点。这些大型预训练模型，如GPT-3、BERT、XLNet等，以其强大的语言理解和生成能力，正在改变我们对人工智能的认识。 那以下这些PDF籍就是非常不错的学习资源。
**（全套教程文末领取哈）**
  
![img](https://img-blog.csdnimg.cn/direct/f3f83643ea7e4954ad51c4b3099dddc6.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/348db3f6b65a4a8f8b94c3a6ab560457.jpeg)

#### 👉6.大模型面试题&答案👈

截至目前大模型已经超过200个，在大模型纵横的时代，不仅大模型技术越来越卷，就连大模型相关的岗位和面试也开始越来越卷了。为了让大家更容易上车大模型算法赛道，我总结了大模型常考的面试题。
**（全套教程文末领取哈）**

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/77792b8008fb4d849647c0db9adb148a.png)
  
**👉学会后的收获：👈**
  
•
**基于大模型全栈工程实现**
（前端、后端、产品经理、设计、数据分析等），通过这门课可获得不同能力；

•
**能够利用大模型解决相关实际项目需求**
： 大数据时代，越来越多的企业和机构需要处理海量数据，利用大模型技术可以更好地处理这些数据，提高数据分析和决策的准确性。因此，掌握大模型应用开发技能，可以让程序员更好地应对实际项目需求；

•
**基于大模型和企业数据AI应用开发，实现大模型理论、掌握GPU算力、硬件、LangChain开发框架和项目实战技能**
， 学会Fine-tuning垂直训练大模型（数据准备、数据蒸馏、大模型部署）一站式掌握；

•
**能够完成时下热门大模型垂直领域模型训练能力，提高程序员的编码能力**
： 大模型应用开发需要掌握机器学习算法、深度学习

## CSDN粉丝独家福利

这份完整版的 AI 大模型学习资料已经上传CSDN，朋友们如果需要可以
**扫描下方二维码&点击下方CSDN官方认证链接免费领取**

**【保证100%免费】**
  
![](https://img-blog.csdnimg.cn/img_convert/889b2f9e52944e7410c04936159de6cb.jpeg)

读者福利：
[👉👉CSDN大礼包：《最新AI大模型学习资源包》免费分享 👈👈](https://mp.weixin.qq.com/s/6Gojoxcdpe4s8EDPev2r0A)

（👆👆👆安全链接，放心点击）