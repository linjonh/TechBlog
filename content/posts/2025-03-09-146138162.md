---
layout: post
title: "论文精读GaussReg-Fast-3D-Registration-with-Gaussian-Splatting"
date: 2025-03-09 21:18:46 +0800
description: "Point Cloud Registration是大规模 3D 场景扫描和重建的核心问题。随着深度学习的发展，该任务已趋于成熟。然而，NeRF作为一种新兴的场景表示方法，在大规模场景重建中的注册问题尚未得到充分探索。这主要是由于其隐式表示方式，使得难以建模两个场景之间的几何关系。现有方法通常需要将隐式表示转换为显式表示再进行配准。最近，Gaussian Splatting被剔除，它使用显式3D高斯分布，既保持了高质量渲染，又提高了渲染速度。在本研究中，我们探索基于GS的3D配准任务，并提出了一种新颖的。"
keywords: "【论文精读】GaussReg: Fast 3D Registration with Gaussian Splatting"
categories: ['Nerf']
tags: ['计算机视觉', '深度学习', '人工智能', '3D']
artid: "146138162"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146138162
    alt: "论文精读GaussReg-Fast-3D-Registration-with-Gaussian-Splatting"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146138162
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146138162
cover: https://bing.ee123.net/img/rand?artid=146138162
image: https://bing.ee123.net/img/rand?artid=146138162
img: https://bing.ee123.net/img/rand?artid=146138162
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     【论文精读】GaussReg: Fast 3D Registration with Gaussian Splatting
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     今天读一篇发表在ECCV2024上的文章，作者来自港中深。
     <br/>
     文章链接：
     <a href="https://arxiv.org/pdf/2407.05254" rel="nofollow">
      GaussReg: Fast 3D Registration with Gaussian Splatting
     </a>
     <br/>
     项目地址：
     <a href="https://jiahao620.github.io/gaussreg/" rel="nofollow">
      GaussReg
     </a>
    </p>
    <p>
    </p>
    <p>
    </p>
    <h2>
     <a id="Abstract_5">
     </a>
     Abstract
    </h2>
    <p>
     Point Cloud Registration是大规模 3D 场景扫描和重建的核心问题。随着深度学习的发展，该任务已趋于成熟。然而，NeRF作为一种新兴的场景表示方法，在大规模场景重建中的注册问题尚未得到充分探索。这主要是由于其隐式表示方式，使得难以建模两个场景之间的几何关系。现有方法通常需要将隐式表示转换为显式表示再进行配准。
    </p>
    <p>
     最近，Gaussian Splatting被剔除，它使用显式3D高斯分布，既保持了高质量渲染，又提高了渲染速度。在本研究中，我们探索基于GS的3D配准任务，并提出了一种新颖的
     <strong>
      GaussReg
     </strong>
     框架，该框架采用 coarse-to-fine方法，兼具高效性和准确性：
    </p>
    <ul>
     <li>
      <strong>
       粗配准阶段
      </strong>
      ：基于点云配准方法，估计GS点云的粗略对齐。
     </li>
     <li>
      <strong>
       细配准阶段
      </strong>
      ：利用GS渲染的图像提取几何信息，实现更精确的对齐。
     </li>
    </ul>
    <p>
     此外，我们构建了
     <strong>
      ScanNet-GSReg
     </strong>
     数据集和
     <strong>
      GSReg
     </strong>
     数据集进行评估。实验结果表明，
     <strong>
      GaussReg 比 HLoc（SuperPoint + SuperGlue）快44倍，且精度相当
     </strong>
     ，在多个数据集上达到了 SOTA性能。
    </p>
    <h2>
     <a id="1_Introduction_14">
     </a>
     1 Introduction
    </h2>
    <h3>
     <a id="11_3D_15">
     </a>
     1.1 3D场景配准的背景
    </h3>
    <p>
     在传统的三维场景重建中，大型场景通常会被划分为多个独立的子场景，这些子场景可能处于不同的坐标系中，因此配准成为关键步骤。目前，点云配准技术较为成熟，如：
    </p>
    <ul>
     <li>
      <strong>
       ICP（Iterative Closest Point）
      </strong>
     </li>
     <li>
      <strong>
       D3Feat
      </strong>
     </li>
     <li>
      <strong>
       GeoTransformer
      </strong>
     </li>
    </ul>
    <p>
     这些方法通常通过从点云中提取特征点，并进行匹配以计算变换矩阵来完成配准。
    </p>
    <h4>
     <a id="12_NeRF_22">
     </a>
     1.2 NeRF与配准问题
    </h4>
    <p>
     最近，NeRF 作为 3D 场景建模的热门方法，能够生成高质量的合成视图。然而，NeRF在大规模场景重建中仍然面临两个挑战：
    </p>
    <ul>
     <li>
      <strong>
       数据采集时间长
      </strong>
      ：需要大量的图像或视频进行训练。
     </li>
     <li>
      <strong>
       计算成本高
      </strong>
      ：优化NeRF需要大量计算资源。
     </li>
    </ul>
    <p>
     为了解决这一问题，一种直接的方式是将大场景划分为多个小场景，并通过配准将它们组合在一起。目前NeRF配准方法主要有：
    </p>
    <ul>
     <li>
      <strong>
       NeRFuser
      </strong>
      ：渲染大量图像，使用SfM进行配准，但时间开销大。
     </li>
     <li>
      <strong>
       DReg-NeRF
      </strong>
      ：将NeRF转换为Voxel后进行配准，但受限于体素分辨率。
     </li>
    </ul>
    <h4>
     <a id="13_Gaussian_Splatting_31">
     </a>
     1.3 Gaussian Splatting的引入
    </h4>
    <p>
     <strong>
      GS是一种新型3D场景表示方法
     </strong>
     ，它采用
     <strong>
      显式3D高斯分布
     </strong>
     ，能够在保持高质量渲染的同时提高渲染速度。GS 的引入带来了一个新的问题：
    </p>
    <blockquote>
     <p>
      <strong>
       “既然Gaussian Splatting提供了点云表示，我们能否利用点云配准方法进行GS配准？”
      </strong>
     </p>
    </blockquote>
    <p>
     为了解决这一问题，我们提出了
     <strong>
      GaussReg
     </strong>
     框架，该框架结合点云配准与图像引导的细配准，以实现更高效和准确的GS配准。
    </p>
    <h2>
     <a id="2_Related_Work_37">
     </a>
     2 Related Work
    </h2>
    <p>
     介绍了相关工作。
    </p>
    <h2>
     <a id="3_Method_40">
     </a>
     3 Method
    </h2>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/3f9b8900ae5448aebb497755cd2b8ada.png#pic_center"/>
    </p>
    <h3>
     <a id="31_Overview_42">
     </a>
     3.1 Overview
    </h3>
    <p>
     如Fig. 2所示，我们提出的框架由两个阶段组成：
    </p>
    <ol>
     <li>
      <strong>
       Coarse Registration
      </strong>
      ：
      <ul>
       <li>
        从GS提取点云，并应用GeoTransformer进行初步对齐。
       </li>
       <li>
        由于GS点云通常存在噪声，粗配准的结果可能不够精确。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       Image-Guided Fine Registration
      </strong>
      ：
      <ul>
       <li>
        基于粗配准结果，定位重叠区域，并渲染若干图像。
       </li>
       <li>
        利用这些图像构造3D体素特征（Volumetric Features），以实现更精确的配准。
       </li>
      </ul>
     </li>
    </ol>
    <h3>
     <a id="32_Coarse_Registration_51">
     </a>
     3.2 Coarse Registration
    </h3>
    <ul>
     <li>
      <strong>
       点云提取
      </strong>
      ：GS由3D高斯点组成，每个点包含位置、透明度（Opacity）、旋转、缩放等属性。我们选取透明度高于 0.7 的点作为输入。
     </li>
     <li>
      <strong>
       特征提取
      </strong>
      ：
      <ul>
       <li>
        采用
        <strong>
         KPConv-FPN
        </strong>
        提取多尺度特征。
       </li>
       <li>
        最粗糙的特征用于Superpoint Match，使用Geotransformer来完成；精细的特征用于Point Match，使用ICP得到coarse registration（而非使用Geotransformer中的local-to-global registration）。
       </li>
      </ul>
     </li>
    </ul>
    <h3>
     <a id="33_ImageGuided_Fine_Registration_57">
     </a>
     3.3 Image-Guided Fine Registration
    </h3>
    <p>
     GS不仅包含几何信息，还可以渲染高质量图像。因此，我们利用图像进行更精确的配准：
    </p>
    <ol>
     <li>
      <strong>
       重叠图像选择（Overlap Image Selection）
      </strong>
      ：
      <ul>
       <li>
        计算相机视角的余弦相似度，选取重叠度最高的相机对。
       </li>
       <li>
        通过GS渲染深度图，并计算视角共享区域，筛选最优的图像对。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       图像引导 3D 特征提取（I3D Feature Extraction）
      </strong>
      ：
      <ul>
       <li>
        使用MVS提取深度和特征。
       </li>
       <li>
        构建Probability Volume以优化深度估计。
       </li>
      </ul>
     </li>
    </ol>
    <h3>
     <a id="34_Gaussian_Splatting_66">
     </a>
     3.4 Gaussian Splatting的融合与过滤
    </h3>
    <p>
     在最终变换完成后，我们将两个GS模型合并：
    </p>
    <ul>
     <li>
      变换位置、旋转、尺度、透明度。
     </li>
     <li>
      采用球谐系数调整颜色信息。
     </li>
     <li>
      进行GS过滤，去除重复或错误的高斯点。
     </li>
    </ul>
    <h2>
     <a id="4_Experiment_72">
     </a>
     4 Experiment
    </h2>
    <h3>
     <a id="41_Experiment_Setup_73">
     </a>
     4.1 Experiment Setup
    </h3>
    <p>
     我们构建了两个新数据集：
    </p>
    <ul>
     <li>
      <strong>
       ScanNet-GSReg
      </strong>
      ：基于ScanNet生成，包含不同的视角组合。
     </li>
     <li>
      <strong>
       GSReg
      </strong>
      ：包括6个室内和4个室外场景。
     </li>
    </ul>
    <h3>
     <a id="42_Comparison_78">
     </a>
     4.2 Comparison
    </h3>
    <p>
     在ScanNet-GSReg上的比较：
    </p>
    <table>
     <thead>
      <tr>
       <th>
        方法
       </th>
       <th>
        RRE（↓）
       </th>
       <th>
        RTE（↓）
       </th>
       <th>
        RSE（↓）
       </th>
       <th>
        成功率（↑）
       </th>
       <th>
        时间（↓）
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        <strong>
         HLoc (SuperPoint + SuperGlue)
        </strong>
       </td>
       <td>
        2.725
       </td>
       <td>
        0.099
       </td>
       <td>
        0.098
       </td>
       <td>
        75.6%
       </td>
       <td>
        212.3s
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         GaussReg (Ours)
        </strong>
       </td>
       <td>
        <strong>
         2.827
        </strong>
       </td>
       <td>
        <strong>
         0.042
        </strong>
       </td>
       <td>
        <strong>
         0.032
        </strong>
       </td>
       <td>
        <strong>
         100%
        </strong>
       </td>
       <td>
        <strong>
         4.8s
        </strong>
       </td>
      </tr>
     </tbody>
    </table>
    <p>
     提出的GaussReg比HLoc快44倍，并且具有更高的成功率。
    </p>
    <h3>
     <a id="43_Ablation_Study_86">
     </a>
     4.3 Ablation Study
    </h3>
    <p>
     简单的消融实验验证模块有效性。
    </p>
    <h2>
     <a id="5_Conclusion_88">
     </a>
     5 Conclusion
    </h2>
    <ul>
     <li>
      <strong>
       我们是首个探索 Gaussian Splatting 配准的工作
      </strong>
      。
     </li>
     <li>
      提出了
      <strong>
       Coarse-to-Fine Registration
      </strong>
      ，兼具高效性与准确性。
     </li>
     <li>
      通过图像引导细配准，提高了配准精度。
     </li>
     <li>
      构建了两个新数据集，为后续研究提供基准。
     </li>
    </ul>
    <p>
     未来工作可进一步优化GS模型融合，解决光照变化等问题。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="6874747073:3a2f2f626c6f672e6373646e2e6e65742f597568736948752f:61727469636c652f64657461696c732f313436313338313632" class_="artid" style="display:none">
 </p>
</div>


