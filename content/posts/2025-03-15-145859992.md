---
layout: post
title: "Python-数据分析Pandas一pandas库介绍,pandas操作文件读取和保存"
date: 2025-03-15 10:10:14 +0800
description: "Pandas是一个开源的、用于数据处理和分析的Python库，特别适合处理表格类数 据。它建立在NumPy数组之上，提供了高效的数据结构和数据分析工具，使得数据操作变得更加简单、便捷和高效。Pandas 的目标是成为 Python 数据分析实践与实战的必备高级工具，其长远目标是成为最强大、最灵活、可以支持任何语言的开源数据分析工具。"
keywords: "Python----数据分析（Pandas一：pandas库介绍，pandas操作文件读取和保存）"
categories: ['数据分析', 'Python']
tags: ['数据分析', 'Python', 'Pandas']
artid: "145859992"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145859992
    alt: "Python-数据分析Pandas一pandas库介绍,pandas操作文件读取和保存"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145859992
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145859992
cover: https://bing.ee123.net/img/rand?artid=145859992
image: https://bing.ee123.net/img/rand?artid=145859992
img: https://bing.ee123.net/img/rand?artid=145859992
---

# Python----数据分析（Pandas一：pandas库介绍，pandas操作文件读取和保存）

## 一、Pandas库

![](https://i-blog.csdnimg.cn/direct/d2680244f0d94e79983da6d0e647f1ae.png)

### 1.1、概念

Pandas是一个开源的、用于数据处理和分析的Python库，特别适合处理表格类数
据。它建立在NumPy数组之上，提供了高效的数据结构和数据分析工具，使得数据操作变得更加简单、便捷和高效。

Pandas 的目标是成为 Python 数据分析实践与实战的必备高级工具，其长远目标是成为最强大、最灵活、可以支持任何语言的开源数据分析工具

### 1.2、数据结构

1\. Series：一维数组，可以存储任何数据类型（整数、字符串、浮点数等），每个 元素都有一个与之对应的标签（索引）。

2\. DataFrame：二维表格型数据结构，可以视为多个 Series 对象的集合，每一列 都是一个
Series。每列可以有不同的数据类型，并且有行和列的标签。

### 1.3、数据操作

读取和保存数据：支持多种数据格式，如 CSV、Excel、SQL 数据库、JSON 等。

数据选择和过滤：提供灵活的索引和条件筛选功能，方便数据的提取和过滤。

数据清洗：提供了处理缺失数据、重复数据、异常值等数据清洗功能。

数据转换：通过 apply(), map(),replace()等方法进行数据转换。

数据合并：使用concat(), merge(), join()等方法进行数据的横向和纵向合并。

聚合和分组：使用 组和聚合。

### 1.4、主要特点

1\. 数据结构：Pandas提供了两种主要的数据结构：Series（一维数组）和 DataFrame（二维表格）。

2\. 数据操作：支持数据的增、删、改、查等操作，以及复杂的数据转换和清洗。

3\. 数据分析：提供丰富的数据分析方法，如聚合、分组、透视等。

4\. 文件读取与写入：支持多种文件格式（如CSV、Excel、SQL等）的读取和写入。

5\. 与其他库集成良好：Pandas 与许多其他三方库（如 NumPy、Matplotlib、 Scikit-
learn等）无缝集成，形成了一个强大的数据科学生态系统。

6\. 强大的社区支持：Pandas 拥有庞大的开发者社区，提供丰富的资源和学习材 料。

> #### 官方文档
>
> <http://pandas.pydata.org/pandas-docs/stable/>

> **安装**
>
> **pip install pandas**

## 二、Pandas的读取与保存

### 2.1、读取数据

#### 2.1.1、Pandas读取Excel文件

> **说明**
>
> 使用Pandas模块操作Excel时候，需要安装openpyxl
>
> pip install openpyxl==3.1.2

pandas.read_excel是pandas库中用于读取Excel文件（ .xls 或
数。它可以将Excel文件中的数据读取为DataFrame对象，便于进行数据分析和处 理。

    
    
    pandas.read_excel(io, sheet_name=0, header=0, index_col=None, usecols=None, squeeze=False,dtype=None, skiprows=None, nrows=None, na_values=None, keep_default_na=True, parse_dates=False, date_parser=None,skipfooter=0, convert_float=True, **kwds)

描述| 说明  
---|---  
io| 文件路径或文件对象。这是唯一必需的参数，用于指定要读取的Excel文件。  
sheet_name=0| 要读取的表名或表的索引号。默认为0，表示读取第一个工作 表。可以指定工作表名或索引号，如果指定多个，将返回一个字典，键为工作表
名，值为对应的DataFrame。  
header=0| 用作列名的行号，默认为0，即第一行作为列名。如果没有标题行， 可以设置为None。  
index_col=None| 用作行索引的列号或列名。默认为None，表示不使用任何列 作为索引。可以是一个整数、字符串或列名的列表。  
usecols=None| 要读取的列。默认为None，表示读取所有列。可以是一个整数 列表、字符串列表或Excel列的位置（如 [0, 1,
2]）或字母标记（如 ['A', 'B', 'C']）。  
squeeze=False| 如果读取的数据只有一列，当设置为True时，返回一个Series 而不是DataFrame。  
dtype=None| 指定某列的数据类型。默认为None，表示自动推断。可以是一个 字典，键为列名，值为NumPy数据类型。  
skiprows=None| 要跳过的行号或行号列表。默认为None，表示不跳过任何行。 可以是整数或整数列表。  
nrows=None| 读取的行数，从文件头开始。默认为None，表示读取所有行。  
na_values=None| 将指定的值替换为NaN。默认为None，表示不替换。可以是 一个值或值的列表。  
keep_default_na=True| 如果为True（默认），则除了通过 na_values指定的值外，还将默认的NaN值视为NaN。  
parse_dates=False| 是否尝试将列解析为日期。默认为False。可以是一个布尔 值、列名列表或列号的列表。  
date_parser=None| 用于解析日期的函数。默认为None，表示使用pandas默认 的日期解析器。  
skipfooter=0| 要跳过的文件底部的行数。默认为0，表示不跳过任何底部的 行。  
convert_float=True| 是否将所有浮点数转换为64位浮点数。默认为True，以 避免数据类型推断问题。  
**kwds| 允许用户传递其他关键字参数，这些参数可能会被引擎特定的读取器所 识别。  
      
    
    import pandas as pd
    pd.read_excel('stu_data.xlsx')  
    

> **指定导入哪个Sheet**
>  
>  
>     pd.read_excel('stu_data.xlsx',sheet_name='Target')
>     pd.read_excel('stu_data.xlsx',sheet_name=0)
>  

> **通过index_col指定行索引**
>  
>  
>     pd.read_excel('stu_data.xlsx',sheet_name=0,index_col=0)

> **通过header指定列索引**
>  
>  
>     pd.read_excel('stu_data.xlsx',sheet_name=0,header=1)
>     pd.read_excel('stu_data.xlsx',sheet_name=0,header=None)

> **通过usecols指定导入列**
>  
>  
>     pd.read_excel('stu_data.xlsx',usecols=[1,2,3])

#### 2.1.2、Pandas读取数据_CSV文件

pandas.read_csv 是一个非常强大的函数，用于从文件、URL、文件-like对象等读
取逗号分隔值（CSV）文件。这个函数有很多参数，允许你以多种方式自定义数据加 载过程。

    
    
    pandas.read_csv(filepath_or_buffer, sep, header, usercols, na_values, parse_dates, skiprows, nrows)

描述| 说明  
---|---  
filepath_or_buffer| 指定要读取的 CSV 文件的路径或文件对象。可以是一个
字符串，表示文件的绝对路径或相对路径；也可以是一个已经打开的文件对象 （例如通过 open() 函数打开的文件）。  
sep| 字符串，用于分隔字段的字符。默认是逗号,，但可以是任何字符，例如 ';' 或 '\t'（制表符）。  
header| 整数或整数列表，用于指定行号作为列名，或者没有列名，  
usecols| 列表或 callable，用于指定要读取的列。可以是列名的列表，也可以是 列号的列表。  
na_values| 字符串、列表或字典，用于指定哪些其他值应该被视为NA/NaN  
parse_dates| 列表或字典，用于指定将哪些列解析为日期。  
skiprows| 整数或列表，用于指定要跳过的行号或条件。  
nrows| 整数，用于指定要读取的行数。  
  
> 导入csv文件时除了指明文件路径，还需要设置编码格式。
>
> 在国内，Python中用得比较多的两种编码格式是UTF-8和gbk，默认编码格式是UTF-8。
>
> 通过设置参数encoding来设置导入的编码格式。
    
    
    pd.read_csv('stu_data.csv',encoding='gbk')

#### 2.1.4、Pandas读取txt文件

导入.txt文件用得方法时read_table()，read_table()是将利用分隔符分开的文件导入。DataFrame的通用函数。它不仅仅可以导入.txt文件，还可以导入.csv文件。

> **导入.txt文件**
>  
>  
>     pd.read_table('test_data.txt',encoding='utf-8',sep='\t')
>  

> **导入.csv文件，指明分隔符**
>  
>  
>     pd.read_table('stu_data.csv',encoding='gbk',sep=',')

#### 2.1.5、**读取数据库数据**

> **配置 MySQL 连接引擎**
>  
>  
>     conn = pymysql.connect(
>         host = 'localhost',
>         user = 'root',
>         passwd = 'root',
>         db = 'mydb',
>         port=3306,
>         charset = 'utf8'
>     )
>  
>
> **读取数据表**
>  
>  
>     pd.read_sql(
>         sql :需要执行的 SQL 语句/要读入的表名称
>         con : 连接引擎名称
>         index_col = None :将被用作索引的列名称
>         columns = None :当提供表名称时，需要读入的列名称 list
>     )
>     tab1 = pd.read_sql('SELECT * FROM t_menus',con=conn)
>     tab1 = pd.read_sql('SELECT count(1) FROM t_menus',con=conn)
>  
>  
>     number = 10
>     tab1 = pd.read_sql(
>       f'SELECT * FROM t_menus LIMIT {number}',
>         con=conn,
>         index_col = ['empno'],
>         )
>  
>
> 数据sql
>  
>  
>     CREATE TABLE `t_menus` (
>      `id` int(11) NOT NULL AUTO_INCREMENT,
>      `name` varchar(32) NOT NULL,
>      `path` varchar(32) DEFAULT NULL,
>      `level` int(11) DEFAULT NULL,
>      `pid` int(11) DEFAULT NULL,
>      PRIMARY KEY (`id`),
>      UNIQUE KEY `name` (`name`),
>      KEY `pid` (`pid`),
>      CONSTRAINT `t_menus_ibfk_1` FOREIGN KEY (`pid`) REFERENCES `t_menus`
> (`id`)
>     ) ENGINE=InnoDB AUTO_INCREMENT=52 DEFAULT CHARSET=utf8mb4;
>  
>  
>     INSERT INTO `t_menus` VALUES
> (-1,'全部',NULL,0,NULL),(1,'用户管理',NULL,1,-1),(2,'权限管理',NULL,1,-1),(3,'商品管理',NULL,1,-1),(4,'订单管理',NULL,1,-1),(5,'数据统计',NULL,1,-1),(11,'用户列表','/user_list',2,1),(21,'角色列表','/author_list',2,2),(22,'权限列表','/role_list',2,2),(31,'商品列表','/product_list',2,3),(32,'分类列表','/group_list',2,3),(33,'属性列表','/attribute_list',2,3),(41,'订单列表','/order_list',2,4),(51,'统计列表','/data_list',2,5);
>  

### 2.2、保存数据

    
    
    df.to_csv( 
      filepath_or_buffer :要保存的文件路径 
      sep =：分隔符 
      columns :需要导出的变量列表 
      header = True :指定导出数据的新变量名，可直接提供 list 
      index = True :是否导出索引 
      mode = 'w' : Python 写模式,读写方式：r,r+ , w , w+ , a , a+   
      encoding = 'utf-8' :默认导出的文件编码格式 
    )
    df2.to_csv('temp.csv')
    #===========================
    df.to_excel( 
       filepath_or_buffer :要读入的文件路径 
       sheet_name = 1|Sheet :要保存的表单名称 
    )
    df2.to_excel('temp.xlsx', index = False, sheet_name = data)
    

#### 2.2.1、to_csv

用于将DataFrame对象保存为CSV（逗号分隔值）文件的方法。

    
    
    DataFrame.to_csv(path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, mode='w', encoding=None, quoting=None, quotechar='"'， **kwargs)

描述| 说明  
---|---  
path_or_buf| 指定输出文件的路径或文件对象。  
sep| 字段分隔符，通常使用逗号,或制表符\t。  
na_rep| 缺失值的表示方式，默认为空字符串 ''。  
float_format| 浮点数的格式化方式，例如 '%.2f'用于格式化为两位小数。  
columns| 要写入的列的子集，默认为None，表示写入所有列。  
header| 是否写入行索引，通常设置为True或False，取决于是否需要索引。  
index| 是否写入列名，通常设置为True。  
mode| 写入模式，通常使用’w’（写入，覆盖原文件）或’a’（追加到文件末尾）。  
encoding| 文件编码，特别是在处理非ASCII字符时很重要  
quoting| 控制字段引用的行为，通常用于确保字段中的分隔符被正确处理。  
quotechar| 用于包围字段的字符，默认为双引号"。  
**kwargs| 其他关键字参数。  
      
    
    import pandas as pd
     # 创建一个简单的DataFrame
    data = {
    '姓名': ['张三', '李四', '王五'],
    '年龄': [28, 34, 29],
    '城市': ['北京', '上海', '广州']
    }
    df = pd.DataFrame(data)
    # 将DataFrame保存为CSV文件
    df.to_csv('人员信息.csv', index=False, encoding='utf_8_sig')

#### 2.2.2、to_excel

Pandas中的 to_excel用于将DataFrame保存为Excel文件。

    
    
    DataFrame.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, inf_rep='inf', freeze_panes=None, storage_options=None)

描述| 说明  
---|---  
excel_writer| 字符串或ExcelWriter对象，指定输出文件的路径或文件对象。  
sheet_name='Sheet1'| 要写入的工作表名称。  
na_rep=''| 指定缺失值的表示方式。  
float_format=None| 浮点数的格式化方式，例如’%.2f’。  
columns=None| 要写入的列的子集，默认为None，表示写入所有列。  
header=True| 是否写入列名，默认为True。  
index_label=None| 是否写入行索引，默认为True。  
index=True| 指定行索引列的列名，如果为None，并且 ： header为True，则使用索引名。  
startrow=| 写入DataFrame的起始行位置，默认为0。  
startcol=0| 写入DataFrame的起始列位置，默认为0。  
engine=None| 指定用于写入文件的引擎，可以是’openpyxl’（默认） 或’xlsxwriter’。  
merge_cells=True| 是否合并单元格，这在有合并单元格的Header时很有用。  
inf_rep='inf'| 指定无限大的表示方式。  
freeze_panes=None| 指定冻结窗口的单元格范围，例如’A2’。  
storage_options=None| 指定存储连接的参数，例如认证凭据。  
      
    
    import pandas as pd
    # 创建一个简单的DataFrame
    data = {
    '姓名': ['张三', '李四', '王五'],
    '年龄': [28, 34, 29],
    '城市': ['北京', '上海', '广州']
    }
    df = pd.DataFrame(data)
    # 将DataFrame保存为Excel文件
    df.to_excel('人员信息.xlsx', index=False)

#### 2.2.3、保存数据到数据库

> **注意**
>
> 需要安装sqlalchemy
>
> pip install sqlalchemy
    
    
    df.to_sql( 
      name :将要存储数据的表名称
      con : 连接引擎名称 
      if_exists = 'fail' :指定表已经存在时的处理方式 
           fail :不做任何处理(不插入新数据) 
           replace :删除原表并重建新表 
           append :在原表后插入新数据 
      index = True :是否导出索引 )
    
    
    from sqlalchemy import create_engine
    con = create_engine('mysql+pymysql://root:root@localhost:3306/mydb?charset=utf8') 
    
    
    df.to_sql('t_stu',con,if_exists=append)
    

## 三、思维导图

![](https://i-blog.csdnimg.cn/direct/2b8e4ff5cd7d4e58bbf6cfc2b94eb0f6.png)



