---
layout: post
title: "机器学习基石笔记五-Training-versus-Testing训练与测试过程"
date: 2024-11-05 15:20:46 +0800
description: "Recap and preview上节讲到机器学习的可行性，如果有足够的统计资料和有限的hypoth"
keywords: "机器学习算法训练测试过程"
categories: ['机器学习']
tags: ['无标签']
artid: "82319176"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=82319176
    alt: "机器学习基石笔记五-Training-versus-Testing训练与测试过程"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=82319176
featuredImagePreview: https://bing.ee123.net/img/rand?artid=82319176
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     【机器学习基石笔记五】------Training versus Testing（训练与测试过程）
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h3>
     Recap and preview
    </h3>
    <p>
     上节讲到机器学习的可行性，如果有足够的统计资料和有限的hypothesis，通过演算法无论选择什么样的
     <img alt="g" class="mathcode" src="https://private.codecogs.com/gif.latex?g">
      ，都会有
      <img alt="E_{in}(g)\approx E_{out}(g)" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/086eade23e1217ddc99f8af0f32e3375.gif">
       ；如果演算法A选择了一个hypothesis
       <img alt="g" class="mathcode" src="https://private.codecogs.com/gif.latex?g">
        ，其中
        <img alt="E_{in}(g)\approx 0" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bin%7D%28g%29%5Capprox%200">
         ，根据PCA可以保证
         <img alt="E_{out}(g)\approx 0" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bout%7D%28g%29%5Capprox%200">
          ，可以说明机器学习是可行的。
         </img>
        </img>
       </img>
      </img>
     </img>
    </p>
    <p>
     <img alt="" class="has" height="397" src="https://i-blog.csdnimg.cn/blog_migrate/39bc8ec8e393348d967bcb60363352c9.png" width="604"/>
    </p>
    <p>
     回顾之前的课程，其中第一节是说机器学习的定义是寻找一个最好的函数g，使得很接近理想的函数f，来保证
     <img alt="E_{out}(g)\approx 0" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bout%7D%28g%29%5Capprox%200">
      ；第二节课讲述在已知资料data上如何使
      <img alt="E_{in}(g)\approx 0" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bin%7D%28g%29%5Capprox%200">
       ，可以使用PLA和pocket等演算法来实现；第三节课介绍机器学习的分类，训练样本为批量数据（batch），处理监督式（supervised）和二元分类（binary classfication）的问题；第四节课介绍机器学习的可行性，通过统计学的知识将
       <img alt="E_{out}(g)" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bout%7D%28g%29"/>
       和
       <img alt="E_{in}(g)" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bin%7D%28g%29"/>
       联系起来，证明在一些假设条件下，
       <img alt="E_{in}(g)\approx E_{out}(g)" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/086eade23e1217ddc99f8af0f32e3375.gif"/>
       成立。
      </img>
     </img>
    </p>
    <p>
     <img alt="" class="has" height="271" src="https://i-blog.csdnimg.cn/blog_migrate/8f104f377db5dd094e59096291fb957a.png" width="609"/>
    </p>
    <p>
     总结下来，将机器学习分为两个核心问题，第一个是确保
     <img alt="E_{out}(g)\approx E_{in}(g)" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bout%7D%28g%29%5Capprox%20E_%7Bin%7D%28g%29"/>
     足够接近，第二个是使得
     <img alt="E_{in}(g)" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bin%7D%28g%29"/>
     足够小。机器学习的可行性的条件之一为hypothesis set中的个数M是有限的，那么M和核心问题之间有什么样的关系？
    </p>
    <p>
     根据hoeffding不等式：当M小的时候，
     <img alt="E_{out}(g)\approx E_{in}(g)" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bout%7D%28g%29%5Capprox%20E_%7Bin%7D%28g%29"/>
     发生的概率很大，但是演算法的选择有限，可能不会找到一个函数g使得
     <img alt="E_{in}(g)" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bin%7D%28g%29"/>
     足够小，不能保证核心问题二成立；当M大的时候，
     <img alt="E_{out}(g)\approx E_{in}(g)" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bout%7D%28g%29%5Capprox%20E_%7Bin%7D%28g%29"/>
     发生的概率很小，但是有很多的选择，可以更确保有一个g使得
     <img alt="E_{in}(g)" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bin%7D%28g%29"/>
     足够小，核心问题二成立，但是一可能不成立。
    </p>
    <p>
     <img alt="" class="has" height="130" src="https://i-blog.csdnimg.cn/blog_migrate/fe902b5aa3fe62ef0bb3a92c1f918a30.png" width="605"/>
    </p>
    <p>
     可以看出，M的选择直接影响机器学习的两个核心问题，使用正确的M或者hypothesis set很重要，那么是否
     <img alt="M = \infty" class="mathcode" src="https://private.codecogs.com/gif.latex?M%20%3D%20%5Cinfty"/>
     就不可行呢？所以要想办法解决无限大的M的问题。如果将M限定在一个有限大的变量
     <img alt="m_{H}" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/cc212c8ef19838a65c53661a04f0ebda.gif"/>
     内，问题就解决了。
    </p>
    <p>
     <img alt="" class="has" height="276" src="https://i-blog.csdnimg.cn/blog_migrate/f8dc10b3f0e00927c05f9c908a2e5343.png" width="610"/>
    </p>
    <h3>
     Effective number of line
    </h3>
    <p>
     从之前学过的hoeffding不等式出发，查看为什么M无限大的没办法做？首先查看它的推导过程：如果
     <img alt="E_{in}(h_{m})" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bin%7D%28h_%7Bm%7D%29"/>
     和
     <img alt="E_{out}(h_{m})" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bout%7D%28h_%7Bm%7D%29"/>
     之间相差很远，就说明这个hypothesis在data上是bad event，为了让演算法能够自由在hypothesis中做选择，将每个hypothesis发生bad event的几率全部或起来，（任何一个资料上发生bad event就说明这个hypothesis是不好的，使用连级的方式），计算发生bad event的几率的上限，所以当M=
     <img alt="\infty" class="mathcode" src="https://private.codecogs.com/gif.latex?%5Cinfty"/>
     ，即有无限个项相加bound就会很大，失去意义，此时就会出现问题。
    </p>
    <p>
     <img alt="" class="has" height="164" src="https://i-blog.csdnimg.cn/blog_migrate/29b16141949da2344c5376060a56da13.png" width="597"/>
    </p>
    <p>
     bound出现了什么问题？使用union bound是因为bad event不太会重叠，如果有两个很接近的hyothesis，那么对于大部分的训练样本D，
     <img alt="E_{in}(h_{1})=E_{in}(h_{2})" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bin%7D%28h_%7B1%7D%29%3DE_%7Bin%7D%28h_%7B2%7D%29"/>
     ,那么
     <img alt="E_{out}(h_{1})" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bout%7D%28h_%7B1%7D%29"/>
     和
     <img alt="E_{out}(h_{2})" class="mathcode" src="https://private.codecogs.com/gif.latex?E_%7Bout%7D%28h_%7B2%7D%29"/>
     就会很接近，所以两个hypothesis发生bad event的可能性就会非常接近。实际上，坏事情发生的情况是相互重叠的，但是使用union bound相加的时候没有考虑重叠，造成上限是过分估计的。为了解决重叠的问题，将无限个hypothesis分为有限多类。
    </p>
    <p>
     <img alt="" class="has" height="234" src="https://i-blog.csdnimg.cn/blog_migrate/f4974f4a1e8cce8f1f1decb0994d840d.png" width="597"/>
    </p>
    <p>
     怎样将hypothesis分类，考虑平面中有无限条直线，如果只有一个data x，那么只有两种线，将x归类为正或者负；如果有两个数据项
     <img alt="x_{1}" class="mathcode" src="https://private.codecogs.com/gif.latex?x_%7B1%7D"/>
     和
     <img alt="x_{2}" class="mathcode" src="https://private.codecogs.com/gif.latex?x_%7B2%7D"/>
     ，那么会有四种直线；如果有三个输入，会有八种情形；
    </p>
    <p>
     <img alt="" class="has" height="185" src="https://i-blog.csdnimg.cn/blog_migrate/b4b377a1348296ca56244455f6604666.png" width="558"/>
    </p>
    <p>
     <img alt="" class="has" height="273" src="https://i-blog.csdnimg.cn/blog_migrate/70a1b3151bbb6e3f6349a9a1deeeda46.png" width="534"/>
    </p>
    <p>
     <img alt="" class="has" height="347" src="https://i-blog.csdnimg.cn/blog_migrate/f1b8ee9051f8d932fa2286a272bae8c5.png" width="593"/>
    </p>
    <p>
     三个输入一定是8中情形吗？将三个输入换一种排列方式，发现只有六种情形。
    </p>
    <p>
     <img alt="" class="has" height="333" src="https://i-blog.csdnimg.cn/blog_migrate/4af596bfecf91c0653205ed2ff344510.png" width="603"/>
    </p>
    <p>
     对于四个数据的输入，发现有一种无法存在一条直线使其成立的情形，最多存在14条直线。
    </p>
    <p>
     <img alt="" class="has" height="340" src="https://i-blog.csdnimg.cn/blog_migrate/8e2ea96bfa098cc3c2a2c81ee791bcc5.png" width="604"/>
    </p>
    <p>
     那么对于N个数据的输入，有效的线的个数
     <img alt="&lt;2^{N}" class="mathcode" src="https://private.codecogs.com/gif.latex?%3C2%5E%7BN%7D"/>
     ，表示有效直线是有限的，如果使用有限的数字取代M，如果有效的数字比
     <img alt="2^{N}" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/d79329237dd824efecf20e46afe23fe6.gif"/>
     小很多很多，就可以保障机器学习可能学到东西。
    </p>
    <h3>
     Effective Number of hypothesis
    </h3>
    <p>
     引入一个新的名词：
     <strong>
      dichotomy(二分类)
     </strong>
     ，dichotomy就是将空间中的点（例如二维平面）用一条直线分成正类和负类。设H是将平面上的点用直线分开的所有hypothesis h的集合，dichotomy H与hypothesis H之间的关系是：hypothesis H是平面上
     <span style="color:#f33b45;">
      所有直线的集合
     </span>
     ，个数可能是无限个，而dichotomy H是平面上能将点完全用直线分开的
     <span style="color:#f33b45;">
      直线种类
     </span>
     ，它有一个上界就是
     <img alt="2^{N}" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/d79329237dd824efecf20e46afe23fe6.gif"/>
     。接下来，尝试使用dichotomy代替M。
    </p>
    <p>
     <img alt="" class="has" height="322" src="https://i-blog.csdnimg.cn/blog_migrate/da3a3ca7ea661cc81a39e5c5adcf7a42.png" width="555"/>
    </p>
    <p>
     再引入一个新的名词：
     <strong>
      成长函数（growth function）
     </strong>
     ，记为
     <img alt="m_{H}(H)" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/cc212c8ef19838a65c53661a04f0ebda.gif%28H%29"/>
     ，其定义是对于由N个点组成的不同集合中，某集合对应的hypothesis最大，那么这个dichotomy值就是
     <img alt="m_{H}(H)" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/cc212c8ef19838a65c53661a04f0ebda.gif%28H%29"/>
     ，它有一个上界
     <img alt="2^{N}" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/d79329237dd824efecf20e46afe23fe6.gif"/>
     。
     <span style="color:#f33b45;">
      成长函数就是effective lines的数量的最大值
     </span>
     ，根据成长函数的定义，二维平面上，
     <img alt="m_{H}(H)" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/cc212c8ef19838a65c53661a04f0ebda.gif%28H%29"/>
     随N变化的关系是如图的右方。
    </p>
    <p>
     <img alt="" class="has" height="245" src="https://i-blog.csdnimg.cn/blog_migrate/ea51e39744d46ee0af095f9f2c4c6454.png" width="558"/>
    </p>
    <p>
     如何计算成长函数？
    </p>
    <p>
     首先看一个简单的一维positive rays
    </p>
    <p>
     <img alt="" class="has" height="88" src="https://i-blog.csdnimg.cn/blog_migrate/3cffe4945a27ac5d8f7277851404b4c2.png" width="450"/>
    </p>
    <p>
     如果有N个点，则整个区域可以分为N+1段，很容易得到成长函数
     <img alt="m_{H}(N)=N+1" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/cc212c8ef19838a65c53661a04f0ebda.gif%28N%29%3DN&amp;plus;1"/>
     ，当N很大时，
     <img alt="(N+1)&lt; &lt; 2^{N}" class="mathcode" src="https://private.codecogs.com/gif.latex?%28N&amp;plus;1%29%3C%20%3C%202%5E%7BN%7D"/>
     ，这是希望看到的。
    </p>
    <p>
     对于一维的另一种情况positive interval，它的成长函数推导如下，这种情况下，N很大时，仍满足
     <img alt="m_{H}(N)=\frac{1}{2}N^{2}+\frac{1}{2}N+1&lt;&lt;2^{N}" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/cc212c8ef19838a65c53661a04f0ebda.gif%28N%29%3D%5Cfrac%7B1%7D%7B2%7DN%5E%7B2%7D&amp;plus;%5Cfrac%7B1%7D%7B2%7DN&amp;plus;1%3C%3C2%5E%7BN%7D"/>
     。
    </p>
    <p>
     <img alt="" class="has" height="391" src="https://i-blog.csdnimg.cn/blog_migrate/920227f9e4287b5033703b646553723d.png" width="567"/>
    </p>
    <p>
     假设在二维空间中，如果hypothesis是凸多边形或者类圆构成的封闭曲线，如下，左边是convex，右边不是convex的，对于这种的成长函数
     <img alt="m_{H}=2^{N}" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/6b4e0270e2c1332f85f1ca709bb7bd2d.gif"/>
     。这种情况下，N个点所有可能分类的情况都能被hypothesis set 覆盖，我们把这种情况称为shattered.。也就是说，如果能够找到一个数据分布集，hypothesis set对N个输入左右的分类情况都能做到，那么成长函数就是
     <img alt="2^{N}" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/d79329237dd824efecf20e46afe23fe6.gif"/>
     。
    </p>
    <p>
     <img alt="" class="has" height="296" src="https://i-blog.csdnimg.cn/blog_migrate/d5fd938e9b049d07386e1810c8d8892d.png" width="478"/>
     <img alt="" class="has" height="226" src="https://i-blog.csdnimg.cn/blog_migrate/0aa8eb3d6ff48a1e1f08aa25752af194.png" width="593"/>
    </p>
    <h3>
     Break Point
    </h3>
    <p>
     总结起来共有四种成长函数，分别为：
    </p>
    <p>
     <img alt="" class="has" height="159" src="https://i-blog.csdnimg.cn/blog_migrate/6bc9fcaddf461e6a6f2f2e9748434b5f.png" width="564"/>
     <img alt="" class="has" height="92" src="https://i-blog.csdnimg.cn/blog_migrate/13146bafceed922efe10ae3521c86589.png" width="462"/>
    </p>
    <p>
     对于四种成长函数，positive rays和positive intervals的成长函数都是polynomial（多项式）的，如果用
     <img alt="m_{H}" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/cc212c8ef19838a65c53661a04f0ebda.gif"/>
     代替M的话，这两种情况是比较好的，而convex sets的成长函数是exponential（指数型）的，即等于
     <img alt="2^{N}" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/d79329237dd824efecf20e46afe23fe6.gif"/>
     （不等式右边前半部分是指数增长，后半部分是指数减少的），并不能保证机器学习的可行性。对于2D perceptrons，之前查看含有3个点的输入，最多可以有8种hypothesis；而4个点的时候无法做出16条直线，最多是14个hypothesis，所以，将4成为2D perceptrons的break point(5、6、7等都是break point)。假设有k个点，如果k大于等于break point时，它的成长函数一定小于
     <img alt="2^{k}" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/da6d57f47a43aa8ee8a23d0059382648.gif"/>
     。
    </p>
    <p>
     根据break point的定义，我们知道满足
     <img alt="m_{H}(k)=2^{k}" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/cc212c8ef19838a65c53661a04f0ebda.gif%28k%29%3D2%5E%7Bk%7D"/>
     的k的最小值就是break point。对于之前的四种成长函数，它们的break point分别是：
    </p>
    <p>
     <img alt="" class="has" height="198" src="https://i-blog.csdnimg.cn/blog_migrate/969fb9a39121679378597551dcffe031.png" width="569"/>
    </p>
    <p>
     我们假设成长函数可能与break point存在某种关系：对于convex sets，没有break point，它的成长函数是
     <img alt="2^{N}" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/d79329237dd824efecf20e46afe23fe6.gif"/>
     ；对于positive rays,break point  k=2，它的成长函
     <img alt="O(N)" class="mathcode" src="https://private.codecogs.com/gif.latex?O%28N%29"/>
     数是；对于positive intervals，break point k=3，它的成长函数是
     <img alt="O(N^{2})" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/356c29f0f44b4168b11e0a6b4b63ce55.gif"/>
     ，根据这种推论，猜测2D perceptrons ，它的成长函数
     <img alt="m_{H}(N)=O(N^{k-1})" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/cc212c8ef19838a65c53661a04f0ebda.gif%28N%29%3DO%28N%5E%7Bk-1%7D%29"/>
     。如果成立，那么就可以用
     <img alt="m_{H}" class="mathcode" src="https://i-blog.csdnimg.cn/blog_migrate/cc212c8ef19838a65c53661a04f0ebda.gif"/>
     代替M，就满足了机器学习可行的条件。
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f6d305f3338313033353436:2f61727469636c652f64657461696c732f3832333139313736" class_="artid" style="display:none">
 </p>
</div>


