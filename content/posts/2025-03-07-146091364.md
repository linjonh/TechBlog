---
layout: post
title: "DeepSeek大语言模型下几个常用术语"
date: 2025-03-07 11:37:19 +0800
description: "昨天刷B站看到复旦赵斌老师说的一句话“科幻电影里在人脑中植入芯片或许在当下无法实现，但当下可以借助AI人工智能实现人类第二脑”（大概是这个意思）"
keywords: "DeepSeek大语言模型下几个常用术语"
categories: ['Ai']
tags: ['语言模型', '自然语言处理', '人工智能', 'Ollama', 'Deepseek', 'Ai']
artid: "146091364"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146091364
    alt: "DeepSeek大语言模型下几个常用术语"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146091364
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146091364
cover: https://bing.ee123.net/img/rand?artid=146091364
image: https://bing.ee123.net/img/rand?artid=146091364
img: https://bing.ee123.net/img/rand?artid=146091364
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     DeepSeek大语言模型下几个常用术语
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-tomorrow-night" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <blockquote>
     <p>
      昨天刷B站看到复旦赵斌老师说的一句话“科幻电影里在人脑中植入芯片或许在当下无法实现，但当下可以借助AI人工智能实现人类第二脑”（大概是这个意思）
     </p>
    </blockquote>
    <h3>
     <a id="_2">
     </a>
     基本概念
    </h3>
    <ul>
     <li>
      <code>
       AI
      </code>
      人工智能
     </li>
     <li>
      <code>
       NLP
      </code>
      自然语言处理
     </li>
     <li>
      <code>
       LLM
      </code>
      大语言模型
     </li>
     <li>
      <code>
       Hugging Face
      </code>
      一个提供了丰富的预训练模型和工具库的平台网站
     </li>
     <li>
      <code>
       Ollama
      </code>
      开源的本地大语言模型运行框架，用来在本地部署调用大语言模型，如
      <code>
       DeepSeek-R1
      </code>
     </li>
     <li>
      <code>
       vLLM
      </code>
      一个专注于高性能LLM推理的工具，也可以调用大语言模型，还可作模型文件转化或量化操作
     </li>
     <li>
      <code>
       llama.cpp
      </code>
      基于纯
      <code>
       C/C++
      </code>
      实现的高性能大语言模型推理引擎，专为优化本地及云端部署而设计，上面的
      <code>
       Ollama
      </code>
      即是在此基础上的封装和优化
     </li>
     <li>
      <code>
       Chatbox
      </code>
      为大语言模型对话提供人机界面交互功能，当然也可使用纯命令行方式，随个人喜好
     </li>
    </ul>
    <h3>
     <a id="_12">
     </a>
     量化
    </h3>
    <p>
     一种通过降低模型参数的表示精度来减少模型大小和计算需求的方法
    </p>
    <h3>
     <a id="_16">
     </a>
     常用的模型文件格式
    </h3>
    <ul>
     <li>
      <code>
       safetensors
      </code>
      - 由
      <code>
       Hugging Face
      </code>
      推出的一种新型安全模型存储格式，特别关注模型安全性、隐私保护和快速加载，仅包含张量的文件格式 ，如
      <code>
       model-00001-of-000002.safetensors
      </code>
     </li>
     <li>
      <code>
       GGUF All-in-one
      </code>
      二进制模型文件 ，如
      <code>
       DeepSeek-R1-Distill-Qwen-7B-Q3_K_L.gguf
      </code>
      <ul>
       <li>
        <code>
         Q（Quantization）
        </code>
        量化（压缩），后面的数值表示“单个参数的平均
        <code>
         bit
        </code>
        数”，数值越大越智能
       </li>
       <li>
        <code>
         K（K Quant）
        </code>
        即多个参数组合一
        <code>
         Block
        </code>
        做压缩，初衷是在同一个压缩级别上再补偿些精度回来
       </li>
       <li>
        <code>
         S L M
        </code>
        等用于区分混合精度的程度，字母顺序越小越精简
       </li>
      </ul>
     </li>
    </ul>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f796d7469616e79752f:61727469636c652f64657461696c732f313436303931333634" class_="artid" style="display:none">
 </p>
</div>


