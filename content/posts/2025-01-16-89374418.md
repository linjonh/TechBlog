---
layout: post
title: 面试准备篇之算法岗
date: 2025-01-16 10:31:24 +0800
categories: ['深度学习', '机器学习', 'C']
tags: ['算法与数据结构', '深度学习', '机器学习', 'Python', 'C']
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=89374418
    alt: 面试准备篇之算法岗
artid: 89374418
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=89374418
featuredImagePreview: https://bing.ee123.net/img/rand?artid=89374418
---
<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     面试准备篇之算法岗
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
    </p>
    <div class="toc">
     <h4>
      面试准备篇之算法岗
     </h4>
     <ul>
      <li>
       <a href="#_1" rel="nofollow">
        简介
       </a>
      </li>
      <li>
       <a href="#_3" rel="nofollow">
        一、语言基础知识准备
       </a>
      </li>
      <li>
       <ul>
        <li>
         <a href="#_C_4" rel="nofollow">
          （一） C++
         </a>
        </li>
        <li>
         <a href="#_Python_7" rel="nofollow">
          （二） Python
         </a>
        </li>
        <li>
         <ul>
          <li>
           <a href="#_8" rel="nofollow">
            基础教程
           </a>
          </li>
          <li>
           <a href="#python_parser_10" rel="nofollow">
            python parser模块
           </a>
          </li>
          <li>
           <a href="#Python_12" rel="nofollow">
            Python多线程和多进程编程
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a href="#_Pytorch_15" rel="nofollow">
          （三） Pytorch
         </a>
        </li>
        <li>
         <a href="#_Tensorflow_16" rel="nofollow">
          （四） Tensorflow
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a href="#_17" rel="nofollow">
        二、算法与数据结构基础知识准备
       </a>
      </li>
      <li>
       <ul>
        <li>
         <a href="#_18" rel="nofollow">
          （一）刷题专栏
         </a>
        </li>
        <li>
         <ul>
          <li>
           <a href="#offerhttpsblogcsdnnetexcellent_sunarticledetails99060883_19" rel="nofollow">
            剑指offer专题
           </a>
          </li>
          <li>
           <a href="#leetcodehttpsblogcsdnnetexcellent_sunarticledetails96482797_20" rel="nofollow">
            leetcode专题
           </a>
          </li>
          <li>
           <a href="#BFSDFShttpsblogcsdnnetexcellent_sunarticledetails98657927_21" rel="nofollow">
            BFS和DFS专题
           </a>
          </li>
          <li>
           <a href="#httpsblogcsdnnetexcellent_sunarticledetails98998158_22" rel="nofollow">
            动态规划之背包专题
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a href="#_23" rel="nofollow">
          （二）算法基础
         </a>
        </li>
        <li>
         <ul>
          <li>
           <a href="#_24" rel="nofollow">
            排序算法
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a href="#_26" rel="nofollow">
          （三）数据结构基础
         </a>
        </li>
        <li>
         <ul>
          <li>
           <a href="#_27" rel="nofollow">
            树结构
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
      <li>
       <a href="#_32" rel="nofollow">
        三、计算机网络和操作系统基础知识准备
       </a>
      </li>
      <li>
       <a href="#_33" rel="nofollow">
        四、线性代数和概率论基础知识准备
       </a>
      </li>
      <li>
       <a href="#_34" rel="nofollow">
        五、机器学习基础知识准备
       </a>
      </li>
      <li>
       <a href="#_35" rel="nofollow">
        六、深度学习基础知识准备
       </a>
      </li>
      <li>
       <ul>
        <li>
         <a href="#0_36" rel="nofollow">
          0、数据增强方式及细节
         </a>
        </li>
        <li>
         <a href="#1_44" rel="nofollow">
          1、基础知识
         </a>
        </li>
        <li>
         <a href="#2_46" rel="nofollow">
          2、梯度消失和梯度爆炸
         </a>
        </li>
        <li>
         <a href="#3_56" rel="nofollow">
          3、过拟合与欠拟合
         </a>
        </li>
        <li>
         <a href="#4CNN_poolingDropoutdeformable_conv_57" rel="nofollow">
          4、CNN pooling层、Dropout算梯度反向更新参数（顺便思考一下deformable conv怎么实现的）
         </a>
        </li>
        <li>
         <ul>
          <li>
           <a href="#pooling_58" rel="nofollow">
            pooling层
           </a>
          </li>
          <li>
           <a href="#Dropout_62" rel="nofollow">
            Dropout
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a href="#5_BatchNorm_64" rel="nofollow">
          5、深度学习中的归一化问题 (BatchNorm)
         </a>
        </li>
        <li>
         <a href="#6_67" rel="nofollow">
          6、数据集的归一化与标准化的原因与方法？
         </a>
        </li>
        <li>
         <ul>
          <li>
           <a href="#_68" rel="nofollow">
            原因
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a href="#7_76" rel="nofollow">
          7、深度学习优化器：梯度更新规则+缺点+如何选择
         </a>
        </li>
        <li>
         <ul>
          <li>
           <a href="#1BGD_SGD_77" rel="nofollow">
            (1)BGD, SGD
           </a>
          </li>
          <li>
           <a href="#2Momentum_80" rel="nofollow">
            (2)Momentum
           </a>
          </li>
          <li>
           <a href="#Adaptive_Gradient_85" rel="nofollow">
            Adaptive Gradient
           </a>
          </li>
          <li>
           <a href="#1MomentumAdaptive_Gradient_86" rel="nofollow">
            (1)Momentum和Adaptive Gradient的差别？
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a href="#8bias_variance_88" rel="nofollow">
          8、偏差（bias）和方差 (variance)
         </a>
        </li>
        <li>
         <a href="#911_89" rel="nofollow">
          9、1*1卷积有什么作用？
         </a>
        </li>
        <li>
         <a href="#10VGG33_90" rel="nofollow">
          10、VGG使用3*3卷积核的优势是什么?
         </a>
        </li>
        <li>
         <a href="#11_91" rel="nofollow">
          11、感受野的计算
         </a>
        </li>
        <li>
         <a href="#12_92" rel="nofollow">
          12、权重参数的初始化方式及范围
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a href="#_98" rel="nofollow">
        七、计算机视觉
       </a>
      </li>
      <li>
       <ul>
        <li>
         <a href="#_99" rel="nofollow">
          目标检测
         </a>
        </li>
        <li>
         <ul>
          <li>
           <a href="#rcnn_fastrcnn_fasterrcnn_100" rel="nofollow">
            rcnn, fast-rcnn, faster-rcnn
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
      <li>
       <a href="#_102" rel="nofollow">
        八、立体几何
       </a>
      </li>
      <li>
       <ul>
        <li>
         <a href="#_103" rel="nofollow">
          対极几何
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <p>
    </p>
    <h2>
     <a id="_1">
     </a>
     简介
    </h2>
    <p>
     在这里记录自己准备找工作的历程，接下来的半年会根据自己的学习和成长来更新。。。
    </p>
    <h2>
     <a id="_3">
     </a>
     一、语言基础知识准备
    </h2>
    <h3>
     <a id="_C_4">
     </a>
     （一） C++
    </h3>
    <p>
     <a href="http://c.biancheng.net/cpp/biancheng/cpp/rumen/" rel="nofollow">
      C++入门教程，C++基础教程《C++小白变怪兽》
     </a>
    </p>
    <ol>
     <li>
      <a href="http://c.biancheng.net/cplus/c2cpp/" rel="nofollow">
       第一章 从C到C++
      </a>
     </li>
    </ol>
    <h3>
     <a id="_Python_7">
     </a>
     （二） Python
    </h3>
    <h4>
     <a id="_8">
     </a>
     基础教程
    </h4>
    <p>
     <a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" rel="nofollow">
      廖雪峰Python
     </a>
    </p>
    <h4>
     <a id="python_parser_10">
     </a>
     python parser模块
    </h4>
    <p>
     <a href="https://blog.csdn.net/zjc910997316/article/details/85319894">
      parser模块
     </a>
    </p>
    <h4>
     <a id="Python_12">
     </a>
     Python多线程和多进程编程
    </h4>
    <p>
     <a href="http://c.biancheng.net/python/thread/" rel="nofollow">
      python多线程和多进程编程
     </a>
     <br/>
     <a href="https://blog.csdn.net/brucewong0516/article/details/85776194">
      python多进程
     </a>
    </p>
    <h3>
     <a id="_Pytorch_15">
     </a>
     （三） Pytorch
    </h3>
    <h3>
     <a id="_Tensorflow_16">
     </a>
     （四） Tensorflow
    </h3>
    <h2>
     <a id="_17">
     </a>
     二、算法与数据结构基础知识准备
    </h2>
    <h3>
     <a id="_18">
     </a>
     （一）刷题专栏
    </h3>
    <h4>
     <a id="offerhttpsblogcsdnnetexcellent_sunarticledetails99060883_19">
     </a>
     <a href="https://blog.csdn.net/excellent_sun/article/details/99060883">
      剑指offer专题
     </a>
    </h4>
    <h4>
     <a id="leetcodehttpsblogcsdnnetexcellent_sunarticledetails96482797_20">
     </a>
     <a href="https://blog.csdn.net/excellent_sun/article/details/96482797">
      leetcode专题
     </a>
    </h4>
    <h4>
     <a id="BFSDFShttpsblogcsdnnetexcellent_sunarticledetails98657927_21">
     </a>
     <a href="https://blog.csdn.net/excellent_sun/article/details/98657927">
      BFS和DFS专题
     </a>
    </h4>
    <h4>
     <a id="httpsblogcsdnnetexcellent_sunarticledetails98998158_22">
     </a>
     <a href="https://blog.csdn.net/excellent_sun/article/details/98998158">
      动态规划之背包专题
     </a>
    </h4>
    <h3>
     <a id="_23">
     </a>
     （二）算法基础
    </h3>
    <h4>
     <a id="_24">
     </a>
     排序算法
    </h4>
    <ol start="3">
     <li>
      <a href="https://blog.csdn.net/excellent_sun/article/details/89383261">
       选择排序（selectionsort）
      </a>
     </li>
    </ol>
    <h3>
     <a id="_26">
     </a>
     （三）数据结构基础
    </h3>
    <h4>
     <a id="_27">
     </a>
     树结构
    </h4>
    <ol>
     <li>
      <a href="https://www.cnblogs.com/skywang12345/p/3576373.html" rel="nofollow">
       二叉查找树之C++实现
      </a>
     </li>
     <li>
      <a href="https://blog.csdn.net/isea533/article/details/80345507">
       二叉查找树之删除节点
      </a>
     </li>
     <li>
      <a href="https://blog.csdn.net/chudelong1/article/details/82698010">
       红黑树（一）之小白入门
      </a>
     </li>
    </ol>
    <h2>
     <a id="_32">
     </a>
     三、计算机网络和操作系统基础知识准备
    </h2>
    <h2>
     <a id="_33">
     </a>
     四、线性代数和概率论基础知识准备
    </h2>
    <h2>
     <a id="_34">
     </a>
     五、机器学习基础知识准备
    </h2>
    <h2>
     <a id="_35">
     </a>
     六、深度学习基础知识准备
    </h2>
    <h3>
     <a id="0_36">
     </a>
     0、数据增强方式及细节
    </h3>
    <p>
     （1）哪些数据增强方式？
     <br/>
     1、crop_size
     <br/>
     2、scale
     <br/>
     3、flip
     <br/>
     4、rotate
     <br/>
     注意：rotation的范围为-10到10度。
     <br/>
     5、blur
    </p>
    <h3>
     <a id="1_44">
     </a>
     1、基础知识
    </h3>
    <p>
     <a href="https://www.captainbed.net/" rel="nofollow">
      人工智能基础：https://www.captainbed.net/
     </a>
    </p>
    <h3>
     <a id="2_46">
     </a>
     2、梯度消失和梯度爆炸
    </h3>
    <p>
     （1）方案1-预训练加微调
     <br/>
     （2）方案2-梯度剪切、正则
     <br/>
     （3）方案3-relu、leakrelu、elu等激活函数
     <br/>
     （4）方案4-batchnorm
     <br/>
     （5）方案5-残差结构
     <br/>
     （6）方案6-LSTM
     <br/>
     <a href="https://blog.csdn.net/qq_16137569/article/details/81584165">
      参考链接1
     </a>
     <br/>
     <a href="https://blog.csdn.net/raojunyang/article/details/79962665">
      参考链接2
     </a>
     <br/>
     <a href="https://blog.csdn.net/wj5637606/article/details/84582966">
      深入理解L1、L2范数
     </a>
    </p>
    <h3>
     <a id="3_56">
     </a>
     3、过拟合与欠拟合
    </h3>
    <h3>
     <a id="4CNN_poolingDropoutdeformable_conv_57">
     </a>
     4、CNN pooling层、Dropout算梯度反向更新参数（顺便思考一下deformable conv怎么实现的）
    </h3>
    <h4>
     <a id="pooling_58">
     </a>
     pooling层
    </h4>
    <p>
     无论max pooling还是mean pooling，都没有需要学习的参数。因此，在卷积神经网络的训练中，Pooling层需要做的仅仅是将误差项传递到上一层，而没有梯度的计算。
     <br/>
     （1）max pooling层：对于max pooling，下一层的误差项的值会原封不动的传递到上一层对应区块中的最大值所对应的神经元，而其他神经元的误差项的值都是0；
     <br/>
     （2）mean pooling层：对于mean pooling，下一层的误差项的值会平均分配到上一层对应区块中的所有神经元
    </p>
    <h4>
     <a id="Dropout_62">
     </a>
     Dropout
    </h4>
    <p>
     <a href="https://blog.csdn.net/oBrightLamp/article/details/84105097">
      Dropout详解1
     </a>
    </p>
    <h3>
     <a id="5_BatchNorm_64">
     </a>
     5、深度学习中的归一化问题 (BatchNorm)
    </h3>
    <p>
     <a href="http://www.julyedu.com/video/play/69/686" rel="nofollow">
      归一化问题详解1
     </a>
     <br/>
     注：看BN原论文
     <a href="https://arxiv.org/abs/1502.03167" rel="nofollow">
      Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
     </a>
    </p>
    <h3>
     <a id="6_67">
     </a>
     6、数据集的归一化与标准化的原因与方法？
    </h3>
    <h4>
     <a id="_68">
     </a>
     原因
    </h4>
    <p>
     （1）从寻找最优解的角度分析
     <br/>
     <a href="https://blog.csdn.net/wuxiaosi808/article/details/78059051">
      数据集归一化的原因与方法
     </a>
    </p>
    <p>
     在训练模型之前，需要对特征进行一定的处理，最常见的处理方式之一就是数据的规范化。数据的规范化的作用主要有两个：去掉量纲，使得指标之间具有可比性；将数据限制到一定区间， 使得运算更为便捷。归一化就是典型的数据规范化方法，常见的数据规范化方法如下：
     <br/>
     1、线性函数归一化(Min-Max scaling)
     <br/>
     2、0均值标准化(Z-score standardization)
     <br/>
     0均值归一化方法将原始数据集归一化为均值为0、方差1的数据集（[0, 1]范围）。
    </p>
    <h3>
     <a id="7_76">
     </a>
     7、深度学习优化器：梯度更新规则+缺点+如何选择
    </h3>
    <h4>
     <a id="1BGD_SGD_77">
     </a>
     (1)BGD, SGD
    </h4>
    <p>
     <a href="https://www.cnblogs.com/lliuye/p/9451903.html" rel="nofollow">
      BGD, SGD, MBGD详解
     </a>
     <br/>
     <a href="https://blog.csdn.net/u012328159/article/details/80252012">
      几种梯度下降方法对比
     </a>
    </p>
    <h4>
     <a id="2Momentum_80">
     </a>
     (2)Momentum
    </h4>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/438c8995af80aaa0045ccb259bfbede2.png">
      <br/>
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         η 
        
       
         : 
        
       
      
        \eta:
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.625em; vertical-align: -0.19444em;">
          </span>
          <span class="mord mathdefault" style="margin-right: 0.03588em;">
           η
          </span>
          <span class="mspace" style="margin-right: 0.277778em;">
          </span>
          <span class="mrel">
           :
          </span>
         </span>
        </span>
       </span>
      </span>
      学习率
      <br/>
      注意：学习率的初始化范围以及调节技巧
      <br/>
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         ρ 
        
       
         : 
        
       
      
        \rho:
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.625em; vertical-align: -0.19444em;">
          </span>
          <span class="mord mathdefault">
           ρ
          </span>
          <span class="mspace" style="margin-right: 0.277778em;">
          </span>
          <span class="mrel">
           :
          </span>
         </span>
        </span>
       </span>
      </span>
      momentum
     </img>
    </p>
    <h4>
     <a id="Adaptive_Gradient_85">
     </a>
     Adaptive Gradient
    </h4>
    <h4>
     <a id="1MomentumAdaptive_Gradient_86">
     </a>
     (1)Momentum和Adaptive Gradient的差别？
    </h4>
    <h3>
     <a id="8bias_variance_88">
     </a>
     8、偏差（bias）和方差 (variance)
    </h3>
    <h3>
     <a id="911_89">
     </a>
     9、1*1卷积有什么作用？
    </h3>
    <h3>
     <a id="10VGG33_90">
     </a>
     10、VGG使用3*3卷积核的优势是什么?
    </h3>
    <h3>
     <a id="11_91">
     </a>
     11、感受野的计算
    </h3>
    <h3>
     <a id="12_92">
     </a>
     12、权重参数的初始化方式及范围
    </h3>
    <p>
     （1）权重参数的初始化方式
     <br/>
     1、高斯分布
     <br/>
     2、均匀分布
     <br/>
     3、Xavier/Glorot Initialization（适用于激活函数是sigmoid和tanh）
     <br/>
     4、MSRA/He initialization（适用于激活函数relu）
    </p>
    <h2>
     <a id="_98">
     </a>
     七、计算机视觉
    </h2>
    <h3>
     <a id="_99">
     </a>
     目标检测
    </h3>
    <h4>
     <a id="rcnn_fastrcnn_fasterrcnn_100">
     </a>
     rcnn, fast-rcnn, faster-rcnn
    </h4>
    <h2>
     <a id="_102">
     </a>
     八、立体几何
    </h2>
    <h3>
     <a id="_103">
     </a>
     対极几何
    </h3>
    <p>
     本质矩阵E（Essential Matrix）:反应空间一点p的像素在不同视角摄像机下摄像机坐标系中的表示之间的关系。
     <br/>
     基础矩阵F（Fundamental Matrix）:反应空间一点p的像素点在不同视角摄像机下图像坐标系中的表示之间的关系。
     <br/>
     极线约束：
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
</div>


