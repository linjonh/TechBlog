---
arturl_encode: "68747470733a2f:2f626c6f672e6373646e2e6e65742f75303130343936383537:2f61727469636c652f64657461696c732f3739383036303839"
layout: post
title: "Python爬取微博热搜榜,将数据存入数据库"
date: 2024-08-02 17:01:43 +08:00
description: "一直想学习用Python来进行数据的爬取，也一直想知道Python连接数据库的操作，今天刚好看到的这"
keywords: "爬取微博热搜榜"
categories: ['爬虫']
tags: ['爬虫', '数据库', '微博', 'Python', 'Bat']
artid: "79806089"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=79806089
    alt: "Python爬取微博热搜榜,将数据存入数据库"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=79806089
featuredImagePreview: https://bing.ee123.net/img/rand?artid=79806089
---

# Python爬取微博热搜榜，将数据存入数据库

一直想学习用Python来进行数据的爬取，也一直想知道Python连接数据库的操作，今天刚好看到的这篇文章满足了这两个条件，我试着爬了下微博，并成功将数据添加到数据库中，颇为欢喜。作者写的很简单，有些过程省略掉了，因此我尝试了好几次才成功，接下来记录自己的成功操作。

### 一、选择需要爬取的网页

这里是用来爬取微博热搜榜的数据，网页地址为
<http://s.weibo.com/top/summary>
，打开网页并按下F12进入开发者模式，找到<td class = "td_05">...</td>里的内容，如图所示：

![](https://i-blog.csdnimg.cn/blog_migrate/a75bb3f688cb49c79697433e6d908162.png)

![](https://i-blog.csdnimg.cn/blog_migrate/6f6b58c80653144cca0b4e192142c308.png)

![](https://i-blog.csdnimg.cn/blog_migrate/d114801ff1a6914cecf007d45dac4c85.png)

href后面的内容即为对应的中文编码的源码，其中很多25应该是干扰字符，后面删掉解析就可以发现是微博热搜的标题。我数了下，一共有27个，刚好第一个标题为“比伯愿为赛琳娜捐肾”九个字，一个汉字占三个字符，一共27个。

我用的是Python3.6.0，开发工具为PyCharm2017.2.3，数据库为MySql。

### 二、下面是完整代码

```
#-*-coding:utf-8-*-
import urllib, pymysql, requests, re
# 配置数据库
config = {
    'host': '127.0.0.1',
    'port': 3306,
    'user': 'root',
    'password': '******',
    'db': 'weibo',
    'charset': 'utf8',
}
# 链接数据库
conn = pymysql.connect(**config)
cursor = conn.cursor()
# 获取热搜源码
weiboHotFile = requests.get('http://s.weibo.com/top/summary')
weiboHotHtml = weiboHotFile.text
# 正则表达式匹配URL，找到title
hotKey = re.compile(r'td class=\\"td_05\\"><a href=\\"\\/weibo\\/(.*?)&Refer=top\\"')
hotKeyListBe = hotKey.findall(weiboHotHtml)
rank = 1
# 遍历获取的title列表
for title in hotKeyListBe:
    # 去除干扰数字
    title = title.replace('25', '')
    url = 'http://s.weibo.com/weibo/' + title
    title = urllib.parse.unquote(title)
    print(str(rank)+' '+title + ' '+' '+url+'\n')
    # 执行数据语句
    sql = 'insert into hotsearch (rank, daydate, mindate, title, url) values (%s, curdate(), curtime(), %s, %s)'
    cursor.execute(sql, (rank, title, url))
    rank += 1
    conn.commit()
cursor.close()
conn.close()
```

### 三、注意事项

这里要说明一下，数据库的连接，db是数据库的名称weibo（这个可以自己取名字），charset表示字符集为utf8，表的名称为hotsearch，里面有rank，daydate，mindate，title，url为表中的字段，作者未说明这些字段的定义，我自己定义如下：

![](https://i-blog.csdnimg.cn/blog_migrate/3c2f6a7dab6ad430bbc283688d592635.png)

对于varchar的类型，如果默认，则其编码模式为latin1，我刚开始不知道，运行py文件一直报错，然后网上搜索了一下，需要将latin1改为utf8，这样就对了。

![](https://i-blog.csdnimg.cn/blog_migrate/c589fb150afe2156fd68ab7996d3867c.png)

最终可在数据库中查看导入成功的数据。

![](https://i-blog.csdnimg.cn/blog_migrate/0d3cc804852a2086f86590170e355ffc.png)

### 四、利用bat脚本运行py文件

当然，作者还写了利用bat直接运行py文件，这样更快些，我在网上查了下，也学会了：

1、找到.py对应所在的文件目录并记录下来，比如我的就是E:\***\pythonprojects\BlogSpider

2、创建一个txt文件，在文件中写入如下内容：

@echo off
  
cd E:\***\pythonprojects\BlogSpider

start python CrawlerBlog01.py

3、将txt文件改为bat后缀，然后双击运行即可。

### 五、参考链接：

<https://blog.csdn.net/weixin_41407399/article/details/79775900>

[https://www.cnblogs.com/yingdiblog/p/7244228.html](https://blog.csdn.net/weixin_41407399/article/details/79775900)

<http://s.weibo.com/top/summary>