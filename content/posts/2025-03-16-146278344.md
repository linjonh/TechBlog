---
layout: post
title: "搜广推校招面经五十"
date: 2025-03-16 00:15:00 +0800
description: "处理连续数据，以加速决策树的训练。这种方法避免了对所有特征值进行遍历，大幅提升计算效率，同时对模型精度影响很小。，避免传统 GBDT 在遍历所有样本时的高昂计算开销。见【搜广推校招面经九、十】LightGBM 使用。这种方式的核心目标是。"
keywords: "搜广推校招面经五十"
categories: ['搜广推面经']
tags: ['算法', '深度学习', '机器学习', '搜索算法', '推荐算法', '人工智能', 'Pytorch']
artid: "146278344"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146278344
    alt: "搜广推校招面经五十"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146278344
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146278344
cover: https://bing.ee123.net/img/rand?artid=146278344
image: https://bing.ee123.net/img/rand?artid=146278344
img: https://bing.ee123.net/img/rand?artid=146278344
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     搜广推校招面经五十
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h2>
     <a id="shopee_0">
     </a>
     shopee搜广推算法
    </h2>
    <h2>
     <a id="_1">
     </a>
     一、如何进行连续数据的分箱，除了传统统计方法，有什么先进方法
    </h2>
    <h3>
     <a id="11__2">
     </a>
     1.1. 为什么要进行连续数据的分箱？
    </h3>
    <ol>
     <li>
      <strong>
       降低数据复杂度
      </strong>
      ：将连续数据转换为离散区间，简化数据分析和模型构建。
     </li>
     <li>
      <strong>
       减少噪声影响
      </strong>
      ：分箱可以减少数据中的噪声，提高模型的鲁棒性。
     </li>
     <li>
      <strong>
       处理非线性关系
      </strong>
      ：分箱可以帮助捕捉连续变量与目标变量之间的非线性关系。
     </li>
     <li>
      <strong>
       提高计算效率
      </strong>
      ：离散化后的数据可以减少计算复杂度，加快模型训练速度。
     </li>
     <li>
      <strong>
       增强解释性
      </strong>
      ：离散化的数据更容易理解和解释，特别是在业务场景中。
     </li>
    </ol>
    <h3>
     <a id="12__10">
     </a>
     1.2. 如何进行连续数据的分箱？
    </h3>
    <h4>
     <a id="1_11">
     </a>
     (1)传统统计方法
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        等宽分箱（Equal Width Binning）
       </strong>
       ：
      </p>
      <ul>
       <li>
        将数据范围划分为等宽的区间。
       </li>
       <li>
        例如，将年龄分为0-10, 10-20, 20-30等区间。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        等频分箱（Equal Frequency Binning）
       </strong>
       ：
      </p>
      <ul>
       <li>
        将数据划分为包含相同数量样本的区间。
       </li>
       <li>
        例如，将数据分为4个区间，每个区间包含25%的数据。
       </li>
      </ul>
     </li>
    </ol>
    <h4>
     <a id="2_20">
     </a>
     (2)先进方法
    </h4>
    <ol>
     <li>
      <strong>
       基于核密度估计的分箱
      </strong>
      ：
      <ul>
       <li>
        使用核密度估计（KDE）来识别数据的密度分布，并根据密度变化进行分箱。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       基于贝叶斯优化的分箱
      </strong>
      ：
      <ul>
       <li>
        使用贝叶斯优化方法自动搜索最优的分箱策略，最大化某种评价指标（如AUC）。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       基于自适应分箱的方法
      </strong>
      ：
      <ul>
       <li>
        使用自适应算法（如AdaBoost）动态调整分箱边界，以适应数据分布的变化。
       </li>
       <li>
        使用LightGBM的直方图算法，将连续特征分成不同的桶，在每个桶内，统计样本数量、目标值的累积和（用于计算分裂增益）。（实际并没有改变特征，只是计算分裂增益）
       </li>
      </ul>
     </li>
     <li>
      <strong>
       IV和WOE在分箱中的应用
      </strong>
      ：
     </li>
    </ol>
    <h3>
     <a id="13_IVWOE_30">
     </a>
     1.3. IV和WOE(多用于金融风控、信用评分等领域)
    </h3>
    <h4>
     <a id="WOEWeight_of_Evidence_31">
     </a>
     WOE（Weight of Evidence，证据权重）
    </h4>
    <ul>
     <li>
      <strong>
       定义
      </strong>
      ：WOE用于衡量某个分箱中目标事件（如违约）与非目标事件（如未违约）的比例差异。
     </li>
     <li>
      <strong>
       公式
      </strong>
      ：
      <br/>
      <span class="katex--display">
       <span class="katex-display">
        <span class="katex">
         <span class="katex-mathml">
          W 
          
         
           O 
          
         
           E 
          
         
           = 
          
         
           ln 
          
         
           ⁡ 
          
          
          
            ( 
           
           
           
             Good% 
            
           
             Bad% 
            
           
          
            ) 
           
          
         
        
          WOE = \ln\left(\frac{\text{Good\%}}{\text{Bad\%}}\right)
         </span>
         <span class="katex-html">
          <span class="base">
           <span class="strut" style="height: 0.6833em;">
           </span>
           <span class="mord mathnormal" style="margin-right: 0.1389em;">
            W
           </span>
           <span class="mord mathnormal" style="margin-right: 0.0576em;">
            OE
           </span>
           <span class="mspace" style="margin-right: 0.2778em;">
           </span>
           <span class="mrel">
            =
           </span>
           <span class="mspace" style="margin-right: 0.2778em;">
           </span>
          </span>
          <span class="base">
           <span class="strut" style="height: 2.4em; vertical-align: -0.95em;">
           </span>
           <span class="mop">
            ln
           </span>
           <span class="mspace" style="margin-right: 0.1667em;">
           </span>
           <span class="minner">
            <span class="mopen delimcenter" style="top: 0em;">
             <span class="delimsizing size3">
              (
             </span>
            </span>
            <span class="mord">
             <span class="mopen nulldelimiter">
             </span>
             <span class="mfrac">
              <span class="vlist-t vlist-t2">
               <span class="vlist-r">
                <span class="vlist" style="height: 1.427em;">
                 <span class="" style="top: -2.314em;">
                  <span class="pstrut" style="height: 3em;">
                  </span>
                  <span class="mord">
                   <span class="mord text">
                    <span class="mord">
                     Bad%
                    </span>
                   </span>
                  </span>
                 </span>
                 <span class="" style="top: -3.23em;">
                  <span class="pstrut" style="height: 3em;">
                  </span>
                  <span class="frac-line" style="border-bottom-width: 0.04em;">
                  </span>
                 </span>
                 <span class="" style="top: -3.677em;">
                  <span class="pstrut" style="height: 3em;">
                  </span>
                  <span class="mord">
                   <span class="mord text">
                    <span class="mord">
                     Good%
                    </span>
                   </span>
                  </span>
                 </span>
                </span>
                <span class="vlist-s">
                 ​
                </span>
               </span>
               <span class="vlist-r">
                <span class="vlist" style="height: 0.7416em;">
                 <span class="">
                 </span>
                </span>
               </span>
              </span>
             </span>
             <span class="mclose nulldelimiter">
             </span>
            </span>
            <span class="mclose delimcenter" style="top: 0em;">
             <span class="delimsizing size3">
              )
             </span>
            </span>
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
      <br/>
      其中，Good%表示该分箱中好样本的比例，Bad%表示坏样本的比例。
     </li>
    </ul>
    <h4>
     <a id="IVInformation_Value_38">
     </a>
     IV（Information Value，信息价值）
    </h4>
    <ul>
     <li>
      <strong>
       定义
      </strong>
      ：IV用于衡量某个变量对目标变量的预测能力，通常用于特征选择。
     </li>
     <li>
      <strong>
       公式
      </strong>
      ：
      <br/>
      <span class="katex--display">
       <span class="katex-display">
        <span class="katex">
         <span class="katex-mathml">
          I 
          
         
           V 
          
         
           = 
          
         
           ∑ 
          
          
          
            ( 
           
          
            Good% 
           
          
            − 
           
          
            Bad% 
           
          
            ) 
           
          
         
           × 
          
         
           W 
          
         
           O 
          
         
           E 
          
         
        
          IV = \sum \left(\text{Good\%} - \text{Bad\%}\right) \times WOE
         </span>
         <span class="katex-html">
          <span class="base">
           <span class="strut" style="height: 0.6833em;">
           </span>
           <span class="mord mathnormal" style="margin-right: 0.0785em;">
            I
           </span>
           <span class="mord mathnormal" style="margin-right: 0.2222em;">
            V
           </span>
           <span class="mspace" style="margin-right: 0.2778em;">
           </span>
           <span class="mrel">
            =
           </span>
           <span class="mspace" style="margin-right: 0.2778em;">
           </span>
          </span>
          <span class="base">
           <span class="strut" style="height: 1.6em; vertical-align: -0.55em;">
           </span>
           <span class="mop op-symbol large-op" style="position: relative; top: 0em;">
            ∑
           </span>
           <span class="mspace" style="margin-right: 0.1667em;">
           </span>
           <span class="minner">
            <span class="mopen delimcenter" style="top: 0em;">
             (
            </span>
            <span class="mord text">
             <span class="mord">
              Good%
             </span>
            </span>
            <span class="mspace" style="margin-right: 0.2222em;">
            </span>
            <span class="mbin">
             −
            </span>
            <span class="mspace" style="margin-right: 0.2222em;">
            </span>
            <span class="mord text">
             <span class="mord">
              Bad%
             </span>
            </span>
            <span class="mclose delimcenter" style="top: 0em;">
             )
            </span>
           </span>
           <span class="mspace" style="margin-right: 0.2222em;">
           </span>
           <span class="mbin">
            ×
           </span>
           <span class="mspace" style="margin-right: 0.2222em;">
           </span>
          </span>
          <span class="base">
           <span class="strut" style="height: 0.6833em;">
           </span>
           <span class="mord mathnormal" style="margin-right: 0.1389em;">
            W
           </span>
           <span class="mord mathnormal" style="margin-right: 0.0576em;">
            OE
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
      <br/>
      IV值越大，表示该变量的预测能力越强。
     </li>
    </ul>
    <h4>
     <a id="IVWOE_45">
     </a>
     IV和WOE在分箱中的应用
    </h4>
    <h5>
     <a id="1_WOE_46">
     </a>
     1.
     <strong>
      基于WOE的分箱
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        步骤
       </strong>
       ：
      </p>
      <ol>
       <li>
        对连续变量进行初步分箱（如等宽分箱或等频分箱）。
       </li>
       <li>
        计算每个分箱的WOE值。
       </li>
       <li>
        根据WOE值调整分箱边界，使得每个分箱的WOE值尽可能区分好坏样本。
       </li>
       <li>
        合并或拆分分箱，使得每个分箱的WOE值具有显著差异。
       </li>
      </ol>
     </li>
     <li>
      <p>
       <strong>
        优点
       </strong>
       ：
      </p>
      <ul>
       <li>
        WOE分箱能够更好地捕捉变量与目标变量之间的非线性关系。
       </li>
       <li>
        分箱后的变量具有更好的解释性。
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <a id="2_IV_56">
     </a>
     2.
     <strong>
      基于IV的分箱
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        步骤
       </strong>
       ：
      </p>
      <ol>
       <li>
        对连续变量进行初步分箱。
       </li>
       <li>
        计算每个分箱的WOE值和IV值。
       </li>
       <li>
        根据IV值评估每个分箱的预测能力，调整分箱边界以最大化IV值。
       </li>
       <li>
        合并或拆分分箱，使得整体IV值最大化。
       </li>
      </ol>
     </li>
     <li>
      <p>
       <strong>
        优点
       </strong>
       ：
      </p>
      <ul>
       <li>
        IV分箱能够自动选择对目标变量预测能力最强的分箱策略。
       </li>
       <li>
        IV值可以用于特征选择，帮助筛选出最有价值的变量。
       </li>
      </ul>
     </li>
    </ul>
    <h2>
     <a id="lgb_67">
     </a>
     二、lgb如何对连续数据处理的（直方图算法）
    </h2>
    <p>
     LightGBM 使用
     <strong>
      直方图分箱（Histogram Binning）
     </strong>
     处理连续数据，以加速决策树的训练。这种方法避免了对所有特征值进行遍历，大幅提升计算效率，同时对模型精度影响很小。
    </p>
    <h3>
     <a id="21_LightGBM__69">
     </a>
     <strong>
      2.1. LightGBM 直方图分箱的基本原理
     </strong>
    </h3>
    <p>
     LightGBM 并不会直接使用原始的连续特征值，而是：
    </p>
    <ol>
     <li>
      <strong>
       对连续特征进行分箱（Binning）
      </strong>
      ：将连续数值映射到固定数量的 bin（默认 255 个）。
     </li>
     <li>
      <strong>
       统计每个 bin 内的样本信息
      </strong>
      ：记录样本数量、目标值的累积和等。
     </li>
     <li>
      <strong>
       在 bin 边界处查找最优分裂点
      </strong>
      ，而不是遍历所有可能的特征值，从而提高训练速度。
     </li>
    </ol>
    <p>
     这种方式的核心目标是
     <strong>
      降低计算复杂度
     </strong>
     ，避免传统 GBDT 在遍历所有样本时的高昂计算开销。
    </p>
    <h3>
     <a id="22__76">
     </a>
     <strong>
      2.2. 具体的连续数据处理步骤
     </strong>
    </h3>
    <h4>
     <a id="1__77">
     </a>
     <strong>
      (1) 预处理阶段：特征值离散化
     </strong>
    </h4>
    <ul>
     <li>
      LightGBM 采用
      <strong>
       无监督分箱
      </strong>
      ，通常使用
      <strong>
       等频分箱（Quantile Binning）
      </strong>
      进行数据离散化，将连续特征值映射到
      <strong>
       有限数量的 bin
      </strong>
      。默认情况下，每个特征会被分到
      <strong>
       最多 255 个 bin
      </strong>
      ，即
      <code>
       max_bins=255
      </code>
      。
     </li>
    </ul>
    <h4>
     <a id="2__79">
     </a>
     <strong>
      (2) 计算直方图
     </strong>
    </h4>
    <ul>
     <li>
      对每个 bin 统计：
      <ul>
       <li>
        该 bin 内的样本数量。
       </li>
       <li>
        目标变量的累积值（用于计算信息增益）。
       </li>
       <li>
        梯度和二阶梯度（用于计算损失）。
       </li>
      </ul>
     </li>
    </ul>
    <h4>
     <a id="3__84">
     </a>
     <strong>
      (3) 计算最优分裂点
     </strong>
    </h4>
    <ul>
     <li>
      在
      <strong>
       bin 的边界处
      </strong>
      计算信息增益，找到最优分裂点，而不是遍历所有可能的连续值。
     </li>
    </ul>
    <h4>
     <a id="4__86">
     </a>
     <strong>
      (4) 直方图共享
     </strong>
    </h4>
    <ul>
     <li>
      在决策树的每个节点上，LightGBM 复用
      <strong>
       父节点的直方图
      </strong>
      ，仅计算新增样本的贡献，而不重新计算整个直方图。
      <strong>
       减少冗余计算，提高训练速度
      </strong>
      。
     </li>
    </ul>
    <p>
     <strong>
      注：LGBM 的直方图分箱本质上是一个动态特征工程方法，但它的作用仅限于加速训练，而不会改变特征本身。
     </strong>
    </p>
    <h2>
     <a id="lgbxgb_91">
     </a>
     三、lgb和xgb的损失函数
    </h2>
    <p>
     见【搜广推校招面经九、十】
    </p>
    <h2>
     <a id="240__II_93">
     </a>
     四、240. 搜索二维矩阵 II
    </h2>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/5d2229ccdecd4c4995570ed40063efcf.png"/>
    </p>
    <ul>
     <li>
      思路1：
      <br/>
      站在矩阵的右上角来说，当前元素是当前行最大，当前列的最小值。判断右上角元素和target的关系，从而简化剩余矩阵
     </li>
     <li>
      代码：
     </li>
    </ul>
    <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">searchMatrix</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> matrix<span class="token punctuation">:</span> List<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>
        m<span class="token punctuation">,</span> n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>matrix<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>matrix<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        i<span class="token punctuation">,</span> j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> n <span class="token operator">-</span> <span class="token number">1</span>                       <span class="token comment"># 从右上角开始</span>
        <span class="token keyword">while</span> i <span class="token operator">&lt;</span> m <span class="token keyword">and</span> j <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">:</span>               <span class="token comment"># 还有剩余元素</span>
            <span class="token keyword">if</span> matrix<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">==</span> target<span class="token punctuation">:</span>
                <span class="token keyword">return</span> <span class="token boolean">True</span>                   <span class="token comment"># 1.找到 target</span>
            <span class="token keyword">if</span> matrix<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">&lt;</span> target<span class="token punctuation">:</span>
                i <span class="token operator">+=</span> <span class="token number">1</span>  <span class="token comment"># 这一行剩余元素全部小于 target，排除</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                j <span class="token operator">-=</span> <span class="token number">1</span>  <span class="token comment"># 这一列剩余元素全部大于 target，排除</span>
        <span class="token keyword">return</span> <span class="token boolean">False</span>
</code></pre>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f79696e323536373538383834312f:61727469636c652f64657461696c732f313436323738333434" class_="artid" style="display:none">
 </p>
</div>


