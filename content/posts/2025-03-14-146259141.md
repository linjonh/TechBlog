---
layout: post
title: "深度学习大模型补充知识点"
date: 2025-03-14 18:00:04 +0800
description: "了解大语言模型的预训练，指令微调，强化学习的概念和典型例子。以及大模型的不同架构实例，分为only-encoder,only-decoder,encoder-decoder；"
keywords: "深度学习大模型补充知识点"
categories: ['未分类']
tags: ['自然语言处理', '深度学习', '机器学习', '人工智能']
artid: "146259141"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146259141
    alt: "深度学习大模型补充知识点"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146259141
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146259141
cover: https://bing.ee123.net/img/rand?artid=146259141
image: https://bing.ee123.net/img/rand?artid=146259141
img: https://bing.ee123.net/img/rand?artid=146259141
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     深度学习大模型补充知识点
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
    </p>
    <p>
    </p>
    <hr/>
    <h2>
     <a id="VIT_6">
     </a>
     VIT
    </h2>
    <p>
     ViT（Vision Transformer） 首次将 Transformer架构成功应用于计算机视觉领域（尤其是图像分类任务）。传统视觉任务主要依赖卷积神经网络（CNN），而ViT通过将图像视为序列化的
     <strong>
      图像块（Patch），利用Transformer的全局注意力机制捕捉图像的长距离依赖关系，突破了CNN的局部感受野限制。
     </strong>
    </p>
    <h3>
     <a id="_9">
     </a>
     用途
    </h3>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/d27a1de08bc943d8bf70a0e1141b792c.png"/>
    </p>
    <h3>
     <a id="_11">
     </a>
     处理方法
    </h3>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/57b40789b8e5409686f74deef8fe94a3.png">
      <br/>
      将图片划分为多个patch，转换为离散的向量，作为encoder输入,进行交互提取特征然后经过分类头输出。
     </img>
    </p>
    <h3>
     <a id="CNN_14">
     </a>
     与CNN区别
    </h3>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/fff17df514e847f79441000774a18129.png"/>
    </p>
    <hr/>
    <p>
     `
    </p>
    <h2>
     <a id="_21">
     </a>
     多模态
    </h2>
    <p>
     <img alt="示例：pandas 是基于NumPy 的一种工具，该工具是为了解决数据分析任务而创建的。" src="https://i-blog.csdnimg.cn/direct/eeb64aee22174a48b71af3e951b05eb0.png">
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/fbf629e5a45b46d0877fc3f3b593bc1a.png">
       <br/>
       transformer架构天然为多模态而生。
       <br/>
       Bert就常用于多模态训练：无论输入是文字，图片，还是声音，都让他们进入self_attention进行交互。
       <br/>
       如：ViltBert就是一个多模态模型，用于从图片和文字中提取特征
      </img>
     </img>
    </p>
    <h2>
     <a id="LLM_30">
     </a>
     LLM：大语言模型
    </h2>
    <p>
     基于transformer架构的大模型
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/c74956ed7daa4ba8a8158ba457add8f5.png">
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/1c753e49d12549538cf2462480beabc3.png"/>
     </img>
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/8ae2cabbc9a44811904d021931e48720.png"/>
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/3f2bf9bf2bbe45769cf9a457cfec2943.png"/>
    </p>
    <p>
     以gpt为例，only-decoder架构的大模型
    </p>
    <h4>
     <a id="_39">
     </a>
     预训练
    </h4>
    <p>
     gpt采用自回归预训练，通过预测下一个字的生成，与翻译任务不同，预训练采用的是teach force.
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/5ffed16ba02541adb109ee4024e13f6c.png"/>
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/8c56b241bcd041f9980698eee427ca26.png"/>
    </p>
    <h4>
     <a id="_43">
     </a>
     指令微调
    </h4>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/d77b9886a9384334a933f094110c60be.png"/>
     <br/>
     SFT 是 Supervised Fine-Tuning（监督微调）的缩写，是大语言模型（LLM）训练流程中的一个关键阶段。它的核心思想是：通过人工标注的高质量数据，进一步调整预训练模型的参数，使其更符合特定任务的需求（例如对话生成、指令遵循等）
    </p>
    <h4>
     <a id="_46">
     </a>
     强化学习
    </h4>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/1180916693564a3e998badf747e6efe2.png"/>
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/6c46252ddfbb4b58b91a77e9aff3589a.png"/>
     <br/>
     PPO 近端策略优化，选择某个操作如果正确奖励就越高，梯度就越大，朝着越好的方向更新，选择正确操作的概率越大。
    </p>
    <h3>
     <a id="_51">
     </a>
     总结
    </h3>
    <p>
     了解大语言模型的预训练，指令微调，强化学习的概念和典型例子。
     <br/>
     以及大模型的不同架构实例，分为only-encoder,only-decoder,encoder-decoder；
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f35323438323634302f:61727469636c652f64657461696c732f313436323539313431" class_="artid" style="display:none">
 </p>
</div>


