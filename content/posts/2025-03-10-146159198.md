---
layout: post
title: "Spring-Boot-集成-Kettle"
date: 2025-03-10 17:19:40 +0800
description: "Kettle 最初由 Matt Casters 开发，是 Pentaho 数据集成平台的一部分。它提供了一个用户友好的界面和丰富的功能集，使用户能够轻松地设计、执行和监控 ETL 任务。Kettle 通过其强大的功能和灵活性，帮助企业高效地处理大规模数据集成任务。"
keywords: "Spring Boot 集成 Kettle"
categories: ['面试', '阿里巴巴', '学习路线']
tags: ['后端', 'Spring', 'Java', 'Boot']
artid: "146159198"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146159198
    alt: "Spring-Boot-集成-Kettle"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146159198
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146159198
cover: https://bing.ee123.net/img/rand?artid=146159198
image: https://bing.ee123.net/img/rand?artid=146159198
img: https://bing.ee123.net/img/rand?artid=146159198
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Spring Boot 集成 Kettle
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="./../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="./../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h5>
     <a id="Kettle__4">
     </a>
     Kettle 简介
    </h5>
    <p>
     Kettle 最初由 Matt Casters 开发，是 Pentaho 数据集成平台的一部分。它提供了一个用户友好的界面和丰富的功能集，使用户能够轻松地设计、执行和监控 ETL 任务。Kettle 通过其强大的功能和灵活性，帮助企业高效地处理大规模数据集成任务。
    </p>
    <h6>
     <a id="_8">
     </a>
     主要组成部分
    </h6>
    <ol>
     <li>
      <strong>
       Spoon
      </strong>
      ：
      <ul>
       <li>
        <strong>
         用途
        </strong>
        ：Spoon 是 Kettle 的图形化设计工具。用户可以使用 Spoon 设计和调试 ETL 转换和作业。
       </li>
       <li>
        <strong>
         功能
        </strong>
        ：拖放式界面、预览数据、测试 ETL 流程、管理连接、编写脚本等。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       Pan
      </strong>
      ：
      <ul>
       <li>
        <strong>
         用途
        </strong>
        ：Pan 是一个命令行工具，用于执行由 Spoon 设计的 ETL 转换。
       </li>
       <li>
        <strong>
         功能
        </strong>
        ：通过命令行执行转换、调度作业、集成到其他自动化流程中。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       Kitchen
      </strong>
      ：
      <ul>
       <li>
        <strong>
         用途
        </strong>
        ：Kitchen 是一个命令行工具，用于执行由 Spoon 设计的 ETL 作业。
       </li>
       <li>
        <strong>
         功能
        </strong>
        ：通过命令行执行作业、调度作业、集成到其他自动化流程中。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       Carte
      </strong>
      ：
      <ul>
       <li>
        <strong>
         用途
        </strong>
        ：Carte 是一个轻量级的 Web 服务器，提供远程执行和监控功能。
       </li>
       <li>
        <strong>
         功能
        </strong>
        ：远程执行和监控 ETL 转换和作业、查看日志、管理集群等。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       Repositories
      </strong>
      ：
      <ul>
       <li>
        <strong>
         用途
        </strong>
        ：存储和管理 ETL 转换和作业的地方。
       </li>
       <li>
        <strong>
         功能
        </strong>
        ：可以使用数据库或文件系统作为存储库，支持版本控制和共享。
       </li>
      </ul>
     </li>
    </ol>
    <h6>
     <a id="_26">
     </a>
     主要功能和特点
    </h6>
    <ol>
     <li>
      <p>
       <strong>
        数据提取
       </strong>
       ：
      </p>
      <ul>
       <li>
        支持多种数据源，如关系数据库、文件（CSV、Excel、XML 等）、大数据平台（Hadoop、Hive 等）、云存储（Amazon S3、Google Drive 等）、Web 服务和 API 等。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        数据转换
       </strong>
       ：
      </p>
      <ul>
       <li>
        丰富的转换步骤，包括数据清洗、数据聚合、数据过滤、数据排序、数据连接、数据拆分、数据类型转换等。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        数据加载
       </strong>
       ：
      </p>
      <ul>
       <li>
        支持将数据加载到多种目标系统中，如关系数据库、大数据平台、文件系统、云存储等。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        调度和自动化
       </strong>
       ：
      </p>
      <ul>
       <li>
        支持通过命令行工具（Pan 和 Kitchen）和调度器（如 cron 或 Windows 任务计划）进行调度和自动化执行。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        扩展性
       </strong>
       ：
      </p>
      <ul>
       <li>
        提供了插件机制，用户可以编写自定义插件，扩展 Kettle 的功能。
       </li>
       <li>
        支持 JavaScript 和 Java 进行脚本编写，增强转换和作业的灵活性。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        集群和并行处理
       </strong>
       ：
      </p>
      <ul>
       <li>
        支持集群模式，能够在分布式环境中并行处理大规模数据。
       </li>
       <li>
        提供了分布式 ETL 执行和负载均衡功能。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        数据质量和数据治理
       </strong>
       ：
      </p>
      <ul>
       <li>
        提供了数据验证、数据一致性检查和数据校验功能，帮助确保数据的质量和一致性。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        实时数据处理
       </strong>
       ：
      </p>
      <ul>
       <li>
        支持实时数据流处理，通过集成 Kafka、MQTT 等流处理平台，实现实时数据的提取、转换和加载。
       </li>
      </ul>
     </li>
    </ol>
    <h5>
     <a id="_Kettle_55">
     </a>
     集成 Kettle
    </h5>
    <p>
     将 Kettle（Pentaho Data Integration, PDI）集成到 Spring Boot 项目中，可以实现 ETL 流程的自动化和集成化处理。以下是详细的集成过程：
    </p>
    <h6>
     <a id="_59">
     </a>
     准备工作
    </h6>
    <ol>
     <li>
      <strong>
       下载 Kettle
      </strong>
      ：从 Pentaho 官网下载 Kettle（PDI）的最新版本，并解压到本地目录。
     </li>
     <li>
      <strong>
       Spring Boot 项目
      </strong>
      ：确保已有一个 Spring Boot 项目，或新建一个 Spring Boot 项目。
     </li>
    </ol>
    <h6>
     <a id="_Kettle__64">
     </a>
     引入 Kettle 依赖
    </h6>
    <p>
     在 Spring Boot 项目的
     <code>
      pom.xml
     </code>
     文件中添加 Kettle 所需的依赖。你可以将 Kettle 的 JAR 文件添加到本地 Maven 仓库，或直接在项目中引入这些 JAR 文件。
    </p>
    <pre><code>&lt;dependencies&gt;
    &lt;!-- Spring Boot 依赖 --&gt;

    &lt;!-- Kettle 依赖 --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;pentaho-kettle&lt;/groupId&gt;
        &lt;artifactId&gt;kettle-core&lt;/artifactId&gt;
        &lt;version&gt;9.4.0.0-343&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;pentaho-kettle&lt;/groupId&gt;
        &lt;artifactId&gt;kettle-engine&lt;/artifactId&gt;
        &lt;version&gt;9.4.0.0-343&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;pentaho-kettle&lt;/groupId&gt;
        &lt;artifactId&gt;kettle-dbdialog&lt;/artifactId&gt;
        &lt;version&gt;9.4.0.0-343&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
        &lt;artifactId&gt;commons-vfs2&lt;/artifactId&gt;
        &lt;version&gt;2.7.0&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;!-- 根据需要添加其他 Kettle 依赖 --&gt;
    
    &lt;!-- 操作数据库数据时添加相应的数据库依赖 --&gt;
    
&lt;/dependencies&gt;
</code></pre>
    <h6>
     <a id="_99">
     </a>
     处理密码加密
    </h6>
    <p>
     在
     <code>
      resources
     </code>
     目录下创建
     <code>
      kettle-password-encoder-plugins.xml
     </code>
     文件，用于配置密码加密插件：
    </p>
    <pre><code>&lt;password-encoder-plugins&gt;

    &lt;password-encoder-plugin id="Kettle"&gt;
        &lt;description&gt;Kettle Password Encoder&lt;/description&gt;
        &lt;classname&gt;org.pentaho.support.encryption.KettleTwoWayPasswordEncoder&lt;/classname&gt;
    &lt;/password-encoder-plugin&gt;

&lt;/password-encoder-plugins&gt;
</code></pre>
    <p>
     kettle-core依赖中org.pentaho.support.encryption.KettleTwoWayPasswordEncoder类实现了TwoWayPasswordEncoderInterface接口，用于处理密码的加密和解密操作。
    </p>
    <h6>
     <a id="_Spoon__115">
     </a>
     添加 Spoon 的任务文件
    </h6>
    <p>
     在 Kettle（Pentaho Data Integration，PDI）中，作业（Job）和转换（Transformation）是两种核心的 ETL 组件，它们在设计和功能上有着本质的区别。
    </p>
    <h6>
     <a id="Transformation_119">
     </a>
     转换（Transformation）
    </h6>
    <ol>
     <li>
      <strong>
       数据处理流程
      </strong>
      ：转换是一个数据处理流程，专注于数据的提取（Extract）、转换（Transform）和加载（Load）。
     </li>
     <li>
      <strong>
       行级处理
      </strong>
      ：转换以行级处理数据，每次处理一行数据，并将其传递给下一步骤。
     </li>
     <li>
      <strong>
       任务文件为.ktr文件。
      </strong>
     </li>
    </ol>
    <h6>
     <a id="Job_125">
     </a>
     作业（Job）
    </h6>
    <ol>
     <li>
      <strong>
       任务管理和控制流程
      </strong>
      ：作业是一个任务管理和控制流程，负责调度和控制一系列任务的执行顺序。
     </li>
     <li>
      <strong>
       步骤级处理
      </strong>
      ：作业以步骤为单位处理任务，每次执行一个步骤，然后根据条件决定执行下一个步骤。
     </li>
     <li>
      <strong>
       任务文件为.kjb文件。
      </strong>
     </li>
    </ol>
    <h6>
     <a id="_131">
     </a>
     区别
    </h6>
    <ol>
     <li>
      转换处理数据行，作业处理任务步骤。
     </li>
     <li>
      转换中的步骤是并行执行的，而作业中的步骤是顺序执行的。
     </li>
     <li>
      转换侧重于数据的处理和转换，作业侧重于任务的调度和管理。
     </li>
     <li>
      转换主要通过数据流控制，作业提供了丰富的逻辑控制（条件判断、循环、错误处理等）。
     </li>
     <li>
      转换适用于复杂的数据处理流程，作业适用于任务调度和控制。
     </li>
    </ol>
    <p>
     在 Spring Boot 项目的
     <code>
      resources
     </code>
     目录下，创建一个
     <code>
      kettle
     </code>
     目录，并将 Kettle 的任务文件（如
     <code>
      转换1.ktr
     </code>
     ）复制到该目录中。
    </p>
    <h6>
     <a id="_Kettle__141">
     </a>
     编写 Kettle 服务类
    </h6>
    <p>
     创建一个服务类，用于执行 Kettle 转换或作业。
    </p>
    <pre><code>package com.example.kettletest.service.impl;

import com.example.kettletest.service.KettleJobService;
import org.pentaho.di.core.KettleEnvironment;
import org.pentaho.di.core.exception.KettleException;
import org.pentaho.di.core.exception.KettleXMLException;
import org.pentaho.di.core.util.EnvUtil;
import org.pentaho.di.job.Job;
import org.pentaho.di.job.JobMeta;
import org.pentaho.di.trans.Trans;
import org.pentaho.di.trans.TransMeta;
import org.springframework.core.io.ClassPathResource;
import org.springframework.stereotype.Service;

import java.io.File;
import java.io.IOException;

/**
 * @author 罗森
 * @date 2024/6/6 13:21
 */
@Service
public class KettleJobServiceImpl implements KettleJobService {
    @Override
    public void runTaskFile(String taskFileName) {
        // 初始化 Kettle 环境
        try {
            KettleEnvironment.init();
            EnvUtil.environmentInit();
        } catch (KettleException e) {
            throw new RuntimeException(e);
        }
        // 执行任务文件
        if (taskFileName.endsWith(".ktr")) {
            taskFileKTR(taskFileName);
        } else if (taskFileName.endsWith(".kjb")) {
            taskFileKJB(taskFileName);
        } else {
            throw new IllegalArgumentException("Unsupported file type: " + taskFileName);
        }
    }

    /**
     * 针对kjb文件的操作
     * @param taskFileName
     */
    public void taskFileKJB(String taskFileName) {
        try {
            // 获取资源文件路径
            ClassPathResource resource = new ClassPathResource("kettle/" + taskFileName);
            File jobFile = resource.getFile();
            // 加载 KJB 文件
            JobMeta jobMeta = new JobMeta(jobFile.getAbsolutePath(), null);
            // 创建作业对象
            Job job = new Job(null, jobMeta);
            // 启动作业
            job.start();
            // 等待作业完成
            job.waitUntilFinished();

            if (job.getErrors() &gt; 0) {
                System.out.println("There were errors during job execution.");
            } else {
                System.out.println("Job executed successfully.");
            }
        } catch (IOException | KettleXMLException e) {
            e.printStackTrace();
        }
    }

    /**
     * 针对ktr文件的操作
     * @param taskFileName
     */
    public void taskFileKTR(String taskFileName) {
        try {
            // 获取资源文件路径
            ClassPathResource resource = new ClassPathResource("kettle/" + taskFileName);
            File transFile = resource.getFile();
            // 加载 KTR 文件
            TransMeta transMeta = new TransMeta(transFile.getAbsolutePath());
            // 创建转换对象
            Trans trans = new Trans(transMeta);
            // 启动作业
            trans.execute(null);
            // 等待作业完成
            trans.waitUntilFinished();

            if (trans.getErrors() &gt; 0) {
                System.err.println("There were errors during Transformation execution.");
            } else {
                System.out.println("Transformation executed successfully!");
            }
        } catch (IOException | KettleException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
    <h5>
     <a id="_245">
     </a>
     常见问题解决办法
    </h5>
    <ol>
     <li>
      <p>
       运行后报错信息为：
       <code>
        Unable to find plugin with ID 'Kettle'. If this is a test, make sure kettle-core tests jar is a dependency. If this is live make sure a kettle-password-encoder-plugins.xml exits in the classpath.
       </code>
      </p>
      <p>
       **解决办法：**在
       <code>
        resources
       </code>
       目录下创建
       <code>
        kettle-password-encoder-plugins.xml
       </code>
       文件。
      </p>
     </li>
     <li>
      <p>
       运行后报错信息为：
       <code>
        ERROR (version 9.4.0.0-343, build 0.0 from 2022-11-08 07.50.27 by buildguy) : A serious error occurred during job execution: 无法找到作业的开始点.
       </code>
      </p>
      <p>
       **解决办法：**为Spoon制作的作业任务增加开始节点。
      </p>
     </li>
     <li>
      <p>
       运行后报错信息为：
       <code>
        Can't run transformation due to plugin missing.
       </code>
      </p>
      <p>
       **解决办法：**此问题通常出现在涉及类似于导出excel文件、json文件时。在初始化 Kettle 环境之前指明相关插件的绝对路径（相关插件通常在Kettle本地解压文件夹中的plugins目录下），新增以下代码：
      </p>
      <pre><code>StepPluginType.getInstance().getPluginFolders().add(new PluginFolder("E:\Kettle\pdi-ce-9.4.0.0-343\data-integration\plugins", false, true));
</code></pre>
      <p>
       将代码中的地址换成您本地的绝对地址。
      </p>
     </li>
    </ol>
    <hr/>
    <p>
     （END）
     <br/>
     by luosen.
    </p>
   </div>
   <link href="./../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="./../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f37343832343131322f:61727469636c652f64657461696c732f313436313539313938" class_="artid" style="display:none">
 </p>
</div>


