---
layout: post
title: "大数据学习68-Flink和Spark-Streaming"
date: 2025-03-14 15:51:40 +0800
description: "Flink 是基于流的真正runtime,可以持续地对无界数据流进行计算。Spark Streaming 则采用的是微批处理模型,将数据流离散为批进行处理。"
keywords: "大数据学习（68）- Flink和Spark Streaming"
categories: ['未分类']
tags: ['学习', '大数据', 'Spark', 'Flink']
artid: "146257713"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146257713
    alt: "大数据学习68-Flink和Spark-Streaming"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146257713
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146257713
cover: https://bing.ee123.net/img/rand?artid=146257713
image: https://bing.ee123.net/img/rand?artid=146257713
img: https://bing.ee123.net/img/rand?artid=146257713
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     大数据学习（68）- Flink和Spark Streaming
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     🍋🍋
     <strong>
      大数据学习
     </strong>
     🍋🍋
    </p>
    <p id="%F0%9F%94%A5%E7%B3%BB%E5%88%97%E4%B8%93%E6%A0%8F%EF%BC%9A%20%F0%9F%91%91%E5%93%B2%E5%AD%A6%E8%AF%AD%E5%BD%95%3A%20%E6%89%BF%E8%AE%A4%E8%87%AA%E5%B7%B1%E7%9A%84%E6%97%A0%E7%9F%A5%EF%BC%8C%E4%B9%83%E6%98%AF%E5%BC%80%E5%90%AF%E6%99%BA%E6%85%A7%E7%9A%84%E5%A4%A7%E9%97%A8%F0%9F%92%96%E5%A6%82%E6%9E%9C%E8%A7%89%E5%BE%97%E5%8D%9A%E4%B8%BB%E7%9A%84%E6%96%87%E7%AB%A0%E8%BF%98%E4%B8%8D%E9%94%99%E7%9A%84%E8%AF%9D%EF%BC%8C%E8%AF%B7%E7%82%B9%E8%B5%9E%F0%9F%91%8D%2B%E6%94%B6%E8%97%8F%E2%AD%90%EF%B8%8F%2B%E7%95%99%E8%A8%80%F0%9F%93%9D%E6%94%AF%E6%8C%81%E4%B8%80%E4%B8%8B%E5%8D%9A%E4%B8%BB%E5%93%A6%F0%9F%A4%9E" name="%F0%9F%94%A5%E7%B3%BB%E5%88%97%E4%B8%93%E6%A0%8F%EF%BC%9A%20%F0%9F%91%91%E5%93%B2%E5%AD%A6%E8%AF%AD%E5%BD%95%3A%20%E6%89%BF%E8%AE%A4%E8%87%AA%E5%B7%B1%E7%9A%84%E6%97%A0%E7%9F%A5%EF%BC%8C%E4%B9%83%E6%98%AF%E5%BC%80%E5%90%AF%E6%99%BA%E6%85%A7%E7%9A%84%E5%A4%A7%E9%97%A8%F0%9F%92%96%E5%A6%82%E6%9E%9C%E8%A7%89%E5%BE%97%E5%8D%9A%E4%B8%BB%E7%9A%84%E6%96%87%E7%AB%A0%E8%BF%98%E4%B8%8D%E9%94%99%E7%9A%84%E8%AF%9D%EF%BC%8C%E8%AF%B7%E7%82%B9%E8%B5%9E%F0%9F%91%8D%2B%E6%94%B6%E8%97%8F%E2%AD%90%EF%B8%8F%2B%E7%95%99%E8%A8%80%F0%9F%93%9D%E6%94%AF%E6%8C%81%E4%B8%80%E4%B8%8B%E5%8D%9A%E4%B8%BB%E5%93%A6%F0%9F%A4%9E">
     <a name="t1">
     </a>
     <strong>
      🔥系列专栏： 👑哲学语录: 用力所能及，改变世界。
      <br/>
      💖如果觉得博主的文章还不错的话，请点赞👍+收藏⭐️+留言📝支持一下博主哦🤞
     </strong>
    </p>
    <hr/>
    <h2>
     🍋一、Flink and Spark基本原理
    </h2>
    <p>
     Flink 和 Spark Streaming 都是用于实时流式数据处理的分布式计算框架,但两者的基本设计思想和内部执行机制有些不同。
    </p>
    <p>
     <span style="color:#fe2c24">
      <strong>
       Flink 基于流的理念,采用了基于数据流模型的核心运行时引擎。
      </strong>
     </span>
     它可以对无界和有界数据流进行有状态的计算。Flink 使用了链式操作来表达运算逻辑,并基于流水线的方式进行任务调度。
    </p>
    <p>
     Spark Streaming 则是通过微批处理的方式来实现对实时数据流的处理。它将数据流切分成很小的批数据,然后提交给 Spark 执行批处理任务。
     <span style="color:#ed7976">
      <strong>
       Spark Streaming 基于 RDD 来表达运算逻辑,并通过 Spark 的任务调度机制进行调度。
      </strong>
     </span>
    </p>
    <p>
     <span style="color:#be191c">
      <strong>
       Flink 的内部把流处理算法表示为数据流图,并以流水线的方式持续运算。
      </strong>
     </span>
     而
     <span style="color:#fe2c24">
      <strong>
       Spark Streaming
      </strong>
     </span>
     <span style="color:#be191c">
      <strong>
       是
       <strong>
        将
       </strong>
       流任务拆解为一个个小批的 Spark 任务,这些批任务按时间顺序执行。
      </strong>
     </span>
    </p>
    <p>
     两者在 fault tolerance 机制上也有区别。Flink 基于检查点机制实现了 exactly-once 语义。而 Spark Streaming 通过 Write ahead logs 实现了至少一次保证。
    </p>
    <h4>
     <strong>
      实现机制
     </strong>
    </h4>
    <ol>
     <li>
      数据处理模式上,
      <span style="color:#be191c">
       <strong>
        Flink 是基于流的真正runtime,可以持续地对无界数据流进行计算。Spark Streaming 则采用的是微批处理模型,将数据流离散为批进行处理。
       </strong>
      </span>
     </li>
     <li>
      Flink 通过aperator chains实现了流式数据流水线计算。Spark Streaming基于RDD拼接批结果来模拟流计算。
     </li>
     <li>
      Flink 使用轻量级的流水线调度机制进行任务调度。Spark Streaming则依赖Spark Engine进行任务调度。
     </li>
     <li>
      Flink检查点机制实现了Exactly-once语义。Spark Streaming通过Write Ahead Logs实现了至少一次保证。
     </li>
     <li>
      Flink基于数据流图进行计算,允许循环数据流(迭代计算)。Spark Streaming的DAG不允许存在循环。
     </li>
     <li>
      Flink有更低的延迟,可以达到毫秒级。Spark Streaming批间隔一般在500毫秒以上。
     </li>
     <li>
      Flink有更好的重启能力,可以从检查点恢复状态。Spark Streaming重启后需要重新计算。
     </li>
     <li>
      Flink有更多针对流的优化,如窗口机制等。Spark Streaming继承自Spark的批设计。
     </li>
     <li>
      Flink需要额外的Cluster部署和操作。Spark Streaming可以直接基于Spark Cluster运行。
     </li>
    </ol>
    <h2>
     🍋二、运行角色
    </h2>
    <p>
     <strong>
      Spark Streaming
     </strong>
     运行时的角色(standalone 模式)主要有：
    </p>
    <ul>
     <li>
      <p>
       <span style="color:#be191c">
        <strong>
         Master
        </strong>
       </span>
       :主要负责整体集群资源的管理和应用程序调度；
      </p>
     </li>
     <li>
      <p>
       <span style="color:#be191c">
        <strong>
         Worker
        </strong>
       </span>
       :负责单个节点的资源管理，driver 和 executor 的启动等；
      </p>
     </li>
     <li>
      <p>
       <span style="color:#be191c">
        <strong>
         Driver
        </strong>
       </span>
       :用户入口程序执行的地方，即 SparkContext 执行的地方，主要是 DGA 生成、stage 划分、task 生成及调度；
      </p>
     </li>
     <li>
      <p>
       <span style="color:#be191c">
        <strong>
         Executor
        </strong>
       </span>
       :负责执行 task，反馈执行状态和执行结果。
      </p>
     </li>
     <li>
      <p>
       <img alt="" height="267" src="https://i-blog.csdnimg.cn/direct/87f7ea2f3b8a438ca8a0c325706ca1a3.png" width="865"/>
      </p>
     </li>
    </ul>
    <p>
     <strong>
      Flink
     </strong>
     运行时的角色(standalone 模式)主要有:
    </p>
    <ul>
     <li>
      <p>
       <span style="color:#be191c">
        <strong>
         Jobmanager
        </strong>
       </span>
       : 协调分布式执行，他们调度任务、协调 checkpoints、协调故障恢复等。至少有一个 JobManager。高可用情况下可以启动多个 JobManager，其中一个选举为 leader，其余为 standby；
      </p>
     </li>
     <li>
      <p>
       <span style="color:#be191c">
        <strong>
         Taskmanager
        </strong>
       </span>
       : 负责执行具体的 tasks、缓存、交换数据流，至少有一个 TaskManager；
      </p>
     </li>
     <li>
      <p>
       <span style="color:#be191c">
        <strong>
         Slot
        </strong>
       </span>
       : 每个 task slot 代表 TaskManager 的一个固定部分资源，
       <span style="color:#be191c">
        <strong>
         Slot 的个数代表着 taskmanager 可并行执行的 task 数。
        </strong>
       </span>
      </p>
     </li>
    </ul>
    <p>
     <img alt="" height="279" src="https://i-blog.csdnimg.cn/direct/aad0b342cb3949a2b878e8f7f055b590.png" width="852"/>
    </p>
    <h2>
     🍋三、spark streaming和Flink运行模型
    </h2>
    <p>
     1.
     <span style="color:#be191c">
      Spark Streaming 是
      <strong>
       微批处理
      </strong>
     </span>
     ，运行的时候需要指定批处理的时间，每次运行 job 时处理一个批次的数据，流程如图 3 所示：
    </p>
    <p>
     <img alt="640?" src="https://i-blog.csdnimg.cn/blog_migrate/040e12a5f17eecd2d25ec7e739141e64.png"/>
    </p>
    <p>
     2.
     <span style="color:#be191c">
      Flink 是基于
      <strong>
       事件
      </strong>
      驱动的
     </span>
     ，事件可以理解为消息。事件驱动的应用程序是一种状态应用程序，它会从一个或者多个流中注入事件，通过触发计算更新状态，或外部动作对注入的事件作出反应。
    </p>
    <p>
     <img alt="640?" src="https://i-blog.csdnimg.cn/blog_migrate/1eb8a1b2118a2fdb23cf6e2a76f97409.jpeg"/>
    </p>
    <h2>
     🍋四、任务调度
    </h2>
    <h3>
     1.Spark 任务调度
    </h3>
    <p>
     Spark Streaming 任务如上文提到的是基于微批处理的，实际上每个批次都是一个 Spark Core 的任务。对于编码完成的 Spark Core 任务在生成到最终执行结束主要包括以下几个部分：
    </p>
    <ul>
     <li>
      <p>
       构建 DGA 图；
      </p>
     </li>
     <li>
      <p>
       划分 stage；
      </p>
     </li>
     <li>
      <p>
       生成 taskset；
      </p>
     </li>
     <li>
      <p>
       调度 task。
      </p>
     </li>
    </ul>
    <p>
     <img alt="640?" height="351" src="https://i-blog.csdnimg.cn/blog_migrate/048b02b89b1453ca42dd29524ef2c283.jpeg" width="655"/>
    </p>
    <p>
     对于 job 的调度执行有 fifo 和 fair 两种模式，Task 是根据
     <span style="color:#be191c">
      <strong>
       数据本地性
      </strong>
     </span>
     调度执行的。 假设每个 Spark Streaming 任务消费的 kafka topic 有四个分区，中间有一个 transform操作（如 map）和一个 reduce 操作。
    </p>
    <p>
     <img alt="640?" src="https://i-blog.csdnimg.cn/blog_migrate/816449d8bf905c217230dc471b86304b.jpeg"/>
    </p>
    <p>
     假设有两个 executor，其中每个 executor 三个核，那么每个批次相应的 task 运行位置是固定的吗？是否能预测？ 由于数据本地性和调度不确定性，每个批次对应 kafka 分区生成的 task 运行位置并不是固定的。
    </p>
    <h3>
     <strong>
      2.Flink 任务调度
     </strong>
    </h3>
    <p>
     对于 flink 的流任务客户端首先会生成 StreamGraph，接着生成 JobGraph，然后将 jobGraph 提交给 Jobmanager 由它完成 jobGraph 到 ExecutionGraph 的转变，最后由 jobManager 调度执行。
    </p>
    <p>
     <img alt="640?" src="https://i-blog.csdnimg.cn/blog_migrate/b702adb9f2be207975b020bdb9018e5f.jpeg"/>
    </p>
    <p>
     上图所示有一个由 data source、MapFunction和 ReduceFunction 组成的程序，data source 和 MapFunction 的并发度都为 4，而 ReduceFunction 的并发度为 3。一个数据流由 Source-Map-Reduce 的顺序组成，在具有 2 个TaskManager、每个 TaskManager 都有 3 个 Task Slot 的集群上运行。
    </p>
    <p>
     可以看出
     <span style="color:#be191c">
      <strong>
       flink 的拓扑生成提交执行之后，除非故障，否则拓扑部件执行位置不变，并行度由每一个算子并行度决定，类似于 storm。而 spark Streaming 是每个批次都会根据数据本地性和资源情况进行调度，无固定的执行拓扑结构。 flink 是数据在拓扑结构里流动执行，而 Spark Streaming 则是对数据缓存批次并行处理。
      </strong>
     </span>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f36313030363236322f:61727469636c652f64657461696c732f313436323537373133" class_="artid" style="display:none">
 </p>
</div>


