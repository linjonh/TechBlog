---
layout: post
title: "在笔记本电脑上用DeepSeek搭建个人知识库"
date: 2025-03-02 00:22:06 +0800
description: "本文尝试在个人笔记本电脑上部署DeepSeek并使用开源工具搭建一套个人知识库，实现完全在本地环境下使用本地文档搭建个人知识库。操作过程共享出来，供大家参考。"
keywords: "fail to access model(deepseek-r1:8b).**error**:model requires more system me"
categories: ['未分类']
tags: ['知识库', 'Deepseek']
artid: "145954816"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145954816
    alt: "在笔记本电脑上用DeepSeek搭建个人知识库"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145954816
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145954816
cover: https://bing.ee123.net/img/rand?artid=145954816
image: https://bing.ee123.net/img/rand?artid=145954816
img: https://bing.ee123.net/img/rand?artid=145954816
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     在笔记本电脑上用DeepSeek搭建个人知识库
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     最近DeepSeek爆火，试用DeepSeek的企业和个人越来越多。最常见的应用场景就是知识库和知识问答。所以本人也试用了一下，在笔记本电脑上部署DeepSeek并使用开源工具搭建一套知识库，实现完全在本地环境下使用本地文档搭建个人知识库。操作过程共享出来，供大家参考。
    </p>
    <h2>
     部署环境
    </h2>
    <p>
     笔记本电脑，具体配置如下：
    </p>
    <blockquote>
     <p>
      处理器：Intel(R) Core(TM) i7-10510U CPU @ 1.80GHz   2.30 GHz
     </p>
     <p>
      内存：16G
     </p>
     <p>
      硬盘：500G
     </p>
     <p>
      显卡：集成显卡
     </p>
     <p>
      操作系统：Windows 11
     </p>
    </blockquote>
    <h2>
     软件清单
    </h2>
    <p>
     构建本地知识库，除了DeepSeek还需要安装知识库软件。网上推荐比较多的是RagFlow，软件开源，功能也很强大，可以使用本地文档构建外挂知识库。另外，同时也安装了Cherry Studio，可以作为操作DeepSeek的交互工具。
    </p>
    <table border="1" cellpadding="1" cellspacing="1" style="width:500px">
     <tbody>
      <tr>
       <td>
        软件
       </td>
       <td>
        功能
       </td>
       <td>
        版本
       </td>
       <td>
        依赖工具
       </td>
      </tr>
      <tr>
       <td>
        DeepSeek
       </td>
       <td>
        LLM模型，主要用于自然语言理解和推理
       </td>
       <td>
        deepseek-r1:7b
       </td>
       <td>
        Ollama
       </td>
      </tr>
      <tr>
       <td>
        Cherry Studio
       </td>
       <td>
        一款强大的多模型 AI 助手，可用于DeepSeek的人机交互
       </td>
       <td>
        最新版就好
       </td>
       <td>
       </td>
      </tr>
      <tr>
       <td>
        BGE
       </td>
       <td>
        通用向量模型，用于知识库中文档检索
       </td>
       <td>
        bge-m3:latest
       </td>
       <td>
       </td>
      </tr>
      <tr>
       <td>
        RAGFlow
       </td>
       <td>
        知识库构建工具
       </td>
       <td>
        最新版就好
       </td>
       <td>
        <p>
         Docker
        </p>
        <p>
         Git
        </p>
       </td>
      </tr>
     </tbody>
    </table>
    <h2>
     安装DeepSeek
    </h2>
    <p>
     从官网下载并安装Ollama，过程略。可参考 https://ollama.com/
    </p>
    <p>
     <img alt="" height="997" src="https://i-blog.csdnimg.cn/direct/787d280368af45c0be3cee9ca8d10844.png" width="1080"/>
    </p>
    <p>
     安装完毕后，执行命令：
    </p>
    <pre><code class="language-bash">ollama run deepseek-r1:7b</code></pre>
    <p>
     安装成功后，就可以在命令行里操作deepseek了。
    </p>
    <p>
     <img alt="" height="754" src="https://i-blog.csdnimg.cn/direct/f37eda17b6334546ad97649bada346aa.png" width="1466"/>
    </p>
    <p>
     操作很简单。至此，deepseek就安装完毕。
    </p>
    <h2>
     安装Cherry Studio
    </h2>
    <p>
     如果不习惯使用命令行，希望使用客户端与本地安装的deepseek交互，可以安装一个对话界面软件，我试用了Chatbox和Cherry Studio都不错，可以更直观地调整模型的参数和提示词，同时也支持将对话内容完全存档在本地，本文以Cherry Studio为例。
    </p>
    <p>
     前往https://cherry-ai.com/，根据你的操作系统（支持 Windows、Mac 和 Linux）下载对应的安装包。默认下一步安装完毕就好。
    </p>
    <p>
     启动Cherry Studio，添加嵌入模型。
    </p>
    <p>
     <img alt="" height="824" src="https://i-blog.csdnimg.cn/direct/cf565d1db79c468a97474221ca0e002e.png" width="1326"/>
    </p>
    <p>
     在模型服务中选择Ollama
    </p>
    <p>
     <img alt="" height="835" src="https://i-blog.csdnimg.cn/direct/8a1b33bb4f5e471bb4f06e4594bf014a.png" width="1345"/>
    </p>
    <p>
     点击“管理”进行模型选择，从模型列表中选择与你本地部署的 DeepSeek-R1 模型版本对应的选项，如果没有直接匹配项，选择支持自定义模型配置的入口。
    </p>
    <p>
     在“API地址”中，将 API 地址设置为http://localhost:11434 ，这是 Ollama 服务的默认接口地址，确保 Cherry Studio 能连接到本地运行的 DeepSeek-R1 模型。
    </p>
    <p>
     <img alt="" height="833" src="https://i-blog.csdnimg.cn/direct/a12f85f3e8a142cf9c2a2f910049c6a4.png" width="1338"/>
    </p>
    <p>
     保存后，就可以创建助手与本地deepseek进行对话了。
    </p>
    <p>
     <img alt="" height="831" src="https://i-blog.csdnimg.cn/direct/af7b953f60514a3587948433247db13d.png" width="1343"/>
    </p>
    <h2>
     安装RAGFlow
    </h2>
    <p>
     RAGFlow使用Docker部署运行，因此需要先在电脑上部署Docker环境。同时本文采用从GitHub仓库直接拉取镜像部署的方式，因此也需要提前安装Git。
    </p>
    <blockquote>
     <p>
      可访问官方 GitHub 仓库的 README 页面拉取镜像，并按照文档中的指引安装部署：https://github.com/infiniflow/ragflow/blob/main/README_zh.md
     </p>
     <p>
      如果遇到问题，可访问网络上部署 RAGFlow 的踩坑帖子，如：https://blog.csdn.net/gr1785/article/details/145543754?spm=1001.2014.3001.5502
     </p>
    </blockquote>
    <p>
     如果电脑没装Docker，可以参考
     <a href="https://docs.docker.com/desktop/setup/install/windows-install/" rel="nofollow" title="Windows | Docker Docs">
      Windows | Docker Docs
     </a>
     自行安装，本文使用WSL。
    </p>
    <p>
     <img alt="" height="610" src="https://i-blog.csdnimg.cn/direct/48420b5ca032449ba71ecb8957073e2d.png" width="878"/>
    </p>
    <blockquote>
     <p>
      安装完毕后，要记得启动“Docker Desktop”，否则后面执行docker命令时会报错。
     </p>
    </blockquote>
    <p>
     如果电脑没装Git，可以从
     <a href="https://git-scm.com/downloads/win" rel="nofollow" title="Git - Downloading Package">
      Git - Downloading Package
     </a>
     下载安装文件进行安装。
    </p>
    <p>
     安装完毕后，进入命令行，将RAGFlow工程Clone到本地文件夹下。
    </p>
    <pre><code class="language-bash">$ git clone https://github.com/infiniflow/ragflow.git</code></pre>
    <p>
     <img alt="" height="917" src="https://i-blog.csdnimg.cn/direct/c1b1b11486704d43b658ce419980458e.png" width="743"/>
    </p>
    <p>
     进入
     <strong>
      docker
     </strong>
     文件夹
    </p>
    <pre><code class="language-bash">$ cd ragflow/docker </code></pre>
    <p>
     利用提前编译好的 Docker 镜像启动服务器：
    </p>
    <p>
     运行以下命令会自动下载 RAGFlow slim Docker 镜像 v0.16.0-slim。
    </p>
    <pre><code class="language-bash">$ docker compose -f docker-compose.yml up -d</code></pre>
    <blockquote>
     <p>
      如需下载不同于 v0.16.0-slim 的 Docker 镜像，请在运行 docker compose 启动服务之前先更新
      <strong>
       docker/.env
      </strong>
      文件内的 RAGFLOW_IMAGE 变量。比如，你可以通过设置 RAGFLOW_IMAGE=infiniflow/ragflow:v0.16.0 来下载 RAGFlow 镜像的 v0.16.0 完整发行版。
     </p>
     <p>
      如果遇到 Docker 镜像拉不下来的问题，可以在
      <strong>
       docker/.env
      </strong>
      文件内根据变量
      <code>
       RAGFLOW_IMAGE
      </code>
      的注释提示选择华为云的相应镜像。
     </p>
     <p>
      华为云镜像名：
      <code>
       swr.cn-north-4.myhuaweicloud.com/infiniflow/ragflow
      </code>
     </p>
    </blockquote>
    <p>
     运行成功后，打开浏览器，登录localhost进入RAGFlow页面。注册账号后，就可以登录使用了。
    </p>
    <h2>
     设置知识库
    </h2>
    <p>
     使用RAGFlow设置知识库，首先要在“模型提供商”中添加模型。必须要添加的有两个模型，一个是LLM模型，使用DeepSeek；另一个是嵌入模型，使用bge-m3。
    </p>
    <p>
     在“待添加的模型”列表中选择“Ollama”，添加LLM.
    </p>
    <p>
     <img alt="" height="770" src="https://i-blog.csdnimg.cn/direct/02cb870dec474fd2a3c33405b42bc83f.png" width="651"/>
    </p>
    <p>
     “最大token数”可以通过如下命令获取后填入。
    </p>
    <pre><code class="language-bash">ollama show deepseek-r1:7b</code></pre>
    <p>
     “基础Url”需要注意如果填写“http://localhost:11434”，会遇到“[Errno 111] Connection refused”的异常。原因是Docker中的程序访问不到本机的11434端口，可以参考
    </p>
    <p>
     <a href="https://github.com/infiniflow/ragflow/issues/5090#top" title="[Question]: Fail to access model(deepseek-r1:8b).**ERROR**: [Errno 111] Connection refused">
      [Question]: Fail to access model(deepseek-r1:8b).**ERROR**: [Errno 111] Connection refused
     </a>
     因此，此处要注意“基础Url”处填写：
    </p>
    <blockquote>
     <p>
      <a href="http://host.docker.internal:11434/" rel="nofollow" title="http://host.docker.internal:11434">
       http://host.docker.internal:11434
      </a>
     </p>
    </blockquote>
    <p>
     添加嵌入模型前，首先使用Ollama 安装bge-m3
    </p>
    <pre><code class="language-bash">ollama pull bge-m3</code></pre>
    <p>
     然后配置嵌入模型。
    </p>
    <p>
     <img alt="" height="664" src="https://i-blog.csdnimg.cn/direct/ff56b85c1c054864be9c71a704d267bd.png" width="649"/>
    </p>
    <p>
     模型添加成功后，进入“系统模型设置”，选择添加的模型。
    </p>
    <p>
     <img alt="" height="788" src="https://i-blog.csdnimg.cn/direct/59404ed6d8284ddda1305f5facef3c89.png" width="633"/>
    </p>
    <p>
     然后就可以创建知识库了。
    </p>
    <p>
     在知识库设置中修改语言、权限、嵌入模型。
    </p>
    <p>
     <img alt="" height="870" src="https://i-blog.csdnimg.cn/direct/4de4d39eeedd48dab95749a3ccd2c110.png" width="1830"/>
    </p>
    <p>
     在“数据集”中上传所需的文档。
    </p>
    <p>
     <img alt="" height="830" src="https://i-blog.csdnimg.cn/direct/0c4f881de4484cb098aeca5341c3e0b5.png" width="1901"/>
    </p>
    <p>
     上传成功后，选择文档进行“解析”。
    </p>
    <p>
     <img alt="" height="344" src="https://i-blog.csdnimg.cn/direct/15f237c01a3548dfa1804b06d1b284d7.png" width="1427"/>
    </p>
    <p>
     上传了几个PDF文档，解析的效果还不错。解析分段如果有不准确的地方，可以人工修正。
    </p>
    <p>
     <img alt="" height="887" src="https://i-blog.csdnimg.cn/direct/329cc88ddb2b444a8c76017d4f4f84d9.png" width="1895"/>
    </p>
    <p>
     数据集准备就绪后，就可以“新建助理”，然后问问题了。
    </p>
    <p>
     <img alt="" height="763" src="https://i-blog.csdnimg.cn/direct/b40958f58c8c4e3a88e9b6d402e3b271.png" width="1872"/>
    </p>
    <p>
     <img alt="" height="785" src="https://i-blog.csdnimg.cn/direct/5ec358352f0647438126325979cc1875.png" width="1871"/>
    </p>
    <p>
     相比于互联网模型，个人知识库会从结合本地文档训练的数据集进行分析，更加符合个人专业诉求。
    </p>
    <h2>
     总结
    </h2>
    <p>
     DeepSeek确实很香，搭配开源工具不花一分钱就搭建了一个定制化的知识库。从回答的逻辑和文档解析的效果看，都很不错。当然，本案例个人尝鲜可以，作企业商用还不行，抛开企业定制化和运维需求之外，主要问题有两个：
    </p>
    <p>
     1. 个人笔记本的配置部署7b小模型已经是极限了，使用Cherry Studio做问答速度还可以。但使用RAGFlow做的个人知识库做问答，确实慢的要死。正式使用或企业商用，还是需要试用商用推荐配置。
    </p>
    <p>
     2. 数据集质量极大影响知识库问答效果，因此高价值的原始数据以及对原始数据的解析整理十分重要。现在工具能力相当不错了，但数据工程将是企业数据库构建的主要挑战。
    </p>
    <p>
    </p>
    <p>
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f676176696e6162632f:61727469636c652f64657461696c732f313435393534383136" class_="artid" style="display:none">
 </p>
</div>


