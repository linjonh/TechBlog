---
layout: post
title: "Hadoop集群搭建及wordcount测试"
date: 2024-04-30 00:26:47 +0800
description: "1. hadoop三种安装模式单机模式 无需运行任何守护进程（daemon），所有程序都在单个JVM"
keywords: "hadoop在软件测试领域的应用"
categories: ['Bigdata']
tags: ['Mapreduce', 'Hadoop', 'Hadoop']
artid: "51114517"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=51114517
    alt: "Hadoop集群搭建及wordcount测试"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=51114517
featuredImagePreview: https://bing.ee123.net/img/rand?artid=51114517
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Hadoop集群搭建及wordcount测试
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     <strong>
      1. hadoop三种安装模式
     </strong>
    </p>
    <ul>
     <li>
      单机模式
      <br/>
      无需运行任何守护进程（daemon），所有程序都在单个JVM上执行。由于在本机模式下测试和调试MapReduce程序较为方便，因此，这种模式适宜用在开发阶段。
     </li>
     <li>
      伪分布式模式
      <br/>
      Hadoop守护进程运行在本地机器上，模拟一个小规模的集群。
     </li>
     <li>
      完全分布式模式
      <br/>
      Hadoop运行在一个真实的集群中，本文以hadoop-2.6.3为例讲解此模式配置。
     </li>
    </ul>
    <p>
     <strong>
      2. hadoop分布式模式配置
     </strong>
     <br/>
     本文的配置基于完成
     <a href="http://blog.csdn.net/czliuming/article/details/51103312">
      《hadoop安装与配置》
     </a>
     的基础之上。集群配置信息如下：
    </p>
    <table>
     <thead>
      <tr>
       <th>
        名称
       </th>
       <th>
        IP
       </th>
       <th>
        功能
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        ubuntu-master
       </td>
       <td>
        192.168.30.128
       </td>
       <td>
        namenode,jobtracker
       </td>
      </tr>
      <tr>
       <td>
        ubuntu-slave
       </td>
       <td>
        192.168.30.129
       </td>
       <td>
        datanode
       </td>
      </tr>
     </tbody>
    </table>
    <hr/>
    <p>
     在hadoop解压目录下新建tmp、hdfs、hdfs\name、hdfs\data文件夹，后续配置文件中会使用这些目录。
     <br/>
     为hadoop用户赋予权限，使得该用户获得hadoop目录下文件的操作权限，命令如下：
    </p>
    <pre class="prettyprint"><code class="hljs bash"><span class="hljs-built_in">sudo</span> chown -r /usr/opt/hadoop/hadoop-<span class="hljs-number">2.6</span>.<span class="hljs-number">3</span></code></pre>
    <p>
     编辑hadoop-2.6.3/etc/hadoop/hadoop-env.sh文件，修改JAVA_HOME值对应到jdk安装目录，如下：
    </p>
    <pre class="prettyprint"><code class="hljs ruby">export <span class="hljs-constant">JAVA_HOME</span>=<span class="hljs-regexp">/usr/opt</span><span class="hljs-regexp">/java/jdk</span>1.<span class="hljs-number">8.0_77</span>
</code></pre>
    <p>
     配置hadoop守护进程的运行参数：
    </p>
    <ul>
     <li>
      配置core-site.xml
     </li>
    </ul>
    <pre class="prettyprint"><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>hdfs://193.168.30.128:9000<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>io.file.buffer.size<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>131072<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>file:/usr/opt/hadoop/hadoop-2.6.3/tmp<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>    
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hadoop.proxyuser.spark.hosts<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>*<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>hadoop.proxyuser.spark.groups<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>*<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span>  </code></pre>
    <ul>
     <li>
      配置hdfs-site.xml
     </li>
    </ul>
    <pre class="prettyprint"><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>192.168.30.128:9001<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>file:/usr/opt/hadoop/hadoop-2.6.3/hdfs/name<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>file:/usr/opt/hadoop/hadoop-2.6.3/hdfs/data<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>3<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>dfs.webhdfs.enabled<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span>  </code></pre>
    <ul>
     <li>
      配置mapred-site.xml
     </li>
    </ul>
    <pre class="prettyprint"><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>192.168.30.128:10020<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>192.168.30.128:19888<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span>  </code></pre>
    <ul>
     <li>
      配置yarn-site.xml
     </li>
    </ul>
    <pre class="prettyprint"><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-title">configuration</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>192.168.30.128:8032<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>192.168.30.128:8030<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>192.168.30.128:8035<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>192.168.30.128:8033<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
    <span class="hljs-tag">&lt;<span class="hljs-title">property</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-title">name</span>&gt;</span>  
        <span class="hljs-tag">&lt;<span class="hljs-title">value</span>&gt;</span>192.168.30.128:8088<span class="hljs-tag">&lt;/<span class="hljs-title">value</span>&gt;</span>  
    <span class="hljs-tag">&lt;/<span class="hljs-title">property</span>&gt;</span>  
<span class="hljs-tag">&lt;/<span class="hljs-title">configuration</span>&gt;</span>  </code></pre>
    <ul>
     <li>
      配置masters
      <br/>
      将msater机器加入masters文件中，内如如下：
     </li>
    </ul>
    <pre class="prettyprint"><code class="hljs">192.168.30.128</code></pre>
    <ul>
     <li>
      配置slaves
      <br/>
      将所有slave机器加入到slave是文件中（如果master也作为datanode请一并加入），内容如下：
     </li>
    </ul>
    <pre class="prettyprint"><code class="hljs">192.168.30.128
192.168.30.129
</code></pre>
    <ul>
     <li>
      修改hosts
      <br/>
      修改所有master机器和slave机器的hosts文件，注意注释掉127.0.1.1配置
      <br/>
      <img alt="这里写图片描述" src="https://img-blog.csdn.net/20160421164825740" title=""/>
     </li>
    </ul>
    <p>
     最后在所有机器上复制以上配置信息，可以通过复制/etc/hadoop文件夹到所有机器相应目录下，完成机器配置复制，命令如下：
    </p>
    <pre class="prettyprint"><code class="hljs ruby">scp -r /usr/opt/hadoop/hadoop-<span class="hljs-number">2.6</span>.<span class="hljs-number">3</span>/etc/hadoop czliuming<span class="hljs-variable">@192</span>.<span class="hljs-number">168.30</span>.<span class="hljs-number">128</span><span class="hljs-symbol">:/usr/opt/hadoop/hadoop-</span><span class="hljs-number">2.6</span>.<span class="hljs-number">3</span>/etc</code></pre>
    <p>
     注：如果上述文件在相应目录下不存在，可以自行创建，我的目录下就没有mapred-site.xml
     <br/>
     完成以上配置后，hadoop集群已搭建完毕，下面进行hdfs初始化(仅执行一次)，进入hadoop安装目录，执行以下命令：
    </p>
    <pre class="prettyprint"><code class="hljs rsl">bin/hadoop namenode -<span class="hljs-built_in">format</span></code></pre>
    <p>
     出现如下界面则hdfs初始化成功：
    </p>
    <p>
     <img alt="这里写图片描述" src="https://img-blog.csdn.net/20160421171039266" title=""/>
    </p>
    <p>
     hdfs初始化结束后，我们就可以尝试启动hadoop集群了，首先启动hdfs命令如下：
    </p>
    <pre class="prettyprint"><code class="hljs sql">sbin/<span class="hljs-operator"><span class="hljs-keyword">start</span>-dfs.sh</span></code></pre>
    <p>
     出现如下图信息，则表示启动成功：
    </p>
    <p>
     <img alt="这里写图片描述" src="https://img-blog.csdn.net/20160421171551970" title=""/>
    </p>
    <p>
     接下来，我们启动yarn，执行以下命令；
    </p>
    <pre class="prettyprint"><code class="hljs sql">sbin/<span class="hljs-operator"><span class="hljs-keyword">start</span>-yarn.sh</span></code></pre>
    <p>
     启动信息如下图：
    </p>
    <p>
     <img alt="这里写图片描述" src="https://img-blog.csdn.net/20160421171750253" title=""/>
    </p>
    <p>
     最后通过浏览器访问(
     <a href="http://192.168.30.128:8088/cluster/nodes" rel="nofollow">
      http://192.168.30.128:8088/cluster/nodes
     </a>
     )来查看集群运行状态，如下图所示：
    </p>
    <p>
     <img alt="这里写图片描述" src="https://img-blog.csdn.net/20160421171954648" title=""/>
    </p>
    <p>
     至此，hadoop集群的搭建已全部完成。
    </p>
    <p>
     <strong>
      3. WordCount测试
     </strong>
    </p>
    <ul>
     <li>
      <p>
       <strong>
        Eclipse安装Hadoop插件
       </strong>
       <br/>
       在GitHub上下载
       <a href="https://github.com/winghc/hadoop2x-eclipse-plugin">
        [hadoop-eclipse-plugin-2.6.0插件]
       </a>
       将hadoop-eclipse-plugin-2.6.0.jar拷贝到Eclipse安装目录\plungins目录下，重启Eclipse打开window-&gt;preferences，如果增加了Hadoop map/reduce菜单则证明插件安装成功。
       <br/>
       在系统环境变量中新建变量“HADOOP_USER_NAME=czliuming”并新建变量“HADOOP_HOME=D:\Software\Hadoop\hadoop-2.6.3”将hadoop解压目录下bin目录加入path路径中。
       <br/>
       点击Hadoop map/reduce菜单，配置hadoop在本地系统的解压目录如图所示：
       <br/>
      </p>
      <center>
       <img alt="这里写图片描述" src="https://img-blog.csdn.net/20160505111650310" title="">
       </img>
      </center>
      <br/>
      切换到map/reduce工程视图，在Map/Reduce Locations控制台中右键选择“New Hadoop Location”对hadoop集群进行连接配置，如图所示：
      <br/>
      <center>
       <img alt="这里写图片描述" src="https://img-blog.csdn.net/20160505112244766" title="">
       </img>
      </center>
      <br/>
      其中，Host为hadoop-master的ip地址，map/reduce端口号为mapred-site.xml中mapreduce.jobhistory.address配置的端口号，DFS端口号为core-site.xml中fs.defaultFS配置的端口号。
      <p>
      </p>
      <blockquote>
       <p>
        注意：如果连接失败，请检查代理设置，将master机器IP加入到代理过滤列表中，如图所示：
        <br/>
       </p>
       <center>
        <img alt="这里写图片描述" src="https://img-blog.csdn.net/20160505112903058" title="">
        </img>
       </center>
       <p>
       </p>
      </blockquote>
     </li>
     <li>
      <p>
       WordCount程序测试
       <br/>
       新建Map/Reduce Project，在src目录中新建WordCount类，并输入以下代码：
      </p>
      <pre class="prettyprint"><code class="hljs avrasm">package wordcount<span class="hljs-comment">;</span>

import java<span class="hljs-preprocessor">.io</span><span class="hljs-preprocessor">.IOException</span><span class="hljs-comment">;</span>
import java<span class="hljs-preprocessor">.util</span><span class="hljs-preprocessor">.StringTokenizer</span><span class="hljs-comment">;</span>

import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.conf</span><span class="hljs-preprocessor">.Configuration</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.fs</span><span class="hljs-preprocessor">.Path</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.io</span><span class="hljs-preprocessor">.IntWritable</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.io</span><span class="hljs-preprocessor">.Text</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.mapreduce</span><span class="hljs-preprocessor">.Job</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.mapreduce</span><span class="hljs-preprocessor">.Mapper</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.mapreduce</span><span class="hljs-preprocessor">.Reducer</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.mapreduce</span><span class="hljs-preprocessor">.lib</span><span class="hljs-preprocessor">.input</span><span class="hljs-preprocessor">.FileInputFormat</span><span class="hljs-comment">;</span>
import org<span class="hljs-preprocessor">.apache</span><span class="hljs-preprocessor">.hadoop</span><span class="hljs-preprocessor">.mapreduce</span><span class="hljs-preprocessor">.lib</span><span class="hljs-preprocessor">.output</span><span class="hljs-preprocessor">.FileOutputFormat</span><span class="hljs-comment">;</span>

public class WordCount {

  public static class TokenizerMapper
       extends Mapper&lt;Object, Text, Text, IntWritable&gt;{

    private final static IntWritable one = new IntWritable(<span class="hljs-number">1</span>)<span class="hljs-comment">;</span>
    private Text word = new Text()<span class="hljs-comment">;</span>

    public void map(Object key, Text value, Context context
                    ) throws IOException, InterruptedException {
      StringTokenizer itr = new StringTokenizer(value<span class="hljs-preprocessor">.toString</span>())<span class="hljs-comment">;</span>
      while (itr<span class="hljs-preprocessor">.hasMoreTokens</span>()) {
        word<span class="hljs-preprocessor">.set</span>(itr<span class="hljs-preprocessor">.nextToken</span>())<span class="hljs-comment">;</span>
        context<span class="hljs-preprocessor">.write</span>(word, one)<span class="hljs-comment">;</span>
      }
    }
  }

  public static class IntSumReducer
       extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; {
    private IntWritable result = new IntWritable()<span class="hljs-comment">;</span>

    public void reduce(Text key, Iterable&lt;IntWritable&gt; values,
                       Context context
                       ) throws IOException, InterruptedException {
      int sum = <span class="hljs-number">0</span><span class="hljs-comment">;</span>
      for (IntWritable val : values) {
        sum += val<span class="hljs-preprocessor">.get</span>()<span class="hljs-comment">;</span>
      }
      result<span class="hljs-preprocessor">.set</span>(sum)<span class="hljs-comment">;</span>
      context<span class="hljs-preprocessor">.write</span>(key, result)<span class="hljs-comment">;</span>
    }
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration()<span class="hljs-comment">;</span>
    Job job = Job<span class="hljs-preprocessor">.getInstance</span>(conf, <span class="hljs-string">"word count"</span>)<span class="hljs-comment">;</span>
    job<span class="hljs-preprocessor">.setJarByClass</span>(WordCount<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>
    job<span class="hljs-preprocessor">.setMapperClass</span>(TokenizerMapper<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>
    job<span class="hljs-preprocessor">.setCombinerClass</span>(IntSumReducer<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>
    job<span class="hljs-preprocessor">.setReducerClass</span>(IntSumReducer<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>
    job<span class="hljs-preprocessor">.setOutputKeyClass</span>(Text<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>
    job<span class="hljs-preprocessor">.setOutputValueClass</span>(IntWritable<span class="hljs-preprocessor">.class</span>)<span class="hljs-comment">;</span>
    FileInputFormat<span class="hljs-preprocessor">.addInputPath</span>(job, new Path(args[<span class="hljs-number">0</span>]))<span class="hljs-comment">;</span>
    FileOutputFormat<span class="hljs-preprocessor">.setOutputPath</span>(job, new Path(args[<span class="hljs-number">1</span>]))<span class="hljs-comment">;</span>
    System<span class="hljs-preprocessor">.exit</span>(job<span class="hljs-preprocessor">.waitForCompletion</span>(true) ? <span class="hljs-number">0</span> : <span class="hljs-number">1</span>)<span class="hljs-comment">;</span>
  }
}</code></pre>
      <p>
       设置启动参数，如图所示：
       <br/>
      </p>
      <center>
       <img alt="这里写图片描述" src="https://img-blog.csdn.net/20160505225336592" title=""/>
      </center>
      <br/>
      其中，第一个为输入目录，第二个为输出目录，根据实际情况进行配置，我的配置如下：
      <br/>
      <center>
       <img alt="这里写图片描述" src="https://img-blog.csdn.net/20160505225642078" title=""/>
      </center>
      <br/>
      最后执行wordcount程序，执行完毕会在输出目录输出单词统计结果，至此wordcount测试结束。
      <p>
      </p>
     </li>
    </ul>
    <blockquote>
     <p>
      注意：如果执行过程中出现报错，请参考《
      <a href="http://blog.csdn.net/czliuming/article/details/51326430">
       Hadoop常见问题汇总
      </a>
      》进行处理。
     </p>
    </blockquote>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f637a6c69756d696e67:2f61727469636c652f64657461696c732f3531313134353137" class_="artid" style="display:none">
 </p>
</div>


