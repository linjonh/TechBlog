---
layout: post
title: "大模型就业方向"
date: 2025-07-23T23:58:39+0800
description: "本文介绍了大模型就业方向：基座模型训练、大模型微调、大模型开发、大模型推理部署、多模态大模型等"
keywords: "大模型就业方向"
categories: ['未分类']
tags: ['深度学习', '就业', '大模型', '人工智能']
artid: "149586224"
arturl: "https://blog.csdn.net/2401_85747530/article/details/149586224"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=149586224
    alt: "大模型就业方向"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=149586224
featuredImagePreview: https://bing.ee123.net/img/rand?artid=149586224
cover: https://bing.ee123.net/img/rand?artid=149586224
image: https://bing.ee123.net/img/rand?artid=149586224
img: https://bing.ee123.net/img/rand?artid=149586224
---



# 大模型就业方向



有如下几个方向：

## 基座模型训练

* 工作内容：优化模型结构、数据比例，实现在各种任务上效果比较好的通用基座模型
* 护城河：出了问题只有你能解决，给足情绪价值
* 经验要求：

  + 必备：模型分布式框架（如deepspeed）、多机多卡训练、顶会的经验；阅读一系列 LLM 经典论文，例如 Instruct-GPT、LORA 等，从而对 LLM 有一个更深入、透彻的掌握。同
  + 任选：

    - 万卡集群的训练经验（包括预训练、sft、强化学习）、踩坑经验；
    - 数据配比调优、模型结构调优的经验；
    - 各类魔改信手捏来、快速实现并完成验证，给足情绪价值
* 现状：人才比较紧缺，市场薪资最高

## 

## 大模型微调

* 工作内容：对开源LLM进行分布式微调并不断迭代优化Bad Case。目前，LLM 微调一般有两种核心工作:一是微调 LLM 来解决实际业务问题，另一个就是微调垂域大模型，如医学大模型、法律大模型等。
* 推荐的开源教程：

> 1.深度学习入门经典教程《李宏毅深度学习教程》:https://github.com/datawhalechina/leedl-tutorial
>
> 2.深入浅出、从理论到实践的 Pytorch 教程《深入浅出Pytorch》: https://github.com/
>
> datawhalechina/thorough-pytorch
>
> 3. 全面介绍 LLM 理论基础的《So Large LM》:https://github.com/datawhalechina/so-large-lm
>
> 4.提供LLM 的调用、部署、微调全链路手把手教学的《Self LLM--开源大模型食用指南》:https://github.com/datawhalechina/self-llm

## 

## 大模型开发

* 工作内容：RAG、Agent、优化prompt。RAG：便于和搜推结合，降低模型幻觉。但是，随着模型max token的扩大，RAG不是必须的了
* 护城河：在不能做精的情况下，把自己的角色做宽（不局限于自己是算法工程师，多从产品视角、工程视角系统的分析问题），在大模型的加持下做一些全站开发的事情。亮点：垂直领域的agent
* 经验要求：搜推等
* 现状：做的人最多（大部分人受限于训练条件）
* 推荐的开源教程：

> 1.聚焦于如何使用ChatGPT相关API创造新的功能和应用的《Hugging LLM》:https://github.com/datawhalechina/hugging-llm
>
> 2.面向小白开发者的大模型应用开发教程《LLM Universe -- 动手学大模型应用开发》:(https://github.com/datawhalechina/llm-universe
>
> 3.基于 MetaGPT 框架的多智能体开发教程《Hugging Multi-Agent》:https://github.com/datawhalechina/hugging-multi-agent

## 

## 大模型推理部署

* 工作内容：分为模型量化、模型部署、推理加速，一般在大型企业的架构部门，在一些企业中，负贵训练模型算法工程师也需要兼顾模型部署和推理。需要学习一些经典的框架：分布式框架 Deepspeed、部署推理框架 VLLM 和量化框架 accelerate。
* 其中，模型量化：将全精度模型量化成混合精度的模型，效果上的损失带来性能上的优化；模型部署：优化推理速度，属于偏工程化的方向，但是需求量比较大
* 护城河：与开源框架拉开的差距
* 经验要求：并行化量化、蒸馏等各种加速的经验；深入其原理和源码；上手真实业务场景下 LLM 的部署与推理加速;也可以进行 CUDA 编程的学习,从更底层掌握 LLM 的部署优化
* 现状：需求量大，因为每个公司都需要有大模型落地的话，就需要有相关人才

## 

## 多模态大模型

* 工作内容：文生图/视频、图/视频生文
* 护城河：暂无说明
* 经验要求：暂无说明
* 现状：多尺寸的模型，应用场景不少，如：妙鸭相机、Sora的视频生成

## 结尾

亲爱的读者朋友：感谢您在繁忙中驻足阅读本期内容！您的到来是对我们最大的支持❤️

正如古语所言："当局者迷，旁观者清"。您独到的见解与客观评价，恰似一盏明灯💡，能帮助我们照亮内容盲区，让未来的创作更加贴近您的需求。

若此文给您带来启发或收获，不妨通过以下方式为彼此搭建一座桥梁： ✨ 点击右上角【点赞】图标，让好内容被更多人看见 ✨ 滑动屏幕【收藏】本篇，便于随时查阅回味 ✨ 在评论区留下您的真知灼见，让我们共同碰撞思维的火花

我始终秉持匠心精神，以键盘为犁铧深耕知识沃土💻，用每一次敲击传递专业价值，不断优化内容呈现形式，力求为您打造沉浸式的阅读盛宴📚。

有任何疑问或建议？评论区就是我们的连心桥！您的每一条留言我都将认真研读，并在24小时内回复解答📝。

愿我们携手同行，在知识的雨林中茁壮成长🌳，共享思想绽放的甘甜果实。下期相遇时，期待看到您智慧的评论与闪亮的点赞身影✨！

万分感谢🙏🙏您的点赞👍👍、收藏⭐🌟、评论💬🗯️、关注❤️💚～

---

> 自我介绍：一线互联网大厂资深算法研发（工作6年+），4年以上招聘面试官经验（一二面面试官，面试候选人400+），深谙岗位专业知识、技能雷达图，已累计辅导15+求职者顺利入职大中型互联网公司。熟练掌握大模型、NLP、搜索、推荐、数据挖掘算法和优化，提供面试辅导、专业知识入门到进阶辅导等定制化需求等服务，助力您顺利完成学习和求职之旅（有需要者可私信联系）

友友们，自己的知乎账号为**“快乐星球”**，定期更新技术文章，敬请关注！



