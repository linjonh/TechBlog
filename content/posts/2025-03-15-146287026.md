---
layout: post
title: "Vulkan视频解码decode显示display之同步"
date: 2025-03-15 22:54:23 +0800
description: "pFrameSynchronizationInfo->frameConsumerDoneFence和 pFrameSynchronizationInfo->frameConsumerDoneSemaphore。在ReleaseDisplayedPicture函数中消耗图片资源并且显示display完成，设置两个标志。这两个标志一旦设置为true，在QueuePictureForDecode函数中，将设置。ReleaseDisplayedPicture被。，返回后使用，同时重置两个标志为false。"
keywords: "Vulkan视频解码decode&显示display之同步"
categories: ['未分类']
tags: ['音视频', '算法', 'C']
artid: "146287026"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146287026
    alt: "Vulkan视频解码decode显示display之同步"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146287026
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146287026
cover: https://bing.ee123.net/img/rand?artid=146287026
image: https://bing.ee123.net/img/rand?artid=146287026
img: https://bing.ee123.net/img/rand?artid=146287026
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Vulkan视频解码decode&amp;显示display之同步
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     在ReleaseDisplayedPicture函数中消耗图片资源并且显示display完成，设置两个标志
     <span style="color:#fe2c24">
      <strong>
       m_hasConsummerSignalFence = true 和m_hasConsummerSignalSemaphore
      </strong>
      = true
     </span>
     <br/>
     virtual int32_t ReleaseDisplayedPicture(DecodedFrameRelease** pDecodedFramesRelease, uint32_t numFramesToRelease)
     <br/>
     {
     <!-- -->
     <br/>
     std::lock_guard&lt;std::mutex&gt; lock(m_displayQueueMutex);
     <br/>
     for (uint32_t i = 0; i &lt; numFramesToRelease; i++) {
     <!-- -->
     <br/>
     const DecodedFrameRelease* pDecodedFrameRelease = pDecodedFramesRelease[i];
     <br/>
     int picId = pDecodedFrameRelease-&gt;pictureIndex;
     <br/>
     assert((picId &gt;= 0) &amp;&amp; ((uint32_t)picId &lt; m_perFrameDecodeImageSet.size()));
    </p>
    <p>
     assert(m_perFrameDecodeImageSet[picId].m_decodeOrder == pDecodedFrameRelease-&gt;decodeOrder);
     <br/>
     assert(m_perFrameDecodeImageSet[picId].m_displayOrder == pDecodedFrameRelease-&gt;displayOrder);
    </p>
    <p>
     assert(m_ownedByDisplayMask &amp; (1 &lt;&lt; picId));
     <br/>
     m_ownedByDisplayMask &amp;= ~(1 &lt;&lt; picId);
     <br/>
     m_perFrameDecodeImageSet[picId].m_inDecodeQueue = false;
     <br/>
     m_perFrameDecodeImageSet[picId].m_ownedByConsummer = false;
     <br/>
     m_perFrameDecodeImageSet[picId].Release();
    </p>
    <p>
     <span style="color:#fe2c24">
      <strong>
       m_perFrameDecodeImageSet[picId].m_hasConsummerSignalFence = pDecodedFrameRelease-&gt;hasConsummerSignalFence;
       <br/>
       m_perFrameDecodeImageSet[picId].m_hasConsummerSignalSemaphore = pDecodedFrameRelease-&gt;hasConsummerSignalSemaphore;
      </strong>
     </span>
     <br/>
     }
     <br/>
     return 0;
     <br/>
     }
    </p>
    <p>
     ReleaseDisplayedPicture被
     <span style="color:#0d0016">
      ReleaseFrame
     </span>
     调用，
     <span style="color:#0d0016">
      pLastDecodedFrame就是当前已经解码的帧
     </span>
    </p>
    <p>
     .....................................
    </p>
    <p>
     <span style="color:#fe2c24">
      m_videoQueue-&gt;ReleaseFrame(pLastDecodedFrame);
     </span>
    </p>
    <p>
     pLastDecodedFrame-&gt;Reset();
    </p>
    <p>
     bool endOfStream = false;
     <br/>
     int32_t numVideoFrames = 0;
    </p>
    <p>
     numVideoFrames = m_videoQueue-&gt;GetNextFrame(pLastDecodedFrame, &amp;endOfStream);
    </p>
    <p>
     .............................................
    </p>
    <p>
    </p>
    <p>
     //-----------------------------------------------------------------------
    </p>
    <p>
     这两个标志一旦设置为true，在QueuePictureForDecode函数中，将设置
     <span style="color:#fe2c24">
      pFrameSynchronizationInfo-&gt;frameConsumerDoneFence和 pFrameSynchronizationInfo-&gt;frameConsumerDoneSemaphore
     </span>
     ，返回后使用，同时重置两个标志为false
    </p>
    <p>
     virtual int32_t
     <span style="color:#fe2c24">
      <strong>
       QueuePictureForDecode
      </strong>
     </span>
     (int8_t picId, VkParserDecodePictureInfo* pDecodePictureInfo,
     <br/>
     ReferencedObjectsInfo* pReferencedObjectsInfo,
     <br/>
     FrameSynchronizationInfo* pFrameSynchronizationInfo)
     <br/>
     {
     <!-- -->
     <br/>
     if (pFrameSynchronizationInfo-&gt;hasFrameCompleteSignalFence) {
     <!-- -->
     <br/>
     pFrameSynchronizationInfo-&gt;frameCompleteFence = m_perFrameDecodeImageSet[picId].m_frameCompleteFence;
     <br/>
     if (pFrameSynchronizationInfo-&gt;frameCompleteFence) {
     <!-- -->
     <br/>
     m_perFrameDecodeImageSet[picId].m_hasFrameCompleteSignalFence = true;
     <br/>
     }
     <br/>
     }
    </p>
    <p>
     if (
     <strong>
      <span style="color:#fe2c24">
       m_perFrameDecodeImageSet[picId].m_hasConsummerSignalFence
      </span>
     </strong>
     ) {
     <!-- -->
     <br/>
     <span style="color:#fe2c24">
      pFrameSynchronizationInfo-&gt;frameConsumerDoneFence
     </span>
     = m_perFrameDecodeImageSet[picId].m_frameConsumerDoneFence;
     <br/>
     m_perFrameDecodeImageSet[picId].m_hasConsummerSignalFence = false;
     <br/>
     }
    </p>
    <p>
     if (pFrameSynchronizationInfo-&gt;hasFrameCompleteSignalSemaphore) {
     <!-- -->
     <br/>
     pFrameSynchronizationInfo-&gt;frameCompleteSemaphore = m_perFrameDecodeImageSet[picId].m_frameCompleteSemaphore;
     <br/>
     if (pFrameSynchronizationInfo-&gt;frameCompleteSemaphore) {
     <!-- -->
     <br/>
     m_perFrameDecodeImageSet[picId].m_hasFrameCompleteSignalSemaphore = true;
     <br/>
     }
     <br/>
     }
    </p>
    <p>
     if (
     <span style="color:#fe2c24">
      <strong>
       m_perFrameDecodeImageSet[picId].m_hasConsummerSignalSemaphore
      </strong>
     </span>
     ) {
     <!-- -->
     <br/>
     <span style="color:#fe2c24">
      pFrameSynchronizationInfo-&gt;frameConsumerDoneSemaphore
     </span>
     = m_perFrameDecodeImageSet[picId].m_frameConsumerDoneSemaphore;
     <br/>
     m_perFrameDecodeImageSet[picId].m_hasConsummerSignalSemaphore = false;
     <br/>
     }
     <br/>
     .................
    </p>
    <p>
     }
    </p>
    <p>
    </p>
    <p>
    </p>
    <p>
     返回后如何使用pFrameSynchronizationInfo-&gt;frameConsumerDoneFence和 pFrameSynchronizationInfo-&gt;frameConsumerDoneSemaphore,代码如下：
    </p>
    <p>
    </p>
    <p>
     VkFence frameCompleteFence = frameSynchronizationInfo.frameCompleteFence;
     <br/>
     VkSemaphore frameCompleteSemaphore = frameSynchronizationInfo.frameCompleteSemaphore;
     <br/>
     VkSemaphore
     <span style="color:#fe2c24">
      frameConsumerDoneSemaphore
     </span>
     =
     <span style="color:#fe2c24">
      frameSynchronizationInfo.frameConsumerDoneSemaphore;
     </span>
    </p>
    <p>
    </p>
    <p>
     <span style="color:#0d0016">
      uint32_t waitSemaphoreCount = 0;
      <br/>
      if (frameConsumerDoneSemaphore != VK_NULL_HANDLE) {
      <!-- -->
      <br/>
     </span>
     <span style="color:#fe2c24">
      waitSemaphores[waitSemaphoreCount] = frameConsumerDoneSemaphore;
     </span>
     <br/>
     <span style="color:#0d0016">
      waitSemaphoreCount++;
      <br/>
      }
     </span>
    </p>
    <p>
     VkSubmitInfo submitInfo = { VK_STRUCTURE_TYPE_SUBMIT_INFO, nullptr };
     <br/>
     const VkPipelineStageFlags videoDecodeSubmitWaitStages = VK_PIPELINE_STAGE_ALL_COMMANDS_BIT;
     <br/>
     submitInfo.pNext = (m_hwLoadBalancingTimelineSemaphore != VK_NULL_HANDLE) ? &amp;timelineSemaphoreInfos : nullptr;
     <br/>
     submitInfo.waitSemaphoreCount = waitSemaphoreCount;
     <br/>
     <span style="color:#fe2c24">
      submitInfo.pWaitSemaphores = waitSemaphores;
     </span>
     <br/>
     submitInfo.pWaitDstStageMask = &amp;videoDecodeSubmitWaitStages;
     <br/>
     submitInfo.commandBufferCount = 1;
     <br/>
     submitInfo.pCommandBuffers = &amp;frameDataSlot.commandBuffer;
     <br/>
     submitInfo.signalSemaphoreCount = signalSemaphoreCount;
     <br/>
     submitInfo.pSignalSemaphores = signalSemaphores;
    </p>
    <p>
     assert(VK_NOT_READY == m_vkDevCtx-&gt;GetFenceStatus(*m_vkDevCtx, videoDecodeCompleteFence));
     <br/>
     VkResult result = m_vkDevCtx-&gt;MultiThreadedQueueSubmit(VulkanDeviceContext::DECODE, m_currentVideoQueueIndx,
     <br/>
     1, &amp;submitInfo, videoDecodeCompleteFence);
    </p>
    <p>
    </p>
    <p>
     <span style="color:#fe2c24">
      拷贝pictureIndex视频帧，并进行等待解码完成并且设置显示完成信号
     </span>
    </p>
    <p>
     virtual int32_t DequeueDecodedPicture(VulkanDecodedFrame* pDecodedFrame)
     <br/>
     {
     <!-- -->
    </p>
    <p>
     <br/>
     if (m_perFrameDecodeImageSet[pictureIndex].m_hasFrameCompleteSignalFence) {
     <!-- -->
     <br/>
     pDecodedFrame-&gt;frameCompleteFence = m_perFrameDecodeImageSet[pictureIndex].m_frameCompleteFence;
     <br/>
     m_perFrameDecodeImageSet[pictureIndex].m_hasFrameCompleteSignalFence = false;
     <br/>
     } else {
     <!-- -->
     <br/>
     pDecodedFrame-&gt;frameCompleteFence = VkFence();
     <br/>
     }
    </p>
    <p>
     if (m_perFrameDecodeImageSet[pictureIndex].m_hasFrameCompleteSignalSemaphore) {
     <!-- -->
     <br/>
     pDecodedFrame-&gt;frameCompleteSemaphore = m_perFrameDecodeImageSet[pictureIndex].m_frameCompleteSemaphore;
     <br/>
     m_perFrameDecodeImageSet[pictureIndex].m_hasFrameCompleteSignalSemaphore = false;
     <br/>
     } else {
     <!-- -->
     <br/>
     pDecodedFrame-&gt;frameCompleteSemaphore = VkSemaphore();
     <br/>
     }
    </p>
    <p>
     pDecodedFrame-&gt;frameConsumerDoneFence = m_perFrameDecodeImageSet[pictureIndex].m_frameConsumerDoneFence;
     <br/>
     pDecodedFrame-&gt;frameConsumerDoneSemaphore = m_perFrameDecodeImageSet[pictureIndex].m_frameConsumerDoneSemaphore;
    </p>
    <p>
     pDecodedFrame-&gt;timestamp = m_perFrameDecodeImageSet[pictureIndex].m_timestamp;
     <br/>
     pDecodedFrame-&gt;decodeOrder = m_perFrameDecodeImageSet[pictureIndex].m_decodeOrder;
     <br/>
     pDecodedFrame-&gt;displayOrder = m_perFrameDecodeImageSet[pictureIndex].m_displayOrder;
    </p>
    <p>
     pDecodedFrame-&gt;queryPool = m_queryPool;
     <br/>
     pDecodedFrame-&gt;startQueryId = pictureIndex;
     <br/>
     pDecodedFrame-&gt;numQueries = 1;
    </p>
    <p>
     }
    </p>
    <p>
     //pDecodedFrame传递给DrawFrame最后一个参数pLastDecodedFrame
    </p>
    <p>
     VkResult result = DrawFrame(renderIndex,
     <br/>
     waitSemaphoreCount,
     <br/>
     pWaitSemaphores,
     <br/>
     signalSemaphoreCount,
     <br/>
     pSignalSemaphores,
     <br/>
     pLastDecodedFrame)
    </p>
    <p>
    </p>
    <p>
     VkResult VulkanFrame&lt;FrameDataType&gt;::DrawFrame( int32_t            renderIndex,
     <br/>
     uint32_t           waitSemaphoreCount,
     <br/>
     const VkSemaphore* pWaitSemaphores,
     <br/>
     uint32_t           signalSemaphoreCount,
     <br/>
     const VkSemaphore* pSignalSemaphores,
     <br/>
     FrameDataType*     inFrame)
    </p>
    <p>
     {
     <!-- -->
    </p>
    <p>
     <br/>
     const uint32_t maxWaitSemaphores = 2;
     <br/>
     uint32_t numWaitSemaphores = 0;
     <br/>
     VkSemaphore waitSemaphores[maxWaitSemaphores] = {};
    </p>
    <p>
     assert(waitSemaphoreCount &lt;= 1);
     <br/>
     if ((waitSemaphoreCount &gt; 0) &amp;&amp; (pWaitSemaphores != nullptr)) {
     <!-- -->
    </p>
    <p>
     //这个是等待上一次present完成
     <br/>
     <span style="color:#fe2c24">
      waitSemaphores[numWaitSemaphores++] = *pWaitSemaphores;
     </span>
     <br/>
     }
    </p>
    <p>
     if (inFrame &amp;&amp; (inFrame-&gt;frameCompleteSemaphore != VkSemaphore())) {
     <!-- -->
    </p>
    <p>
     <span style="color:#fe2c24">
      //等待解码完成信号
     </span>
     <br/>
     <span style="color:#fe2c24">
      waitSemaphores[numWaitSemaphores++] = inFrame-&gt;frameCompleteSemaphore;
     </span>
     <br/>
     }
     <br/>
     assert(numWaitSemaphores &lt;= maxWaitSemaphores);
    </p>
    <p>
     const uint32_t maxSignalSemaphores = 2;
     <br/>
     uint32_t numSignalSemaphores = 0;
     <br/>
     VkSemaphore signalSemaphores[maxSignalSemaphores] = {};
    </p>
    <p>
     assert(signalSemaphoreCount &lt;= 1);
     <br/>
     if ((signalSemaphoreCount &gt; 0) &amp;&amp; (pSignalSemaphores != nullptr)) {
     <!-- -->
     <br/>
     <span style="color:#fe2c24">
      <strong>
       signalSemaphores[numSignalSemaphores++] = *pSignalSemaphores;
      </strong>
     </span>
     <br/>
     }
    </p>
    <p>
     if (inFrame &amp;&amp; (inFrame-&gt;frameConsumerDoneSemaphore != VkSemaphore())) {
     <!-- -->
    </p>
    <p>
     <span style="color:#fe2c24">
      //显示完成消费信号激活，这样这个图片资源才能被用来继续解码新视频帧，解码函数中需要等待这个frameConsumerDoneSemaphore有信号才能使用这个图片资源解码
     </span>
     <br/>
     <span style="color:#fe2c24">
      signalSemaphores[numSignalSemaphores++] = inFrame-&gt;frameConsumerDoneSemaphore;
     </span>
     <br/>
     inFrame-&gt;hasConsummerSignalSemaphore = true;
     <br/>
     }
     <br/>
     assert(numSignalSemaphores &lt;= maxSignalSemaphores);
    </p>
    <p>
     if (frameConsumerDoneFence != VkFence()) {
     <!-- -->
     <br/>
     inFrame-&gt;hasConsummerSignalFence = true;
     <br/>
     }
    </p>
    <p>
     <br/>
     // Wait for the image to be owned and signal for render completion
     <br/>
     VkPipelineStageFlags primaryCmdSubmitWaitStages[2] = { VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT,
     <br/>
     VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT };
     <br/>
     VkSubmitInfo primaryCmdSubmitInfo = VkSubmitInfo();
     <br/>
     primaryCmdSubmitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;
     <br/>
     primaryCmdSubmitInfo.pWaitDstStageMask = primaryCmdSubmitWaitStages;
     <br/>
     primaryCmdSubmitInfo.commandBufferCount = 1;
    </p>
    <p>
     primaryCmdSubmitInfo.waitSemaphoreCount = numWaitSemaphores;
     <br/>
     primaryCmdSubmitInfo.pWaitSemaphores = numWaitSemaphores ? waitSemaphores : NULL;
     <br/>
     primaryCmdSubmitInfo.pCommandBuffers = pPerDrawContext-&gt;commandBuffer.GetCommandBuffer();
    </p>
    <p>
     primaryCmdSubmitInfo.signalSemaphoreCount = numSignalSemaphores;
     <br/>
     primaryCmdSubmitInfo.pSignalSemaphores = numSignalSemaphores ? signalSemaphores : NULL;
    </p>
    <p>
     // For fence/sync debugging
     <br/>
     if (false &amp;&amp; inFrame &amp;&amp; inFrame-&gt;frameCompleteFence) {
     <!-- -->
     <br/>
     result = m_vkDevCtx-&gt;WaitForFences(*m_vkDevCtx, 1, &amp;inFrame-&gt;frameCompleteFence, true, 100 * 1000 * 1000);
     <br/>
     assert(result == VK_SUCCESS);
     <br/>
     if (result != VK_SUCCESS) {
     <!-- -->
     <br/>
     fprintf(stderr, "\nERROR: WaitForFences() result: 0x%x\n", result);
     <br/>
     }
     <br/>
     result = m_vkDevCtx-&gt;GetFenceStatus(*m_vkDevCtx, inFrame-&gt;frameCompleteFence);
     <br/>
     assert(result == VK_SUCCESS);
     <br/>
     if (result != VK_SUCCESS) {
     <!-- -->
     <br/>
     fprintf(stderr, "\nERROR: GetFenceStatus() result: 0x%x\n", result);
     <br/>
     }
     <br/>
     }
    </p>
    <p>
     result = m_vkDevCtx-&gt;MultiThreadedQueueSubmit(VulkanDeviceContext::GRAPHICS, 0, 1, &amp;primaryCmdSubmitInfo, frameConsumerDoneFence);
     <br/>
     if (result != VK_SUCCESS) {
     <!-- -->
     <br/>
     assert(result == VK_SUCCESS);
     <br/>
     fprintf(stderr, "\nERROR: MultiThreadedQueueSubmit() result: 0x%x\n", result);
     <br/>
     return result;
     <br/>
     }
    </p>
    <p>
     if (false &amp;&amp; (frameConsumerDoneFence != VkFence())) { // For fence/sync debugging
     <br/>
     const uint64_t fenceTimeout = 100 * 1000 * 1000 /* 100 mSec */;
     <br/>
     result = m_vkDevCtx-&gt;WaitForFences(*m_vkDevCtx, 1, &amp;frameConsumerDoneFence, true, fenceTimeout);
     <br/>
     assert(result == VK_SUCCESS);
     <br/>
     if (result != VK_SUCCESS) {
     <!-- -->
     <br/>
     fprintf(stderr, "\nERROR: WaitForFences() result: 0x%x\n", result);
     <br/>
     }
     <br/>
     result = m_vkDevCtx-&gt;GetFenceStatus(*m_vkDevCtx, frameConsumerDoneFence);
     <br/>
     assert(result == VK_SUCCESS);
     <br/>
     if (result != VK_SUCCESS) {
     <!-- -->
     <br/>
     fprintf(stderr, "\nERROR: GetFenceStatus() result: 0x%x\n", result);
     <br/>
     }
     <br/>
     }
    </p>
    <p>
     #if 0 // for testing VK_KHR_external_fence_fd
     <br/>
     int fd = -1; // VK_EXTERNAL_FENCE_HANDLE_TYPE_SYNC_FD_BIT
     <br/>
     const VkFenceGetFdInfoKHR getFdInfo =  { VK_STRUCTURE_TYPE_FENCE_GET_FD_INFO_KHR, NULL, data.lastDecodedFrame.frameConsumerDoneFence, VK_EXTERNAL_FENCE_HANDLE_TYPE_SYNC_FD_BIT};
     <br/>
     res = m_vkDevCtx-&gt;GetFenceFdKHR(*m_vkDevCtx, &amp;getFdInfo, &amp;fd);
     <br/>
     close(fd);
     <br/>
     #endif
    </p>
    <p>
     m_frameDataIndex = (m_frameDataIndex + 1) % m_frameData.size();
    </p>
    <p>
     return result;
    </p>
    <p>
     }
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e6373:646e2e6e65742f7a7862636f6c6c65676573747564656e742f:61727469636c652f64657461696c732f313436323837303236" class_="artid" style="display:none">
 </p>
</div>


