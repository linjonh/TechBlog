---
arturl_encode: "68747470733a2f2f626c6f672e6373:646e2e6e65742f7a7862636f6c6c65676573747564656e742f:61727469636c652f64657461696c732f313436323837303236"
layout: post
title: "Vulkan视频解码decode显示display之同步"
date: 2025-03-15 22:54:23 +08:00
description: "pFrameSynchronizationInfo->frameConsumerDoneFence和 pFrameSynchronizationInfo->frameConsumerDoneSemaphore。在ReleaseDisplayedPicture函数中消耗图片资源并且显示display完成，设置两个标志。这两个标志一旦设置为true，在QueuePictureForDecode函数中，将设置。ReleaseDisplayedPicture被。，返回后使用，同时重置两个标志为false。"
keywords: "Vulkan视频解码decode&显示display之同步"
categories: ['未分类']
tags: ['音视频', '算法', 'C']
artid: "146287026"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146287026
    alt: "Vulkan视频解码decode显示display之同步"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146287026
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146287026
cover: https://bing.ee123.net/img/rand?artid=146287026
image: https://bing.ee123.net/img/rand?artid=146287026
img: https://bing.ee123.net/img/rand?artid=146287026
---

# Vulkan视频解码decode&显示display之同步

在ReleaseDisplayedPicture函数中消耗图片资源并且显示display完成，设置两个标志
**m\_hasConsummerSignalFence = true 和m\_hasConsummerSignalSemaphore**
= true
  
virtual int32\_t ReleaseDisplayedPicture(DecodedFrameRelease** pDecodedFramesRelease, uint32\_t numFramesToRelease)
  
{
  
std::lock\_guard<std::mutex> lock(m\_displayQueueMutex);
  
for (uint32\_t i = 0; i < numFramesToRelease; i++) {
  
const DecodedFrameRelease* pDecodedFrameRelease = pDecodedFramesRelease[i];
  
int picId = pDecodedFrameRelease->pictureIndex;
  
assert((picId >= 0) && ((uint32\_t)picId < m\_perFrameDecodeImageSet.size()));

assert(m\_perFrameDecodeImageSet[picId].m\_decodeOrder == pDecodedFrameRelease->decodeOrder);
  
assert(m\_perFrameDecodeImageSet[picId].m\_displayOrder == pDecodedFrameRelease->displayOrder);

assert(m\_ownedByDisplayMask & (1 << picId));
  
m\_ownedByDisplayMask &= ~(1 << picId);
  
m\_perFrameDecodeImageSet[picId].m\_inDecodeQueue = false;
  
m\_perFrameDecodeImageSet[picId].m\_ownedByConsummer = false;
  
m\_perFrameDecodeImageSet[picId].Release();

**m\_perFrameDecodeImageSet[picId].m\_hasConsummerSignalFence = pDecodedFrameRelease->hasConsummerSignalFence;
  
m\_perFrameDecodeImageSet[picId].m\_hasConsummerSignalSemaphore = pDecodedFrameRelease->hasConsummerSignalSemaphore;**
  
}
  
return 0;
  
}

ReleaseDisplayedPicture被
ReleaseFrame
调用，
pLastDecodedFrame就是当前已经解码的帧

.....................................

m\_videoQueue->ReleaseFrame(pLastDecodedFrame);

pLastDecodedFrame->Reset();

bool endOfStream = false;
  
int32\_t numVideoFrames = 0;

numVideoFrames = m\_videoQueue->GetNextFrame(pLastDecodedFrame, &endOfStream);

.............................................

//-----------------------------------------------------------------------

这两个标志一旦设置为true，在QueuePictureForDecode函数中，将设置
pFrameSynchronizationInfo->frameConsumerDoneFence和 pFrameSynchronizationInfo->frameConsumerDoneSemaphore
，返回后使用，同时重置两个标志为false

virtual int32\_t
**QueuePictureForDecode**
(int8\_t picId, VkParserDecodePictureInfo* pDecodePictureInfo,
  
ReferencedObjectsInfo* pReferencedObjectsInfo,
  
FrameSynchronizationInfo* pFrameSynchronizationInfo)
  
{
  
if (pFrameSynchronizationInfo->hasFrameCompleteSignalFence) {
  
pFrameSynchronizationInfo->frameCompleteFence = m\_perFrameDecodeImageSet[picId].m\_frameCompleteFence;
  
if (pFrameSynchronizationInfo->frameCompleteFence) {
  
m\_perFrameDecodeImageSet[picId].m\_hasFrameCompleteSignalFence = true;
  
}
  
}

if (
**m\_perFrameDecodeImageSet[picId].m\_hasConsummerSignalFence**
) {
  

pFrameSynchronizationInfo->frameConsumerDoneFence
= m\_perFrameDecodeImageSet[picId].m\_frameConsumerDoneFence;
  
m\_perFrameDecodeImageSet[picId].m\_hasConsummerSignalFence = false;
  
}

if (pFrameSynchronizationInfo->hasFrameCompleteSignalSemaphore) {
  
pFrameSynchronizationInfo->frameCompleteSemaphore = m\_perFrameDecodeImageSet[picId].m\_frameCompleteSemaphore;
  
if (pFrameSynchronizationInfo->frameCompleteSemaphore) {
  
m\_perFrameDecodeImageSet[picId].m\_hasFrameCompleteSignalSemaphore = true;
  
}
  
}

if (
**m\_perFrameDecodeImageSet[picId].m\_hasConsummerSignalSemaphore**
) {
  

pFrameSynchronizationInfo->frameConsumerDoneSemaphore
= m\_perFrameDecodeImageSet[picId].m\_frameConsumerDoneSemaphore;
  
m\_perFrameDecodeImageSet[picId].m\_hasConsummerSignalSemaphore = false;
  
}
  
.................

}

返回后如何使用pFrameSynchronizationInfo->frameConsumerDoneFence和 pFrameSynchronizationInfo->frameConsumerDoneSemaphore,代码如下：

VkFence frameCompleteFence = frameSynchronizationInfo.frameCompleteFence;
  
VkSemaphore frameCompleteSemaphore = frameSynchronizationInfo.frameCompleteSemaphore;
  
VkSemaphore
frameConsumerDoneSemaphore
=
frameSynchronizationInfo.frameConsumerDoneSemaphore;

uint32\_t waitSemaphoreCount = 0;
  
if (frameConsumerDoneSemaphore != VK\_NULL\_HANDLE) {
  

waitSemaphores[waitSemaphoreCount] = frameConsumerDoneSemaphore;
  

waitSemaphoreCount++;
  
}

VkSubmitInfo submitInfo = { VK\_STRUCTURE\_TYPE\_SUBMIT\_INFO, nullptr };
  
const VkPipelineStageFlags videoDecodeSubmitWaitStages = VK\_PIPELINE\_STAGE\_ALL\_COMMANDS\_BIT;
  
submitInfo.pNext = (m\_hwLoadBalancingTimelineSemaphore != VK\_NULL\_HANDLE) ? &timelineSemaphoreInfos : nullptr;
  
submitInfo.waitSemaphoreCount = waitSemaphoreCount;
  

submitInfo.pWaitSemaphores = waitSemaphores;
  
submitInfo.pWaitDstStageMask = &videoDecodeSubmitWaitStages;
  
submitInfo.commandBufferCount = 1;
  
submitInfo.pCommandBuffers = &frameDataSlot.commandBuffer;
  
submitInfo.signalSemaphoreCount = signalSemaphoreCount;
  
submitInfo.pSignalSemaphores = signalSemaphores;

assert(VK\_NOT\_READY == m\_vkDevCtx->GetFenceStatus(*m\_vkDevCtx, videoDecodeCompleteFence));
  
VkResult result = m\_vkDevCtx->MultiThreadedQueueSubmit(VulkanDeviceContext::DECODE, m\_currentVideoQueueIndx,
  
1, &submitInfo, videoDecodeCompleteFence);

拷贝pictureIndex视频帧，并进行等待解码完成并且设置显示完成信号

virtual int32\_t DequeueDecodedPicture(VulkanDecodedFrame* pDecodedFrame)
  
{

if (m\_perFrameDecodeImageSet[pictureIndex].m\_hasFrameCompleteSignalFence) {
  
pDecodedFrame->frameCompleteFence = m\_perFrameDecodeImageSet[pictureIndex].m\_frameCompleteFence;
  
m\_perFrameDecodeImageSet[pictureIndex].m\_hasFrameCompleteSignalFence = false;
  
} else {
  
pDecodedFrame->frameCompleteFence = VkFence();
  
}

if (m\_perFrameDecodeImageSet[pictureIndex].m\_hasFrameCompleteSignalSemaphore) {
  
pDecodedFrame->frameCompleteSemaphore = m\_perFrameDecodeImageSet[pictureIndex].m\_frameCompleteSemaphore;
  
m\_perFrameDecodeImageSet[pictureIndex].m\_hasFrameCompleteSignalSemaphore = false;
  
} else {
  
pDecodedFrame->frameCompleteSemaphore = VkSemaphore();
  
}

pDecodedFrame->frameConsumerDoneFence = m\_perFrameDecodeImageSet[pictureIndex].m\_frameConsumerDoneFence;
  
pDecodedFrame->frameConsumerDoneSemaphore = m\_perFrameDecodeImageSet[pictureIndex].m\_frameConsumerDoneSemaphore;

pDecodedFrame->timestamp = m\_perFrameDecodeImageSet[pictureIndex].m\_timestamp;
  
pDecodedFrame->decodeOrder = m\_perFrameDecodeImageSet[pictureIndex].m\_decodeOrder;
  
pDecodedFrame->displayOrder = m\_perFrameDecodeImageSet[pictureIndex].m\_displayOrder;

pDecodedFrame->queryPool = m\_queryPool;
  
pDecodedFrame->startQueryId = pictureIndex;
  
pDecodedFrame->numQueries = 1;

}

//pDecodedFrame传递给DrawFrame最后一个参数pLastDecodedFrame

VkResult result = DrawFrame(renderIndex,
  
waitSemaphoreCount,
  
pWaitSemaphores,
  
signalSemaphoreCount,
  
pSignalSemaphores,
  
pLastDecodedFrame)

VkResult VulkanFrame<FrameDataType>::DrawFrame( int32\_t            renderIndex,
  
uint32\_t           waitSemaphoreCount,
  
const VkSemaphore* pWaitSemaphores,
  
uint32\_t           signalSemaphoreCount,
  
const VkSemaphore* pSignalSemaphores,
  
FrameDataType*     inFrame)

{

const uint32\_t maxWaitSemaphores = 2;
  
uint32\_t numWaitSemaphores = 0;
  
VkSemaphore waitSemaphores[maxWaitSemaphores] = {};

assert(waitSemaphoreCount <= 1);
  
if ((waitSemaphoreCount > 0) && (pWaitSemaphores != nullptr)) {

//这个是等待上一次present完成
  

waitSemaphores[numWaitSemaphores++] = *pWaitSemaphores;
  
}

if (inFrame && (inFrame->frameCompleteSemaphore != VkSemaphore())) {

//等待解码完成信号
  

waitSemaphores[numWaitSemaphores++] = inFrame->frameCompleteSemaphore;
  
}
  
assert(numWaitSemaphores <= maxWaitSemaphores);

const uint32\_t maxSignalSemaphores = 2;
  
uint32\_t numSignalSemaphores = 0;
  
VkSemaphore signalSemaphores[maxSignalSemaphores] = {};

assert(signalSemaphoreCount <= 1);
  
if ((signalSemaphoreCount > 0) && (pSignalSemaphores != nullptr)) {
  

**signalSemaphores[numSignalSemaphores++] = *pSignalSemaphores;**
  
}

if (inFrame && (inFrame->frameConsumerDoneSemaphore != VkSemaphore())) {

//显示完成消费信号激活，这样这个图片资源才能被用来继续解码新视频帧，解码函数中需要等待这个frameConsumerDoneSemaphore有信号才能使用这个图片资源解码
  

signalSemaphores[numSignalSemaphores++] = inFrame->frameConsumerDoneSemaphore;
  
inFrame->hasConsummerSignalSemaphore = true;
  
}
  
assert(numSignalSemaphores <= maxSignalSemaphores);

if (frameConsumerDoneFence != VkFence()) {
  
inFrame->hasConsummerSignalFence = true;
  
}

// Wait for the image to be owned and signal for render completion
  
VkPipelineStageFlags primaryCmdSubmitWaitStages[2] = { VK\_PIPELINE\_STAGE\_TOP\_OF\_PIPE\_BIT,
  
VK\_PIPELINE\_STAGE\_TOP\_OF\_PIPE\_BIT };
  
VkSubmitInfo primaryCmdSubmitInfo = VkSubmitInfo();
  
primaryCmdSubmitInfo.sType = VK\_STRUCTURE\_TYPE\_SUBMIT\_INFO;
  
primaryCmdSubmitInfo.pWaitDstStageMask = primaryCmdSubmitWaitStages;
  
primaryCmdSubmitInfo.commandBufferCount = 1;

primaryCmdSubmitInfo.waitSemaphoreCount = numWaitSemaphores;
  
primaryCmdSubmitInfo.pWaitSemaphores = numWaitSemaphores ? waitSemaphores : NULL;
  
primaryCmdSubmitInfo.pCommandBuffers = pPerDrawContext->commandBuffer.GetCommandBuffer();

primaryCmdSubmitInfo.signalSemaphoreCount = numSignalSemaphores;
  
primaryCmdSubmitInfo.pSignalSemaphores = numSignalSemaphores ? signalSemaphores : NULL;

// For fence/sync debugging
  
if (false && inFrame && inFrame->frameCompleteFence) {
  
result = m\_vkDevCtx->WaitForFences(*m\_vkDevCtx, 1, &inFrame->frameCompleteFence, true, 100 * 1000 * 1000);
  
assert(result == VK\_SUCCESS);
  
if (result != VK\_SUCCESS) {
  
fprintf(stderr, "\nERROR: WaitForFences() result: 0x%x\n", result);
  
}
  
result = m\_vkDevCtx->GetFenceStatus(*m\_vkDevCtx, inFrame->frameCompleteFence);
  
assert(result == VK\_SUCCESS);
  
if (result != VK\_SUCCESS) {
  
fprintf(stderr, "\nERROR: GetFenceStatus() result: 0x%x\n", result);
  
}
  
}

result = m\_vkDevCtx->MultiThreadedQueueSubmit(VulkanDeviceContext::GRAPHICS, 0, 1, &primaryCmdSubmitInfo, frameConsumerDoneFence);
  
if (result != VK\_SUCCESS) {
  
assert(result == VK\_SUCCESS);
  
fprintf(stderr, "\nERROR: MultiThreadedQueueSubmit() result: 0x%x\n", result);
  
return result;
  
}

if (false && (frameConsumerDoneFence != VkFence())) { // For fence/sync debugging
  
const uint64\_t fenceTimeout = 100 * 1000 * 1000 /* 100 mSec */;
  
result = m\_vkDevCtx->WaitForFences(*m\_vkDevCtx, 1, &frameConsumerDoneFence, true, fenceTimeout);
  
assert(result == VK\_SUCCESS);
  
if (result != VK\_SUCCESS) {
  
fprintf(stderr, "\nERROR: WaitForFences() result: 0x%x\n", result);
  
}
  
result = m\_vkDevCtx->GetFenceStatus(*m\_vkDevCtx, frameConsumerDoneFence);
  
assert(result == VK\_SUCCESS);
  
if (result != VK\_SUCCESS) {
  
fprintf(stderr, "\nERROR: GetFenceStatus() result: 0x%x\n", result);
  
}
  
}

#if 0 // for testing VK\_KHR\_external\_fence\_fd
  
int fd = -1; // VK\_EXTERNAL\_FENCE\_HANDLE\_TYPE\_SYNC\_FD\_BIT
  
const VkFenceGetFdInfoKHR getFdInfo =  { VK\_STRUCTURE\_TYPE\_FENCE\_GET\_FD\_INFO\_KHR, NULL, data.lastDecodedFrame.frameConsumerDoneFence, VK\_EXTERNAL\_FENCE\_HANDLE\_TYPE\_SYNC\_FD\_BIT};
  
res = m\_vkDevCtx->GetFenceFdKHR(*m\_vkDevCtx, &getFdInfo, &fd);
  
close(fd);
  
#endif

m\_frameDataIndex = (m\_frameDataIndex + 1) % m\_frameData.size();

return result;

}