---
layout: post
title: "prompt工程起步"
date: 2025-03-14 11:22:41 +08:00
description: "有关CLIP和ActionClip的手工特征,也是一个进步。通过给标签填入不同的修饰语当中，组成一段话来,来增强语义理解这个就是一个手工提示词,针对于特殊的任务设计出来的。text_dict就是蕴含着一个模板是键,对应不同的一句话!将输入标签随机选一个模板与视频进行对比学习！"
keywords: "prompt工程起步"
categories: ['基于Prompt视觉语言模型的长视频行文理解分析']
tags: ['开发语言', 'Python', 'Prompt']
artid: "146249117"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146249117
    alt: "prompt工程起步"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146249117
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146249117
cover: https://bing.ee123.net/img/rand?artid=146249117
image: https://bing.ee123.net/img/rand?artid=146249117
img: https://bing.ee123.net/img/rand?artid=146249117
---

# prompt工程起步
## 1.手工提示词
有关CLIP和ActionClip的手工特征,也是一个进步。通过给标签填入不同的修饰语当中，组成一段话来,来增强语义理解
def text\_prompt(data):
text\_aug = [f"a photo of action {{}}", f"a picture of action {{}}", f"Human action of {{}}", f"{{}}, an action",
f"{{}} this is an action", f"{{}}, a video of action", f"Playing action of {{}}", f"{{}}",
f"Playing a kind of action, {{}}", f"Doing a kind of action, {{}}", f"Look, the human is {{}}",
f"Can you recognize the action of {{}}?", f"Video classification of {{}}", f"A video of {{}}",
f"The man is {{}}", f"The woman is {{}}"]
text\_dict = {}
num\_text\_aug = len(text\_aug)
for ii, txt in enumerate(text\_aug):
text\_dict[ii] = torch.cat([clip.tokenize(txt.format(c)) for i, c in data.classes])
classes = torch.cat([v for k, v in text\_dict.items()])
return classes, num\_text\_aug,text\_dict
这个就是一个手工提示词,针对于特殊的任务设计出来的。text\_dict就是蕴含着一个模板是键,对应不同的一句话!
\*\*应用为：\*\*
text\_id = numpy.random.randint(num\_text\_aug,size=len(list\_id))#类别长度 上限
#text\_dict[j][i, :]：根据 text\_id 中的索引 j 从 text\_dict 中选择对应的编码张量，再根据 list\_id 中的索引 i 从该张量中选择一行。
texts = torch.stack([text\_dict[j][i,:] for i,j in zip(list\_id,text\_id)])
将输入标签随机选一个模板与视频进行对比学习！
## 2.自动生成提示
\*\*(1) 视觉特征的提取\*\*
首先，从视频中提取视觉特征。这些特征可以是视频帧的特征，也可以是视频的整体特征。视觉特征的提取通常使用预训练的视觉模型（如 CLIP 的视觉编码器）来完成。
\*\*(2) 文本特征的初始化\*\*
文本特征可以是类别标签的嵌入，也可以是其他与任务相关的文本信息。这些文本特征将作为提示的初始输入。
\*\*(3)跨模态注意力机制\*\*
class MulitHeadAttention(nn.Module):
def \_\_init\_\_(self, dim, num\_heads=8, qkv\_bias=False, qk\_scale=None, attn\_drop=0., proj\_drop=0.):
super().\_\_init\_\_()
self.num\_heads = num\_heads
head\_dim = dim // num\_heads
self.scale = qk\_scale or head\_dim \*\* -0.5
self.q\_proj = nn.Linear(dim, dim, bias=qkv\_bias)
self.k\_proj = nn.Linear(dim, dim, bias=qkv\_bias)
self.v\_proj = nn.Linear(dim, dim, bias=qkv\_bias)
self.attn\_drop = nn.Dropout(attn\_drop)
self.proj = nn.Linear(dim, dim)
self.proj\_drop = nn.Dropout(proj\_drop)
def forward(self, q, k, v):
B, N, C = q.shape
B, M, C = k.shape
q = self.q\_proj(q).reshape(B, N, self.num\_heads, C // self.num\_heads).permute(0,2,1,3)
k = self.k\_proj(k).reshape(B, M, self.num\_heads, C // self.num\_heads).permute(0,2,1,3)
v = self.v\_proj(v).reshape(B, M, self.num\_heads, C // self.num\_heads).permute(0,2,1,3)
attn = (q @ k.transpose(-2, -1)) \* self.scale
attn = attn.softmax(dim=-1)
attn = self.attn\_drop(attn)
x = (attn @ v).transpose(1, 2).reshape(B, N, C)
x = self.proj(x)
x = self.proj\_drop(x)
return x
\*\*（4）\*\* PromptGeneratorLayer(本质上是一个transfomer编码器)
class PromptGeneratorLayer(nn.Module):
def \_\_init\_\_(
self,
d\_model,
nhead,
dropout=0.,
):
super().\_\_init\_\_()
self.cross\_attn = MulitHeadAttention(d\_model, nhead, proj\_drop=dropout)
self.norm1 = nn.LayerNorm(d\_model)
self.norm3 = nn.LayerNorm(d\_model)
self.dropout = nn.Dropout(dropout)
self.mlp = nn.Sequential(
nn.Linear(d\_model, d\_model \* 4),
QuickGELU(),
nn.Dropout(dropout),
nn.Linear(d\_model \* 4, d\_model)
)
def forward(self, x, visual):
q = k = v = self.norm1(x)
x = x + self.cross\_attn(q, visual, visual)
x = x + self.dropout(self.mlp(self.norm3(x)))
return x
\*\*（5）融合\*\*
class VideoSpecificPrompt(nn.Module):
def \_\_init\_\_(self, layers=2, embed\_dim=512, alpha=0.1,):
super().\_\_init\_\_()
self.norm = nn.LayerNorm(embed\_dim)
self.decoder = nn.ModuleList([PromptGeneratorLayer(embed\_dim, embed\_dim//64) for \_ in range(layers)])
self.alpha = nn.Parameter(torch.ones(embed\_dim) \* alpha)
self.apply(self.\_init\_weights)
def \_init\_weights(self, m):
if isinstance(m, nn.Linear):
trunc\_normal\_(m.weight, std=.02)
if isinstance(m, nn.Linear) and m.bias is not None:
nn.init.constant\_(m.bias, 0)
elif isinstance(m, nn.LayerNorm):
nn.init.constant\_(m.bias, 0)
nn.init.constant\_(m.weight, 1.0)
def forward(self, text, visual):
B, N, C = visual.shape
visual = self.norm(visual)
for layer in self.decoder:
text = layer(text, visual)
\*\*应用：\*\*
def generate\_text(data):
text\_aug = f"{{}}"
classes = torch.cat([clip.tokenize(text\_aug.format(c), context\_length=77) for i, c in data.classes])
return classes
def classes(self):
classes\_all = pd.read\_csv(self.labels\_file)
return classes\_all.values.tolist()
class是：`classes` 是一个 `torch.Tensor` 类型的对象，其形状为 `(n, 77)`，其中 `n`
是类别名称的数量，每一行代表一个类别名称经过 CLIP 分词后的结果。