---
layout: post
title: "PyTorch-实现-Conditional-DCGAN条件深度卷积生成对抗网络进行图像到图像转换的示例代码"
date: 2025-03-16 22:14:38 +08:00
description: "生成器# 输入: [batch_size, z_dim + 4, 1, 1]nn.Tanh()),# 判别器# 输入: [batch_size, img_channels + 4, 64, 64]nn.Conv2d(),"
keywords: "PyTorch 实现 Conditional DCGAN（条件深度卷积生成对抗网络）进行图像到图像转换的示例代码"
categories: ['算法', 'Python']
tags: ['深度学习', '人工智能', 'Yolo']
artid: "146302731"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146302731
    alt: "PyTorch-实现-Conditional-DCGAN条件深度卷积生成对抗网络进行图像到图像转换的示例代码"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146302731
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146302731
cover: https://bing.ee123.net/img/rand?artid=146302731
image: https://bing.ee123.net/img/rand?artid=146302731
img: https://bing.ee123.net/img/rand?artid=146302731
---

# PyTorch 实现 Conditional DCGAN（条件深度卷积生成对抗网络）进行图像到图像转换的示例代码
以下是一个使用 PyTorch 实现 Conditional
DCGAN（条件深度卷积生成对抗网络）进行图像到图像转换的示例代码。该代码包含训练和可视化部分，假设输入为图片和 4
个工艺参数，根据这些输入生成相应的图片。
#### 1\. 导入必要的库
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import numpy as np
import matplotlib.pyplot as plt
# 检查是否有可用的 GPU
device = torch.device("cuda" if torch.cuda.is\_available() else "cpu")
#### 2\. 定义数据集类
class ImagePairDataset(Dataset):
def \_\_init\_\_(self, image\_pairs, params):
self.image\_pairs = image\_pairs
self.params = params
def \_\_len\_\_(self):
return len(self.image\_pairs)
def \_\_getitem\_\_(self, idx):
input\_image, target\_image = self.image\_pairs[idx]
param = self.params[idx]
return input\_image, target\_image, param
#### 3\. 定义生成器和判别器
# 生成器
class Generator(nn.Module):
def \_\_init\_\_(self, z\_dim=4, img\_channels=3):
super(Generator, self).\_\_init\_\_()
self.gen = nn.Sequential(
# 输入: [batch\_size, z\_dim + 4, 1, 1]
self.\_block(z\_dim + 4, 1024, 4, 1, 0), # [batch\_size, 1024, 4, 4]
self.\_block(1024, 512, 4, 2, 1), # [batch\_size, 512, 8, 8]
self.\_block(512, 256, 4, 2, 1), # [batch\_size, 256, 16, 16]
self.\_block(256, 128, 4, 2, 1), # [batch\_size, 128, 32, 32]
nn.ConvTranspose2d(128, img\_channels, kernel\_size=4, stride=2, padding=1),
nn.Tanh()
)
def \_block(self, in\_channels, out\_channels, kernel\_size, stride, padding):
return nn.Sequential(
nn.ConvTranspose2d(
in\_channels, out\_channels, kernel\_size, stride, padding, bias=False
),
nn.BatchNorm2d(out\_channels),
nn.ReLU(True)
)
def forward(self, z, params):
params = params.view(params.size(0), 4, 1, 1)
x = torch.cat([z, params], dim=1)
return self.gen(x)
# 判别器
class Discriminator(nn.Module):
def \_\_init\_\_(self, img\_channels=3):
super(Discriminator, self).\_\_init\_\_()
self.disc = nn.Sequential(
# 输入: [batch\_size, img\_channels + 4, 64, 64]
nn.Conv2d(img\_channels + 4, 64, kernel\_size=4, stride=2, padding=1),
nn.LeakyReLU(0.2),
self.\_block(64, 128, 4, 2, 1), # [batch\_size, 128, 16, 16]
self.\_block(128, 256, 4, 2, 1), # [batch\_size, 256, 8, 8]
self.\_block(256, 512, 4, 2, 1), # [batch\_size, 512, 4, 4]
nn.Conv2d(512, 1, kernel\_size=4, stride=2, padding=0),
nn.Sigmoid()
)
def \_block(self, in\_channels, out\_channels, kernel\_size, stride, padding):
return nn.Sequential(
nn.Conv2d(
in\_channels, out\_channels, kernel\_size, stride, padding, bias=False
),
nn.BatchNorm2d(out\_channels),
nn.LeakyReLU(0.2)
)
def forward(self, img, params):
params = params.view(params.size(0), 4, 1, 1).repeat(1, 1, img.size(2), img.size(3))
x = torch.cat([img, params], dim=1)
return self.disc(x)
#### 4\. 训练代码
def train\_conditional\_dcgan(image\_pairs, params, batch\_size=32, epochs=10, lr=0.0002, z\_dim=4):
dataset = ImagePairDataset(image\_pairs, params)
dataloader = DataLoader(dataset, batch\_size=batch\_size, shuffle=True)
gen = Generator(z\_dim).to(device)
disc = Discriminator().to(device)
criterion = nn.BCELoss()
opt\_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))
opt\_disc = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))
for epoch in range(epochs):
for i, (input\_images, target\_images, param) in enumerate(dataloader):
input\_images = input\_images.to(device)
target\_images = target\_images.to(device)
param = param.to(device)
# 训练判别器
opt\_disc.zero\_grad()
real\_labels = torch.ones((target\_images.size(0), 1, 1, 1)).to(device)
fake\_labels = torch.zeros((target\_images.size(0), 1, 1, 1)).to(device)
# 计算判别器对真实图像的损失
real\_output = disc(target\_images, param)
d\_real\_loss = criterion(real\_output, real\_labels)
# 生成假图像
z = torch.randn(target\_images.size(0), z\_dim, 1, 1).to(device)
fake\_images = gen(z, param)
# 计算判别器对假图像的损失
fake\_output = disc(fake\_images.detach(), param)
d\_fake\_loss = criterion(fake\_output, fake\_labels)
# 总判别器损失
d\_loss = d\_real\_loss + d\_fake\_loss
d\_loss.backward()
opt\_disc.step()
# 训练生成器
opt\_gen.zero\_grad()
output = disc(fake\_images, param)
g\_loss = criterion(output, real\_labels)
g\_loss.backward()
opt\_gen.step()
print(f'Epoch [{epoch+1}/{epochs}] D\_loss: {d\_loss.item():.4f} G\_loss: {g\_loss.item():.4f}')
return gen
#### 5\. 可视化代码
def visualize\_generated\_images(gen, input\_images, params, z\_dim=4):
input\_images = input\_images.to(device)
params = params.to(device)
z = torch.randn(input\_images.size(0), z\_dim, 1, 1).to(device)
fake\_images = gen(z, params).cpu().detach()
fig, axes = plt.subplots(1, input\_images.size(0), figsize=(15, 3))
for i in range(input\_images.size(0)):
img = fake\_images[i].permute(1, 2, 0).numpy()
img = (img + 1) / 2 # 从 [-1, 1] 转换到 [0, 1]
axes[i].imshow(img)
axes[i].axis('off')
plt.show()
#### 6\. 示例使用
# 假设 image\_pairs 是一个包含图像对的列表，params 是一个包含 4 个工艺参数的列表
image\_pairs = [] # 这里需要替换为实际的图像对数据
params = [] # 这里需要替换为实际的工艺参数数据
# 训练模型
gen = train\_conditional\_dcgan(image\_pairs, params)
# 可视化生成的图像
test\_input\_images, test\_target\_images, test\_params = image\_pairs[:5], image\_pairs[:5], params[:5]
test\_input\_images = torch.stack([torch.tensor(img) for img in test\_input\_images]).float()
test\_params = torch.tensor(test\_params).float()
visualize\_generated\_images(gen, test\_input\_images, test\_params)
#### 代码说明
1. \*\*数据集类\*\* ：`ImagePairDataset` 用于加载图像对和工艺参数。
2. \*\*生成器和判别器\*\* ：`Generator` 和 `Discriminator` 分别定义了生成器和判别器的网络结构。
3. \*\*训练代码\*\* ：`train\_conditional\_dcgan` 函数用于训练 Conditional DCGAN 模型。
4. \*\*可视化代码\*\* ：`visualize\_generated\_images` 函数用于可视化生成的图像。
5. \*\*示例使用\*\* ：最后部分展示了如何使用上述函数进行训练和可视化。
请注意，你需要将 `image\_pairs` 和 `params` 替换为实际的数据集。此外，代码中的超参数（如
`batch\_size`、`epochs`、`lr` 等）可以根据实际情况进行调整。