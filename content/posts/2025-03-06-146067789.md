---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34333437393138382f:61727469636c652f64657461696c732f313436303637373839"
layout: post
title: "实战指南构建高可用生产级Kafka集群的完整教程"
date: 2025-03-06 13:28:08 +0800
description: "本文详细讲解了从零开始部署多节点Kafka集群的全流程，涵盖环境准备、ZooKeeper集群搭建、Kafka多节点配置、性能优化、监控集成及容灾验证等关键环节。教程以3台服务器为例，指导用户完成ZooKeeper集群的选举配置与同步测试，并通过调整server.properties实现Kafka节点的协同工作。文章重点解析了参数优化技巧（如JVM调优、网络线程配置）以提升集群性能，并引入EFAK可视化工具实现集群状态监控。此外，通过模拟Broker宕机、数据持久化验证及分区恢复测试，确保集群的高可用性与容灾"
keywords: "实战指南：构建高可用生产级Kafka集群的完整教程"
categories: ['Linux', 'Devops']
tags: ['分布式', 'Zookeeper', 'Linq', 'Kafka', 'Efak']
artid: "146067789"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146067789
    alt: "实战指南构建高可用生产级Kafka集群的完整教程"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146067789
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146067789
cover: https://bing.ee123.net/img/rand?artid=146067789
image: https://bing.ee123.net/img/rand?artid=146067789
img: https://bing.ee123.net/img/rand?artid=146067789
---

# 实战指南：构建高可用生产级Kafka集群的完整教程

![](https://i-blog.csdnimg.cn/img_convert/d5c972ce42e8b2c88ad860580cb3ef89.gif#pic_center)
> 前文教程：
> [Apache Kafka单节点极速部署指南：10分钟搭建开发单节点环境-CSDN博客](https://blog.csdn.net/qq_43479188/article/details/146017446?spm=1001.2014.3001.5502)

#### **一、多节点 Kafka 集群部署**

##### 1. 环境准备

> 此处需注意，如已经安装测试过
> `Kafka`
> 单节点，请在安装集群之前清空之前配置的目录
>
> ```
> sudo rm -r /var/lib/zookeeper
> sudo rm -r /var/lib/kafka-logs
> sudo mkdir -p /var/lib/{zookeeper,kafka-logs}
> sudo chown -R kafka:kafka /var/lib/{zookeeper,kafka-logs} /opt/kafka
>
> ```

* **3台服务器**
  ：假设 IP 为
  `192.168.1.101`
  ,
  `192.168.1.102`
  ,
  `192.168.1.103`
* **统一安装 Kafka**
  ：在每台服务器重复 之前的安装步骤，但是暂时不启动各个服务，确保路径一致（如
  `/opt/kafka`
  ）
* **同步配置**
  ：确保所有节点配置文件的
  `zookeeper.connect`
  指向相同的
  `ZooKeeper`
  集群

##### 2. ZooKeeper 集群配置

1. **每台
   `ZooKeeper`
   节点配置**

   `config/zookeeper.properties`

   ```properties
   # 基础时间单位（毫秒），默认 2000
   tickTime=2000

   # Leader 等待 Follower 初始连接的最长时间（tickTime 的倍数）
   initLimit=5

   # Leader 与 Follower 心跳同步的最大延迟时间（tickTime 的倍数）
   syncLimit=2

   # 其他原有配置保持不变
   dataDir=/var/lib/zookeeper
   clientPort=2181
   maxClientCnxns=0
   admin.enableServer=false
   # 集群节点列表（所有 ZooKeeper 节点需一致）
   server.1=192.168.1.101:2888:3888
   server.2=192.168.1.102:2888:3888
   server.3=192.168.1.103:2888:3888

   ```
2. **创建
   `myid`
   文件**
   （每个节点唯一）：

   ```bash
   # 在 192.168.1.101 上执行
   echo "1" > /var/lib/zookeeper/myid

   # 在 192.168.1.102 上执行
   echo "2" > /var/lib/zookeeper/myid

   # 在 192.168.1.103 上执行
   echo "3" > /var/lib/zookeeper/myid

   ```

   此处要确认
   `myid`
   ，对于用户
   `kafka`
   有权限。

   ![image-20250304181404183](https://i-blog.csdnimg.cn/img_convert/0babe8b5344048fd6efb53d8a9618bf0.png)
3. **启动
   `ZooKeeper`
   集群**
   ：

   ```bash
   # 所有节点执行
   sudo systemctl start zookeeper
   # 检查集群状态（任一节点执行）
   echo srvr | nc <服务器IP> 2181 | grep Mode
   # 应输出 "leader" 或 "follower"

   ```

   ![img_v3_02k3_727f6e38-598c-47c5-b5da-2f7c2c938a3g](https://i-blog.csdnimg.cn/img_convert/42907ab1495a01a3706825d83fd79098.jpeg)

   ![img_v3_02k3_8f01b6f5-202c-47a0-b59e-61de268511fg](https://i-blog.csdnimg.cn/img_convert/fe569e42dbdbd0245b912c373c50c357.jpeg)
4. **测试集群是否创建成功**

   ```bash
   #模拟选举事件
   # 停止当前 Leader
   sudo systemctl stop zookeeper

   # 查看其他节点日志
   echo srvr | nc <服务器IP> 2181 | grep Mode

   ```

   ![img_v3_02k3_d0453183-b72c-486f-a394-6bace7d388fg](https://i-blog.csdnimg.cn/img_convert/4faa656d5285cfdc998189afef812307.jpeg)

   可以看到
   `Leader`
   已经从133转到了134节点。

   ```bash
   #数据同步验证
   #在Leader节点创建临时节点并写入数据data
   /opt/kafka/bin/zookeeper-shell.sh 192.168.6.134:2181 <<< "create -e /test-node 'data'"
   ## 在 Follower 节点检查数据
   /opt/kafka/bin/zookeeper-shell.sh 192.168.6.133:2181 <<< "get /test-node"

   ```

   ![img_v3_02k3_05158fc0-be96-412e-b1c5-7719a89560cg](https://i-blog.csdnimg.cn/img_convert/21efa5cc863147bd9b49ddb4eba53654.jpeg)

   ![img_v3_02k3_a4435d6f-8aae-43fe-8d44-a915b092026g](https://i-blog.csdnimg.cn/img_convert/08398ee4fe8d16ee6508e43ad8dd8e48.jpeg)

##### 3. Kafka 集群配置

1. **修改每台
   `Kafka`
   节点的
   `server.properties`**
   ：
     
   此处的其他配置于上一个教程一样即可。

   ```properties
   # 节点1 (192.168.1.101)
   broker.id=1
   listeners=PLAINTEXT://192.168.1.101:9092
   advertised.listeners=PLAINTEXT://192.168.1.101:9092
   zookeeper.connect=192.168.1.101:2181,192.168.1.102:2181,192.168.1.103:2181

   # 节点2 (192.168.1.102)
   broker.id=2
   listeners=PLAINTEXT://192.168.1.102:9092
   advertised.listeners=PLAINTEXT://192.168.1.102:9092
   zookeeper.connect=同上

   # 节点3 (192.168.1.103)
   broker.id=3
   listeners=PLAINTEXT://192.168.1.103:9092
   advertised.listeners=PLAINTEXT://192.168.1.103:9092
   zookeeper.connect=同上

   ```

   **关键参数解释**
   ：

   * `advertised.listeners`
     ：客户端实际连接的地址（如果跨网络需配置公网IP或域名）
   * `zookeeper.connect`
     ：所有
     `ZooKeeper`
     节点地址，用逗号分隔
2. **启动
   `Kafka`
   集群**
   ：

   ```bash
   # 所有节点执行
   sudo systemctl start kafka

   # 检查 Broker 是否注册到 ZooKeeper
   /opt/kafka/bin/zookeeper-shell.sh <服务器IP>:2181 ls /brokers/ids
   # 应输出 [1,2,3]

   ```

   ![image-20250305111129936](https://i-blog.csdnimg.cn/img_convert/02e66f297d0bb3d8cd9dab19f98f5a4d.png)
3. **创建 Topic（验证集群）**
   ：

   ```bash
   # 在任意节点执行
   /opt/kafka/bin/kafka-topics.sh --create \
     --topic cluster-test \
     --bootstrap-server 192.168.1.101:9092 \
     --partitions 3 \
     --replication-factor 3  # 副本数≤Broker数量

   # 查看 Topic 详情
   /opt/kafka/bin/kafka-topics.sh --describe \
     --topic cluster-test \
     --bootstrap-server 192.168.1.101:9092

   ```

   **期望输出**
   ：每个分区的
   `Leader`
   和
   `Replicas`
   分布在多个 Broker 上。

---

#### **二、性能调优**

##### 1. JVM 参数优化

编辑 Kafka 启动脚本
`bin/kafka-server-start.sh`
：

```bash
# 修改这一行
export KAFKA_HEAP_OPTS="-Xms3G -Xmx3G -XX:MetaspaceSize=96m -XX:+UseG1GC"

```

* `Xms/Xmx`
  ：堆内存（建议不超过物理内存的 50%）
* `UseG1GC`
  ：G1 垃圾回收器（适合大内存）

##### 2. Kafka 参数优化

```properties
# server.properties
num.network.threads=8  # 网络线程数（默认3）
num.io.threads=16      # IO 线程数（默认8）
log.flush.interval.messages=10000  # 累积多少消息后刷盘
log.flush.interval.ms=1000         # 最多等待多久刷盘

```

---

#### **三、集群监控与管理**

##### 1. 使用 EFAK（kafka eagle）（可视化工具）

1. **安装**
   ：

   访问官网下载安装包：
   [EFAK](https://www.kafka-eagle.org/)

   ![image-20250306104505835](https://i-blog.csdnimg.cn/img_convert/c517ac734b0dd70e8b4152a5104bb7bc.png)

   下载后上传至服务器解压

   ```bash
   tar -zvxf kafka-eagle-bin-3.0.1.tar.gz
   cd kafka-eagle-bin-3.0.1/
   tar -zxvf efak-web-3.0.1-bin.tar.gz
   mv efak-web-3.0.1 /opt/efak

   ```
2. **配置
   `Mysql`
   用来储存元数据**
   ：

   ```sql
   CREATE DATABASE ke_paco DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
   CREATE USER 'ke_paco'@'%' IDENTIFIED BY 'paco123';
   GRANT ALL PRIVILEGES ON ke_paco.* TO 'ke_paco'@'%';
   FLUSH PRIVILEGES; -- 刷新权限生效

   ```
3. **设置环境变量**
   ：

   ```bash
   vim /etc/profile

   ```

   写入如下内容，配置
   `jdk`
   和
   `EFAK`
   的环境变量：

   ```bash
   export KE_HOME=/opt/efak
   export PATH=$PATH:$KE_HOME/bin

   export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
   export PATH=$JAVA_HOME/bin:$PATH

   ```
4. **修改配置文件**

   ```bash
   cd /opt/efak/conf
   vim system-config.properties

   ```

   配置
   `zookeeper`
   地址：

   ```properties
   efak.zk.cluster.alias=cluster1
   cluster1.zk.list=192.168.6.131:2181,192.168.6.133:2181,192.168.6.134:2181

   ```

   此处建议复制kafka配置文件的zookeeper配置。

   配置
   `Mysql`
   :

   ```properties
   efak.driver=com.mysql.cj.jdbc.Driver
   efak.url=jdbc:mysql://<mysql ip>:3306/ke_paco?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull
   efak.username=ke_paco
   efak.password=paco123

   ```
5. **开启JMX监控**
     
   修改
   `Kafka`
   启动配置，参考如下，按自己需要修改：

   ```bash
   vi /opt/kafka/bin/kafka-server-start.sh

   ```

   ```properties
       export KAFKA_HEAP_OPTS="-server -Xms2G -Xmx2G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70 -Djava.rmi.server.hostname=<改为当前节点IP> -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
       export JMX_PORT="9999"

   ```

   ![image-20250306111826958](https://i-blog.csdnimg.cn/img_convert/ccd371e880afffff9c168dd5f2a424b8.png)
6. **启动EFAK**
     
   如若Kakfa未作任何其他配置，则可直接启动

   ```
   $KE_HOME/bin/ke.sh start

   ```

   启动成功后如图：

   ![image-20250306114521739](https://i-blog.csdnimg.cn/img_convert/8a6d93b3b51d307f31f958e6de152686.png)

   访问UI界面：

   ![img_v3_02k4_c4694e2d-5c4d-47b4-b37f-8fc8ec75303g](https://i-blog.csdnimg.cn/img_convert/fca2ad17511845eb20c3860a9dacd300.jpeg)

   ![img_v3_02k4_fcd27012-fa82-4d39-9f37-dab21e3c00cg](https://i-blog.csdnimg.cn/img_convert/bed0daf9a52c3396223ccf4e9b7237a3.jpeg)

   ![image-20250306114509512](https://i-blog.csdnimg.cn/img_convert/fe812ecec8b4539e65437fbd0c1d691a.png)

---

#### **四、灾难恢复验证**

1. **创建 Topic**
     
   在 Kafka 集群中创建一个测试 Topic，用于后续的测试。

   ```bash
   # 创建 Topic，指定分区数和副本因子
   /opt/kafka/bin/kafka-topics.sh --create \
     --topic cluster-test \
     --bootstrap-server 192.168.6.131:9092 \
     --partitions 3 \
     --replication-factor 2

   # 查看 Topic 详情，确认创建成功
   /opt/kafka/bin/kafka-topics.sh --describe \
     --topic cluster-test \
     --bootstrap-server 192.168.6.131:9092

   ```

   **输出示例**
   ：
     
   ![835bfce2-a162-4cb5-8f8b-59c4e5625983](https://i-blog.csdnimg.cn/img_convert/0672288a61343df474b070b9c2029a23.jpeg)
2. **写入消息**
     
   向 Topic 中写入测试消息，用于验证数据持久化和消费。
     
   **操作步骤**
   ：

   ```bash
   # 使用 kafka-console-producer 写入消息
   echo "test message 1" | /opt/kafka/bin/kafka-console-producer.sh \
     --topic cluster-test \
     --bootstrap-server 192.168.6.131:9092

   # 写入多条消息
   for i in {1..10}; do
     echo "test message $i" | /opt/kafka/bin/kafka-console-producer.sh \
       --topic cluster-test \
       --bootstrap-server 192.168.6.131:9092
   done

   ```

   ![f8392450-0e53-4e78-91c8-612661727aa6](https://i-blog.csdnimg.cn/img_convert/eb34733f7d65aa6e325f82f3a716dd6d.jpeg)
3. **消费消息**
     
   启动一个消费者（任意其他节点），验证消息是否成功写入。
     
   **操作步骤**
   ：

   ```bash
   # 使用 kafka-console-consumer 消费消息
   /opt/kafka/bin/kafka-console-consumer.sh \
     --topic cluster-test \
     --bootstrap-server 192.168.6.131:9092 \
     --from-beginning

   ```

   ![25e404b8-8ba7-4528-9b4a-62509d490bbc](https://i-blog.csdnimg.cn/img_convert/b7b452e05d7dde7ba0a50fac9fa9aa59.jpeg)
4. **模拟 Broker 宕机**

   停止一个 Broker，观察分区 Leader 是否切换。

   **操作步骤**
   ：

   ```bash
   # 停止 Broker 2
   sudo systemctl stop kafka  # 假设 Broker 2 的 ID 是 2

   # 查看 Topic 分区状态，确认 Leader 切换
   /opt/kafka/bin/kafka-topics.sh --describe \
     --topic cluster-test \
     --bootstrap-server 192.168.6.131:9092

   ```

   ![faa4ff58-a327-494e-a480-d3d38a1b5028](https://i-blog.csdnimg.cn/img_convert/b357cad48c7dbf98ce1bcffb56cae0fb.jpeg)
   **说明**
   ：

   * 停止 Broker 2 后，分区 0 的 Leader 仍然是 Broker 1，分区 1 的 Leader 从 Broker 2 切换到了 Broker 3。
5. **验证数据持久化**

   重启所有 Broker，验证消息是否仍然可以消费。

   **操作步骤**
   ：

   ```bash
   # 重启所有 Broker
   sudo systemctl restart kafka

   # 等待 Broker 重新启动（约 30 秒）
   sleep 30

   # 再次消费消息，验证数据是否保留
   /opt/kafka/bin/kafka-console-consumer.sh \
     --topic cluster-test \
     --bootstrap-server 192.168.6.131:9092 \
     --from-beginning

   ```

   **输出示例**
   ：

   ![f803bb1a-e543-463c-8871-cc5763de16d7](https://i-blog.csdnimg.cn/img_convert/0ee2451637c38b01c7e9f497fae57923.jpeg)
6. **验证分区恢复**

   确认停止的 Broker 重新加入集群后，分区状态恢复正常。

   **操作步骤**
   ：

   ```bash
   # 查看 Topic 分区状态
   /opt/kafka/bin/kafka-topics.sh --describe \
     --topic cluster-test \
     --bootstrap-server 192.168.6.131:9092

   ```

   ![image-20250306131951590](https://i-blog.csdnimg.cn/img_convert/0706fe4bcb53389f4d4f5f124d64d66d.png)

---

#### **五、关键注意事项**

1. **网络防火墙**
   ：

   * 开放
     `ZooKeeper`
     端口：
     `2181`
     （客户端）,
     `2888`
     （节点间通信）,
     `3888`
     （选举）
   * 开放
     `Kafka`
     端口：
     `9092`
     （明文）,
     `999`
     9（JMX）
2. **时间同步**
   ：

   ```bash
   # 所有节点安装 NTP
   sudo yum install ntp -y && sudo systemctl enable --now ntpd

   ```
3. **定期清理日志**
   ：

   ```bash
   # 手动触发日志删除
   /opt/kafka/bin/kafka-log-dirs.sh \
     --bootstrap-server 192.168.1.101:9092 \
     --describe --topic-list cluster-test

   ```

---

通过以上步骤，您将获得一个高可用、安全的 Kafka 生产级集群，并具备基础的监控和容灾能力。