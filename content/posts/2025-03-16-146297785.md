---
layout: post
title: "PyTorch使用-张量类型转换"
date: 2025-03-16 18:01:44 +0800
description: "共享内存：默认情况下，CPU 张量与 NumPy 数组共享内存，修改会同步。独立副本：使用 .copy() 或 clone() + .numpy() 创建独立数据。设备与梯度：处理 GPU 张量或带梯度张量时，需先移至 CPU 并分离梯度。优先使用 .item()：安全且明确，专为标量设计。避免强制类型转换：可能隐藏维度不匹配或设备不一致的问题。处理复杂情况：通过 .squeeze()、.cpu()、.detach() 确保张量符合要求。"
keywords: "PyTorch使用-张量类型转换"
categories: ['深度学习']
tags: ['人工智能', 'Pytorch', 'Python']
artid: "146297785"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146297785
    alt: "PyTorch使用-张量类型转换"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146297785
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146297785
cover: https://bing.ee123.net/img/rand?artid=146297785
image: https://bing.ee123.net/img/rand?artid=146297785
img: https://bing.ee123.net/img/rand?artid=146297785
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     PyTorch使用-张量类型转换
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
    </p>
    <p>
    </p>
    <h2>
     <a id="_1">
     </a>
     张量类型转换
    </h2>
    <blockquote>
     <p>
      张量的类型转换也是经常使用的一种操作，是必须掌握的知识点。
     </p>
    </blockquote>
    <h2>
     <a id="1__numpy__3">
     </a>
     1. 张量转换为 numpy 数组
    </h2>
    <blockquote>
     <p>
      在 PyTorch 中，张量（Tensor）与 NumPy 数组（ndarray）之间的转换是常见操作，但需要注意 内存共享机制。
     </p>
    </blockquote>
    <h3>
     <a id="11__5">
     </a>
     1.1. 默认行为：共享内存
    </h3>
    <blockquote>
     <p>
      当张量位于 CPU 上时，直接使用 .numpy() 会生成共享底层内存的 NumPy 数组。修改其中一个对象会影响另一个：
     </p>
    </blockquote>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># 创建 CPU 张量</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 默认在 CPU 上</span>
numpy_array <span class="token operator">=</span> tensor<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># 共享内存</span>

<span class="token comment"># 修改 NumPy 数组</span>
numpy_array<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">100</span>

<span class="token comment"># 张量也会被修改！</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>  <span class="token comment"># 输出: tensor([100,   2,   3])</span>
</code></pre>
    <h3>
     <a id="12__23">
     </a>
     1.2. 避免内存共享
    </h3>
    <blockquote>
     <p>
      若需独立的数据副本，使用 .copy() 方法或 torch.clone()：
     </p>
    </blockquote>
    <h4>
     <a id="121__copy_26">
     </a>
     1.2.1. 使用 .copy()
    </h4>
    <pre><code class="prism language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
numpy_array <span class="token operator">=</span> tensor<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 创建独立副本</span>

numpy_array<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">100</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>  <span class="token comment"># 输出: tensor([1, 2, 3])（原数据不变）</span>
</code></pre>
    <h4>
     <a id="122__torchclone__numpy_36">
     </a>
     1.2.2. 使用 torch.clone() + .numpy()
    </h4>
    <pre><code class="prism language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
cloned_tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># 创建张量副本</span>
numpy_array <span class="token operator">=</span> cloned_tensor<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 仍共享 cloned_tensor 的内存</span>

numpy_array<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">100</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>cloned_tensor<span class="token punctuation">)</span>  <span class="token comment"># 输出: tensor([100, 2, 3])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>         <span class="token comment"># 输出: tensor([1, 2, 3])</span>
</code></pre>
    <h3>
     <a id="13__GPU__48">
     </a>
     1.3. 处理 GPU 张量
    </h3>
    <blockquote>
     <p>
      若张量在 GPU 上，需先移动到 CPU 再转换：
     </p>
    </blockquote>
    <pre><code class="prism language-python"><span class="token comment"># 创建 GPU 张量</span>
tensor_gpu <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>

<span class="token comment"># 错误操作：直接转换会报错</span>
<span class="token keyword">try</span><span class="token punctuation">:</span>
    numpy_array <span class="token operator">=</span> tensor_gpu<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">except</span> RuntimeError <span class="token keyword">as</span> e<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"错误："</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span>  <span class="token comment"># 需先将张量移至 CPU</span>

<span class="token comment"># 正确操作：移动到 CPU 再转换</span>
tensor_cpu <span class="token operator">=</span> tensor_gpu<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
numpy_array <span class="token operator">=</span> tensor_cpu<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 共享内存</span>
</code></pre>
    <h3>
     <a id="14__66">
     </a>
     1.4. 分离梯度跟踪
    </h3>
    <p>
     若张量带有梯度（requires_grad=True），需先分离计算图：
    </p>
    <pre><code class="prism language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 错误操作：直接转换会警告</span>
<span class="token keyword">try</span><span class="token punctuation">:</span>
    numpy_array <span class="token operator">=</span> tensor<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">except</span> RuntimeError <span class="token keyword">as</span> e<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"错误："</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span>

<span class="token comment"># 正确操作：先分离梯度</span>
detached_tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 返回一个无梯度的新张量</span>
numpy_array <span class="token operator">=</span> detached_tensor<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="15__83">
     </a>
     1.5. 代码示例
    </h3>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># 示例1：共享内存（CPU 张量）</span>
tensor_cpu <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
numpy_shared <span class="token operator">=</span> tensor_cpu<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
numpy_shared<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">100</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"共享内存 - 原张量:"</span><span class="token punctuation">,</span> tensor_cpu<span class="token punctuation">)</span>  <span class="token comment"># tensor([100., 2., 3.])</span>

<span class="token comment"># 示例2：独立副本（使用 copy）</span>
numpy_copy <span class="token operator">=</span> tensor_cpu<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
numpy_copy<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">200</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"独立副本 - 原张量:"</span><span class="token punctuation">,</span> tensor_cpu<span class="token punctuation">)</span>  <span class="token comment"># tensor([100., 2., 3.])</span>

<span class="token comment"># 示例3：GPU 张量处理</span>
tensor_gpu <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>
tensor_cpu <span class="token operator">=</span> tensor_gpu<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
numpy_gpu <span class="token operator">=</span> tensor_cpu<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"GPU 转 CPU 后数组:"</span><span class="token punctuation">,</span> numpy_gpu<span class="token punctuation">)</span>  <span class="token comment"># [4 5 6]</span>

<span class="token comment"># 示例4：带梯度的张量</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> x <span class="token operator">*</span> <span class="token number">2</span>
detached_x <span class="token operator">=</span> x<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
numpy_detached <span class="token operator">=</span> detached_x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
numpy_detached<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">5.0</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"分离梯度后张量:"</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>  <span class="token comment"># tensor([3.], requires_grad=True)</span>
</code></pre>
    <h3>
     <a id="16__115">
     </a>
     1.6. 关键注意事项
    </h3>
    <table>
     <thead>
      <tr>
       <th>
        场景
       </th>
       <th>
        处理方式
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        避免内存共享
       </td>
       <td>
        使用 .copy() 或先 .clone() 再转换
       </td>
      </tr>
      <tr>
       <td>
        GPU 张量
       </td>
       <td>
        先 .cpu() 移动至 CPU，再转换
       </td>
      </tr>
      <tr>
       <td>
        梯度跟踪张量
       </td>
       <td>
        先 .detach() 分离计算图
       </td>
      </tr>
      <tr>
       <td>
        数据类型一致性
       </td>
       <td>
        确保张量与 NumPy 数组数据类型兼容（如 float32 对应 np.float32）
       </td>
      </tr>
     </tbody>
    </table>
    <h3>
     <a id="17__123">
     </a>
     1.7. 总结
    </h3>
    <p>
     <strong>
      共享内存
     </strong>
     ：默认情况下，CPU 张量与 NumPy 数组共享内存，修改会同步。
     <br/>
     <strong>
      独立副本
     </strong>
     ：使用 .copy() 或 clone() + .numpy() 创建独立数据。
     <br/>
     <strong>
      设备与梯度
     </strong>
     ：处理 GPU 张量或带梯度张量时，需先移至 CPU 并分离梯度。
    </p>
    <h2>
     <a id="2__128">
     </a>
     2. 标量张量和数字的转换
    </h2>
    <h3>
     <a id="21_torchfrom_numpy_129">
     </a>
     2.1. torch.from_numpy()：共享内存
    </h3>
    <p>
     <strong>
      特点：
     </strong>
     <br/>
     <strong>
      默认共享内存
     </strong>
     ：生成的张量与原始 NumPy 数组共享底层内存，修改其中一个会影响另一个。
     <br/>
     <strong>
      高效但风险
     </strong>
     ：适合处理大型数据时节省内存，但需谨慎操作避免意外修改。
    </p>
    <p>
     示例：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch

<span class="token comment"># 创建 NumPy 数组</span>
numpy_array <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

<span class="token comment"># 转换为张量（共享内存）</span>
tensor_shared <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>numpy_array<span class="token punctuation">)</span>

<span class="token comment"># 修改 NumPy 数组会影响张量</span>
numpy_array<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">100</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"共享内存张量:"</span><span class="token punctuation">,</span> tensor_shared<span class="token punctuation">)</span>  <span class="token comment"># 输出: tensor([100., 2., 3.])</span>

<span class="token comment"># 修改张量也会影响 NumPy 数组</span>
tensor_shared<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">200</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"原始 NumPy 数组:"</span><span class="token punctuation">,</span> numpy_array<span class="token punctuation">)</span>  <span class="token comment"># 输出: [100. 200.   3.]</span>
</code></pre>
    <p>
     避免共享内存：
     <br/>
     若需独立副本，显式复制数据：
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 方法1：通过 NumPy 的 copy()</span>
numpy_copy <span class="token operator">=</span> numpy_array<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
tensor_independent <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>numpy_copy<span class="token punctuation">)</span>

<span class="token comment"># 方法2：通过张量的 clone()</span>
tensor_clone <span class="token operator">=</span> tensor_shared<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="22_torchtensor_166">
     </a>
     2.2. torch.tensor()：独立内存
    </h3>
    <p>
     特点：
     <br/>
     默认独立内存：生成的新张量会复制数据，与原始 NumPy 数组无内存共享。
    </p>
    <p>
     安全但略低效：适合需要数据隔离的场景（如训练时预处理）。
    </p>
    <p>
     示例：
    </p>
    <pre><code class="prism language-python">numpy_array <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

<span class="token comment"># 转换为张量（独立内存）</span>
tensor_new <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>numpy_array<span class="token punctuation">)</span>

<span class="token comment"># 修改 NumPy 数组不影响张量</span>
numpy_array<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">100</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"独立内存张量:"</span><span class="token punctuation">,</span> tensor_new<span class="token punctuation">)</span>  <span class="token comment"># 输出: tensor([1., 2., 3.])</span>

<span class="token comment"># 修改张量也不影响原数组</span>
tensor_new<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">200</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"原始 NumPy 数组:"</span><span class="token punctuation">,</span> numpy_array<span class="token punctuation">)</span>  <span class="token comment"># 输出: [100. 2. 3.]</span>
</code></pre>
    <h3>
     <a id="23__189">
     </a>
     2.3. 关键对比
    </h3>
    <table>
     <thead>
      <tr>
       <th>
        方法
       </th>
       <th>
        内存共享
       </th>
       <th>
        性能
       </th>
       <th>
        适用场景
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        torch.from_numpy()
       </td>
       <td>
        是
       </td>
       <td>
        高
       </td>
       <td>
        大数据处理，需减少内存复制时使用
       </td>
      </tr>
      <tr>
       <td>
        torch.tensor()
       </td>
       <td>
        否
       </td>
       <td>
        中
       </td>
       <td>
        需要数据隔离的场景（如训练数据）
       </td>
      </tr>
     </tbody>
    </table>
    <h3>
     <a id="24__194">
     </a>
     2.4. 注意事项
    </h3>
    <h4>
     <a id="241__195">
     </a>
     2.4.1. 数据类型一致性
    </h4>
    <p>
     torch.from_numpy() 会保留 NumPy 数组的数据类型。
     <br/>
     torch.tensor() 可手动指定 dtype：
    </p>
    <pre><code class="prism language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>numpy_array<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float64<span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="242_GPU__203">
     </a>
     2.4.2. GPU 张量转换
    </h4>
    <p>
     若需直接在 GPU 上创建张量，需显式指定设备：
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 共享内存 + GPU（需先复制到 CPU）</span>
numpy_array <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor_gpu <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>numpy_array<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 复制到 GPU，不共享内存</span>

<span class="token comment"># 独立内存 + GPU</span>
tensor_gpu <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>numpy_array<span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="243__216">
     </a>
     2.4.3. 梯度跟踪
    </h4>
    <p>
     若需张量参与梯度计算，推荐使用 torch.tensor()：
    </p>
    <pre><code class="prism language-python">x_np <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
x_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>x_np<span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 可跟踪梯度</span>
y <span class="token operator">=</span> x_tensor<span class="token operator">**</span><span class="token number">2</span>
y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_tensor<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>  <span class="token comment"># 输出: tensor([6.])</span>
</code></pre>
    <h3>
     <a id="25__227">
     </a>
     2.5. 完整代码示例
    </h3>
    <pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch

<span class="token comment"># 示例1：共享内存转换</span>
numpy_shared <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
tensor_shared <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>numpy_shared<span class="token punctuation">)</span>
numpy_shared<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">100</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"共享内存张量:"</span><span class="token punctuation">,</span> tensor_shared<span class="token punctuation">)</span>  <span class="token comment"># tensor([100, 2, 3], dtype=torch.int32)</span>

<span class="token comment"># 示例2：独立内存转换</span>
numpy_independent <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float64<span class="token punctuation">)</span>
tensor_independent <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>numpy_independent<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
numpy_independent<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">400</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"独立内存张量:"</span><span class="token punctuation">,</span> tensor_independent<span class="token punctuation">)</span>  <span class="token comment"># tensor([4., 5., 6.])</span>

<span class="token comment"># 示例3：避免共享内存的显式复制</span>
numpy_original <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor_copy <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>numpy_original<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 独立副本</span>
numpy_original<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">700</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"显式复制后的张量:"</span><span class="token punctuation">,</span> tensor_copy<span class="token punctuation">)</span>  <span class="token comment"># tensor([7, 8, 9])</span>
</code></pre>
    <h3>
     <a id="26__252">
     </a>
     2.6. 最佳实践
    </h3>
    <p>
     <strong>
      优先选择 torch.tensor()：
     </strong>
     默认数据隔离更安全，避免意外修改。
    </p>
    <p>
     <strong>
      谨慎使用 torch.from_numpy()：
     </strong>
     仅在明确需要共享内存且能控制同步时使用。
    </p>
    <p>
     <strong>
      显式复制数据：
     </strong>
     使用 .copy() 或 .clone() 确保数据独立。
    </p>
    <p>
     <strong>
      统一数据类型和设备：
     </strong>
     避免因类型或设备不匹配导致的错误。
    </p>
    <h2>
     <a id="3__261">
     </a>
     3. 标量张量和数字的转换
    </h2>
    <blockquote>
     <p>
      在 PyTorch 中，处理标量张量（即只含有一个元素的张量）与 Python 数字之间的转换是常见操作，尤其是在训练过程中提取损失值、指标值等场景。以下是详细的方法说明及注意事项：
     </p>
    </blockquote>
    <h3>
     <a id="31_item__264">
     </a>
     3.1. 提取标量张量的值：item() 方法
    </h3>
    <p>
     <strong>
      功能：
     </strong>
     将标量张量（元素数量为 1）转换为 Python 数字（int 或 float）。
    </p>
    <p>
     <strong>
      要求：
     </strong>
     张量必须为标量（即 tensor.numel() == 1）。
    </p>
    <p>
     示例：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch

<span class="token comment"># 标量张量（单个元素）</span>
scalar_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">3.1415</span><span class="token punctuation">)</span>
value <span class="token operator">=</span> scalar_tensor<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span>          <span class="token comment"># 输出: 3.1415</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 输出: &lt;class 'float'&gt;</span>

<span class="token comment"># 非标量张量会报错</span>
vector_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">try</span><span class="token punctuation">:</span>
    vector_tensor<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 报错：ValueError</span>
<span class="token keyword">except</span> ValueError <span class="token keyword">as</span> e<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"错误："</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span>  <span class="token comment"># 输出: only one element tensors can be converted to Python scalars</span>
</code></pre>
    <h3>
     <a id="32__288">
     </a>
     3.2. 强制类型转换（不推荐）
    </h3>
    <p>
     对于单元素张量，可通过强制类型转换（如 float()、int()）直接提取值，但需注意：
    </p>
    <p>
     要求：张量必须在 CPU 上且无梯度跟踪。
    </p>
    <p>
     风险：若张量包含多个元素，会触发隐式的维度压缩（可能引发意外错误）。
    </p>
    <p>
     示例：
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 标量张量</span>
scalar_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">5.0</span><span class="token punctuation">)</span>
value <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>scalar_tensor<span class="token punctuation">)</span>  <span class="token comment"># 5.0</span>

<span class="token comment"># 单元素张量（非标量）</span>
single_element_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
value <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>single_element_tensor<span class="token punctuation">)</span>  <span class="token comment"># 5.0（自动压缩维度）</span>

<span class="token comment"># 多元素张量会报错</span>
vector_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">try</span><span class="token punctuation">:</span>
    <span class="token builtin">float</span><span class="token punctuation">(</span>vector_tensor<span class="token punctuation">)</span>  <span class="token comment"># 报错：ValueError</span>
<span class="token keyword">except</span> ValueError <span class="token keyword">as</span> e<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"错误："</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="33__314">
     </a>
     3.3. 安全操作流程
    </h3>
    <h4>
     <a id="331__315">
     </a>
     3.3.1. 确保张量为标量
    </h4>
    <p>
     使用 .squeeze() 或 .flatten() 去除冗余维度：
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 冗余维度张量（如形状为 (1, 1)）</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3.14</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
scalar_tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 形状变为空张量 []</span>
value <span class="token operator">=</span> scalar_tensor<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># 3.14</span>
</code></pre>
    <h4>
     <a id="332__325">
     </a>
     3.3.2. 处理设备与梯度
    </h4>
    <p>
     若张量在 GPU 或带有梯度，需先移至 CPU 并分离计算图：
    </p>
    <pre><code class="prism language-python"><span class="token comment"># GPU 上的标量张量</span>
tensor_gpu <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>
value <span class="token operator">=</span> tensor_gpu<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 移动到 CPU 后提取</span>

<span class="token comment"># 带梯度的标量张量</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">3.0</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> x<span class="token operator">**</span><span class="token number">2</span>
y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
value <span class="token operator">=</span> x<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 分离梯度后提取</span>
</code></pre>
    <h3>
     <a id="34__340">
     </a>
     3.4. 代码示例
    </h3>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch

<span class="token comment"># 示例1：标准提取</span>
scalar <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"标量值:"</span><span class="token punctuation">,</span> scalar<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 42</span>

<span class="token comment"># 示例2：处理冗余维度</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
squeezed_tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"压缩后形状:"</span><span class="token punctuation">,</span> squeezed_tensor<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># torch.Size([])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"提取值:"</span><span class="token punctuation">,</span> squeezed_tensor<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 5.0</span>

<span class="token comment"># 示例3：GPU 张量处理</span>
<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tensor_gpu <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">6.28</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>
    tensor_cpu <span class="token operator">=</span> tensor_gpu<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"GPU 张量值:"</span><span class="token punctuation">,</span> tensor_cpu<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 6.28</span>

<span class="token comment"># 示例4：错误处理（非标量）</span>
vector <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">try</span><span class="token punctuation">:</span>
    vector<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">except</span> ValueError <span class="token keyword">as</span> e<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"错误信息:"</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span>  <span class="token comment"># only one element tensors can be converted to Python scalars</span>
</code></pre>
    <h3>
     <a id="35__369">
     </a>
     3.5. 关键注意事项
    </h3>
    <table>
     <thead>
      <tr>
       <th>
        场景
       </th>
       <th>
        处理方式
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        标量张量
       </td>
       <td>
        直接使用 .item()
       </td>
      </tr>
      <tr>
       <td>
        单元素但非标量
       </td>
       <td>
        先用 .squeeze() 压缩维度，再用 .item()
       </td>
      </tr>
      <tr>
       <td>
        GPU 上的张量
       </td>
       <td>
        先 .cpu() 移动到 CPU，再 .item()
       </td>
      </tr>
      <tr>
       <td>
        带梯度的张量
       </td>
       <td>
        先 .detach() 分离计算图，再 .item()
       </td>
      </tr>
      <tr>
       <td>
        强制类型转换
       </td>
       <td>
        仅限单元素张量，需谨慎使用（推荐优先使用 .item()）
       </td>
      </tr>
     </tbody>
    </table>
    <h3>
     <a id="36__377">
     </a>
     3.6. 总结
    </h3>
    <p>
     优先使用 .item()：安全且明确，专为标量设计。
    </p>
    <p>
     避免强制类型转换：可能隐藏维度不匹配或设备不一致的问题。
    </p>
    <p>
     处理复杂情况：通过 .squeeze()、.cpu()、.detach() 确保张量符合要求。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6a69616f6d6f6e676a756e2f:61727469636c652f64657461696c732f313436323937373835" class_="artid" style="display:none">
 </p>
</div>


