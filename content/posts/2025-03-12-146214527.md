---
layout: post
title: "-支持向量机SVM原理与应用"
date: 2025-03-12 21:01:57 +0800
description: "支持向量机是一种二分类模型，其基本思想是找到一个超平面，将不同类别的样本分开，并且使得两类样本到超平面的间隔最大化。SVM不仅可以处理线性可分问题，还可以通过核函数处理非线性问题。鸢尾花数据集（Iris Dataset）是机器学习领域中最经典的数据集之一。它包含150个样本，每个样本有4个特征：花萼长度、花萼宽度、花瓣长度和花瓣宽度。数据集分为3类，每类50个样本。本文中，我们只使用前两类数据进行二分类任务。---优点- 在高维空间中表现优异。- 适用于小样本数据集。"
keywords: " 支持向量机（SVM）原理与应用"
categories: ['未分类']
tags: ['算法', '机器学习', '支持向量机']
artid: "146214527"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146214527
    alt: "-支持向量机SVM原理与应用"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146214527
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146214527
cover: https://bing.ee123.net/img/rand?artid=146214527
image: https://bing.ee123.net/img/rand?artid=146214527
img: https://bing.ee123.net/img/rand?artid=146214527
---

#  支持向量机（SVM）原理与应用

### 背景

支持向量机（Support Vector Machine,
SVM）是一种经典的监督学习算法，广泛应用于分类和回归问题。SVM以其强大的数学基础和优异的性能在机器学习领域占据了重要地位。本文将详细介绍SVM的原理、核函数的作用以及如何在Python中使用SVM解决实际问题。

#### 1\. 什么是支持向量机？

支持向量机是一种二分类模型，其基本思想是找到一个超平面，将不同类别的样本分开，并且使得两类样本到超平面的间隔最大化。SVM不仅可以处理线性可分问题，还可以通过核函数处理非线性问题。

##### 1.1 超平面与间隔

在SVM中，超平面是一个决策边界，用于将数据分为两类。对于线性可分的数据，超平面可以表示为：

![](https://i-blog.csdnimg.cn/direct/0cae40e304eb4432915797c1f26766dc.png)

其中：![](https://i-blog.csdnimg.cn/direct/29caa095711147e786f0ca538ff676e5.png)

**间隔（Margin）：** 是指两类样本中距离超平面最近的样本点到超平面的距离。SVM的目标是最大化这个间隔。

##### 1.2 支持向量

支持向量是距离超平面最近的样本点，它们决定了超平面的位置和方向。SVM的优化目标就是找到这些支持向量，并基于它们构建最优超平面。

####  2\. SVM的数学原理

SVM的优化问题可以表示为以下约束优化问题：

![](https://i-blog.csdnimg.cn/direct/efee24250e424db69944f408d8524be2.png)

约束条件为：

![](https://i-blog.csdnimg.cn/direct/9a39903c30054caba2282388fb4d4ebf.png)

其中：![](https://i-blog.csdnimg.cn/direct/5fb88e5533f64694ad4ea8a4a835f3d1.png)

通过拉格朗日乘子法，可以将上述问题转化为对偶问题，从而高效求解。

####  3\. 核函数：处理非线性问题

对于非线性可分的数据，SVM通过核函数将数据映射到高维空间，使得数据在高维空间中线性可分。常用的核函数包括：

![](https://i-blog.csdnimg.cn/direct/60d7f37e079047baa99196a9075896a4.png)

核函数的选择对SVM的性能有很大影响，通常需要通过交叉验证来确定最佳核函数。

### 实例

**使用SVM对鸢尾花数据集进行分类与可视化**

#### 1\. 数据集介绍

鸢尾花数据集（Iris
Dataset）是机器学习领域中最经典的数据集之一。它包含150个样本，每个样本有4个特征：花萼长度、花萼宽度、花瓣长度和花瓣宽度。数据集分为3类，每类50个样本。本文中，我们只使用前两类数据进行二分类任务。

\---

#### 2\. 加载数据

首先，我们使用`pandas`加载数据集，并将数据集分为训练集和测试集。

    
    
    import pandas as pd
    import matplotlib.pyplot as plt
    from sklearn.model_selection import train_test_split
    
    # 加载数据集
    data = pd.read_csv('iris.csv', header=None)
    
    # 提取特征和标签
    x = data.iloc[:, :-1]
    y = data.iloc[:, -1]
    
    # 划分训练集和测试集
    x_train, x_test, y_train, y_test = \
       train_test_split(x, y, test_size=0.2, random_state=20)
    

#### 3\. 数据可视化

为了更好地理解数据，我们可以将训练集和测试集的特征进行可视化。这里我们选择第2列（花萼宽度）和第4列（花瓣宽度）作为可视化的特征。

    
    
    # 可视化训练集和测试集
    plt.scatter(x_train[1], x_train[3], marker='+', label='Train')
    plt.scatter(x_test[1], x_test[3], marker='o', label='Test')
    plt.xlabel('Sepal Width')
    plt.ylabel('Petal Width')
    plt.legend()
    plt.show()
    

#### 4\. 使用SVM进行分类

接下来，我们使用SVM对数据进行分类。这里我们选择线性核函数，并将正则化参数`C`设置为无穷大，以确保模型能够找到最大间隔超平面。

    
    
    from sklearn.svm import SVC
    
    # 选择特征
    X = x_train.iloc[:, [1, 3]]
    y = y_train
    
    # 训练SVM模型
    svm = SVC(kernel='linear', C=float('inf'), random_state=0)
    svm.fit(X, y)
    

####  5\. 可视化决策边界和支持向量

为了更直观地理解SVM的分类结果，我们可以绘制决策边界和支持向量。

    
    
    import numpy as np
    
    # 获取模型参数
    w = svm.coef_[0]
    b = svm.intercept_[0]
    
    # 生成x1的值
    x1 = np.linspace(0, 7, 300)
    
    # 计算决策边界
    x2 = -(w[0] * x1 + b) / w[1]
    x3 = (1 - (w[0] * x1 + b)) / w[1]
    x4 = (-1 - (w[0] * x1 + b)) / w[1]

**绘制决策边界**  

    
    
    plt.plot(x1, x2, linewidth=2, color='r', label='Decision Boundary')
    plt.plot(x1, x3, linewidth=1, color='r', linestyle='--', label='Margin')
    plt.plot(x1, x4, linewidth=1, color='r', linestyle='--')
    
    # 设置坐标轴范围
    plt.xlim(4, 7)
    plt.ylim(0, 5)
    
    # 绘制支持向量
    vets = svm.support_vectors_
    plt.scatter(vets[:, 0], vets[:, 1], c='b', marker='x', label='Support Vectors')
    
    # 显示图例
    plt.legend()
    plt.show()
    

####  6\. 运行结果

![](https://i-blog.csdnimg.cn/direct/74d760e577c746a3a2414db66470b66b.png)

### 总结

#### SVM的优缺点

**优点**  
\- 在高维空间中表现优异。  
\- 适用于小样本数据集。  
\- 通过核函数可以处理非线性问题。  
\- 泛化能力强。

**缺点：**  
\- 对大规模数据训练速度较慢。  
\- 对参数和核函数的选择敏感。  
\- 难以直接解释模型的结果。



