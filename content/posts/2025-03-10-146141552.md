---
arturl_encode: "68747470:733a2f2f626c6f672e6373646e2e6e65742f465f303132352f:61727469636c652f64657461696c732f313436313431353532"
layout: post
title: "Hive的架构"
date: 2025-03-10 00:01:38 +0800
description: "语言（HiveQL）将结构化数据映射为 Hadoop 的 MapReduce、Tez 或 Spark 任务，适合离线批处理，尤其适用于数据仓库场景（如 ETL、报表生成）。2.外部表（External Table）：数据存储在 HDFS 的指定路径，删除表仅删除元数据，保留数据。支持多种引擎：MapReduce（默认）、Tez（优化 DAG 执行）、Spark（内存计算）。：按列值（如日期）将数据划分到不同目录，提升查询效率（如分区裁剪）。Metastore：独立服务，管理元数据，支持高并发访问。"
keywords: "Hive的架构"
categories: ['Hadoop']
tags: ['架构', 'Hive', 'Hadoop']
artid: "146141552"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146141552
    alt: "Hive的架构"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146141552
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146141552
cover: https://bing.ee123.net/img/rand?artid=146141552
image: https://bing.ee123.net/img/rand?artid=146141552
img: https://bing.ee123.net/img/rand?artid=146141552
---

# Hive的架构

**1. 概念**

Hive 是建立在 Hadoop 上的数据仓库工具，旨在简化大规模数据集的查询与管理。它通过
**类 SQL**
语言（HiveQL）将结构化数据映射为 Hadoop 的 MapReduce，适合离线批处理，尤其适用于数据仓库场景。

**2. 数据模型**

**表（Table）**

：
逻辑数据单元，分为两种：

1.内部表（Managed Table）：数据由 Hive 管理，删除表时数据及元数据均被清除。

2.外部表（External Table）：数据存储在 HDFS 的指定路径，删除表仅删除元数据，保留数据。

**分区（Partition）**
：按列值（如日期）将数据划分到不同目录，提升查询效率（如分区裁剪）。

**分桶（Bucket）**
：基于哈希将数据分到固定数量的文件，优化 Join 和采样效率。

**视图（View）**
：虚拟表，基于查询结果定义，不存储实际数据。

**3. 架构**

Hive 架构分为以下核心层：

![](https://i-blog.csdnimg.cn/direct/878a680a269a40cb9135e4f690605bf5.png)

1. 用户接口层：

CLI/JDBC/ODBC：提供命令行和远程访问。

HiveServer2：支持多用户并发、认证，替代旧版 HiveServer。

Web UI（如 Hue）：可视化查询界面。

2. 元数据存储（Metastore）：

使用关系数据库（MySQL、PostgreSQL）存储表结构、分区等元数据。

独立服务模式（Remote Metastore）支持高可用。

3. 驱动层（Driver）：

编译器：将 HiveQL 转换为抽象语法树（AST）、逻辑计划。

优化器：执行逻辑优化（如谓词下推、分区裁剪）。

执行引擎：生成物理计划（MapReduce/Tez/Spark DAG）。

4. 执行层：

支持多种引擎：MapReduce（默认）、Tez（优化 DAG 执行）、Spark（内存计算）。

LLAP（Live Long and Process）：守护进程缓存数据，加速交互式查询。

5. 存储层：

数据存储在 HDFS 或兼容系统（如 S3）。

支持多种格式：文本、ORC（列式存储，支持 ACID）、Parquet。

**4. 核心组件**

Hive CLI：命令行接口，适合简单查询。

HiveServer2：提供 Thrift 服务，支持 JDBC/ODBC 连接。

Metastore：独立服务，管理元数据，支持高并发访问。

SerDe（Serializer/Deserializer）：解析数据格式（如 JSON、CSV），如 `OpenCSVSerde`。

Execution Engine：可插拔引擎（如 Tez 减少中间落盘，提升性能）。

Hive Web Interface（可选）：提供基础监控界面。

> **Hive 通过 SQL 抽象简化了 Hadoop 生态的数据处理，其架构围绕元数据管理、查询编译优化和多引擎执行展开。随着 Tez/Spark 引擎和 LLAP 的引入，Hive 在性能上持续改进，但仍以批处理为核心定位。理解其数据模型与组件协作，是优化 Hive 应用的关键。**