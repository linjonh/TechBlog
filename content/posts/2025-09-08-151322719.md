---
layout: post
title: "AI-云再进化,百度智能云新技术与产品全景解读"
date: 2025-09-08T14:59:04+0800
description: "从 2024 年 DeepSeek 等模型的爆发开始，整个大模型技术也实现了范式的升级，从稠密模型演化到了稀疏的 MoE 模型，专家数量从早期的 8 个逐步扩展到 256 个甚至更多。在人工智能这一核心场景下，我们聚焦于 AI 训推优化，力求在实例形态和功能上实现极致的性能、丰富的自运维诊断能力，并保障模型的安全。对于企业级应用，我们实现了「计算优化」与「高性能 I/O」系列的全面增强，支持 I/O 突增和弹性临时盘，其性能堪比本地盘，满足了在线计算和微服务的突发需求。，我们的目标非常明确：追求极致性能。"
keywords: "AI 云再进化，百度智能云新技术与产品全景解读"
categories: ['未分类']
tags: ['百度', '人工智能']
artid: "151322719"
arturl: "https://blog.csdn.net/2301_82040283/article/details/151322719"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=151322719
    alt: "AI-云再进化,百度智能云新技术与产品全景解读"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=151322719
featuredImagePreview: https://bing.ee123.net/img/rand?artid=151322719
cover: https://bing.ee123.net/img/rand?artid=151322719
image: https://bing.ee123.net/img/rand?artid=151322719
img: https://bing.ee123.net/img/rand?artid=151322719
---



# AI 云再进化，百度智能云新技术与产品全景解读

![](https://i-operation.csdnimg.cn/images/cf31225e169b4512917b2e77694eb0a2.png)百度智能云AI技术全景解析

本文整理自 2025 年 8 月 29 日百度云智大会 —— AI + 算力平台专题论坛，百度智能云技术委员会联席主席郑然的同名主题演讲。

---

各位来宾，大家好。今天，我将分享在过去一年里，百度智能云在计算、存储和网络领域为应对人工智能技术的飞速发展所做出的产品与技术创新。

回顾云计算的发展历程，它经历了三个核心阶段：2000 年左右的 PC 互联网时代，以大数据技术为核心，催生了 MapReduce、BigTable 等分布式技术及 AWS S3 等早期云产品；随后是移动 APP 广泛应用的云原生时代，通过软硬一体的跃迁，实现了计算与存储分离等核心技术的升华；而从 2022 年底 ChatGPT 技术普及开始，我们正式迈入了生成式 AI 时代。这一时代要求云计算具备大规模异构计算、高速并行文件系统和微秒级互联网络，以满足 AI 对算力、存储和通信的极致需求。

从 2024 年 DeepSeek 等模型的爆发开始，整个大模型技术也实现了范式的升级，从稠密模型演化到了稀疏的 MoE 模型，专家数量从早期的 8 个逐步扩展到 256 个甚至更多。整个计算后训练的阶段也实现了从 SFT 向强化学习，围绕着智能体优化模型能力的阶段，模型从快速响应模式进一步演化到了需要深度思考、长上下文的计算模式。AI 原生应用也从早期的简单对话进一步演化成了非常丰富的智能体应用。

模型技术的发展对于云计算产品和技术设计产生了深远的影响。MoE 模型以动态稀疏的特点，相比稠密模型对云计算的动态性提出了更高的要求。动态意味着不确定性，这就意味着计算、存储、网络需要更好地适应。

![](https://i-blog.csdnimg.cn/img_convert/bc7130f88a9e239c1c80eed70bf84298.webp?x-oss-process=image/format,png)

因此，在过去一年里，百度智能云公有云 IaaS 产品发布了以百度百舸 AI 计算平台 5.0 为核心的计算产品，同时计算实例、存储产品、网络产品也进行了全面的升级，更好地满足大模型时代的需求。

我们的技术创新，集中体现在百度百舸 AI 计算平台 5.0 的全面升级上。该平台在算力、网络、推理系统及训推一体等 4 大方向持续突破，已将 PD（Prefill-Decode）分离系统、分布式 KV Cache 等关键技术产品化，供客户直接使用。

在计算实例方面，我们推出了机柜级的**昆仑芯超节点 UltraServer**，通过高密度互联，显著加速 MoE 模型和分布式推理。

同时，以**百度太行 DPU**为技术基座，我们已将所有云上 GPU 实例升级为虚拟机模式，通过硬件卸载虚拟化组件，实现了性能与物理机无限接近。

在存储方面，百度沧海·存储产品矩阵全面升级，面向 AI 数据的全生命周期——从采集、预处理到训练、推理和强化学习，提供了端到端的加速能力。

![](https://i-blog.csdnimg.cn/img_convert/02ad2d4d7b44a20070dd50f873230681.webp?x-oss-process=image/format,png)

随着人工智能和各行各业的数字化进程不断深入，市场对计算的稳定性、性能和场景化覆盖提出了前所未有的高要求。百度太行计算产品体系的全面升级，正是为了回应这些需求，为用户提供一个更稳定、更强大、更丰富的计算平台。

在人工智能这一核心场景下，我们聚焦于 AI 训推优化，力求在实例形态和功能上实现极致的性能、丰富的自运维诊断能力，并保障模型的安全。为此，我们推出了创新的柜级高密实例 UltraServer，通过单实例支持 32 卡互联，实现了从算力芯片到上层功能特性的全栈自研。相较于传统 GPU 实例，它能将 MoE 大模型的单节点训练性能提升 5 到 10 倍。

我们深知，业务的高效落地离不开强大的支持。因此，我们不仅关注性能，也着力于打磨实例的诊断能力和模型安全。我们提供了业务级的 LLM 自运维能力，配合日志服务 BLS，能实现大模型业务的智能诊断，显著提升用户定位问题和优化性能的效率。同时，我们持续强化机密计算，通过支持 TDX 技术的机密实例，为高性能与数据安全双重赋能。

在通用计算方面，我们同样关注 AI 流转链条中的具体需求。针对预处理、任务调度等环节，我们全新推出了通用型 g8/ga4 实例。通过在同核心规格下实现 10% 的整体性能提升，并针对小核心规格优化全链路 I/O 性能，结合 AVX-512 指令集和 Intel 至强 6 平台的 AMX 特性，精准承接 AI 场景下的数据处理需求。

对于企业级应用，我们实现了「计算优化」与「高性能 I/O」系列的全面增强，支持 I/O 突增和弹性临时盘，其性能堪比本地盘，满足了在线计算和微服务的突发需求。而对于量化交易、游戏等对时延和主频极度敏感的热点业务，我们则提供主频高达 3.3 GHz 的高主频实例，辅以标准开放的 ERI 技术，确保节点通信灵活、低时延。

所有这些能力的实现，都得益于百度太行 DPU 底座的全面升级。通过将虚拟化组件全面卸载至 DPU，结合全自研调度器和全硬件加速能力，我们从根本上释放了计算资源的潜力，实现了虚拟机性能与物理机的无限接近。创新的单路节点架构和 2U1N 设计，进一步提升了实例的稳定性和可靠性，为用户的 AI 业务提供了坚实可靠的计算基石。

![](https://i-blog.csdnimg.cn/img_convert/39abe15bf27d128e26209ded957f7456.webp?x-oss-process=image/format,png)

接下来，重点介绍我们的重磅产品——**超节点实例 UltraServer**。

这首先是一次实例形态的创新。通过柜级高密度设计，单实例可支持 32 张昆仑芯 AI 加速卡，并通过自研的 XPU Link 实现全互联，带宽提升高达 8 倍。在单机训练性能上，相对于传统 8 卡实例能够提升 4 到 8 倍。

它还完美支持 **PD 分离**架构。用户可将 Prefill 和 Decode 阶段分别部署在不同超节点中并行运行。从我们的实践来看，在满足首 Token 时延（TTFT）、每个输出 Token 时延（TPOT）等服务质量要求的同时，这种并行运行方式能显著提高加速卡利用率，从而获取推理的最优吞吐。

此外，UltraServer 还配套了事件中心、任务诊断等运维工具，实现了完整的端到端运维。过去，AI 任务可能因软硬件问题而中断，人工定位根因往往需要数小时甚至数天。现在，通过事件中心，客户可以第一时间获知资源健康状态变化，对任务进行 Checkpoint 并移出故障资源。而日志服务 BLS 的智能诊断功能，融合了大模型训练专家经验，曾经需要多人协作耗时数小时才能定位的疑难故障，如今最快仅需十几秒即可精准锁定。

综合来看，在 PD 分离架构下，相较于单机 8 卡的传统实例，Decode/Prefill 阶段的整体性能预计可分别提升 95% 和 36%。

![](https://i-blog.csdnimg.cn/img_convert/f6d0b143e5d90be33f43afa5a39a02f8.webp?x-oss-process=image/format,png)

百度太行 DPU 是整个计算产品坚实的技术底座。传统虚拟化会因 VM 的进出（VM Entry/Exit）和占用 CPU 核心而产生性能损耗。

我们的解决方案是，将整个虚拟化组件卸载到 DPU 上执行。这不仅消除了 CPU 成本的损耗，还通过软硬结合优化，减少了 VM 的换入换出，使虚拟机性能损耗无限接近于物理机水平。

DPU 还提供了丰富的设备虚拟化能力。所有网络和存储设备都通过 DPU 虚拟化，其 I/O 链路在硬件上得到加速，并支持设备的灵活插拔和迁移，保证了虚拟机实例的弹性与韧性。

针对 GPU 实例，我们不仅透传 GPU 设备，还将 NVSwitch 等设备透传至虚拟机，确保了异构计算环境下，虚拟机性能与物理机性能的无限接近。正是基于太行 DPU 的零损耗虚拟化和软硬一体化设计，我们才能为用户提供原生的高性能计算体验。

![](https://i-blog.csdnimg.cn/img_convert/e35ec5fb64185c8102d46746a65f5abc.webp?x-oss-process=image/format,png)

在人工智能领域，数据与算力、模型并列为核心要素。因此，**百度沧海·存储**产品全面升级，旨在加速 AI 数据的全生命周期。

在数据传输环节，我们通过 CDN 动态加速和全球加速网络，实现海外到国内访问链路提速 30% 以上，助力出海 AI 应用。

在数据预处理环节，对象存储 **BOS**不仅支持 PyTorch、Ray 等 AI 生态，还通过 **BOSFS 2.0**实现了单客户端 3GB/s 的吞吐，可直接挂载到计算节点高速访问。高性能并行文件存储 **PFS**则提供百微秒级 I/O 延迟和 40GB/s 的单客户端吞吐，支持目录级的容量和吞吐配额，满足极致性能的训练需求。

在推理环节，我们上线了自研的 KV C**ache 加速方案**，通过异步实现全局索引，提升了 Cache 命中率，已在 DeepSeek 推理场景实现 TTFT 37% 的下降。

在强化学习场景，我们通过异步并行读写机制，实现了模型权重参数的秒级极速更新。

![](https://i-blog.csdnimg.cn/direct/a753fd40b4f440ba940168af9e893523.png)

丰富的产品能力，源于我们统一的存储技术底座。我们将元数据系统与高性能数据引擎分离，实现了积木式构建。

左侧是**自适应元数据架构**。它针对目录树的访问特点，在单机和分布式模式间自适应切换：小规模时聚合存储，实现极致低延迟；大规模时自动平滑切换到分布式架构，支撑千亿级文件规模。该技术成果已被国际顶会 SOSP '25 收录。

右侧是**高性能存储引擎**。它采用 I/O 分流机制：小 I/O 先写入三副本缓冲层，后台聚合写入 EC（纠删码）；大 I/O 则直接写入在线 EC 引擎。这既保证了小 I/O 的低延迟，又兼顾了大 I/O 的成本效益。同时，自研的实时空洞回收技术实现了高达 90% 的空间利用率。

所有存储产品（对象、文件、块）均基于此统一底座，确保了性能、成本与可靠性的业界领先水平。

![](https://i-blog.csdnimg.cn/img_convert/f63182fa37df876aa68fd361ebfbb4bd.webp?x-oss-process=image/format,png)

存储的瓶颈，往往不在于磁盘本身，而在于数据在系统中的传输链路。为了解决这一痛点，我们构建了一套软硬协同的高性能网络通信技术栈，旨在打通从应用到存储的全链路性能瓶颈。

这套技术栈的底层，是**百度自研 DPU**与商用网卡的协同。它们共同实现了端网融合的 RDMA 协议和多路径转发，为上层提供了坚实的网络基础。

在加速层，我们自研了**用户态 TCP 协议栈**，其性能比传统内核态提升了 3 倍；同时，我们对 RDMA 协议也进行了深度优化，确保在各种场景下都能发挥最佳性能。

在接口层，我们提供了两种选择：兼容传统应用的 Socket-like API，以及面向高性能应用的 Verbs API。

最终，通过这套高性能 RPC 框架，我们为上层的块、文件、KV、对象等各类存储应用，提供了透明、高效的 I/O 服务。这不仅显著提升了云磁盘 CDS 和并行文件存储 PFS 的性能，也为 AI 工作负载的高效运行打下了坚实的基础。

![](https://i-blog.csdnimg.cn/img_convert/8c6ebc33f7cc52d4e06e4c4e5d576498.webp?x-oss-process=image/format,png)

生成式 AI 时代，特别是 MoE 模型的动态稀疏特性，对网络的 AlltoAll 通信提出了前所未有的挑战。为此，我们设计了全新的**新一代 AI 网络**来应对。

首先，在**高效 AlltoAll 通信**方面，我们采用了 2 跳可达的网络架构，将物理时延从 5 微秒降低到 4 微秒。同时，通过大规模 RoCE 自适应路由技术，将 HPN 网络的带宽有效性提升了 20%，更好地适应了 MoE 模型动态变化的通信模式。

其次，在**极致通信优化**上，我们对 DeepEP 等主流通信库进行了深度调优。通过为通信流量设置高优队列，并对机内数据拷贝进行硬件加速，使通信性能达到了理论极限。

最后，为了支持**高性能 KV Cache 传输**，我们在 VPC 网络中引入了**弹性 eRDMA 技术**。它为 KV Cache 的传输提供了专用的高速通道，确保其与 MoE 计算过程完美地隐藏在一起，从而优化了整体性能。

![](https://i-blog.csdnimg.cn/img_convert/90f2204f3c4865e22ced2c7f1ff5698b.webp?x-oss-process=image/format,png)

随着 AI 和全球化的浪潮，云网络迎来了爆发式的流量增长，用户对网络性能、时延和稳定性的要求也愈发严格。在此背景下，我们的 VPC 网络产品进行了全面革新。

在**全球加速**方面，我们基于专用线路、智能 DNS 解析、高速互连构建全球加速能力等，有效加速了境内外用户的互访，解决了卡顿和延迟问题，为出海 AI 应用提供了有力支持。

在**性能与可靠性**方面，我们通过基于 DPU 的软硬一体 vSwitch 和网关，实现了极致的新建链接能力，CPS 提升 65%。即便在极端的 incast 流量冲击下，丢包率也实现了显著下降，保障了网络的确定性。

在**网络管理**上，我们为混合云场景提供了 QoS 能力，帮助客户合理规划带宽，平衡不同业务流量的优先级，确保关键业务的网络质量。

在网络**故障诊断**领域，我们实现了重大突破。在新一代网络诊断产品的技术架构中，我们将 Overlay 网络与物理网络的拓扑完全衔接，可以监控报文从虚拟机到物理网络的完整路径。结合探测和监控技术，能够快速定位丢包或时延增大的异常点。我们还将网络故障演练的核心能力产品化，让客户可以自主验证组网的可靠性。

![](https://i-blog.csdnimg.cn/img_convert/155964e7c2235760c14d88f4695ae432.webp?x-oss-process=image/format,png)

云原生作为 AI 时代的核心技术底座，其重要性不言而喻。今年，我们的云原生产品体系围绕企业 AI 工程化需求，进行了全面升级，致力于为客户提供一个稳定可靠、高性能、全托管的 AI 基础设施。

我们发布了以「AI 云原生应用」为核心的全新解决方案，旨在一站式支撑 AI 应用的高效稳定运行。具体而言，我们推出了基于函数计算的 **MCP Server 部署托管服务**，极大简化了 MCP 服务的部署和管理，提升了开发迭代效率。同时，我们发布了 **AI 云原生网关**，它具备 LLM 智能路由和 Token 配额限流能力，能够有效优化大模型请求的调度与成本控制。

在集群管理方面，我们实现了**核心控制器全托管**，把复杂的运维工作留给自己，把简单留给客户。通过集群网络的自动规划、智能故障定位和自动伸缩等能力，显著提升了集群的稳定性，实现了对常见运维场景的无人化处理。

在大规模计算支持方面，**5,000 节点规模的大规模训练集群托管能力**已全面落地，覆盖 GPU 与国产昆仑芯等多种算力架构。我们提供分钟级的软硬件故障自动恢复能力，并具备毫秒级高精度 RDMA 监控，能够有效感知瞬时性能波动，为高性能分布式计算任务提供深度的性能诊断支持。

![](https://i-blog.csdnimg.cn/img_convert/b108042b514bf870d106b2faa2422ff5.webp?x-oss-process=image/format,png)

在大模型时代，我们面临着前所未有的挑战。智能体的决策链复杂且充满不确定性，我们迫切需要工具来理解其运行和决策流程。同时，大模型的训练过程一旦卡顿或中断，意味着巨大的资源和金钱浪费，研发人员也需要耗费大量时间去诊断故障。因此，我们推出了全面的可观测产品，旨在帮助用户更好地理解和优化其 AI 应用。

在**智能体可观测**方面，通过 BLS 日志服务，我们可以完整记录智能体的调用链和上下文信息，方便客户分析其运行情况和决策流程。

在**大模型训练可观测**方面，我们支持采集 PyTorch 等框架的全栈性能数据，收集调用链和堆栈。结合专家经验，系统能生成性能分析报告，帮助用户快速定位训练过程中的性能瓶颈。

在**大模型推理可观测**方面，我们已适配 vLLM、SGLang 等主流推理框架，能够一键暴露 TTFT、TPOT 以及 PD 分离各阶段的时延等关键指标，助力用户优化分布式推理服务。

![](https://i-blog.csdnimg.cn/img_convert/6b610bddc6e175435f155c3b0fe9a4e5.webp?x-oss-process=image/format,png)

回顾过去十年的技术演进，我们沉淀出了一些核心的设计原则。这些原则，就像是我们打造产品的「心法」，指导着我们如何构建面向未来的基础设施。

先看**计算**。我们习惯把计算分成数据面和控制面来看。

在**数据面**，我们的目标非常明确：追求极致性能。那如何实现呢？这不仅意味着要通过 DPU 实现零虚拟化损耗，更重要的是，我们的设计必须紧贴用户的工作负载。无论是大数据、云原生还是今天的 AI 大模型，我们的产品设计都必须和主流技术特点完美匹配，实现最佳的性能表现。

而在**控制面**，我们更关注的是弹性和韧性。想象一下，我们管理着几十万台服务器，任何一次升级或故障都不能影响用户。所以我们坚持声明式架构，支持热升级、热插拔，一切设计都是为了应对局部故障，确保整个系统稳如磐石。

![](https://i-blog.csdnimg.cn/img_convert/c2668f6bb7c72f3dac2d1210874130c3.webp?x-oss-process=image/format,png)

再看**网络**。网络是基础，平时看不见，一出问题就是大事。我们的设计有三个核心要素：

第一，**面向容灾**。我们通过分片隔离、采用不同厂商异构形态的硬件、把网元做得更小更简单，来最小化故障的影响范围，让租户之间互不影响。

第二，**可编程**。我们以 SDN 为核心，让报文的路径可以被细粒度地编程控制，实现流量工程和 QoS 分级，精准地控制每一个报文怎么处理、走哪条路径，从而保障关键业务的最优体验。

第三，**软硬一体化**。各网元通过软硬一体化设计，强化了软硬件的深度融合与协同编排能力。这不仅实现了超大规格与超高性能的兼顾，还能通过硬件对大象流、微突发等进行卸载，显著提升了网络的确定性。

![](https://i-blog.csdnimg.cn/img_convert/211f19ae1e00c4cd5d3831429323b71a.webp?x-oss-process=image/format,png)

最后，分享一下我们在**存储**领域的设计原则。

第一，**协同工作负载**。我们的存储架构绝不是凭空设计的，而是紧密结合上层应用的特点。比如 AI 训练是大文件顺序读写，我们的系统每一层都会去适应这种模式，实现整体效率最优。

第二，**结合硬件趋势**。行业正在从「磁盘时代」进入「全闪存时代」，瓶颈从磁盘转移到了 CPU。因此，我们的设计理念也必须进化，要从「磁盘友好」转向「CPU 友好」，避免 Compaction 这类高 CPU 消耗的操作，真正释放硬件的性能。

第三，也是我们整个架构的基石——**分层架构**。我们把存储系统抽象为元数据和数据引擎两部分，把它们沉淀成可复用的「积木」。这样，我们就能快速、高效地构建出对象、文件、块等多种存储产品，让技术创新能迅速复制和迭代。

![](https://i-blog.csdnimg.cn/img_convert/04d04f8978ea424e171245389d1d747d.webp?x-oss-process=image/format,png)

百度智能云始终紧密围绕客户的核心需求场景，与客户共同成长。

在**智能驾驶**领域，我们不仅提供基础的高性能计算、网络与存储服务，更构建了端到端智驾训练与模型仿真软硬一体的加速能力。在我们的平台上，端到端智驾训练速度可达开源社区方案的两倍。同时，我们提供潮汐算力、抢占式实例等多样化算力形态，有效助力客户高效处理海量多模态数据，加速「模型-数据」闭环。

在**具身智能**领域，我们聚焦视觉语言模型（VLM）的强化，通过增强模型对超长序列输入的处理能力，支持更高清、更长时间的视频样本训练。在规控、仿真（世界模型）和模型上身（模型量化）等关键技术路径上，我们均提供了行业领先的最佳实践与训推一体化加速支持。

我们深信，只有基于对行业的深入洞察，以前瞻性和主动性的姿态持续演进 AI 基础设施的软硬一体能力，才能真正实现与客户的双赢。

![](https://i-blog.csdnimg.cn/img_convert/5b871ea9ce203ea1f55965509e861137.webp?x-oss-process=image/format,png)

谢谢大家！



