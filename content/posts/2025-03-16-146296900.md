---
layout: post
title: "LLM论文笔记-25-Chain-of-Thought-Reasoning-without-Prompting"
date: 2025-03-16 16:22:50 +0800
description: "注：本系列不包括基础的知识点讲解，为笔记/大纲性质而非教程，用于论文知识点和思想和快速记忆和回顾，更多细节建议阅读论文原文。1. LLMs 不需要prompting就可以生成链式推理路径，prompting只是将这些能力显性化的一种手段。2. cot path 往往与更高的model confidence相关，可以用作可靠性的metric。3. 探索多样化的解码路径能有效挖掘模型的内在推理能力，而不仅仅依赖于模型规模或训练数据的多样性。模型未经过指令调优时的推理能力缺陷，并在指令调优的模型中。"
keywords: "LLM论文笔记 25: Chain-of-Thought Reasoning without Prompting"
categories: ['未分类']
tags: ['论文阅读', '深度学习', '机器学习', '人工智能', 'Chatgpt']
artid: "146296900"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146296900
    alt: "LLM论文笔记-25-Chain-of-Thought-Reasoning-without-Prompting"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146296900
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146296900
cover: https://bing.ee123.net/img/rand?artid=146296900
image: https://bing.ee123.net/img/rand?artid=146296900
img: https://bing.ee123.net/img/rand?artid=146296900
---

# LLM论文笔记 25: Chain-of-Thought Reasoning without Prompting

>   * Arxiv日期：2024.5.31
>   * 机构：Google DeepMind
>

### 关键词

  * cot-decoding
  * 推理路径
  * pretrain

### 核心结论

1\. LLMs 不需要prompting就可以生成链式推理路径，prompting只是将这些能力显性化的一种手段

2\. cot path 往往与更高的model confidence相关，可以用作可靠性的metric

3\. 探索多样化的解码路径能有效挖掘模型的内在推理能力，而不仅仅依赖于模型规模或训练数据的多样性

4\. CoT-Decoding 可以**弥补** 模型未经过指令调优时的推理能力缺陷，并在指令调优的模型中**进一步优化** 性能

5\. Cot-Decoding适用于多种任务和语言模型，显示出显著的通用性和鲁棒性

### 主要方法

（验证了内在推理能力的存在）使用pretrain模型，**不使用greedy decoding，而是在第一个token预测使用top-k**
：**发现内化cot推理能力，且带cot的答案置信度更高**

![](https://i-blog.csdnimg.cn/direct/f66940e479bd4f13a36ecf19cee83217.png)

置信度衡量标准：

**answer中每一个token在NTP时当前token和下一个token的概率差异**

![](https://i-blog.csdnimg.cn/direct/78a19f54dc3f4c6e9229c2a215accbb2.png)

> 注：本系列不包括基础的知识点讲解，为笔记/大纲性质而非教程，用于论文知识点和思想和快速记忆和回顾，更多细节建议阅读论文原文



