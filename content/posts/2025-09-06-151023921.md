---
layout: post
title: "å¦‚ä½•è¿›è¡Œç¥ç»ç½‘ç»œçš„æ¨¡å‹è®­ç»ƒè§†é¢‘ä»£ç ä¸­çš„çŸ¥è¯†ç‚¹è®°å½•"
date: 2025-09-06T18:04:00+0800
description: "å…¶ä¸­data_train.iloc[i:i+4, :-1]æ˜¯pandaä¸­æŒ‰ä½ç½®æå–æ•°æ®çš„æ“ä½œï¼Œæ˜¯ä¸€ä¸ªpanda_DataFrameå¯¹è±¡ï¼Œè¦æ±‚å˜é‡åä¸èƒ½æœ‰ç©ºæ ¼ï¼Œç”±æ­¤å‘½åä¸ºdata_trainã€‚ç¨€ç–å¼ é‡ï¼š ä¾‹å¦‚ä¸€ä¸ª3Ã—4 çš„è¡¨æ ¼ï¼Œè‹¥åªæœ‰ 2 ä¸ªéé›¶å€¼ï¼Œåªéœ€è®°å½•è¿™ 2 ä¸ªå€¼çš„ â€œè¡Œå·ã€åˆ—å·â€ å’Œ â€œå€¼æœ¬èº«â€ï¼Œæ— éœ€è®°å½•å…¶ä»–é›¶å€¼ã€‚ä¸æ˜¯æ‰€æœ‰çš„ç±»ä¸­çš„å‡½æ•°ï¼ˆæ–¹æ³•ï¼‰éƒ½æœ‰selfå‚æ•°ï¼Œç±»çš„æ–¹æ³•æœ‰å®ä¾‹åŒ–æ–¹æ³•ï¼Œç±»æ–¹æ³•ï¼Œé™æ€æ–¹æ³•ã€‚ä½œç”¨ï¼šæ“ä½œç±»çš„å±æ€§æˆ–åˆ›å»ºå®ä¾‹ï¼ˆä¸ç±»ç›¸å…³ï¼Œä¸ä¾èµ–å…·ä½“å®ä¾‹ï¼‰ã€‚ï¼Œæœ¬è´¨ä¸Šæ˜¯å®šä¹‰åœ¨ç±»å‘½åç©ºé—´ä¸­çš„æ™®é€šå‡½æ•°ã€‚"
keywords: "å¦‚ä½•è¿›è¡Œç¥ç»ç½‘ç»œçš„æ¨¡å‹è®­ç»ƒï¼ˆè§†é¢‘ä»£ç ä¸­çš„çŸ¥è¯†ç‚¹è®°å½•ï¼‰"
categories: ['æœªåˆ†ç±»']
tags: ['ç¥ç»ç½‘ç»œ', 'æ·±åº¦å­¦ä¹ ', 'äººå·¥æ™ºèƒ½']
artid: "151023921"
arturl: "https://blog.csdn.net/weixin_63566653/article/details/151023921"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=151023921
    alt: "å¦‚ä½•è¿›è¡Œç¥ç»ç½‘ç»œçš„æ¨¡å‹è®­ç»ƒè§†é¢‘ä»£ç ä¸­çš„çŸ¥è¯†ç‚¹è®°å½•"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=151023921
featuredImagePreview: https://bing.ee123.net/img/rand?artid=151023921
cover: https://bing.ee123.net/img/rand?artid=151023921
image: https://bing.ee123.net/img/rand?artid=151023921
img: https://bing.ee123.net/img/rand?artid=151023921
---



# å¦‚ä½•è¿›è¡Œç¥ç»ç½‘ç»œçš„æ¨¡å‹è®­ç»ƒï¼ˆè§†é¢‘ä»£ç ä¸­çš„çŸ¥è¯†ç‚¹è®°å½•ï¼‰

è§†é¢‘é“¾æ¥ï¼š[è¯¦è§£ç¥ç»ç½‘ç»œæ˜¯å¦‚ä½•è®­ç»ƒçš„â€”â€”ç»†èŠ‚åˆ°æ¯ä¸ªå‚æ•°ï¼ˆğŸ‘‰æˆ³å³è¾¹åˆé›†è§‚çœ‹æœ€æ–°Transformerç›¸å…³æ•™ç¨‹ï¼‰_å“”å“©å“”å“©_bilibili](https://www.bilibili.com/video/BV1w8zhYwEGo/?-Arouter=story&buvid=Z046F70FD2ABEB8C48898487B6649ED24A43&from_spmid=united.player-video-detail.0.0&is_story_h5=false&mid=LpEDpB9FONd4OB%2BEMFNYkw%3D%3D&plat_id=163&share_from=ugc&share_medium=iphone&share_plat=ios&share_session_id=D12E05FA-EA70-4A18-A319-F63835F548FD&share_source=WEIXIN&share_source=weixin&share_tag=s_i&spmid=main.ugc-video-detail-vertical.0.0&timestamp=1756526772&unique_k=vdGBumK&up_id=9228231&vd_source=84cf3404834d7c2faa771f3df6d70e58 "è¯¦è§£ç¥ç»ç½‘ç»œæ˜¯å¦‚ä½•è®­ç»ƒçš„â€”â€”ç»†èŠ‚åˆ°æ¯ä¸ªå‚æ•°ï¼ˆğŸ‘‰æˆ³å³è¾¹åˆé›†è§‚çœ‹æœ€æ–°Transformerç›¸å…³æ•™ç¨‹ï¼‰_å“”å“©å“”å“©_bilibili")

#### 1.nn.Parameter()

åœ¨ PyTorch ä¸­ï¼Œ`nn.Parameter()`Â æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„ç±»ï¼ˆ`torch.nn.Parameter`ï¼‰ï¼Œç”¨äºå®šä¹‰ç¥ç»ç½‘ç»œä¸­**å¯å­¦ä¹ çš„å‚æ•°**ï¼ˆå¦‚æƒé‡ã€åç½®ç­‰ï¼‰ã€‚å®ƒæ˜¯Â `torch.Tensor`Â çš„å­ç±»ï¼Œæ ¸å¿ƒä½œç”¨æ˜¯ï¼šå½“æŠŠÂ `Parameter`Â å¯¹è±¡èµ‹å€¼ç»™Â `nn.Module`Â ç±»ï¼ˆæˆ–å…¶å­ç±»ï¼Œå¦‚è‡ªå®šä¹‰æ¨¡å‹ã€å±‚ï¼‰çš„å±æ€§æ—¶ï¼Œä¼š**è‡ªåŠ¨è¢«æ³¨å†Œä¸ºæ¨¡å‹çš„å‚æ•°**ï¼Œå¹¶å‚ä¸è®­ç»ƒæ—¶çš„æ¢¯åº¦è®¡ç®—å’Œæ›´æ–°ã€‚

* `nn.Parameter`Â ä¼šè¢«è‡ªåŠ¨çº³å…¥æ¨¡å‹çš„å‚æ•°ç®¡ç†ï¼Œæ˜¯ â€œå¯å­¦ä¹ å‚æ•°â€ çš„å®˜æ–¹æ ‡è®°æ–¹å¼ã€‚

  ```
  import torch
  from torch import nn
  class Model(nn.Module):
      def __init__(self):
          super().__init__()
          self.w=nn.Parameter(torch.randn(2,3))
          self.b=nn.Parameter(torch.zeros(2))
      
      def forward(self,x):
          return x@self.w.t()+self.b
  model=Model()
  for name,param in model.named_parameters():
      print(f"å‚æ•°å:{name},å½¢çŠ¶ï¼š{param.shape}")
      




          

  ```

  æ³¨æ„ï¼šåœ¨ PyTorch ä¸­ï¼Œ`torch.randn(4, 3)`Â ä¼šç”Ÿæˆä¸€ä¸ªå½¢çŠ¶ä¸ºÂ `(4, 3)`Â çš„å¼ é‡ï¼Œå…¶å…ƒç´ æ˜¯**æœä»æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼ˆå‡å€¼ä¸º 0ï¼Œæ ‡å‡†å·®ä¸º 1ï¼‰çš„éšæœºæ•°**ã€‚å› æ­¤ï¼Œ`self.w`Â çš„å…·ä½“æ•°å€¼æ˜¯**éšæœºç”Ÿæˆçš„**ï¼Œæ¯æ¬¡è¿è¡Œä»£ç éƒ½ä¼šå¾—åˆ°ä¸åŒçš„ç»“æœã€‚

#### 2.æŸå¤±å‡½æ•°æ ‡å‡†å·®çš„è®¡ç®—

![](https://i-blog.csdnimg.cn/direct/02af33fc095e403d8f46fd88c8279440.png)

å…¶ä¸­data_train.iloc[i:i+4, :-1]æ˜¯pandaä¸­æŒ‰ä½ç½®æå–æ•°æ®çš„æ“ä½œï¼Œæ˜¯ä¸€ä¸ªpanda_DataFrameå¯¹è±¡ï¼Œè¦æ±‚å˜é‡åä¸èƒ½æœ‰ç©ºæ ¼ï¼Œç”±æ­¤å‘½åä¸ºdata_trainã€‚i:i+4è¡¨ç¤ºé€‰å–ä»ç´¢å¼•Â `i`Â åˆ°Â `i+3`Â çš„è¿ç»­ 4 è¡Œæ•°æ®ï¼Œï¼š-1è¡¨ç¤ºé€‰å–é™¤æœ€åä¸€åˆ—ä¹‹å¤–çš„æ‰€æœ‰åˆ—ã€‚è€Œåªæœ‰-1è¡¨ç¤ºé€‰å–æœ€åä¸€åˆ—ã€‚

#### 3.selfçš„ç”¨æ³•

ä¸æ˜¯æ‰€æœ‰çš„ç±»ä¸­çš„å‡½æ•°ï¼ˆæ–¹æ³•ï¼‰éƒ½æœ‰selfå‚æ•°ï¼Œç±»çš„æ–¹æ³•æœ‰å®ä¾‹åŒ–æ–¹æ³•ï¼Œç±»æ–¹æ³•ï¼Œé™æ€æ–¹æ³•ã€‚

å®ä¾‹åŒ–æ–¹æ³•è¦æ±‚ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯selfï¼Œ`self`Â ä»£è¡¨è°ƒç”¨è¯¥æ–¹æ³•çš„å®ä¾‹å¯¹è±¡æœ¬èº«ã€‚

ç±»æ–¹æ³•ï¼šç”¨Â `@classmethod`Â è£…é¥°ï¼Œç¬¬ä¸€ä¸ªå‚æ•°å¿…é¡»æ˜¯Â `cls`ï¼ˆä»£è¡¨ç±»æœ¬èº«ï¼‰ï¼Œ**ä¸éœ€è¦Â `self`**ã€‚  
 ä½œç”¨ï¼šæ“ä½œç±»çš„å±æ€§æˆ–åˆ›å»ºå®ä¾‹ï¼ˆä¸ç±»ç›¸å…³ï¼Œä¸ä¾èµ–å…·ä½“å®ä¾‹ï¼‰ã€‚

é™æ€æ–¹æ³•ï¼šç”¨Â `@staticmethod`Â è£…é¥°ï¼Œ**æ—¢ä¸éœ€è¦Â `self`ï¼Œä¹Ÿä¸éœ€è¦Â `cls`**ï¼Œæœ¬è´¨ä¸Šæ˜¯å®šä¹‰åœ¨ç±»å‘½åç©ºé—´ä¸­çš„æ™®é€šå‡½æ•°ã€‚  
 ä½œç”¨ï¼šæä¾›ä¸ç±»ç›¸å…³çš„å·¥å…·åŠŸèƒ½ï¼Œä¸ä¾èµ–ç±»æˆ–å®ä¾‹çš„çŠ¶æ€ã€‚

#### 4.pyTorchæ¨¡å‹è®­ç»ƒæ­¥éª¤

**åˆå§‹åŒ–æ¨¡å‹**Â â†’ 2.Â **åˆå§‹åŒ–ä¼˜åŒ–å™¨**ï¼ˆä¾èµ–æ¨¡å‹å‚æ•°ï¼Œéœ€åœ¨æ¨¡å‹ä¹‹åï¼‰â†’ 3.Â **å‡†å¤‡æ•°æ®**Â â†’ 4.Â **å¾ªç¯è®­ç»ƒï¼ˆå¤šè½® Epochï¼‰**ï¼š

æ¯è½®è®­ç»ƒï¼šæ¢¯åº¦æ¸…é›¶ â†’ å‰å‘ä¼ æ’­ï¼ˆç®—Â `y_pred`ï¼‰â†’ è®¡ç®—æŸå¤± â†’ åå‘ä¼ æ’­ï¼ˆç®—æ¢¯åº¦ï¼‰â†’ ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°ï¼ˆç”¨æ¢¯åº¦è°ƒå‚ï¼‰

```
import torch
from torch import nn
import numpy as np
import pandas as pd
from torch.optim import AdamW

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.w = nn.Parameter(torch.tensor([
            [0.1,0.2],
            [0.2,0.3],
            [0.1,0.3]

        ]))  # æƒé‡ï¼š(1,2)ï¼Œå¯¹åº”2ä¸ªç‰¹å¾
        self.b = nn.Parameter(torch.tensor([0.0,0.1,0.2]))     # åç½®ï¼š
        self.softmax=nn.Softmax(-1)
    
    def forward(self, x):
        # ä¿®æ­£ï¼šç”¨squeeze()å°†è¾“å‡ºä»(3,1)è½¬ä¸º(3,)ï¼Œä¸yçš„å½¢çŠ¶å®Œå…¨åŒ¹é…
        return self.softmax((x @ self.w.t() + self.b).squeeze()  )
    
    @staticmethod
    def loss(y_pred, y):
        return ((y_pred - y) ** 2).mean()  # MSEæŸå¤±

if __name__ == '__main__':
    # 1. åˆå§‹åŒ–æ¨¡å‹
    model = Model()
    print(model.w) 
    print(model.b)
    # 2. åˆå§‹åŒ–ä¼˜åŒ–å™¨ï¼ˆå¿…é¡»åœ¨æ¨¡å‹ä¹‹åï¼‰
    optimizer = AdamW(
        params=model.parameters(),
        lr=0.1  # å­¦ä¹ ç‡
    )

    # 3. å‡†å¤‡è®­ç»ƒæ•°æ®
    data_list = [
        [1, 2, 3, 4],   # xå–å‰2åˆ—[1,2]ï¼Œyå–æœ€å1åˆ—[4]
        [2, 3, 4, 5],   # xå–[2,3]ï¼Œyå–[5]
        [3, 4, 5, 6]    # xå–[3,4]ï¼Œyå–[6]
    ]
    data_train = pd.DataFrame(data_list)

    # 4. è®­ç»ƒå¾ªç¯ï¼ˆæ ¸å¿ƒä¿®æ­£éƒ¨åˆ†ï¼‰
    epochs = 10  # è®­ç»ƒè½®æ¬¡
    for epoch in range(epochs):  # å¤–éƒ¨epochå¾ªç¯ï¼šç”¨epochè€Œéiï¼Œé¿å…å˜é‡å†²çª
        # å…³é”®1ï¼šæ¯ä¸ªepoché‡ç½®æŸå¤±åˆ—è¡¨ï¼Œä¸ç´¯ç§¯å†å²æŸå¤±
        epoch_loss_list = []  
        # å…³é”®2ï¼šå†…éƒ¨æ•°æ®å¾ªç¯ç”¨jï¼Œé¿å…ä¸å¤–éƒ¨epochå˜é‡å†²çªï¼ˆåŸä»£ç ç”¨iè¦†ç›–ï¼‰


        for j in range(0, len(data_train), 4):  #æ ¸å¿ƒä½œç”¨æ˜¯ä» data_train çš„ç¬¬ 0 ä¸ªå…ƒç´ å¼€å§‹ï¼Œæ¯é—´éš” 4 ä¸ªå…ƒç´ å–ä¸€ä¸ªç´¢å¼• jï¼Œé€šå¸¸ç”¨äº æ‰¹é‡å¤„ç†æ•°æ®ï¼ˆæ¯”å¦‚æ¯æ¬¡å¤„ç† 4 ä¸ªæ ·æœ¬ï¼Œå³æ‰¹é‡å¤§å°ä¸º 4ï¼‰
            # æå–ç‰¹å¾xï¼šå‰2åˆ—ï¼Œå½¢çŠ¶(3,2)ï¼ˆ3ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬2ä¸ªç‰¹å¾ï¼‰
            x = torch.tensor(np.array(data_train.iloc[j:j+3, :-2]), dtype=torch.float32)
            # æå–æ ‡ç­¾yï¼šæœ€å1åˆ—ï¼Œå½¢çŠ¶(3,)ï¼ˆ3ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬1ä¸ªæ ‡ç­¾ï¼‰
            y = torch.tensor(np.array(data_train.iloc[j:j+3, -1]), dtype=torch.float32)
            
            # å‰å‘ä¼ æ’­ï¼šå¾—åˆ°y_predï¼ˆå½¢çŠ¶(3,)ï¼‰
            y_pred = model(x)
            # è®¡ç®—å½“å‰æ‰¹æ¬¡æŸå¤±
            batch_loss = Model.loss(y_pred, y)
            # æ”¶é›†å½“å‰epochçš„æ‰¹æ¬¡æŸå¤±
            epoch_loss_list.append(batch_loss)


        # 5. åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–°ï¼ˆå…³é”®ä¿®æ­£ï¼šé¡ºåºå’Œæ¢¯åº¦æ¸…é›¶ï¼‰
        optimizer.zero_grad()  # å…³é”®3ï¼šå…ˆæ¸…é›¶æ¢¯åº¦ï¼Œå†åå‘ä¼ æ’­ï¼ˆåŸä»£ç é¡ºåºé¢ å€’ï¼‰
        total_epoch_loss = sum(epoch_loss_list)  # å½“å‰epochçš„æ€»æŸå¤±ï¼ˆä¸ç´¯ç§¯å†å²ï¼‰
        total_epoch_loss.backward()  # å¯¹å½“å‰epochçš„æ€»æŸå¤±åå‘ä¼ æ’­
        optimizer.step()  # æ›´æ–°å‚æ•°

        # 6. æ‰“å°è®­ç»ƒæ—¥å¿—ï¼ˆè§‚å¯ŸæŸå¤±ä¸‹é™å’Œå‚æ•°æ›´æ–°ï¼‰
        print(f"Epoch: {epoch+1:2d} | Total Loss: {total_epoch_loss.item():.4f}")
        print(model.w)
        print(model.b)
    y_preds=[torch.round(y_pre) for y_pre in y_pred]
    print('#########',y_preds)

    accuracy=(np.array(y_pred)==(np.array(y))).mean()
    print('Accaracy:',accuracy)


    
```

#### 5ï¼Œå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­çš„åŒºåˆ«

![](https://i-blog.csdnimg.cn/direct/c330189fa4b341baa413e77fb59e6a5b.png)

#### 6.nn.Linear()

`nn.Linear`Â æ˜¯ PyTorchï¼ˆ`torch.nn`Â æ¨¡å—ï¼‰ä¸­å®ç°**çº¿æ€§å˜æ¢**çš„æ ¸å¿ƒå±‚ç±»ï¼Œæœ¬è´¨æ˜¯å¯¹è¾“å…¥æ•°æ®æ‰§è¡Œã€ŒçŸ©é˜µä¹˜æ³• + åç½®åŠ æ³•ã€æ“ä½œï¼Œå…¬å¼ä¸ºï¼š  
 `y = x Â· Aáµ€ + b`  
 å…¶ä¸­ï¼š`x`Â æ˜¯è¾“å…¥ï¼Œ`A`Â æ˜¯å±‚çš„æƒé‡çŸ©é˜µï¼Œ`b`Â æ˜¯åç½®å‘é‡ï¼ˆå¯é€‰ï¼‰ï¼Œ`y`Â æ˜¯è¾“å‡ºã€‚å®ƒæ˜¯ç¥ç»ç½‘ç»œä¸­æ„å»ºå…¨è¿æ¥å±‚ã€è¾“å…¥è¾“å‡ºå±‚çš„åŸºç¡€ç»„ä»¶ã€‚

![](https://i-blog.csdnimg.cn/direct/c6ad70916eda476db8bb3b84dbb282c5.png)

```
import torch
from torch import nn
torch.random.manual_seed(42)

class F1(nn.Module):
    def __init__(self):
        super().__init__()
        self.softmax=nn.Softmax(-1)
        self.linear=nn.Linear(4,3)
    def forward(self,x):
        return self.softmax(self.linear(x))
    
f=F1()
X=torch.tensor([
    [1.2,2.1,3.3,4.5],
    [2.3,3.4,4.5,5.1]
])

y_pred=f(X)
print(y_pred)
print(f.linear.weight)
print(f.linear.bias)


```

#### 7.å¯†é›†å¼ é‡ä¸ç¨€ç–å¼ é‡çš„åŒºåˆ«

å¯†é›†å¼ é‡å­˜å‚¨å…¨éƒ¨å…ƒç´ ï¼ˆåŒ…æ‹¬å¤§é‡æ— æ„ä¹‰çš„é›¶å€¼ / æ— æ•ˆå€¼ï¼‰ï¼Œç¨€ç–å¼ é‡ä»…å­˜å‚¨ â€œæœ‰æ„ä¹‰çš„éé›¶ / æœ‰æ•ˆå…ƒç´ â€ åŠå…¶ä½ç½®ï¼ŒäºŒè€…é€‚ç”¨äºä¸åŒæ•°æ®åœºæ™¯ã€‚

ç¨€ç–å¼ é‡ï¼š ä¾‹å¦‚ä¸€ä¸ª3Ã—4 çš„è¡¨æ ¼ï¼Œè‹¥åªæœ‰ 2 ä¸ªéé›¶å€¼ï¼Œåªéœ€è®°å½•è¿™ 2 ä¸ªå€¼çš„ â€œè¡Œå·ã€åˆ—å·â€ å’Œ â€œå€¼æœ¬èº«â€ï¼Œæ— éœ€è®°å½•å…¶ä»–é›¶å€¼ã€‚

å¯†é›†å¼ é‡ï¼šæ¯”å¦‚ä¸€ä¸ª 3Ã—4 çš„è¡¨æ ¼ï¼Œå³ä½¿å¤§éƒ¨åˆ†å•å…ƒæ ¼æ˜¯ 0ï¼Œä¹Ÿä¼šæŠŠæ¯ä¸ªå•å…ƒæ ¼çš„å†…å®¹ï¼ˆåŒ…æ‹¬ 0ï¼‰éƒ½è®°å½•ä¸‹æ¥ã€‚

#### 8.TensorFlowï¼ŒPytorchå’ŒTransfromçš„å…³ç³»

TensorFlow å’Œ PyTorch æ˜¯ â€œå¹³è¡Œçš„æ·±åº¦å­¦ä¹ å·¥å…·â€ï¼Œéƒ½èƒ½å°† â€œTransformer è¿™ä¸ªåºåˆ—å»ºæ¨¡æ–¹æ¡ˆâ€ è½¬åŒ–ä¸ºå¯è®­ç»ƒã€å¯è¿è¡Œçš„æ¨¡å‹ï¼›Transformer ä¾èµ–è¿™ä¸¤ä¸ªæ¡†æ¶ï¼ˆæˆ–å…¶ä»–æ¡†æ¶ï¼‰å®ç°ï¼Œè€Œä¸¤ä¸ªæ¡†æ¶åˆ™é€šè¿‡æ”¯æŒ Transformerï¼Œæ‹“å±•äº†è‡ªèº«å¤„ç†åºåˆ—ä»»åŠ¡çš„èƒ½åŠ›ã€‚



