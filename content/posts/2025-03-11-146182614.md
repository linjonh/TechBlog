---
layout: post
title: "Pytortch深度学习网络框架库-torch.no_grad方法-核心原理与使用场景"
date: 2025-03-11 16:40:29 +0800
description: "它通过关闭计算图的构建和梯度跟踪，优化内存使用和计算效率，尤其适用于不需要反向传播的场景。是一个上下文管理器（Context Manager），其作用是禁用在此作用域内所有张量操作的梯度计算。（Computation Graph）跟踪张量的操作链，以便在反向传播时自动计算梯度。通过临时修改 PyTorch 的全局状态，禁用 Autograd 的梯度跟踪机制。，可以在保证功能正确性的同时显著提升模型推理和评估的效率，尤其在资源受限的环境中效果更为明显。，则会记录其操作链并构建计算图。在PyTorch中，"
keywords: "Pytortch深度学习网络框架库 torch.no_grad方法 核心原理与使用场景"
categories: ['未分类']
tags: ['深度学习', '人工智能']
artid: "146182614"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146182614
    alt: "Pytortch深度学习网络框架库-torch.no_grad方法-核心原理与使用场景"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146182614
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146182614
cover: https://bing.ee123.net/img/rand?artid=146182614
image: https://bing.ee123.net/img/rand?artid=146182614
img: https://bing.ee123.net/img/rand?artid=146182614
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Pytortch深度学习网络框架库 torch.no_grad方法 核心原理与使用场景
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     在PyTorch中，
     <code>
      with torch.no_grad()
     </code>
     是一个用于
     <strong>
      临时禁用自动梯度计算
     </strong>
     的上下文管理器。它通过关闭计算图的构建和梯度跟踪，优化内存使用和计算效率，尤其适用于不需要反向传播的场景。以下是其核心含义、作用及使用场景的详细说明：
    </p>
    <hr/>
    <h4>
     <a id="_3">
     </a>
     <strong>
      一、核心原理
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        自动微分机制（Autograd）
       </strong>
       <br/>
       PyTorch 的 Autograd 系统通过
       <strong>
        计算图
       </strong>
       （Computation Graph）跟踪张量的操作链，以便在反向传播时自动计算梯度。每个张量（
       <code>
        torch.Tensor
       </code>
       ）都有一个
       <code>
        requires_grad
       </code>
       属性，若为
       <code>
        True
       </code>
       ，则会记录其操作链并构建计算图。
      </p>
     </li>
     <li>
      <p>
       <strong>
        <code>
         torch.no_grad()
        </code>
        的作用
       </strong>
       <br/>
       <code>
        torch.no_grad()
       </code>
       通过临时修改 PyTorch 的全局状态，禁用 Autograd 的梯度跟踪机制。具体来说：
      </p>
      <ul>
       <li>
        在
        <code>
         torch.no_grad()
        </code>
        作用域内，
        <strong>
         所有新生成的张量的
         <code>
          requires_grad
         </code>
         属性会被强制设为
         <code>
          False
         </code>
        </strong>
        ，即使输入张量原本需要梯度。
       </li>
       <li>
        <strong>
         不会记录操作链
        </strong>
        ，因此不会构建计算图，从而避免反向传播时的梯度累积。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_13">
     </a>
     <strong>
      二、核心定义
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        功能本质
       </strong>
       <br/>
       <code>
        torch.no_grad()
       </code>
       是一个上下文管理器（Context Manager），其作用是禁用在此作用域内所有张量操作的梯度计算。这意味着：
      </p>
      <ul>
       <li>
        所有新生成的张量的
        <code>
         requires_grad
        </code>
        属性会被自动设为
        <code>
         False
        </code>
        ，即使输入张量原本需要梯度。
       </li>
       <li>
        不会构建计算图（Computation Graph），从而避免反向传播时的梯度累积。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        底层机制
       </strong>
      </p>
      <ul>
       <li>
        PyTorch通过跟踪张量的操作链（计算图）实现自动求导。在
        <code>
         torch.no_grad()
        </code>
        环境下，这一跟踪机制被临时关闭。
       </li>
       <li>
        即使对
        <code>
         requires_grad=True
        </code>
        的输入张量进行操作，输出的新张量也不会记录梯度。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_25">
     </a>
     <strong>
      三、主要作用
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        禁用梯度计算
       </strong>
      </p>
      <ul>
       <li>
        在模型评估（Evaluation）或推理（Inference）阶段，禁用梯度可减少不必要的计算图构建，提升性能。
       </li>
       <li>
        示例：验证集前向传播时，仅需输出预测结果，无需计算损失梯度。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        节省内存与加速计算
       </strong>
      </p>
      <ul>
       <li>
        梯度计算需要存储中间结果，禁用后可减少显存占用（尤其在处理大模型或批量数据时）。
       </li>
       <li>
        避免反向传播相关计算，提升前向传播速度（实验显示在某些场景下速度可提升20%-30%）。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        防止梯度干扰
       </strong>
      </p>
      <ul>
       <li>
        在参数初始化、权重手动修改或特定数学运算中，避免意外修改梯度值。
       </li>
       <li>
        示例：直接修改模型权重（如
        <code>
         model.weight.fill_(1.0)
        </code>
        ）时，需禁用梯度以避免破坏计算图。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_40">
     </a>
     <strong>
      四、典型使用场景
     </strong>
    </h4>
    <table>
     <thead>
      <tr>
       <th>
        场景
       </th>
       <th>
        说明
       </th>
       <th>
        示例代码片段
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        <strong>
         模型评估
        </strong>
       </td>
       <td>
        验证/测试阶段仅需前向传播，无需反向传播。
       </td>
       <td>
        <code>
         model.eval()&lt;br&gt;with torch.no_grad():&lt;br&gt; outputs = model(inputs)
        </code>
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         模型推理
        </strong>
       </td>
       <td>
        部署时生成预测结果，不涉及参数更新。
       </td>
       <td>
        <code>
         with torch.no_grad():&lt;br&gt; pred = torch.argmax(model(input), dim=1)
        </code>
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         参数初始化/修改
        </strong>
       </td>
       <td>
        直接操作模型权重时，避免梯度计算干扰。
       </td>
       <td>
        <code>
         with torch.no_grad():&lt;br&gt; model.weight += 0.1 * torch.randn_like(weight)
        </code>
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         数据预处理
        </strong>
       </td>
       <td>
        对输入数据进行非可导变换（如归一化、量化）。
       </td>
       <td>
        <code>
         with torch.no_grad():&lt;br&gt; normalized_data = (data - mean) / std
        </code>
       </td>
      </tr>
     </tbody>
    </table>
    <hr/>
    <h4>
     <a id="_50">
     </a>
     <strong>
      五、注意事项
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        与
        <code>
         model.eval()
        </code>
        的区别
       </strong>
      </p>
      <ul>
       <li>
        <code>
         model.eval()
        </code>
        ：改变模型层的行为（如关闭Dropout、固定BatchNorm统计量），但不影响梯度计算。
       </li>
       <li>
        <code>
         torch.no_grad()
        </code>
        ：仅禁用梯度计算，不改变模型层的运行模式。两者常结合使用。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        原地操作（In-place Operations）
       </strong>
      </p>
      <ul>
       <li>
        在
        <code>
         torch.no_grad()
        </code>
        中修改
        <code>
         requires_grad=True
        </code>
        的叶子张量（如模型参数）时，需谨慎使用原地操作（如
        <code>
         tensor.add_()
        </code>
        ），否则可能破坏梯度链。
       </li>
       <li>
        推荐用法：在非梯度环境中进行参数更新后，手动清零梯度。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        嵌套与作用域
       </strong>
      </p>
      <ul>
       <li>
        <code>
         torch.no_grad()
        </code>
        可嵌套使用，内层作用域依然保持梯度禁用状态。
       </li>
       <li>
        退出作用域后，梯度计算自动恢复，无需额外操作。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        装饰器用法
       </strong>
      </p>
      <ul>
       <li>
        可用
        <code>
         @torch.no_grad()
        </code>
        修饰函数，使整个函数内的操作不跟踪梯度。
        <br/>
        示例：
        <pre><code class="prism language-python"><span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
</code></pre>
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_74">
     </a>
     <strong>
      六、对比其他方法
     </strong>
    </h4>
    <table>
     <thead>
      <tr>
       <th>
        方法
       </th>
       <th>
        特点
       </th>
       <th>
        适用场景
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        <strong>
         <code>
          torch.no_grad()
         </code>
        </strong>
       </td>
       <td>
        临时禁用梯度，作用域内所有操作不跟踪梯度。
       </td>
       <td>
        局部代码块或函数
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         <code>
          torch.set_grad_enabled(False)
         </code>
        </strong>
       </td>
       <td>
        全局关闭梯度计算，需手动恢复。
       </td>
       <td>
        需要长期禁用梯度的复杂逻辑
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         <code>
          detach()
         </code>
        </strong>
       </td>
       <td>
        从计算图中分离单个张量，返回的新张量
        <code>
         requires_grad=False
        </code>
        。
       </td>
       <td>
        仅需隔离特定张量的梯度时
       </td>
      </tr>
     </tbody>
    </table>
    <hr/>
    <h4>
     <a id="_83">
     </a>
     <strong>
      七、代码示例
     </strong>
    </h4>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch

<span class="token comment"># 场景1：模型评估</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        <span class="token comment"># 计算准确率等指标</span>

<span class="token comment"># 场景2：参数初始化</span>
<span class="token keyword">def</span> <span class="token function">init_weights</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            m<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span>
            m<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>init_weights<span class="token punctuation">)</span>

<span class="token comment"># 场景3：装饰器用法</span>
<span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">inference</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
</code></pre>
    <hr/>
    <p>
     通过合理使用
     <code>
      torch.no_grad()
     </code>
     ，可以在保证功能正确性的同时显著提升模型推理和评估的效率，尤其在资源受限的环境中效果更为明显。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f:2f626c6f672e6373646e2e6e65742f7661726461383839392f:61727469636c652f64657461696c732f313436313832363134" class_="artid" style="display:none">
 </p>
</div>


