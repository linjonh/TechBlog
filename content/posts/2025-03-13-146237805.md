---
layout: post
title: "Transformer如何进行图像分类从新手到入门"
date: 2025-03-13 17:43:18 +0800
description: "这篇博客将带你从零开始，了解Transformer的基本概念、它如何被应用到图像分类，以及通过一个简单的例子让你直观理解它的运作原理。假设我们要训练一个模型，区分CIFAR-10数据集中的“猫”和“狗”图片（CIFAR-10是PyTorch内置的一个小型图像数据集，包含10类32x32像素的图像）。让我们看看它是如何工作的。在最后一层，ViT取一个特殊的“分类标记”（CLS Token），通过全连接层输出10个类别的概率（CIFAR-10有10类），比如“猫”的概率是0.8，“狗”是0.1。"
keywords: "《Transformer如何进行图像分类：从新手到入门》"
categories: ['深度学习']
tags: ['深度学习', '图像分类', '分类', 'Transformer']
artid: "146237805"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146237805
    alt: "Transformer如何进行图像分类从新手到入门"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146237805
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146237805
cover: https://bing.ee123.net/img/rand?artid=146237805
image: https://bing.ee123.net/img/rand?artid=146237805
img: https://bing.ee123.net/img/rand?artid=146237805
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     《Transformer如何进行图像分类：从新手到入门》
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="_1">
     </a>
     引言
    </h3>
    <p>
     如果你对人工智能（AI）或深度学习（Deep Learning）感兴趣，可能听说过“Transformer”这个词。它最初在自然语言处理（NLP）领域大放异彩，比如在翻译、聊天机器人和文本生成中表现出色。但你知道吗？Transformer不仅能处理文字，还能用来分类图像！这听起来是不是有点神奇？别担心，这篇博客将带你从零开始，了解Transformer的基本概念、它如何被应用到图像分类，以及通过一个简单的例子让你直观理解它的运作原理。无论你是AI新手还是好奇的技术爱好者，这篇文章都会尽量用通俗的语言为你解锁Transformer的奥秘。
    </p>
    <h3>
     <a id="Transformer_4">
     </a>
     第一部分：Transformer是什么？
    </h3>
    <p>
     Transformer是一种深度学习模型，最早由Vaswani等人在2017年的论文《Attention is All You Need》中提出。它的核心思想是“注意力机制”（Attention Mechanism），这是一种让模型学会“关注”输入中重要部分的能力。传统的模型，比如卷积神经网络（CNN）和循环神经网络（RNN），在处理图像或序列数据时有局限性，而Transformer通过注意力机制突破了这些限制。
    </p>
    <h4>
     <a id="11_Transformer_7">
     </a>
     1.1 为什么叫“Transformer”？
    </h4>
    <p>
     “Transformer”这个名字听起来很酷，但它其实反映了模型的功能：它能将输入数据“转换”（Transform）成更有意义的表示形式。比如，把一句话翻译成另一种语言，或者把一张图片“翻译”成一个分类标签（比如“猫”或“狗”）。它的核心在于通过计算输入数据之间的关系，生成更有用的输出。
    </p>
    <h4>
     <a id="12_Transformer_10">
     </a>
     1.2 Transformer的基本结构
    </h4>
    <p>
     Transformer由两个主要部分组成：编码器（Encoder）和解码器（Decoder）。不过，在图像分类任务中，我们通常只用到编码器部分。让我们简单看看它的组成：
    </p>
    <ul>
     <li>
      输入嵌入（Input Embedding）：把输入数据（比如单词或图像块）转换成数字向量。
     </li>
     <li>
      注意力机制（Attention）：让模型关注输入中最重要的部分。
     </li>
     <li>
      前馈神经网络（Feed-Forward Network）：对数据进一步处理。
     </li>
     <li>
      层归一化和残差连接（Layer Normalization &amp; Residual Connection）：帮助模型稳定训练，避免“梯度消失”等问题。
     </li>
    </ul>
    <p>
     这些组件堆叠在一起，形成多层结构，每一层都让模型对数据的理解更深一层。
    </p>
    <h4>
     <a id="13_Transformer_20">
     </a>
     1.3 注意力机制：Transformer的“超能力”
    </h4>
    <p>
     注意力机制是Transformer的核心。想象你在读一本书，当你看到“猫”这个词时，你会自动想到整句话的上下文，比如“猫在睡觉”还是“猫在跑”。注意力机制让模型也能做到这一点：它会计算输入中每个部分对其他部分的“重要性”，然后根据这些关系调整输出。
    </p>
    <p>
     具体来说，Transformer使用的是“自注意力”（Self-Attention）。它会为输入的每个部分（比如图像的一个小块）生成三个向量：
    </p>
    <ul>
     <li>
      查询（Query）：我想知道什么？
     </li>
     <li>
      键（Key）：我有哪些信息？
     </li>
     <li>
      值（Value）：这些信息有多重要？
     </li>
    </ul>
    <p>
     通过计算查询和键之间的相似度，模型决定每个值的权重，然后把它们加权组合起来。这种方式让Transformer能捕捉全局关系，而不是像CNN那样只关注局部区域。
    </p>
    <h3>
     <a id="NLPVision_Transformer_ViT_31">
     </a>
     第二部分：从NLP到图像分类：Vision Transformer (ViT)
    </h3>
    <p>
     Transformer最初是为NLP设计的，那它是怎么“跨界”到图像分类的呢？这要归功于2020年提出的Vision Transformer（简称ViT）。让我们看看它是如何工作的。
    </p>
    <h4>
     <a id="21_Transformer_34">
     </a>
     2.1 图像怎么变成Transformer的输入？
    </h4>
    <p>
     图像和文字完全不同，对吧？图像是一堆像素，而文字是一串单词。要让Transformer处理图像，第一步就是把图像“翻译”成它能理解的形式。ViT的做法是：
    </p>
    <ol>
     <li>
      切分图像：把一张图片（比如224x224像素）切成固定大小的小块（比如16x16像素），就像把一张大拼图拆成小碎片。
     </li>
     <li>
      展平并嵌入：把每个小块展平成一个向量（就像把拼图碎片摊平），然后通过一个线性层把它们变成嵌入向量（Embedding）。
     </li>
     <li>
      加上位置信息：因为Transformer不像CNN有固定的空间感知能力，我们需要手动告诉它每个小块在图像中的位置。这通过“位置编码”（Positional Encoding）实现。
     </li>
    </ol>
    <p>
     经过这些步骤，一张图像就变成了一个序列（Sequence），就像NLP中的一句话，只不过这里的“单词”是图像块。
    </p>
    <h4>
     <a id="22_Transformer_43">
     </a>
     2.2 Transformer处理图像的过程
    </h4>
    <p>
     一旦图像被转换成序列，Transformer的编码器就开始工作：
    </p>
    <ul>
     <li>
      自注意力：计算每个图像块和其他图像块之间的关系。比如，在一张猫的图片中，耳朵和眼睛的图像块可能会被关联起来。
     </li>
     <li>
      多层堆叠：通过多层编码器，模型逐渐提取更高层次的特征。
      <br/>
      分类头：在最后一层，添加一个简单的分类层（比如全连接层），输出图像的类别（比如“猫”或“狗”）。
     </li>
    </ul>
    <h4>
     <a id="23_ViT_49">
     </a>
     2.3 ViT的优势和挑战
    </h4>
    <p>
     相比传统的CNN，ViT有几个优点：
    </p>
    <ul>
     <li>
      全局视野：它能一次性看到整张图像的关系，而不像CNN只关注局部。
     </li>
     <li>
      灵活性：同一个模型可以轻松处理不同大小的输入。
     </li>
    </ul>
    <p>
     但它也有挑战：
    </p>
    <ul>
     <li>
      计算量大：自注意力机制需要大量计算，尤其当图像块很多时。
     </li>
     <li>
      数据需求高：ViT需要大量标注数据才能训练得好。
     </li>
    </ul>
    <h3>
     <a id="ViT_60">
     </a>
     第三部分：一个简单的例子：用ViT分类猫和狗
    </h3>
    <p>
     为了让新手更容易理解，我们通过一个具体的例子来说明Transformer如何进行图像分类。假设我们要训练一个模型，区分CIFAR-10数据集中的“猫”和“狗”图片（CIFAR-10是PyTorch内置的一个小型图像数据集，包含10类32x32像素的图像）。下面我们逐步拆解过程，并新增代码实现。
    </p>
    <h4>
     <a id="31__63">
     </a>
     3.1 数据准备
    </h4>
    <p>
     CIFAR-10中的每张图片是32x32像素，RGB格式。我们将它切成4x4的小块（为了简化示例），总共有64个块（32 ÷ 4 = 8，8x8 = 64）。每个小块有48个数值（4x4x3，因为RGB有3个通道）。
    </p>
    <h4>
     <a id="32__66">
     </a>
     3.2 嵌入过程
    </h4>
    <ul>
     <li>
      把每个小块展平成一个48维向量。
     </li>
     <li>
      通过一个线性层，把48维映射到一个固定维度（比如32维），得到嵌入向量。
     </li>
     <li>
      加上位置编码，告诉模型每个块的位置。
     </li>
    </ul>
    <p>
     现在，这张图片变成了一个64x32的矩阵，就像一个有64个“单词”的序列。
    </p>
    <h4>
     <a id="33__74">
     </a>
     3.3 自注意力计算
    </h4>
    <p>
     假设猫咪的耳朵在第10个块，眼睛在第20个块。Transformer会：
    </p>
    <ol>
     <li>
      为每个块生成查询、键和值向量。
     </li>
     <li>
      计算第10个块的查询和第20个块的键之间的相似度，发现它们关系密切。
     </li>
     <li>
      根据相似度加权组合值向量，生成一个新的表示。
     </li>
    </ol>
    <p>
     经过多层自注意力，模型学会关联猫的特征。
    </p>
    <h4>
     <a id="34__83">
     </a>
     3.4 分类输出
    </h4>
    <p>
     在最后一层，ViT取一个特殊的“分类标记”（CLS Token），通过全连接层输出10个类别的概率（CIFAR-10有10类），比如“猫”的概率是0.8，“狗”是0.1。
    </p>
    <h4>
     <a id="35__86">
     </a>
     3.5 代码实现
    </h4>
    <p>
     下面我们提供两种代码实现方式，帮助你直观感受ViT的运作。代码基于PyTorch，使用CIFAR-10数据集。
    </p>
    <h5>
     <a id="1ViT_89">
     </a>
     实现方式1：从头实现一个简化的ViT
    </h5>
    <p>
     这个实现简化了ViT的核心组件，适合理解原理。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torchvision
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token comment"># 超参数</span>
patch_size <span class="token operator">=</span> <span class="token number">4</span>  <span class="token comment"># 切分图像为4x4的小块</span>
embed_dim <span class="token operator">=</span> <span class="token number">32</span>  <span class="token comment"># 每个小块的嵌入维度</span>
num_heads <span class="token operator">=</span> <span class="token number">4</span>   <span class="token comment"># 注意力头的数量</span>
num_classes <span class="token operator">=</span> <span class="token number">10</span>  <span class="token comment"># CIFAR-10有10个类别</span>
num_patches <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">32</span> <span class="token operator">//</span> patch_size<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>  <span class="token comment"># 64个小块 (32x32图像)</span>

<span class="token comment"># 数据加载</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
trainset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
trainloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 简化的ViT模型</span>
<span class="token keyword">class</span> <span class="token class-name">SimpleViT</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SimpleViT<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 将图像块映射到嵌入空间</span>
        self<span class="token punctuation">.</span>patch_to_embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>patch_size <span class="token operator">*</span> patch_size <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">,</span> embed_dim<span class="token punctuation">)</span>
        <span class="token comment"># 位置编码</span>
        self<span class="token punctuation">.</span>pos_embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_patches <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> embed_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># CLS Token</span>
        self<span class="token punctuation">.</span>cls_token <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> embed_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># Transformer编码器</span>
        self<span class="token punctuation">.</span>transformer <span class="token operator">=</span> nn<span class="token punctuation">.</span>TransformerEncoder<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>TransformerEncoderLayer<span class="token punctuation">(</span>d_model<span class="token operator">=</span>embed_dim<span class="token punctuation">,</span> nhead<span class="token operator">=</span>num_heads<span class="token punctuation">)</span><span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token comment"># 分类头</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>embed_dim<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w <span class="token operator">=</span> x<span class="token punctuation">.</span>shape  <span class="token comment"># [batch_size, 3, 32, 32]</span>
        <span class="token comment"># 切分成小块并展平</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h <span class="token operator">//</span> patch_size<span class="token punctuation">,</span> patch_size<span class="token punctuation">,</span> w <span class="token operator">//</span> patch_size<span class="token punctuation">,</span> patch_size<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># [b, 8, 8, 3, 4, 4]</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> num_patches<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># [b, 64, 48]</span>
        <span class="token comment"># 映射到嵌入空间</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>patch_to_embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># [b, 64, 32]</span>
        <span class="token comment"># 添加CLS Token</span>
        cls_tokens <span class="token operator">=</span> self<span class="token punctuation">.</span>cls_token<span class="token punctuation">.</span>expand<span class="token punctuation">(</span>b<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># [b, 1, 32]</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>cls_tokens<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># [b, 65, 32]</span>
        <span class="token comment"># 加上位置编码</span>
        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>pos_embedding
        <span class="token comment"># 通过Transformer</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>transformer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># [b, 65, 32]</span>
        <span class="token comment"># 取CLS Token的输出进行分类</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># [b, 10]</span>
        <span class="token keyword">return</span> x

<span class="token comment"># 训练模型</span>
model <span class="token operator">=</span> SimpleViT<span class="token punctuation">(</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 训练5个epoch</span>
    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> trainloader<span class="token punctuation">:</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">, Loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

</code></pre>
    <p>
     代码解释：
    </p>
    <ul>
     <li>
      数据加载：从CIFAR-10加载32x32的图像，归一化处理。
     </li>
     <li>
      图像切分：将32x32图像切成64个4x4的小块，展平后映射到32维嵌入。
     </li>
     <li>
      CLS Token：添加一个特殊标记，用于最终分类。
     </li>
     <li>
      Transformer：使用PyTorch内置的Transformer编码器，包含2层，每层有4个注意力头。
     </li>
     <li>
      训练：简单训练5个epoch，优化分类损失。
     </li>
    </ul>
    <h5>
     <a id="2ViTHugging_Face_170">
     </a>
     实现方式2：使用预训练ViT模型（Hugging Face）
    </h5>
    <p>
     这个实现利用Hugging Face的预训练ViT模型，适合快速上手。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> ViTFeatureExtractor<span class="token punctuation">,</span> ViTForImageClassification
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> transforms
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token comment"># 数据加载</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># ViT需要224x224输入</span>
    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
trainset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
trainloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 加载预训练ViT模型和特征提取器</span>
feature_extractor <span class="token operator">=</span> ViTFeatureExtractor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'google/vit-base-patch16-224'</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> ViTForImageClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'google/vit-base-patch16-224'</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>classifier <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>model<span class="token punctuation">.</span>classifier<span class="token punctuation">.</span>in_features<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># 修改分类头为10类</span>

<span class="token comment"># 训练设置</span>
criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 训练3个epoch</span>
    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> trainloader<span class="token punctuation">:</span>
        inputs <span class="token operator">=</span> feature_extractor<span class="token punctuation">(</span>images<span class="token operator">=</span><span class="token punctuation">[</span>img<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> img <span class="token keyword">in</span> images<span class="token punctuation">]</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
        inputs <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>k<span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> inputs<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>  <span class="token comment"># 转换为模型输入格式</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span><span class="token punctuation">.</span>logits  <span class="token comment"># 获取分类输出</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">, Loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

</code></pre>
    <p>
     代码解释：
    </p>
    <ul>
     <li>
      数据预处理：将CIFAR-10图像调整到224x224（ViT预训练模型的要求）。
     </li>
     <li>
      预训练模型：加载Google的vit-base-patch16-224，替换分类头为10类。
     </li>
     <li>
      特征提取器：自动处理图像输入，切分并嵌入。
     </li>
     <li>
      训练：微调模型，适应CIFAR-10任务。
     </li>
    </ul>
    <p>
     <mark>
      注意：运行第二种方式需要安装transformers库（pip install transformers）。
     </mark>
    </p>
    <h3>
     <a id="_219">
     </a>
     第四部分：新手常见问题解答
    </h3>
    <h4>
     <a id="41_TransformerCNN_220">
     </a>
     4.1 Transformer和CNN有什么不同？
    </h4>
    <p>
     CNN像一个放大镜，逐步扫描图像的局部特征；而Transformer像一个全景相机，一次性捕捉全局关系。两者各有千秋，ViT证明了Transformer也能在图像任务中大放异彩。
    </p>
    <h4>
     <a id="42_Transformer_223">
     </a>
     4.2 我需要多强的编程基础才能用Transformer？
    </h4>
    <p>
     好消息是，你不需要从头写Transformer！开源工具（如PyTorch和Hugging Face）提供了预训练模型。你只需要学会加载模型、准备数据和微调，就能上手。
    </p>
    <h4>
     <a id="43_ViT_226">
     </a>
     4.3 ViT适合所有图像任务吗？
    </h4>
    <p>
     不完全是。ViT在大数据集（如ImageNet）上表现很好，但在小数据集或需要精细局部特征的任务上，CNN可能更合适。
    </p>
    <h3>
     <a id="_229">
     </a>
     第五部分
    </h3>
    <p>
     Transformer通过注意力机制和全局视野，为图像分类带来了新思路。Vision Transformer（ViT）展示了它如何将图像切分成块，像处理句子一样处理图片，最终实现分类。对于新手来说，理解它的关键在于：
    </p>
    <ol>
     <li>
      图像如何变成序列。
     </li>
     <li>
      自注意力如何捕捉关系。
     </li>
     <li>
      分类如何通过简单输出实现。
     </li>
    </ol>
    <p>
     通过上面的代码示例，你可以看到：
    </p>
    <ul>
     <li>
      从头实现ViT帮助理解原理。
     </li>
     <li>
      使用预训练模型能快速应用到实际任务。
     </li>
    </ul>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f323330325f37393330383038322f:61727469636c652f64657461696c732f313436323337383035" class_="artid" style="display:none">
 </p>
</div>


