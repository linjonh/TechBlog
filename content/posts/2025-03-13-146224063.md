---
arturl_encode: "6874747073:3a2f2f626c6f672e6373646e2e6e65742f73756e79616f782f:61727469636c652f64657461696c732f313436323234303633"
layout: post
title: "编程助手学Python-Deepseek对Langchain的调用OpenAI的GPT-3.5模型起名字与格式化输出"
date: 2025-03-13 10:22:42 +08:00
description: "自定义的输出解析器，继承自。parse方法text（字符串）。功能：打印文本内容，并将文本按逗号分隔成列表。返回：分隔后的列表。功能：代码实现了一个基于 OpenAI 模型的起名服务，生成 5 个名字并以逗号分隔的形式返回。关键点使用创建动态提示。通过调用模型生成文本。"
keywords: "编程助手学Python--Deepseek对Langchain的调用OpenAI的GPT-3.5模型起名字与格式化输出"
categories: ['编程助手学Python']
tags: ['Python', 'Langchain', '3']
artid: "146224063"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146224063
    alt: "编程助手学Python-Deepseek对Langchain的调用OpenAI的GPT-3.5模型起名字与格式化输出"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146224063
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146224063
cover: https://bing.ee123.net/img/rand?artid=146224063
image: https://bing.ee123.net/img/rand?artid=146224063
img: https://bing.ee123.net/img/rand?artid=146224063
---

# 编程助手学Python--Deepseek对Langchain的调用OpenAI的GPT-3.5模型起名字与格式化输出

```python
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.schema import BaseOutputParser
import os


class CommaSeparatedListOutPutParser(BaseOutputParser):
    def parse(self, text:str):
        print(text)
        return text.strip().split(",")
    

os.environ["OPENAI_API_KEY"] = "sk-xx"
os.environ["OPENAI_API_BASE"] = "https://ai.com/v1"

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_API_BASE = os.getenv("OPENAI_API_BASE")
print(OPENAI_API_KEY)
print(OPENAI_API_BASE)
llm = OpenAI(
    model="gpt-3.5-turbo-instruct",
    temperature=0,
    openai_api_key=OPENAI_API_KEY,
    openai_api_base=OPENAI_API_BASE
)

prompt = PromptTemplate.from_template("你是一名起名老师，你的客户是一位新生儿的父母，他们想要给自己的孩子起一个名字。请你为他们提供{num}个名字,请返回以逗号分隔的列表形式。仅返回逗号分隔的列表，不要返回其他内容。")
message = prompt.format(num=5)
res = llm.predict(message)
print(res)   详细解释

```

* 以下是对代码的详细解释，包括每个部分的功能、实现逻辑以及代码的作用：

  ---

  #### 1. 导入库

  ```python
  from langchain.llms import OpenAI
  from langchain.prompts import PromptTemplate
  from langchain.schema import BaseOutputParser
  import os

  ```

  + **`langchain.llms`**
    ：
    `langchain`
    是一个用于构建基于大语言模型（LLM）应用的框架。
    `OpenAI`
    是
    `langchain`
    中用于与 OpenAI 模型交互的类。
  + **`langchain.prompts`**
    ：提供了
    `PromptTemplate`
    类，用于创建和管理提示模板。
  + **`langchain.schema`**
    ：提供了
    `BaseOutputParser`
    类，用于解析模型输出。
  + **`os`**
    ：Python 标准库，用于与操作系统交互，例如读取环境变量。

  ---

  #### 2. 自定义输出解析器

  ```python
  class CommaSeparatedListOutPutParser(BaseOutputParser):
      def parse(self, text: str):
          print(text)
          return text.strip().split(",")

  ```

  + **`CommaSeparatedListOutPutParser`**
    ：自定义的输出解析器，继承自
    `BaseOutputParser`
    。
  + **`parse`
    方法**
    ：
    - 输入：
      `text`
      （字符串）。
    - 功能：打印文本内容，并将文本按逗号分隔成列表。
    - 返回：分隔后的列表。

  ---

  #### 3. 设置环境变量

  ```python
  os.environ["OPENAI_API_KEY"] = "sk-xx"
  os.environ["OPENAI_API_BASE"] = "https://ai.com/v1"

  ```

  + **`os.environ`**
    ：用于设置或读取环境变量。
  + **`OPENAI_API_KEY`**
    ：OpenAI API 的密钥，用于身份验证。
    `"sk-xx"`
    是示例密钥，实际使用时需要替换为有效的 API 密钥。
  + **`OPENAI_API_BASE`**
    ：OpenAI API 的基础 URL。这里设置为
    `"https://ai.com/v1"`
    ，可能是自定义的 API 端点（例如，使用代理或本地部署的 OpenAI 兼容服务）。

  ---

  #### 4. 读取环境变量

  ```python
  OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
  OPENAI_API_BASE = os.getenv("OPENAI_API_BASE")
  print(OPENAI_API_KEY)
  print(OPENAI_API_BASE)

  ```

  + **`os.getenv`**
    ：从环境变量中读取值。
  + **`OPENAI_API_KEY`
    和
    `OPENAI_API_BASE`**
    ：分别存储 API 密钥和 API 基础 URL。
  + **`print`**
    ：输出这两个变量的值，用于调试或验证。

  ---

  #### 5. 初始化 OpenAI LLM 对象

  ```python
  llm = OpenAI(
      model="gpt-3.5-turbo-instruct",
      temperature=0,
      openai_api_key=OPENAI_API_KEY,
      openai_api_base=OPENAI_API_BASE
  )

  ```

  + **`OpenAI`**
    ：
    `langchain`
    提供的类，用于与 OpenAI 模型交互。
  + **参数说明**
    ：
    - **`model`**
      ：指定使用的模型，这里是
      `"gpt-3.5-turbo-instruct"`
      ，适用于指令类任务。
    - **`temperature`**
      ：控制生成文本的随机性。
      `0`
      表示完全确定性输出，适合需要精确答案的任务。
    - **`openai_api_key`**
      ：API 密钥，这里正确使用了
      `OPENAI_API_KEY`
      变量。
    - **`openai_api_base`**
      ：API 基础 URL，这里正确使用了
      `OPENAI_API_BASE`
      变量。

  ---

  #### 6. 创建提示模板并生成提示

  ```python
  prompt = PromptTemplate.from_template("你是一名起名老师，你的客户是一位新生儿的父母，他们想要给自己的孩子起一个名字。请你为他们提供{num}个名字,请返回以逗号分隔的列表形式。仅返回逗号分隔的列表，不要返回其他内容。")
  message = prompt.format(num=5)

  ```

  + **`PromptTemplate.from_template`**
    ：创建一个提示模板，模板中包含一个占位符
    `{num}`
    。
  + **`prompt.format(num=5)`**
    ：将占位符
    `{num}`
    替换为
    `5`
    ，生成最终的提示文本。

  ---

  #### 7. 调用模型生成文本

  ```python
  res = llm.predict(message)
  print(res)

  ```

  + **`llm.predict`**
    ：调用
    `OpenAI`
    对象的
    `predict`
    方法，向模型发送提示文本，并返回生成的文本。
  + **`print(res)`**
    ：输出模型的生成结果。

  ---

  #### 8. 代码运行结果

  假设模型返回的结果是：

  ```python
  张伟,李娜,王芳,刘洋,赵敏

  ```

  输出将是：

  ```python
  张伟,李娜,王芳,刘洋,赵敏

  ```

  ---

  #### 9. 代码总结

  + **功能**
    ：代码实现了一个基于 OpenAI 模型的起名服务，生成 5 个名字并以逗号分隔的形式返回。
  + **关键点**
    ：
    - 使用
      `PromptTemplate`
      创建动态提示。
    - 通过
      `llm.predict`
      调用模型生成文本。

  ---

  #### 10. 改进建议

  1. **错误处理**
     ：

     + 在调用模型时，可以添加错误处理逻辑，防止因网络问题或 API 调用失败而导致程序崩溃。
     + 示例：

       ```python
       try:
           res = llm.predict(message)
       except Exception as e:
           print("模型调用失败:", e)
           res = ""

       ```
  2. **安全性**
     ：

     + 避免将 API 密钥硬编码在代码中，建议通过环境变量或配置文件管理密钥。
  3. **扩展性**
     ：

     + 可以将提示模板和模型调用封装成函数，方便复用和扩展。

  ---

  #### 修正后的完整代码

  ```python
  from langchain.llms import OpenAI
  from langchain.prompts import PromptTemplate
  from langchain.schema import BaseOutputParser
  import os


  class CommaSeparatedListOutPutParser(BaseOutputParser):
      def parse(self, text: str):
          print("模型输出:", text)
          return text.strip().split(",")


  # 设置环境变量
  os.environ["OPENAI_API_KEY"] = "sk-xx"
  os.environ["OPENAI_API_BASE"] = "https://ai.com/v1"

  # 读取环境变量
  OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
  OPENAI_API_BASE = os.getenv("OPENAI_API_BASE")
  print("API Key:", OPENAI_API_KEY)
  print("API Base:", OPENAI_API_BASE)

  # 初始化 OpenAI LLM 对象
  llm = OpenAI(
      model="gpt-3.5-turbo-instruct",
      temperature=0,
      openai_api_key=OPENAI_API_KEY,
      openai_api_base=OPENAI_API_BASE
  )

  # 创建提示模板并生成提示
  prompt = PromptTemplate.from_template(
      "你是一名起名老师，你的客户是一位新生儿的父母，他们想要给自己的孩子起一个名字。请你为他们提供{num}个名字,请返回以逗号分隔的列表形式。仅返回逗号分隔的列表，不要返回其他内容。"
  )
  message = prompt.format(num=5)

  # 调用模型生成文本
  try:
      res = llm.predict(message)
      print("模型生成结果:", res)
  except Exception as e:
      print("模型调用失败:", e)
      res = ""

  ```