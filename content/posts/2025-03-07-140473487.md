---
layout: post
title: "Python-机器学习中最常用的超参数及使用示例"
date: 2025-03-07 22:03:48 +0800
description: "这些超参数的选择通常依赖于具体问题、数据集的特性以及模型的类型。超参数调优是一个迭代的过程，通常需要多次实验来找到最佳的参数组合。"
keywords: "常用的learning rate"
categories: ['机器学习', 'Python']
tags: ['机器学习', 'Python']
artid: "140473487"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=140473487
    alt: "Python-机器学习中最常用的超参数及使用示例"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=140473487
featuredImagePreview: https://bing.ee123.net/img/rand?artid=140473487
cover: https://bing.ee123.net/img/rand?artid=140473487
image: https://bing.ee123.net/img/rand?artid=140473487
img: https://bing.ee123.net/img/rand?artid=140473487
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Python | 机器学习中最常用的超参数及使用示例
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     在机器学习中，超参数是用于控制机器学习模型训练过程的外部配置。它们是在训练开始之前配置的设置参数，并在整个过程中保持不变。您应该了解一些常用于优化机器学习模型的超参数。本文将带您了解机器学习中最常用的超参数以及如何在Python中使用它们。
    </p>
    <h4>
     <a id="_3">
     </a>
     机器学习中最常用的超参数
    </h4>
    <p>
     下面是你应该知道的机器学习中最常用的超参数列表：
    </p>
    <ol>
     <li>
      Learning Rate - 学习率
     </li>
     <li>
      Number of Epochs - “迭代次数"或"训练轮数”
     </li>
     <li>
      Batch Size - 批量大小
     </li>
     <li>
      Regularization Parameter - 正则化参数
     </li>
     <li>
      Max Depth - 最大深度
     </li>
     <li>
      Number of Trees (n_estimators) - 树的个数
     </li>
    </ol>
    <p>
     现在，让我们详细了解所有这些最常用的超参数，以及如何在Python中使用它们。
    </p>
    <h4>
     <a id="1_Learning_Rate___17">
     </a>
     1. Learning Rate - 学习率
    </h4>
    <p>
     学习率是一个超参数，它控制着模型在训练过程中优化参数时所采取的步骤的大小。它本质上决定了模型从数据中学习的速度或速度。学习率对于任何基于梯度的优化算法都是至关重要的，特别是在神经网络和深度学习模型中。它总是在训练阶段使用，以基于损失函数的梯度迭代地调整模型的权重。
    </p>
    <p>
     学习率通常是一个小的正值，通常在0.0001到1的范围内。常用的值有：
    </p>
    <ul>
     <li>
      0.0001
     </li>
     <li>
      0.001
     </li>
     <li>
      0.01
     </li>
     <li>
      0.1
     </li>
    </ul>
    <p>
     最佳学习率可以根据特定的模型、数据集和问题而变化。它通常通过实验或使用超参数调优方法（如网格搜索或随机搜索）找到。下面是如何在使用神经网络架构时使用此参数的示例：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>optimizers <span class="token keyword">import</span> Adam
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># hypothetical data</span>
X_train <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># model</span>
model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> input_dim<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># compile with a specific learning rate</span>
optimizer <span class="token operator">=</span> Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="2_Number_of_Epochs___52">
     </a>
     2. Number of Epochs - 迭代次数
    </h4>
    <p>
     epochs的数量是一个超参数，它定义了在训练过程中通过整个训练数据集的完整次数。在每个时期，模型根据训练数据学习和更新其权重。epoch越多，模型从数据中学习的越多，尽管如果epoch的数量太高，则存在过拟合的风险。
    </p>
    <p>
     epochs的数量在训练神经网络和其他迭代算法中特别重要，其中模型随着每个epoch而逐渐改进。找到一个平衡点是至关重要的：太少的时期可能导致欠拟合（模型没有学习足够的知识），而太多的时期可能导致过拟合（模型已经学习了太多，包括噪音）。
    </p>
    <p>
     epoch的最佳数量取决于具体问题、模型的复杂性和数据集的大小。epoch的常见范围和值为：
    </p>
    <ul>
     <li>
      10 - 50 epoch：通常用于较简单的模型或训练时间受限的情况。
     </li>
     <li>
      50 - 200 epoch：适用于中等复杂的模型和中等规模的数据集。
     </li>
     <li>
      200 - 1000+ epoch：用于更复杂的模型，如深度神经网络和更大的数据集。
     </li>
    </ul>
    <p>
     下面是一个使用Python使用这个超参数的例子：
    </p>
    <pre><code class="prism language-python">model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="3_Batch_Size___71">
     </a>
     3. Batch Size - 批量大小
    </h4>
    <p>
     在上面的代码中，你可以看到也使用了批量大小超参数。批量大小是一个超参数，它定义了在一次迭代中用于更新模型参数的训练样本的数量。在训练过程中，不是一次处理整个数据集（这是计算密集型的），而是将数据集划分为较小的批次。模型在每个批次之后更新其权重。
    </p>
    <p>
     批量大小在训练神经网络和其他迭代算法中至关重要，其中模型是逐步更新的，而不是一次全部更新。影响训练的速度和稳定性。
    </p>
    <p>
     最佳批处理大小取决于数据集、模型和可用的计算资源。批量的常见范围和值为：
    </p>
    <ul>
     <li>
      1 - 32：通常用于小数据集或内存受限时。
     </li>
     <li>
      32 - 128：适合于内存使用和计算效率之间的平衡。
     </li>
     <li>
      128 - 1024+：用于大型数据集，并且有足够的内存来处理更大的批处理。
     </li>
    </ul>
    <h4>
     <a id="4_Regularization_Parameter___84">
     </a>
     4. Regularization Parameter - 正则化参数
    </h4>
    <p>
     正则化参数通常表示为lambda（λ）或alpha（α），是一个超参数，用于通过向损失函数添加惩罚来防止过拟合。这种惩罚阻止了模型拟合训练数据中的噪声，从而提高了模型对未知数据的泛化能力。
    </p>
    <p>
     正则化技术通常包括L1正则化（Lasso），L2正则化（Ridge）或两者的组合（Elastic Net）：
    </p>
    <ul>
     <li>
      L1正则化（Lasso）：将系数的绝对值作为惩罚项添加到损失函数中。
     </li>
     <li>
      L2正则化（岭）：将系数的平方值作为惩罚项添加到损失函数中。
     </li>
     <li>
      Elastic Net：合并L1和L2惩罚。
     </li>
    </ul>
    <p>
     当训练容易过拟合的模型时，正则化参数至关重要，特别是在高维空间或有噪声的数据中。它通常用于回归模型，神经网络和支持向量机。
    </p>
    <p>
     正则化参数的最佳值取决于数据集和具体问题。正则化参数的常见范围和值是：
    </p>
    <ul>
     <li>
      0 - 0.1：通常用于轻度正则化，以允许模型更紧密地拟合数据，但有轻微的惩罚以防止过度拟合。
     </li>
     <li>
      0.1 - 1：适合适度正则化，以平衡拟合和惩罚，从而提高泛化能力。
     </li>
     <li>
      1 - 10：用于强正则化，这显著限制了模型的复杂性，可以帮助处理非常嘈杂的数据或高维数据集。
     </li>
    </ul>
    <p>
     下面是在Python中使用此参数的示例：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> Ridge

model <span class="token operator">=</span> Ridge<span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="5_Max_Depth___112">
     </a>
     5. Max Depth - 最大深度
    </h4>
    <p>
     决策树和基于树的集成方法中的最大深度参数控制树的最大深度。树的深度是从根节点到叶节点的最长路径。限制最大深度有助于通过限制树的复杂性来防止过拟合。较浅的树捕获较少的细节并更好地概括，而较深的树捕获更多的细节并有过度拟合训练数据的风险。
    </p>
    <p>
     在使用决策树和基于树的集成方法（如随机森林，梯度提升，XGBoost，LightGBM和CatBoost）时，最大深度至关重要。它有助于控制模型的复杂性并提高泛化能力。
    </p>
    <p>
     最大深度的最佳值取决于数据集和特定问题。最大深度的常见范围和值为：
    </p>
    <ul>
     <li>
      1 - 10：适用于较简单的数据集或需要高级别泛化的情况。
     </li>
     <li>
      10 - 30：适合中等复杂的数据集。
     </li>
     <li>
      30 - 100：用于非常复杂的数据集，但需要小心避免过度拟合。
     </li>
    </ul>
    <p>
     以下是如何在决策树分类器中设置最大深度：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier

<span class="token comment"># example dataset</span>
X_train <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>

<span class="token comment"># define the model with max depth</span>
model <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>max_depth<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="6_Number_of_Trees_n_estimators___138">
     </a>
     6. Number of Trees (n_estimators) - 树的个数
    </h4>
    <p>
     树的数量或n_estimators是一个超参数，用于集成方法，如Random Forest，Gradient Boosting Machines，XGBoost，LightGBM和CatBoost。它指定要在集合中生长的单个树的数量。每棵树都有助于最终的预测，增加树的数量通常会通过减少方差和防止过拟合来提高模型性能。然而，它也增加了计算成本和训练时间。
    </p>
    <p>
     树的数量在集成方法中至关重要，因为它直接影响模型的泛化能力和鲁棒性。增加树的数量通常会提高性能，但存在一个收益递减点，即额外的树提供的收益最小。
    </p>
    <p>
     树的最佳数量取决于数据集和具体问题。n_estimators的常见范围和值为：
    </p>
    <ul>
     <li>
      10 - 100：适用于较简单的模型或计算资源有限的情况。
     </li>
     <li>
      100 - 500：通常是性能和计算成本之间的良好平衡。
     </li>
     <li>
      500 - 1000+：用于更复杂的数据集或需要更高精度时。
     </li>
    </ul>
    <p>
     以下是如何在随机森林分类器中设置n_estimators：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier

<span class="token comment"># define the model with a specified number of trees</span>
model <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="_162">
     </a>
     总结
    </h4>
    <p>
     这些超参数的选择通常依赖于具体问题、数据集的特性以及模型的类型。超参数调优是一个迭代的过程，通常需要多次实验来找到最佳的参数组合。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34323033343539302f:61727469636c652f64657461696c732f313430343733343837" class_="artid" style="display:none">
 </p>
</div>


