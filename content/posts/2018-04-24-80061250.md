---
layout: post
title: "详解音视频直播中的低延时"
date: 2018-04-24 10:49:36 +0800
description: "高泽华，声网 Agora 音频工匠，先后在中磊电子、士兰微电子、虹软科技主导音频项目。任职 YY 期"
keywords: "音视频中的选择低延迟编码配置"
categories: ['行业深度']
tags: ['音视频开发', '低延时']
artid: "80061250"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=80061250
    alt: "详解音视频直播中的低延时"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=80061250
featuredImagePreview: https://bing.ee123.net/img/rand?artid=80061250
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     详解音视频直播中的低延时
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <blockquote>
     <p>
      <em>
       高泽华，声网 Agora 音频工匠，先后在中磊电子、士兰微电子、虹软科技主导音频项目。任职 YY 期间负责语音音频技术工作。在音乐、语音编解码方面有超过十年的研发经验。
      </em>
     </p>
    </blockquote>
    <p>
     音视频实时通讯的应用场景已经随处可见，从“吃鸡”的语音对讲、直播连麦、直播答题组队开黑，再到银行视频开户等。对于开发者来讲，除了关注如何能快速实现不同应用场景重点额音视频通讯，另一个更需要关注的可能就是“低延时”。但是，到底实时音视频传输延时应该如何“低”，才能满足你的应用场景呢？
    </p>
    <h3>
     <a id="_4">
     </a>
     延时的产生与优化
    </h3>
    <p>
     在聊低延时之前，我们先要讲清延时是如何产生的。由于音视频的传输路径一样，我们可以通过一张图来说明延时的产生:
    </p>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/23/162f120b7e279b5e?w=1494&amp;h=538&amp;f=png&amp;s=74786"/>
    </p>
    <p>
     在音视频传输过程中，在不同阶段都会产生延时。总体可以分为三类：
    </p>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/23/162f122572409a19?w=1290&amp;h=452&amp;f=png&amp;s=92929"/>
    </p>
    <h4>
     <a id="T1_15">
     </a>
     T1：设备端上的延时
    </h4>
    <p>
     音视频数据在设备端上产生延时还可以细分。设备端上的延时主要与硬件性能、采用的编解码算法、音视频数据量相关，设备端上的延时可达到 30~200ms，甚至更高。如上表所示，音频与视频分别在采集端或播放端产生延时的过程基本相同，但产生延时的原因不同。
    </p>
    <p>
     <strong>
      音频在设备端上的延时：
     </strong>
    </p>
    <ul>
     <li>
      <p>
       音频采集延时：采集后的音频首先会经过声卡进行信号转换，声卡本身会产生延时，比如 M-Audio 声卡设备延迟 1ms，艾肯声卡设备延迟约为 37ms；
      </p>
     </li>
     <li>
      <p>
       编解码延时：随后音频进入前处理、编码的阶段，如果采用 OPUS 标准编码，最低算法延时大约需要 2.5~60ms；
      </p>
     </li>
     <li>
      <p>
       音频播放延时：这部分延时与播放端硬件性能相关。
      </p>
     </li>
     <li>
      <p>
       音频处理延时：前后处理，包括 AEC，ANS，AGC 等前后处理算法都会带来算法延时，通常这里的延时就是滤波器阶数。在 10ms 以内。
      </p>
     </li>
     <li>
      <p>
       端网络延时：这部分延时主要出现在解码之前的 jitter buffer 内，如果在抗丢包处理中，增加了重传算法和前向纠错算法，这里的延时一般在 20ms 到 200ms 左右。但是受到 jitter buffer 影响，可能会更高。
      </p>
     </li>
    </ul>
    <p>
     <strong>
      视频在设备端上的延时：
     </strong>
    </p>
    <ul>
     <li>
      <p>
       采集延时：采集时会遇到成像延迟，主要由 CCD 相关硬件产生，市面上较好的 CCD 一秒可达 50 帧，成像延时约为 20ms，如果是一秒 20~25 帧的 CCD，会产生 40~50ms 的延时；
      </p>
     </li>
     <li>
      <p>
       编解码延时：以 H.264 为例，它包含 I、P、B 三种帧（下文会详细分析），如果是每秒 30 帧相连帧，且不包括 B 帧（由于 B 帧的解码依赖前后视频帧会增加延迟），采集的一帧数据可能直接进入编码器，没有 B 帧时，编码的帧延时可以忽略不计，但如果有 B 帧，会带来算法延时。
      </p>
     </li>
     <li>
      <p>
       视频渲染延时：一般情况下渲染延时非常小，但是它也会受到系统性能、音画同步的影响而增大。
      </p>
     </li>
     <li>
      <p>
       端网络延时：与音频一样，视频也会遇到端网络延时。
      </p>
     </li>
    </ul>
    <p>
     另外，在设备端，CPU、缓存通常会同时处理来自多个应用、外接设备的请求，如果某个问题设备的请求占用了 CPU，会导致音视频的处理请求出现延时。以音频为例，当出现该状况时，CPU 可能无法及时填充音频缓冲区，音频会出现卡顿。所以设备整体的性能，也会影响音视频采集、编解码与播放的延时。
    </p>
    <h4>
     <a id="T2_43">
     </a>
     T2：端与服务器间的延时
    </h4>
    <p>
     影响采集端与服务器、服务器与播放端的延时的有以下主几个因素：客户端同服务间的物理距离、客户端和服务器的网络运营商、终端网络的网速、负载和网络类型等。如果服务器就近部署在服务区域、服务器与客户端的网络运营商一致时，影响上下行网络延时的主要因素就是终端网络的负载和网络类型。一般来说，无线网络环境下的传输延时波动较大，传输延时通常在 10~100ms 不定。而有线宽带网络下，同城的传输延时能较稳定的低至 5ms~10ms。但是在国内有很多中小运营商，以及一些交叉的网络环境、跨国传输，那么延时会更高。
    </p>
    <h4>
     <a id="T3_47">
     </a>
     T3：服务器间的延时
    </h4>
    <p>
     在此我们要要考虑两种情况，第一种，两端都连接着同一个边缘节点，那么作为最优路径，数据直接通过边缘节点进行转发至播放端；第二种，采集端与播放端并不在同一个边缘节点覆盖范围内，那么数据会经由“靠近”采集端的边缘节点传输至主干网络，然后再发送至“靠近”播放端的边缘节点，但这时服务器之间的传输、排队还会产生延时。仅以骨干网络来讲，数据传输从黑龙江到广州大约需要 30ms，从上海到洛杉矶大约需要 110ms~130ms。
    </p>
    <p>
     在实际情况下，我们为了解决网络不佳、网络抖动，会在采集设备端、服务器、播放端增设缓冲策略。一旦触发缓冲策略就会产生延时。如果卡顿情况多，延时会慢慢积累。要解决卡顿、积累延时，就需要优化整个网络状况。
    </p>
    <p>
     综上所述，由于音视频在采集与播放端上的延时取决于硬件性能、编解码内核的优化，不同设备，表现不同。所以通常市面上常见的“端到端延时”指的是 T2+T3。
    </p>
    <h3>
     <a id="_55">
     </a>
     延时低≠通话质量可靠
    </h3>
    <p>
     不论是教育、社交、金融，还是其它场景下，大家在开发产品时可能会认为“低延时”一定就是最好的选择。但有时，这种“追求极致”也是陷入误区的表现，低延时不一定意味着通讯质量可靠。由于音频与视频本质上的差异，我们需要分别来讲实时音频、视频的通讯质量与延时之间的关系。
    </p>
    <h4>
     <a id="_59">
     </a>
     音频质量与延时
    </h4>
    <p>
     <img alt="音频采样示意图" src="https://user-gold-cdn.xitu.io/2018/4/23/162f14441d51d1b5?w=3116&amp;h=1449&amp;f=png&amp;s=121683"/>
    </p>
    <p>
     影响实时音频通讯质量的因素包括：音频采样率、码率、延时。音频信息其实就是一段以时间为横轴的正弦波，它是一段连续的信号（如上图）。
    </p>
    <p>
     采样率：是每秒从连续信号中提取并组成离散信号的采样个数。采样率越高，音频听起来越接近真实声音。
    </p>
    <p>
     码率：它描述了单位时间长度的媒体内容需要空间。码率越高，意味着每个采样的信息量就越大，对这个采样的描述就越精确，音质越好。
    </p>
    <p>
     假设网络状态稳定不变，那么采样率越高、码率越高，音质就越好，但是相应单个采样信息量就越大，那么传输时间可能会相对更长。
    </p>
    <p>
     对照我们之前的公式，如果想要达到低延时，那么可以提高网络传输效率，比如提高带宽、网络速度，这在实验室环境下可以轻易实现。但放到生活环境中，弱网、中小运营商等不可控的问题必定会影响网络传输效率，最后结果就是通讯质量没有保障。还有一种方法，就是降低码率，那么会损失音质。
    </p>
    <h4>
     <a id="_74">
     </a>
     视频质量与延时
    </h4>
    <p>
     影响实时视频质量的因素包括：码率、帧率、分辨率、延时。其中视频的码率与音频码率相似，是指单位时间传输的数据位数。码率越大，画面细节信息越丰富，视频文件体积越大。
    </p>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/23/162f145414885f3c?w=640&amp;h=479&amp;f=jpeg&amp;s=23697"/>
    </p>
    <p>
     **帧：**正如大家所知，视频由一帧帧图像组成，如上图所示为 H.264 标准下的视频帧。它以 I 帧、P 帧、B 帧组成的 GOP 分组来表示图像画面（如下图）：I 帧是关键帧，带有图像全部信息；P 帧是预测编码帧，表示与当前与前一帧（I 或 P 帧）之间的差别；B 帧是双向预测编码帧，记录本帧与前后帧的差别。
    </p>
    <p>
     **帧率：**它是指每秒钟刷新的图像帧数。它直接影响视频的流畅度，帧率越大，视频越流畅。由于人类眼睛与大脑处理图像信息非常快，当帧率高于 24fps 时，画面看起来是连贯的，但这只是一个起步值。在游戏场景下，帧率小于 30fps 就会让人感到画面不流畅，当提升到 60fps 时会带来更实时的交互感，但超过 75fps 后一般很难让人感到有什么区别了。
    </p>
    <p>
     **分辨率：**是指单位英寸中所包含的像素点数，直接影响图像的清晰度。如果将一张 640 x 480 与 1024 x 768 的视频在同一设备上全屏播放，你会感到清晰度明显不同。
    </p>
    <p>
     在分辨率一定的情况下，码率与清晰度成正比关系，码率越高，图像越清晰；码率越低，图像越不清晰。
    </p>
    <p>
     在实时视频通话情况下，会出现多种质量问题，比如：与编解码相关的画面糊、不清晰、画面跳跃等现象，因网络传输问题带来的延时、卡顿等。所以解决了低延时，只是解决了实时音频通讯的一小部分问题而已。
    </p>
    <p>
     综上来看，如果在网络传输稳定的情况下，想获得越低的延时，就需要在流畅度、视频清晰度、音频质量等方面进行权衡。
    </p>
    <h3>
     <a id="_92">
     </a>
     不同场景下的延时
    </h3>
    <p>
     我们通过下表看到每个行业对实时音视频部分特性的大致需求。但是每个行业，不仅对低延时的要求不同，对延时、音质、画质，甚至功耗之间的平衡也有要求。在有些行业中，低延时并非永远排在首位。
    </p>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/23/162f146ce4925b88?w=1710&amp;h=564&amp;f=png&amp;s=120254"/>
    </p>
    <p>
     <strong>
      游戏场景
     </strong>
    </p>
    <p>
     在手游场景下，不同游戏类型对实时音视频的要求不同，比如狼人杀这样的桌游，语音沟通是否顺畅，对游戏体验影响很大，所以对延时要求较高。其它类型游戏具体如下方表格所示。
    </p>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/23/162f14b0ccdba473?w=1330&amp;h=132&amp;f=png&amp;s=100838"/>
    </p>
    <p>
     但满足低延时，并不意味着能满足手游开发的要求。因为手游开发本身存在很多痛点，比如功耗、安装包体积、安全性等。从技术层面讲，将实时音视频与手游结合时，手游开发关注的问题有两类：性能类与体验类。
    </p>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/24/162f5786d7d6834e?w=1280&amp;h=158&amp;f=png&amp;s=41409"/>
    </p>
    <p>
     在将实时音视频与手游结合时，除了延时，更注重包的大小、功耗等。安装包的大小直接影响用户是否安装，而功耗则直接影响游戏体验。
    </p>
    <p>
     <strong>
      社交直播场景
     </strong>
    </p>
    <p>
     目前的社交直播产品按照功能类型分有仅支持纯音频社交的，比如荔枝 FM；还有音视频社交的，比如陌陌。这两类场景对实时音视频的要求包括：
    </p>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/24/162f5799d8176680?w=1298&amp;h=418&amp;f=png&amp;s=92218"/>
    </p>
    <p>
     <strong>
      直播答题场景
     </strong>
    </p>
    <p>
     在直播答题场景中，对实时音视频的要求主要有如下两点：
    </p>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/24/162f57a2fe5c0b34?w=1294&amp;h=176&amp;f=png&amp;s=38886"/>
    </p>
    <p>
     我们以前经常能看到主持人说完一道题，题目却还没发到手机上，最后只剩 3 秒的答题时间，甚至没看到题就已出局。该场景的痛点不是低延时，而是直播音视频与题目的同步，保证所有人公平，有钱分。
    </p>
    <p>
     <strong>
      K 歌合唱场景
     </strong>
    </p>
    <p>
     天天 K 歌、唱吧等 K 歌类应用中，都有合唱功能，主流形式是 A 用户上传完整录音，B 用户再进行合唱。实现实时合唱的主要需求有如下几点：
    </p>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/24/162f57aaa4662998?w=1270&amp;h=292&amp;f=png&amp;s=72180"/>
    </p>
    <p>
     在这个场景中，两人的歌声与音乐三者之间的同步给低延时提出了很高的要求。同时，音质也是关键，如果为了延时而大幅降低音质，就偏离了 K 歌应用的初衷。
    </p>
    <p>
     <strong>
      金融场景
     </strong>
    </p>
    <p>
     对于核保、银行开户来讲，需要一对一音视频通话。由于金融业特殊性，该类应用对实时音视频的需求，按照重要性来排序如下：
    </p>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/24/162f57bd2ba88b0b?w=1270&amp;h=242&amp;f=png&amp;s=63197"/>
    </p>
    <p>
     在这个场景中，低延时不是关键。重要的是，要保证安全性、双录功能和系统平台的兼容。
    </p>
    <p>
     <strong>
      在线教育
     </strong>
    </p>
    <p>
     在线教育主要分为两类：非 K12 在线教育，比如技术开发类教学，该场景对实时音视频的要求主要有：
    </p>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/24/162f57c542a188ef?w=1266&amp;h=170&amp;f=png&amp;s=50279"/>
    </p>
    <p>
     很多非 K12 教学发生在单向直播场景下，所以延时要求并不高。
    </p>
    <p>
     另一类是 K12 在线教育，比如英语外教、部分兴趣教学，通常会有一对一或一对多的师生连麦功能，它对直播场景的要求包括：
    </p>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/24/162f57ccd370cb48?w=1272&amp;h=248&amp;f=png&amp;s=61517"/>
    </p>
    <p>
     在 K12 的在线教育中，师生的连麦在低延时方面有较高的要求。如果会涉及跨国的英语教学，或需要面向偏远地区学生，那还要考虑海外节点部署、中小运营商网络的支持等。
    </p>
    <p>
     <strong>
      在线抓娃娃
     </strong>
    </p>
    <p>
     在线抓娃娃是近期新兴热点，主要依靠实时音视频与线下娃娃机来实现。它对实时音视频的要求包括：
    </p>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/24/162f57d37a478de9?w=1264&amp;h=242&amp;f=png&amp;s=61497"/>
    </p>
    <h3>
     <a id="_168">
     </a>
     瓶颈与权衡
    </h3>
    <p>
     <img alt="" src="https://user-gold-cdn.xitu.io/2018/4/24/162f57e7486ba183?w=900&amp;h=500&amp;f=jpeg&amp;s=17629"/>
    </p>
    <p>
     产品的开发追求极致，需要让延时低到极限。但理想丰满，现实骨感。我们曾在上文提到，延时是因多个阶段的数据处理、传输而产生的。那么就肯定有它触及天花板的时候。
    </p>
    <p>
     我们大胆假设，要从北京机场传输一路音视频留到上海虹桥机场。我们突破一切物理环境、财力、人力限制，在两地之间搭设了一条笔直的光纤，且保证真空传输（实际上根本不可能）。两地之间距离约为 1061 km。通过计算可知，传输需要约 3.5ms。数据在采集设备与播放设备端需要的采集、编解码处理与播放缓冲延时计为较高的值，30ms。那么端到端的延时大概需要 33.5ms。请注意，我们在这里还忽略了音视频文件本身、系统、光的衰减等因素带来的影响。
    </p>
    <p>
     所以，所谓“超低延时”也会遇到瓶颈。在任何实验环境下都可以达到很低的延时，但是到实际环境中，要考虑边缘节点的部署、主干网络拥塞、弱网环境、设备性能、系统性能等问题，实际延时会更大。在一定的网络条件限制下，针对不同场景选择低延时方案或技术选型时，就需要围绕延时、卡顿、音频质量、视频清晰度等指标进行权衡与判断。
    </p>
    <hr/>
    <p>
     声网Agora有奖征文活动 正在进行中，只要在5月25日前分享你与声网SDK相关的开发经验，即有机会获得机械键盘、T恤等声网定制奖品。
     <a href="https://mp.weixin.qq.com/s/HKEmuMzxRokFXXYHXSVjtw" rel="nofollow">
      详情请戳这里
     </a>
     或邮件咨询tougao#
     <a href="http://agora.io" rel="nofollow">
      agora.io
     </a>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f61676f72615f636c6f7564:2f61727469636c652f64657461696c732f3830303631323530" class_="artid" style="display:none">
 </p>
</div>


