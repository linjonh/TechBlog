---
layout: post
title: "从-GitHub-批量下载项目各版本的方法"
date: 2025-03-09 15:31:18 +0800
description: "从github批量下载项目源代码"
keywords: "从 GitHub 批量下载项目各版本的方法"
categories: ['供应链安全']
tags: ['Github', 'Github']
artid: "146133082"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146133082
    alt: "从-GitHub-批量下载项目各版本的方法"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146133082
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146133082
cover: https://bing.ee123.net/img/rand?artid=146133082
image: https://bing.ee123.net/img/rand?artid=146133082
img: https://bing.ee123.net/img/rand?artid=146133082
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     从 GitHub 批量下载项目各版本的方法
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h4>
     一、脚本功能概述
    </h4>
    <p>
     这个 Python 脚本的主要功能是从 GitHub 上下载指定项目的各个发布版本的压缩包（
     <code>
      .zip
     </code>
     和
     <code>
      .tar.gz
     </code>
     格式）。用户需要提供两个参数：一个是包含项目信息的 CSV 文件，另一个是用于保存下载版本信息的 CSV 文件。脚本会遍历项目列表，访问每个项目的
     <code>
      tags
     </code>
     页面，下载所有可用的版本压缩包，并记录相关信息到指定的 CSV 文件中。
    </p>
    <h5>
     二、脚本使用说明
    </h5>
    <p>
     在运行脚本前，请确保你已经安装了
     <code>
      requests
     </code>
     和
     <code>
      beautifulsoup4
     </code>
     库。如果未安装，可以使用以下命令进行安装：
    </p>
    <p>
     bash
    </p>
    <pre><code>pip install requests beautifulsoup4
</code></pre>
    <p>
     运行脚本时，在命令行中输入以下格式的命令：
    </p>
    <p>
     bash
    </p>
    <pre><code>python script.py project_list.csv save_info.csv
</code></pre>
    <p>
     其中，
     <code>
      script.py
     </code>
     是脚本文件名，
     <code>
      project_list.csv
     </code>
     是包含项目信息的 CSV 文件，
     <code>
      save_info.csv
     </code>
     是用于保存下载版本信息的 CSV 文件。
    </p>
    <p>
    </p>
    <p>
     下面是完整的脚本。
    </p>
    <p>
    </p>
    <p>
     import requests
     <br/>
     from bs4 import BeautifulSoup
     <br/>
     import os
     <br/>
     import csv
     <br/>
     import sys
     <br/>
     import time
     <br/>
     import random
     <br/>
     from urllib.error import HTTPError
     <br/>
     import signal
    </p>
    <p>
     <br/>
     # 设置GitHub API的个人访问令牌
     <br/>
     # 从这里获取：https://github.com/settings/tokens
     <br/>
     access_token = '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'
    </p>
    <p>
     # 分页参数
     <br/>
     page = 1
     <br/>
     num = 0
     <br/>
     savelastfilename =""
     <br/>
     lastfilename = ""
     <br/>
     url_with_page = ""
     <br/>
     fieldnames = ['项目名称', 'tags', '版本号', '压缩包名','是否有发布']
     <br/>
     file = None
     <br/>
     writer = None
    </p>
    <p>
     proxies = {
     <!-- -->
     <br/>
     "https1": "https://182.204.177.61:4331",
     <br/>
     "https2": "https://140.255.150.253:4361",
     <br/>
     "https3": "https://113.231.18.51:4334",
     <br/>
     "https4": "https://116.7.192.240:43581",
     <br/>
     "https5": "https://121.61.160.170:43311",
     <br/>
     "https6": "https://124.231.69.245:43311",
     <br/>
     "https7": "https://183.128.97.139:43251",
     <br/>
     "https8": "https://124.94.188.113:43341",
     <br/>
     "https9": "https://1.82.107.78:4389",
     <br/>
     "https10": "https://1.82.107.49:4379",
     <br/>
     }
    </p>
    <p>
     headers = {
     <!-- -->
     <br/>
     'User-Agent': 'Mozilla/5.0',
     <br/>
     'Authorization': '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',
     <br/>
     'Content-Type': 'text/html',
     <br/>
     'Accept': 'application/json'
     <br/>
     }
    </p>
    <p>
     <br/>
     # 定义信号处理函数
     <br/>
     def signal_handler(sig, frame):
     <br/>
     print("\n收到了中断信号，程序退出！！！")
     <br/>
     sys.exit(0)
    </p>
    <p>
     # 注册信号处理函数
     <br/>
     signal.signal(signal.SIGINT, signal_handler)
    </p>
    <p>
     def get_html_url_with_tags(file_name):
     <br/>
     html_urls = []
     <br/>
     Name = ''
     <br/>
     with open(file_name, 'r', newline='') as file:
     <br/>
     reader = csv.DictReader(file)
     <br/>
     for row in reader:
     <br/>
     Name = row.get('Name')
     <br/>
     html_url = row.get('HTML URL')
     <br/>
     if html_url:
     <br/>
     new_html_url = html_url + "/tags"
     <br/>
     html_urls.append(new_html_url)
     <br/>
     #print("Name="+ Name +"  url=" + new_html_url)
     <br/>
     return Name,html_urls
    </p>
    <p>
     def download_file(url, save_path, timeout=20, max_retries=3):
     <br/>
     retries = 0
     <br/>
     while retries &lt; max_retries:
     <br/>
     try:
     <br/>
     # 发送GET请求获取文件内容，设置超时时间
     <br/>
     #@retry(tries=3, delay=2)  # 重试3次，每次间隔2秒
     <br/>
     #response = requests.get(url, proxies=proxies, headers=headers, timeout=15)
     <br/>
     response = requests.get(url, proxies=proxies, timeout=15)
     <br/>
     # 检查响应状态码
     <br/>
     if response.status_code == 200:
     <br/>
     # 写入文件
     <br/>
     print(f"正在下载文件{save_path}...",end='')
     <br/>
     with open(save_path, 'wb') as f:
     <br/>
     f.write(response.content)
     <br/>
     print(f"...文件下载完成")
     <br/>
     return True
     <br/>
     else:
     <br/>
     print(f"下载失败：状态码 {response.status_code}")
     <br/>
     #print("下载失败：超过最大重试次数")
     <br/>
     check_connection_error(response)
     <br/>
     except requests.exceptions.Timeout:
     <br/>
     print(f"请求超时，正在尝试重试...", end="")
     <br/>
     except requests.exceptions.RequestException as e:
     <br/>
     print(f"请求异常：{e}", end="")
    </p>
    <p>
     retries += 1
     <br/>
     print(f"重试次数：{retries}")
     <br/>
     <br/>
     return False
    </p>
    <p>
     def check_connection_error(response):
     <br/>
     """检查是否由于连接问题而无法访问 GitHub"""
     <br/>
     if response.status_code == 200:
     <br/>
     print("返回200！")
     <br/>
     return True
     <br/>
     if response.status_code == 403:
     <br/>
     print("已达到 GitHub API 请求限制！")
     <br/>
     return False
     <br/>
     elif response.status_code == 400:
     <br/>
     print("服务器无法理解请求！")
     <br/>
     return False
     <br/>
     elif response.status_code == 502:
     <br/>
     print("远程服务器关闭了连接。")
     <br/>
     return False
     <br/>
     elif response.status_code == 404:
     <br/>
     print("未找到请求的资源。")
     <br/>
     return False
     <br/>
     elif response.status_code == 407:
     <br/>
     print("代理服务器需要身份验证！")
     <br/>
     return False
     <br/>
     elif response.status_code == 406:
     <br/>
     print("客户端请求问题,可能是代理失效,建议更换代理IP列表")
     <br/>
     return False
     <br/>
     elif response.status_code == 429:
     <br/>
     print("请求过多，请稍后重试。")
     <br/>
     return False
     <br/>
     elif response.status_code == 504:
     <br/>
     print("网关超时，等等并重试或更换其它代理！")
     <br/>
     return False
     <br/>
     elif response.status_code &gt;= 500:
     <br/>
     print("远程服务器内部错误。")
     <br/>
     return False
     <br/>
     else:
     <br/>
     try:
     <br/>
     print("远程服务器返回未知错误，正在尝试获取更多详细信息...")
     <br/>
     response.raise_for_status()  # 如果请求失败，这将抛出一个 HTTPError 异常
     <br/>
     print("获取详细信息失败，当前状态码为：", response.status_code)
     <br/>
     return False  # 如果无法获取详细信息，则返回 False，表示请求失败
     <br/>
     except HTTPError as e:
     <br/>
     print("发生了 HTTPError 异常：", e)
     <br/>
     return False  # 如果抛出 HTTPError 异常，则返回 False，表示请求失败
     <br/>
     except ConnectionError as ce:
     <br/>
     print("连接被远程服务器关闭，没有返回任何响应。")
     <br/>
     return False  # 如果捕获到 ConnectionError 异常，则返回 False，表示请求失败
     <br/>
     except requests.exceptions.Timeout:
     <br/>
     print("连接超时：可能是由于网络问题导致的连接失败")
     <br/>
     return False
     <br/>
     except requests.exceptions.ConnectionError:
     <br/>
     print("连接错误：无法连接到服务器")
     <br/>
     return False
     <br/>
     except requests.exceptions.RequestException as e:
     <br/>
     print("请求异常,最可能是代理问题：", e)
     <br/>
     return False
    </p>
    <p>
     def wait_and_retry(wait_time=30):
     <br/>
     """等待一段时间后重试请求"""
     <br/>
     print(f"等待 {wait_time} 秒后重试...")
     <br/>
     time.sleep(wait_time)
    </p>
    <p>
     def get_github_rate_limit(headers):
     <br/>
     url = "https://api.github.com/rate_limit"
     <br/>
     headers = {
     <!-- -->
     <br/>
     'User-Agent': 'Mozilla/5.0',
     <br/>
     'Authorization': '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',
     <br/>
     'Content-Type': 'text/html',
     <br/>
     'Accept': 'application/json'
     <br/>
     }
     <br/>
     #response = requests.get(url, proxies=proxies, headers=headers)
     <br/>
     response = requests.get(url, proxies=proxies)
     <br/>
     data = response.json()
     <br/>
     limit = data["rate"]["limit"]
     <br/>
     remaining = data["rate"]["remaining"]
     <br/>
     reset_time = data["rate"]["reset"]
     <br/>
     print(f"限速检查完成...")
     <br/>
     return limit, remaining, reset_time
    </p>
    <p>
     def update_ifcheck_value(file_name, Name):
     <br/>
     """打开 CSV 文件，将指定 Name 对应的行的 ifcheck 字段值修改为 1"""
     <br/>
     rows = []
     <br/>
     with open(file_name, 'r', newline='') as file:
     <br/>
     reader = csv.DictReader(file)
     <br/>
     fieldnames = reader.fieldnames  # 获取表头字段名
     <br/>
     for row in reader:
     <br/>
     if row.get('Name') == Name:
     <br/>
     row['ifcheck'] = '1'  # 将 ifcheck 字段值修改为 1
     <br/>
     rows.append(row)
     <br/>
     # 写回 CSV 文件
     <br/>
     with open(file_name, 'w', newline='') as file:
     <br/>
     writer = csv.DictWriter(file, fieldnames=fieldnames)
     <br/>
     writer.writeheader()
     <br/>
     writer.writerows(rows)
    </p>
    <p>
     def renamefile(name,filename):
     <br/>
     current_path = os.getcwd()
     <br/>
     old_name = filename
     <br/>
     # 设置新的文件名
     <br/>
     new_name = name + "_" + filename
     <br/>
     # 构建新文件的完整路径
     <br/>
     new_path = os.path.join(current_path, new_name)
     <br/>
     # 构建旧文件的完整路径
     <br/>
     old_path = os.path.join(current_path, old_name)
     <br/>
     # 重命名文件
     <br/>
     if os.path.isfile(new_path):
     <br/>
     return False
     <br/>
     else:
     <br/>
     os.rename(old_path, new_path)
     <br/>
     return True
    </p>
    <p>
     def analyze_download_links(Name, url):
     <br/>
     global lastfilename,num,headers
     <br/>
     global writer,file
     <br/>
     while True:
     <br/>
     <br/>
     #判断是否为多页
     <br/>
     if num == 20:
     <br/>
     url_with_page = url + "?after=" + lastfilename
     <br/>
     num = 0
     <br/>
     else:
     <br/>
     url_with_page = url
     <br/>
     print("访问的url=" + url_with_page)
     <br/>
     <br/>
     #判断是否被限速，被限速的话，等待10~20秒
     <br/>
     limit, remaining, reset_time=get_github_rate_limit(headers)
     <br/>
     if remaining == 0:
     <br/>
     count = 1
     <br/>
     time.sleep(random.randint(10, 20))
     <br/>
     print("剩余请求次数为 0 了，现在更新header" )
     <br/>
     headers = {
     <!-- -->
     <br/>
     'User-Agent': 'User-Agent:Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0',
     <br/>
     'Authorization': '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',
     <br/>
     'Content-Type': 'text/html',
     <br/>
     'Accept': 'application/json'
     <br/>
     }
     <br/>
     <br/>
     #通过一个代理列表中中的一个代理获取当前url项目的tags页面
     <br/>
     #response = requests.get(url_with_page,proxies=proxies, headers=headers)
     <br/>
     #直接获取当前url项目的tags页面
     <br/>
     response = requests.get(url_with_page,proxies=proxies)
     <br/>
     #进行容错判断，如果链接错误，则等一会重新链接
     <br/>
     print("进行服务器返回检查中..." )
     <br/>
     if False == check_connection_error(response):
     <br/>
     wait_and_retry()
     <br/>
     print("服务器返回错误，请稍等一会..." )
     <br/>
     #time.sleep(random.randint(10, 20))
     <br/>
     headers = {
     <!-- -->
     <br/>
     'User-Agent': 'Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11',
     <br/>
     'Authorization': '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',
     <br/>
     'Content-Type': 'text/html',
     <br/>
     'Accept': 'application/json'
     <br/>
     }
     <br/>
     continue
     <br/>
     #如果没有响应，则10~20秒，更换header重新链接
     <br/>
     if response is None:
     <br/>
     # Exit loop if HTTP Error 422
     <br/>
     print("GitHub 未响应")
     <br/>
     time.sleep(random.randint(10, 20))
     <br/>
     headers = {
     <!-- -->
     <br/>
     'User-Agent': 'Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11',
     <br/>
     'Authorization': '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',
     <br/>
     'Content-Type': 'text/html',
     <br/>
     'Accept': 'application/json'
     <br/>
     }
     <br/>
     continue
     <br/>
     #如果返回200，说明请求正确，处理返回数据
     <br/>
     if response.status_code == 200:
     <br/>
     soup = BeautifulSoup(response.text, 'html.parser')
     <br/>
     #如果项目tags中没有版本，则返回
     <br/>
     if "There aren’t any releases here" in response.text:
     <br/>
     with open(save_file_name, 'a', newline='') as file:
     <br/>
     writer = csv.writer(file)
     <br/>
     writer.writerow([Name, url, '', '','0'])
     <br/>
     print("当前项目tags下无发布版本")
     <br/>
     break
     <br/>
     #H抓取tags页面中所有的下载链接
     <br/>
     download_links = soup.find_all('a', href=lambda href: href and (href.endswith('.zip') or href.endswith('.tar.gz')))
     <br/>
     #print("所有链接：" + download_links)
     <br/>
     if len(download_links) == 0:
     <br/>
     print("当前项目tags下无发布版本")
     <br/>
     break
     <br/>
     #分析每一个链接
     <br/>
     for link in download_links:
     <br/>
     #print("Found download link:", link['href'])
     <br/>
     file_name = os.path.basename(link['href'])  #file_name是压缩包名字
    </p>
    <p>
     if os.path.isfile(file_name):
     <br/>
     print("该项目版本已经下载，略过!")
     <br/>
     continue
     <br/>
     <br/>
     if download_file("https://github.com/" + link['href'], file_name):  #拼接为完整下载链接后下载文件
     <br/>
     #print(f"确认文件已下载完成")
     <br/>
     renamefile(Name,file_name)
     <br/>
     <br/>
     lastfilename, _ = os.path.splitext(file_name)  #lastfilename 是去掉.zip或.gz后的文件名
     <br/>
     if lastfilename.endswith('.tar'):  #如果后面还有tar后缀
     <br/>
     lastfilename, _ = os.path.splitext(lastfilename)  #lastfilename 文件名称，实际上版本号
     <br/>
     #项目名称，tags url、版本号和压缩包文件名，是否找到发布包写入文件。1表示有发布包
     <br/>
     with open(save_file_name, 'a', newline='') as file:
     <br/>
     writer = csv.writer(file)
     <br/>
     writer.writerow([Name, url, lastfilename, file_name,'1'])
     <br/>
     num = num + 1  #当前下载文件数加1
     <br/>
     else:
     <br/>
     headers = {
     <!-- -->
     <br/>
     'User-Agent': 'Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11',
     <br/>
     'Authorization': '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',
     <br/>
     'Content-Type': 'text/html',
     <br/>
     'Accept': 'application/json'
     <br/>
     }
     <br/>
     print(f"更换header重新下载...")
     <br/>
     download_file("https://github.com/" + link['href'], file_name)  #拼接为完整下载链接后下载文件
     <br/>
     if  num == 20:
     <br/>
     continue
     <br/>
     #如果有多页，每页返回10个版本，一共20个压缩包，如果不到20表示版本页面不到一页，
     <br/>
     if num &lt; 20:
     <br/>
     break
     <br/>
     #user_input = input("请输入任意内容，按 Enter 键结束程序：")
     <br/>
     #if user_input:
     <br/>
     #    print("用户输入了ctrl+C：", user_input)
     <br/>
     #
     <br/>
     #break
     <br/>
     else:
     <br/>
     print(f'页面返回不是200时，返回状态码是: {response.status_code}')
     <br/>
     continue
     <br/>
     <br/>
     # 测试程序
     <br/>
     if __name__ == "__main__":
     <br/>
     if len(sys.argv) != 3:
     <br/>
     print("请提供两个参数：第一个参数是项目列表；第二个需要创新的文件用来保存该项目版本信息")
     <br/>
     sys.exit(1)
     <br/>
     <br/>
     file_name = sys.argv[1]
     <br/>
     if not file_name.endswith('.csv'):
     <br/>
     print("Please provide a CSV file.")
     <br/>
     sys.exit(1)
     <br/>
     if os.path.exists(file_name):
     <br/>
     print("打开文件，开始分析...")
     <br/>
     else:
     <br/>
     print("输入文件不存在，请确认")
     <br/>
     sys.exit(1)
     <br/>
     <br/>
     save_file_name = sys.argv[2]
     <br/>
     if not save_file_name.endswith('.csv'):
     <br/>
     print("Please provide a CSV save file.")
     <br/>
     sys.exit(1)
     <br/>
     #如果保存文件不存在，则创建文件，添加表头
     <br/>
     if os.path.exists(save_file_name):
     <br/>
     print("保存文件已经存在，会在文件后面追加数据")
     <br/>
     else:
     <br/>
     with open(save_file_name, 'a', newline='') as file:
     <br/>
     writer = csv.writer(file)
     <br/>
     writer.writerow(fieldnames)
    </p>
    <p>
     #Name,html_urls = get_html_url_with_tags(file_name)
     <br/>
     #for url in html_urls:
     <br/>
     Name = ''
     <br/>
     with open(file_name, 'r', newline='') as file:
     <br/>
     reader = csv.DictReader(file)
     <br/>
     for row in reader:
     <br/>
     ifcheck = row.get('ifcheck')
     <br/>
     Name = row.get('Name')
     <br/>
     html_url = row.get('HTML URL')
     <br/>
     if ifcheck == '0' and html_url:
     <br/>
     new_html_url = html_url + "/tags"
     <br/>
     analyze_download_links(Name,new_html_url)
     <br/>
     update_ifcheck_value(file_name, Name)
     <br/>
     #user_input = input("您的输入中断了下载，按Ctrl+C键结束程序，其它键继续下载")
     <br/>
     #if user_input:
     <br/>
     #   print("用户输入了：", user_input)
     <br/>
     #   break
     <br/>
     print("检测完成！")
    </p>
    <p>
     ————————————————————————————————
    </p>
   </div>
  </div>
 </article>
 <p alt="687474:70733a2f2f626c6f672e6373646e2e6e65742f6d616e6f6b2f:61727469636c652f64657461696c732f313436313333303832" class_="artid" style="display:none">
 </p>
</div>


