---
layout: post
title: 盘点目前有关数字人的开源项目
date: 2024-07-15 15:14:08 +0800
categories: ['数字人']
tags: ['生成对抗网络', '深度学习', '开源', '人工智能', 'Stablediffusion']
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=140439526
    alt: 盘点目前有关数字人的开源项目
artid: 140439526
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=140439526
featuredImagePreview: https://bing.ee123.net/img/rand?artid=140439526
---
<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     盘点目前有关数字人的开源项目
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     近年来，数字人技术的迅猛发展吸引了众多研究者和开发者的关注。开源社区也涌现出许多优秀的项目，为数字人技术的发展提供了强有力的支持。本文将对一些目前较为热门的数字人生成相关开源项目进行分类整理和总结，以供广大开发者和研究人员参考。
    </p>
    <h4>
     <a id="_2">
     </a>
     一、动画人像生成与动作驱动
    </h4>
    <p>
     这些项目主要致力于通过各种技术手段生成动画人像，并根据输入的动作数据驱动其动作。
    </p>
    <ol>
     <li>
      <p>
       <strong>
        AniPortrait
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         项目地址
        </strong>
        :
        <a href="https://github.com/Zejun-Yang/AniPortrait">
         AniPortrait
        </a>
       </li>
       <li>
        <strong>
         项目简介
        </strong>
        : AniPortrait 是一个高质量的动画人像生成项目，能够从单张静态图像生成动态头像。该项目利用了深度学习和计算机视觉技术，通过检测和分析面部特征点，实现头像的自然运动和表情变化，主要应用于游戏、虚拟主播和社交媒体等领域。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        MOFA-Video
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         项目地址
        </strong>
        :
        <a href="https://github.com/MyNiuuu/MOFA-Video">
         MOFA-Video
        </a>
       </li>
       <li>
        <strong>
         项目简介
        </strong>
        : MOFA-Video 项目通过多模态融合技术实现高保真脸部动画生成。该项目结合了3D人脸重建和视频驱动技术，通过对输入视频进行分析和处理，生成与原视频动作一致的3D人脸动画，广泛应用于虚拟形象和数字人视频合成，适用于影视制作和虚拟现实等领域。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        magic-animate
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         项目地址
        </strong>
        :
        <a href="https://github.com/magic-research/magic-animate">
         magic-animate
        </a>
       </li>
       <li>
        <strong>
         项目简介
        </strong>
        : magic-animate 项目专注于实现图像到视频的高质量转换。该项目通过检测图像中的关键点并进行动画处理，生成自然流畅的动作效果。magic-animate 支持各种图像类型的输入，能够生成多样化的动画效果，广泛应用于广告、动画制作和社交媒体等领域。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        Thin-Plate-Spline-Motion-Model
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         项目地址
        </strong>
        :
        <a href="https://github.com/yoyo-nb/Thin-Plate-Spline-Motion-Model">
         Thin-Plate-Spline-Motion-Model
        </a>
       </li>
       <li>
        <strong>
         项目简介
        </strong>
        : Thin-Plate-Spline-Motion-Model 通过薄板样条变换模型，将静态图像转换为动态视频。该项目利用薄板样条变换技术，对图像中的特征点进行平滑插值，从而生成自然的动作效果。该项目主要应用于人像动画生成和表情驱动，适用于虚拟偶像和动画制作等领域。
       </li>
      </ul>
     </li>
    </ol>
    <h4>
     <a id="_21">
     </a>
     二、动作模仿与生成
    </h4>
    <p>
     这些项目主要关注于通过模仿和生成技术实现数字人动作的逼真模拟。
    </p>
    <ol start="5">
     <li>
      <p>
       <strong>
        MimicMotion
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         项目地址
        </strong>
        :
        <a href="https://github.com/Tencent/MimicMotion">
         MimicMotion
        </a>
       </li>
       <li>
        <strong>
         项目简介
        </strong>
        : MimicMotion 是由腾讯开发的一个高精度动作模仿项目。该项目利用深度学习技术，从输入的视频或动作捕捉数据中提取动作特征，并生成高度逼真的动作模仿。MimicMotion 广泛应用于虚拟角色、机器人和影视制作等领域，能够显著提高数字人的动作真实性和自然度。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        MusePose
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         项目地址
        </strong>
        :
        <a href="https://github.com/TMElyralab/MusePose">
         MusePose
        </a>
       </li>
       <li>
        <strong>
         项目简介
        </strong>
        : MusePose 项目利用深度学习技术，实现对音乐驱动的人体动作生成。该项目通过分析音乐的节奏和情感，生成与音乐同步的舞蹈动作，特别适用于虚拟偶像和舞蹈生成等场景。MusePose 支持多种音乐输入，能够生成多样化的舞蹈动作，为虚拟表演和娱乐应用提供了强有力的技术支持。
       </li>
      </ul>
     </li>
    </ol>
    <h4>
     <a id="_32">
     </a>
     三、语音合成与模仿
    </h4>
    <p>
     这些项目主要集中在语音合成与模仿领域，通过先进的语音生成技术，实现高质量的语音输出。
    </p>
    <ol start="7">
     <li>
      <p>
       <strong>
        GPT-SoVITS
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         项目地址
        </strong>
        :
        <a href="https://github.com/RVC-Boss/GPT-SoVITS">
         GPT-SoVITS
        </a>
       </li>
       <li>
        <strong>
         项目简介
        </strong>
        : GPT-SoVITS 项目结合了 GPT 和 SoVITS 技术，实现高质量的语音合成与转换。该项目利用 GPT 模型生成自然流畅的语音文本，结合 SoVITS 技术进行语音合成和转换，广泛应用于智能客服、虚拟助手和语音播报等领域。GPT-SoVITS 支持多语言输入，能够生成多种风格的语音输出。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        CosyVoice
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         项目地址
        </strong>
        :
        <a href="https://github.com/FunAudioLLM/CosyVoice">
         CosyVoice
        </a>
       </li>
       <li>
        <strong>
         项目简介
        </strong>
        : CosyVoice 项目旨在提供舒适自然的语音合成体验。该项目利用先进的语音合成技术，生成自然流畅的语音输出，主要应用于智能音箱、语音助手和语音播报等领域。CosyVoice 支持多种语言和声音风格的语音生成，能够满足多样化的应用需求。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        ChatTTS
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         项目地址
        </strong>
        :
        <a href="https://github.com/2noise/ChatTTS">
         ChatTTS
        </a>
       </li>
       <li>
        <strong>
         项目简介
        </strong>
        : ChatTTS 项目通过文本到语音的转换，实现高质量的对话语音生成。该项目结合了自然语言处理和语音合成技术，能够从输入的文本生成自然流畅的对话语音，特别适用于聊天机器人、虚拟助理和智能客服等场景。ChatTTS 提供了丰富的语音合成接口，支持多种语言和声音风格的语音生成。
       </li>
      </ul>
     </li>
    </ol>
    <h4>
     <a id="_47">
     </a>
     四、多模态数字人
    </h4>
    <p>
     这些项目致力于实现多模态的数字人生成，结合语音、视频和动作数据，提供全方位的数字人解决方案。
    </p>
    <ol start="10">
     <li>
      <strong>
       EchoMimic
      </strong>
     </li>
    </ol>
    <ul>
     <li>
      <strong>
       项目地址
      </strong>
      :
      <a href="https://github.com/BadToBest/EchoMimic">
       EchoMimic
      </a>
     </li>
     <li>
      <strong>
       项目简介
      </strong>
      : EchoMimic 专注于多模态数字人生成，通过结合图像、语音和动作数据，生成高保真的数字人形象。该项目利用先进的深度学习算法，能够从少量输入数据中生成逼真的数字人形象，适用于虚拟偶像、影视制作和互动娱乐等场景。
     </li>
    </ul>
    <ol start="11">
     <li>
      <p>
       <strong>
        hallo
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         项目地址
        </strong>
        :
        <a href="https://github.com/fudan-generative-vision/hallo">
         hallo
        </a>
       </li>
       <li>
        <strong>
         项目简介
        </strong>
        : hallo 项目结合图像和语音数据，通过深度学习技术实现高质量的数字人生成。该项目能够从输入的图像和语音中提取多模态特征，生成自然流畅的数字人形象，广泛应用于虚拟偶像、影视制作和虚拟现实等领域。hallo 支持多种输入格式，能够生成多样化的数字人形象，为开发者提供了强有力的技术支持。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        MuseTalk
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         项目地址
        </strong>
        :
        <a href="https://github.com/TMElyralab/MuseTalk">
         MuseTalk
        </a>
       </li>
       <li>
        <strong>
         项目简介
        </strong>
        : MuseTalk 项目通过多模态融合技术，实现对话驱动的虚拟人生成。该项目结合了自然语言处理、语音合成和视频生成技术，能够从输入的对话文本生成自然流畅的虚拟人形象，适用于虚拟主播、在线教育和智能客服等场景。MuseTalk 提供了丰富的接口和工具，方便开发者进行二次开发和应用。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        MuseV
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         项目地址
        </strong>
        :
        <a href="https://github.com/TMElyralab/MuseV">
         MuseV
        </a>
       </li>
       <li>
        <strong>
         项目简介
        </strong>
        : MuseV 项目结合视频和语音数据，实现多模态的虚拟人生成。该项目能够从输入的视频和语音中提取多模态特征，生成自然流畅的虚拟人形象，特别适用于虚拟会议、远程互动和虚拟现实等场景。MuseV 提供了丰富的接口和工具，方便开发者进行二次开发和应用。
       </li>
      </ul>
     </li>
    </ol>
    <p>
     综上所述，这些开源项目在数字人技术领域展现了强大的创新能力和技术实力，为开发者和研究人员提供了丰富的资源和工具。希望本文的总结能对大家有所帮助，并激发更多关于数字人技术的研究和开发热情。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
</div>


