---
arturl_encode: "68747470:733a2f2f626c6f672e6373646e2e6e65742f6c697a7a33312f:61727469636c652f64657461696c732f313436303536313432"
layout: post
title: "机器学习中的线性代数奇异值分解-SVD"
date: 2025-03-06 09:16:23 +0800
description: "大的部分放的更靠前，那么我们就在一定程度上认为，前面的部分所占的权重更大，可能只取前面 200 项的时候，就基本能够近似表示原本的图片，这也就是所谓“相当于进行了一次线性变换，但是这样并不简洁，从直观的角度上来说，既发生了旋转，也发生了拉伸，比如说。，这里显然发生了“拉伸”，也发生了“旋转”，毕竟单一维度的向量已经到达了更高维度的情况。比如说，一张 512 * 512 的图片，我们正常来说需要记录它的全部像素点，但是。我们先进行某种角度的旋转，待到伸缩变换之后，我们再进行反角度的旋转；"
keywords: "机器学习中的线性代数：奇异值分解 SVD"
categories: ['机器学习的数学原理试析']
tags: ['线性代数', '算法', '机器学习']
artid: "146056142"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146056142
    alt: "机器学习中的线性代数奇异值分解-SVD"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146056142
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146056142
cover: https://bing.ee123.net/img/rand?artid=146056142
image: https://bing.ee123.net/img/rand?artid=146056142
img: https://bing.ee123.net/img/rand?artid=146056142
---

# 机器学习中的线性代数：奇异值分解 SVD

### 线性代数 奇异值分解（SVD）

> 参考资料：
>   
> [超详细！彻底搞懂矩阵奇异值分解（SVD）本质+计算+应用！\_哔哩哔哩\_bilibili](https://www.bilibili.com/video/BV1ExWxesEVf)
>   
> 非常好的视频，本文内容主要来自于该视频，在此表示感谢！

#### 简单的实对称矩阵

我们从一个简单的对称矩阵开始说起：
  




A
=
[
1
2
2
1
]
A = \left[ \begin{matrix} 1 & 2 \\ 2 & 1 \\ \end{matrix} \right]





A



=







[











1





2

​














2





1

​



]
  
我们有

A
A





A
这样的一个矩阵，一个二维向量

x
x





x
右乘

A
A





A
相当于进行了一次线性变换，但是这样并不简洁，从直观的角度上来说，既发生了旋转，也发生了拉伸，比如说

x
1
=
(
1
0
)
x\_1 = \left( \begin{matrix}1\\0\end{matrix} \right )






x









1

​




=







(











1





0

​



)
，就会得到

A
x
1
=
(
1
2
)
Ax\_1 = \left( \begin{matrix}1 \\ 2\end{matrix}\right)





A


x









1

​




=







(











1





2

​



)
，这里显然发生了“拉伸”，也发生了“旋转”，毕竟单一维度的向量已经到达了更高维度的情况。

在这样的思路下，我们尝试抽取一般性的“伸缩矩阵”和“旋转变换矩阵”

* **伸缩变换**
  （也就是只会沿着某个坐标轴的方向进行倍数变化）：
    




  S
  =
  [
  λ
  1
  λ
  2
  ]
  =
  d
  i
  a
  g
  {
  λ
  1
  ,
  λ
  2
  }
  S
  =
  S
  T
  ,
        
  λ
  1
  ,
  λ
  2
  ≥
  0
  S = \left[ \begin{matrix} \lambda\_1 & &\\& & \lambda\_2 \end{matrix} \right ] = {diag} \{ \lambda\_1, \lambda\_2\} \newline S = S^T, \;\;\;\lambda\_1, \lambda\_2 \ge 0





  S



  =







  [












  λ









  1

  ​


  ​























  ​





















  λ









  2

  ​


  ​



  ]



  =






  d

  ia

  g

  {


  λ









  1

  ​


  ,




  λ









  2

  ​


  }






  S



  =






  S









  T

  ,










  λ









  1

  ​


  ,




  λ









  2

  ​




  ≥





  0
    
  其中，经过简单验证，可以发现矩阵

  S
  S





  S
  可以保证只会坐标轴方向进行伸缩，其他情况同理
* **旋转变换**
  ：对应到正交矩阵

  Q
  Q





  Q
    




  Q
  T
  Q
  =
  Q
  Q
  T
  =
  E
  ,
      
  Q
  −
  1
  =
  Q
  T
  Q^T Q=Q Q^T = E, \;\; Q^{-1} = Q^T






  Q









  T

  Q



  =





  Q


  Q









  T



  =





  E

  ,








  Q










  −

  1



  =






  Q









  T
    
  正交矩阵对应的就是不改变长度的情况下，向量的旋转变换

##### 从 实对称矩阵 到 分解后的变换

对于

A
A





A
来说，旋转 -> 伸缩 -> 再旋转是一种比较自然的想法，
  




A
=
Q
S
Q
T
→
  
S
=
Q
T
A
Q
=
Q
−
1
A
Q
A = QSQ^T \rightarrow \; S = Q^T A Q = Q^{-1} A Q





A



=





QS


Q









T



→





S



=






Q









T

A

Q



=






Q










−

1

A

Q
  
我们先进行某种角度的旋转，待到伸缩变换之后，我们再进行反角度的旋转；
  
这里

S
S





S
是对角矩阵，且

Q
T
=
Q
−
1
Q^T = Q^{-1}






Q









T



=






Q










−

1
所以

S
S





S
与

A
A





A
一定是相似矩阵，这里我们求

S
S





S
，只需要求出特征值就可以；

但是这里需要注意的是：
  
我们要求：

λ
i
≥
0
\lambda\_i \ge 0






λ









i

​




≥





0
成立，代表的含义是某个维度上的放缩不可以进行反向放缩
  
但是

Q
Q





Q
还有其他要求，需要进行“
**矫正**
”操作，带后面会继续进行说明

> 为了使得
>
> S
> S
>
>
>
>
>
> S
> 尽量具有唯一性和好的性质，我们常常将
>
> S
> =
> d
> i
> a
> g
> {
> λ
> 1
> ,
>   
> .
> .
> .
> ,
>   
> λ
> n
> }
> S=diag\{ \lambda\_1, \;... ,\; \lambda\_n\}
>
>
>
>
>
> S
>
>
>
> =
>
>
>
>
>
> d
>
> ia
>
> g
>
> {
>
>
> λ
>
>
>
>
>
>
>
>
>
> 1
>
> ​
>
>
> ,
>
>
>
>
>
> ...
>
> ,
>
>
>
>
>
>
> λ
>
>
>
>
>
>
>
>
>
> n
>
> ​
>
>
> }
> 从大到小排列 这样尽量保证唯一性，并且在
> **低秩近似矩阵**
> 中也有一定的应用

#### 普通方阵的奇异值分解

对一个普通的方阵

A
A





A
，我们可以知道

A
A
T
AA^T





A


A









T
以及

A
T
A
A^TA






A









T

A
一定是对称矩阵，证明也很显然：
  




(
A
A
T
)
T
=
(
A
T
)
T
(
A
)
T
=
A
A
T
(AA^T)^T = (A^T)^T (A)^T = AA^T





(

A


A









T


)









T



=





(


A









T


)









T

(

A


)









T



=





A


A









T
  
我们假设

A
A





A
是可以进行某种类型的分解的（这一点在这里没有证明）：
  




A
=
P
S
Q
T
,
P
P
T
=
P
T
P
=
E
,
Q
Q
T
=
Q
T
Q
=
E
(1.1)
A = P S Q^T, \qquad PP^T=P^TP=E, QQ^T=Q^TQ=E \tag{1.1}





A



=





PS


Q









T

,





P


P









T



=






P









T

P



=





E

,



Q


Q









T



=






Q









T

Q



=





E





(


1.1

)

A
A
T
=
P
S
Q
T
Q
S
T
P
=
P
S
2
P
T
A
T
A
=
Q
S
T
P
T
P
S
Q
T
=
Q
S
2
Q
T
(1.2)
AA^T = PSQ^T Q S^T P = P S^2 P^T \newline A^T A = Q S^T P^T P S Q^T = QS^2Q^T \tag {1.2}





A


A









T



=





PS


Q









T

Q


S









T

P



=





P


S









2


P









T







A









T

A



=





Q


S









T


P









T

PS


Q









T



=





Q


S









2


Q









T





(


1.2

)

**注意**
：尽管我们可以从

(
1.1
)
(1.1)





(

1.1

)
推导到

(
1.2
)
(1.2)





(

1.2

)
，但是二者并不是充要条件，也就是说 这里的

A
T
A
=
(
−
Q
)
S
2
(
−
Q
)
T
A^TA = (-Q) S^2 (-Q)^T






A









T

A



=





(

−

Q

)


S









2

(

−

Q


)









T
也是有可能出现的，因此，我们通过

(
1.2
)
(1.2)





(

1.2

)
求出来的特征值可以保证是正确的（直接开根号、取正数），但是特征向量还是需要进行
**校正**
：

具体来说，我们需要

(
1.1
)
(1.1)





(

1.1

)
的完全等价表示：
  




A
=
P
S
Q
T
⇔
A
Q
=
P
S
(1.3)
A = PSQ^T \quad \Leftrightarrow \quad AQ = PS \tag{1.3}





A



=





PS


Q









T





⇔





A

Q



=





PS





(


1.3

)
  
我们接下来，我们就可以用

(
1.3
)
(1.3)





(

1.3

)
进行校正，我们可以固定其中的

Q
Q





Q
，默认它是正确的，然后重新解出来

P
P





P
，此时也就可以保证正确性

#### 从 方阵 到 m ∗ n m\*n m ∗ n 矩阵

A
m
∗
n
=
P
m
∗
m
  
S
m
∗
n
  
Q
n
∗
n
T
(1.4)
A\_{m\*n} = P\_{m\*m} \; S\_{m\*n} \; Q\_{n\*n}^T \tag{1.4}






A










m

∗

n

​




=






P










m

∗

m

​





S










m

∗

n

​





Q










n

∗

n





T

​






(


1.4

)

这里，

P
,
Q
P,Q





P

,



Q
均为正交矩阵，这里假设

m
<
n
m\lt n





m



<





n
且

S
S





S
需要满足这样的性质：

S
m
∗
n
=
(
J
m
∗
m
 
,
  
O
)
S\_{m\*n} = (J\_{m\*m}\,,\;O)






S










m

∗

n

​




=





(


J










m

∗

m

​




,





O

)
，

J
J





J
是对角矩阵；

> 这里可以思考这样一个问题：
>   
> 如果说，
>
> J
> m
> ∗
> m
> J\_{m\*m}
>
>
>
>
>
>
> J
>
>
>
>
>
>
>
>
>
>
> m
>
> ∗
>
> m
>
> ​
>
> 表示的是各个维度上的伸缩，那么
>
> J
> m
> ∗
> n
> J\_{m\*n}
>
>
>
>
>
>
> J
>
>
>
>
>
>
>
>
>
>
> m
>
> ∗
>
> n
>
> ​
>
> 表示了怎样的几何含义？

这里只对

A
m
∗
n
,
m
<
n
A\_{m\*n}, m \lt n






A










m

∗

n

​


,



m



<





n
的情况进行讨论，另一边可以用相似的方法：
  




A
m
∗
n
=
P
S
Q
T
=
P
 
(
J
,
O
)
 
Q
T
A
A
T
=
P
S
S
T
P
T
=
P
J
2
P
T
A
T
A
=
Q
S
T
S
Q
T
=
Q
(
J
O
)
(
J
O
)
Q
T
=
Q
(
J
2
O
O
O
)
Q
T
A\_{m\*n} = PSQ^T = P\,(J, O) \,Q^T \newline AA^T = PSS^TP^T = PJ^2P^T \newline A^TA = QS^TSQ^T = Q \left( \begin{matrix} J \\ O \end{matrix} \right) \left( \begin{matrix} J & O \end{matrix} \right)Q^T = Q \left( \begin{matrix}J^2 & O \\ O & O \end{matrix} \right)Q^T






A










m

∗

n

​




=





PS


Q









T



=





P



(

J

,



O

)




Q









T






A


A









T



=





PS


S









T


P









T



=





P


J









2


P









T







A









T

A



=





Q


S









T

S


Q









T



=





Q





(











J





O

​



)





(











J

​














O

​



)




Q









T



=





Q





(












J









2





O

​














O





O

​



)




Q









T
  
这样求出公共的特征值，仍然需要进行校正操作，就可以得到最终答案

#### 奇异值分解的实际应用

奇异值分解被广泛用于图像处理、低秩近似矩阵等领域，可以用来进行数据压缩等等；
  
比如说，一张 512 \* 512 的图片，我们正常来说需要记录它的全部像素点，但是

A
=
P
S
Q
T
A = PSQ^T





A



=





PS


Q









T
，而且我们可以逐个

S
S





S
的元素进行展开，
  




A
=
[
α
1
.
.
.
α
n
]
d
i
a
g
{
λ
1
,
.
.
.
,
λ
n
}
[
β
1
.
.
.
β
n
]
T
A = \left[ \begin{matrix} \alpha\_1& ... &\alpha\_n \end{matrix} \right] diag\{\lambda\_1, ... ,\lambda\_n \} \left[ \begin{matrix} \beta\_1& ... &\beta\_n \end{matrix} \right]^T





A



=







[












α









1

​


​














...

​















α









n

​


​



]



d

ia

g

{


λ









1

​


,



...

,




λ









n

​


}






[












β









1

​


​














...

​















β









n

​


​



]









T
  
这样我们可以发现，每一项一定是秩为1的，而且如果按照我们所说的

λ
i
\lambda\_i






λ









i

​

大的部分放的更靠前，那么我们就在一定程度上认为，前面的部分所占的权重更大，可能只取前面 200 项的时候，就基本能够近似表示原本的图片，这也就是所谓“
**低秩近似**
”，也就起到了压缩图片的作用