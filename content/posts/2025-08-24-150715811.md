---
layout: post
title: "基于Langchain框架的DeepSeek-v3Faiss实现RAG知识问答系统含完整代码"
date: 2025-08-24T21:29:40+0800
description: "通过以上代码，可以将自己的本地数据（pdf文件）分块向量化，并存入向量数据库中，通过deepseek-v3模型和langchain问答链，进行知识问答，搭建了一个简易的RAG系统。PDF文件 → 提取文本 → 分块 → 向量化 → FAISS存储。"
keywords: "基于Langchain框架的DeepSeek-v3+Faiss实现RAG知识问答系统（含完整代码）"
categories: ['Ai']
tags: ['向量化', 'Rag', 'Python', 'Langchain', 'Faiss', 'Ai']
artid: "150715811"
arturl: "https://blog.csdn.net/weixin_42148914/article/details/150715811"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=150715811
    alt: "基于Langchain框架的DeepSeek-v3Faiss实现RAG知识问答系统含完整代码"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=150715811
featuredImagePreview: https://bing.ee123.net/img/rand?artid=150715811
cover: https://bing.ee123.net/img/rand?artid=150715811
image: https://bing.ee123.net/img/rand?artid=150715811
img: https://bing.ee123.net/img/rand?artid=150715811
---



# 基于Langchain框架的DeepSeek-v3+Faiss实现RAG知识问答系统（含完整代码）



#### 总体流程逻辑设计：

PDF文件 → 提取文本 → 分块 → 向量化 → FAISS存储

                                                                            ↓

                                                                     相似度检索

                                                                            ↓

                                                                       LLM问答

                                                                            ↓

                                                                       返回答案

#### 核心代码块功能实现：

```

from PyPDF2 import PdfReader
from langchain.chains.question_answering import load_qa_chain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.vectorstores import FAISS
import os
```

##### 1. 本地PDF 文本提取内容

```

def extract_text_from_pdf(pdf) -> str:
    """
    从PDF中提取文本内容
    
    参数:
        pdf: PDF文件对象
    
    返回:
        text: 提取的文本内容
    """
    text = ""
    for page_number, page in enumerate(pdf.pages, start=1):
        extracted_text = page.extract_text()
        if extracted_text:
            text += extracted_text
        else:
            print(f"第 {page_number} 页未找到文本内容。")
    
    return text
```

##### 2.文本分割与向量数据库加载

```

def create_knowledge_base(text: str) -> FAISS:
    """
    处理文本并创建向量存储
    
    参数:
        text: 提取的文本内容
    
    返回:
        knowledgeBase: 基于FAISS的向量存储对象
    """
    # 创建文本分割器，用于将长文本分割成小块
    text_splitter = RecursiveCharacterTextSplitter(
        separators=["\n\n", "\n", ".", " ", ""],
        chunk_size=200,
        chunk_overlap=50,
        length_function=len,
    )

    # 分割文本
    chunks = text_splitter.split_text(text)
    print(f"文本被分割成 {len(chunks)} 个块。")
        
    # 创建嵌入模型
    embeddings = DashScopeEmbeddings(
        model="text-embedding-v1",
        dashscope_api_key=DASHSCOPE_API_KEY,
    )
    
    # 从文本块创建知识库
    knowledgeBase = FAISS.from_texts(chunks, embeddings)
    print("已从文本块创建知识库。")
    
    return knowledgeBase

```

##### 3.模型相似度匹配，基于LangChain问答链进行查询

```


def query_pdf(knowledgeBase, query: str, llm) -> str:
    """
    查询PDF内容
    
    参数:
        knowledgeBase: FAISS向量存储对象
        query: 查询问题
        llm: 语言模型
    
    返回:
        response: 查询结果
    """
    # 执行相似度搜索，找到与查询相关的文档
    docs = knowledgeBase.similarity_search(query, k=1)

    # 加载问答链
    chain = load_qa_chain(llm, chain_type="stuff")

    # 准备输入数据
    input_data = {"input_documents": docs, "question": query}

    # 执行问答链
    response = chain.invoke(input=input_data)
    return response["output_text"]
```

##### 4.主函数流程

```

def main():
    """主函数"""
    # 读取PDF文件
    pdf_path = 'xxx.pdf' #加载你自己本地的pdf文件
    pdf_reader = PdfReader(pdf_path)
    
    # 提取文本
    text = extract_text_from_pdf(pdf_reader)
    print(f"提取的文本长度: {len(text)} 个字符。")
    
    # 创建知识库
    knowledgeBase = create_knowledge_base(text)
    
    # 创建语言模型
    from langchain_community.llms import Tongyi
    llm = Tongyi(model_name="deepseek-v3", dashscope_api_key=DASHSCOPE_API_KEY)
    
    # 设置查询问题
    query = "研究生专业实践时间需要多长时间"  #这里是我调用了自己学校的实践说明文档，发起的提问
    
    if query:
        # 执行查询
        response = query_pdf(knowledgeBase, query, llm)
        print(f"问题: {query}")
        print(f"回答: {response}")

if __name__ == "__main__":
    main()
```

通过以上代码，可以将自己的本地数据（pdf文件）分块向量化，并存入向量数据库中，通过deepseek-v3模型和langchain问答链，进行知识问答，搭建了一个简易的RAG系统。



