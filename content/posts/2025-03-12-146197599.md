---
layout: post
title: "大语言模型-1.3-GPTDeepSeek模型介绍"
date: 2025-03-12 11:13:38 +0800
description: "本博客内容是《大语言模型》一书的读书笔记，本文主要记录datawhale的活动学习笔记，本部分主要介绍GPT和DeepSeek的进展。"
keywords: "大语言模型-1.3-GPT、DeepSeek模型介绍"
categories: ['机器学习2025', '大模型Llm']
tags: ['语言模型', '人工智能', 'Gpt', 'Datawhale']
artid: "146197599"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146197599
    alt: "大语言模型-1.3-GPTDeepSeek模型介绍"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146197599
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146197599
cover: https://bing.ee123.net/img/rand?artid=146197599
image: https://bing.ee123.net/img/rand?artid=146197599
img: https://bing.ee123.net/img/rand?artid=146197599
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     大语言模型-1.3-GPT、DeepSeek模型介绍
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="_0">
     </a>
     简介
    </h3>
    <p>
     本博客内容是《大语言模型》一书的读书笔记，该书是中国人民大学高瓴人工智能学院赵鑫教授团队出品，覆盖大语言模型训练与使用的全流程，从预训练到微调与对齐，从使用技术到评测应用，帮助学员全面掌握大语言模型的核心技术。并且，课程内容基于大量的代码实战与讲解，通过实际项目与案例，学员能将理论知识应用于真实场景，提升解决实际问题的能力。
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/8462d74a8d764cc7a56c909eade4c15a.png"/>
    </p>
    <p>
     本文主要记录datawhale的活动学习笔记，
     <a href="https://www.datawhale.cn/activity/150" rel="nofollow">
      可点击活动连接
     </a>
    </p>
    <h3>
     <a id="_6">
     </a>
     参考
    </h3>
    <p>
     参考
     <br/>
     <a href="https://www.zhihu.com/tardis/bd/art/669984257?source_id=1001" rel="nofollow">
      【大模型】GPT: Improving Language Understanding by Generative Pre-Training
     </a>
     <br/>
     <a href="https://news.qq.com/rain/a/20250307A0200M00" rel="nofollow">
      AI 世界生存手册（二）：从LR到DeepSeek，模型慢慢变大了，也变强了
     </a>
    </p>
    <p>
     <a href="https://juejin.cn/post/7175753434761527356#heading-4" rel="nofollow">
      #41 AI-002-十分钟理解ChatGPT的技术逻辑及演进(前世、今生）
     </a>
    </p>
    <p>
     <a href="https://zhuanlan.zhihu.com/p/82312421" rel="nofollow">
      十分钟理解Transformer
     </a>
    </p>
    <h3>
     <a id="131GPT__14">
     </a>
     1.3.1GPT 系列模型成体系推进
    </h3>
    <blockquote>
     <p>
      2017年，谷歌提出Transformer
      <br/>
      2018年，OpenAI提出GPT（1亿+参数）
      <br/>
      2019年，GPT-2（15亿参数）
      <br/>
      2020年，GPT-3（1750亿参数）
      <br/>
      2021年，CodeX（基于GPT-3，代码预训练）
      <br/>
      2021年，WebGPT（搜索能力）
      <br/>
      2022年2月，InstructGPT（人类对齐）
      <br/>
      2022年11月，ChatGPT（对话能力）
      <br/>
      2023年3月，GPT-4（推理能力、多模态能力）
      <br/>
      2024年9月，o1（深度思考能力提升）
      <br/>
      2025年1月，o3（深度思考能力进一步增强）
      <br/>
      GPT系列模型从18年开始系统迭代，对于大模型发展起到了深远影响
     </p>
    </blockquote>
    <p>
     GPT从开始至今，其发展历程如下：
    </p>
    <blockquote>
     <p>
      2017年6月，Google发布论文《Attention is all you need》，首次提出Transformer模型，成为GPT发展的基础。 论文地址：
      <a href="https://arxiv.org/abs/1706.03762" rel="nofollow">
       https://arxiv.org/abs/1706.03762
      </a>
      <br/>
      2018年6月,OpenAI 发布论文《Improving Language Understanding by Generative Pre-Training》(通过生成式预训练提升语言理解能力)，首次提出GPT模型(Generative Pre-Training)。论文地址：
      <a href="https://paperswithcode.com/method/gpt" rel="nofollow">
       paperswithcode.com/method/gpt
      </a>
      。
      <br/>
      2019年2月，OpenAI 发布论文《Language Models are Unsupervised Multitask Learners》（语言模型应该是一个无监督多任务学习者），提出GPT-2模型。论文地址: paperswithcode.com/method/gpt-…
      <br/>
      2020年5月，OpenAI 发布论文《Language Models are Few-Shot Learners》(语言模型应该是一个少量样本(few-shot)学习者，提出GPT-3模型。论文地址：
      <a href="https://paperswithcode.com/method/gpt-2" rel="nofollow">
       https://paperswithcode.com/method/gpt-2
      </a>
      <br/>
      2022年2月底，OpenAI 发布论文《Training language models to follow instructions with human feedback》（使用人类反馈指令流来训练语言模型），公布 Instruction GPT模型。论文地址：
      <a href="https://arxiv.org/abs/2203.02155" rel="nofollow">
       https://arxiv.org/abs/2203.02155
      </a>
      <br/>
      2022年11月30日，OpenAI推出ChatGPT模型，并提供试用，全网火爆。见：
      <a href="https://mp.weixin.qq.com/s?__biz=Mzg5MDU2MzM2Mw==&amp;mid=2247484868&amp;idx=1&amp;sn=14b036f1ef366f2ee04ce3d560bfb693&amp;chksm=cfdbfb88f8ac729e9432dedf4c232114b0c1d0e06d14dfad1dca4d12ee01172174caf0011597&amp;token=494872941&amp;lang=zh_CN#rd" rel="nofollow">
       AI-001-火爆全网的聊天机器人ChatGPT能做什么
      </a>
     </p>
    </blockquote>
    <h4>
     <a id="GPT__39">
     </a>
     GPT 系列模型发展历程
    </h4>
    <blockquote>
     <p>
      ➢ 小模型：GPT-1，GPT-2
      <br/>
      ➢ 大模型：GPT-3，CodeX，GPT-3.5，GPT-4
      <br/>
      ➢ 推理大模型：o-series
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/828f03bed3a8444e954bcbc135f460e0.png">
       <br/>
       <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/9e9e8ed3d38f44bcab78d66e803a408a.png"/>
      </img>
     </p>
    </blockquote>
    <h4>
     <a id="GPT111_46">
     </a>
     GPT-1（1.1亿参数）
    </h4>
    <p>
     当时NLP的问题
    </p>
    <blockquote>
     <p>
      此时训练一个 NLP 模型和我们之前做的推荐类似，针对某个任务，首先搞一些样本，然后对模型进行有监督训练。问题出在题面上。
      <br/>
      1.样本怎么来，大量的高质量的标注不太容易获得。
      <br/>
      2.模型训练的任务是固定的，很难学到泛化能力，没法复用到做其他任务。
      <br/>
      这样训练出来的模型被困在了一个特定的领域，离我们想要的 AGI（人工通用智能）有点远。
     </p>
    </blockquote>
    <p>
     GPT-1采用的架构
    </p>
    <blockquote>
     <p>
      ➢ Decode-only Transformer架构
      <br/>
      ➢ 预训练后针对特定任务微调
      <br/>
      entailment术语翻译为“蕴涵”
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/2af7c0156e3b43d7a0d3d69759825b55.png">
       1.用了4.6GB的BookCorpus数据集（该数据集主要是小说，openai 为了验证技术可行性，特意选了未出版的 7000 本书），无监督训练一个预训练模型，即generative pre-training，GPT 名字的由来。
       <br/>
       2.对于子任务，用有标签的小的数据集训练一个微调模型，discriminative fine-tuning。
       <br/>
       <strong>
        微调方式具体来说，可见上图右图部分。
       </strong>
       <br/>
       对于每个任务，输入会被构造成一个连续的 token 序列。分类任务，会将输入文本拼接成一个序列，并在开头添加一个特殊token-start，在结尾增加 extract然后经过模型+线性层后输出结果，对于相似度的文本比较有趣，比如看 A 和 B 是否相似，那么就组成个序列分别为 AB 和 BA，其输入模型后，最终通过softmax 判断，是否相似，是个二分类问题。第四个问答其实是一个多分类问题。
       <br/>
       这四个任务有一个共性，就是我们只需要对输入做定制化，输出做一些定制，但是中间的 transformer 模型不会去动它。
       <br/>
       左图：GPT是一个transformer decoder-only的结构， MHA +add&amp;norm 的 Block 其用了 12 层，参数量 0.11B，对，此时它还很小。另外输入的token 用了word2vec做了 embedding 表征。
      </img>
     </p>
    </blockquote>
    <blockquote>
     <p>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b156ad169bf341dd88ff53be82edacda.png">
       <br/>
       <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/06a910f762744e69b266c5f94e86d9ab.png">
        <br/>
        <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/ef3fcc2aae984db1bdf7816c9492a93a.png">
         <br/>
         <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/de375120fef24a4c9d74e8ba79e42fda.png">
          <br/>
          <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/bed9d55620484cdb91892d0a7f5b7cde.png">
           <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/3b676540e51548c3b291640b84ff46b3.png">
            <br/>
            <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/1740805a36584a22b96edc3f0acfea11.png"/>
            <br/>
            <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/7be7a5f62e1b4fd584e63ccbef92c8eb.png"/>
           </img>
          </img>
         </img>
        </img>
       </img>
      </img>
     </p>
    </blockquote>
    <h4>
     <a id="GPT2_15_73">
     </a>
     GPT-2 （15亿参数）
    </h4>
    <p>
     ➢ 将任务形式统一为单词预测
     <br/>
     ➢ Pr (output | input, task)
     <br/>
     ➢ 预训练与下游任务一致
     <br/>
     ➢ 使用提示进行无监督任务求解
     <br/>
     ➢ 初步尝试了规模扩展
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/812cf300f44b4c349c142bae734017f5.png"/>
    </p>
    <h4>
     <a id="GPT31750_83">
     </a>
     GPT-3(1750亿参数)
    </h4>
    <p>
     ➢ 模型规模达到1750亿参数
     <br/>
     ➢ 涌现出上下文学习能力
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/7fbfa4691eed40e68fb7ac8b9f24676a.png"/>
    </p>
    <h4>
     <a id="CodeX_88">
     </a>
     CodeX
    </h4>
    <p>
     ➢ 代码数据训练
     <br/>
     ➢ 推理与代码合成能力
    </p>
    <blockquote>
     <p>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b741c31b156b40e7bc9c5b5f252f3c42.png"/>
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/13524c0541a64dcf87f6772aded33f2f.png"/>
     </p>
    </blockquote>
    <h4>
     <a id="WebGPT_95">
     </a>
     WebGPT
    </h4>
    <p>
     ➢ 大语言模型使用浏览器
    </p>
    <blockquote>
     <p>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b5bf1ee426074273be11d70f3aea9eeb.png"/>
      <br/>
      WebGPT: Browser-assisted question-answering with human feedback, Arxiv 2021
     </p>
    </blockquote>
    <h4>
     <a id="InstructGPT_101">
     </a>
     InstructGPT
    </h4>
    <p>
     ➢ 大语言模型与人类价值观对齐
     <br/>
     ➢ 提出RLHF算法
    </p>
    <blockquote>
     <p>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/eee74fef46b94cc983b6783b77bf9f7b.png"/>
      <br/>
      Training language models to follow instructions with human feedback, NIPS 2022
     </p>
    </blockquote>
    <blockquote>
     <p>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/2bb8f26af5484d82a4b2746784a6e111.webp"/>
     </p>
    </blockquote>
    <blockquote>
     <p>
      1)、对GPT-3进行fine-tuning(监督微调)。
      <br/>
      2)、再训练一个Reward Model(奖励模型，RM)
      <br/>
      3)、最后通过增强学习优化SFT
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b0b538dec12e47a798cb225efae1c1bc.webp"/>
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/165476709f7d4fd68aa967211d014845.webp"/>
      <br/>
      值得注意的是，第2步、第3步是完全可以迭代、循环多次进行的。
     </p>
    </blockquote>
    <h5>
     <a id="Instruction_GPT_118">
     </a>
     Instruction GPT的训练规模
    </h5>
    <blockquote>
     <p>
      基础数据规模同GPT-3 ，只是在其基础上增加了3个步骤（监督微调SFT、奖励模型训练Reward Model，增强学习优化RPO)。
      <br/>
      下图中labeler是指OpenAI雇佣或有相关关系的标注人员(labler)。
      <br/>
      而customer则是指GPT-3 API的调用用户（即其他一些机器学习研究者、程序员等）。
      <br/>
      本次ChatGPT上线后据说有百万以上的用户，我们每个人都是其customer，所以可以预见，未来GPT-4发布时，其customer规模至少是百万起。
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b95918e02b824af58a830ac849325931.webp"/>
     </p>
    </blockquote>
    <h4>
     <a id="ChatGPT_130">
     </a>
     ChatGPT
    </h4>
    <p>
     ➢ 基于 InstructGPT 相似技术开发，面向对话进行优化
    </p>
    <blockquote>
     <p>
      ChatGPT和InstructionGPT本质上是同一代际的，仅仅是在InstructionGPT的基础上，增加了Chat功能，同时开放到公众测试训练，以便产生更多有效标注数据。
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/07479876ebce407ea491857d00d2e11b.webp"/>
     </p>
    </blockquote>
    <h4>
     <a id="GPT4_135">
     </a>
     GPT-4
    </h4>
    <p>
     ➢ 推理能力显著提升，建立可预测的训练框架
     <br/>
     ➢ 可支持多模态信息的大语言模型
    </p>
    <blockquote>
     <p>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/0ab001ea52f4421b858de911f74cf38d.png"/>
      <br/>
      GPT-4 Technical Report, Arxiv 2023
     </p>
    </blockquote>
    <h4>
     <a id="GPT4o_141">
     </a>
     GPT-4o
    </h4>
    <p>
     ➢ 原生多模态模型，综合模态能力显著提升
     <br/>
     ➢ 支持统一处理和输出文本、音频、图片、视频信息
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/0573b064a1ea499ab1bcac0bd76a993b.png"/>
    </p>
    <h4>
     <a id="o_146">
     </a>
     o系列模型
    </h4>
    <p>
     ➢ 推理任务上能力大幅提升
     <br/>
     ➢ 长思维链推理能力
    </p>
    <blockquote>
     <p>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/ef1aadf5fba14cea918ee4ea12f3b760.png"/>
     </p>
    </blockquote>
    <h4>
     <a id="oseries_151">
     </a>
     o-series
    </h4>
    <p>
     ➢ 类似人类的“慢思考”过程
    </p>
    <blockquote>
     <p>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/dbba9ec635a14cf59b8ade2c38e3a67a.png"/>
     </p>
    </blockquote>
    <h3>
     <a id="132DeepSeek__155">
     </a>
     1.3.2DeepSeek 系列模型的技术演变
    </h3>
    <blockquote>
     <p>
      DeepSeek系列模型发展历程
      <br/>
      ➢ 训练框架：HAI-LLM
      <br/>
      ➢ 语言大模型：DeepSeek LLM/V2/V3、Coder/Coder-V2、Math
      <br/>
      ➢ 多模态大模型：DeepSeek-VL
      <br/>
      ➢ 推理大模型：DeepSeek-R1
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/ea0e5a870bde4b4aaee1e611dbb160fd.png"/>
     </p>
    </blockquote>
    <p>
     DeepSeek 实现了较好的训练框架与数据准备
    </p>
    <blockquote>
     <p>
      ➢ 训练框架 HAI-LLM（发布于2023年6月）
      <br/>
      ➢ 大规模深度学习训练框架，支持多种并行策略
      <br/>
      ➢ 三代主力模型均基于该框架训练完成
      <br/>
      ➢ 数据采集
      <br/>
      ➢ V1和Math的报告表明清洗了大规模的Common Crawl，具备超大规模数据处理能力
      <br/>
      ➢ Coder的技术报告表明收集了大量的代码数据
      <br/>
      ➢ Math的技术报告表明清洗收集了大量的数学数据
      <br/>
      ➢ VL的技术报告表明清洗收集了大量多模态、图片数据
     </p>
    </blockquote>
    <p>
     DeepSeek 进行了重要的网络架构、训练算法、性能优化探索
    </p>
    <blockquote>
     <p>
      ➢ V1 探索了scaling law分析（考虑了数据质量影响），用于预估超参数性能
      <br/>
      ➢ V2 提出了MLA高效注意力机制，提升推理性能
      <br/>
      ➢ V2、V3都针对MoE架构提出了相关稳定性训练策略
      <br/>
      ➢ V3 使用了MTP（多token预测）训练
      <br/>
      ➢ Math 提出了PPO的改进算法 GRPO
      <br/>
      ➢ V3详细介绍Infrastructure的搭建方法，并提出了高效 FP8 训练方法
     </p>
    </blockquote>
    <h4>
     <a id="DeepSeekV3_184">
     </a>
     DeepSeek-V3
    </h4>
    <blockquote>
     <p>
      ➢ 671B参数（37B激活），14.8T训练数据
      <br/>
      ➢ 基于V2的MoE架构，引入了MTP和新的复杂均衡损失
      <br/>
      ➢ 对于训练效率进行了极致优化，共使用 2.788M H800 GPU时
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/08c932f6b05241498faaa5bb0022ad94.png"/>
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/1e14c95b22bb40b39d0c26382eca8a34.png"/>
     </p>
    </blockquote>
    <h4>
     <a id="DeepSeekR1_192">
     </a>
     DeepSeek-R1
    </h4>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/e66e42a741c04fb98846d742112048bf.png"/>
     <br/>
     DeepSeek-V3和DeepSeek-R1均达到了同期闭源模型的最好效果
    </p>
    <blockquote>
     <p>
      ➢ 开源模型实现了重要突破
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/87ab4085234f48be87521150a17254ba.png"/>
     </p>
    </blockquote>
    <h4>
     <a id="_DeepSeek__199">
     </a>
     为什么 DeepSeek 会引起世界关注
    </h4>
    <blockquote>
     <p>
      ➢ 打破了OpenAI 闭源产品的领先时效性
      <br/>
      ➢ 国内追赶GPT-4的时间很长，然而复现o1模型的时间大大缩短
      <br/>
      ➢ 达到了与OpenAI现有API性能可比的水平
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/0fd37e8969ee42fd8cbf6fd60e07b188.png"/>
      <br/>
      Large Language Model, 2025 (Book under progress)
     </p>
    </blockquote>
    <h4>
     <a id="_DeepSeek__208">
     </a>
     为什么 DeepSeek 会引起世界关注
    </h4>
    <blockquote>
     <p>
      ➢ 中国具备实现世界最前沿大模型的核心技术
      <br/>
      ➢ 模型开源、技术开放
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/8918141a66f24a469a038b3eda0a4e93.png"/>
     </p>
    </blockquote>
    <p>
     参考:
     <a href="https://www.zhihu.com/tardis/bd/art/669984257?source_id=1001" rel="nofollow">
      【大模型】GPT: Improving Language Understanding by Generative Pre-Training
     </a>
     <br/>
     <a href="https://news.qq.com/rain/a/20250307A0200M00" rel="nofollow">
      AI 世界生存手册（二）：从LR到DeepSeek，模型慢慢变大了，也变强了
     </a>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f33383133393235302f:61727469636c652f64657461696c732f313436313937353939" class_="artid" style="display:none">
 </p>
</div>


