---
layout: post
title: "深入剖析Kafka分布式消息队列架构奥秘之Springboot集成Kafka"
date: 2025-08-31T15:00:18+0800
description: "其实在单机服务下，Kafka已经具备了非常高的性能，TPS能够达到百万级，但是实际工作中使用，单机搭建的Kafka有很大的局限性。"
keywords: "《深入剖析Kafka分布式消息队列架构奥秘》之Springboot集成Kafka"
categories: ['未分类']
tags: ['架构', '分布式', 'Kafka']
artid: "145858119"
arturl: "https://blog.csdn.net/shsjssnn/article/details/145858119"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145858119
    alt: "深入剖析Kafka分布式消息队列架构奥秘之Springboot集成Kafka"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145858119
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145858119
cover: https://bing.ee123.net/img/rand?artid=145858119
image: https://bing.ee123.net/img/rand?artid=145858119
img: https://bing.ee123.net/img/rand?artid=145858119
---



# 《深入剖析Kafka分布式消息队列架构奥秘》之Springboot集成Kafka



![](https://img-blog.csdnimg.cn/direct/2d95dedc1e3c4fd387ab0376ee99e652.gif)

**🎼个人主页：**[【Y小夜】](https://blog.csdn.net/shsjssnn?type=blog "【Y小夜】")

**😎作者简介：一位双非学校的大三学生，编程爱好者，**

**专注于基础和实战分享，欢迎私信咨询！**

**🎆入门专栏：🎇【**[MySQL](https://blog.csdn.net/shsjssnn/category_12433907.html?spm=1001.2014.3001.5482 "MySQL")，[Javaweb](https://blog.csdn.net/shsjssnn/category_12603064.html?spm=1001.2014.3001.5482 "Javaweb")，[Rust](https://blog.csdn.net/shsjssnn/category_12572899.html "Rust")，[python](https://blog.csdn.net/shsjssnn/category_12463990.html "python")】

**🎈热门专栏：🎊【**[Springboot](https://blog.csdn.net/shsjssnn/category_12679147.html "Springboot")，[Redis](https://blog.csdn.net/shsjssnn/category_12839505.html "Redis")，[Springsecurity](https://blog.csdn.net/shsjssnn/category_12858055.html "Springsecurity")，[Docker](https://blog.csdn.net/shsjssnn/category_12879572.html "Docker")，[AI](https://blog.csdn.net/shsjssnn/category_12799666.html "AI")】

***感谢您的点赞、关注、评论、收藏、是对我最大的认可和支持！❤️***

![](https://img-blog.csdnimg.cn/direct/c66a63db064845efa9cb6fb9caea3032.gif)













---

## ​🎈为什么要使用集群？

![](https://i-blog.csdnimg.cn/direct/ac66882c6c074bbfa4b728eb12d66fea.png)

        其实在单机服务下，Kafka已经具备了非常高的性能，TPS能够达到百万级，但是实际工作中使用，单机搭建的Kafka有很大的局限性。

**一方面：消息太多，需要分开放**

**另一方面：服务不稳定，数据容易丢失**

![](https://i-blog.csdnimg.cn/direct/e8310fb7347c4349b411e872644b1e3b.png)

大家集群这部分我的电脑上没有多个虚拟机，所以这部分，要是需要操作的话。可以看其他博主的文章。

## ​🎈Springboot集成Kafka

### 🎉引入依赖

这个依赖关系版本和下载的kafka有依赖关系，大家可以关注下。

```
        <dependency>
            <groupId>org.springframework.kafka</groupId>
            <artifactId>spring-kafka</artifactId>
            <version>3.3.1</version>
        </dependency>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka-clients</artifactId>
            <version>3.9.0</version>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
```

### 🎉配置

```
spring.kafka.bootstrap-servers=ip地址:9092
kafka.topics=test1
```

### 🎉编写Kafka的配置类

```
package com.yan.kafka;

import org.apache.kafka.clients.admin.NewTopic;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.config.TopicBuilder;

@Configuration
public class KafkaConfig {
    @Value("${kafka.topics}")
    private String topic;

    @Bean
    public NewTopic topic(){
        return TopicBuilder.name(topic).build();
    }
}

```

### 🎉编写生产者配置类

```
package com.yan.kafka;

import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;

import java.util.HashMap;
import java.util.Map;

//发送配置类
@Configuration
public class KafkaProducerConfig {
    @Value("${spring.kafka.bootstrap-servers}")
    private String service;

    public Map<String, Object>  config(){
        Map<String,Object> config=new HashMap<>();
        config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,service);
        //进行序列化
        config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,StringSerializer.class);
        return config;
    }
    @Bean
    public ProducerFactory<String,String> producerFactory(){
        return new DefaultKafkaProducerFactory<>(config());
    }
    @Bean
    public KafkaTemplate<String,String> kafkaTemplate(){
        return new KafkaTemplate<>(producerFactory());
    }
}

```

### 🎉编写生产者业务

```
package com.yan.kafka;


import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class KafkaController {
    @Autowired
    private KafkaTemplate kafkaTemplate;

    @Value("${kafka.topics}")
    private String topic;

    @GetMapping("/kafka")
    public String sendMsg(){
        for (int i = 0; i < 10; i++) {
            kafkaTemplate.send(topic,"你好"+i);
        }
        return "success";
    }
}

```

### 🎉编写消费者配置类

```
package com.yan.kafka;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.*;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaConsumerConfig {
    @Value("${spring.kafka.bootstrap-servers}")
    private String service;

    public Map<String, Object> config(){
        Map<String,Object> config=new HashMap<>();
        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,service);
        //进行反序列化
        config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringSerializer.class);
        config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringSerializer.class);
        return config;
    }
    @Bean
    public ConsumerFactory<String,String> consumerFactory(){
        return new DefaultKafkaConsumerFactory<>(config());
    }
    @Bean
    public ConcurrentKafkaListenerContainerFactory concurrentKafkaListenerContainerFactory(){
        ConcurrentKafkaListenerContainerFactory ckcf=new ConcurrentKafkaListenerContainerFactory();
        ckcf.setConsumerFactory(consumerFactory());
        return ckcf;
    }

}

```

### 🎉编写消费者监听类

```
package com.yan.kafka;


import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

@Component
public class KafkaListeners {
    @KafkaListener(topics="${kafka.topics}",groupId = "aaa")
    void listener(String data){
        System.out.println("收到了"+data);
    }
}

```

然后，启动程序，访问一下[localhost:8080/kafka](http://localhost:8080/kafka "localhost:8080/kafka")，控制台会输出：

![](https://i-blog.csdnimg.cn/direct/5c524bd513664144bf55b8f3d9d3bcac.png)

### 🎉报错：

下面三种图是我做的时候出现的报错。我们可以对程序做一下检测

![](https://i-blog.csdnimg.cn/direct/31968dbe9e8b4e38bee3ffe40b30891a.png)

![](https://i-blog.csdnimg.cn/direct/2becc128b91247a2b4b92a401799fd2e.png)

![](https://i-blog.csdnimg.cn/direct/00493c2d26a94d6d9c51c26facd78ff8.png)

首先输入jps，看linux中kafka是否启动

![](https://i-blog.csdnimg.cn/direct/c38724ca1f1b45ec953038fe85cd1883.png)

如果没有启动，则需要输入命令进行启动。

然后看一下9092端口是否开放：

```
firewall-cmd --zone=public --list-ports

```

![](https://i-blog.csdnimg.cn/direct/467155c147e54b9d8cc8ae0594673029.png)

若没有开放，则使用命令，开放9092端口

```
firewall-cmd --zone=public --add-port=9092/tcp --permanent
firewall-cmd --reload
```

接着打开 **/config/server.properties** 文件，

```
listeners=PLAINTEXT://localhost:9092

```

将localhost修改为kafka当前的操作系统的地址即可。

![](https://i-blog.csdnimg.cn/direct/53c73acde349407ba4f41be8f0119aa3.png)

然后打开windows窗口，输入

```
telnet ip地址 9092
```

![](https://i-blog.csdnimg.cn/direct/360aa15f9aaa461ea6374965bcb674f4.png)

能进入的话，就说明可以连接到。

把这些修改完毕后，应该就可以顺利访问了。！！！



