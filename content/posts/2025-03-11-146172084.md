---
layout: post
title: "HippoRAG-2-原理精读"
date: 2025-03-11 10:27:32 +0800
description: "1、只是用三元组来协助检索，并没有利用图2、难以相信这种做法能超越普通RAG几十个点。"
keywords: "HippoRAG 2 原理精读"
categories: ['未分类']
tags: ['人工智能', 'Llm']
artid: "146172084"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146172084
    alt: "HippoRAG-2-原理精读"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146172084
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146172084
cover: https://bing.ee123.net/img/rand?artid=146172084
image: https://bing.ee123.net/img/rand?artid=146172084
img: https://bing.ee123.net/img/rand?artid=146172084
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     HippoRAG 2 原理精读
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <blockquote>
     <p>
      提示：文章写完后，目录可以自动生成，如何生成可参考右边的帮助文档
     </p>
    </blockquote>
    <p>
    </p>
    <p>
    </p>
    <h3>
     <a id="_8">
     </a>
     整体流程
    </h3>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/7f57b66de38f45d7aedc9c0dabf0b9e8.png"/>
    </p>
    <p>
     从上图可以看出，整个流程分为两个阶段
    </p>
    <p>
     1、离线索引阶段
    </p>
    <p>
     2、在线检索和问答阶段
    </p>
    <h4>
     <a id="_19">
     </a>
     离线索引阶段
    </h4>
    <p>
     1、对文档进行分段
     <br/>
     2、抽取实体
    </p>
    <p>
     对应的prompt
    </p>
    <pre><code class="prism language-python">ner_system <span class="token operator">=</span> <span class="token triple-quoted-string string">"""Your task is to extract named entities from the given paragraph. 
Respond with a JSON list of entities.
"""</span>

one_shot_ner_paragraph <span class="token operator">=</span> <span class="token triple-quoted-string string">"""Radio City
Radio City is India's first private FM radio station and was started on 3 July 2001.
It plays Hindi, English and regional songs.
Radio City recently forayed into New Media in May 2008 with the launch of a music portal - PlanetRadiocity.com that offers music related news, videos, songs, and other music-related features."""</span>


one_shot_ner_output <span class="token operator">=</span> <span class="token triple-quoted-string string">"""{"named_entities":
    ["Radio City", "India", "3 July 2001", "Hindi", "English", "May 2008", "PlanetRadiocity.com"]
}
"""</span>


prompt_template <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> ner_system<span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> one_shot_ner_paragraph<span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> one_shot_ner_output<span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string">"${passage}"</span><span class="token punctuation">}</span>
<span class="token punctuation">]</span>
</code></pre>
    <p>
     LLM的输出如
    </p>
    <pre><code class="prism language-json"><span class="token punctuation">{<!-- --></span>
  <span class="token string-property property">"named_entities"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token string">"迦楼罗"</span><span class="token punctuation">,</span>
    <span class="token string">"大鹏金翅鸟"</span><span class="token punctuation">,</span>
    <span class="token string">"岳飞"</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre>
    <p>
     3、根据实体和文本生成三元组
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> <span class="token punctuation">.</span>ner <span class="token keyword">import</span> one_shot_ner_paragraph<span class="token punctuation">,</span> one_shot_ner_output
<span class="token keyword">from</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>utils<span class="token punctuation">.</span>llm_utils <span class="token keyword">import</span> convert_format_to_template

ner_conditioned_re_system <span class="token operator">=</span> <span class="token triple-quoted-string string">"""Your task is to construct an RDF (Resource Description Framework) graph from the given passages and named entity lists. 
Respond with a JSON list of triples, with each triple representing a relationship in the RDF graph. 

Pay attention to the following requirements:
- Each triple should contain at least one, but preferably two, of the named entities in the list for each passage.
- Clearly resolve pronouns to their specific names to maintain clarity.

"""</span>


ner_conditioned_re_frame <span class="token operator">=</span> <span class="token string">""</span>"Convert the paragraph into a JSON <span class="token builtin">dict</span><span class="token punctuation">,</span> it has a named entity <span class="token builtin">list</span> <span class="token keyword">and</span> a triple <span class="token builtin">list</span><span class="token punctuation">.</span>
Paragraph<span class="token punctuation">:</span>
</code></pre>
    <p>
     {passage}
    </p>
    <pre><code>
{named_entity_json}
"""


ner_conditioned_re_input = ner_conditioned_re_frame.format(passage=one_shot_ner_paragraph, named_entity_json=one_shot_ner_output)


ner_conditioned_re_output = """{"triples": [
            ["Radio City", "located in", "India"],
            ["Radio City", "is", "private FM radio station"],
            ["Radio City", "started on", "3 July 2001"],
            ["Radio City", "plays songs in", "Hindi"],
            ["Radio City", "plays songs in", "English"],
            ["Radio City", "forayed into", "New Media"],
            ["Radio City", "launched", "PlanetRadiocity.com"],
            ["PlanetRadiocity.com", "launched in", "May 2008"],
            ["PlanetRadiocity.com", "is", "music portal"],
            ["PlanetRadiocity.com", "offers", "news"],
            ["PlanetRadiocity.com", "offers", "videos"],
            ["PlanetRadiocity.com", "offers", "songs"]
    ]
}
"""


prompt_template = [
    {"role": "system", "content": ner_conditioned_re_system},
    {"role": "user", "content": ner_conditioned_re_input},
    {"role": "assistant", "content": ner_conditioned_re_output},
    {"role": "user", "content": convert_format_to_template(original_string=ner_conditioned_re_frame, placeholder_mapping=None, static_values=None)}
]
</code></pre>
    <p>
     这一步会根据上面抽取出来的实体、原始文本内容生成三元组。
    </p>
    <p>
     格式如：[主语, 谓语, 宾语]
    </p>
    <p>
     4、对原始文本、三元组、实体进行向量化
    </p>
    <p>
     使用的是
     <a href="https://huggingface.co/nvidia/NV-Embed-v2" rel="nofollow">
      nvidia/NV-Embed-v2
     </a>
     模型，参数量为7B
    </p>
    <p>
     对不同类型的数据，使用的prompt不同，如下：
    </p>
    <pre><code class="prism language-python">instructions <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">'ner_to_node'</span><span class="token punctuation">:</span> <span class="token string">'Given a phrase, retrieve synonymous or relevant phrases that best match this phrase.'</span><span class="token punctuation">,</span>
    <span class="token string">'query_to_node'</span><span class="token punctuation">:</span> <span class="token string">'Given a question, retrieve relevant phrases that are mentioned in this question.'</span><span class="token punctuation">,</span>
    <span class="token string">'query_to_fact'</span><span class="token punctuation">:</span> <span class="token string">'Given a question, retrieve relevant triplet facts that matches this question.'</span><span class="token punctuation">,</span>
    <span class="token string">'query_to_sentence'</span><span class="token punctuation">:</span> <span class="token string">'Given a question, retrieve relevant sentences that best answer the question.'</span><span class="token punctuation">,</span>
    <span class="token string">'query_to_passage'</span><span class="token punctuation">:</span> <span class="token string">'Given a question, retrieve relevant documents that best answer the question.'</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
</code></pre>
    <p>
     5、增加同义词边
    </p>
    <p>
     连接语义相近的实体
    </p>
    <h4>
     <a id="_147">
     </a>
     在线检索和问答阶段
    </h4>
    <p>
     1、检索topn 的三元组，用LLM对检索结果过滤无关三元组
     <br/>
     * 如果没有检索到三元组，则直接检索相关文档
     <br/>
     * 如果检索到三元组，则从构建的图中基于个性化的pagerank算法，检索出topn的相关文档
    </p>
    <p>
     2、利用LLM基于检索结果回答
    </p>
    <p>
     对应prompt
    </p>
    <pre><code class="prism language-python">one_shot_ircot_demo_docs <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token triple-quoted-string string">"""Wikipedia Title: Milk and Honey (album)\nMilk and Honey is an album by John Lennon and Yoko Ono released in 1984. Following the compilation "The John Lennon Collection", it is Lennon's eighth and final studio album, and the first posthumous release of new Lennon music, having been recorded in the last months of his life during and following the sessions for their 1980 album "Double Fantasy". It was assembled by Yoko Ono in association with the Geffen label.\n\n"""</span>
    <span class="token triple-quoted-string string">"""Wikipedia Title: John Lennon Museum\nJohn Lennon Museum (ジョン・レノン・ミュージアム , Jon Renon Myūjiamu ) was a museum located inside the Saitama Super Arena in Chūō-ku, Saitama, Saitama Prefecture, Japan. It was established to preserve knowledge of John Lennon's life and musical career. It displayed Lennon's widow Yoko Ono's collection of his memorabilia as well as other displays. The museum opened on October 9, 2000, the 60th anniversary of Lennon’s birth, and closed on September 30, 2010, when its exhibit contract with Yoko Ono expired. A tour of the museum began with a welcoming message and short film narrated by Yoko Ono (in Japanese with English headphones available), and ended at an avant-garde styled "reflection room" full of chairs facing a slide show of moving words and images. After this room there was a gift shop with John Lennon memorabilia available.\n\n"""</span>
    <span class="token triple-quoted-string string">"""Wikipedia Title: Walls and Bridges\nWalls and Bridges is the fifth studio album by English musician John Lennon. It was issued by Apple Records on 26 September 1974 in the United States and on 4 October in the United Kingdom. Written, recorded and released during his 18-month separation from Yoko Ono, the album captured Lennon in the midst of his "Lost Weekend". "Walls and Bridges" was an American "Billboard" number-one album and featured two hit singles, "Whatever Gets You thru the Night" and "#9 Dream". The first of these was Lennon's first number-one hit in the United States as a solo artist, and his only chart-topping single in either the US or Britain during his lifetime.\n\n"""</span>
    <span class="token triple-quoted-string string">"""Wikipedia Title: Nobody Loves You (When You're Down and Out)\n"Nobody Loves You (When You're Down and Out)" is a song written by John Lennon released on his 1974 album "Walls and Bridges". The song is included on the 1986 compilation "Menlove Ave.", the 1990 boxset "Lennon", the 1998 boxset "John Lennon Anthology", the 2005 two-disc compilation "", and the 2010 boxset "Gimme Some Truth".\n\n"""</span>
    <span class="token triple-quoted-string string">"""Wikipedia Title: Give Peace a Chance\n"Give Peace a Chance" is an anti-war song written by John Lennon (credited to Lennon–McCartney), and performed with Yoko Ono in Montreal, Quebec, Canada. Released as a single in 1969 by the Plastic Ono Band on Apple Records (catalogue Apple 13 in the United Kingdom, Apple 1809 in the United States), it is the first solo single issued by Lennon, released when he was still a member of the Beatles, and became an anthem of the American anti-war movement during the 1970s. It peaked at number 14 on the "Billboard" Hot 100 and number 2 on the British singles chart.\n"""</span>
<span class="token punctuation">)</span>


one_shot_ircot_demo <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>one_shot_ircot_demo_docs<span class="token punctuation">}</span></span><span class="token string">'</span></span>
    <span class="token string">'\n\nQuestion: '</span>
    <span class="token string-interpolation"><span class="token string">f"Nobody Loves You was written by John Lennon and released on what album that was issued by Apple Records, and was written, recorded, and released during his 18 month separation from Yoko Ono?"</span></span>
    <span class="token string">'\nThought: '</span>
    <span class="token string-interpolation"><span class="token string">f"The album issued by Apple Records, and written, recorded, and released during John Lennon's 18 month separation from Yoko Ono is Walls and Bridges. Nobody Loves You was written by John Lennon on Walls and Bridges album. So the answer is: Walls and Bridges."</span></span>
    <span class="token string">'\n\n'</span>
<span class="token punctuation">)</span>

ircot_system <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token string">'You serve as an intelligent assistant, adept at facilitating users through complex, multi-hop reasoning across multiple documents. This task is illustrated through demonstrations, each consisting of a document set paired with a relevant question and its multi-hop reasoning thoughts. Your task is to generate one thought for current step, DON\'T generate the whole thoughts at once! If you reach what you believe to be the final step, start with "So the answer is:".'</span>
    <span class="token string">'\n\n'</span>
    <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>one_shot_ircot_demo<span class="token punctuation">}</span></span><span class="token string">'</span></span>
<span class="token punctuation">)</span>


prompt_template <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> ircot_system<span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string">"${prompt_user}"</span><span class="token punctuation">}</span>
<span class="token punctuation">]</span>
</code></pre>
    <h3>
     <a id="_190">
     </a>
     总结
    </h3>
    <p>
     1、只是用三元组来协助检索，并没有利用图
     <br/>
     2、难以相信这种做法能超越普通RAG几十个点
    </p>
    <p>
     参考：
    </p>
    <p>
     <a href="https://arxiv.org/pdf/2502.14802" rel="nofollow">
      HippoRAG 2: From RAGtoMemory: Non-Parametric Continual Learning for Large Language Models
     </a>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34343139333936392f:61727469636c652f64657461696c732f313436313732303834" class_="artid" style="display:none">
 </p>
</div>


