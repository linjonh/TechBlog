---
layout: post
title: "Elastic-Stack-8.16.0-日志收集平台的搭建"
date: 2025-03-13 16:15:00 +0800
description: "本篇分享了Elastisearch、Logstash、Kibana 和 Filebeat 8.16.0 的安装，以及介绍了安装过程中的注意事项"
keywords: "Elastic Stack 8.16.0 日志收集平台的搭建"
categories: ['未分类']
tags: ['Stack', 'Logstash', 'Kibana', 'Filebeat', 'Elk', 'Elastisearch', 'Elastic']
artid: "146200423"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146200423
    alt: "Elastic-Stack-8.16.0-日志收集平台的搭建"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146200423
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146200423
cover: https://bing.ee123.net/img/rand?artid=146200423
image: https://bing.ee123.net/img/rand?artid=146200423
img: https://bing.ee123.net/img/rand?artid=146200423
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Elastic Stack 8.16.0 日志收集平台的搭建
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     简介
    </h2>
    <h3>
     1.1 ELK 介绍
    </h3>
    <p>
    </p>
    <p>
     ELK 是 ‌
     <strong>
      Elasticsearch
     </strong>
     ‌、‌
     <strong>
      Logstash
     </strong>
     ‌、‌
     <strong>
      Kibana
     </strong>
     ‌ 三款开源工具的首字母缩写，构成了一套完整的日志管理解决方案，主要用于日志的采集、存储、分析与可视化‌。
    </p>
    <p>
     1）Logstash：数据管道工具，负责从多种来源（如文件、数据库、消息队列）采集日志，进行过滤、格式化后输出到目标（如 Elasticsearch）‌；
    </p>
    <p>
     2）Elasticsearch：分布式实时搜索与分析引擎，基于 Lucene 构建，负责存储和检索数据。支持全文检索、结构化查询和大规模数据的高效处理‌；
    </p>
    <p>
     3）Kibana：数据可视化平台，提供交互式图表、仪表盘和地图，提供 ‌
     <strong>
      Dev Tools
     </strong>
     ‌ 直接操作 Elasticsearch 中的数据并生成可视化报告‌；
    </p>
    <p>
     <img alt="" height="283" src="https://i-blog.csdnimg.cn/direct/1fd8577bb03c4a399eca740d32491641.png" width="1017"/>
    </p>
    <h3>
     1.2 Elastic Stack 介绍
    </h3>
    <p>
     Logstash 是基于 JVM 运行，默认堆内存 1GB，资源消耗较高，单节点处理能力受限于 CPU 和内存‌ ，尤其在大规模日志场景下性能瓶颈明显‌ 。Elastic公司推出‌Beats家族‌，旨在提供轻量级、专一化的数据采集工具。Filebeat作为其中一员，专攻‌日志文件采集‌，解决了Logstash Forwarder（旧版采集器）的功能局限和性能问题‌。
    </p>
    <p>
     Filebeat采用Go语言开发，具有低资源占用（CPU/内存消耗可忽略不计）、易部署等特点，尤其适合边缘节点和资源受限环境‌。
     <br/>
     <br/>
     随着 Beats 等新成员的加入，原有名称无法涵盖全部组件。为统一品牌和技术生态，Elastic 公司将 ELK 更名为 ‌Elastic Stack‌，强调其能力的全面性（如支持日志、指标、安全监控等）。
    </p>
    <p>
     <img alt="" height="284" src="https://i-blog.csdnimg.cn/direct/61089235e6af42708930f17ab9691840.png" width="1345"/>
    </p>
    <h3>
     1.3 高并发高可用架构（分布式）
    </h3>
    <p>
     在高并发的架构中，ELK可以结合Kafka作为中间件，用于解耦数据生产者和消费者，处理突发的数据流量，避免Logstash或Elasticsearch过载。
    </p>
    <p>
     1）
     <strong>
      Beats
     </strong>
     ‌（Filebeat/Metricbeat）直接采集数据并发送至 Kafka 主题，避免数据直接冲击下游组件‌；
    </p>
    <p>
     2）
     <strong>
      Logstash
     </strong>
     ‌ 从 Kafka 消费数据，进行过滤、富化等操作后批量写入 Elasticsearch‌；
    </p>
    <p>
     <img alt="" height="408" src="https://i-blog.csdnimg.cn/direct/82fd124b3d324af496966ae004ac585f.png" width="2034"/>
    </p>
    <h2>
     准备工作
    </h2>
    <p>
     1）准备一台服务器，系统为CentOS8；
    </p>
    <p>
     2）安装Docker及docker-compose；
    </p>
    <blockquote>
     <p>
      <span style="color:#fe2c24">
       注：在安装 Elasticsearch、Kibana、Logstash，需安装相同版本号的版本。Filebeat 和 ELK 的大版本也要保持一致。
      </span>
     </p>
    </blockquote>
    <h2>
     Elasticsearch 安装
    </h2>
    <h3>
     3.1 elasticsearch.yml 配置
    </h3>
    <p>
     a）创建elasticsearch用户
    </p>
    <blockquote>
     <p>
      useradd elasticsearch
     </p>
    </blockquote>
    <p>
     可通过 cat /etc/passwd 查看当前系统的用户信息。
    </p>
    <p>
     b）在home目录中，创建elasticsearch目录，并授权给elasticsearch用户
    </p>
    <blockquote>
     <p>
      mkdir elasticsearch
     </p>
     <p>
      chown -R elasticsearch:elasticsearch /home/elasticsearch
     </p>
    </blockquote>
    <p>
     c）在elasticsearch目录中，创建data、logs、conf目录
    </p>
    <p>
     d）在conf目录中，创建elasticsearch.yml文件。文件的配置信息如下：
    </p>
    <pre><code class="language-Groovy"># 集群名称
cluster.name: es-cluster
network.host: 0.0.0.0
# 支持跨域访问
http.cors.enabled: true
http.cors.allow-origin: "*"
# 关闭安全认证
xpack.security.enabled: false</code></pre>
    <h3>
     3.2 elk_elasticsearch-compose.yml 配置
    </h3>
    <p>
     编写 elk_elasticsearch-compose.yml，内容如下：
    </p>
    <pre><code class="language-Groovy">version: "3"
services:
  elasticsearch:
    container_name: elasticsearch
    hostname: elasticsearch
    image: elasticsearch:8.16.0
    user: "elasticsearch:elasticsearch"
    ports:
      - 9200:9200
    volumes:
      - /home/elasticsearch/conf/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - /home/elasticsearch/data:/usr/share/elasticsearch/data
      - /home/elasticsearch/logs:/usr/share/elasticsearch/logs
    environment:
      - "discovery.type=single-node"  # 设置elasticsearch为单节点
      - "TAKE_FILE_OWNERSHIP=true"   # 在容器启动时，自动将宿主机中挂载的卷的文件操作权限赋给容器的用户（默认为UID 1000）。
      - "ES_JAVA_OPTS=-Xms216m -Xmx512m"
      - "TZ=Asia/Shanghai"
</code></pre>
    <p>
     1）user: "elasticsearch:elasticsearch"
    </p>
    <blockquote>
     <p>
      elasticsearch容器的用户为elasticsearch
     </p>
    </blockquote>
    <p>
     2）- "TAKE_FILE_OWNERSHIP=true"
    </p>
    <blockquote>
     <p>
      在容器启动时，自动将宿主机中挂载的卷的文件操作权限赋给容器的用户（默认为UID 1000）。
     </p>
     <p>
      生产环境慎用：自动修改目录权限可能存在安全风险，建议预配置权限
     </p>
    </blockquote>
    <h3>
     3.3 执行安装
    </h3>
    <p>
     进入elk_elasticsearch_compose.yml 目录，执行如下：
    </p>
    <blockquote>
     <p>
      docker-compse -f elk_elasticsearch_compose.yml up -d
     </p>
    </blockquote>
    <h3>
     3.4 docker 常用命令
    </h3>
    <p>
     1）查看容器id
    </p>
    <blockquote>
     <p>
      docker ps
     </p>
    </blockquote>
    <p>
     2）查看容器实时日志
    </p>
    <blockquote>
     <p>
      docker logs -f 容器id
     </p>
    </blockquote>
    <p>
     3）将日志实时追加到日志文件中
    </p>
    <blockquote>
     <p>
      docker logs -f 容器id  &gt;&gt; test.log 2&gt;&amp;1
     </p>
    </blockquote>
    <p>
     4）进入容器
    </p>
    <blockquote>
     <p>
      docker exec -it 容器id bash
     </p>
    </blockquote>
    <h2>
     Logstash 安装
    </h2>
    <h3>
     4.1 logstash.yml 配置
    </h3>
    <p>
     在home目录中，创建logstash/conf目录，创建logstash.yml文件，文件的配置信息如下：
    </p>
    <pre><code class="language-Groovy"># 通过filebeat数据输入，端口为5044
input {
  beats {
    port =&gt; 5044
  }
}

# 数据处理
filter {
  grok {   # Grok结构化文本解析，解析日志信息
    match =&gt; [    
      "message", "(?&lt;logTime&gt;\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2}.\d{3})\s+\[(?&lt;thread&gt;.*)\]\s+(?&lt;level&gt;\w*)\s{1,2}+(?&lt;class&gt;\S*)\s+-\s+(?&lt;content&gt;.*)\s*"
    ] 
  }
  date {    # 时间处理
    match =&gt; ["timestamp_string", "ISO8601"]
  }
  mutate {   # 字段操作
    remove_field =&gt; [message, timestamp_string]
  }   
}
 
# 数据输出
output {        
  elasticsearch {   # 输出到elasticsearch
    hosts =&gt;  ["http://192.168.199.210:9200"]
    index =&gt; "logstash-test"
  }
  stdout {   # 输出到控制器，用于调试
    codec =&gt; rubydebug
  }
}
</code></pre>
    <h4>
     1）logstash配置分为三部分，分别为
    </h4>
    <blockquote>
     <p>
      input {   ...    }       # 数据输入
     </p>
     <p>
      filter {    ...    }       # 数据处理
     </p>
     <p>
      output {   ...    }     # 数据输出
     </p>
    </blockquote>
    <h4>
     2）grok的match
    </h4>
    <blockquote>
     <p>
      a）logstash接收到内容会放到message字段中，通过正则表达式匹配message中的信息；
     </p>
     <p>
      b）可配置多个解析规则，当任意一个 message 匹配上了这个正则，则 grok 执行完毕；
     </p>
     <p>
      c）如果配置了多个规则，grok依然没有匹配上，message 也会输出到 ES，只是这条日志在 ES 中不会展示 logTime、level 等字段；
     </p>
    </blockquote>
    <p>
     grok的正则表达式编写比较麻烦，可通过 kibana 进行调试
    </p>
    <blockquote>
     <p>
      <a href="http://IP:5601/app/dev_tools#/grokdebugger" rel="nofollow" title="http://IP:5601/app/dev_tools#/grokdebugger">
       http://IP:5601/app/dev_tools#/grokdebugger
      </a>
     </p>
    </blockquote>
    <p>
     <img alt="" height="761" src="https://i-blog.csdnimg.cn/direct/b5de02b326d54ac394e9b83dbb2f8937.png" width="1540"/>
    </p>
    <blockquote>
     <p>
      如上面的日志信息，通过解析后，会解析出level、thread、class、content 和 logTime
     </p>
    </blockquote>
    <h3>
     4.2 elk_logstash_compose.yml 配置
    </h3>
    <p>
     elk_logstash_compose.yml 的内容如下：
    </p>
    <pre><code class="language-Groovy">version: "3"
services:
  logstash:
    container_name: logstash
    hostname: logstash
    image: logstash:8.16.0
    command: logstash -f ./conf/logstash.conf
    volumes:
      - /home/logstash/conf/logstash.conf:/usr/share/logstash/conf/logstash.conf
    environment:
      - elasticsearch.hosts=http://192.168.199.210:9200
      - xpack.monitoring.elasticsearch.hosts=http://192.168.199.210:9200   # 解决logstash监控连接报错
      - "TZ=Asia/Shanghai"
      - "LS_JAVA_OPTS=-Xms216m -Xmx512m"
    ports:
      - 5044:5044</code></pre>
    <p>
     同3.3，执行 elk_logstash_compose.yml 进行安装
    </p>
    <h2>
     Filebeat 安装
    </h2>
    <h3>
     5.1 filebeat.yml 配置
    </h3>
    <p>
     在home目录中，创建filebeat目录，创建conf、data 和 logs 文件夹。在conf中，创建logstash.yml文件，文件的配置信息如下：
    </p>
    <pre><code class="language-bash">filebeat.inputs:
- type: filestream
  enabled: true
  paths:
    - /home/app/*.log
  # 多行日志合并（处理Java异常堆栈）
  multiline:
    pattern: '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3}'
    negate: false
    match: after
# 使用processors 提取字段
processors:
  # 第一步：使用 dissect 分解原始日志行
  - dissect:
      tokenizer: '%{timestamp} [%{thread}] %{level} %{logger} - %{message}'
      field: "message"  # 原始日志字段（默认存储为 message）
      target_prefix: ""   # 直接提取到根字段（非嵌套）
  # 第二步：解析时间戳（覆盖默认@timestamp）
  - timestamp:
      field: timestamp   # 从 dissect 提取的timestamp字段
      layouts:
        - '2006-01-02 15:04:05.000'   # Go 时间格式（必须与日志中的时间格式完全匹配）
      test:
        - '2025-03-07 10:12:23.123'   # 测试用例（可选）
  第三步：删除临时字段
  - drop_fields:
      fields: ["timestamp", "log.offset", "input.type"]  # 清理无用字段
# 输出到 Elasticsearch
output.elasticsearch:
  hosts: ["http://192.168.199.210:9200"]
  index: "filebeat-%{+yyyy.MM.dd}"
# 输出到控制台（测试时可查看结果）
output.console:
  pretty: true
  codec.json:
    pretty: true  
</code></pre>
    <blockquote>
     <p>
      在测试的时候，可以通过output.console，将信息输出到控制台。
     </p>
    </blockquote>
    <p>
     5.2 elk_filebeat_compose.yml 配置
    </p>
    <h3>
     elk_filebeat_compose.yml 的内容如下：
    </h3>
    <pre><code class="language-Groovy">version: "3"
services:
  filebeat:
    container_name: filebeat
    hostname: filebeat
    image: elastic/filebeat:8.16.4
    user: root
    volumes:
      # 映射到容器中【作为数据源】
      - /var/lib/docker/containers:/var/lib/docker/containers
      - /home/app:/home/app
      # 方便查看数据及日志
      - /home/filebeat/logs:/usr/share/filebeat/logs
      - /home/filebeat/data:/usr/share/filebeat/data
      - /home/filebeat/conf/filebeat.yml:/usr/share/filebeat/filebeat.yml
</code></pre>
    <p>
     1）user: root
    </p>
    <blockquote>
     <p>
      Filebeat 需要访问宿主机的文件，需要有 root 的权限
     </p>
    </blockquote>
    <p>
     2）- /home/app:/home/app
    </p>
    <blockquote>
     <p>
      <span style="color:#fe2c24">
       注：在 filebeat.yml 中配置了文件的 paths 为 /home/app 下的文件，此处需要将 /home/app3 和容器进行映射，否则 filebeat 将访问不到日志文件
      </span>
     </p>
    </blockquote>
    <p>
     同3.3，执行 elk_logstash_compose.yml 进行安装
    </p>
    <h2>
     Kibana 安装
    </h2>
    <h3>
     6.1 kibana.yml 配置
    </h3>
    <p>
     在home目录中，创建kibana/conf目录，创建kibana.yml文件，文件的配置信息如下：
    </p>
    <pre><code class="language-Groovy"># 服务端口
server.port: 5601
# 服务IP
server.host: "0.0.0.0"
# ES
elasticsearch.hosts: ["http://192.168.199.210:9200"]
# 汉化
i18n.locale: "zh-CN"</code></pre>
    <p>
     6.2 elk_kibana_compose.yml 配置
    </p>
    <p>
     elk_kibana_compose.yml 的配置如下：
    </p>
    <pre><code class="language-Groovy">version: "3"
services:
  kibana:
    container_name: kibana
    hostname: kibana
    image: kibana:8.16.0
    ports:
      - 5601:5601
    volumes:
      - /home/kibana/conf/kibana.yml:/usr/share/kibana/config/kibana.yml
    environment:
      - elasticsearch.hosts=http://192.168.199.210:9200
      - "TZ=Asia/Shanghai"
      - XPACK_SECURITY_ENABLED=false       # 关闭安全模块（非必要功能）
      - ELASTICSEARCH_ASSISTANT_ENABLED=false  # 禁用 Elastic Assistant 插件：ml-citation{ref="3,4" data="citationList"}
</code></pre>
    <blockquote>
     <p>
      Kibana安装时，需关闭安全模块（非必要功能）和禁用Elastic Assistant 插件
     </p>
    </blockquote>
    <blockquote>
     <p>
      <span style="color:#fe2c24">
       <strong>
        注：不同版本的 ELK 可能会存在不同的问题
       </strong>
      </span>
     </p>
    </blockquote>
    <h2>
     测试示例
    </h2>
    <p>
     容器都安装成功后，在 /home/app 中添加日志文件，测试的日志信息如下：
    </p>
    <pre><code class="language-bash">2025-03-04 01:34:24.143 [http-nio-8094-exec-7] INFO  c.q.s.s.i.SessionUserInterceptor - session user check ... false
2025-03-04 01:35:13.984 [nioEventLoopGroup-5-7] INFO  c.q.e.addsub.netty.WebSocketHandler - handlerRemove 调用fa163efffe9f832c-000079e3-00000973-55cbd5b44071a452-2c89d78a
</code></pre>
    <h2>
     结尾
    </h2>
    <p>
     以上为本篇分析的全部内容。
    </p>
    <p>
    </p>
    <p>
     关于本篇内容你有什么自己的想法或独到见解，欢迎在评论区一起交流探讨下吧。
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f4a696e6741695f6a69613931372f:61727469636c652f64657461696c732f313436323030343233" class_="artid" style="display:none">
 </p>
</div>


