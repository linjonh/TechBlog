---
arturl_encode: "68747470733a2f2f626c6f67:2e6373646e2e6e65742f48617264776f726b696e673636362f:61727469636c652f64657461696c732f313330393536313331"
layout: post
title: "ChatGPT与网络安全"
date: 2024-12-04 19:47:48 +08:00
description: "ChatGPT是一种基于生成式预训练模型（GPT）的聊天机器人，其核心技术是自然语言处理（NLP）。"
keywords: "ChatGPT与网络安全"
categories: ['网络安全']
tags: ['人工智能', 'Chatgpt']
artid: "130956131"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=130956131
    alt: "ChatGPT与网络安全"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=130956131
featuredImagePreview: https://bing.ee123.net/img/rand?artid=130956131
---

# ChatGPT与网络安全

#### 文章目录

* [一、“AI用于攻击”](#AI_10)
* [二、“AI用于安全（防御）”](#AI_16)
* [三、“AI的防御”](#AI_25)
* [四、“AI被攻击”](#AI_27)

ChatGPT作为基于生成式预训练模型（GPT）的聊天机器人，其核心技术是自然语言处理（NLP）。随着NLP技术的不断发展，ChatGPT的智能程度也在飞速提高。最初的ChatGPT只能回答一些简单的问题，但现在它已经可以根据用户的偏好提供更加个性化的建议和服务。

ChatGPT通过自然语言处理技术理解用户的输入，并根据用户的需求提供相应的服务和建议。ChatGPT在生产（例如智能客服、电子商务、医疗保健等）和生活中的广泛应用，将极大地改善体验，提升效率。

作为在线服务类的AI应用，ChatGPT在提高用户体验方面有很大的优势，但是它也会对网络安全产生深远的影响。特别是2023年1月，一篇新闻报道指出，使用ChatGPT可以自动化的构建可以绕过安全检测的恶意程序，引发了关于网络安全的广泛担忧。

一般而言，ChatGPT作为AI的一种用例或者说场景，其和网络安全领域有如下四个维度的交互：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/8a52773be649a5e05959c0ef441ec230.png)

## 一、“AI用于攻击”

“AI用于攻击”，分析了攻击者（恶意行为者）可以如何利用ChatGPT增强其“武器库”。特别是，针对网络攻击链的各个环节，特别是“侦查”和“漏洞利用”两个环节，ChatGPT都可以起到非常大的作用。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/1f521977fecfb4386ece07ebdb0c649b.png)
  
在侦查阶段的目标识别上，AI模型基于其掌握的海量信息，可以让用户（甚至是恶意行为者）迅速收集目标的各项相关信息。例如，人工收集某企业的人员名单和组织架构可能非常耗时耗力，而ChatGPT可以以较小的代价做到这一点。

在侦查阶段的“寻找漏洞”环节，AI模型也可以增强攻击者的知识库（比如nmap扫描的端口类型、常见服务、其管理页面等），使攻击更有效。

## 二、“AI用于安全（防御）”

“AI用于安全（防御）”，是指防御者也可以将AI作为防御手段，从广度和深度两个维度，提升防御的质量和效率。

ChatGPT可以通过自然语言处理技术识别恶意信息，并及时向用户发出警报，从而帮助用户避免受到网络攻击。此外，ChatGPT还可以通过机器学习技术不断学习和优化自身的安全防御能力，提高其对网络安全的保护能力。

ChatGPT可以在网络防御中常见的安全漏洞识别、安全配置脚本自动化处理、安全工具集成等场景发挥作用。例如自动生成脚本。

此外，ChatGPT还可以用于网络安全培训和教育。ChatGPT可以通过自然语言处理技术向用户提供网络安全知识和技能，帮助用户提高网络安全意识和能力，从而减少网络安全风险。

## 三、“AI的防御”

“AI的防御”，是指AI模型本身的安全。主要是指提供方需要从正向设计AI模型的安全性。ChatGPT的开发者OpenAI并未公开发布论文或者白皮书，详述ChatGPT的防御机制，特别是模型安全、算法安全等维度。但是，作为互联网服务，其互联网基础设施的安全问题，例如连接和会话安全、API安全、用户的身份认证和传输加密等，均不容忽视。

## 四、“AI被攻击”

“AI被攻击”，是指AI作为被攻击的目标对象。这个维度和“AI的防御”类似，只是从攻击和防御的不同视角。由于ChatGPT可以通过自然语言处理技术理解用户的输入，黑客可以通过发送恶意提示信息来攻击ChatGPT，从而窃取用户的敏感信息，这种攻击方式一般被称为“提示注入攻击”。因此，ChatGPT的开发者需要采取一系列的安全措施来保护ChatGPT的安全。

对于企业等各类组织而言，在ChatGPT的引入和使用的过程中，传统的信息安全的风险也很重要。涉及企业商业秘密、个人识别信息的数据，不应该输入到ChatGPT；需要实施身份认证、访问控制和审计等多种措施，防止数据的非授权访问等。采取上述策略，“……可确保企业安全、负责任地使用ChatGPT等AI驱动工具，也能最大限度地发挥这些技术的潜在价值。”

最后，截至目前为止，在通用人工智能（AGI）时代之前，AI提供的各项服务，诸如ChatGPT等，仍然是一个有用的“助手”或者“工具”，掌握在谁的手中很重要。在网络安全领域，恶意行为者掌握了工具，可以大大的提升侦查、漏洞利用的效率；防御者也同样可以利用ChatGPT的技术优势，提高网络安全防御能力和网络安全教育水平。

ChatGPT并非是洪水猛兽，也无需谈虎色变，让我们每个网络安全的从业者，深入的理解它，掌握它，在业务中有效运用它，在攻防对抗中不断增强个体和组织的实力，构筑网络空间的安全和数据的有效保护，充分利用的能力。

参考来源：云安全联盟大中华区报告《ChatGPT的安全影响（Security Implications of ChatGPT）》