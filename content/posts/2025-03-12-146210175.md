---
layout: post
title: "超越限制大模型token管理与优化实践"
date: 2025-03-12 17:21:52 +0800
description: "在大型语言模型（LLM）的应用中，token数量的管理是一个核心挑战。无论是模型的输入限制、计算资源的分配，还是成本的控制，token计数都至关重要。然而，当调用超过预期范围时，我们该如何应对？本书以一段简单的Python代码为起点，探索token管理的实用方法，帮助开发者从临时方案走向系统化解决方案。"
keywords: "超过模型token限制 解决"
categories: ['未分类']
tags: ['开发语言', 'Python']
artid: "146210175"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146210175
    alt: "超越限制大模型token管理与优化实践"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146210175
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146210175
cover: https://bing.ee123.net/img/rand?artid=146210175
image: https://bing.ee123.net/img/rand?artid=146210175
img: https://bing.ee123.net/img/rand?artid=146210175
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     超越限制：大模型token管理与优化实践
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="_0">
     </a>
     前言
    </h3>
    <p>
     在大型语言模型（LLM）的应用中，token数量的管理是一个核心挑战。无论是模型的输入限制、计算资源的分配，还是成本的控制，token计数都至关重要。然而，当调用超过预期范围时，我们该如何应对？本书以一段简单的Python代码为起点，探索token管理的实用方法，帮助开发者从临时方案走向系统化解决方案。
    </p>
    <h3>
     <a id="_3">
     </a>
     第一章：问题的起源——调用超预期
    </h3>
    <h4>
     <a id="11_token_4">
     </a>
     1.1 大模型的token限制
    </h4>
    <ul>
     <li>
      LLM为何对token敏感？从输入上下文窗口到输出生成长度。
     </li>
     <li>
      案例：调用API时意外超出限制的后果（错误、成本激增）。
     </li>
     <li>
      引出问题：如何提前发现和管理超预期情况？
     </li>
    </ul>
    <h4>
     <a id="12__9">
     </a>
     1.2 临时方案的诞生
    </h4>
    <ul>
     <li>
      JSON结构：
      <code>
       "original_data"
      </code>
      作为输入，
      <code>
       "generated_text"
      </code>
      作为输出。
     </li>
     <li>
      代码简介：统计token的简单工具。
     </li>
     <li>
      临时方案的优势与局限性。
     </li>
    </ul>
    <h3>
     <a id="_14">
     </a>
     第二章：代码解构——从临时到实用
    </h3>
    <h4>
     <a id="21__15">
     </a>
     2.1 核心功能分析
    </h4>
    <p>
     以下是代码，我将逐部分解释其在token管理中的作用：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> json
<span class="token keyword">import</span> tiktoken

<span class="token keyword">def</span> <span class="token function">calculate_token</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"deepseek-v3"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""计算文本的token数量"""</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        encoding <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>encoding_for_model<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
        tokens <span class="token operator">=</span> encoding<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>
    <span class="token keyword">except</span> KeyError<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"模型编码未找到。使用默认编码。"</span><span class="token punctuation">)</span>
        encoding <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span><span class="token string">"cl100k_base"</span><span class="token punctuation">)</span>
        tokens <span class="token operator">=</span> encoding<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">calculate_total_tokens</span><span class="token punctuation">(</span>output_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""计算输出目录中所有JSON文件的总输入和输出token数量"""</span>
    total_input_tokens <span class="token operator">=</span> <span class="token number">0</span>
    total_output_tokens <span class="token operator">=</span> <span class="token number">0</span>
    total_files <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">for</span> filename <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>output_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> filename<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">".json"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            file_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>output_dir<span class="token punctuation">,</span> filename<span class="token punctuation">)</span>
            <span class="token keyword">try</span><span class="token punctuation">:</span>
                <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
                    data <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
                    input_tokens <span class="token operator">=</span> calculate_token<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">"original_data"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                    output_tokens <span class="token operator">=</span> calculate_token<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">"generated_text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                    total_input_tokens <span class="token operator">+=</span> input_tokens
                    total_output_tokens <span class="token operator">+=</span> output_tokens
                    total_files <span class="token operator">+=</span> <span class="token number">1</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"文件: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>filename<span class="token punctuation">}</span></span><span class="token string">, 输入token: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>input_tokens<span class="token punctuation">}</span></span><span class="token string">, 输出token: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>output_tokens<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
            <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"处理文件 </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>filename<span class="token punctuation">}</span></span><span class="token string"> 时出错: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>e<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\n总文件数: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>total_files<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"总输入token数: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>total_input_tokens<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"总输出token数: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>total_output_tokens<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

output_dir <span class="token operator">=</span> <span class="token string">"generated_jsons"</span>
calculate_total_tokens<span class="token punctuation">(</span>output_dir<span class="token punctuation">)</span>
</code></pre>
    <ul>
     <li>
      <strong>
       <code>
        calculate_token
       </code>
      </strong>
      ：计算单段文本的token数，支持特定模型（如“deepseek-v3”），并提供备用编码。
     </li>
     <li>
      <strong>
       <code>
        calculate_total_tokens
       </code>
      </strong>
      ：扫描目录，统计所有JSON文件的输入和输出token总数。
     </li>
     <li>
      <strong>
       JSON结构
      </strong>
      ：临时设计的
      <code>
       "original_data"
      </code>
      和
      <code>
       "generated_text"
      </code>
      字段，直观反映模型的输入输出。
     </li>
    </ul>
    <h4>
     <a id="22__66">
     </a>
     2.2 代码的应用场景
    </h4>
    <ul>
     <li>
      <strong>
       调试
      </strong>
      ：快速检查每次调用的token消耗。
     </li>
     <li>
      <strong>
       成本估算
      </strong>
      ：按token计费时，预估总费用。
     </li>
     <li>
      <strong>
       优化提示
      </strong>
      ：识别长输入或冗长输出，调整策略。
     </li>
    </ul>
    <h4>
     <a id="23__71">
     </a>
     2.3 局限性与改进方向
    </h4>
    <ul>
     <li>
      <strong>
       临时性
      </strong>
      ：JSON结构简单，但缺乏元数据（如模型参数、时间戳）。
     </li>
     <li>
      <strong>
       单一性
      </strong>
      ：仅支持固定字段，难以扩展。
     </li>
     <li>
      <strong>
       性能
      </strong>
      ：对大量文件处理效率低。
     </li>
    </ul>
    <h3>
     <a id="_76">
     </a>
     第三章：应对超预期——策略与实践
    </h3>
    <h4>
     <a id="31__77">
     </a>
     3.1 识别超预期情况
    </h4>
    <ul>
     <li>
      定义“预期范围”：输入token上限、输出token预算。
     </li>
     <li>
      使用代码监控：实时统计token，设置阈值告警。
     </li>
    </ul>
    <h4>
     <a id="32__81">
     </a>
     3.2 优化输入
    </h4>
    <ul>
     <li>
      <strong>
       文本压缩
      </strong>
      ：去除冗余内容，精简
      <code>
       "original_data"
      </code>
      。
     </li>
     <li>
      <strong>
       分段处理
      </strong>
      ：将长输入拆分为多个调用。
     </li>
     <li>
      示例代码：扩展
      <code>
       calculate_token
      </code>
      以支持分段。
     </li>
    </ul>
    <h4>
     <a id="33__86">
     </a>
     3.3 控制输出
    </h4>
    <ul>
     <li>
      <strong>
       生成参数调整
      </strong>
      ：限制
      <code>
       "generated_text"
      </code>
      长度（如设置
      <code>
       max_tokens
      </code>
      ）。
     </li>
     <li>
      <strong>
       后处理
      </strong>
      ：截断或总结超长输出。
     </li>
     <li>
      示例代码：添加输出token阈值检查。
     </li>
    </ul>
    <h4>
     <a id="34__91">
     </a>
     3.4 成本管理
    </h4>
    <ul>
     <li>
      计算token成本：结合API定价（如每千token $0.002）。
     </li>
     <li>
      扩展代码：输出成本估算报告。
     </li>
    </ul>
    <h3>
     <a id="_95">
     </a>
     第四章：从临时到系统化
    </h3>
    <h4>
     <a id="41_JSON_96">
     </a>
     4.1 改进JSON结构
    </h4>
    <ul>
     <li>
      增强版JSON：
      <pre><code class="prism language-json"><span class="token punctuation">{<!-- --></span>
  <span class="token string-property property">"input"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string-property property">"text"</span><span class="token operator">:</span> <span class="token string">"Hello, world!"</span><span class="token punctuation">,</span>
    <span class="token string-property property">"token_count"</span><span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span>
    <span class="token string-property property">"timestamp"</span><span class="token operator">:</span> <span class="token string">"2025-03-12T10:00:00"</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token string-property property">"output"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string-property property">"text"</span><span class="token operator">:</span> <span class="token string">"Hello, world! How are you?"</span><span class="token punctuation">,</span>
    <span class="token string-property property">"token_count"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
    <span class="token string-property property">"model_params"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string-property property">"max_tokens"</span><span class="token operator">:</span> <span class="token number">50</span><span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
     </li>
     <li>
      优点：自描述性强，可追溯。
     </li>
    </ul>
    <h4>
     <a id="42_token_114">
     </a>
     4.2 构建token管理系统
    </h4>
    <ul>
     <li>
      <strong>
       数据库存储
      </strong>
      ：从JSON文件升级到SQLite或MongoDB。
     </li>
     <li>
      <strong>
       实时监控
      </strong>
      ：集成API调用，动态更新token统计。
     </li>
     <li>
      <strong>
       可视化
      </strong>
      ：用Matplotlib生成token使用图表。
     </li>
    </ul>
    <h4>
     <a id="43__119">
     </a>
     4.3 示例实现
    </h4>
    <ul>
     <li>
      扩展代码：添加数据库支持、阈值告警和可视化。
     </li>
    </ul>
    <pre><code class="prism language-python"><span class="token keyword">import</span> sqlite3
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">def</span> <span class="token function">save_to_db</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> db_path<span class="token operator">=</span><span class="token string">"token_usage.db"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    conn <span class="token operator">=</span> sqlite3<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>db_path<span class="token punctuation">)</span>
    c <span class="token operator">=</span> conn<span class="token punctuation">.</span>cursor<span class="token punctuation">(</span><span class="token punctuation">)</span>
    c<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token triple-quoted-string string">'''CREATE TABLE IF NOT EXISTS usage 
                 (filename TEXT, input_tokens INTEGER, output_tokens INTEGER)'''</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> filename<span class="token punctuation">,</span> input_t<span class="token punctuation">,</span> output_t <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        c<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"INSERT INTO usage VALUES (?, ?, ?)"</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>filename<span class="token punctuation">,</span> input_t<span class="token punctuation">,</span> output_t<span class="token punctuation">)</span><span class="token punctuation">)</span>
    conn<span class="token punctuation">.</span>commit<span class="token punctuation">(</span><span class="token punctuation">)</span>
    conn<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 结合calculate_total_tokens，保存结果到数据库并绘图</span>
</code></pre>
    <h3>
     <a id="_138">
     </a>
     第五章：未来展望
    </h3>
    <ul>
     <li>
      <strong>
       自动化token优化
      </strong>
      ：AI驱动的输入输出调整。
     </li>
     <li>
      <strong>
       跨模型兼容
      </strong>
      ：支持更多模型的token化方案。
     </li>
     <li>
      <strong>
       云端集成
      </strong>
      ：将token管理部署为服务。
     </li>
    </ul>
    <h3>
     <a id="_143">
     </a>
     附录
    </h3>
    <ul>
     <li>
      <strong>
       代码完整版
      </strong>
      ：包含所有扩展功能。
     </li>
     <li>
      <strong>
       资源链接
      </strong>
      ：
      <code>
       tiktoken
      </code>
      文档、LLM优化指南。
     </li>
    </ul>
    <hr/>
    <h3>
     <a id="___149">
     </a>
     示例章节：第三章 - 应对超预期
    </h3>
    <h4>
     <a id="31__150">
     </a>
     3.1 识别超预期情况
    </h4>
    <p>
     当模型调用超出预期时，可能表现为：
    </p>
    <ul>
     <li>
      <strong>
       输入超限
      </strong>
      ：
      <code>
       "original_data"
      </code>
      超过模型上下文窗口（例如，GPT-3.5的4096 token）。
     </li>
     <li>
      <strong>
       输出冗长
      </strong>
      ：
      <code>
       "generated_text"
      </code>
      超出预算，增加成本。
     </li>
    </ul>
    <p>
     使用现有代码，我们可以：
    </p>
    <ol>
     <li>
      运行
      <code>
       calculate_total_tokens
      </code>
      ，获取统计。
     </li>
     <li>
      设置阈值，例如输入token &gt; 3000 或输出token &gt; 1000 时警告。
     </li>
    </ol>
    <pre><code class="prism language-python"><span class="token keyword">if</span> total_input_tokens <span class="token operator">&gt;</span> <span class="token number">3000</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"警告：输入token超出预期范围！"</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="32__163">
     </a>
     3.2 优化输入
    </h4>
    <p>
     若
     <code>
      "original_data"
     </code>
     过长，可尝试：
    </p>
    <ul>
     <li>
      <strong>
       手动精简
      </strong>
      ：删除不必要内容。
     </li>
     <li>
      <strong>
       自动分段
      </strong>
      ：
     </li>
    </ul>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">split_text</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> max_tokens<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    encoding <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span><span class="token string">"cl100k_base"</span><span class="token punctuation">)</span>
    tokens <span class="token operator">=</span> encoding<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> max_tokens<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>text<span class="token punctuation">]</span>
    segments <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">,</span> max_tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>
        segment <span class="token operator">=</span> encoding<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>tokens<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i <span class="token operator">+</span> max_tokens<span class="token punctuation">]</span><span class="token punctuation">)</span>
        segments<span class="token punctuation">.</span>append<span class="token punctuation">(</span>segment<span class="token punctuation">)</span>
    <span class="token keyword">return</span> segments
</code></pre>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34303934313130322f:61727469636c652f64657461696c732f313436323130313735" class_="artid" style="display:none">
 </p>
</div>


