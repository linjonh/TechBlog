---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f37343236383831372f:61727469636c652f64657461696c732f313436313136313531"
layout: post
title: "淘宝母婴购物数据可视化分析基于脱敏公开数据集"
date: 2025-03-08 15:31:02 +08:00
description: "思路，过程，收获"
keywords: "淘宝母婴数据分析"
categories: ['未分类']
tags: ['数据可视化', '数据分析', '学习笔记', 'Python']
artid: "146116151"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146116151
    alt: "淘宝母婴购物数据可视化分析基于脱敏公开数据集"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146116151
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146116151
cover: https://bing.ee123.net/img/rand?artid=146116151
image: https://bing.ee123.net/img/rand?artid=146116151
img: https://bing.ee123.net/img/rand?artid=146116151
---

# 淘宝母婴购物数据可视化分析（基于脱敏公开数据集）

## 一、前言

*以下是“阿里天池”上的比赛介绍，数据集也是源自于那里的公开数据集，数据经过脱敏处理，避免了用户隐私问题。下面是数据集和任务的介绍：*

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/1ac6a34b213042f78aa20940f6eba1b9.png)

## 二、数据导入与数据预处理

```python
import pandas as pd
# 导入交易信息表
trade_inf = pd.read_csv(r"C:\Users\31049\Desktop\数据分析\淘宝母婴购物数据可视化分析\tianchi_mum_baby_trade_history.csv")
# 查看前 10行数据
trade_inf.head(10)

```

|  | user\_id | auction\_id | category\_2 | category\_1 | buy\_mount | day |
| --- | --- | --- | --- | --- | --- | --- |
| 0 | 786295544 | 41098319944 | 50014866 | 50022520 | 2 | 20140919 |
| 1 | 532110457 | 17916191097 | 50011993 | 28 | 1 | 20131011 |
| 2 | 249013725 | 21896936223 | 50012461 | 50014815 | 1 | 20131011 |
| 3 | 917056007 | 12515996043 | 50018831 | 50014815 | 2 | 20141023 |
| 4 | 444069173 | 20487688075 | 50013636 | 50008168 | 1 | 20141103 |
| 5 | 152298847 | 41840167463 | 121394024 | 50008168 | 1 | 20141103 |
| 6 | 513441334 | 19909384116 | 50010557 | 50008168 | 1 | 20121212 |
| 7 | 297411659 | 13540124907 | 50010542 | 50008168 | 1 | 20121212 |
| 8 | 82830661 | 19948600790 | 50013874 | 28 | 1 | 20121101 |
| 9 | 475046636 | 10368360710 | 203527 | 28 | 1 | 20121101 |

```python
# 删除重复数据（不知道有没有重复数据也要执行一遍，避免重复）
trade_inf.drop_duplicates(subset=['auction_id'], inplace=True)

# 查看数据类型、查看有无缺省值
trade_inf.info()

```

```
<class 'pandas.core.frame.DataFrame'>
Index: 28422 entries, 0 to 29970
Data columns (total 6 columns):
 #   Column      Non-Null Count  Dtype
---  ------      --------------  -----
 0   user_id     28422 non-null  int64
 1   auction_id  28422 non-null  int64
 2   category_2  28422 non-null  int64
 3   category_1  28422 non-null  int64
 4   buy_mount   28422 non-null  int64
 5   day         28422 non-null  int64
dtypes: int64(6)
memory usage: 1.5 MB

```

可以发现，并没有缺缺失值，且部分字段的数据类型不正确，需要修正。

```python
# 数据类型转换
for col in ['user_id', 'auction_id', 'category_1', 'category_2', 'day']:
    trade_inf[col] = trade_inf[col].astype(str)
trade_inf['day'] = pd.to_datetime(trade_inf['day'], format='%Y%m%d')

```

```python
# 添加年、季度、月、日这4个字段用于后续分析。
trade_inf['year'] = trade_inf['day'].dt.year
trade_inf['month'] = trade_inf['day'].dt.month
trade_inf['date'] = trade_inf['day'].dt.day
trade_inf['quarter'] = trade_inf['day'].dt.quarter

```

```python
# 查看基本统计信息
trade_inf[['buy_mount','day']].describe()

```

|  | buy\_mount | day |
| --- | --- | --- |
| count | 28422.000000 | 28422 |
| mean | 2.596862 | 2014-01-15 13:39:12.121596160 |
| min | 1.000000 | 2012-07-02 00:00:00 |
| 25% | 1.000000 | 2013-06-18 00:00:00 |
| 50% | 1.000000 | 2014-03-04 00:00:00 |
| 75% | 1.000000 | 2014-09-09 00:00:00 |
| max | 10000.000000 | 2015-02-05 00:00:00 |
| std | 65.683763 | NaN |

发现1：用户的购买数量大多数在1或2,均值在2.5，但是最大为10000，可以认为存在异常特殊数据，我们需要剔除避免影响分析。

发现2：该数据集为2012-07-02 至 2015-02-05 的数据。也就是说，2012年和2015年的数据并不完整只有2013和2014年的数据完整。

```python
# 异常值处理
trade_inf = trade_inf[trade_inf['buy_mount']<3*65.683763]    # 默认 3 倍标准差以内的数为正常数据

```

查看总体的描述性统计数据：

```python
# 描述性统计（从总体上预览数据）
print('数据处理后的数据量：', trade_inf.shape[0])
print('用户数：', trade_inf.user_id.nunique())
print('交易量：', trade_inf.auction_id.nunique())
print('商品一级类目数：', trade_inf.category_1.nunique())
print('商品二级类目数：', trade_inf.category_2.nunique())
print('总销量：', trade_inf.buy_mount.nunique())

```

```
数据处理后的数据量： 28394
用户数： 28367
交易量： 28394
商品一级类目数： 6
商品二级类目数： 661
总销量： 60

```

## 三、流量分析

```python
import seaborn as sns
import matplotlib.pyplot as plt

# 数据可视化（年）

plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']

year = trade_inf.groupby(['year'])['buy_mount'].sum()
sns.barplot(x=year.index, y=year.values, hue =year.index, palette='viridis')
plt.ylabel('销量')
plt.title('年销量')
plt.show()

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/7bb61bb3e08a45028b1cba9325e55ab0.png#pic_center)

根据可视化结果，只考虑完整的数据（即13和14年）可以发现，2014年的销量比2013年的销量多了很多（大概8000左右）。

```python
# 每年的季度销量对比

years = [2012, 2013, 2014, 2015]
colors = ['orange', 'blue', 'skyblue', 'red']

fig, axes = plt.subplots(1, 4, figsize=(25, 6))

for i, year in enumerate(years):
    season_data = trade_inf[trade_inf.year == year].groupby(by='quarter')['buy_mount'].sum()
    sns.barplot(x=season_data.index, y=season_data.values, ax=axes[i], color=colors[i])
    axes[i].set_title(f"{year}")
    axes[i].set_xlabel("季度")
    axes[i].set_ylabel("销量")

# 统一 y 轴范围
for ax in axes:
    ax.set_ylim(0, 8000)

plt.tight_layout()
plt.show()

```

![](https://i-blog.csdnimg.cn/direct/0b6d67a4dc764b47a69497cd52046dbe.png#pic_center)

可以发现，销售量逐年增加。且每年第一季度销量都是最低，每年第四季度销量都是最高。

猜想原因：一季度的春节期间，用户无法网购收货，导致销量下降；四季度的 “双十一” 大促活动，导致销量增加。

```python
# 每年的月份销量对比

years = [2012, 2013, 2014, 2015]
colors = ['orange', 'blue', 'skyblue', 'red']

fig, axes = plt.subplots(1, 4, figsize=(25, 6))

for i, year in enumerate(years):
    season_data = trade_inf[trade_inf.year == year].groupby(by='month')['buy_mount'].sum()
    sns.barplot(x=season_data.index, y=season_data.values, ax=axes[i], color=colors[i])
    axes[i].set_title(f"{year}")
    axes[i].set_xlabel("月份")
    axes[i].set_ylabel("销量")

# 统一 y 轴范围
for ax in axes:
    ax.set_ylim(0, 3000)

plt.tight_layout()         
plt.show()

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/dfa31f1dc549411898ea69d0cb77e892.png#pic_center)

结论：2013年春节在2月10号左右，2014年春节在1月底到2月初，明显春节期间销量明显最低，11月销量明显增多。说明猜想可能是正确的。我们进一步验证。

```python
# 日销量分析（11月）

years = [2012, 2013, 2014]
colors = ['orange', 'blue', 'skyblue']

fig, axes = plt.subplots(1, 3, figsize=(25, 6))

for i, year in enumerate(years):
    date_data = trade_inf[(trade_inf.year == year) & (trade_inf.month == 11)].groupby(by='date')['buy_mount'].sum()
    sns.barplot(x=date_data.index, y=date_data.values, ax=axes[i], color=colors[i])
    axes[i].set_title(f"{year}")
    axes[i].set_ylabel("销量")
    axes[i].set_xlabel("11月的日期")

# 统一 y 轴范围
for ax in axes:
    ax.set_ylim(0, 800)

plt.tight_layout()
plt.show()

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/87963e364c9244269091d8e26410d41d.png#pic_center)

双十一期间销量比其他日期都要高，说明第四季度的销量增加是主要是“双十一”大促活动带来的。我们看看春节期间的情况。

```python
years = [2013, 2014]
colors = ['orange', 'blue', 'skyblue']

fig, axes = plt.subplots(1, 2, figsize=(25, 6))

for i, year in enumerate(years):
    date_data = trade_inf[(trade_inf.year == year) & (trade_inf.month == 2)].groupby(by='date')['buy_mount'].sum()
    sns.barplot(x=date_data.index, y=date_data.values, ax=axes[i], color=colors[i])
    axes[i].set_title(f"{year}")
    axes[i].set_ylabel("销量")
    axes[i].set_xlabel("2月的日期")

# 统一 y 轴范围
for ax in axes:
    ax.set_ylim(0, 200)

plt.tight_layout()
plt.show()

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/511ad253d962435399fded22dc4f51bf.png#pic_center)

可以发现，确实是春节导致了第一季度销量明显下降。

## 四、类目分析

```python
# 查看一级类目不同商品的销售量
category1 = trade_inf.groupby(by='category_1')['buy_mount'].sum().sort_values(ascending=False)
sns.barplot(x=category1.index, y=category1.values, hue=category1.index, palette='viridis')
plt.title('一级类目不同商品的销售量')
plt.xlabel('商品类别')
plt.ylabel('销量')
plt.show()

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5ad664bcdfdc46f39a4e33facc10260c.png#pic_center)

根据可视化结果，我们可以直观看到每种一级类目的商品销量对比。

```python
# 查看每个一级类目下，包含的二级类目种类数
category_1_to_2 = trade_inf.groupby(by='category_1')['category_2'].nunique().reindex(category1.index)
sns.barplot(x=category_1_to_2.index, y=category_1_to_2.values, hue=category_1_to_2.index, palette='viridis')
plt.title('二级类目不同商品的销售量')
plt.xlabel('商品类别')
plt.ylabel('销量')
plt.show()

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4b0106ccb08b4a9c93d7f41d2128199a.png#pic_center)

上图则是每种一级类目包含的二级类目种数。

```python
# 每个一级类目下，每个二级类目的平均销售量
sns.barplot(x=category1.index, y=category1/category_1_to_2, hue=category1.index, palette='viridis')
plt.xlabel('一级类目商品类别')
plt.ylabel('二级类目的平均销量')
plt.show()

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/091b097fdaab4312b9020efe0a2897cc.png#pic_center)

可以发现，虽然总体上看，虽然50009168（一级类目）和122650008（一级类目）包含的二级种类数目都很少，但是该类目下的二级类目平均销量高。这说明，50009168（一级类目）和122650008（一级类目）主要是婴儿消费的必需品，比如奶粉、尿不湿等。

## 五、个人收获和感想

本来根据比赛提出的三个任务（流量分析、类目分析、性别分析）完完整整地做一遍，但是在做的过程中，我发现这个交易数据集的交易量（28394）和用户数（非重复，共28367）差异不大，这里就存在一个问题，用户的复购率几乎为零，也就说，购买数据基本上都是新用户的。因为个人的某些原因（我自己感觉数据集不适合我用hhhh），然后并没有继续深入研究这个数据集。
  
最终，我选择参考了文章
<https://tianchi.aliyun.com/notebook/508900>
，跟着做了流量分析、类目分析，当然了，也有修改部分和自己的思考，不是完全按部就班。

* 提升了利用python进行数据处理的能力
* 更熟练的利用python进行可视化的能力
* 提升了编程能力（参考的软件版本和自己用的版本不一致的bug处理）
* 锻炼了数据分析思维能力

其实，一开始进行“流量分析”的时候，我选择的是使用Power BI 软件进行分析，做了一个简单的数据可视化报表，如下：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/aed3304ce4cc4b18b8a611e8766804c0.png)
  
根据左边的切片器，可以灵活的筛选数据的范围（比如某年，某季度等等），而且做这个可视化报表花了时间真的是特别少的，基本上拖拽就完成了，后面有机会再分享以下使用Power BI进行分析的演示hhhhh。

**文章如有错误，欢迎大家指正，我们下期再见叭**