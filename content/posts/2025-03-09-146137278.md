---
layout: post
title: "Spark-TTS基于大模型的文本语音合成工具"
date: 2025-03-09 22:02:52 +0800
description: "Spark TTS完全基于Qwen2.5构建，无需额外的生成模型，它不依赖于单独的模型来生成声学特征，而是直接从LLM预测的代码中重建音频。这种方法简化了流程，提高了效率并降低了复杂性；支持零样本语音克隆，它可以直接复制说话者的语音。这是跨语言和代码转换场景的理想选择，允许语言和语音之间的无缝转换，而不需要对每种语言进行单独的培训；支持中文和英文两种语言，使模型能够以高自然度和准确性合成多种语言的语音；支持通过调整性别、音高和语速等参数来创建虚拟说话者。"
keywords: "Spark-TTS：基于大模型的文本语音合成工具"
categories: ['魅力语音']
tags: ['语音识别', '深度学习', '人工智能']
artid: "146137278"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146137278
    alt: "Spark-TTS基于大模型的文本语音合成工具"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146137278
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146137278
cover: https://bing.ee123.net/img/rand?artid=146137278
image: https://bing.ee123.net/img/rand?artid=146137278
img: https://bing.ee123.net/img/rand?artid=146137278
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Spark-TTS：基于大模型的文本语音合成工具
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="./../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="./../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     <img alt="" height="824" src="https://i-blog.csdnimg.cn/direct/80b7229016ac4859a45571ed60709cdf.png" width="1792"/>
    </p>
    <p>
     GitHub：
     <a href="https://github.com/SparkAudio/Spark-TTS" title="https://github.com/SparkAudio/Spark-TTS">
      https://github.com/SparkAudio/Spark-TTS
     </a>
    </p>
    <p>
     Spark-TTS是一个先进的文本到语音系统，它利用大型语言模型（LLM）的强大功能进行高度准确和自然的语音合成；旨在高效、灵活、强大地用于研究和生产用途。
    </p>
    <h2>
     一、介绍
    </h2>
    <p>
     Spark TTS完全基于Qwen2.5构建，无需额外的生成模型，它不依赖于单独的模型来生成声学特征，而是直接从LLM预测的代码中重建音频。这种方法简化了流程，提高了效率并降低了复杂性；支持零样本语音克隆，它可以直接复制说话者的语音。这是跨语言和代码转换场景的理想选择，允许语言和语音之间的无缝转换，而不需要对每种语言进行单独的培训；支持中文和英文两种语言，使模型能够以高自然度和准确性合成多种语言的语音；支持通过调整性别、音高和语速等参数来创建虚拟说话者。
    </p>
    <h2>
     二、安装
    </h2>
    <h3>
     2.1 克隆项目
    </h3>
    <pre><code class="language-bash">git clone https://github.com/SparkAudio/Spark-TTS.git
cd Spark-TTS</code></pre>
    <h3>
     2.2 构建环境依赖
    </h3>
    <pre><code class="language-bash">conda create -n sparktts -y python=3.12 
conda activate sparktts
pip install -r requirements.txt
# If you are in mainland China, you can set the mirror as follows:
# pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com</code></pre>
    <p>
     <strong>
      PS：官方推荐python3.12，但是我这边使用3.12环境一直安装失败，所以我选择3.11.11，和我一样问题的同学可以尝试一下降低python版本 ；
     </strong>
    </p>
    <h3>
     2.3 下载预训练模型
    </h3>
    <pre><code class="language-bash">mkdir pretrained_models &amp;&amp; cd pretrained_models

# 安装大文件拉取工具
git lfs install

# 从Modelscpoe上下载模型
git clone https://www.modelscope.cn/SparkAudio/Spark-TTS-0.5B.git</code></pre>
    <h2>
     三、运行
    </h2>
    <h3>
     3.1 终端运行
    </h3>
    <pre><code class="language-python">python -m cli.inference \
    --text "text to synthesis." \
    --device 0 \
    --save_dir "path/to/save/audio" \
    --model_dir pretrained_models/Spark-TTS-0.5B \
    --prompt_text "transcript of the prompt audio" \
    --prompt_speech_path "path/to/prompt_audio"</code></pre>
    <p>
     上面是在终端的运行代码，项目中给出了一个运行事例，我们结合这个运行事例来具体看一下每个参数代表的含义，下面就是example/infer.sh的文件内容：
    </p>
    <pre><code class="language-bash">#!/bin/bash

# Copyright (c) 2025 SparkAudio
#               2025 Xinsheng Wang (w.xinshawn@gmail.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


# Get the absolute path of the script's directory
script_dir=$(dirname "$(realpath "$0")")

# Get the root directory
root_dir=$(dirname "$script_dir")

# Set default parameters
device=0
save_dir='example/results'
model_dir="pretrained_models/Spark-TTS-0.5B"
text="身临其境，换新体验。塑造开源语音合成新范式，让智能语音更自然。"
prompt_text="吃燕窝就选燕之屋，本节目由26年专注高品质燕窝的燕之屋冠名播出。豆奶牛奶换着喝，营养更均衡，本节目由豆本豆豆奶特约播出。"
prompt_speech_path="example/prompt_audio.wav"

# Change directory to the root directory
cd "$root_dir" || exit

source sparktts/utils/parse_options.sh

# Run inference
python -m cli.inference \
    --text "${text}" \
    --device "${device}" \
    --save_dir "${save_dir}" \
    --model_dir "${model_dir}" \
    --prompt_text "${prompt_text}" \
    --prompt_speech_path "${prompt_speech_path}"
    
    </code></pre>
    <table align="center" border="1" cellpadding="1" cellspacing="1" style="width:500px">
     <tbody>
      <tr>
       <td style="text-align:center">
        <strong>
         传参
        </strong>
       </td>
       <td style="text-align:center">
        <strong>
         含义
        </strong>
       </td>
      </tr>
      <tr>
       <td style="text-align:center">
        text
       </td>
       <td style="text-align:center">
        需要克隆语音所对应的文本
       </td>
      </tr>
      <tr>
       <td style="text-align:center">
        device
       </td>
       <td style="text-align:center">
        指定显卡编号
       </td>
      </tr>
      <tr>
       <td style="text-align:center">
        save_dir
       </td>
       <td style="text-align:center">
        克隆语音的保存路径
       </td>
      </tr>
      <tr>
       <td style="text-align:center">
        model_dir
       </td>
       <td style="text-align:center">
        大模型的保存路径
       </td>
      </tr>
      <tr>
       <td style="text-align:center">
        prompt_text
       </td>
       <td style="text-align:center">
        样本语音的文本信息
       </td>
      </tr>
      <tr>
       <td style="text-align:center">
        prompt_speech_path
       </td>
       <td style="text-align:center">
        样本语音的保存路径
       </td>
      </tr>
     </tbody>
    </table>
    <h3>
     3.2 WebUI
    </h3>
    <h4>
     3.2.1 启动
    </h4>
    <p>
     看到如下界面表示启动成功，在本地通过浏览器访问红框的网址；
    </p>
    <pre><code class="language-bash"># 在终端运行：
python webui.py --device 0</code></pre>
    <h4>
     <img alt="" height="136" src="https://i-blog.csdnimg.cn/direct/db6f69e9adf3455d93395def6644ce61.png" width="906"/>
    </h4>
    <h4>
     3.2.2 克隆
    </h4>
    <p>
     看到如下界面，黄框是语音克隆功能区：
    </p>
    <p>
     <img alt="" height="1418" src="https://i-blog.csdnimg.cn/direct/6270fa4b8d9145468c6491061b856eb5.png" width="2604"/>
    </p>
    <p>
     序号一：上传本地待克隆的语音样本（好像不支持m4a格式，最好上传wav格式）；
    </p>
    <p>
     序号二：可以在线录制需要克隆的人的声音（1、2选择一个就可以）；
    </p>
    <p>
     序号三：添加需要克隆语音的文本，即命令行运行中的‘text’参数；
    </p>
    <p>
     序号四：上传或者录音的语音所对应的文本信息；
    </p>
    <p>
     序号五：生成克隆语音的展示区；
    </p>
    <p>
     序号六：上述1-4信息填写完成后点击开始克隆；
    </p>
    <h4>
     3.2.3 语音创作
    </h4>
    <p>
     看到如下界面，黄框是语音创作功能区：
    </p>
    <p>
     <img alt="" height="1266" src="https://i-blog.csdnimg.cn/direct/31421c82de6a42d78e140c92324e3ec5.png" width="2664"/>
    </p>
    <p>
     序号一：可以选择生成语音的性别；
    </p>
    <p>
     序号二：调整生成语音的音调；
    </p>
    <p>
     序号三：调整生成语音的语速；
    </p>
    <p>
     序号四：输入生成语音的文本信息；
    </p>
    <p>
     序号五：点击开始创作，生成结果会展示在下方；
    </p>
    <h2>
     四、总结
    </h2>
    <p>
     整体体验感觉推理速度还是比较快的，但是在功能性上还是在效果上都有所欠缺；语音处理功能相较于之前测试的
     <a class="link-info" href="https://blog.csdn.net/CITY_OF_MO_GY/article/details/145729190" title="FunASR">
      FunASR
     </a>
     显得就比较单一；在克隆的效果上相较于之前测试的
     <a class="link-info" href="https://blog.csdn.net/CITY_OF_MO_GY/article/details/145863485" title="StepAudio">
      StepAudio
     </a>
     也略有逊色；大家可以尝试一下，进行一下比较～
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f434954595f4f465f4d4f5f47592f:61727469636c652f64657461696c732f313436313337323738" class_="artid" style="display:none">
 </p>
</div>


