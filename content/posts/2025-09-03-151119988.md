---
layout: post
title: "机器学习六朴素贝叶斯分类"
date: 2025-09-03T16:05:13+0800
description: "本文介绍了贝叶斯分类理论及其应用。贝叶斯决策的核心是选择最高概率的类别，通过比较条件概率p1(x,y)和p2(x,y)进行分类决策。文章详细解释了条件概率、全概率公式和贝叶斯推断的概念，重点阐述了朴素贝叶斯分类器对特征条件独立性的假设及其概率计算方法。针对零概率问题，提出了拉普拉斯平滑的解决方案。最后展示了使用scikit-learn库实现朴素贝叶斯分类的代码示例，包括数据加载、模型训练和预测评估等步骤，并以葡萄酒分类为例说明实际应用。"
keywords: "机器学习（六）朴素贝叶斯分类"
categories: ['未分类']
tags: ['算法', '机器学习', '开发语言', '分类', '人工智能', 'Python']
artid: "151119988"
arturl: "https://blog.csdn.net/2302_80301538/article/details/151119988"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=151119988
    alt: "机器学习六朴素贝叶斯分类"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=151119988
featuredImagePreview: https://bing.ee123.net/img/rand?artid=151119988
cover: https://bing.ee123.net/img/rand?artid=151119988
image: https://bing.ee123.net/img/rand?artid=151119988
img: https://bing.ee123.net/img/rand?artid=151119988
---



# 机器学习（六）朴素贝叶斯分类



## 一 贝叶斯分类理论

有一个数据集，有两类数据租车给，数据分布如下：

![](https://i-blog.csdnimg.cn/direct/e31649d486f94865952b0e8a28cff2cf.png)

用p1(x,y）表示数据点(x,y)属于类别1，也就是红色表示的类别的概率；

用p2(x,y)表示数据点(x,y)属于类别2，也就是蓝色表示的类别概率；

那么对于**新数据点(x,y)**，可以用下面的规则来判断它的类别：

>         如果p1(x,y)>p2(x,y),那么类别为1
>
>         如果p1(x,y)<p2(x,y),那么类别为2

可以看出来，我们会选择高概率对应的类别，贝叶斯决策理论的核心就是选择最高概率的决策。

## 二 条件概率

条件概率是指事件A在另外一个事件B已经发生条件下的发生概率，也就是P(A|B)。

事件A发生的概率就是P(A∩B)除以P(B)。

𝑃(𝐴|𝐵)=𝑃(𝐴∩𝐵)/𝑃(𝐵)，因此，𝑃(𝐴∩𝐵)=𝑃(𝐴|𝐵)𝑃(𝐵)

𝑃(𝐴∩𝐵)=𝑃(𝐵|𝐴)𝑃(𝐴)，即𝑃(𝐴|𝐵)=𝑃(B|A)𝑃(𝐴)/𝑃(𝐵)

这就是条件概率的计算公式。

## 三 全概率公式

假定样本空间s，是两个事件A和A'的和。

![](https://i-blog.csdnimg.cn/direct/98d702ee243d4d55b5d09fcff859a145.jpeg)

那么事件B可以划分为两个部分。

即：𝑃(𝐵)=𝑃(𝐵∩𝐴)+𝑃(𝐵∩𝐴′)

在上面的推导当中，我们已知𝑃(𝐵∩𝐴)=𝑃(𝐵|𝐴)𝑃(𝐴)

所以𝑃(𝐵)=𝑃(𝐵|𝐴)𝑃(𝐴)+𝑃(𝐵|𝐴′)𝑃(𝐴′)

这就是全概率公式。

含义就是，如果A和A‘构成样本空间的一个划分，那么B的改了，就等于A和A'的概率分别乘以B对这两个事件的条件概率之和。

那么条件概率可以变换为：![P(A|B)=\frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|A^,)P(A^,)}](https://latex.csdn.net/eq?P%28A%7CB%29%3D%5Cfrac%7BP%28B%7CA%29P%28A%29%7D%7BP%28B%7CA%29P%28A%29&plus;P%28B%7CA%5E%2C%29P%28A%5E%2C%29%7D)

## 四 贝叶斯推断

条件概率变形：

![](https://i-blog.csdnimg.cn/direct/f88cc8e034ae48ec940953854fd60191.png)

**P(A)称为"先验概率"（Prior probability）**，即在B事件发生之前，我们对A事件概率的一个判断。

**P(A|B)称为"后验概率"（Posterior probability）**，即在B事件发生之后，我们对A事件概率的重新评估。

**P(B|A)/P(B)称为"可能性函数"（Likelyhood）**，调整因子，使得预估概率更接近真实概率。

】条件概率可以理解：**后验概率　＝　先验概率ｘ调整因子**

这就是贝叶斯推断的含义。我们先预估一个"先验概率"，然后加入实验结果，看这个实验到底是增强还是削弱了"先验概率"，由此得到更接近事实的"后验概率"。

## 五 朴素贝叶斯推断

贝叶斯和朴素贝叶斯的概念是不同的，区别就在于“朴素”二字。朴素贝叶斯对条件概率分布做了**条件独立**性的假设。

比如下面的公式，假设有n个特征：

根据贝叶斯定理，后验概率 P(a|X) 可以表示为：

![P(a|X) = \frac{P(X|a)P(a)}{P(X)}](https://latex.csdn.net/eq?P%28a%7CX%29%20%3D%20%5Cfrac%7BP%28X%7Ca%29P%28a%29%7D%7BP%28X%29%7D)

![](https://latex.csdn.net/eq?)其中：

> P(X|a) 是给定类别 ( a ) 下观测到特征向量 X=(x_1, x_2, ..., x_n) 的概率；
>
> P(a) 是类别 a 的先验概率；
>
> P(X) 是观测到特征向量 X 的边缘概率，通常作为归一化常数处理。

朴素贝叶斯分类器的关键假设是特征之间的条件独立性，即给定类别 a ，特征 x_i 和 x_j (其中![i \neq j](https://latex.csdn.net/eq?i%20%5Cneq%20j)相互独立。)

因此，我们可以将联合概率 P(X|a) 分解为各个特征的概率乘积：

![P(X|a) = P(x_1, x_2, ..., x_n|a) = P(x_1|a)P(x_2|a)...P(x_n|a)](https://latex.csdn.net/eq?P%28X%7Ca%29%20%3D%20P%28x_1%2C%20x_2%2C%20...%2C%20x_n%7Ca%29%20%3D%20P%28x_1%7Ca%29P%28x_2%7Ca%29...P%28x_n%7Ca%29)

将这个条件独立性假设应用于贝叶斯公式，我们得到：

![P(a|X) = \frac{P(x_1|a)P(x_2|a)...P(x_n|a)P(a)}{P(X)}](https://latex.csdn.net/eq?P%28a%7CX%29%20%3D%20%5Cfrac%7BP%28x_1%7Ca%29P%28x_2%7Ca%29...P%28x_n%7Ca%29P%28a%29%7D%7BP%28X%29%7D)

通过计算每种可能类别的条件概率和先验概率，选择**具有最高概率的类别**作为预测结果。

## 六 拉普拉斯平滑系数

因为某些事件或者特征可能从未出现，会导致它们的概率被估计为0。

在实际应用中，即使某个事件或特征没有出现在训练集，也不排除其在以后的样本出现。

而我们的拉普拉斯平滑技术可以避免这种零概率陷阱。

![P(F1|C)=\tfrac{Ni+a}{N+am}](https://latex.csdn.net/eq?P%28F1%7CC%29%3D%5Ctfrac%7BNi&plus;a%7D%7BN&plus;am%7D)

一般我们的α取值为1，m为总的特征的数量。

即使某个特征在训练集指令从未出现，它的概率也不会被估计为0，而是会被赋予一个很小但是非0的值，从而避免了模型在面对新数据时可能出现的过拟合或预测错误。

## 七 API

```

sklearn.naive_bayes.MultinomialNB()estimator.fit(x_train, y_train)y_predict = estimator.predict(x_test)
```

代码实例：

```

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
# 1）获取数据
news =load_iris()
# 2）划分数据集
x_train, x_test, y_train, y_test = train_test_split(news.data, news.target)
# 3）特征工程：不用做标准化
# 4）朴素贝叶斯算法预估器流程
estimator = MultinomialNB()
estimator.fit(x_train, y_train)
# 5）模型评估
score = estimator.score(x_test, y_test)
print("准确率为：\n", score)
# 6）预测
index=estimator.predict([[2,2,3,1]])
print("预测:\n",index,news.target_names,news.target_names[index])
```

补充：贝叶斯实现葡萄酒分类



