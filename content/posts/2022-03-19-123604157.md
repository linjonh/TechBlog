---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f33333937333538332f:61727469636c652f64657461696c732f313233363034313537"
layout: post
title: 大数据从业人员需要哪些技能
date: 2022-03-19 22:09:14 +0800
description: "在之前的文章中《关于能力模型的思考 | 技术从业人员》"
keywords: 大数据运维工程师需要的技能
categories: ['Hadoop']
tags: ['Hadoop']
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=123604157
    alt: 大数据从业人员需要哪些技能
artid: 123604157
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=123604157
featuredImagePreview: https://bing.ee123.net/img/rand?artid=123604157
---

# 大数据从业人员需要哪些技能？

有小伙伴在问，大数据从业人员到底需要哪些技能？为什么搞大数据的最后变成了Sqlboy或Sqlgirl？搞大数据的每天到底在干什么？今天，我们就来一一回答下，并总结出在当下大数据从业人员需要会哪些技能。

**大数据团队的构成与基本要求**

一般来说，企业内部建立大数据团队，至少会包含以下几个类别：大数据开发工程师、大数据运维工程师、大数据架构师、有的还会有偏向业务侧的数据分析工程师。

先说大数据运维工程师，从职责上看，负责初期的大数据集群搭建、大数据集群的资源配置优化、故障诊断、日常运营维护等。从技能上看，需要了解网络、硬件、服务器的基本知识，熟悉Hadoop、Spark、Flink、Yarn等主流核心技术框架，对常见的配置项、基本原理有基本的了解，有较强的Shell或Python脚本的开发能力、熟悉常用的服务器、集群监控管理工具、对JVM有基本的认识，具有快速定位问题、处理故障的能力。

大数据开发工程师，又分为两类，一类是偏ETL数据开发的，主要是应用Hive、Impala、Spark、Flink等完成数据处理和业务逻辑实现，主要是以Sql为主，偶尔写一些UDF函数、Spark/Flink程序等。这一类开发人员，除了有较强的Sql功底以外，还需要大致了解Hadoop生态的核心技术，至少要熟悉各个组件的编程框架，能快速基于程序代码、Sql等方式完成数据的计算。另一类开发人员偏向底层平台的开发，基于业务需求对开源组件进行二次扩展，区别于前者ETL开发人员，除了会用组件以外，还需要有较强的Java功底、有快速阅读源码的能力，需要对Hadoop生态有源码级别的了解。

大数据架构师也分两类，一类是偏数据侧的，主要是围绕DCMM数据管理的方法论，以及数据仓库建设方法论，能基于业务需求完成数仓的顶层设计规划、以及相应数据标准、数据质量的规划设计、与实施落地。另一类是偏技术侧的，除了有较强的技术功底以外，还需要对开源或商用的大数据系统平台、相关生态技术的特点非常熟悉，对技术发展趋势有一定的认识，能基于大数据技术提供场景化的解决方案、完成平台的架构设计、以及具体项目的设计实现、及时解决项目开发或产品研发过程中的技术难题。

**大数据学习路线**

**非常熟练的掌握一门语言**
：建议Java，包括Java基础、JVM、锁、NIO、并发、数据库、服务器、SpringBoot、SpringCloud、微服务相关知识。至少要能独立完成后端服务接口、功能的编写。

**非常熟练的掌握以下大数据相关技术**
**：**

**hadoop**
：鼻祖级的技术，核心中的核心，至少要能独立完成集群的搭建、MapReduce的编写，对各个主流版本特性有一定的认识，并掌握基本模块的源码。

**Spark**
：能基于Java或Scala，完成SparkCore、SparkStreaming程序的编写，掌握核心模块的源码。

**SQL相关**
：掌握Hive、Impala等技术组件，能基于SQL完成指标逻辑统计、以及基本的SQL优化。

**Flink**
：能基于Flink完成开发、对FLink基本的执行流程、优化项有一定的认识。掌握核心模块的源码。

**Hbase/ClickHouse/ES/Doris/Kafka/Presto/Kudu等中间件**
：掌握基本的使用、优化，能Mapping到应用场景。

**调度与集成**
：对主流的调度工具、数据集成方法/理论有一定的认识，并能基于业务需求完成基本配置和使用。如Flume、Sqoop、DS、Datax、各种CDC技术。

**Linux**
：服务器的基本认识、较强的Shell。

**机器学习**
：了解基本的机器学习流程，这部分主要是考虑机器学习工程化需要大数据的支持。

**熟悉常见的大数据解决方案**
：如集群监控、多租户管理、Kerberos相关、即席查询等。

**了解常用的计算机知识**
：计算机组成原理、操作系统、计算机网络、设计模式、数据结构等。

**写在最后**

技术一定是不断迭代的，技术从业人员一定要向前看，不断的更新自己的技能，并让自己的技能贴合技术发展趋势，从大数据的发展方向来看，以下四个方向已经基本明晰。

**hadoop存算一体架构向存算分离架构演化**
：在大数据计算场景中，我们一般采用移动计算、不移动数据的策略来进行优化，会将计算节点和数据节点部署在一起，这会导致三个核心问题，集群规划难（存算耦合、机器带状态，无法弹性扩缩容）、运维负担重（坏盘坏节点无法避免）、存储成本高（容量预留）。在万物云原生的今天，数据存储层可以对象存储为主，计算资源基于K8S进行弹性扩缩容，可以很大程度的满足潮汐计算的需要。

**数据湖解决方案逐步替代传统hive数仓**
：hive最大的问题在于对upsert的能力支持较弱，并没有写scheme的校验。在历史数据发生变化的数据集成场景中，需要设计复杂的ETL架构，如拉链表等，来做upsert的增强，这无疑增加了系统复杂度，同时提高了数据存储和开发成本。如今，iceberg、hudi和delta都很好的支持了upsert能力，并支持数据的实时写入，可以更好的简化数据ETL的复杂度。

**流批一体化**
：目前很多公司依旧采用lambda架构，这种架构的缺点是需要同时维护实时和批处理两套架构，这样会导致数据口径不一致、数据维护成本高等等一系列问题。基于flink技术，实现计算引擎的统一、业务层逻辑的统一，以一套语义完成数据开发，可以更好的提高效率。

**多云一站式DataOps**
：一站式数据平台的升级版，目前一站式数据平台更多的是为了落地数据治理，来规约全链路数据开发的规范性，提高全链路的数据流转效率。但这远远不够，未来的企业的IT基础设施会在多云之上，如何同时实现多云一站式DataOps，并且真正实现基于元数据驱动的DataOps，是我们要持续关注的问题。

---

关注公众号：IT转型指北，分享高质量电子书和文章