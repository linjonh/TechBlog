---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f33333230303936372f:61727469636c652f64657461696c732f313436313133343834"
layout: post
title: "快速使用PPASR-V3版不能语音识别框架"
date: 2025-03-08 11:40:51 +0800
description: "主要介绍如何快速使用PPASR语音识别框架训练和推理，该框架支持多个语音识别模型，包含deepspeech2、conformer、squeezeformer、efficient_conformer等，每个模型都支持流式识别和非流式识别，以及多种解码器，包含ctc_greedy_search、ctc_prefix_beam_search、attention_rescoring、ctc_beam_search等"
keywords: "快速使用PPASR V3版不能语音识别框架"
categories: ['语音', '深度学习', 'Paddlepaddle']
tags: ['语音识别', '人工智能', 'Paddlepaddle']
artid: "146113484"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146113484
    alt: "快速使用PPASR-V3版不能语音识别框架"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146113484
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146113484
cover: https://bing.ee123.net/img/rand?artid=146113484
image: https://bing.ee123.net/img/rand?artid=146113484
img: https://bing.ee123.net/img/rand?artid=146113484
---

# 快速使用PPASR V3版不能语音识别框架

## 前言

本文章主要介绍如何快速使用PPASR语音识别框架训练和推理，本文将致力于最简单的方式去介绍使用，如果使用更进阶功能，还需要从源码去看文档。仅需三行代码即可实现训练和推理。

**源码地址：
<https://github.com/yeyupiaoling/PPASR>**

## 安装环境

使用Anaconda，并创建了Python3.11的虚拟环境。

* 首先安装的是PaddlePaddle 2.6.2 的GPU版本，如果已经安装过了，请跳过。

```shell
conda install paddlepaddle-gpu==2.6.2 cudatoolkit=11.7 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/Paddle/ -c conda-forge

```

* 使用pip安装PPASR库，命令如下：

```shell
python -m pip install ppasr -U -i https://pypi.tuna.tsinghua.edu.cn/simple

```

## 准备数据集

执行下面代码即可自动完成下载数据，和制作数据列表。默认下载可能会比较慢，可以复制下载地址用迅雷等工具下载，并指定
`filepath`
为下载好的文件路径，可以快速完成制作数据列表。

```python
import argparse
import os
import functools
from utility import download, unpack
from utility import add_arguments, print_arguments

DATA_URL = 'https://openslr.trmal.net/resources/33/data_aishell.tgz'
MD5_DATA = '2f494334227864a8a8fec932999db9d8'

parser = argparse.ArgumentParser(description=__doc__)
add_arg = functools.partial(add_arguments, argparser=parser)
add_arg("target_dir", default="dataset/audio/", type=str, help="存放音频文件的目录")
add_arg("annotation_text", default="dataset/annotation/", type=str, help="存放音频标注文件的目录")
add_arg("filepath", default=None, type=str, help="提前下载好的数据集压缩文件")
args = parser.parse_args()


def create_annotation_text(data_dir, annotation_path):
    print('Create Aishell annotation text ...')
    if not os.path.exists(annotation_path):
        os.makedirs(annotation_path)
    f_train = open(os.path.join(annotation_path, 'aishell.txt'), 'w', encoding='utf-8')
    if not os.path.exists(os.path.join(annotation_path, 'test.txt')):
        f_test = open(os.path.join(annotation_path, 'test.txt'), 'w', encoding='utf-8')
    else:
        f_test = open(os.path.join(annotation_path, 'test.txt'), 'a', encoding='utf-8')
    transcript_path = os.path.join(data_dir, 'transcript', 'aishell_transcript_v0.8.txt')
    transcript_dict = {}
    for line in open(transcript_path, 'r', encoding='utf-8'):
        line = line.strip()
        if line == '': continue
        audio_id, text = line.split(' ', 1)
        # remove space
        text = ''.join(text.split())
        transcript_dict[audio_id] = text
    data_types = ['train', 'dev']
    for type in data_types:
        audio_dir = os.path.join(data_dir, 'wav', type)
        for subfolder, _, filelist in sorted(os.walk(audio_dir)):
            for fname in filelist:
                audio_path = os.path.join(subfolder, fname).replace('\\', '/')
                audio_id = fname[:-4]
                # if no transcription for audio then skipped
                if audio_id not in transcript_dict:
                    continue
                text = transcript_dict[audio_id]
                f_train.write(audio_path.replace('../', '') + '\t' + text + '\n')
    audio_dir = os.path.join(data_dir, 'wav', 'test')
    for subfolder, _, filelist in sorted(os.walk(audio_dir)):
        for fname in filelist:
            audio_path = os.path.join(subfolder, fname).replace('\\', '/')
            audio_id = fname[:-4]
            # if no transcription for audio then skipped
            if audio_id not in transcript_dict:
                continue
            text = transcript_dict[audio_id]
            f_test.write(audio_path.replace('../', '') + '\t' + text + '\n')
    f_test.close()
    f_train.close()


def prepare_dataset(url, md5sum, target_dir, annotation_path):
    """Download, unpack and create manifest file."""
    data_dir = os.path.join(target_dir, 'data_aishell')
    if not os.path.exists(data_dir):
        if args.filepath is None:
            filepath = download(url, md5sum, target_dir)
        else:
            filepath = args.filepath
        unpack(filepath, target_dir)
        # unpack all audio tar files
        audio_dir = os.path.join(data_dir, 'wav')
        for subfolder, _, filelist in sorted(os.walk(audio_dir)):
            for ftar in filelist:
                unpack(os.path.join(subfolder, ftar), subfolder, True)
        os.remove(filepath)
    else:
        print("Skip downloading and unpacking. Aishell data already exists in %s." % target_dir)
    create_annotation_text(data_dir, annotation_path)


def main():
    print_arguments(args)
    if args.target_dir.startswith('~'):
        args.target_dir = os.path.expanduser(args.target_dir)

    prepare_dataset(url=DATA_URL,
                    md5sum=MD5_DATA,
                    target_dir=args.target_dir,
                    annotation_path=args.annotation_text)


if __name__ == '__main__':
    main()

```

## 训练

使用PPASR框架训练非常简单，核心代码就3行，如下，
`configs`
参数可以指定使用的默认配置文件。

```python
from ppasr.trainer import PPASRTrainer

trainer = PPASRTrainer(configs="conformer", use_gpu=True)

trainer.train(save_model_path="models/")

```

输出类似如下：

```
2025-03-08 11:04:57.884 | INFO     | ppasr.optimizer:build_optimizer:16 - 成功创建优化方法：Adam，参数为：{'lr': 0.001, 'weight_decay': 1e-06}
2025-03-08 11:04:57.884 | INFO     | ppasr.optimizer:build_lr_scheduler:31 - 成功创建学习率衰减：WarmupLR，参数为：{'warmup_steps': 25000, 'min_lr': 1e-05}
2025-03-08 11:04:57.885 | INFO     | ppasr.trainer:train:541 - 词汇表大小：5561
2025-03-08 11:04:57.885 | INFO     | ppasr.trainer:train:542 - 训练数据：13382
2025-03-08 11:04:57.885 | INFO     | ppasr.trainer:train:543 - 评估数据：27
2025-03-08 11:04:58.642 | INFO     | ppasr.trainer:__train_epoch:414 - Train epoch: [1/200], batch: [0/836], loss: 51.60880, learning_rate: 0.00000008, reader_cost: 0.1062, batch_cost: 0.6486, ips: 21.1991 speech/sec, eta: 1 day, 11:03:13

```

## 导出模型

训练完成之后还需要导出模型才能进行推理，导出模型也非常简单。需要三行代码，如下：

```python
from ppasr.trainer import PPASRTrainer

# 获取训练器
trainer = PPASRTrainer(configs="conformer", use_gpu=True)

# 导出预测模型
trainer.export(save_model_path='models/',
               resume_model='models/ConformerModel_fbank/best_model/')

```

## 推理

推理也相当简单，只需要下面三行代码即可完成语音识别。

```python
from ppasr.predict import PPASRPredictor

predictor = PPASRPredictor(model_dir="models/ConformerModel_fbank/inference_model/", use_gpu=True)

audio_path = "dataset/test.wav"
result = predictor.predict(audio_data=audio_path)
print(f"识别结果: {result}")

```

输出如下：

```
2025-03-08 11:21:52.100 | INFO     | ppasr.infer_utils.inference_predictor:__init__:38 - 已加载模型：models/ConformerModel_fbank/inference_model/inference.pth
2025-03-08 11:21:52.147 | INFO     | ppasr.predict:__init__:117 - 流式VAD模型已加载完成
2025-03-08 11:21:52.147 | INFO     | ppasr.predict:__init__:119 - 开始预热预测器...
2025-03-08 11:22:01.366 | INFO     | ppasr.predict:reset_predictor:471 - 重置预测器
2025-03-08 11:22:01.366 | INFO     | ppasr.predict:__init__:128 - 预测器已准备完成！
识别结果: {'text': '近几年不但我用书给女儿压岁也劝说亲朋不要给女儿压岁钱而改送压岁书', 'sentences': [{'text': '近几年不但我用书给女儿压岁也劝说亲朋不要给女儿压岁钱而改送压岁书', 'start': 0, 'end': 8.39}]}

```

## 结语

该框架支持多个语音识别模型，包含
`deepspeech2`
、
`conformer`
、
`squeezeformer`
、
`efficient_conformer`
等，每个模型都支持流式识别和非流式识别，以及多种解码器，包含
`ctc_greedy_search`
、
`ctc_prefix_beam_search`
、
`attention_rescoring`
、
`ctc_beam_search`
等。更多功能等你发现。