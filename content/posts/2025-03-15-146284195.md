---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f33373939303138362f:61727469636c652f64657461696c732f313436323834313935"
layout: post
title: "CVPR-2025-长程视觉语言导航平台与数据集迈向复杂环境中的智能机器人"
date: 2025-03-15 19:59:39 +0800
description: "近日，中山大学HCP-Lab团队提出复杂长程视觉语言导航（LH-VLN）任务，并配套开发了自动化数据生成平台NavGen、复杂长程导航基准测试LHPR-VLN，以及创新模型MGDM，为智能机器人在动态复杂环境中的自主导航开辟了新路径。目前该论文已被CVPR2025接收。"
keywords: "CVPR-2025 | 长程视觉语言导航平台与数据集：迈向复杂环境中的智能机器人"
categories: ['Vln']
tags: ['深度学习', '具身智能', '人工智能']
artid: "146284195"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146284195
    alt: "CVPR-2025-长程视觉语言导航平台与数据集迈向复杂环境中的智能机器人"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146284195
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146284195
cover: https://bing.ee123.net/img/rand?artid=146284195
image: https://bing.ee123.net/img/rand?artid=146284195
img: https://bing.ee123.net/img/rand?artid=146284195
---

# CVPR-2025 | 长程视觉语言导航平台与数据集：迈向复杂环境中的智能机器人

![](https://i-blog.csdnimg.cn/img_convert/91b1f8d45169c261a40d124a611dc6ee.jpeg)

* 作者：Xinshuai Song, Weixing Chen, Yang Liu, Weikai Chen, Guanbin Li, Liang Lin
* 单位：中山大学，Independent Researcher，鹏城实验室
* 项目主页：https://hcplab-sysu.github.io/LH-VLN
* 论文地址：https://arxiv.org/pdf/2412.09082

从“拿毛巾到厨房岛台，再取茶壶放到茶几”到“找到客厅的遥控器后去卧室关灯”，现实中的机器人需要完成的往往是包含多个步骤的长链条任务。然而，现有的视觉语言导航（Vision-Language Navigation, VLN）技术大多局限于单一目标、短路径的简单场景，难以应对复杂环境中的多阶段挑战。

![](https://i-blog.csdnimg.cn/img_convert/88a9db3b63d1a5708bcdd618566cd460.png)

近日，中山大学HCP-Lab团队提出
**复杂长程视觉语言导航（LH-VLN）任务，并配套开发了自动化数据生成平台NavGen**
、复杂长程导航基准测试
**LHPR-VLN**
，以及创新模型
**MGDM**
，为智能机器人在动态复杂环境中的自主导航开辟了新路径。目前该论文已被CVPR2025接收。

### 困境：单阶段导航的“玻璃天花板”

传统VLN任务通常要求机器人根据指令完成单一目标的导航，例如“走到客厅的沙发旁”。这类任务在实验室中表现优异，但面对现实场景时却捉襟见肘——真正的挑战往往需要
**连续决策**
和
**动态调整**
。例如，家政机器人可能需要先找到浴室中的毛巾，将其送至厨房岛台，再取出茶壶放置在茶几上。这类任务不仅涉及多个子目标，还需要在过程中保持上下文连贯性，避免因环境变化或路径阻塞导致任务中断。

现有研究的短板显而易见：

* **数据局限**
  ：主流数据集（如R2R、VLN-CE）任务步骤短（平均<10步），缺乏多阶段交互设计；
* **评估粗放**
  ：仅用整体成功率（SR）衡量性能，无法反映子任务执行质量；
* **模型僵化**
  ：依赖静态路径规划，缺乏长期记忆和动态调整能力。

**“要让机器人真正走进家庭，必须突破单阶段任务的思维定式。”**
论文作者在引言中直指问题核心。

![](https://i-blog.csdnimg.cn/img_convert/0cac0dcfd3d9a877a58d6c09697e17e9.png)

图1. 框架总览以及与现有单阶段导航的对比

### 破局：NavGen——复杂任务数据的“全自动工厂”

为解决数据瓶颈，研究团队开发了
**NavGen平台**
，这是一个支持
**多阶段、多粒度**
任务生成的自动化系统。其核心创新在于
**双向生成机制**
：

* **前向生成**
  ：基于GPT-4构建复杂任务指令。例如，输入浴室和厨房的场景信息后，自动生成“将浴室毛巾送至厨房岛台，再取茶壶放到客厅茶几”的多步骤任务；
* **后向分解**
  ：通过轨迹分割算法，将长路径拆解为“左转绕过沙发”“直行至餐桌”等原子动作，并反向生成对应的分步指令。

![](https://i-blog.csdnimg.cn/img_convert/1217a6e4967605a8f71b248a8c69cc1f.png)

图2. NavGen通过前向生成复杂任务，后向分解为原子动作，形成完整数据闭环

NavGen的三大优势使其成为VLN领域的“数据引擎”：

* **场景多样性**
  ：整合HM3D数据集中的216个3D室内场景，涵盖卧室、厨房、办公室等多种环境；
* **机器人适配**
  ：支持波士顿动力Spot（四足机器人）和Hello Robot Stretch（轮式机械臂）等不同形态的任务设置；
* **任务复杂度**
  ：单个任务可包含4-6个子步骤，平均指令长度达18.17词，远超传统数据集。

“
**这相当于为模型提供了‘任务炼狱’级别的训练场**
。” 研究者如此评价NavGen的生成能力。

### 试金石：LHPR-VLN基准——让模型“原形毕露”

基于NavGen，团队构建了复杂长程VLN基准LHPR-VLN，包含3260个任务，平均每个复杂任务需执行150个动作步骤。与传统基准相比，LHPR-VLN有两大革新：

#### 1. 任务设计：从“线性执行”到“逻辑串联”

每个任务要求机器人按顺序完成
**对象定位-抓取-转移**
的链条操作。例如： “在卧室找到台灯，将其搬到书房书桌，再取出桌上的文件放到文件柜。” 这种设计迫使模型必须理解任务间的逻辑依赖——若未能正确放置台灯，后续寻找文件的子任务将直接失败。

![](https://i-blog.csdnimg.cn/img_convert/b64ce1867a757f26e74b0f5aa0ad5611.png)

表1. 与现有VLN基准的对比

#### 2. 评估体系：从“笼统打分”到“显微镜式诊断”

传统指标如成功率（SR）已无法满足需求，LHPR-VLN引入三大新指标：

* **独立成功率（ISR）**
  ：衡量每个子任务的单独完成度；
* **条件成功率（CSR）**
  ：评估任务链条的整体连贯性；
* **基于真实路径加权的CGT**
  ：考虑实际路径难度，避免“取巧式”成功。

是任务的数量， 是子任务的数量。

是第个子任务的成功情况。

CSR通过加权计算任务链的连贯性，CGT进一步引入真实路径长度修正偏差

实验显示，传统模型在LHPR-VLN上表现惨淡：在2-3个子任务场景中，所有基线模型的整体成功率（SR）均为0%，凸显现有技术的局限性。

![](https://i-blog.csdnimg.cn/img_convert/b1f7a2e4309b5a4ad65977cf4d566c77.png)

表2. 在LHPR-VLN基准上的性能对比

### 智慧大脑：MGDM模型——记忆与推理的“双螺旋”

为攻克复杂长程导航难题，团队提出
**多粒度动态记忆模型（MGDM）**
，其核心架构如同“生物神经系统”：

* **记忆分层：短期模糊与长期强化**
  + **短期记忆**
    ：通过滑动窗口池化动态“遗忘”次要信息；
  + **长期记忆**
    ：从数据集中检索历史成功案例，为当前决策提供参考。
* **链式思维（CoT）反馈：让AI“说出推理过程”**
  + 模型在一定行动步，会通过GPT-4生成
    **推理链条**
    ：“当前位于走廊，需先左转进入浴室；浴室门可能位于左侧视野，需向前移动2步确认...” 这种显式推理机制大幅降低了传统LLM模型的“幻觉”风险，使决策过程可解释、可调整。

![](https://i-blog.csdnimg.cn/img_convert/c6ebfd3dd60fe84ae0472920081cb06d.png)

图3. MGDM通过CoT模块生成推理链条，结合短/长期记忆动态调整决策

实验结果表2验证了MGDM的优越性：在4个子任务场景中，其CGT指标达到5.83，全部模型中最佳。

### 未来：从虚拟场景到现实世界的“惊险一跃”

尽管LH-VLN框架取得突破，研究者坦言
**现实落地仍面临三重挑战**
：

* **跨场景泛化**
  ：实验室训练的模型能否适应真实家庭的布局变异？
* **多模态融合**
  ：如何整合语音指令、触觉反馈等更丰富的信息源？
* **实时性瓶颈**
  ：150步任务的平均决策耗时需从分钟级压缩至秒级。

对此，论文提出两条演进路径：

* **仿真-现实迁移学习**
  ：利用Holodeck等工具生成高保真虚拟环境，缩小仿真与现实差距；
* **具身大模型**
  ：将VLM（视觉语言模型）与机器人运动控制模块深度耦合，实现端到端优化。

### 结语：推开智能机器人的“第二扇门”

当实验室的机器人能流畅完成“泡茶-清洁-整理”的连贯操作时，我们离真正的家庭服务机器人便不再遥远。这项研究的意义不仅在于技术指标的提升，更在于
**重构了VLN任务的范式**
——从孤立动作到连续决策，从静态环境到动态交互，从人工规则到自主推理。

正如论文结尾的展望：“LH-VLN是一把钥匙，它将打开智能体在复杂物理世界中长期生存的大门。”在这条通向未来的道路上，每一步导航的突破，都是对人类生活方式的重新定义。

![](https://i-blog.csdnimg.cn/img_convert/9850486b286791b84ea1f7aa85b4e88a.jpeg)