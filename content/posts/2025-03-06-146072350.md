---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f33383938393534302f:61727469636c652f64657461696c732f313436303732333530"
layout: post
title: "open-webui-二次开发-源码启动前后端工程-超简洁步骤"
date: 2025-03-06 16:14:11 +08:00
description: "open webui 二次开发 源码启动前后端服务以及常见问题解决"
keywords: "open-webui 服务端启动"
categories: ['未分类']
tags: ['Ai']
artid: "146072350"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146072350
    alt: "open-webui-二次开发-源码启动前后端工程-超简洁步骤"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146072350
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146072350
cover: https://bing.ee123.net/img/rand?artid=146072350
image: https://bing.ee123.net/img/rand?artid=146072350
img: https://bing.ee123.net/img/rand?artid=146072350
---

# open webui-二次开发-源码启动前后端工程-【超简洁步骤】

## 参考资料

[openwebui docs](https://docs.openwebui.com/getting-started/advanced-topics/development)

## 获取源码

```shell
git clone https://github.com/open-webui/open-webui && cd open-webui

```

## 启动后端服务

```shell
cd backend
conda create --name open-webui python=3.11
conda activate open-webui
pip install -r requirements.txt -U
sh dev.sh

```

没有
`conda`
的要先安装下，启动成功会后监听
`8080`
端口。

## 启动前端服务

回到代码根目录

```shell
npm i
npm run dev

```

启动成功后会监听
`5173`
端口，在浏览器就可以访问
`http://127.0.0.1:5173`
。

## 常见问题解决

#### 1.在访问前端服务时显示logo后会显示空白页面

> 这个问题是因为后端在获取模型列表，在获取模型列表时会访问openai，在国内无法访问，可以通过修改后端代码屏蔽掉这个逻辑，代码如下：

```python
代码路径 backend/open_webui/utils/models.py

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/1ee493dddfab475fae3e2db3ee95b0eb.png)
  
注释掉以上代码后可进入webui界面。

#### 2.在相关界面有可能会遇到跨域问题，导致无法访问后端工程服务

> 解决问题思路是避免跨域，可以使用nginx代理合并端口，把
> `8080`
> 和
> `5173`
> 合并到
> `8888`
> 进行访问，这样就规避了跨域问题。nginx配置参考如下：

```
    server {
        listen       8888;
        server_name  localhost;

        location / {
             proxy_pass http://127.0.0.1:5173/;
        }

        location /api/ {
          proxy_pass http://127.0.0.1:8080/api/;
        }

        location /ollama/ {
          proxy_pass http://127.0.0.1:8080/ollama/;
        }

        location /openai/ {
          proxy_pass http://127.0.0.1:8080/openai/;
        }
    }

```

#### 如何修改ollama监听地址和端口

```shell
vi /etc/profile
添加如下一行
export OLLAMA_HOST=http://0.0.0.0:11434
source /etc/profile
然后重启ollama服务

```

## 插入个人广告，不喜欢可以不用往下看了

搭建属于你自己的WEB堡垒机系统，只要有浏览器就可以远程控制你的电脑，协议支持rdp,vnc,ssh
  
官方地址:
[百百WEB堡垒机](http://bb.yun-api.com/)
http://bb.yun-api.com/