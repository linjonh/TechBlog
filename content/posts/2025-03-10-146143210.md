---
arturl_encode: "68747470733a2f2f626c6f:672e6373646e2e6e65742f323430315f38323339333231372f:61727469636c652f64657461696c732f313436313433323130"
layout: post
title: "Spark8配置Hadoop集群环境-使用脚本命令实现集群文件同步"
date: 2025-03-10 10:31:17 +08:00
description: "在一台机器上模拟出 Hadoop 分布式系统的各个组件，各个组件在逻辑上是分离的，但是都运行在同一台物理机器上，以此来模拟分布式环境。在hadoop102上，将hadoop101中/opt/module/hadoop-3.1.3目录拷贝到hadoop102上。在root目录建立bin文件夹，在bin内建立xsync文件，并在文件中输入脚本。2.scp -r /etc/tst/B机器的用户名@主机名:/etc/tst。重新查看它的颜色，它现在已经变成执行的脚本了（如下图）。把这个脚本同步到其他的机器中。"
keywords: "Spark（8）配置Hadoop集群环境-使用脚本命令实现集群文件同步"
categories: ['未分类']
tags: ['大数据', '分布式', 'Spark']
artid: "146143210"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146143210
    alt: "Spark8配置Hadoop集群环境-使用脚本命令实现集群文件同步"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146143210
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146143210
cover: https://bing.ee123.net/img/rand?artid=146143210
image: https://bing.ee123.net/img/rand?artid=146143210
img: https://bing.ee123.net/img/rand?artid=146143210
---

# Spark（8）配置Hadoop集群环境-使用脚本命令实现集群文件同步

**一.hadoop的运行模式**

**二.scp命令————基本使用**

**三.scp命令———拓展使用**

**四.rsync远程同步**

**五.xsync脚本集群之间的同步**

---

**一.hadoop的运行模式**

hadoop一共有如下

三种运行方式：

1. 本地运行。

数据存储在

linux

本地，测试偶尔用一下。

我们上一节课使用的就是本地

运行模式hadoop100。

2.

伪分布式

。在一台机器上模拟出 Hadoop 分布式系统的各个组件，各个组件在逻辑上是分离的，但是都运行在同一台物理机器上，以此来模拟分布式环境。

3. 完全分布式。数据存储在HDFS，多台服务器工作，企业中大量使用。

**要在本地去

模拟这个

真实的场景

功能，我们需要做好如下的准备

：**

**1）准备3台客户机（关闭防火墙、静态

IP

、主机名称）**

**2）安装javaJDK

，

安装Hadoop

，

并

配置环境变量**

**3

）配置集群**

**4

）单点启动**

**5

）

配置

ssh**

**6）

群起并

测试集群**

**现在我们来看看按照JDK和Hadoop并配置环境变量的工作。有两种思路：**

**1. 每台机器都去手动安装一次（上传jar包再去解压）。**

**2. 把一台机器装好，把module 拷贝到其他的机器。这样就不需要省略了上传和解压的工作了。**

**二.scp命令————基本使用**

现在要学一个新的命令：

scp

。

它

可以实现服务器与服务器之间的数据拷贝。

****1.****
****基本语法****

scp    -r        $pdir/$fname    $user@$host:$pdir/$fname

说明

：

（1）

-

r

:

表示递归拷贝

。如果要拷贝的是文件夹，就把文件夹下的内容都拷贝

（2）

$pdir/$fname:

要拷贝的文件路径/名称

（3）

$user@host:$pdir/$fname:

目的地用户@主机:目的地路径/名称

****注意：要输入相应的账号和密码！****

****2.案例操作****

来，我们一起看下

案例实操

。

****背景****

假设你

已经：

（1）

在

两

台虚拟机（

hadoop10

0

、hadoop10

1

）

都已经创建好了/opt/module

,

/opt/software两个目录

（2）

在

hadoop10

0

这台机器中已经安装了jdk和hadoop。

****目标****

现在的目标是：

要把

hadoop

10

0

上的jdk

文件夹

拷贝到

ha

d

oop

10

1

中

的相同的目录下

。

![](https://i-blog.csdnimg.cn/direct/5f781944a840454e987a5c48794666dd.png)

****操作****

我们一起看

具体操作：

1. 启动虚拟机

。把

hadoop100

和

hadoop101

都启动

。

2. 进入到hadoop10

0

3. 命令：
  

scp -r /opt/module/jdk1.8.0_212

/

root

@hadoop10

1

:/opt/module

/

jdk1.8.0_212

/

**三.scp命令———拓展使用**

1. 拉取。

   在

   hadoop101

   上，拉取

   hadoop100

   机器上的内容

   （如下左图）

   。

![](https://i-blog.csdnimg.cn/direct/3cc0435c88e34390b41f9e56e2356793.png)

1. 推送。

   在

   hadoop100

   机器上，把文件

   推送

   到

   hadoop101

   机器上

   （如上右图）

   。
2. 搭桥。

   在

   hadoop101

   机器上，把

   hadoop100

   的文件传递到

   hadoop102

   上

![](https://i-blog.csdnimg.cn/direct/b8ba13f0475e48bca297469c716369e6.png)

****任务****
****1****

：

在hadoop102上，将hadoop101中/opt/module/hadoop-3.1.3目录拷贝到hadoop102上。

分析：使用scp进行拉取

操作：

1. 先登录到

   hadoop2
2. 使用命令：

scp -r

root

@hadoop101:/opt/module/hadoop-3.1.3 /opt/module/

****任务****
****2****

：

在hadoop10

1

上操作，将hadoop10

0

中/opt/module目录下所有目录拷贝到hadoop10

2

上。

分析：使用scp进行搭桥

操作：

1. 登录hadoop101
2. 使用命令：

scp -r

root

@hadoop10

0

:/opt/module/\*

root

@hadoop10

2

:/opt/module

**四.rsync远程同步**

rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。

rsync和scp区别是：rsync只对差异文件做更新，

而

scp是把所有文件都复制过去

，所以它的效果更高一些

。

![](https://i-blog.csdnimg.cn/direct/edadf076d8f34b2abd7076473f8dbd84.png)

****1.****
****基本语法****

rsync    -av       $pdir/$fname             $user@$host:$pdir/$fname

语法

说明：

（1）

-

a：归档拷贝

，尽可能让拷贝的文件之间保持一致。

（2）

-

v：显示拷贝过程。

（3）

$

p

dir/$fname:

要拷贝的文件路径/名称

（4）

$user@host:$pdir/$fname:

目的地用户@主机:目的地路径/名称

实操：

rsync -av /opt/conf/ root@hadoop101:/opt/conf

第一步：在

两台

机器上

准备

文件。

在

hadoop

100

的

/opt/

conf

/

新

建1

.txt,

2

.txt

, 3

.txt,

4

.txt

做一次同步。

[

root

@hadoop10

0

]$ rsync -av

/opt/conf/

root

@hadoop10

1

:/opt/

conf/

它会在hadoop101上创建conf目录。

第二步：

在hadoop100中，添加新文件，5.txt, 6.txt, 7.txt

第三步：

使用命令把新

添加的

文件同步到

hadoop101中

。

命令如下：

[

root

@hadoop10

0

]$ rsync -av

/opt/conf/

root

@hadoop10

1

:/opt/

conf/

请特别注意目录最后的尾/。有/表示拷贝这文件夹下的内容，没有/表示会拷贝这个文件夹

**五.xsync脚本集群之间的同步**

在root目录建立bin文件夹，在bin内建立xsync文件，并在文件中输入脚本

chmod +x xsync

****2.****
****步骤****

（1）

在/

root

/bin目录下创建xsync文件

。在这个

（2）

在该文件中编写如下代码

。这个部分的代码不需要会写，能看懂，了解即可。

#!/bin/bash

#1. 判断参数个数

if [ $# -lt 1 ]

then

echo Not Enough Arguement!

exit;

fi

#2. 遍历集群所有机器

for host in hadoop10

0

hadoop10

1

hadoop10

2

do

echo ====================  $host  ====================

#3. 遍历所有目录，挨个发送

for file in $@

do

#4. 判断文件是否存在

if [ -e $file ]

then

#5. 获取父目录

pdir=$(cd -P $(dirname $file); pwd)

#6. 获取当前文件的名称

fname=$(basename $file)

ssh $host "mkdir -p $pdir"

rsync -av $pdir/$fname $host:$pdir

else

echo $file does not exists!

fi

done

done

（

3

）

修改执行权限。

此时，我们去查看文件

，可以看到它的

颜色是灰色的，不具备执行权限

（如下图）

![](https://i-blog.csdnimg.cn/direct/0c05a747973a4e63a9de2a060e84841d.png)

接下来要通过命令：

chmod +x xsync

（

或者是chmod 777 xsync

）

重新查看它的颜色，它现在已经变成执行的脚本了（如下图）。

![](https://i-blog.csdnimg.cn/direct/06e54b8ccf4046c18547a6e2c495a5b4.png)

（4）测试使用。把这个脚本同步到其他的机器中。

[

root

@hadoop10

0

~]$ xsync /

root

/bin

/

---

课堂小结

1. scp的作用是什么？
2. 如果当前在A机器上，要把A机器上的/etc/tst下的所有内容拷贝到B机器上的/etc/tst目录下，应该的命令应该怎么写？
3. rsync与scp的区别是什么？

答案：

1.实现服务器和服务器之间数据拷贝

2.scp -r /etc/tst/B机器的用户名@主机名:/etc/tst

3.rsync和scp区别是：rsync只对差异文件做更新，

而

scp是把所有文件都复制过去

，所以它的效果更高一些

。