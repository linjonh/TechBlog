---
layout: post
title: "æ·±åº¦å­¦ä¹ ç¬”è®°16-è¿åŠ¨é‹å“ç‰Œè¯†åˆ«Pytorch"
date: 2025-03-06 18:37:44 +0800
description: "ç›®å½•ä¸€ã€å‰æœŸå·¥ä½œ1.å¯¼å…¥æ•°æ®å¹¶è¯»å–2.åˆ›å»ºæ•°æ®åŠ è½½å™¨ äºŒã€æ„å»ºç®€å•çš„CNNç½‘ç»œä¸‰ã€è®­ç»ƒæ¨¡å‹1.ç¼–å†™è®­ç»ƒå‡½æ•°2.ç¼–å†™æµ‹è¯•å‡½æ•°3.è®¾ç½®åŠ¨æ€å­¦ä¹ ç‡4.æ­£å¼è®­ç»ƒå››ã€ç»“æœå¯è§†åŒ–äº”ã€å°è¯•æ•°æ®å¢å¼ºæ“ä½œå…­ã€æ€»ç»“1.torchvision.transforms.Compose()ç±»2.[N, C, H, W]3.æ„Ÿå—é‡ä¸å·ç§¯æ ¸å¤§å°çš„æƒè¡¡ 2.ç¼–å†™æµ‹è¯•å‡½æ•°3.è®¾ç½®åŠ¨æ€å­¦ä¹ ç‡4.æ­£å¼è®­ç»ƒæ ¹æ®losså’Œaccuracyå›¾ï¼Œè®­ç»ƒå‡†ç¡®ç‡æ˜æ˜¾é«˜äºæµ‹è¯•å‡†ç¡®"
keywords: "æ·±åº¦å­¦ä¹ ç¬”è®°16-è¿åŠ¨é‹å“ç‰Œè¯†åˆ«(Pytorch)"
categories: ['æ·±åº¦å­¦ä¹ ']
tags: ['ç¬”è®°', 'æ·±åº¦å­¦ä¹ ', 'Pytorch']
artid: "146074848"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146074848
    alt: "æ·±åº¦å­¦ä¹ ç¬”è®°16-è¿åŠ¨é‹å“ç‰Œè¯†åˆ«Pytorch"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146074848
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146074848
cover: https://bing.ee123.net/img/rand?artid=146074848
image: https://bing.ee123.net/img/rand?artid=146074848
img: https://bing.ee123.net/img/rand?artid=146074848
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     æ·±åº¦å­¦ä¹ ç¬”è®°16-è¿åŠ¨é‹å“ç‰Œè¯†åˆ«(Pytorch)
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <ul>
     <li id="u5a0cf7ef">
      <strong>
       ğŸ¨ æœ¬æ–‡ä¸º
      </strong>
      <a href="https://mp.weixin.qq.com/s/kV8ZsJv6cPNzJLEuhPfvXg" rel="nofollow" title="ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥">
       ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥
      </a>
      <strong>
       ä¸­çš„å­¦ä¹ è®°å½•åšå®¢
      </strong>
     </li>
     <li id="uabaf6a39">
      <strong>
       ğŸ–
      </strong>
      <strong>
       åŸä½œè€…ï¼š
      </strong>
      <a href="https://mtyjkh.blog.csdn.net/" rel="nofollow" title="KåŒå­¦å•Š">
       KåŒå­¦å•Š
      </a>
     </li>
    </ul>
    <hr id="hr-toc" name="tableOfContents"/>
    <p>
    </p>
    <h2 id="%E4%B8%80%E3%80%81%E5%89%8D%E6%9C%9F%E5%B7%A5%E4%BD%9C" name="%E4%B8%80%E3%80%81%E5%89%8D%E6%9C%9F%E5%B7%A5%E4%BD%9C">
     ä¸€ã€å‰æœŸå·¥ä½œ
    </h2>
    <h3 id="1.%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%B9%B6%E6%9F%A5%E7%9C%8B" name="1.%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%B9%B6%E6%9F%A5%E7%9C%8B">
     1.å¯¼å…¥æ•°æ®å¹¶è¯»å–
    </h3>
    <pre><code class="language-python">import torch.nn as nn
import torch
from torchvision import datasets
import os,PIL,pathlib
import torchvision
import torchvision.transforms as transforms</code></pre>
    <pre><code class="language-python">data_dir='D:/TensorFlow1/T5'
data_dir=pathlib.Path(data_dir)
data_path=list(data_dir.glob('*'))
classnames=[path.name for path in data_path if path.is_dir()]
classnames
</code></pre>
    <p class="img-center">
     <img alt="" height="81" src="https://i-blog.csdnimg.cn/direct/e5daa8edd4784c27a24d4826707704ce.png" width="378"/>
    </p>
    <pre><code class="language-python"># å…³äºtransforms.Composeçš„æ›´å¤šä»‹ç»å¯ä»¥å‚è€ƒï¼šhttps://blog.csdn.net/qq_38251616/article/details/124878863
train_transforms = transforms.Compose([
    transforms.Resize([224, 224]),  # å°†è¾“å…¥å›¾ç‰‡resizeæˆç»Ÿä¸€å°ºå¯¸
    # transforms.RandomHorizontalFlip(), # éšæœºæ°´å¹³ç¿»è½¬
    transforms.ToTensor(),          # å°†PIL Imageæˆ–numpy.ndarrayè½¬æ¢ä¸ºtensorï¼Œå¹¶å½’ä¸€åŒ–åˆ°[0,1]ä¹‹é—´
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
        std=[0.229, 0.224, 0.225])])

test_transform = transforms.Compose([
    transforms.Resize([224, 224]),  # å°†è¾“å…¥å›¾ç‰‡resizeæˆç»Ÿä¸€å°ºå¯¸
    transforms.ToTensor(),          # å°†PIL Imageæˆ–numpy.ndarrayè½¬æ¢ä¸ºtensorï¼Œå¹¶å½’ä¸€åŒ–åˆ°[0,1]ä¹‹é—´
    transforms.Normalize(mean=[0.485, 0.456, 0.406], #ImageNetçš„å‡å€¼å’Œæ ‡å‡†å·®
        std=[0.229, 0.224, 0.225])])

train_dataset = datasets.ImageFolder("D:/TensorFlow1/T5/train/",transform=train_transforms)
test_dataset  = datasets.ImageFolder("D:/TensorFlow1/T5/test/",transform=test_transform)</code></pre>
    <pre><code class="language-python">train_dataset.class_to_idx  #ç”¨äºæ˜ å°„æ•°æ®é›†ä¸­æ¯ä¸ªç±»åˆ«çš„åç§°åˆ°ä¸€ä¸ªå”¯ä¸€çš„æ•´æ•°ç´¢å¼•ã€‚</code></pre>
    <p class="img-center">
     <img alt="" height="43" src="https://i-blog.csdnimg.cn/direct/eb77b95dc5534af98e92d69070c951d8.png" width="332"/>
    </p>
    <h3 id="2.%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%99%A8%C2%A0" name="2.%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%99%A8%C2%A0">
     2.åˆ›å»ºæ•°æ®åŠ è½½å™¨
    </h3>
    <pre><code class="language-python">batch_size=32
train_dl=torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,
                                     shuffle=True,num_workers=1)
test_dl=torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,
                                     shuffle=True,num_workers=1)</code></pre>
    <pre><code class="language-python">for X, y in test_dl:
    print("Shape of X [N, C, H, W]: ", X.shape)
    print("Shape of y: ", y.shape, y.dtype)
    break</code></pre>
    <p>
     <img alt="" height="74" src="https://i-blog.csdnimg.cn/direct/6634932cd00945ad8c1e3c0bef15416f.png" width="746"/>
    </p>
    <h2 id="%E4%BA%8C%E3%80%81%E6%9E%84%E5%BB%BA%E7%AE%80%E5%8D%95%E7%9A%84CNN%E7%BD%91%E7%BB%9C" name="%E4%BA%8C%E3%80%81%E6%9E%84%E5%BB%BA%E7%AE%80%E5%8D%95%E7%9A%84CNN%E7%BD%91%E7%BB%9C">
     äºŒã€æ„å»ºç®€å•çš„CNNç½‘ç»œ
    </h2>
    <p>
     <img alt="" height="773" src="https://i-blog.csdnimg.cn/direct/2bbb29dcb92744aaa1e7a4a786612154.png" width="1923"/>
    </p>
    <pre><code class="language-python">import torch.nn.functional as F    #å¯¼å…¥torch.nn.functionalæ¨¡å—ï¼Œé€šå¸¸ç”¨äºè°ƒç”¨ä¸€äº›å‡½æ•°å¼çš„æ“ä½œ

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1=nn.Sequential(
            nn.Conv2d(3, 12, kernel_size=5, padding=0), # 12*220*220  è¾“å…¥é€šé“æ•° 3ï¼Œè¾“å‡ºé€šé“æ•° 12ï¼Œå·ç§¯æ ¸å¤§å° 5x5ï¼Œæ— å¡«å……
            nn.BatchNorm2d(12),
            nn.ReLU())
        
        self.conv2=nn.Sequential(
            nn.Conv2d(12, 12, kernel_size=5, padding=0), # 12*216*216
            nn.BatchNorm2d(12),
            nn.ReLU())
        
        self.pool3=nn.Sequential(
            nn.MaxPool2d(2))                              # 12*108*108
        
        self.conv4=nn.Sequential(
            nn.Conv2d(12, 24, kernel_size=5, padding=0), # 24*104*104
            nn.BatchNorm2d(24),
            nn.ReLU())
        
        self.conv5=nn.Sequential(
            nn.Conv2d(24, 24, kernel_size=5, padding=0), # 24*100*100
            nn.BatchNorm2d(24),
            nn.ReLU())
        
        self.pool6=nn.Sequential( nn.MaxPool2d(2))                              # 24*50*50

        self.dropout = nn.Sequential(nn.Dropout(0.25))
        
        self.fc=nn.Sequential(nn.Linear(24*50*50, len(classenames)))
        
    def forward(self, x):
        
        batch_size = x.size(0)
        x = self.conv1(x)  # å·ç§¯-BN-æ¿€æ´»
        x = self.conv2(x)  # å·ç§¯-BN-æ¿€æ´»
        x = self.pool3(x)  # æ± åŒ–
        x = self.conv4(x)  # å·ç§¯-BN-æ¿€æ´»
        x = self.conv5(x)  # å·ç§¯-BN-æ¿€æ´»
        x = self.pool6(x)  # æ± åŒ–
        x = self.dropout(x)
        x = x.view(batch_size, -1)  # # å°†å·ç§¯å±‚çš„è¾“å‡ºå±•å¹³æˆä¸€ç»´å‘é‡ (batch, 24*50*50) ==&gt; (batch, -1), -1 æ­¤å¤„è‡ªåŠ¨ç®—å‡ºçš„æ˜¯24*50*50
        x = self.fc(x)
       
        return x
model = Model()
model</code></pre>
    <p>
     <img alt="" height="1037" src="https://i-blog.csdnimg.cn/direct/d989a2bcab6d407a9743744818da2742.png" width="1173"/>
    </p>
    <h2 id="%E4%B8%89%E3%80%81%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B" name="%E4%B8%89%E3%80%81%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">
     ä¸‰ã€è®­ç»ƒæ¨¡å‹
    </h2>
    <h3 id="1.%E7%BC%96%E5%86%99%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0" name="1.%E7%BC%96%E5%86%99%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0">
     1.ç¼–å†™è®­ç»ƒå‡½æ•°
    </h3>
    <pre><code class="language-python"># è®­ç»ƒå¾ªç¯
def train(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset)  # è®­ç»ƒé›†çš„å¤§å°
    num_batches = len(dataloader)   # æ‰¹æ¬¡æ•°ç›®, (size/batch_sizeï¼Œå‘ä¸Šå–æ•´)

    train_loss, train_acc = 0, 0  # åˆå§‹åŒ–è®­ç»ƒæŸå¤±å’Œæ­£ç¡®ç‡
    
    for X, y in dataloader:  # è·å–å›¾ç‰‡åŠå…¶æ ‡ç­¾        
        # è®¡ç®—é¢„æµ‹è¯¯å·®
        pred = model(X)          # ç½‘ç»œè¾“å‡º
        loss = loss_fn(pred, y)  # è®¡ç®—ç½‘ç»œè¾“å‡ºå’ŒçœŸå®å€¼ä¹‹é—´çš„å·®è·ï¼Œtargetsä¸ºçœŸå®å€¼ï¼Œè®¡ç®—äºŒè€…å·®å€¼å³ä¸ºæŸå¤±
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()  # gradå±æ€§å½’é›¶
        loss.backward()        # åå‘ä¼ æ’­
        optimizer.step()       # æ¯ä¸€æ­¥è‡ªåŠ¨æ›´æ–°
        
        # è®°å½•accä¸loss
        train_acc  += (pred.argmax(1) == y).type(torch.float).sum().item()
        train_loss += loss.item()
            
    train_acc  /= size
    train_loss /= num_batches

    return train_acc, train_loss</code></pre>
    <h3 id="2.%E7%BC%96%E5%86%99%E6%B5%8B%E8%AF%95%E5%87%BD%E6%95%B0" name="2.%E7%BC%96%E5%86%99%E6%B5%8B%E8%AF%95%E5%87%BD%E6%95%B0">
     2.ç¼–å†™æµ‹è¯•å‡½æ•°
    </h3>
    <pre><code class="language-python">def test (dataloader, model, loss_fn):
    size        = len(dataloader.dataset)  # æµ‹è¯•é›†çš„å¤§å°
    num_batches = len(dataloader)          # æ‰¹æ¬¡æ•°ç›®, (size/batch_sizeï¼Œå‘ä¸Šå–æ•´)
    test_loss, test_acc = 0, 0
    
    # å½“ä¸è¿›è¡Œè®­ç»ƒæ—¶ï¼Œåœæ­¢æ¢¯åº¦æ›´æ–°ï¼ŒèŠ‚çœè®¡ç®—å†…å­˜æ¶ˆè€—
    with torch.no_grad():
        for imgs, target in dataloader:        
            # è®¡ç®—loss
            target_pred = model(imgs)
            loss        = loss_fn(target_pred, target)
            
            test_loss += loss.item()
            test_acc  += (target_pred.argmax(1) == target).type(torch.float).sum().item()

    test_acc  /= size
    test_loss /= num_batches

    return test_acc, test_loss</code></pre>
    <h3 id="3.%E8%AE%BE%E7%BD%AE%E5%8A%A8%E6%80%81%E5%AD%A6%E4%B9%A0%E7%8E%87" name="3.%E8%AE%BE%E7%BD%AE%E5%8A%A8%E6%80%81%E5%AD%A6%E4%B9%A0%E7%8E%87">
     3.è®¾ç½®åŠ¨æ€å­¦ä¹ ç‡
    </h3>
    <pre><code class="language-python">def adjust_learning_rate(optimizer, epoch, start_lr):
    # æ¯ 2 ä¸ªepochè¡°å‡åˆ°åŸæ¥çš„ 0.92
    lr = start_lr * (0.92 ** (epoch // 2))
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr

learn_rate = 1e-4 # åˆå§‹å­¦ä¹ ç‡
optimizer  = torch.optim.SGD(model.parameters(), lr=learn_rate)</code></pre>
    <h3 id="4.%E6%AD%A3%E5%BC%8F%E8%AE%AD%E7%BB%83" name="4.%E6%AD%A3%E5%BC%8F%E8%AE%AD%E7%BB%83">
     4.æ­£å¼è®­ç»ƒ
    </h3>
    <pre><code class="language-python">loss_fn    = nn.CrossEntropyLoss() # åˆ›å»ºæŸå¤±å‡½æ•°
epochs     = 40

train_loss = []
train_acc  = []
test_loss  = []
test_acc   = []

for epoch in range(epochs):
    # æ›´æ–°å­¦ä¹ ç‡ï¼ˆä½¿ç”¨è‡ªå®šä¹‰å­¦ä¹ ç‡æ—¶ä½¿ç”¨ï¼‰
    adjust_learning_rate(optimizer, epoch, learn_rate)
    
    model.train()
    epoch_train_acc, epoch_train_loss = train(train_dl, model, loss_fn, optimizer)
    # scheduler.step() # æ›´æ–°å­¦ä¹ ç‡ï¼ˆè°ƒç”¨å®˜æ–¹åŠ¨æ€å­¦ä¹ ç‡æ¥å£æ—¶ä½¿ç”¨ï¼‰
    
    model.eval()
    epoch_test_acc, epoch_test_loss = test(test_dl, model, loss_fn)
    
    train_acc.append(epoch_train_acc)
    train_loss.append(epoch_train_loss)
    test_acc.append(epoch_test_acc)
    test_loss.append(epoch_test_loss)
    
    # è·å–å½“å‰çš„å­¦ä¹ ç‡
    lr = optimizer.state_dict()['param_groups'][0]['lr']
    
    template = ('Epoch:{:2d}, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%, Test_loss:{:.3f}, Lr:{:.2E}')
    print(template.format(epoch+1, epoch_train_acc*100, epoch_train_loss, 
                          epoch_test_acc*100, epoch_test_loss, lr))
print('Done')</code></pre>
    <p>
     <img alt="" height="811" src="https://i-blog.csdnimg.cn/direct/6e808db5d9c7478cb952856e72a814a3.png" width="784"/>
    </p>
    <h2 id="%E5%9B%9B%E3%80%81%E7%BB%93%E6%9E%9C%E5%8F%AF%E8%A7%86%E5%8C%96" name="%E5%9B%9B%E3%80%81%E7%BB%93%E6%9E%9C%E5%8F%AF%E8%A7%86%E5%8C%96">
     å››ã€ç»“æœå¯è§†åŒ–
    </h2>
    <pre><code class="language-python">import matplotlib.pyplot as plt
#éšè—è­¦å‘Š
import warnings
warnings.filterwarnings("ignore")               #å¿½ç•¥è­¦å‘Šä¿¡æ¯
plt.rcParams['font.sans-serif']    = ['SimHei'] # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False      # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
plt.rcParams['figure.dpi']         = 100        #åˆ†è¾¨ç‡

from datetime import datetime
current_time = datetime.now() # è·å–å½“å‰æ—¶é—´

epochs_range = range(epochs)

plt.figure(figsize=(12, 3))
plt.subplot(1, 2, 1)

plt.plot(epochs_range, train_acc, label='Training Accuracy')
plt.plot(epochs_range, test_acc, label='Test Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')
plt.xlabel(current_time) # æ‰“å¡è¯·å¸¦ä¸Šæ—¶é—´æˆ³ï¼Œå¦åˆ™ä»£ç æˆªå›¾æ— æ•ˆ

plt.subplot(1, 2, 2)
plt.plot(epochs_range, train_loss, label='Training Loss')
plt.plot(epochs_range, test_loss, label='Test Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()</code></pre>
    <p>
     <img alt="" height="515" src="https://i-blog.csdnimg.cn/direct/9cc74c4a764c401a8c0c58959335ab1b.png" width="1646"/>
    </p>
    <h2 id="%E4%BA%94%E3%80%81%E5%B0%9D%E8%AF%95%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%93%8D%E4%BD%9C" name="%E4%BA%94%E3%80%81%E5%B0%9D%E8%AF%95%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%93%8D%E4%BD%9C">
     äº”ã€å°è¯•æ•°æ®å¢å¼ºæ“ä½œ
    </h2>
    <p>
     æ ¹æ®losså’Œaccuracyå›¾ï¼Œè®­ç»ƒå‡†ç¡®ç‡æ˜æ˜¾é«˜äºæµ‹è¯•å‡†ç¡®ç‡ï¼Œå¯èƒ½è¡¨æ˜æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šè¿‡æ‹Ÿåˆã€‚å› æ­¤ï¼Œæˆ‘å°†å°è¯•å¯¹è®­ç»ƒé›†æ ·æœ¬è¿›è¡Œç¿»è½¬ã€æ—‹è½¬ç­‰å¢å¼ºæ“ä½œã€‚
    </p>
    <pre><code class="language-python">train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])
</code></pre>
    <p>
     æœ€åå¾—åˆ°
     <img alt="" height="557" src="https://i-blog.csdnimg.cn/direct/125f127cfbe94bb1abe941ecf50d5338.png" width="1781"/>
    </p>
    <p>
     å°½ç®¡è¿‡æ‹Ÿåˆç¨‹åº¦æ²¡æœ‰å¢å¼ºå‰é«˜ï¼Œä½†æ€»ä½“å‡†ç¡®ç‡å’ŒæŸå¤±éƒ½ä¸å¦‚ç¬¬ä¸€ç»„å›¾ï¼Œä¹Ÿè®¸æ˜¯æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›è¾ƒå¼±ï¼Œæˆ–è€…è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œå¯¼è‡´æ¨¡å‹æœªèƒ½å……åˆ†å­¦ä¹ åˆ°æ•°æ®çš„ç‰¹å¾ã€‚
    </p>
    <h2 id="%E5%85%AD%E3%80%81%E6%80%BB%E7%BB%93" name="%E5%85%AD%E3%80%81%E6%80%BB%E7%BB%93" style="background-color:transparent">
     å…­ã€æ€»ç»“
    </h2>
    <h3 id="1.torchvision.transforms.Compose()%E7%B1%BB" name="1.torchvision.transforms.Compose()%E7%B1%BB">
     1.
     <code>
      <span style="background-color:#fbd4d0">
       torchvision.transforms.Compose()
      </span>
     </code>
     ç±»
    </h3>
    <p>
     ç”¨äºå°†å¤šä¸ªå›¾åƒå˜æ¢æ“ä½œç»„åˆæˆä¸€ä¸ªåºåˆ—ã€‚åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œå¯¹å›¾åƒæ•°æ®è¿›è¡Œé¢„å¤„ç†æ˜¯ä¸€ä¸ªå¸¸è§çš„æ“ä½œï¼Œä¾‹å¦‚è°ƒæ•´å›¾åƒå¤§å°ã€å½’ä¸€åŒ–ã€è£å‰ªç­‰ï¼Œ
     <code>
      Compose()
     </code>
     å¯ä»¥å°†è¿™äº›æ“ä½œæŒ‰é¡ºåºä¾æ¬¡åº”ç”¨åˆ°è¾“å…¥çš„å›¾åƒä¸Šã€‚
    </p>
    <p>
     <img alt="" height="609" src="https://i-blog.csdnimg.cn/direct/28576e1ab1fb40edbb80f8c72e0ac50d.png" width="1635"/>
    </p>
    <p>
     æ³¨æ„ï¼Œè¿™é‡Œçš„meanå’Œstdå–çš„æ˜¯imagenetçš„ã€‚è‹¥æ•°æ®é›†æ˜¯è‡ªç„¶åœºæ™¯å›¾åƒï¼ˆå¦‚äººã€åŠ¨ç‰©ã€å»ºç­‘ç­‰ï¼‰ï¼Œæˆ–ä½¿ç”¨äº†é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚åŸºäº ImageNet æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹ï¼‰å»ºè®®ä½¿ç”¨Imagenetçš„meanå’Œstdã€‚
     <br/>
     å¦‚æœä½ çš„æ•°æ®é›†ä¸ ImageNet ä¸åŒï¼ˆä¾‹å¦‚åŒ»å­¦å›¾åƒã€å«æ˜Ÿå›¾åƒæˆ–ç»è¿‡ç‰¹æ®Šå¤„ç†çš„å›¾åƒï¼‰ï¼Œå»ºè®®è®¡ç®—ä½ è‡ªå·±çš„æ•°æ®é›†çš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚ä½†å¯¹äºCIFAR-10ã€COCOç­‰æ•°æ®é›†æœ‰è‡ªå·±çš„meanå’Œstd
    </p>
    <h3 id="2.%5BN%2C%20C%2C%20H%2C%20W%5D" name="2.%5BN%2C%20C%2C%20H%2C%20W%5D">
     2.[N, C, H, W]
    </h3>
    <p>
     åœ¨å›¾åƒæ•°æ®ä¸­ï¼Œé€šå¸¸éµå¾ª [N, C, H, W] çš„æ ¼å¼ï¼Œå…¶ä¸­ï¼š
    </p>
    <ul>
     <li>
      N è¡¨ç¤ºæ‰¹æ¬¡å¤§å°ï¼ˆå³ä¸€ä¸ªæ‰¹æ¬¡ä¸­åŒ…å«çš„å›¾åƒæ•°é‡ï¼‰ã€‚
     </li>
     <li>
      C è¡¨ç¤ºå›¾åƒçš„é€šé“æ•°ï¼Œå¯¹äºå½©è‰²å›¾åƒé€šå¸¸ä¸º 3ï¼ˆRGB ä¸‰ä¸ªé€šé“ï¼‰ã€‚
     </li>
     <li>
      H è¡¨ç¤ºå›¾åƒçš„é«˜åº¦ã€‚
     </li>
     <li>
      W è¡¨ç¤ºå›¾åƒçš„å®½åº¦ã€‚
     </li>
    </ul>
    <h3 id="3.%E6%84%9F%E5%8F%97%E9%87%8E%E4%B8%8E%E5%8D%B7%E7%A7%AF%E6%A0%B8%E5%A4%A7%E5%B0%8F%E7%9A%84%E6%9D%83%E8%A1%A1%C2%A0" name="3.%E6%84%9F%E5%8F%97%E9%87%8E%E4%B8%8E%E5%8D%B7%E7%A7%AF%E6%A0%B8%E5%A4%A7%E5%B0%8F%E7%9A%84%E6%9D%83%E8%A1%A1%C2%A0">
     3.æ„Ÿå—é‡ä¸å·ç§¯æ ¸å¤§å°çš„æƒè¡¡
    </h3>
    <ul>
     <li>
      <strong>
       å·ç§¯æ ¸
      </strong>
      ï¼šå·ç§¯æ ¸æ˜¯å·ç§¯ç¥ç»ç½‘ç»œä¸­ç”¨äºå¯¹è¾“å…¥æ•°æ®è¿›è¡Œå·ç§¯æ“ä½œçš„å°å‹çŸ©é˜µã€‚åœ¨å›¾åƒå·ç§¯æ“ä½œä¸­ï¼Œå·ç§¯æ ¸åœ¨è¾“å…¥å›¾åƒä¸Šæ»‘åŠ¨ï¼Œé€å…ƒç´ ç›¸ä¹˜å¹¶æ±‚å’Œï¼Œä»è€Œæå–è¾“å…¥å›¾åƒçš„ç‰¹å¾ã€‚å·ç§¯æ ¸çš„å¤§å°ï¼ˆå¦‚ 3x3 ç­‰ï¼‰å’Œæ•°é‡ï¼ˆå³è¾“å‡ºé€šé“æ•°ï¼‰æ˜¯å·ç§¯å±‚çš„é‡è¦å‚æ•°ã€‚
     </li>
     <li>
      <strong>
       æ„Ÿå—é‡
      </strong>
      ï¼šæ„Ÿå—é‡æ˜¯æŒ‡å·ç§¯ç¥ç»ç½‘ç»œä¸­æŸä¸€å±‚è¾“å‡ºç‰¹å¾å›¾ä¸Šçš„ä¸€ä¸ªåƒç´ ç‚¹å¯¹åº”è¾“å…¥å›¾åƒä¸Šçš„åŒºåŸŸå¤§å°ã€‚ç®€å•æ¥è¯´ï¼Œæ„Ÿå—é‡æè¿°äº†å·ç§¯ç¥ç»ç½‘ç»œä¸­æŸä¸ªç¥ç»å…ƒèƒ½å¤Ÿ â€œçœ‹åˆ°â€ çš„è¾“å…¥å›¾åƒçš„åŒºåŸŸèŒƒå›´ã€‚
     </li>
    </ul>
    <p>
     <strong>
      æ„Ÿå—é‡å’Œå·ç§¯æ ¸å¤§å°æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ
     </strong>
    </p>
    <ul>
     <li>
      <strong>
       å¢å¤§å·ç§¯æ ¸å¤§å°
      </strong>
      ï¼šä½¿ç”¨æ›´å¤§çš„å·ç§¯æ ¸å¯ä»¥åœ¨å•ä¸ªå·ç§¯å±‚ä¸­è·å¾—æ›´å¤§çš„æ„Ÿå—é‡ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿæ•æ‰åˆ°æ›´å¹¿æ³›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ç„¶è€Œï¼Œå¢å¤§å·ç§¯æ ¸å¤§å°ä¼šå¢åŠ æ¨¡å‹çš„å‚æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦ï¼Œå¹¶ä¸”å¯èƒ½ä¼šå¿½ç•¥ä¸€äº›å±€éƒ¨ç»†èŠ‚ä¿¡æ¯ã€‚
     </li>
     <li>
      <strong>
       å †å å°å·ç§¯æ ¸
      </strong>
      ï¼šå¤šä¸ªå°å·ç§¯æ ¸å †å çš„æ•ˆæœé€šå¸¸ä¼˜äºä¸€ä¸ªå¤§å·ç§¯æ ¸ã€‚é€šè¿‡å †å å¤šä¸ªå°å·ç§¯æ ¸ï¼Œå¯ä»¥åœ¨è·å¾—ç›¸åŒæ„Ÿå—é‡çš„æƒ…å†µä¸‹ï¼Œå‡å°‘æ¨¡å‹çš„å‚æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦ã€‚ä¾‹å¦‚ï¼Œä¸¤ä¸ª 3x3 çš„å·ç§¯æ ¸å †å å¯ä»¥è·å¾—ä¸ä¸€ä¸ª 5x5 å·ç§¯æ ¸ç›¸åŒçš„æ„Ÿå—é‡ï¼Œä½†å‚æ•°é‡æ›´å°‘ã€‚
     </li>
    </ul>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f36373836393333332f:61727469636c652f64657461696c732f313436303734383438" class_="artid" style="display:none">
 </p>
</div>


