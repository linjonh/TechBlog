---
layout: post
title: "æ·±åº¦å­¦ä¹ ç¬”è®°16-è¿åŠ¨é‹å“ç‰Œè¯†åˆ«Pytorch"
date: 2025-03-06 18:37:44 +0800
description: "ç›®å½•ä¸€ã€å‰æœŸå·¥ä½œ1.å¯¼å…¥æ•°æ®å¹¶è¯»å–2.åˆ›å»ºæ•°æ®åŠ è½½å™¨ äºŒã€æ„å»ºç®€å•çš„CNNç½‘ç»œä¸‰ã€è®­ç»ƒæ¨¡å‹1.ç¼–å†™è®­ç»ƒå‡½æ•°2.ç¼–å†™æµ‹è¯•å‡½æ•°3.è®¾ç½®åŠ¨æ€å­¦ä¹ ç‡4.æ­£å¼è®­ç»ƒå››ã€ç»“æœå¯è§†åŒ–äº”ã€å°è¯•æ•°æ®å¢å¼ºæ“ä½œå…­ã€æ€»ç»“1.torchvision.transforms.Compose()ç±»2.[N, C, H, W]3.æ„Ÿå—é‡ä¸å·ç§¯æ ¸å¤§å°çš„æƒè¡¡ 2.ç¼–å†™æµ‹è¯•å‡½æ•°3.è®¾ç½®åŠ¨æ€å­¦ä¹ ç‡4.æ­£å¼è®­ç»ƒæ ¹æ®losså’Œaccuracyå›¾ï¼Œè®­ç»ƒå‡†ç¡®ç‡æ˜æ˜¾é«˜äºæµ‹è¯•å‡†ç¡®"
keywords: "æ·±åº¦å­¦ä¹ ç¬”è®°16-è¿åŠ¨é‹å“ç‰Œè¯†åˆ«(Pytorch)"
categories: ['æ·±åº¦å­¦ä¹ ']
tags: ['ç¬”è®°', 'æ·±åº¦å­¦ä¹ ', 'Pytorch']
artid: "146074848"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146074848
    alt: "æ·±åº¦å­¦ä¹ ç¬”è®°16-è¿åŠ¨é‹å“ç‰Œè¯†åˆ«Pytorch"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146074848
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146074848
cover: https://bing.ee123.net/img/rand?artid=146074848
image: https://bing.ee123.net/img/rand?artid=146074848
img: https://bing.ee123.net/img/rand?artid=146074848
---

# æ·±åº¦å­¦ä¹ ç¬”è®°16-è¿åŠ¨é‹å“ç‰Œè¯†åˆ«(Pytorch)

  * **ğŸ¨ æœ¬æ–‡ä¸º**[ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥](https://mp.weixin.qq.com/s/kV8ZsJv6cPNzJLEuhPfvXg "ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥")**ä¸­çš„å­¦ä¹ è®°å½•åšå®¢**
  * **ğŸ–****åŸä½œè€…ï¼š**[KåŒå­¦å•Š](https://mtyjkh.blog.csdn.net/ "KåŒå­¦å•Š")

* * *

## ä¸€ã€å‰æœŸå·¥ä½œ

### 1.å¯¼å…¥æ•°æ®å¹¶è¯»å–

    
    
    import torch.nn as nn
    import torch
    from torchvision import datasets
    import os,PIL,pathlib
    import torchvision
    import torchvision.transforms as transforms
    
    
    data_dir='D:/TensorFlow1/T5'
    data_dir=pathlib.Path(data_dir)
    data_path=list(data_dir.glob('*'))
    classnames=[path.name for path in data_path if path.is_dir()]
    classnames
    

![](https://i-blog.csdnimg.cn/direct/e5daa8edd4784c27a24d4826707704ce.png)

    
    
    # å…³äºtransforms.Composeçš„æ›´å¤šä»‹ç»å¯ä»¥å‚è€ƒï¼šhttps://blog.csdn.net/qq_38251616/article/details/124878863
    train_transforms = transforms.Compose([
        transforms.Resize([224, 224]),  # å°†è¾“å…¥å›¾ç‰‡resizeæˆç»Ÿä¸€å°ºå¯¸
        # transforms.RandomHorizontalFlip(), # éšæœºæ°´å¹³ç¿»è½¬
        transforms.ToTensor(),          # å°†PIL Imageæˆ–numpy.ndarrayè½¬æ¢ä¸ºtensorï¼Œå¹¶å½’ä¸€åŒ–åˆ°[0,1]ä¹‹é—´
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
            std=[0.229, 0.224, 0.225])])
    
    test_transform = transforms.Compose([
        transforms.Resize([224, 224]),  # å°†è¾“å…¥å›¾ç‰‡resizeæˆç»Ÿä¸€å°ºå¯¸
        transforms.ToTensor(),          # å°†PIL Imageæˆ–numpy.ndarrayè½¬æ¢ä¸ºtensorï¼Œå¹¶å½’ä¸€åŒ–åˆ°[0,1]ä¹‹é—´
        transforms.Normalize(mean=[0.485, 0.456, 0.406], #ImageNetçš„å‡å€¼å’Œæ ‡å‡†å·®
            std=[0.229, 0.224, 0.225])])
    
    train_dataset = datasets.ImageFolder("D:/TensorFlow1/T5/train/",transform=train_transforms)
    test_dataset  = datasets.ImageFolder("D:/TensorFlow1/T5/test/",transform=test_transform)
    
    
    train_dataset.class_to_idx  #ç”¨äºæ˜ å°„æ•°æ®é›†ä¸­æ¯ä¸ªç±»åˆ«çš„åç§°åˆ°ä¸€ä¸ªå”¯ä¸€çš„æ•´æ•°ç´¢å¼•ã€‚

![](https://i-blog.csdnimg.cn/direct/eb77b95dc5534af98e92d69070c951d8.png)

### 2.åˆ›å»ºæ•°æ®åŠ è½½å™¨

    
    
    batch_size=32
    train_dl=torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,
                                         shuffle=True,num_workers=1)
    test_dl=torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,
                                         shuffle=True,num_workers=1)
    
    
    for X, y in test_dl:
        print("Shape of X [N, C, H, W]: ", X.shape)
        print("Shape of y: ", y.shape, y.dtype)
        break

![](https://i-blog.csdnimg.cn/direct/6634932cd00945ad8c1e3c0bef15416f.png)

## äºŒã€æ„å»ºç®€å•çš„CNNç½‘ç»œ

![](https://i-blog.csdnimg.cn/direct/2bbb29dcb92744aaa1e7a4a786612154.png)

    
    
    import torch.nn.functional as F    #å¯¼å…¥torch.nn.functionalæ¨¡å—ï¼Œé€šå¸¸ç”¨äºè°ƒç”¨ä¸€äº›å‡½æ•°å¼çš„æ“ä½œ
    
    class Model(nn.Module):
        def __init__(self):
            super(Model, self).__init__()
            self.conv1=nn.Sequential(
                nn.Conv2d(3, 12, kernel_size=5, padding=0), # 12*220*220  è¾“å…¥é€šé“æ•° 3ï¼Œè¾“å‡ºé€šé“æ•° 12ï¼Œå·ç§¯æ ¸å¤§å° 5x5ï¼Œæ— å¡«å……
                nn.BatchNorm2d(12),
                nn.ReLU())
            
            self.conv2=nn.Sequential(
                nn.Conv2d(12, 12, kernel_size=5, padding=0), # 12*216*216
                nn.BatchNorm2d(12),
                nn.ReLU())
            
            self.pool3=nn.Sequential(
                nn.MaxPool2d(2))                              # 12*108*108
            
            self.conv4=nn.Sequential(
                nn.Conv2d(12, 24, kernel_size=5, padding=0), # 24*104*104
                nn.BatchNorm2d(24),
                nn.ReLU())
            
            self.conv5=nn.Sequential(
                nn.Conv2d(24, 24, kernel_size=5, padding=0), # 24*100*100
                nn.BatchNorm2d(24),
                nn.ReLU())
            
            self.pool6=nn.Sequential( nn.MaxPool2d(2))                              # 24*50*50
    
            self.dropout = nn.Sequential(nn.Dropout(0.25))
            
            self.fc=nn.Sequential(nn.Linear(24*50*50, len(classenames)))
            
        def forward(self, x):
            
            batch_size = x.size(0)
            x = self.conv1(x)  # å·ç§¯-BN-æ¿€æ´»
            x = self.conv2(x)  # å·ç§¯-BN-æ¿€æ´»
            x = self.pool3(x)  # æ± åŒ–
            x = self.conv4(x)  # å·ç§¯-BN-æ¿€æ´»
            x = self.conv5(x)  # å·ç§¯-BN-æ¿€æ´»
            x = self.pool6(x)  # æ± åŒ–
            x = self.dropout(x)
            x = x.view(batch_size, -1)  # # å°†å·ç§¯å±‚çš„è¾“å‡ºå±•å¹³æˆä¸€ç»´å‘é‡ (batch, 24*50*50) ==> (batch, -1), -1 æ­¤å¤„è‡ªåŠ¨ç®—å‡ºçš„æ˜¯24*50*50
            x = self.fc(x)
           
            return x
    model = Model()
    model

![](https://i-blog.csdnimg.cn/direct/d989a2bcab6d407a9743744818da2742.png)

## ä¸‰ã€è®­ç»ƒæ¨¡å‹

### 1.ç¼–å†™è®­ç»ƒå‡½æ•°

    
    
    # è®­ç»ƒå¾ªç¯
    def train(dataloader, model, loss_fn, optimizer):
        size = len(dataloader.dataset)  # è®­ç»ƒé›†çš„å¤§å°
        num_batches = len(dataloader)   # æ‰¹æ¬¡æ•°ç›®, (size/batch_sizeï¼Œå‘ä¸Šå–æ•´)
    
        train_loss, train_acc = 0, 0  # åˆå§‹åŒ–è®­ç»ƒæŸå¤±å’Œæ­£ç¡®ç‡
        
        for X, y in dataloader:  # è·å–å›¾ç‰‡åŠå…¶æ ‡ç­¾        
            # è®¡ç®—é¢„æµ‹è¯¯å·®
            pred = model(X)          # ç½‘ç»œè¾“å‡º
            loss = loss_fn(pred, y)  # è®¡ç®—ç½‘ç»œè¾“å‡ºå’ŒçœŸå®å€¼ä¹‹é—´çš„å·®è·ï¼Œtargetsä¸ºçœŸå®å€¼ï¼Œè®¡ç®—äºŒè€…å·®å€¼å³ä¸ºæŸå¤±
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()  # gradå±æ€§å½’é›¶
            loss.backward()        # åå‘ä¼ æ’­
            optimizer.step()       # æ¯ä¸€æ­¥è‡ªåŠ¨æ›´æ–°
            
            # è®°å½•accä¸loss
            train_acc  += (pred.argmax(1) == y).type(torch.float).sum().item()
            train_loss += loss.item()
                
        train_acc  /= size
        train_loss /= num_batches
    
        return train_acc, train_loss

### 2.ç¼–å†™æµ‹è¯•å‡½æ•°

    
    
    def test (dataloader, model, loss_fn):
        size        = len(dataloader.dataset)  # æµ‹è¯•é›†çš„å¤§å°
        num_batches = len(dataloader)          # æ‰¹æ¬¡æ•°ç›®, (size/batch_sizeï¼Œå‘ä¸Šå–æ•´)
        test_loss, test_acc = 0, 0
        
        # å½“ä¸è¿›è¡Œè®­ç»ƒæ—¶ï¼Œåœæ­¢æ¢¯åº¦æ›´æ–°ï¼ŒèŠ‚çœè®¡ç®—å†…å­˜æ¶ˆè€—
        with torch.no_grad():
            for imgs, target in dataloader:        
                # è®¡ç®—loss
                target_pred = model(imgs)
                loss        = loss_fn(target_pred, target)
                
                test_loss += loss.item()
                test_acc  += (target_pred.argmax(1) == target).type(torch.float).sum().item()
    
        test_acc  /= size
        test_loss /= num_batches
    
        return test_acc, test_loss

### 3.è®¾ç½®åŠ¨æ€å­¦ä¹ ç‡

    
    
    def adjust_learning_rate(optimizer, epoch, start_lr):
        # æ¯ 2 ä¸ªepochè¡°å‡åˆ°åŸæ¥çš„ 0.92
        lr = start_lr * (0.92 ** (epoch // 2))
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr
    
    learn_rate = 1e-4 # åˆå§‹å­¦ä¹ ç‡
    optimizer  = torch.optim.SGD(model.parameters(), lr=learn_rate)

### 4.æ­£å¼è®­ç»ƒ

    
    
    loss_fn    = nn.CrossEntropyLoss() # åˆ›å»ºæŸå¤±å‡½æ•°
    epochs     = 40
    
    train_loss = []
    train_acc  = []
    test_loss  = []
    test_acc   = []
    
    for epoch in range(epochs):
        # æ›´æ–°å­¦ä¹ ç‡ï¼ˆä½¿ç”¨è‡ªå®šä¹‰å­¦ä¹ ç‡æ—¶ä½¿ç”¨ï¼‰
        adjust_learning_rate(optimizer, epoch, learn_rate)
        
        model.train()
        epoch_train_acc, epoch_train_loss = train(train_dl, model, loss_fn, optimizer)
        # scheduler.step() # æ›´æ–°å­¦ä¹ ç‡ï¼ˆè°ƒç”¨å®˜æ–¹åŠ¨æ€å­¦ä¹ ç‡æ¥å£æ—¶ä½¿ç”¨ï¼‰
        
        model.eval()
        epoch_test_acc, epoch_test_loss = test(test_dl, model, loss_fn)
        
        train_acc.append(epoch_train_acc)
        train_loss.append(epoch_train_loss)
        test_acc.append(epoch_test_acc)
        test_loss.append(epoch_test_loss)
        
        # è·å–å½“å‰çš„å­¦ä¹ ç‡
        lr = optimizer.state_dict()['param_groups'][0]['lr']
        
        template = ('Epoch:{:2d}, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%, Test_loss:{:.3f}, Lr:{:.2E}')
        print(template.format(epoch+1, epoch_train_acc*100, epoch_train_loss, 
                              epoch_test_acc*100, epoch_test_loss, lr))
    print('Done')

![](https://i-blog.csdnimg.cn/direct/6e808db5d9c7478cb952856e72a814a3.png)

## å››ã€ç»“æœå¯è§†åŒ–

    
    
    import matplotlib.pyplot as plt
    #éšè—è­¦å‘Š
    import warnings
    warnings.filterwarnings("ignore")               #å¿½ç•¥è­¦å‘Šä¿¡æ¯
    plt.rcParams['font.sans-serif']    = ['SimHei'] # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
    plt.rcParams['axes.unicode_minus'] = False      # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
    plt.rcParams['figure.dpi']         = 100        #åˆ†è¾¨ç‡
    
    from datetime import datetime
    current_time = datetime.now() # è·å–å½“å‰æ—¶é—´
    
    epochs_range = range(epochs)
    
    plt.figure(figsize=(12, 3))
    plt.subplot(1, 2, 1)
    
    plt.plot(epochs_range, train_acc, label='Training Accuracy')
    plt.plot(epochs_range, test_acc, label='Test Accuracy')
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')
    plt.xlabel(current_time) # æ‰“å¡è¯·å¸¦ä¸Šæ—¶é—´æˆ³ï¼Œå¦åˆ™ä»£ç æˆªå›¾æ— æ•ˆ
    
    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, train_loss, label='Training Loss')
    plt.plot(epochs_range, test_loss, label='Test Loss')
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.show()

![](https://i-blog.csdnimg.cn/direct/9cc74c4a764c401a8c0c58959335ab1b.png)

## äº”ã€å°è¯•æ•°æ®å¢å¼ºæ“ä½œ

æ ¹æ®losså’Œaccuracyå›¾ï¼Œè®­ç»ƒå‡†ç¡®ç‡æ˜æ˜¾é«˜äºæµ‹è¯•å‡†ç¡®ç‡ï¼Œå¯èƒ½è¡¨æ˜æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šè¿‡æ‹Ÿåˆã€‚å› æ­¤ï¼Œæˆ‘å°†å°è¯•å¯¹è®­ç»ƒé›†æ ·æœ¬è¿›è¡Œç¿»è½¬ã€æ—‹è½¬ç­‰å¢å¼ºæ“ä½œã€‚

    
    
    train_transforms = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])
    

æœ€åå¾—åˆ°![](https://i-blog.csdnimg.cn/direct/125f127cfbe94bb1abe941ecf50d5338.png)

å°½ç®¡è¿‡æ‹Ÿåˆç¨‹åº¦æ²¡æœ‰å¢å¼ºå‰é«˜ï¼Œä½†æ€»ä½“å‡†ç¡®ç‡å’ŒæŸå¤±éƒ½ä¸å¦‚ç¬¬ä¸€ç»„å›¾ï¼Œä¹Ÿè®¸æ˜¯æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›è¾ƒå¼±ï¼Œæˆ–è€…è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œå¯¼è‡´æ¨¡å‹æœªèƒ½å……åˆ†å­¦ä¹ åˆ°æ•°æ®çš„ç‰¹å¾ã€‚

## å…­ã€æ€»ç»“

### 1.`torchvision.transforms.Compose()`ç±»

ç”¨äºå°†å¤šä¸ªå›¾åƒå˜æ¢æ“ä½œç»„åˆæˆä¸€ä¸ªåºåˆ—ã€‚åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œå¯¹å›¾åƒæ•°æ®è¿›è¡Œé¢„å¤„ç†æ˜¯ä¸€ä¸ªå¸¸è§çš„æ“ä½œï¼Œä¾‹å¦‚è°ƒæ•´å›¾åƒå¤§å°ã€å½’ä¸€åŒ–ã€è£å‰ªç­‰ï¼Œ`Compose()`
å¯ä»¥å°†è¿™äº›æ“ä½œæŒ‰é¡ºåºä¾æ¬¡åº”ç”¨åˆ°è¾“å…¥çš„å›¾åƒä¸Šã€‚

![](https://i-blog.csdnimg.cn/direct/28576e1ab1fb40edbb80f8c72e0ac50d.png)

æ³¨æ„ï¼Œè¿™é‡Œçš„meanå’Œstdå–çš„æ˜¯imagenetçš„ã€‚è‹¥æ•°æ®é›†æ˜¯è‡ªç„¶åœºæ™¯å›¾åƒï¼ˆå¦‚äººã€åŠ¨ç‰©ã€å»ºç­‘ç­‰ï¼‰ï¼Œæˆ–ä½¿ç”¨äº†é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚åŸºäº ImageNet
æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹ï¼‰å»ºè®®ä½¿ç”¨Imagenetçš„meanå’Œstdã€‚  
å¦‚æœä½ çš„æ•°æ®é›†ä¸ ImageNet
ä¸åŒï¼ˆä¾‹å¦‚åŒ»å­¦å›¾åƒã€å«æ˜Ÿå›¾åƒæˆ–ç»è¿‡ç‰¹æ®Šå¤„ç†çš„å›¾åƒï¼‰ï¼Œå»ºè®®è®¡ç®—ä½ è‡ªå·±çš„æ•°æ®é›†çš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚ä½†å¯¹äºCIFAR-10ã€COCOç­‰æ•°æ®é›†æœ‰è‡ªå·±çš„meanå’Œstd

### 2.[N, C, H, W]

åœ¨å›¾åƒæ•°æ®ä¸­ï¼Œé€šå¸¸éµå¾ª [N, C, H, W] çš„æ ¼å¼ï¼Œå…¶ä¸­ï¼š

  * N è¡¨ç¤ºæ‰¹æ¬¡å¤§å°ï¼ˆå³ä¸€ä¸ªæ‰¹æ¬¡ä¸­åŒ…å«çš„å›¾åƒæ•°é‡ï¼‰ã€‚
  * C è¡¨ç¤ºå›¾åƒçš„é€šé“æ•°ï¼Œå¯¹äºå½©è‰²å›¾åƒé€šå¸¸ä¸º 3ï¼ˆRGB ä¸‰ä¸ªé€šé“ï¼‰ã€‚
  * H è¡¨ç¤ºå›¾åƒçš„é«˜åº¦ã€‚
  * W è¡¨ç¤ºå›¾åƒçš„å®½åº¦ã€‚

### 3.æ„Ÿå—é‡ä¸å·ç§¯æ ¸å¤§å°çš„æƒè¡¡

  * **å·ç§¯æ ¸** ï¼šå·ç§¯æ ¸æ˜¯å·ç§¯ç¥ç»ç½‘ç»œä¸­ç”¨äºå¯¹è¾“å…¥æ•°æ®è¿›è¡Œå·ç§¯æ“ä½œçš„å°å‹çŸ©é˜µã€‚åœ¨å›¾åƒå·ç§¯æ“ä½œä¸­ï¼Œå·ç§¯æ ¸åœ¨è¾“å…¥å›¾åƒä¸Šæ»‘åŠ¨ï¼Œé€å…ƒç´ ç›¸ä¹˜å¹¶æ±‚å’Œï¼Œä»è€Œæå–è¾“å…¥å›¾åƒçš„ç‰¹å¾ã€‚å·ç§¯æ ¸çš„å¤§å°ï¼ˆå¦‚ 3x3 ç­‰ï¼‰å’Œæ•°é‡ï¼ˆå³è¾“å‡ºé€šé“æ•°ï¼‰æ˜¯å·ç§¯å±‚çš„é‡è¦å‚æ•°ã€‚
  * **æ„Ÿå—é‡** ï¼šæ„Ÿå—é‡æ˜¯æŒ‡å·ç§¯ç¥ç»ç½‘ç»œä¸­æŸä¸€å±‚è¾“å‡ºç‰¹å¾å›¾ä¸Šçš„ä¸€ä¸ªåƒç´ ç‚¹å¯¹åº”è¾“å…¥å›¾åƒä¸Šçš„åŒºåŸŸå¤§å°ã€‚ç®€å•æ¥è¯´ï¼Œæ„Ÿå—é‡æè¿°äº†å·ç§¯ç¥ç»ç½‘ç»œä¸­æŸä¸ªç¥ç»å…ƒèƒ½å¤Ÿ â€œçœ‹åˆ°â€ çš„è¾“å…¥å›¾åƒçš„åŒºåŸŸèŒƒå›´ã€‚

**æ„Ÿå—é‡å’Œå·ç§¯æ ¸å¤§å°æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ**

  * **å¢å¤§å·ç§¯æ ¸å¤§å°** ï¼šä½¿ç”¨æ›´å¤§çš„å·ç§¯æ ¸å¯ä»¥åœ¨å•ä¸ªå·ç§¯å±‚ä¸­è·å¾—æ›´å¤§çš„æ„Ÿå—é‡ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿæ•æ‰åˆ°æ›´å¹¿æ³›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ç„¶è€Œï¼Œå¢å¤§å·ç§¯æ ¸å¤§å°ä¼šå¢åŠ æ¨¡å‹çš„å‚æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦ï¼Œå¹¶ä¸”å¯èƒ½ä¼šå¿½ç•¥ä¸€äº›å±€éƒ¨ç»†èŠ‚ä¿¡æ¯ã€‚
  * **å †å å°å·ç§¯æ ¸** ï¼šå¤šä¸ªå°å·ç§¯æ ¸å †å çš„æ•ˆæœé€šå¸¸ä¼˜äºä¸€ä¸ªå¤§å·ç§¯æ ¸ã€‚é€šè¿‡å †å å¤šä¸ªå°å·ç§¯æ ¸ï¼Œå¯ä»¥åœ¨è·å¾—ç›¸åŒæ„Ÿå—é‡çš„æƒ…å†µä¸‹ï¼Œå‡å°‘æ¨¡å‹çš„å‚æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦ã€‚ä¾‹å¦‚ï¼Œä¸¤ä¸ª 3x3 çš„å·ç§¯æ ¸å †å å¯ä»¥è·å¾—ä¸ä¸€ä¸ª 5x5 å·ç§¯æ ¸ç›¸åŒçš„æ„Ÿå—é‡ï¼Œä½†å‚æ•°é‡æ›´å°‘ã€‚



