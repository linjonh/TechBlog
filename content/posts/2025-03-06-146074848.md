---
layout: post
title: "深度学习笔记16-运动鞋品牌识别Pytorch"
date: 2025-03-06 18:37:44 +0800
description: "目录一、前期工作1.导入数据并读取2.创建数据加载器 二、构建简单的CNN网络三、训练模型1.编写训练函数2.编写测试函数3.设置动态学习率4.正式训练四、结果可视化五、尝试数据增强操作六、总结1.torchvision.transforms.Compose()类2.[N, C, H, W]3.感受野与卷积核大小的权衡 2.编写测试函数3.设置动态学习率4.正式训练根据loss和accuracy图，训练准确率明显高于测试准确"
keywords: "深度学习笔记16-运动鞋品牌识别(Pytorch)"
categories: ['深度学习']
tags: ['笔记', '深度学习', 'Pytorch']
artid: "146074848"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146074848
    alt: "深度学习笔记16-运动鞋品牌识别Pytorch"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146074848
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146074848
cover: https://bing.ee123.net/img/rand?artid=146074848
image: https://bing.ee123.net/img/rand?artid=146074848
img: https://bing.ee123.net/img/rand?artid=146074848
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     深度学习笔记16-运动鞋品牌识别(Pytorch)
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <ul>
     <li id="u5a0cf7ef">
      <strong>
       🍨 本文为
      </strong>
      <a href="https://mp.weixin.qq.com/s/kV8ZsJv6cPNzJLEuhPfvXg" rel="nofollow" title="🔗365天深度学习训练营">
       🔗365天深度学习训练营
      </a>
      <strong>
       中的学习记录博客
      </strong>
     </li>
     <li id="uabaf6a39">
      <strong>
       🍖
      </strong>
      <strong>
       原作者：
      </strong>
      <a href="https://mtyjkh.blog.csdn.net/" rel="nofollow" title="K同学啊">
       K同学啊
      </a>
     </li>
    </ul>
    <hr id="hr-toc" name="tableOfContents"/>
    <p>
    </p>
    <h2 id="%E4%B8%80%E3%80%81%E5%89%8D%E6%9C%9F%E5%B7%A5%E4%BD%9C" name="%E4%B8%80%E3%80%81%E5%89%8D%E6%9C%9F%E5%B7%A5%E4%BD%9C">
     一、前期工作
    </h2>
    <h3 id="1.%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%B9%B6%E6%9F%A5%E7%9C%8B" name="1.%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%B9%B6%E6%9F%A5%E7%9C%8B">
     1.导入数据并读取
    </h3>
    <pre><code class="language-python">import torch.nn as nn
import torch
from torchvision import datasets
import os,PIL,pathlib
import torchvision
import torchvision.transforms as transforms</code></pre>
    <pre><code class="language-python">data_dir='D:/TensorFlow1/T5'
data_dir=pathlib.Path(data_dir)
data_path=list(data_dir.glob('*'))
classnames=[path.name for path in data_path if path.is_dir()]
classnames
</code></pre>
    <p class="img-center">
     <img alt="" height="81" src="https://i-blog.csdnimg.cn/direct/e5daa8edd4784c27a24d4826707704ce.png" width="378"/>
    </p>
    <pre><code class="language-python"># 关于transforms.Compose的更多介绍可以参考：https://blog.csdn.net/qq_38251616/article/details/124878863
train_transforms = transforms.Compose([
    transforms.Resize([224, 224]),  # 将输入图片resize成统一尺寸
    # transforms.RandomHorizontalFlip(), # 随机水平翻转
    transforms.ToTensor(),          # 将PIL Image或numpy.ndarray转换为tensor，并归一化到[0,1]之间
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
        std=[0.229, 0.224, 0.225])])

test_transform = transforms.Compose([
    transforms.Resize([224, 224]),  # 将输入图片resize成统一尺寸
    transforms.ToTensor(),          # 将PIL Image或numpy.ndarray转换为tensor，并归一化到[0,1]之间
    transforms.Normalize(mean=[0.485, 0.456, 0.406], #ImageNet的均值和标准差
        std=[0.229, 0.224, 0.225])])

train_dataset = datasets.ImageFolder("D:/TensorFlow1/T5/train/",transform=train_transforms)
test_dataset  = datasets.ImageFolder("D:/TensorFlow1/T5/test/",transform=test_transform)</code></pre>
    <pre><code class="language-python">train_dataset.class_to_idx  #用于映射数据集中每个类别的名称到一个唯一的整数索引。</code></pre>
    <p class="img-center">
     <img alt="" height="43" src="https://i-blog.csdnimg.cn/direct/eb77b95dc5534af98e92d69070c951d8.png" width="332"/>
    </p>
    <h3 id="2.%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%99%A8%C2%A0" name="2.%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%99%A8%C2%A0">
     2.创建数据加载器
    </h3>
    <pre><code class="language-python">batch_size=32
train_dl=torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,
                                     shuffle=True,num_workers=1)
test_dl=torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,
                                     shuffle=True,num_workers=1)</code></pre>
    <pre><code class="language-python">for X, y in test_dl:
    print("Shape of X [N, C, H, W]: ", X.shape)
    print("Shape of y: ", y.shape, y.dtype)
    break</code></pre>
    <p>
     <img alt="" height="74" src="https://i-blog.csdnimg.cn/direct/6634932cd00945ad8c1e3c0bef15416f.png" width="746"/>
    </p>
    <h2 id="%E4%BA%8C%E3%80%81%E6%9E%84%E5%BB%BA%E7%AE%80%E5%8D%95%E7%9A%84CNN%E7%BD%91%E7%BB%9C" name="%E4%BA%8C%E3%80%81%E6%9E%84%E5%BB%BA%E7%AE%80%E5%8D%95%E7%9A%84CNN%E7%BD%91%E7%BB%9C">
     二、构建简单的CNN网络
    </h2>
    <p>
     <img alt="" height="773" src="https://i-blog.csdnimg.cn/direct/2bbb29dcb92744aaa1e7a4a786612154.png" width="1923"/>
    </p>
    <pre><code class="language-python">import torch.nn.functional as F    #导入torch.nn.functional模块，通常用于调用一些函数式的操作

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1=nn.Sequential(
            nn.Conv2d(3, 12, kernel_size=5, padding=0), # 12*220*220  输入通道数 3，输出通道数 12，卷积核大小 5x5，无填充
            nn.BatchNorm2d(12),
            nn.ReLU())
        
        self.conv2=nn.Sequential(
            nn.Conv2d(12, 12, kernel_size=5, padding=0), # 12*216*216
            nn.BatchNorm2d(12),
            nn.ReLU())
        
        self.pool3=nn.Sequential(
            nn.MaxPool2d(2))                              # 12*108*108
        
        self.conv4=nn.Sequential(
            nn.Conv2d(12, 24, kernel_size=5, padding=0), # 24*104*104
            nn.BatchNorm2d(24),
            nn.ReLU())
        
        self.conv5=nn.Sequential(
            nn.Conv2d(24, 24, kernel_size=5, padding=0), # 24*100*100
            nn.BatchNorm2d(24),
            nn.ReLU())
        
        self.pool6=nn.Sequential( nn.MaxPool2d(2))                              # 24*50*50

        self.dropout = nn.Sequential(nn.Dropout(0.25))
        
        self.fc=nn.Sequential(nn.Linear(24*50*50, len(classenames)))
        
    def forward(self, x):
        
        batch_size = x.size(0)
        x = self.conv1(x)  # 卷积-BN-激活
        x = self.conv2(x)  # 卷积-BN-激活
        x = self.pool3(x)  # 池化
        x = self.conv4(x)  # 卷积-BN-激活
        x = self.conv5(x)  # 卷积-BN-激活
        x = self.pool6(x)  # 池化
        x = self.dropout(x)
        x = x.view(batch_size, -1)  # # 将卷积层的输出展平成一维向量 (batch, 24*50*50) ==&gt; (batch, -1), -1 此处自动算出的是24*50*50
        x = self.fc(x)
       
        return x
model = Model()
model</code></pre>
    <p>
     <img alt="" height="1037" src="https://i-blog.csdnimg.cn/direct/d989a2bcab6d407a9743744818da2742.png" width="1173"/>
    </p>
    <h2 id="%E4%B8%89%E3%80%81%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B" name="%E4%B8%89%E3%80%81%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">
     三、训练模型
    </h2>
    <h3 id="1.%E7%BC%96%E5%86%99%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0" name="1.%E7%BC%96%E5%86%99%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0">
     1.编写训练函数
    </h3>
    <pre><code class="language-python"># 训练循环
def train(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset)  # 训练集的大小
    num_batches = len(dataloader)   # 批次数目, (size/batch_size，向上取整)

    train_loss, train_acc = 0, 0  # 初始化训练损失和正确率
    
    for X, y in dataloader:  # 获取图片及其标签        
        # 计算预测误差
        pred = model(X)          # 网络输出
        loss = loss_fn(pred, y)  # 计算网络输出和真实值之间的差距，targets为真实值，计算二者差值即为损失
        
        # 反向传播
        optimizer.zero_grad()  # grad属性归零
        loss.backward()        # 反向传播
        optimizer.step()       # 每一步自动更新
        
        # 记录acc与loss
        train_acc  += (pred.argmax(1) == y).type(torch.float).sum().item()
        train_loss += loss.item()
            
    train_acc  /= size
    train_loss /= num_batches

    return train_acc, train_loss</code></pre>
    <h3 id="2.%E7%BC%96%E5%86%99%E6%B5%8B%E8%AF%95%E5%87%BD%E6%95%B0" name="2.%E7%BC%96%E5%86%99%E6%B5%8B%E8%AF%95%E5%87%BD%E6%95%B0">
     2.编写测试函数
    </h3>
    <pre><code class="language-python">def test (dataloader, model, loss_fn):
    size        = len(dataloader.dataset)  # 测试集的大小
    num_batches = len(dataloader)          # 批次数目, (size/batch_size，向上取整)
    test_loss, test_acc = 0, 0
    
    # 当不进行训练时，停止梯度更新，节省计算内存消耗
    with torch.no_grad():
        for imgs, target in dataloader:        
            # 计算loss
            target_pred = model(imgs)
            loss        = loss_fn(target_pred, target)
            
            test_loss += loss.item()
            test_acc  += (target_pred.argmax(1) == target).type(torch.float).sum().item()

    test_acc  /= size
    test_loss /= num_batches

    return test_acc, test_loss</code></pre>
    <h3 id="3.%E8%AE%BE%E7%BD%AE%E5%8A%A8%E6%80%81%E5%AD%A6%E4%B9%A0%E7%8E%87" name="3.%E8%AE%BE%E7%BD%AE%E5%8A%A8%E6%80%81%E5%AD%A6%E4%B9%A0%E7%8E%87">
     3.设置动态学习率
    </h3>
    <pre><code class="language-python">def adjust_learning_rate(optimizer, epoch, start_lr):
    # 每 2 个epoch衰减到原来的 0.92
    lr = start_lr * (0.92 ** (epoch // 2))
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr

learn_rate = 1e-4 # 初始学习率
optimizer  = torch.optim.SGD(model.parameters(), lr=learn_rate)</code></pre>
    <h3 id="4.%E6%AD%A3%E5%BC%8F%E8%AE%AD%E7%BB%83" name="4.%E6%AD%A3%E5%BC%8F%E8%AE%AD%E7%BB%83">
     4.正式训练
    </h3>
    <pre><code class="language-python">loss_fn    = nn.CrossEntropyLoss() # 创建损失函数
epochs     = 40

train_loss = []
train_acc  = []
test_loss  = []
test_acc   = []

for epoch in range(epochs):
    # 更新学习率（使用自定义学习率时使用）
    adjust_learning_rate(optimizer, epoch, learn_rate)
    
    model.train()
    epoch_train_acc, epoch_train_loss = train(train_dl, model, loss_fn, optimizer)
    # scheduler.step() # 更新学习率（调用官方动态学习率接口时使用）
    
    model.eval()
    epoch_test_acc, epoch_test_loss = test(test_dl, model, loss_fn)
    
    train_acc.append(epoch_train_acc)
    train_loss.append(epoch_train_loss)
    test_acc.append(epoch_test_acc)
    test_loss.append(epoch_test_loss)
    
    # 获取当前的学习率
    lr = optimizer.state_dict()['param_groups'][0]['lr']
    
    template = ('Epoch:{:2d}, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%, Test_loss:{:.3f}, Lr:{:.2E}')
    print(template.format(epoch+1, epoch_train_acc*100, epoch_train_loss, 
                          epoch_test_acc*100, epoch_test_loss, lr))
print('Done')</code></pre>
    <p>
     <img alt="" height="811" src="https://i-blog.csdnimg.cn/direct/6e808db5d9c7478cb952856e72a814a3.png" width="784"/>
    </p>
    <h2 id="%E5%9B%9B%E3%80%81%E7%BB%93%E6%9E%9C%E5%8F%AF%E8%A7%86%E5%8C%96" name="%E5%9B%9B%E3%80%81%E7%BB%93%E6%9E%9C%E5%8F%AF%E8%A7%86%E5%8C%96">
     四、结果可视化
    </h2>
    <pre><code class="language-python">import matplotlib.pyplot as plt
#隐藏警告
import warnings
warnings.filterwarnings("ignore")               #忽略警告信息
plt.rcParams['font.sans-serif']    = ['SimHei'] # 用来正常显示中文标签
plt.rcParams['axes.unicode_minus'] = False      # 用来正常显示负号
plt.rcParams['figure.dpi']         = 100        #分辨率

from datetime import datetime
current_time = datetime.now() # 获取当前时间

epochs_range = range(epochs)

plt.figure(figsize=(12, 3))
plt.subplot(1, 2, 1)

plt.plot(epochs_range, train_acc, label='Training Accuracy')
plt.plot(epochs_range, test_acc, label='Test Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')
plt.xlabel(current_time) # 打卡请带上时间戳，否则代码截图无效

plt.subplot(1, 2, 2)
plt.plot(epochs_range, train_loss, label='Training Loss')
plt.plot(epochs_range, test_loss, label='Test Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()</code></pre>
    <p>
     <img alt="" height="515" src="https://i-blog.csdnimg.cn/direct/9cc74c4a764c401a8c0c58959335ab1b.png" width="1646"/>
    </p>
    <h2 id="%E4%BA%94%E3%80%81%E5%B0%9D%E8%AF%95%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%93%8D%E4%BD%9C" name="%E4%BA%94%E3%80%81%E5%B0%9D%E8%AF%95%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%93%8D%E4%BD%9C">
     五、尝试数据增强操作
    </h2>
    <p>
     根据loss和accuracy图，训练准确率明显高于测试准确率，可能表明模型在训练集上过拟合。因此，我将尝试对训练集样本进行翻转、旋转等增强操作。
    </p>
    <pre><code class="language-python">train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])
</code></pre>
    <p>
     最后得到
     <img alt="" height="557" src="https://i-blog.csdnimg.cn/direct/125f127cfbe94bb1abe941ecf50d5338.png" width="1781"/>
    </p>
    <p>
     尽管过拟合程度没有增强前高，但总体准确率和损失都不如第一组图，也许是模型的学习能力较弱，或者训练数据不足，导致模型未能充分学习到数据的特征。
    </p>
    <h2 id="%E5%85%AD%E3%80%81%E6%80%BB%E7%BB%93" name="%E5%85%AD%E3%80%81%E6%80%BB%E7%BB%93" style="background-color:transparent">
     六、总结
    </h2>
    <h3 id="1.torchvision.transforms.Compose()%E7%B1%BB" name="1.torchvision.transforms.Compose()%E7%B1%BB">
     1.
     <code>
      <span style="background-color:#fbd4d0">
       torchvision.transforms.Compose()
      </span>
     </code>
     类
    </h3>
    <p>
     用于将多个图像变换操作组合成一个序列。在深度学习中，对图像数据进行预处理是一个常见的操作，例如调整图像大小、归一化、裁剪等，
     <code>
      Compose()
     </code>
     可以将这些操作按顺序依次应用到输入的图像上。
    </p>
    <p>
     <img alt="" height="609" src="https://i-blog.csdnimg.cn/direct/28576e1ab1fb40edbb80f8c72e0ac50d.png" width="1635"/>
    </p>
    <p>
     注意，这里的mean和std取的是imagenet的。若数据集是自然场景图像（如人、动物、建筑等），或使用了预训练模型（如基于 ImageNet 数据集训练的模型）建议使用Imagenet的mean和std。
     <br/>
     如果你的数据集与 ImageNet 不同（例如医学图像、卫星图像或经过特殊处理的图像），建议计算你自己的数据集的均值和标准差。但对于CIFAR-10、COCO等数据集有自己的mean和std
    </p>
    <h3 id="2.%5BN%2C%20C%2C%20H%2C%20W%5D" name="2.%5BN%2C%20C%2C%20H%2C%20W%5D">
     2.[N, C, H, W]
    </h3>
    <p>
     在图像数据中，通常遵循 [N, C, H, W] 的格式，其中：
    </p>
    <ul>
     <li>
      N 表示批次大小（即一个批次中包含的图像数量）。
     </li>
     <li>
      C 表示图像的通道数，对于彩色图像通常为 3（RGB 三个通道）。
     </li>
     <li>
      H 表示图像的高度。
     </li>
     <li>
      W 表示图像的宽度。
     </li>
    </ul>
    <h3 id="3.%E6%84%9F%E5%8F%97%E9%87%8E%E4%B8%8E%E5%8D%B7%E7%A7%AF%E6%A0%B8%E5%A4%A7%E5%B0%8F%E7%9A%84%E6%9D%83%E8%A1%A1%C2%A0" name="3.%E6%84%9F%E5%8F%97%E9%87%8E%E4%B8%8E%E5%8D%B7%E7%A7%AF%E6%A0%B8%E5%A4%A7%E5%B0%8F%E7%9A%84%E6%9D%83%E8%A1%A1%C2%A0">
     3.感受野与卷积核大小的权衡
    </h3>
    <ul>
     <li>
      <strong>
       卷积核
      </strong>
      ：卷积核是卷积神经网络中用于对输入数据进行卷积操作的小型矩阵。在图像卷积操作中，卷积核在输入图像上滑动，逐元素相乘并求和，从而提取输入图像的特征。卷积核的大小（如 3x3 等）和数量（即输出通道数）是卷积层的重要参数。
     </li>
     <li>
      <strong>
       感受野
      </strong>
      ：感受野是指卷积神经网络中某一层输出特征图上的一个像素点对应输入图像上的区域大小。简单来说，感受野描述了卷积神经网络中某个神经元能够 “看到” 的输入图像的区域范围。
     </li>
    </ul>
    <p>
     <strong>
      感受野和卷积核大小有什么关系？
     </strong>
    </p>
    <ul>
     <li>
      <strong>
       增大卷积核大小
      </strong>
      ：使用更大的卷积核可以在单个卷积层中获得更大的感受野，从而使模型能够捕捉到更广泛的上下文信息。然而，增大卷积核大小会增加模型的参数量和计算复杂度，并且可能会忽略一些局部细节信息。
     </li>
     <li>
      <strong>
       堆叠小卷积核
      </strong>
      ：多个小卷积核堆叠的效果通常优于一个大卷积核。通过堆叠多个小卷积核，可以在获得相同感受野的情况下，减少模型的参数量和计算复杂度。例如，两个 3x3 的卷积核堆叠可以获得与一个 5x5 卷积核相同的感受野，但参数量更少。
     </li>
    </ul>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f36373836393333332f:61727469636c652f64657461696c732f313436303734383438" class_="artid" style="display:none">
 </p>
</div>


