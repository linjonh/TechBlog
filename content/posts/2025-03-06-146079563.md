---
layout: post
title: "AIGC系列6HunyuanVideo视频生成模型部署和代码分析"
date: 2025-03-06 22:35:22 +0800
description: "本文详细介绍HunyuanVideo的部署、应用以及源码分析。不得不说，生成的视频很真实生动！"
keywords: "hunyuanvideo采样器错误"
categories: ['大模型', 'Aigc']
tags: ['音视频', '语言模型', '深度学习', '人工智能', 'Transformer', 'Aigc']
artid: "146079563"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146079563
    alt: "AIGC系列6HunyuanVideo视频生成模型部署和代码分析"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146079563
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146079563
cover: https://bing.ee123.net/img/rand?artid=146079563
image: https://bing.ee123.net/img/rand?artid=146079563
img: https://bing.ee123.net/img/rand?artid=146079563
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     【AIGC系列】6：HunyuanVideo视频生成模型部署和代码分析
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <blockquote>
     <p>
      AIGC系列博文：
      <br/>
      <a href="https://blog.csdn.net/sinat_16020825/article/details/145840972">
       【AIGC系列】1：自编码器（AutoEncoder, AE）
      </a>
      <br/>
      <a href="https://blog.csdn.net/sinat_16020825/article/details/145841351">
       【AIGC系列】2：DALL·E 2模型介绍（内含扩散模型介绍）
      </a>
      <br/>
      <a href="https://blog.csdn.net/sinat_16020825/article/details/145875813">
       【AIGC系列】3：Stable Diffusion模型原理介绍
      </a>
      <br/>
      <a href="https://blog.csdn.net/sinat_16020825/article/details/145888995">
       【AIGC系列】4：Stable Diffusion应用实践和代码分析
      </a>
      <br/>
      <a href="https://blog.csdn.net/sinat_16020825/article/details/145927508">
       【AIGC系列】5：视频生成模型数据处理和预训练流程介绍（Sora、MovieGen、HunyuanVideo）
      </a>
      <br/>
      <a href="https://blog.csdn.net/sinat_16020825/article/details/146079563">
       【AIGC系列】6：HunyuanVideo视频生成模型部署和代码分析
      </a>
     </p>
    </blockquote>
    <p>
    </p>
    <p>
    </p>
    <h2>
     <a id="1__17">
     </a>
     1 前言
    </h2>
    <p>
     先展示一下结果。
    </p>
    <p>
     生成540p视频，推理占用的显存超过40G：（720p x 1280p 分辨率大约需要76G显存，544p x 960p分辨率大约需要43G显存）
    </p>
    <p>
     <img alt="显存占用情况" src="https://i-blog.csdnimg.cn/direct/73cac4eb3a9e45b689a6c1e42fa1b791.png"/>
    </p>
    <p>
     迭代50步，需要超过一个半小时，还是挺久的。
    </p>
    <p>
     <img alt="运行界面" src="https://i-blog.csdnimg.cn/direct/15892a1a7cc84ba8adec9e4b1dfa619e.png"/>
    </p>
    <p>
     <img alt="耗时" src="https://i-blog.csdnimg.cn/direct/d6c82996d74b425fa07800542ef4f3be.png"/>
    </p>
    <p>
     Prompt：A cat walks on the grass, realistic style.
    </p>
    <p>
     生成的视频结果如下，效果还是很逼真的，包括光影、猫毛的细节、景深等等。
    </p>
    <p>
     视频链接：
     <a href="https://b23.tv/Boazciy" rel="nofollow">
      哔哩哔哩：https://b23.tv/Boazciy
     </a>
    </p>
    <p>
     <img alt="1" src="https://i-blog.csdnimg.cn/direct/28d127c220684dc391487bcfc1e8fe89.png">
      <br/>
      <img alt="2" src="https://i-blog.csdnimg.cn/direct/d40a660522c94ae2bf77d9ab1a50fe70.png"/>
     </img>
    </p>
    <p>
     当然，用8卡推理可以更快一点，生成5s的视频耗时约20分钟，整体效果也还可以。
    </p>
    <p>
     <a href="https://b23.tv/vBiXMKT" rel="nofollow">
      哔哩哔哩：https://b23.tv/vBiXMKT
     </a>
    </p>
    <p>
     <img alt="8卡" src="https://i-blog.csdnimg.cn/direct/80976ffb25424549bccad253ed499eae.png"/>
    </p>
    <h2>
     <a id="2__50">
     </a>
     2 部署
    </h2>
    <h3>
     <a id="21__52">
     </a>
     2.1 环境配置
    </h3>
    <h4>
     <a id="211_OpenR1_53">
     </a>
     2.1.1 方法一：使用Open-R1的环境
    </h4>
    <p>
     HuyuanVideo也使用到flash attention了，为了方便起见，我们使用Open-R1的环境来跑HunyuanVideo。
    </p>
    <p>
     Open-R1的环境配置详细步骤请参考博文：
     <a href="https://blog.csdn.net/sinat_16020825/article/details/145656678?spm=1001.2014.3001.5502">
      【复现DeepSeek-R1之Open R1实战】系列1：跑通SFT（一步步操作，手把手教学）
     </a>
     。
    </p>
    <p>
     将源码clone下来之后，接下来我们安装HunyuanVideo的依赖库：
    </p>
    <pre><code class="prism language-bash">python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token parameter variable">-r</span> requirements.txt
</code></pre>
    <h4>
     <a id="212_Docker_65">
     </a>
     2.1.2 方法二：使用官方Docker
    </h4>
    <p>
     当然，我们也可以直接使用官方提供的docker：
    </p>
    <pre><code class="prism language-bash"><span class="token comment"># 1. Use the following link to download the docker image tar file (For CUDA 12).</span>
<span class="token function">wget</span> https://aivideo.hunyuan.tencent.com/download/HunyuanVideo/hunyuan_video_cu12.tar
 
<span class="token comment"># 2. Import the docker tar file and show the image meta information (For CUDA 12).</span>
<span class="token function">docker</span> load <span class="token parameter variable">-i</span> hunyuan_video_cu12.tar
 
<span class="token function">docker</span> image <span class="token function">ls</span>
 
<span class="token comment"># 3. Run the container based on the image</span>
<span class="token function">docker</span> run <span class="token parameter variable">-itd</span> <span class="token parameter variable">--gpus</span> all <span class="token parameter variable">--init</span> <span class="token parameter variable">--net</span><span class="token operator">=</span>host <span class="token parameter variable">--uts</span><span class="token operator">=</span>host <span class="token parameter variable">--ipc</span><span class="token operator">=</span>host <span class="token parameter variable">--name</span> hunyuanvideo --security-opt<span class="token operator">=</span>seccomp<span class="token operator">=</span>unconfined <span class="token parameter variable">--ulimit</span><span class="token operator">=</span>stack<span class="token operator">=</span><span class="token number">67108864</span> <span class="token parameter variable">--ulimit</span><span class="token operator">=</span>memlock<span class="token operator">=</span>-1 <span class="token parameter variable">--privileged</span>  docker_image_tag
</code></pre>
    <p>
     推荐使用方法一，方法二我尝试了一下，报了个torch的错误，后来我没接着往下解决，GitHub上也有小伙伴反馈cuda12的docker跑起来会有些问题，感兴趣的小伙伴也可使用cuda11.8的docker。
    </p>
    <pre><code class="prism language-bash"><span class="token comment"># For CUDA 12.4 (updated to avoid float point exception)</span>
<span class="token function">docker</span> pull hunyuanvideo/hunyuanvideo:cuda_12
<span class="token function">docker</span> run <span class="token parameter variable">-itd</span> <span class="token parameter variable">--gpus</span> all <span class="token parameter variable">--init</span> <span class="token parameter variable">--net</span><span class="token operator">=</span>host <span class="token parameter variable">--uts</span><span class="token operator">=</span>host <span class="token parameter variable">--ipc</span><span class="token operator">=</span>host <span class="token parameter variable">--name</span> hunyuanvideo --security-opt<span class="token operator">=</span>seccomp<span class="token operator">=</span>unconfined <span class="token parameter variable">--ulimit</span><span class="token operator">=</span>stack<span class="token operator">=</span><span class="token number">67108864</span> <span class="token parameter variable">--ulimit</span><span class="token operator">=</span>memlock<span class="token operator">=</span>-1 <span class="token parameter variable">--privileged</span> hunyuanvideo/hunyuanvideo:cuda_12

<span class="token comment"># For CUDA 11.8</span>
<span class="token function">docker</span> pull hunyuanvideo/hunyuanvideo:cuda_11
<span class="token function">docker</span> run <span class="token parameter variable">-itd</span> <span class="token parameter variable">--gpus</span> all <span class="token parameter variable">--init</span> <span class="token parameter variable">--net</span><span class="token operator">=</span>host <span class="token parameter variable">--uts</span><span class="token operator">=</span>host <span class="token parameter variable">--ipc</span><span class="token operator">=</span>host <span class="token parameter variable">--name</span> hunyuanvideo --security-opt<span class="token operator">=</span>seccomp<span class="token operator">=</span>unconfined <span class="token parameter variable">--ulimit</span><span class="token operator">=</span>stack<span class="token operator">=</span><span class="token number">67108864</span> <span class="token parameter variable">--ulimit</span><span class="token operator">=</span>memlock<span class="token operator">=</span>-1 <span class="token parameter variable">--privileged</span> hunyuanvideo/hunyuanvideo:cuda_11
</code></pre>
    <h3>
     <a id="22__95">
     </a>
     2.2 下载预训练模型
    </h3>
    <p>
     我们需要下载的模型包括：混元Diffusion模型、VAE模型、text-encoder-tokenizer模型以及CLIP模型。
    </p>
    <h4>
     <a id="221_DiffusionVAE_98">
     </a>
     2.2.1 混元Diffusion模型和VAE模型
    </h4>
    <p>
     HuggingFace：
     <a href="https://huggingface.co/tencent/HunyuanVideo/tree/main" rel="nofollow">
      https://huggingface.co/tencent/HunyuanVideo/tree/main
     </a>
     。
    </p>
    <p>
     <img alt="models" src="https://i-blog.csdnimg.cn/direct/76b99cc6ad554b1e87a1732ece874b2e.png"/>
    </p>
    <p>
     建议
     <strong>
      下载FP8量化模型
     </strong>
     ，推理时总共占用显存40多G。
    </p>
    <p>
     <img alt="fp8" src="https://i-blog.csdnimg.cn/direct/2bdcb2cd3a634909b04ae442b74b2e16.png"/>
    </p>
    <p>
     Diffusion模型放入ckpts/hunyuan-video-t2v-720p/transformers目录，VAE模型放入ckpts/hunyuan-video-t2v-720p/vae目录。
    </p>
    <h4>
     <a id="222_textencodertokenizer_113">
     </a>
     2.2.2 text-encoder-tokenizer
    </h4>
    <p>
     我们可以直接下载text-encoder-tokenizer模型：
     <a href="https://huggingface.co/Kijai/llava-llama-3-8b-text-encoder-tokenizer" rel="nofollow">
      https://huggingface.co/Kijai/llava-llama-3-8b-text-encoder-tokenizer
     </a>
     ，保存在ckpts/text_encoder文件夹中。
    </p>
    <blockquote>
     <p>
      官方的操作是先下载完整版LLaVA 模型，然后再把文本编码器（language_model）和分词器（tokenizer）提取出来，多了一步提取的操作。
     </p>
    </blockquote>
    <h4>
     <a id="223_CLIP_120">
     </a>
     2.2.3 CLIP模型
    </h4>
    <p>
     下载CLIP-ViT-L模型：
     <a href="https://huggingface.co/openai/clip-vit-large-patch14" rel="nofollow">
      https://huggingface.co/openai/clip-vit-large-patch14
     </a>
     ，将模型存放到ckpts/text_encoder_2文件夹中。
    </p>
    <p>
     最终保存的预训练模型路径如下所示：
    </p>
    <p>
     HunyuanVideo
     <br/>
     ├──ckpts
     <br/>
     │ ├──README.md
     <br/>
     │ ├──hunyuan-video-t2v-720p
     <br/>
     │ │ ├──transformers
     <br/>
     │ │ │ ├──mp_rank_00_model_states.pt
     <br/>
     │ │ │ ├──mp_rank_00_model_states_fp8.pt
     <br/>
     │ │ │ ├──mp_rank_00_model_states_fp8_map.pt
     <br/>
     ├ │ ├──vae
     <br/>
     │ ├──text_encoder
     <br/>
     │ ├──text_encoder_2
     <br/>
     ├──…
    </p>
    <p>
     <img alt="ckpt" src="https://i-blog.csdnimg.cn/direct/d630a85536884d56a463c6ee11fb91a0.png"/>
    </p>
    <h3>
     <a id="23__142">
     </a>
     2.3 视频生成命令
    </h3>
    <p>
     使用FP8模型推理：
    </p>
    <pre><code class="prism language-bash"><span class="token builtin class-name">cd</span> HunyuanVideo

python3 sample_video.py <span class="token punctuation">\</span>
    --dit-weight ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt <span class="token punctuation">\</span>
    --video-size <span class="token number">1280</span> <span class="token number">720</span> <span class="token punctuation">\</span>
    --video-length <span class="token number">129</span> <span class="token punctuation">\</span>
    --infer-steps <span class="token number">50</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--prompt</span> <span class="token string">"A cat walks on the grass, realistic style."</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--seed</span> <span class="token number">42</span> <span class="token punctuation">\</span>
    --embedded-cfg-scale <span class="token number">6.0</span> <span class="token punctuation">\</span>
    --flow-shift <span class="token number">7.0</span> <span class="token punctuation">\</span>
    --flow-reverse <span class="token punctuation">\</span>
    --use-cpu-offload <span class="token punctuation">\</span>
    --use-fp8 <span class="token punctuation">\</span>
    --save-path ./results
</code></pre>
    <p>
     –dit-weight指定FP8模型的路径；–use-fp8是指模型的格式是FP8。
    </p>
    <p>
     参数说明：
    </p>
    <table>
     <thead>
      <tr>
       <th align="center">
        Argument
       </th>
       <th align="center">
        Default
       </th>
       <th align="center">
        Description
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td align="center">
        <code>
         --prompt
        </code>
       </td>
       <td align="center">
        None
       </td>
       <td align="center">
        The text prompt for video generation
       </td>
      </tr>
      <tr>
       <td align="center">
        <code>
         --video-size
        </code>
       </td>
       <td align="center">
        720 1280
       </td>
       <td align="center">
        The size of the generated video
       </td>
      </tr>
      <tr>
       <td align="center">
        <code>
         --video-length
        </code>
       </td>
       <td align="center">
        129
       </td>
       <td align="center">
        The length of the generated video
       </td>
      </tr>
      <tr>
       <td align="center">
        <code>
         --infer-steps
        </code>
       </td>
       <td align="center">
        50
       </td>
       <td align="center">
        The number of steps for sampling
       </td>
      </tr>
      <tr>
       <td align="center">
        <code>
         --embedded-cfg-scale
        </code>
       </td>
       <td align="center">
        6.0
       </td>
       <td align="center">
        Embedded Classifier free guidance scale
       </td>
      </tr>
      <tr>
       <td align="center">
        <code>
         --flow-shift
        </code>
       </td>
       <td align="center">
        7.0
       </td>
       <td align="center">
        Shift factor for flow matching schedulers
       </td>
      </tr>
      <tr>
       <td align="center">
        <code>
         --flow-reverse
        </code>
       </td>
       <td align="center">
        False
       </td>
       <td align="center">
        If reverse, learning/sampling from t=1 -&gt; t=0
       </td>
      </tr>
      <tr>
       <td align="center">
        <code>
         --seed
        </code>
       </td>
       <td align="center">
        None
       </td>
       <td align="center">
        The random seed for generating video, if None, we init a random seed
       </td>
      </tr>
      <tr>
       <td align="center">
        <code>
         --use-cpu-offload
        </code>
       </td>
       <td align="center">
        False
       </td>
       <td align="center">
        Use CPU offload for the model load to save more memory, necessary for high-res video generation
       </td>
      </tr>
      <tr>
       <td align="center">
        <code>
         --save-path
        </code>
       </td>
       <td align="center">
        ./results
       </td>
       <td align="center">
        Path to save the generated video
       </td>
      </tr>
     </tbody>
    </table>
    <p>
     当然，我们也可以用多卡推理：
    </p>
    <pre><code class="prism language-bash"><span class="token builtin class-name">cd</span> HunyuanVideo

torchrun <span class="token parameter variable">--nproc_per_node</span><span class="token operator">=</span><span class="token number">8</span> sample_video.py <span class="token punctuation">\</span>
    --video-size <span class="token number">1280</span> <span class="token number">720</span> <span class="token punctuation">\</span>
    --video-length <span class="token number">129</span> <span class="token punctuation">\</span>
    --infer-steps <span class="token number">50</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--prompt</span> <span class="token string">"A cat walks on the grass, realistic style."</span> <span class="token punctuation">\</span>
    --flow-reverse <span class="token punctuation">\</span>
    <span class="token parameter variable">--seed</span> <span class="token number">42</span> <span class="token punctuation">\</span>
    --ulysses-degree <span class="token number">8</span> <span class="token punctuation">\</span>
    --ring-degree <span class="token number">1</span> <span class="token punctuation">\</span>
    --save-path ./results
</code></pre>
    <h2>
     <a id="3__200">
     </a>
     3 源码分析
    </h2>
    <h3>
     <a id="31__203">
     </a>
     3.1 推理流程
    </h3>
    <p>
     上面我们展示的demo的主文件是sample_video.py，定义了一个main函数，用于加载模型并生成视频样本，包含整体推理流程。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 调用 parse_args() 函数来解析命令行参数，并将结果存储在 args 中。</span>
    args <span class="token operator">=</span> parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span>
    <span class="token comment">#使用 args.model_base 指定模型的基础路径。检查路径是否存在，如果路径不存在，抛出异常</span>
    models_root_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>args<span class="token punctuation">.</span>model_base<span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> models_root_path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"`models_root` not exists: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>models_root_path<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    
    <span class="token comment"># 创建保存目录</span>
    save_path <span class="token operator">=</span> args<span class="token punctuation">.</span>save_path <span class="token keyword">if</span> args<span class="token punctuation">.</span>save_path_suffix<span class="token operator">==</span><span class="token string">""</span> <span class="token keyword">else</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>args<span class="token punctuation">.</span>save_path<span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>args<span class="token punctuation">.</span>save_path_suffix<span class="token punctuation">}</span></span><span class="token string">'</span></span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>args<span class="token punctuation">.</span>save_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>save_path<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment"># 加载指定路径下的预训练模型，并传入 args 参数</span>
    hunyuan_video_sampler <span class="token operator">=</span> HunyuanVideoSampler<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>models_root_path<span class="token punctuation">,</span> args<span class="token operator">=</span>args<span class="token punctuation">)</span>
    <span class="token comment"># 更新 args 为模型内部参数，确保之后使用的一致性</span>
    args <span class="token operator">=</span> hunyuan_video_sampler<span class="token punctuation">.</span>args

    <span class="token comment">#  生成视频样本</span>
    outputs <span class="token operator">=</span> hunyuan_video_sampler<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>
        prompt<span class="token operator">=</span>args<span class="token punctuation">.</span>prompt<span class="token punctuation">,</span> <span class="token comment"># 文本提示词，用于引导生成内容。</span>
        height<span class="token operator">=</span>args<span class="token punctuation">.</span>video_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token comment"># 视频帧的分辨率（高度和宽度）</span>
        width<span class="token operator">=</span>args<span class="token punctuation">.</span>video_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        video_length<span class="token operator">=</span>args<span class="token punctuation">.</span>video_length<span class="token punctuation">,</span> <span class="token comment"># 视频时长（帧数）。</span>
        seed<span class="token operator">=</span>args<span class="token punctuation">.</span>seed<span class="token punctuation">,</span> <span class="token comment"># 随机种子，用于结果的可重复性</span>
        negative_prompt<span class="token operator">=</span>args<span class="token punctuation">.</span>neg_prompt<span class="token punctuation">,</span> <span class="token comment"># 负向提示词，指定生成时需避免的特性</span>
        infer_steps<span class="token operator">=</span>args<span class="token punctuation">.</span>infer_steps<span class="token punctuation">,</span> <span class="token comment"># 推理步数</span>
        guidance_scale<span class="token operator">=</span>args<span class="token punctuation">.</span>cfg_scale<span class="token punctuation">,</span><span class="token comment"># 引导系数，控制生成质量。</span>
        num_videos_per_prompt<span class="token operator">=</span>args<span class="token punctuation">.</span>num_videos<span class="token punctuation">,</span> <span class="token comment"># 每个提示生成的视频数量。</span>
        flow_shift<span class="token operator">=</span>args<span class="token punctuation">.</span>flow_shift<span class="token punctuation">,</span> <span class="token comment"># 时间帧间的流动控制参数</span>
        batch_size<span class="token operator">=</span>args<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> <span class="token comment"># 批处理大小</span>
        embedded_guidance_scale<span class="token operator">=</span>args<span class="token punctuation">.</span>embedded_cfg_scale <span class="token comment"># 内嵌引导系数，用于调节特定特征</span>
    <span class="token punctuation">)</span>
    samples <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token string">'samples'</span><span class="token punctuation">]</span>

    <span class="token comment"># 保存视频样本</span>
    <span class="token comment"># 检查环境变量 LOCAL_RANK 是否存在，用于分布式训练的本地进程控制：如果不存在，或者值为 0（即主进程），则继续保存样本。</span>
    <span class="token keyword">if</span> <span class="token string">'LOCAL_RANK'</span> <span class="token keyword">not</span> <span class="token keyword">in</span> os<span class="token punctuation">.</span>environ <span class="token keyword">or</span> <span class="token builtin">int</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'LOCAL_RANK'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token comment"># 遍历生成的samples</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> sample <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>samples<span class="token punctuation">)</span><span class="token punctuation">:</span>
            sample <span class="token operator">=</span> samples<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            <span class="token comment"># 添加时间戳</span>
            time_flag <span class="token operator">=</span> datetime<span class="token punctuation">.</span>fromtimestamp<span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">"%Y-%m-%d-%H:%M:%S"</span><span class="token punctuation">)</span>
            save_path <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>save_path<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>time_flag<span class="token punctuation">}</span></span><span class="token string">_seed</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>outputs<span class="token punctuation">[</span><span class="token string">'seeds'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>outputs<span class="token punctuation">[</span><span class="token string">'prompts'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">.mp4"</span></span>
            save_videos_grid<span class="token punctuation">(</span>sample<span class="token punctuation">,</span> save_path<span class="token punctuation">,</span> fps<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">)</span> <span class="token comment"># 保存视频</span>
            logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Sample save to: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>save_path<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span> <span class="token comment"># 日志记录</span>
</code></pre>
    <h3>
     <a id="32__258">
     </a>
     3.2 模型初始化
    </h3>
    <p>
     加载模型的时候，调用了HunYuanVideoSampler的from_pretrained()初始化实例，改方法是在其Inference实现的（hyvideo/inference.py文件），功能包括初始化vae、text_encoder、扩散模型等核心部件，然后通过cls初始化并返回一个实例，而HunYuanVideoSampler类继承了父类的from_pretrained()方法，因此这里cls返回的是HunYuanVideoSampler的实例。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Inference</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">from_pretrained</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> pretrained_model_path<span class="token punctuation">,</span> args<span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 
        in_channels <span class="token operator">=</span> args<span class="token punctuation">.</span>latent_channels      <span class="token comment"># 16</span>
        out_channels <span class="token operator">=</span> args<span class="token punctuation">.</span>latent_channels     <span class="token comment"># 16</span>
 
        model <span class="token operator">=</span> load_model<span class="token punctuation">(</span>     <span class="token comment"># HYVideoDiffusionTransformer</span>
            args<span class="token punctuation">,</span>
            in_channels<span class="token operator">=</span>in_channels<span class="token punctuation">,</span>
            out_channels<span class="token operator">=</span>out_channels<span class="token punctuation">,</span>
            factor_kwargs<span class="token operator">=</span>factor_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
 
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 
        <span class="token comment"># VAE</span>
        vae<span class="token punctuation">,</span> _<span class="token punctuation">,</span> s_ratio<span class="token punctuation">,</span> t_ratio <span class="token operator">=</span> load_vae<span class="token punctuation">(</span>     <span class="token comment"># AutoencoderKLCausal3D</span>
            args<span class="token punctuation">.</span>vae<span class="token punctuation">,</span>
            args<span class="token punctuation">.</span>vae_precision<span class="token punctuation">,</span>
            logger<span class="token operator">=</span>logger<span class="token punctuation">,</span>
            device<span class="token operator">=</span>device <span class="token keyword">if</span> <span class="token keyword">not</span> args<span class="token punctuation">.</span>use_cpu_offload <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
 
        <span class="token comment"># Text encoder</span>
        <span class="token keyword">if</span> args<span class="token punctuation">.</span>prompt_template_video <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            crop_start <span class="token operator">=</span> PROMPT_TEMPLATE<span class="token punctuation">[</span>args<span class="token punctuation">.</span>prompt_template_video<span class="token punctuation">]</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span>   <span class="token comment"># 95</span>
                <span class="token string">"crop_start"</span><span class="token punctuation">,</span> <span class="token number">0</span>
            <span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        max_length <span class="token operator">=</span> args<span class="token punctuation">.</span>text_len <span class="token operator">+</span> crop_start     <span class="token comment"># 256+95</span>
 
        <span class="token comment"># prompt_template</span>
        prompt_template <span class="token operator">=</span> <span class="token punctuation">(</span>
            PROMPT_TEMPLATE<span class="token punctuation">[</span>args<span class="token punctuation">.</span>prompt_template<span class="token punctuation">]</span>
            <span class="token keyword">if</span> args<span class="token punctuation">.</span>prompt_template <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
            <span class="token keyword">else</span> <span class="token boolean">None</span>
        <span class="token punctuation">)</span>
 
        <span class="token comment"># prompt_template_video</span>
        prompt_template_video <span class="token operator">=</span> <span class="token punctuation">(</span>
            PROMPT_TEMPLATE<span class="token punctuation">[</span>args<span class="token punctuation">.</span>prompt_template_video<span class="token punctuation">]</span>
            <span class="token keyword">if</span> args<span class="token punctuation">.</span>prompt_template_video <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
            <span class="token keyword">else</span> <span class="token boolean">None</span>
        <span class="token punctuation">)</span>
 
        text_encoder <span class="token operator">=</span> TextEncoder<span class="token punctuation">(</span>     <span class="token comment"># text-encoder-tokenizer</span>
            text_encoder_type<span class="token operator">=</span>args<span class="token punctuation">.</span>text_encoder<span class="token punctuation">,</span>        <span class="token comment"># llava</span>
            max_length<span class="token operator">=</span>max_length<span class="token punctuation">,</span>
            text_encoder_precision<span class="token operator">=</span>args<span class="token punctuation">.</span>text_encoder_precision<span class="token punctuation">,</span>
            tokenizer_type<span class="token operator">=</span>args<span class="token punctuation">.</span>tokenizer<span class="token punctuation">,</span>
            prompt_template<span class="token operator">=</span>prompt_template<span class="token punctuation">,</span>
            prompt_template_video<span class="token operator">=</span>prompt_template_video<span class="token punctuation">,</span>
            hidden_state_skip_layer<span class="token operator">=</span>args<span class="token punctuation">.</span>hidden_state_skip_layer<span class="token punctuation">,</span>
            apply_final_norm<span class="token operator">=</span>args<span class="token punctuation">.</span>apply_final_norm<span class="token punctuation">,</span>
            reproduce<span class="token operator">=</span>args<span class="token punctuation">.</span>reproduce<span class="token punctuation">,</span>
            logger<span class="token operator">=</span>logger<span class="token punctuation">,</span>
            device<span class="token operator">=</span>device <span class="token keyword">if</span> <span class="token keyword">not</span> args<span class="token punctuation">.</span>use_cpu_offload <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        text_encoder_2 <span class="token operator">=</span> <span class="token boolean">None</span>
        <span class="token keyword">if</span> args<span class="token punctuation">.</span>text_encoder_2 <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            text_encoder_2 <span class="token operator">=</span> TextEncoder<span class="token punctuation">(</span>
                text_encoder_type<span class="token operator">=</span>args<span class="token punctuation">.</span>text_encoder_2<span class="token punctuation">,</span>      <span class="token comment"># clipL</span>
                max_length<span class="token operator">=</span>args<span class="token punctuation">.</span>text_len_2<span class="token punctuation">,</span>
                text_encoder_precision<span class="token operator">=</span>args<span class="token punctuation">.</span>text_encoder_precision_2<span class="token punctuation">,</span>
                tokenizer_type<span class="token operator">=</span>args<span class="token punctuation">.</span>tokenizer_2<span class="token punctuation">,</span>
                reproduce<span class="token operator">=</span>args<span class="token punctuation">.</span>reproduce<span class="token punctuation">,</span>
                logger<span class="token operator">=</span>logger<span class="token punctuation">,</span>
                device<span class="token operator">=</span>device <span class="token keyword">if</span> <span class="token keyword">not</span> args<span class="token punctuation">.</span>use_cpu_offload <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
 
        <span class="token keyword">return</span> cls<span class="token punctuation">(</span>     <span class="token comment"># 初始化本类的一个实例</span>
            args<span class="token operator">=</span>args<span class="token punctuation">,</span>
            vae<span class="token operator">=</span>vae<span class="token punctuation">,</span>        <span class="token comment"># AutoencoderKLCausal3D</span>
            vae_kwargs<span class="token operator">=</span>vae_kwargs<span class="token punctuation">,</span>
            text_encoder<span class="token operator">=</span>text_encoder<span class="token punctuation">,</span>      <span class="token comment"># llm</span>
            text_encoder_2<span class="token operator">=</span>text_encoder_2<span class="token punctuation">,</span>
            model<span class="token operator">=</span>model<span class="token punctuation">,</span>
            use_cpu_offload<span class="token operator">=</span>args<span class="token punctuation">.</span>use_cpu_offload<span class="token punctuation">,</span>
            device<span class="token operator">=</span>device<span class="token punctuation">,</span>
            logger<span class="token operator">=</span>logger<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
</code></pre>
    <p>
     最后使用了cls()，会调用HunyuanVideoSampler的初始化方法__init__()，指定所有组件并将他们组合到一个pipeline，包括模型、调度器（scheduler）、设备配置等必要的组件，然后指定负面提示词。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">HunyuanVideoSampler</span><span class="token punctuation">(</span>Inference<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
 
        self<span class="token punctuation">.</span>pipeline <span class="token operator">=</span> self<span class="token punctuation">.</span>load_diffusion_pipeline<span class="token punctuation">(</span>       <span class="token comment"># 组合所有原件</span>
            args<span class="token operator">=</span>args<span class="token punctuation">,</span>
            vae<span class="token operator">=</span>self<span class="token punctuation">.</span>vae<span class="token punctuation">,</span>
            text_encoder<span class="token operator">=</span>self<span class="token punctuation">.</span>text_encoder<span class="token punctuation">,</span>
            text_encoder_2<span class="token operator">=</span>self<span class="token punctuation">.</span>text_encoder_2<span class="token punctuation">,</span>
            model<span class="token operator">=</span>self<span class="token punctuation">.</span>model<span class="token punctuation">,</span>
            device<span class="token operator">=</span>self<span class="token punctuation">.</span>device<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
 
        self<span class="token punctuation">.</span>default_negative_prompt <span class="token operator">=</span> NEGATIVE_PROMPT      <span class="token comment"># 负面提示词</span>


    <span class="token keyword">def</span> <span class="token function">load_diffusion_pipeline</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        args<span class="token punctuation">,</span>
        vae<span class="token punctuation">,</span>
        text_encoder<span class="token punctuation">,</span>
        text_encoder_2<span class="token punctuation">,</span>
        model<span class="token punctuation">,</span>
        scheduler<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
        device<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
        progress_bar_config<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
        data_type<span class="token operator">=</span><span class="token string">"video"</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Load the denoising scheduler for inference."""</span>
        <span class="token comment"># 去噪调度器的初始化</span>
        <span class="token keyword">if</span> scheduler <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> args<span class="token punctuation">.</span>denoise_type <span class="token operator">==</span> <span class="token string">"flow"</span><span class="token punctuation">:</span>
                <span class="token comment"># 流动匹配的去噪策略，离散去噪调度器，可能用于视频生成任务中时间帧之间的一致性建模。</span>
                <span class="token comment"># 负责指导扩散模型逐步还原噪声，生成清晰的视频帧。</span>
                scheduler <span class="token operator">=</span> FlowMatchDiscreteScheduler<span class="token punctuation">(</span>
                    shift<span class="token operator">=</span>args<span class="token punctuation">.</span>flow_shift<span class="token punctuation">,</span> <span class="token comment"># 流动偏移值。</span>
                    reverse<span class="token operator">=</span>args<span class="token punctuation">.</span>flow_reverse<span class="token punctuation">,</span> <span class="token comment"># 是否反向计算。</span>
                    solver<span class="token operator">=</span>args<span class="token punctuation">.</span>flow_solver<span class="token punctuation">,</span> <span class="token comment"># 去噪求解器的类型</span>
                <span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Invalid denoise type </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>args<span class="token punctuation">.</span>denoise_type<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token comment"># 构建推理pipeline</span>
        pipeline <span class="token operator">=</span> HunyuanVideoPipeline<span class="token punctuation">(</span>
            vae<span class="token operator">=</span>vae<span class="token punctuation">,</span> <span class="token comment"># 负责特征编码和解码的模块。</span>
            text_encoder<span class="token operator">=</span>text_encoder<span class="token punctuation">,</span> <span class="token comment"># 用于处理文本提示，生成与视频生成相关的特征。</span>
            text_encoder_2<span class="token operator">=</span>text_encoder_2<span class="token punctuation">,</span>
            transformer<span class="token operator">=</span>model<span class="token punctuation">,</span> <span class="token comment"># 主扩散模型，生成视频的核心模块。</span>
            scheduler<span class="token operator">=</span>scheduler<span class="token punctuation">,</span> <span class="token comment"># 去噪调度器，控制扩散生成的时间步长和过程</span>
            progress_bar_config<span class="token operator">=</span>progress_bar_config<span class="token punctuation">,</span> <span class="token comment"># 可选的进度条配置，用于显示推理进度。</span>
            args<span class="token operator">=</span>args<span class="token punctuation">,</span> <span class="token comment"># 配置参数的集合</span>
        <span class="token punctuation">)</span>
        <span class="token comment"># 配置计算资源</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_cpu_offload<span class="token punctuation">:</span>
            <span class="token comment"># 将部分计算任务卸载到 CPU。这是显存不足时的优化策略，可以大幅降低 GPU 的显存占用。</span>
            pipeline<span class="token punctuation">.</span>enable_sequential_cpu_offload<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># 如果为 False，直接将管道加载到指定的 device（如 GPU）上运行</span>
            pipeline <span class="token operator">=</span> pipeline<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        <span class="token keyword">return</span> pipeline

</code></pre>
    <p>
     提示词如下：
    </p>
    <pre><code class="prism language-python">PROMPT_TEMPLATE_ENCODE <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token string">"&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\n\nDescribe the image by detailing the color, shape, size, texture, "</span>
    <span class="token string">"quantity, text, spatial relationships of the objects and background:&lt;|eot_id|&gt;"</span>
    <span class="token string">"&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\n{}&lt;|eot_id|&gt;"</span>
<span class="token punctuation">)</span> 
PROMPT_TEMPLATE_ENCODE_VIDEO <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token string">"&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\n\nDescribe the video by detailing the following aspects: "</span>
    <span class="token string">"1. The main content and theme of the video."</span>
    <span class="token string">"2. The color, shape, size, texture, quantity, text, and spatial relationships of the objects."</span>
    <span class="token string">"3. Actions, events, behaviors temporal relationships, physical movement changes of the objects."</span>
    <span class="token string">"4. background environment, light, style and atmosphere."</span>
    <span class="token string">"5. camera angles, movements, and transitions used in the video:&lt;|eot_id|&gt;"</span>
    <span class="token string">"&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\n{}&lt;|eot_id|&gt;"</span>
<span class="token punctuation">)</span>  
 
NEGATIVE_PROMPT <span class="token operator">=</span> <span class="token string">"Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion"</span>
 
PROMPT_TEMPLATE <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"dit-llm-encode"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">"template"</span><span class="token punctuation">:</span> PROMPT_TEMPLATE_ENCODE<span class="token punctuation">,</span>
        <span class="token string">"crop_start"</span><span class="token punctuation">:</span> <span class="token number">36</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">"dit-llm-encode-video"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">"template"</span><span class="token punctuation">:</span> PROMPT_TEMPLATE_ENCODE_VIDEO<span class="token punctuation">,</span>
        <span class="token string">"crop_start"</span><span class="token punctuation">:</span> <span class="token number">95</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
</code></pre>
    <h3>
     <a id="33__447">
     </a>
     3.3 模型推理
    </h3>
    <p>
     位置编码使用的是RoPE，主要根据输入的视频维度、网络配置以及位置嵌入参数，生成对应的正弦和余弦频率嵌入。
    </p>
    <pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">get_rotary_pos_embed</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> video_length<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># video_length: 视频的帧长度。</span>
        <span class="token comment"># height, width: 视频的帧高和帧宽。 目标是根据这些维度计算位置嵌入。</span>
        <span class="token comment"># 表示生成的 RoPE 的目标维度（3D: 时间维度 + 空间高度和宽度）</span>
        target_ndim <span class="token operator">=</span> <span class="token number">3</span>
        <span class="token comment"># 推导潜在特征（latent feature）所需维度的辅助变量</span>
        ndim <span class="token operator">=</span> <span class="token number">5</span> <span class="token operator">-</span> <span class="token number">2</span>
        <span class="token comment"># 根据 self.args.vae 中的配置（例如 VAE 模型类型 884 或 888），确定潜在特征的空间尺寸 latents_size</span>
        <span class="token comment"># 884: 时间维度下采样 4 倍（1/4），空间高宽下采样 8 倍（1/8）。</span>
        <span class="token keyword">if</span> <span class="token string">"884"</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>args<span class="token punctuation">.</span>vae<span class="token punctuation">:</span>
            latents_size <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>video_length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">4</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> height <span class="token operator">//</span> <span class="token number">8</span><span class="token punctuation">,</span> width <span class="token operator">//</span> <span class="token number">8</span><span class="token punctuation">]</span>
        <span class="token comment"># 888: 时间维度下采样 8 倍（1/8），空间高宽下采样 8 倍。</span>
        <span class="token keyword">elif</span> <span class="token string">"888"</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>args<span class="token punctuation">.</span>vae<span class="token punctuation">:</span>
            latents_size <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>video_length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">8</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> height <span class="token operator">//</span> <span class="token number">8</span><span class="token punctuation">,</span> width <span class="token operator">//</span> <span class="token number">8</span><span class="token punctuation">]</span>
        <span class="token comment"># 默认情况下不对时间维度下采样，但高宽依然下采样 8 倍。</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            latents_size <span class="token operator">=</span> <span class="token punctuation">[</span>video_length<span class="token punctuation">,</span> height <span class="token operator">//</span> <span class="token number">8</span><span class="token punctuation">,</span> width <span class="token operator">//</span> <span class="token number">8</span><span class="token punctuation">]</span>

        <span class="token comment"># 检查潜在空间尺寸是否与 Patch 尺寸兼容</span>
        <span class="token comment"># 如果 self.model.patch_size 是单个整数，检查潜在特征维度的每一维是否能被 patch_size 整除。</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>patch_size<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">assert</span> <span class="token builtin">all</span><span class="token punctuation">(</span>s <span class="token operator">%</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>patch_size <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">for</span> s <span class="token keyword">in</span> latents_size<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>
                <span class="token string-interpolation"><span class="token string">f"Latent size(last </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>ndim<span class="token punctuation">}</span></span><span class="token string"> dimensions) should be divisible by patch size(</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>patch_size<span class="token punctuation">}</span></span><span class="token string">), "</span></span>
                <span class="token string-interpolation"><span class="token string">f"but got </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>latents_size<span class="token punctuation">}</span></span><span class="token string">."</span></span>
            <span class="token punctuation">)</span>
            <span class="token comment"># 如果整除，计算 RoPE 的输入尺寸 rope_sizes（将 latents_size 每一维除以 patch_size）</span>
            rope_sizes <span class="token operator">=</span> <span class="token punctuation">[</span>s <span class="token operator">//</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>patch_size <span class="token keyword">for</span> s <span class="token keyword">in</span> latents_size<span class="token punctuation">]</span>
        <span class="token comment"># 如果 self.model.patch_size 是一个列表，分别对每一维进行整除检查和计算。</span>
        <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>patch_size<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">assert</span> <span class="token builtin">all</span><span class="token punctuation">(</span>
                s <span class="token operator">%</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>patch_size<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span>
                <span class="token keyword">for</span> idx<span class="token punctuation">,</span> s <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>latents_size<span class="token punctuation">)</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>
                <span class="token string-interpolation"><span class="token string">f"Latent size(last </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>ndim<span class="token punctuation">}</span></span><span class="token string"> dimensions) should be divisible by patch size(</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>patch_size<span class="token punctuation">}</span></span><span class="token string">), "</span></span>
                <span class="token string-interpolation"><span class="token string">f"but got </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>latents_size<span class="token punctuation">}</span></span><span class="token string">."</span></span>
            <span class="token punctuation">)</span>
            rope_sizes <span class="token operator">=</span> <span class="token punctuation">[</span>
                s <span class="token operator">//</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>patch_size<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token keyword">for</span> idx<span class="token punctuation">,</span> s <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>latents_size<span class="token punctuation">)</span>
            <span class="token punctuation">]</span>
        <span class="token comment"># 如果 rope_sizes 的维度数不足 target_ndim，在开头补充时间维度（值为 1）。</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>rope_sizes<span class="token punctuation">)</span> <span class="token operator">!=</span> target_ndim<span class="token punctuation">:</span>
            rope_sizes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>target_ndim <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span>rope_sizes<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> rope_sizes  <span class="token comment"># time axis</span>
        <span class="token comment"># head_dim 是单个注意力头的维度大小，由模型的 hidden_size 和 heads_num 计算得出。</span>
        head_dim <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>hidden_size <span class="token operator">//</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>heads_num
        <span class="token comment"># rope_dim_list 是用于位置嵌入的维度分配列表：</span>
        <span class="token comment"># 如果未定义，默认将 head_dim 平均分配到 target_ndim（时间、高度、宽度）。</span>
        rope_dim_list <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>rope_dim_list
        <span class="token keyword">if</span> rope_dim_list <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            rope_dim_list <span class="token operator">=</span> <span class="token punctuation">[</span>head_dim <span class="token operator">//</span> target_ndim <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>target_ndim<span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>
            <span class="token builtin">sum</span><span class="token punctuation">(</span>rope_dim_list<span class="token punctuation">)</span> <span class="token operator">==</span> head_dim
        <span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"sum(rope_dim_list) should equal to head_dim of attention layer"</span>
        <span class="token comment"># 调用 get_nd_rotary_pos_embed 函数，计算基于目标尺寸 rope_sizes 和维度分配 rope_dim_list 的多维旋转位置嵌入。</span>
        freqs_cos<span class="token punctuation">,</span> freqs_sin <span class="token operator">=</span> get_nd_rotary_pos_embed<span class="token punctuation">(</span>
            rope_dim_list<span class="token punctuation">,</span>
            rope_sizes<span class="token punctuation">,</span>
            theta<span class="token operator">=</span>self<span class="token punctuation">.</span>args<span class="token punctuation">.</span>rope_theta<span class="token punctuation">,</span> <span class="token comment">#控制位置嵌入频率。</span>
            use_real<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment"># 表示使用真实数值而非复数形式。</span>
            theta_rescale_factor<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token comment"># 无缩放因子。</span>
        <span class="token punctuation">)</span>
        <span class="token comment">#返回： freqs_cos: 余弦频率嵌入。freqs_sin: 正弦频率嵌入。</span>
        <span class="token keyword">return</span> freqs_cos<span class="token punctuation">,</span> freqs_sin
</code></pre>
    <p>
     predict 函数用于从文本生成视频或图像的预测函数，通过输入文本 prompt，结合其他参数（如视频分辨率、帧数、推理步数等），生成指定数量的视频或图像。
    </p>
    <pre><code class="prism language-python">    <span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        prompt<span class="token punctuation">,</span>
        height<span class="token operator">=</span><span class="token number">192</span><span class="token punctuation">,</span>
        width<span class="token operator">=</span><span class="token number">336</span><span class="token punctuation">,</span>
        video_length<span class="token operator">=</span><span class="token number">129</span><span class="token punctuation">,</span>
        seed<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
        negative_prompt<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
        infer_steps<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>
        guidance_scale<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>
        flow_shift<span class="token operator">=</span><span class="token number">5.0</span><span class="token punctuation">,</span>
        embedded_guidance_scale<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
        batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
        num_videos_per_prompt<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
        <span class="token operator">**</span>kwargs<span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Predict the image/video from the given text.

        Args:
            prompt (str or List[str]): The input text.
            kwargs:
                height (int): The height of the output video. Default is 192.
                width (int): The width of the output video. Default is 336.
                video_length (int): The frame number of the output video. Default is 129.
                seed (int or List[str]): The random seed for the generation. Default is a random integer.
                negative_prompt (str or List[str]): The negative text prompt. Default is an empty string.
                guidance_scale (float): The guidance scale for the generation. Default is 6.0.
                num_images_per_prompt (int): The number of images per prompt. Default is 1.
                infer_steps (int): The number of inference steps. Default is 100.
        """</span>
        <span class="token comment"># 分布式环境检查</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>parallel_args<span class="token punctuation">[</span><span class="token string">'ulysses_degree'</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">1</span> <span class="token keyword">or</span> self<span class="token punctuation">.</span>parallel_args<span class="token punctuation">[</span><span class="token string">'ring_degree'</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
            <span class="token keyword">assert</span> seed <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">,</span> \
                <span class="token string">"You have to set a seed in the distributed environment, please rerun with --seed &lt;your-seed&gt;."</span>
            <span class="token comment"># 满足分布式环境的条件，调用 parallelize_transformer 函数并行化模型</span>
            parallelize_transformer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pipeline<span class="token punctuation">)</span>
        <span class="token comment"># 初始化一个空字典 out_dict，用于存储最终的生成结果。</span>
        out_dict <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># ========================================================================</span>
        <span class="token comment"># 根据传入的 seed 参数生成一组随机种子，并将这些种子用于初始化随机数生成器 (torch.Generator) 来控制生成过程的随机性。</span>
        <span class="token comment"># ========================================================================</span>
        <span class="token comment"># 根据 seed 参数的类型（None、int、list、tuple 或 torch.Tensor），执行不同的逻辑，生成用于控制随机数生成器的 seeds 列表</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>seed<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
            seed <span class="token operator">=</span> seed<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> seed <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            seeds <span class="token operator">=</span> <span class="token punctuation">[</span>
                random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1_000_000</span><span class="token punctuation">)</span>
                <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>batch_size <span class="token operator">*</span> num_videos_per_prompt<span class="token punctuation">)</span>
            <span class="token punctuation">]</span>
        <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>seed<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            seeds <span class="token operator">=</span> <span class="token punctuation">[</span>
                seed <span class="token operator">+</span> i
                <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>
                <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_videos_per_prompt<span class="token punctuation">)</span>
            <span class="token punctuation">]</span>
        <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>seed<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>seed<span class="token punctuation">)</span> <span class="token operator">==</span> batch_size<span class="token punctuation">:</span>
                seeds <span class="token operator">=</span> <span class="token punctuation">[</span>
                    <span class="token builtin">int</span><span class="token punctuation">(</span>seed<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> j
                    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>
                    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_videos_per_prompt<span class="token punctuation">)</span>
                <span class="token punctuation">]</span>
            <span class="token keyword">elif</span> <span class="token builtin">len</span><span class="token punctuation">(</span>seed<span class="token punctuation">)</span> <span class="token operator">==</span> batch_size <span class="token operator">*</span> num_videos_per_prompt<span class="token punctuation">:</span>
                seeds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token keyword">for</span> s <span class="token keyword">in</span> seed<span class="token punctuation">]</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                    <span class="token string-interpolation"><span class="token string">f"Length of seed must be equal to number of prompt(batch_size) or "</span></span>
                    <span class="token string-interpolation"><span class="token string">f"batch_size * num_videos_per_prompt (</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>batch_size<span class="token punctuation">}</span></span><span class="token string"> * </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>num_videos_per_prompt<span class="token punctuation">}</span></span><span class="token string">), got </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>seed<span class="token punctuation">}</span></span><span class="token string">."</span></span>
                <span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                <span class="token string-interpolation"><span class="token string">f"Seed must be an integer, a list of integers, or None, got </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>seed<span class="token punctuation">}</span></span><span class="token string">."</span></span>
            <span class="token punctuation">)</span>
        <span class="token comment"># 对每个种子，在指定设备（self.device）上创建一个 PyTorch 的随机数生成器 torch.Generator，并使用对应的种子进行手动初始化</span>
        <span class="token comment"># （manual_seed(seed)）。将这些生成器存储在列表 generator 中。</span>
        generator <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Generator<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span> <span class="token keyword">for</span> seed <span class="token keyword">in</span> seeds<span class="token punctuation">]</span>
        <span class="token comment"># 将生成的 seeds 列表存储在 out_dict 中，供后续使用（可能用于复现生成结果或记录生成过程的随机性）。</span>
        out_dict<span class="token punctuation">[</span><span class="token string">"seeds"</span><span class="token punctuation">]</span> <span class="token operator">=</span> seeds

        <span class="token comment"># ========================================================================</span>
        <span class="token comment"># 检查和调整视频生成的输入参数（height、width 和 video_length）的合法性与对齐要求，并计算出调整后的目标尺寸。</span>
        <span class="token comment"># ========================================================================</span>
        <span class="token comment"># 检查输入的 height、width 和 video_length 是否为正整数：</span>
        <span class="token keyword">if</span> width <span class="token operator">&lt;=</span> <span class="token number">0</span> <span class="token keyword">or</span> height <span class="token operator">&lt;=</span> <span class="token number">0</span> <span class="token keyword">or</span> video_length <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                <span class="token string-interpolation"><span class="token string">f"`height` and `width` and `video_length` must be positive integers, got height=</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>height<span class="token punctuation">}</span></span><span class="token string">, width=</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>width<span class="token punctuation">}</span></span><span class="token string">, video_length=</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>video_length<span class="token punctuation">}</span></span><span class="token string">"</span></span>
            <span class="token punctuation">)</span>
        <span class="token comment"># 检查 video_length - 1 是否为 4 的倍数</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>video_length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">4</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                <span class="token string-interpolation"><span class="token string">f"`video_length-1` must be a multiple of 4, got </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>video_length<span class="token punctuation">}</span></span><span class="token string">"</span></span>
            <span class="token punctuation">)</span>
        <span class="token comment"># 日志记录</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span>
            <span class="token string-interpolation"><span class="token string">f"Input (height, width, video_length) = (</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>height<span class="token punctuation">}</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>width<span class="token punctuation">}</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>video_length<span class="token punctuation">}</span></span><span class="token string">)"</span></span>
        <span class="token punctuation">)</span>
        <span class="token comment"># 目标高度和宽度对齐到 16 的倍数</span>
        target_height <span class="token operator">=</span> align_to<span class="token punctuation">(</span>height<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>
        target_width <span class="token operator">=</span> align_to<span class="token punctuation">(</span>width<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>
        target_video_length <span class="token operator">=</span> video_length
        <span class="token comment"># 存储目标尺寸</span>
        out_dict<span class="token punctuation">[</span><span class="token string">"size"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>target_height<span class="token punctuation">,</span> target_width<span class="token punctuation">,</span> target_video_length<span class="token punctuation">)</span>

        <span class="token comment"># ========================================================================</span>
        <span class="token comment"># 检查和处理文本生成任务中的 prompt 和 negative_prompt 参数</span>
        <span class="token comment"># ========================================================================</span>
        <span class="token comment"># 确保输入的 prompt 是字符串类型</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> TypeError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"`prompt` must be a string, but got </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">type</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        prompt <span class="token operator">=</span> <span class="token punctuation">[</span>prompt<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment"># 对 prompt 去除首尾多余的空格（使用 .strip()），然后包装成一个单元素列表</span>

        <span class="token comment"># 处理 negative_prompt 参数</span>
        <span class="token keyword">if</span> negative_prompt <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">or</span> negative_prompt <span class="token operator">==</span> <span class="token string">""</span><span class="token punctuation">:</span>
            negative_prompt <span class="token operator">=</span> self<span class="token punctuation">.</span>default_negative_prompt
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>negative_prompt<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> TypeError<span class="token punctuation">(</span>
                <span class="token string-interpolation"><span class="token string">f"`negative_prompt` must be a string, but got </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">type</span><span class="token punctuation">(</span>negative_prompt<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span>
            <span class="token punctuation">)</span>
        negative_prompt <span class="token operator">=</span> <span class="token punctuation">[</span>negative_prompt<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

        <span class="token comment"># ========================================================================</span>
        <span class="token comment"># 设置调度器 (Scheduler)</span>
        <span class="token comment"># ========================================================================</span>
        scheduler <span class="token operator">=</span> FlowMatchDiscreteScheduler<span class="token punctuation">(</span> <span class="token comment"># 处理流（Flow）的调度</span>
            shift<span class="token operator">=</span>flow_shift<span class="token punctuation">,</span> <span class="token comment"># 控制流动调度器的偏移量。flow_shift 通常与时序或流动模型相关，例如调整时间步之间的关系。</span>
            reverse<span class="token operator">=</span>self<span class="token punctuation">.</span>args<span class="token punctuation">.</span>flow_reverse<span class="token punctuation">,</span> <span class="token comment"># 决定是否反向调度（可能是在推理过程中逆序生成帧）</span>
            solver<span class="token operator">=</span>self<span class="token punctuation">.</span>args<span class="token punctuation">.</span>flow_solver <span class="token comment"># 指定用于调度的解算器类型（solver），例如选择数值方法来优化时间步间的计算。</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pipeline<span class="token punctuation">.</span>scheduler <span class="token operator">=</span> scheduler

        <span class="token comment"># ========================================================================</span>
        <span class="token comment"># 构建旋转位置嵌入 (Rotary Positional Embedding)</span>
        <span class="token comment"># ========================================================================</span>
        <span class="token comment"># 根据目标视频长度、高度和宽度生成正弦 (freqs_sin) 和余弦 (freqs_cos) 的频率嵌入。</span>
        freqs_cos<span class="token punctuation">,</span> freqs_sin <span class="token operator">=</span> self<span class="token punctuation">.</span>get_rotary_pos_embed<span class="token punctuation">(</span>
            target_video_length<span class="token punctuation">,</span> target_height<span class="token punctuation">,</span> target_width
        <span class="token punctuation">)</span>
        <span class="token comment"># 表示视频中总的编码标记数（tokens），通常等于时间步数（帧数）与空间分辨率（像素数）相乘。</span>
        n_tokens <span class="token operator">=</span> freqs_cos<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

        <span class="token comment"># ========================================================================</span>
        <span class="token comment"># 打印推理参数</span>
        <span class="token comment"># ========================================================================</span>
        debug_str <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"""
                        height: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>target_height<span class="token punctuation">}</span></span><span class="token string">
                         width: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>target_width<span class="token punctuation">}</span></span><span class="token string">
                  video_length: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>target_video_length<span class="token punctuation">}</span></span><span class="token string">
                        prompt: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>prompt<span class="token punctuation">}</span></span><span class="token string">
                    neg_prompt: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>negative_prompt<span class="token punctuation">}</span></span><span class="token string">
                          seed: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>seed<span class="token punctuation">}</span></span><span class="token string">
                   infer_steps: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>infer_steps<span class="token punctuation">}</span></span><span class="token string">
         num_videos_per_prompt: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>num_videos_per_prompt<span class="token punctuation">}</span></span><span class="token string">
                guidance_scale: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>guidance_scale<span class="token punctuation">}</span></span><span class="token string">
                      n_tokens: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>n_tokens<span class="token punctuation">}</span></span><span class="token string">
                    flow_shift: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>flow_shift<span class="token punctuation">}</span></span><span class="token string">
       embedded_guidance_scale: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>embedded_guidance_scale<span class="token punctuation">}</span></span><span class="token string">"""</span></span>
        logger<span class="token punctuation">.</span>debug<span class="token punctuation">(</span>debug_str<span class="token punctuation">)</span>

        <span class="token comment"># ========================================================================</span>
        <span class="token comment"># Pipeline inference</span>
        <span class="token comment"># ========================================================================</span>
        start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
        samples <span class="token operator">=</span> self<span class="token punctuation">.</span>pipeline<span class="token punctuation">(</span>
            prompt<span class="token operator">=</span>prompt<span class="token punctuation">,</span> <span class="token comment"># 文本提示，用于指导生成内容。</span>
            height<span class="token operator">=</span>target_height<span class="token punctuation">,</span> <span class="token comment"># 生成图像或视频帧的分辨率。</span>
            width<span class="token operator">=</span>target_width<span class="token punctuation">,</span> <span class="token comment">#</span>
            video_length<span class="token operator">=</span>target_video_length<span class="token punctuation">,</span> <span class="token comment"># 视频的帧数。如果 video_length &gt; 1，表示生成视频；否则生成单张图像。</span>
            num_inference_steps<span class="token operator">=</span>infer_steps<span class="token punctuation">,</span> <span class="token comment"># 推理步数，决定生成过程的细粒度程度，步数越多，生成结果越精细。</span>
            guidance_scale<span class="token operator">=</span>guidance_scale<span class="token punctuation">,</span> <span class="token comment"># 指导比例，控制生成与 prompt 的一致性程度。</span>
            negative_prompt<span class="token operator">=</span>negative_prompt<span class="token punctuation">,</span> <span class="token comment"># 负面提示，用于约束生成内容，避免不期望的结果。</span>
            num_videos_per_prompt<span class="token operator">=</span>num_videos_per_prompt<span class="token punctuation">,</span> <span class="token comment"># 每条提示生成的视频数量。</span>

            generator<span class="token operator">=</span>generator<span class="token punctuation">,</span> <span class="token comment"># 随机生成器对象，用于控制生成过程中的随机性，通常与随机种子结合。</span>
            output_type<span class="token operator">=</span><span class="token string">"pil"</span><span class="token punctuation">,</span> <span class="token comment"># 指定输出格式为 PIL.Image 对象，便于后续处理</span>
            freqs_cis<span class="token operator">=</span><span class="token punctuation">(</span>freqs_cos<span class="token punctuation">,</span> freqs_sin<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 旋转位置嵌入 (RoPE) 的频率矩阵，增强时空位置感知能力。</span>
            n_tokens<span class="token operator">=</span>n_tokens<span class="token punctuation">,</span> <span class="token comment"># 输入序列的总标记数，用于指导生成过程。</span>
            embedded_guidance_scale<span class="token operator">=</span>embedded_guidance_scale<span class="token punctuation">,</span> <span class="token comment"># 嵌入式指导比例，用于进一步优化嵌入向量的生成。</span>

            data_type<span class="token operator">=</span><span class="token string">"video"</span> <span class="token keyword">if</span> target_video_length <span class="token operator">&gt;</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token string">"image"</span><span class="token punctuation">,</span> <span class="token comment"># 指定生成目标为视频或图像，取决于帧数。</span>
            is_progress_bar<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment"># 显示推理进度条，方便监控生成进度。</span>

            vae_ver<span class="token operator">=</span>self<span class="token punctuation">.</span>args<span class="token punctuation">.</span>vae<span class="token punctuation">,</span> <span class="token comment"># 使用指定版本的 VAE（变分自编码器），决定生成内容的潜在空间。</span>
            enable_tiling<span class="token operator">=</span>self<span class="token punctuation">.</span>args<span class="token punctuation">.</span>vae_tiling<span class="token punctuation">,</span> <span class="token comment"># 启用 VAE 分块处理，提高内存效率，特别适用于高分辨率生成。</span>
        <span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># 返回生成的样本，通常是一个 PIL.Image 或视频帧序列</span>
        <span class="token comment"># 保存生成结果</span>
        out_dict<span class="token punctuation">[</span><span class="token string">"samples"</span><span class="token punctuation">]</span> <span class="token operator">=</span> samples
        out_dict<span class="token punctuation">[</span><span class="token string">"prompts"</span><span class="token punctuation">]</span> <span class="token operator">=</span> prompt
        <span class="token comment"># 计算并记录推理时间</span>
        gen_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Success, time: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>gen_time<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> out_dict

</code></pre>
    <p>
     推理pipeline（hyvideo/diffusion/pipelines/pipeline_hunyuan_video.py）：
     <strong>
      call
     </strong>
     方法接受用户输入的提示、生成图像或视频的尺寸，以及其他生成过程的参数，完成推理并返回生成的图像或视频。
    </p>
    <pre><code class="prism language-python">    <span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token decorator annotation punctuation">@replace_example_docstring</span><span class="token punctuation">(</span>EXAMPLE_DOC_STRING<span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        prompt<span class="token punctuation">:</span> Union<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        height<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
        width<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
        video_length<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
        data_type<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"video"</span><span class="token punctuation">,</span>
        num_inference_steps<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">,</span>
        timesteps<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        sigmas<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        guidance_scale<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">7.5</span><span class="token punctuation">,</span>
        negative_prompt<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Union<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        num_videos_per_prompt<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
        eta<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span>
        generator<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Union<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Generator<span class="token punctuation">,</span> List<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Generator<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        latents<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        prompt_embeds<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        attention_mask<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        negative_prompt_embeds<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        negative_attention_mask<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        output_type<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"pil"</span><span class="token punctuation">,</span>
        return_dict<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
        cross_attention_kwargs<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        guidance_rescale<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span>
        clip_skip<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        callback_on_step_end<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>
            Union<span class="token punctuation">[</span>
                Callable<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">,</span> Dict<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                PipelineCallback<span class="token punctuation">,</span>
                MultiPipelineCallbacks<span class="token punctuation">,</span>
            <span class="token punctuation">]</span>
        <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        callback_on_step_end_tensor_inputs<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"latents"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        freqs_cis<span class="token punctuation">:</span> Tuple<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        vae_ver<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"88-4c-sd"</span><span class="token punctuation">,</span>
        enable_tiling<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
        n_tokens<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        embedded_guidance_scale<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        <span class="token operator">**</span>kwargs<span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">r"""
        The call function to the pipeline for generation.

        Args:
            prompt (`str` or `List[str]`):
                The prompt or prompts to guide image generation. If not defined, you need to pass `prompt_embeds`.
            height (`int`):
                The height in pixels of the generated image.
            width (`int`):
                The width in pixels of the generated image.
            video_length (`int`):
                The number of frames in the generated video.
            num_inference_steps (`int`, *optional*, defaults to 50):
                The number of denoising steps. More denoising steps usually lead to a higher quality image at the
                expense of slower inference.
            timesteps (`List[int]`, *optional*):
                Custom timesteps to use for the denoising process with schedulers which support a `timesteps` argument
                in their `set_timesteps` method. If not defined, the default behavior when `num_inference_steps` is
                passed will be used. Must be in descending order.
            sigmas (`List[float]`, *optional*):
                Custom sigmas to use for the denoising process with schedulers which support a `sigmas` argument in
                their `set_timesteps` method. If not defined, the default behavior when `num_inference_steps` is passed
                will be used.
            guidance_scale (`float`, *optional*, defaults to 7.5):
                A higher guidance scale value encourages the model to generate images closely linked to the text
                `prompt` at the expense of lower image quality. Guidance scale is enabled when `guidance_scale &gt; 1`.
            negative_prompt (`str` or `List[str]`, *optional*):
                The prompt or prompts to guide what to not include in image generation. If not defined, you need to
                pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale &lt; 1`).
            num_videos_per_prompt (`int`, *optional*, defaults to 1):
                The number of images to generate per prompt.
            eta (`float`, *optional*, defaults to 0.0):
                Corresponds to parameter eta (η) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies
                to the [`~schedulers.DDIMScheduler`], and is ignored in other schedulers.
            generator (`torch.Generator` or `List[torch.Generator]`, *optional*):
                A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html) to make
                generation deterministic.
            latents (`torch.Tensor`, *optional*):
                Pre-generated noisy latents sampled from a Gaussian distribution, to be used as inputs for image
                generation. Can be used to tweak the same generation with different prompts. If not provided, a latents
                tensor is generated by sampling using the supplied random `generator`.
            prompt_embeds (`torch.Tensor`, *optional*):
                Pre-generated text embeddings. Can be used to easily tweak text inputs (prompt weighting). If not
                provided, text embeddings are generated from the `prompt` input argument.
            negative_prompt_embeds (`torch.Tensor`, *optional*):
                Pre-generated negative text embeddings. Can be used to easily tweak text inputs (prompt weighting). If
                not provided, `negative_prompt_embeds` are generated from the `negative_prompt` input argument.
                
            output_type (`str`, *optional*, defaults to `"pil"`):
                The output format of the generated image. Choose between `PIL.Image` or `np.array`.
            return_dict (`bool`, *optional*, defaults to `True`):
                Whether or not to return a [`HunyuanVideoPipelineOutput`] instead of a
                plain tuple.
            cross_attention_kwargs (`dict`, *optional*):
                A kwargs dictionary that if specified is passed along to the [`AttentionProcessor`] as defined in
                [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).
            guidance_rescale (`float`, *optional*, defaults to 0.0):
                Guidance rescale factor from [Common Diffusion Noise Schedules and Sample Steps are
                Flawed](https://arxiv.org/pdf/2305.08891.pdf). Guidance rescale factor should fix overexposure when
                using zero terminal SNR.
            clip_skip (`int`, *optional*):
                Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that
                the output of the pre-final layer will be used for computing the prompt embeddings.
            callback_on_step_end (`Callable`, `PipelineCallback`, `MultiPipelineCallbacks`, *optional*):
                A function or a subclass of `PipelineCallback` or `MultiPipelineCallbacks` that is called at the end of
                each denoising step during the inference. with the following arguments: `callback_on_step_end(self:
                DiffusionPipeline, step: int, timestep: int, callback_kwargs: Dict)`. `callback_kwargs` will include a
                list of all tensors as specified by `callback_on_step_end_tensor_inputs`.
            callback_on_step_end_tensor_inputs (`List`, *optional*):
                The list of tensor inputs for the `callback_on_step_end` function. The tensors specified in the list
                will be passed as `callback_kwargs` argument. You will only be able to include variables listed in the
                `._callback_tensor_inputs` attribute of your pipeline class.

        Examples:

        Returns:
            [`~HunyuanVideoPipelineOutput`] or `tuple`:
                If `return_dict` is `True`, [`HunyuanVideoPipelineOutput`] is returned,
                otherwise a `tuple` is returned where the first element is a list with the generated images and the
                second element is a list of `bool`s indicating whether the corresponding generated image contains
                "not-safe-for-work" (nsfw) content.
        """</span>
        <span class="token comment"># 处理与回调函数相关的参数，同时对已弃用的参数发出警告（deprecation warnings）。</span>
        <span class="token comment"># 它还检查了新的回调函数机制 callback_on_step_end 是否符合预期类型。</span>
        callback <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"callback"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
        callback_steps <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"callback_steps"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> callback <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            deprecate<span class="token punctuation">(</span>
                <span class="token string">"callback"</span><span class="token punctuation">,</span>
                <span class="token string">"1.0.0"</span><span class="token punctuation">,</span>
                <span class="token string">"Passing `callback` as an input argument to `__call__` is deprecated, consider using `callback_on_step_end`"</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
        <span class="token keyword">if</span> callback_steps <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            deprecate<span class="token punctuation">(</span>
                <span class="token string">"callback_steps"</span><span class="token punctuation">,</span>
                <span class="token string">"1.0.0"</span><span class="token punctuation">,</span>
                <span class="token string">"Passing `callback_steps` as an input argument to `__call__` is deprecated, consider using `callback_on_step_end`"</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>

        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>callback_on_step_end<span class="token punctuation">,</span> <span class="token punctuation">(</span>PipelineCallback<span class="token punctuation">,</span> MultiPipelineCallbacks<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            callback_on_step_end_tensor_inputs <span class="token operator">=</span> callback_on_step_end<span class="token punctuation">.</span>tensor_inputs

        <span class="token comment"># 0. Default height and width to unet</span>
        <span class="token comment"># height = height or self.transformer.config.sample_size * self.vae_scale_factor</span>
        <span class="token comment"># width = width or self.transformer.config.sample_size * self.vae_scale_factor</span>
        <span class="token comment"># to deal with lora scaling and other possible forward hooks</span>

        <span class="token comment"># 1. 验证输入参数是否合法。</span>
        self<span class="token punctuation">.</span>check_inputs<span class="token punctuation">(</span>
            prompt<span class="token punctuation">,</span>
            height<span class="token punctuation">,</span>
            width<span class="token punctuation">,</span>
            video_length<span class="token punctuation">,</span>
            callback_steps<span class="token punctuation">,</span> <span class="token comment"># 回调频率，指定在生成过程中每隔多少步执行一次回调。</span>
            negative_prompt<span class="token punctuation">,</span>
            prompt_embeds<span class="token punctuation">,</span> <span class="token comment"># 预嵌入的提示词和反向提示词。如果已经对文本进行了嵌入处理，可以直接传递这些值，而不是原始文本。</span>
            negative_prompt_embeds<span class="token punctuation">,</span>
            callback_on_step_end_tensor_inputs<span class="token punctuation">,</span> <span class="token comment"># 与回调机制相关的数据张量。</span>
            vae_ver<span class="token operator">=</span>vae_ver<span class="token punctuation">,</span> <span class="token comment"># 可选参数，可能指定生成内容时使用的 VAE（变分自动编码器）的版本。</span>
        <span class="token punctuation">)</span>
        <span class="token comment"># 控制生成内容的引导强度。一般用于调整模型对 prompt（提示词）的依赖程度。较大的值会让生成内容更接近提示词，但可能导致丢失多样性。</span>
        self<span class="token punctuation">.</span>_guidance_scale <span class="token operator">=</span> guidance_scale
        <span class="token comment"># 用于重新调整指导比例，可能是对 guidance_scale 的一种动态调整。用于平衡模型在特定生成任务中的表现。</span>
        self<span class="token punctuation">.</span>_guidance_rescale <span class="token operator">=</span> guidance_rescale
        <span class="token comment"># 控制是否在 CLIP 模型中跳过某些层的计算。在某些生成任务中，跳过部分层可以改善生成质量。</span>
        self<span class="token punctuation">.</span>_clip_skip <span class="token operator">=</span> clip_skip
        <span class="token comment"># 与交叉注意力（Cross Attention）相关的参数。可能包括对注意力权重的控制，比如调整注意力机制如何在提示词和生成内容之间分配权重。</span>
        self<span class="token punctuation">.</span>_cross_attention_kwargs <span class="token operator">=</span> cross_attention_kwargs
        <span class="token comment"># 标志可能在生成过程的某些阶段被动态修改。</span>
        <span class="token comment"># 如果 _interrupt 被设置为 True，生成过程可能会被中止。这种设计通常用于在用户希望终止长时间生成任务时使用。</span>
        self<span class="token punctuation">.</span>_interrupt <span class="token operator">=</span> <span class="token boolean">False</span>

        <span class="token comment"># 2. 根据输入的提示词 prompt 或嵌入 prompt_embeds，确定生成任务的批量大小（batch_size）。</span>
        <span class="token keyword">if</span> prompt <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            batch_size <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment"># 如果 prompt 是单个字符串，说明只有一个提示词。批量大小设置为 1。</span>
        <span class="token keyword">elif</span> prompt <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 如果 prompt 是一个列表，说明有多个提示词。</span>
            <span class="token comment"># 此时，批量大小等于提示词的数量，即 len(prompt)。</span>
            batch_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment">#如果 prompt 是 None，说明提示词未提供，可能直接使用预先计算的嵌入 prompt_embeds。</span>
            <span class="token comment"># 此时，批量大小由 prompt_embeds 的第一维（通常是样本数量）决定。</span>
            batch_size <span class="token operator">=</span> prompt_embeds<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

        <span class="token comment"># 确定设备的device</span>
        device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"cuda:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span> <span class="token keyword">if</span> dist<span class="token punctuation">.</span>is_initialized<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> self<span class="token punctuation">.</span>_execution_device

        <span class="token comment"># 3. Encode input prompt</span>
        <span class="token comment"># 处理 LoRA（Low-Rank Adaptation）缩放系数：通过 cross_attention_kwargs 提取或设置缩放比例 lora_scale</span>
        lora_scale <span class="token operator">=</span> <span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>cross_attention_kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"scale"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>cross_attention_kwargs <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
            <span class="token keyword">else</span> <span class="token boolean">None</span>
        <span class="token punctuation">)</span>
        <span class="token comment"># 对提示词进行编码：将文本提示词 prompt 和负向提示词 negative_prompt 编码为嵌入向量，并生成对应的注意力掩码。</span>
        <span class="token punctuation">(</span>
            prompt_embeds<span class="token punctuation">,</span> <span class="token comment"># 正向提示词的嵌入向量。</span>
            negative_prompt_embeds<span class="token punctuation">,</span> <span class="token comment"># 负向提示词的嵌入向量。</span>
            prompt_mask<span class="token punctuation">,</span> <span class="token comment"># 正向提示词的注意力掩码。</span>
            negative_prompt_mask<span class="token punctuation">,</span> <span class="token comment"># 负向提示词的注意力掩码。</span>
        <span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>encode_prompt<span class="token punctuation">(</span>
            prompt<span class="token punctuation">,</span>
            device<span class="token punctuation">,</span>
            num_videos_per_prompt<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>do_classifier_free_guidance<span class="token punctuation">,</span>
            negative_prompt<span class="token punctuation">,</span>
            prompt_embeds<span class="token operator">=</span>prompt_embeds<span class="token punctuation">,</span>
            attention_mask<span class="token operator">=</span>attention_mask<span class="token punctuation">,</span>
            negative_prompt_embeds<span class="token operator">=</span>negative_prompt_embeds<span class="token punctuation">,</span>
            negative_attention_mask<span class="token operator">=</span>negative_attention_mask<span class="token punctuation">,</span>
            lora_scale<span class="token operator">=</span>lora_scale<span class="token punctuation">,</span>
            clip_skip<span class="token operator">=</span>self<span class="token punctuation">.</span>clip_skip<span class="token punctuation">,</span>
            data_type<span class="token operator">=</span>data_type<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token comment"># 处理多文本编码器：若存在额外的文本编码器 text_encoder_2，使用该编码器再次处理提示词。</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>text_encoder_2 <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token punctuation">(</span>
                prompt_embeds_2<span class="token punctuation">,</span>
                negative_prompt_embeds_2<span class="token punctuation">,</span>
                prompt_mask_2<span class="token punctuation">,</span>
                negative_prompt_mask_2<span class="token punctuation">,</span>
            <span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>encode_prompt<span class="token punctuation">(</span>
                prompt<span class="token punctuation">,</span>
                device<span class="token punctuation">,</span>
                num_videos_per_prompt<span class="token punctuation">,</span>
                self<span class="token punctuation">.</span>do_classifier_free_guidance<span class="token punctuation">,</span>
                negative_prompt<span class="token punctuation">,</span>
                prompt_embeds<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                attention_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                negative_prompt_embeds<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                negative_attention_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                lora_scale<span class="token operator">=</span>lora_scale<span class="token punctuation">,</span>
                clip_skip<span class="token operator">=</span>self<span class="token punctuation">.</span>clip_skip<span class="token punctuation">,</span>
                text_encoder<span class="token operator">=</span>self<span class="token punctuation">.</span>text_encoder_2<span class="token punctuation">,</span>
                data_type<span class="token operator">=</span>data_type<span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            prompt_embeds_2 <span class="token operator">=</span> <span class="token boolean">None</span>
            negative_prompt_embeds_2 <span class="token operator">=</span> <span class="token boolean">None</span>
            prompt_mask_2 <span class="token operator">=</span> <span class="token boolean">None</span>
            negative_prompt_mask_2 <span class="token operator">=</span> <span class="token boolean">None</span>

        <span class="token comment"># 处理自由分类指导（Classifier-Free Guidance）：为实现该技术，合并正向和负向提示词嵌入，避免多次前向传递。</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>do_classifier_free_guidance<span class="token punctuation">:</span>
            <span class="token comment"># 功能：如果启用了自由分类指导，则将正向和负向提示词的嵌入和掩码合并为一个批次。</span>
            <span class="token comment"># 原因：自由分类指导需要两次前向传递：一次处理负向提示词（指导无条件生成），一次处理正向提示词（指导条件生成）。</span>
            <span class="token comment"># 为了提高效率，将两组嵌入拼接在一起，作为一个批次传递给模型，避免两次单独的前向传递。</span>
            prompt_embeds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>negative_prompt_embeds<span class="token punctuation">,</span> prompt_embeds<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> prompt_mask <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                prompt_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>negative_prompt_mask<span class="token punctuation">,</span> prompt_mask<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> prompt_embeds_2 <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                prompt_embeds_2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>negative_prompt_embeds_2<span class="token punctuation">,</span> prompt_embeds_2<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> prompt_mask_2 <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                prompt_mask_2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>negative_prompt_mask_2<span class="token punctuation">,</span> prompt_mask_2<span class="token punctuation">]</span><span class="token punctuation">)</span>


        <span class="token comment"># 4. Prepare timesteps</span>
        <span class="token comment">#  准备调度器的额外参数</span>
        extra_set_timesteps_kwargs <span class="token operator">=</span> self<span class="token punctuation">.</span>prepare_extra_func_kwargs<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>scheduler<span class="token punctuation">.</span>set_timesteps<span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"n_tokens"</span><span class="token punctuation">:</span> n_tokens<span class="token punctuation">}</span>
        <span class="token punctuation">)</span>
        <span class="token comment"># 获取推理过程中需要用到的时间步 (timesteps) 和推理步数 (num_inference_steps)。</span>
        timesteps<span class="token punctuation">,</span> num_inference_steps <span class="token operator">=</span> retrieve_timesteps<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>scheduler<span class="token punctuation">,</span>
            num_inference_steps<span class="token punctuation">,</span>
            device<span class="token punctuation">,</span>
            timesteps<span class="token punctuation">,</span>
            sigmas<span class="token punctuation">,</span>
            <span class="token operator">**</span>extra_set_timesteps_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token comment"># 根据 vae_ver 调整视频长度</span>
        <span class="token keyword">if</span> <span class="token string">"884"</span> <span class="token keyword">in</span> vae_ver<span class="token punctuation">:</span>
            video_length <span class="token operator">=</span> <span class="token punctuation">(</span>video_length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">4</span> <span class="token operator">+</span> <span class="token number">1</span>
        <span class="token keyword">elif</span> <span class="token string">"888"</span> <span class="token keyword">in</span> vae_ver<span class="token punctuation">:</span>
            video_length <span class="token operator">=</span> <span class="token punctuation">(</span>video_length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">8</span> <span class="token operator">+</span> <span class="token number">1</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            video_length <span class="token operator">=</span> video_length

        <span class="token comment"># 5. Prepare latent variables</span>
        num_channels_latents <span class="token operator">=</span> self<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>config<span class="token punctuation">.</span>in_channels
        latents <span class="token operator">=</span> self<span class="token punctuation">.</span>prepare_latents<span class="token punctuation">(</span>
            batch_size <span class="token operator">*</span> num_videos_per_prompt<span class="token punctuation">,</span>
            num_channels_latents<span class="token punctuation">,</span>
            height<span class="token punctuation">,</span>
            width<span class="token punctuation">,</span>
            video_length<span class="token punctuation">,</span>
            prompt_embeds<span class="token punctuation">.</span>dtype<span class="token punctuation">,</span>
            device<span class="token punctuation">,</span>
            generator<span class="token punctuation">,</span>
            latents<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># 6. Prepare extra step kwargs. TODO: Logic should ideally just be moved out of the pipeline</span>
        extra_step_kwargs <span class="token operator">=</span> self<span class="token punctuation">.</span>prepare_extra_func_kwargs<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>scheduler<span class="token punctuation">.</span>step<span class="token punctuation">,</span> <span class="token comment"># 扩散模型的调度器中的 step 方法，负责更新噪声预测结果。</span>
            <span class="token punctuation">{<!-- --></span><span class="token string">"generator"</span><span class="token punctuation">:</span> generator<span class="token punctuation">,</span> <span class="token string">"eta"</span><span class="token punctuation">:</span> eta<span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token comment"># 一个字典，包含生成器 generator 和步长相关参数 eta。</span>
        <span class="token punctuation">)</span>
        <span class="token comment">#  确定目标数据类型及自动混合精度的设置</span>
        target_dtype <span class="token operator">=</span> PRECISION_TO_TYPE<span class="token punctuation">[</span>self<span class="token punctuation">.</span>args<span class="token punctuation">.</span>precision<span class="token punctuation">]</span>
        autocast_enabled <span class="token operator">=</span> <span class="token punctuation">(</span>
            target_dtype <span class="token operator">!=</span> torch<span class="token punctuation">.</span>float32
        <span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>args<span class="token punctuation">.</span>disable_autocast
        <span class="token comment"># 确定 VAE 的数据类型及自动混合精度设置</span>
        vae_dtype <span class="token operator">=</span> PRECISION_TO_TYPE<span class="token punctuation">[</span>self<span class="token punctuation">.</span>args<span class="token punctuation">.</span>vae_precision<span class="token punctuation">]</span>
        vae_autocast_enabled <span class="token operator">=</span> <span class="token punctuation">(</span>
            vae_dtype <span class="token operator">!=</span> torch<span class="token punctuation">.</span>float32
        <span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>args<span class="token punctuation">.</span>disable_autocast

        <span class="token comment"># 7. 初始化去噪循环的预处理步骤</span>
        <span class="token comment"># timesteps：调度器生成的时间步序列。</span>
        <span class="token comment"># num_inference_steps：推理过程中真正的去噪步数。</span>
        <span class="token comment"># self.scheduler.order：调度器的阶数（通常与预测算法的高阶插值相关）。</span>
        num_warmup_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>timesteps<span class="token punctuation">)</span> <span class="token operator">-</span> num_inference_steps <span class="token operator">*</span> self<span class="token punctuation">.</span>scheduler<span class="token punctuation">.</span>order
        self<span class="token punctuation">.</span>_num_timesteps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>timesteps<span class="token punctuation">)</span>

        <span class="token comment"># if is_progress_bar:</span>
        <span class="token comment"># progress_bar 用于显示推理过程的进度，num_inference_steps 是总推理步数。</span>
        <span class="token keyword">with</span> self<span class="token punctuation">.</span>progress_bar<span class="token punctuation">(</span>total<span class="token operator">=</span>num_inference_steps<span class="token punctuation">)</span> <span class="token keyword">as</span> progress_bar<span class="token punctuation">:</span>
            <span class="token keyword">for</span> i<span class="token punctuation">,</span> t <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>timesteps<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> self<span class="token punctuation">.</span>interrupt<span class="token punctuation">:</span>
                    <span class="token keyword">continue</span>

                <span class="token comment"># 如果启用了 分类器自由指导（do_classifier_free_guidance），则将 latents 复制两份，用于同时计算 条件预测 和 无条件预测。</span>
                <span class="token comment"># 否则，仅使用原始 latents。</span>
                latent_model_input <span class="token operator">=</span> <span class="token punctuation">(</span>
                    torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>latents<span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span>
                    <span class="token keyword">if</span> self<span class="token punctuation">.</span>do_classifier_free_guidance
                    <span class="token keyword">else</span> latents
                <span class="token punctuation">)</span>
                <span class="token comment"># 调用 scheduler 的 scale_model_input 方法，对 latent_model_input 在当前时间步 t 上进行预处理。</span>
                <span class="token comment"># 这个缩放操作可能根据调度器的实现涉及到归一化或其他调整。</span>
                latent_model_input <span class="token operator">=</span> self<span class="token punctuation">.</span>scheduler<span class="token punctuation">.</span>scale_model_input<span class="token punctuation">(</span>
                    latent_model_input<span class="token punctuation">,</span> t
                <span class="token punctuation">)</span>
                <span class="token comment"># t_expand 将时间步 t 扩展到与 latent_model_input 的批量维度一致。</span>
                <span class="token comment"># 如果 embedded_guidance_scale 存在，则创建扩展的指导参数 guidance_expand，用于对模型预测进行额外控制。</span>
                t_expand <span class="token operator">=</span> t<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>latent_model_input<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                guidance_expand <span class="token operator">=</span> <span class="token punctuation">(</span>
                    torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>
                        <span class="token punctuation">[</span>embedded_guidance_scale<span class="token punctuation">]</span> <span class="token operator">*</span> latent_model_input<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>
                        device<span class="token operator">=</span>device<span class="token punctuation">,</span>
                    <span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>target_dtype<span class="token punctuation">)</span>
                    <span class="token operator">*</span> <span class="token number">1000.0</span>
                    <span class="token keyword">if</span> embedded_guidance_scale <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
                    <span class="token keyword">else</span> <span class="token boolean">None</span>
                <span class="token punctuation">)</span>

                <span class="token comment"># 使用 Transformer 模型预测噪声残差</span>
                <span class="token keyword">with</span> torch<span class="token punctuation">.</span>autocast<span class="token punctuation">(</span>
                    device_type<span class="token operator">=</span><span class="token string">"cuda"</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>target_dtype<span class="token punctuation">,</span> enabled<span class="token operator">=</span>autocast_enabled
                <span class="token punctuation">)</span><span class="token punctuation">:</span>
                    noise_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>transformer<span class="token punctuation">(</span>  <span class="token comment"># For an input image (129, 192, 336) (1, 256, 256)</span>
                        latent_model_input<span class="token punctuation">,</span>  <span class="token comment"># 当前的潜变量输入 [2, 16, 33, 24, 42]</span>
                        t_expand<span class="token punctuation">,</span>  <span class="token comment"># 时间步信息 [2]</span>
                        text_states<span class="token operator">=</span>prompt_embeds<span class="token punctuation">,</span>  <span class="token comment"># 与文本提示相关的嵌入向量 [2, 256, 4096]</span>
                        text_mask<span class="token operator">=</span>prompt_mask<span class="token punctuation">,</span>  <span class="token comment"># [2, 256]</span>
                        text_states_2<span class="token operator">=</span>prompt_embeds_2<span class="token punctuation">,</span>  <span class="token comment"># [2, 768]</span>
                        freqs_cos<span class="token operator">=</span>freqs_cis<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 频率信息，用于特定的时间步缩放 [seqlen, head_dim]</span>
                        freqs_sin<span class="token operator">=</span>freqs_cis<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># [seqlen, head_dim]</span>
                        guidance<span class="token operator">=</span>guidance_expand<span class="token punctuation">,</span> <span class="token comment"># 指导参数，用于条件生成</span>
                        return_dict<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                    <span class="token punctuation">)</span><span class="token punctuation">[</span>
                        <span class="token string">"x"</span>
                    <span class="token punctuation">]</span>

                <span class="token comment"># 分类器自由指导的噪声调整</span>
                <span class="token keyword">if</span> self<span class="token punctuation">.</span>do_classifier_free_guidance<span class="token punctuation">:</span>
                    noise_pred_uncond<span class="token punctuation">,</span> noise_pred_text <span class="token operator">=</span> noise_pred<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment"># 无条件预测的噪声；条件预测的噪声（基于文本提示）</span>
                    noise_pred <span class="token operator">=</span> noise_pred_uncond <span class="token operator">+</span> self<span class="token punctuation">.</span>guidance_scale <span class="token operator">*</span> <span class="token punctuation">(</span>
                        noise_pred_text <span class="token operator">-</span> noise_pred_uncond
                    <span class="token punctuation">)</span>
                <span class="token comment"># 噪声重缩放</span>
                <span class="token keyword">if</span> self<span class="token punctuation">.</span>do_classifier_free_guidance <span class="token keyword">and</span> self<span class="token punctuation">.</span>guidance_rescale <span class="token operator">&gt;</span> <span class="token number">0.0</span><span class="token punctuation">:</span>
                    <span class="token comment"># Based on 3.4. in https://arxiv.org/pdf/2305.08891.pdf</span>
                    noise_pred <span class="token operator">=</span> rescale_noise_cfg<span class="token punctuation">(</span>
                        noise_pred<span class="token punctuation">,</span>
                        noise_pred_text<span class="token punctuation">,</span>
                        guidance_rescale<span class="token operator">=</span>self<span class="token punctuation">.</span>guidance_rescale<span class="token punctuation">,</span>
                    <span class="token punctuation">)</span>

                <span class="token comment"># 使用调度器更新潜变量</span>
                <span class="token comment"># compute the previous noisy sample x_t -&gt; x_t-1</span>
                latents <span class="token operator">=</span> self<span class="token punctuation">.</span>scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>
                    noise_pred<span class="token punctuation">,</span> t<span class="token punctuation">,</span> latents<span class="token punctuation">,</span> <span class="token operator">**</span>extra_step_kwargs<span class="token punctuation">,</span> return_dict<span class="token operator">=</span><span class="token boolean">False</span>
                <span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                <span class="token comment"># callback_on_step_end 函数，则在每步结束时调用，用于自定义操作（如日志记录、结果保存）。</span>
                <span class="token comment"># 更新潜变量和提示嵌入向量。</span>
                <span class="token keyword">if</span> callback_on_step_end <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                    callback_kwargs <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
                    <span class="token keyword">for</span> k <span class="token keyword">in</span> callback_on_step_end_tensor_inputs<span class="token punctuation">:</span>
                        callback_kwargs<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">locals</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span>
                    callback_outputs <span class="token operator">=</span> callback_on_step_end<span class="token punctuation">(</span>self<span class="token punctuation">,</span> i<span class="token punctuation">,</span> t<span class="token punctuation">,</span> callback_kwargs<span class="token punctuation">)</span>

                    latents <span class="token operator">=</span> callback_outputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"latents"</span><span class="token punctuation">,</span> latents<span class="token punctuation">)</span>
                    prompt_embeds <span class="token operator">=</span> callback_outputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"prompt_embeds"</span><span class="token punctuation">,</span> prompt_embeds<span class="token punctuation">)</span>
                    negative_prompt_embeds <span class="token operator">=</span> callback_outputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span>
                        <span class="token string">"negative_prompt_embeds"</span><span class="token punctuation">,</span> negative_prompt_embeds
                    <span class="token punctuation">)</span>

                <span class="token comment"># 进度条更新与其他回调</span>
                <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>timesteps<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span> <span class="token keyword">or</span> <span class="token punctuation">(</span>
                    <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> num_warmup_steps <span class="token keyword">and</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>scheduler<span class="token punctuation">.</span>order <span class="token operator">==</span> <span class="token number">0</span>
                <span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token keyword">if</span> progress_bar <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                        progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    <span class="token keyword">if</span> callback <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> i <span class="token operator">%</span> callback_steps <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                        step_idx <span class="token operator">=</span> i <span class="token operator">//</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>scheduler<span class="token punctuation">,</span> <span class="token string">"order"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
                        callback<span class="token punctuation">(</span>step_idx<span class="token punctuation">,</span> t<span class="token punctuation">,</span> latents<span class="token punctuation">)</span>
        <span class="token comment"># 从潜变量（latent space）解码生成图像</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> output_type <span class="token operator">==</span> <span class="token string">"latent"</span><span class="token punctuation">:</span>
            <span class="token comment">#  潜变量维度的扩展检查</span>
            expand_temporal_dim <span class="token operator">=</span> <span class="token boolean">False</span>
            <span class="token comment"># 如果形状为 4D ([batch_size, channels, height, width])：</span>
            <span class="token comment"># 如果 VAE 是 3D 自回归模型（AutoencoderKLCausal3D），则对潜变量增加一个时间维度 (unsqueeze(2))。</span>
            <span class="token comment"># 设置 expand_temporal_dim=True，标记后续需要移除该额外维度。</span>
            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>latents<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">4</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>vae<span class="token punctuation">,</span> AutoencoderKLCausal3D<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    latents <span class="token operator">=</span> latents<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
                    expand_temporal_dim <span class="token operator">=</span> <span class="token boolean">True</span>
            <span class="token comment"># 如果形状为 5D ([batch_size, channels, frames, height, width])，则不需要操作。</span>
            <span class="token keyword">elif</span> <span class="token builtin">len</span><span class="token punctuation">(</span>latents<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">5</span><span class="token punctuation">:</span>
                <span class="token keyword">pass</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                    <span class="token string-interpolation"><span class="token string">f"Only support latents with shape (b, c, h, w) or (b, c, f, h, w), but got </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>latents<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">."</span></span>
                <span class="token punctuation">)</span>
            <span class="token comment"># 潜变量的缩放与偏移</span>
            <span class="token comment"># 检查 VAE 配置中是否定义了 shift_factor（偏移因子）</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>
                <span class="token builtin">hasattr</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>vae<span class="token punctuation">.</span>config<span class="token punctuation">,</span> <span class="token string">"shift_factor"</span><span class="token punctuation">)</span>
                <span class="token keyword">and</span> self<span class="token punctuation">.</span>vae<span class="token punctuation">.</span>config<span class="token punctuation">.</span>shift_factor
            <span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 如果存在，则对潜变量执行缩放和偏移操作</span>
                latents <span class="token operator">=</span> <span class="token punctuation">(</span>
                    latents <span class="token operator">/</span> self<span class="token punctuation">.</span>vae<span class="token punctuation">.</span>config<span class="token punctuation">.</span>scaling_factor
                    <span class="token operator">+</span> self<span class="token punctuation">.</span>vae<span class="token punctuation">.</span>config<span class="token punctuation">.</span>shift_factor
                <span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span> <span class="token comment"># 如果 shift_factor 不存在，仅进行缩放操作</span>
                latents <span class="token operator">=</span> latents <span class="token operator">/</span> self<span class="token punctuation">.</span>vae<span class="token punctuation">.</span>config<span class="token punctuation">.</span>scaling_factor

            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>autocast<span class="token punctuation">(</span>
                device_type<span class="token operator">=</span><span class="token string">"cuda"</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>vae_dtype<span class="token punctuation">,</span> enabled<span class="token operator">=</span>vae_autocast_enabled
            <span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> enable_tiling<span class="token punctuation">:</span>
                    <span class="token comment"># 调用 VAE 的 enable_tiling() 方法，可能用于解码较大的图像块。</span>
                    self<span class="token punctuation">.</span>vae<span class="token punctuation">.</span>enable_tiling<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    <span class="token comment"># 使用 VAE（变分自编码器）的 decode 方法将潜变量解码为图像。</span>
                    image <span class="token operator">=</span> self<span class="token punctuation">.</span>vae<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>
                        latents<span class="token punctuation">,</span> return_dict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>generator
                    <span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    image <span class="token operator">=</span> self<span class="token punctuation">.</span>vae<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>
                        latents<span class="token punctuation">,</span> return_dict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>generator
                    <span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            <span class="token comment"># 如果添加了时间维度（expand_temporal_dim=True），或者解码出的图像在时间维度上只有一个帧，则移除时间维度。</span>
            <span class="token keyword">if</span> expand_temporal_dim <span class="token keyword">or</span> image<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
                image <span class="token operator">=</span> image<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>

        <span class="token keyword">else</span><span class="token punctuation">:</span>
            image <span class="token operator">=</span> latents
        <span class="token comment"># 图像归一化</span>
        image <span class="token operator">=</span> <span class="token punctuation">(</span>image <span class="token operator">/</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 将图像移动到 CPU，并转换为 float32 类型。这是为了确保图像兼容性，无论之前是否使用了混合精度</span>
        image <span class="token operator">=</span> image<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 调用 maybe_free_model_hooks() 方法，可能会释放模型占用的内存资源，尤其是在内存有限的 GPU 上有用。</span>
        self<span class="token punctuation">.</span>maybe_free_model_hooks<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 如果不需要返回字典（return_dict=False），则直接返回处理后的图像</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> return_dict<span class="token punctuation">:</span>
            <span class="token keyword">return</span> image

        <span class="token keyword">return</span> HunyuanVideoPipelineOutput<span class="token punctuation">(</span>videos<span class="token operator">=</span>image<span class="token punctuation">)</span>


</code></pre>
    <h3>
     <a id="34__1200">
     </a>
     3.4 模型结构
    </h3>
    <p>
     模型结构文件是：hyvideo/modules/models.py，主要包括双流块、单流块和主干网络。
    </p>
    <p>
     <img alt="model" src="https://i-blog.csdnimg.cn/direct/e93e5ba74c914c2c8ed053eeeef11607.png"/>
    </p>
    <h4>
     <a id="341__MMDoubleStreamBlock_1209">
     </a>
     3.4.1 双流块 （MMDoubleStreamBlock）
    </h4>
    <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">MMDoubleStreamBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A multimodal dit block with seperate modulation for
    text and image/video, see more details (SD3): https://arxiv.org/abs/2403.03206
                                     (Flux.1): https://github.com/black-forest-labs/flux
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        hidden_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token comment"># 模型隐藏层维度。</span>
        heads_num<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token comment"># 多头注意力的头数。</span>
        mlp_width_ratio<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token comment"># MLP 中隐藏层宽度与 hidden_size 的比率。</span>
        mlp_act_type<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"gelu_tanh"</span><span class="token punctuation">,</span> <span class="token comment"># 激活函数的类型（默认 gelu_tanh）</span>
        qk_norm<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment"># 是否对 Query 和 Key 启用归一化。</span>
        qk_norm_type<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"rms"</span><span class="token punctuation">,</span> <span class="token comment"># Query 和 Key 归一化的方法（默认 rms）。</span>
        qkv_bias<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token comment"># QKV 投影中是否启用偏置项。</span>
        dtype<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>dtype<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token comment"># 张量的数据类型和设备。</span>
        device<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        factory_kwargs <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"device"</span><span class="token punctuation">:</span> device<span class="token punctuation">,</span> <span class="token string">"dtype"</span><span class="token punctuation">:</span> dtype<span class="token punctuation">}</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">False</span>
        self<span class="token punctuation">.</span>heads_num <span class="token operator">=</span> heads_num
        head_dim <span class="token operator">=</span> hidden_size <span class="token operator">//</span> heads_num
        mlp_hidden_dim <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>hidden_size <span class="token operator">*</span> mlp_width_ratio<span class="token punctuation">)</span>
        <span class="token comment">### 图像模态</span>
        <span class="token comment"># 模态调制模块：使用 ModulateDiT，为图像和文本生成 6 组参数（shift、scale、gate）。</span>
        self<span class="token punctuation">.</span>img_mod <span class="token operator">=</span> ModulateDiT<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span>
            factor<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>
            act_layer<span class="token operator">=</span>get_activation_layer<span class="token punctuation">(</span><span class="token string">"silu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token operator">**</span>factory_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token comment"># 归一化</span>
        self<span class="token punctuation">.</span>img_norm1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>
        <span class="token comment"># QKV 投影层：通过全连接层计算 Query、Key 和 Value</span>
        self<span class="token punctuation">.</span>img_attn_qkv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span> hidden_size <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>
        <span class="token comment"># 归一化模块</span>
        qk_norm_layer <span class="token operator">=</span> get_norm_layer<span class="token punctuation">(</span>qk_norm_type<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>img_attn_q_norm <span class="token operator">=</span> <span class="token punctuation">(</span>
            qk_norm_layer<span class="token punctuation">(</span>head_dim<span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs<span class="token punctuation">)</span>
            <span class="token keyword">if</span> qk_norm
            <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>img_attn_k_norm <span class="token operator">=</span> <span class="token punctuation">(</span>
            qk_norm_layer<span class="token punctuation">(</span>head_dim<span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs<span class="token punctuation">)</span>
            <span class="token keyword">if</span> qk_norm
            <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>img_attn_proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>img_norm2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>img_mlp <span class="token operator">=</span> MLP<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span>
            mlp_hidden_dim<span class="token punctuation">,</span>
            act_layer<span class="token operator">=</span>get_activation_layer<span class="token punctuation">(</span>mlp_act_type<span class="token punctuation">)</span><span class="token punctuation">,</span>
            bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            <span class="token operator">**</span>factory_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        <span class="token comment">### 文本模态</span>
        self<span class="token punctuation">.</span>txt_mod <span class="token operator">=</span> ModulateDiT<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span>
            factor<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>
            act_layer<span class="token operator">=</span>get_activation_layer<span class="token punctuation">(</span><span class="token string">"silu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token operator">**</span>factory_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>txt_norm1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>txt_attn_qkv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span> hidden_size <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>txt_attn_q_norm <span class="token operator">=</span> <span class="token punctuation">(</span>
            qk_norm_layer<span class="token punctuation">(</span>head_dim<span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs<span class="token punctuation">)</span>
            <span class="token keyword">if</span> qk_norm
            <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>txt_attn_k_norm <span class="token operator">=</span> <span class="token punctuation">(</span>
            qk_norm_layer<span class="token punctuation">(</span>head_dim<span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs<span class="token punctuation">)</span>
            <span class="token keyword">if</span> qk_norm
            <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>txt_attn_proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>txt_norm2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>txt_mlp <span class="token operator">=</span> MLP<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span>
            mlp_hidden_dim<span class="token punctuation">,</span>
            act_layer<span class="token operator">=</span>get_activation_layer<span class="token punctuation">(</span>mlp_act_type<span class="token punctuation">)</span><span class="token punctuation">,</span>
            bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            <span class="token operator">**</span>factory_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>hybrid_seq_parallel_attn <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">enable_deterministic</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>

    <span class="token keyword">def</span> <span class="token function">disable_deterministic</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">False</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        img<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> <span class="token comment"># 图像张量 (B, L_img, hidden_size)</span>
        txt<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> <span class="token comment"># 文本张量 (B, L_txt, hidden_size)</span>
        vec<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> <span class="token comment"># 特征向量，用于调制</span>
        cu_seqlens_q<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># Query 的累积序列长度</span>
        cu_seqlens_kv<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token comment"># Key/Value 的累积序列长度</span>
        max_seqlen_q<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>   <span class="token comment"># Query 最大序列长度</span>
        max_seqlen_kv<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># Key/Value 最大序列长度</span>
        freqs_cis<span class="token punctuation">:</span> <span class="token builtin">tuple</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token comment"># 可选的旋转位置编码参数</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tuple<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token comment"># vec 特征向量通过 ModulateDiT 模块分别为图像和文本模态生成 6 组调制参数：</span>
        <span class="token punctuation">(</span>
            img_mod1_shift<span class="token punctuation">,</span>
            img_mod1_scale<span class="token punctuation">,</span>
            img_mod1_gate<span class="token punctuation">,</span>
            img_mod2_shift<span class="token punctuation">,</span>
            img_mod2_scale<span class="token punctuation">,</span>
            img_mod2_gate<span class="token punctuation">,</span>
        <span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>img_mod<span class="token punctuation">(</span>vec<span class="token punctuation">)</span><span class="token punctuation">.</span>chunk<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span>
            txt_mod1_shift<span class="token punctuation">,</span>
            txt_mod1_scale<span class="token punctuation">,</span>
            txt_mod1_gate<span class="token punctuation">,</span>
            txt_mod2_shift<span class="token punctuation">,</span>
            txt_mod2_scale<span class="token punctuation">,</span>
            txt_mod2_gate<span class="token punctuation">,</span>
        <span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>txt_mod<span class="token punctuation">(</span>vec<span class="token punctuation">)</span><span class="token punctuation">.</span>chunk<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token triple-quoted-string string">'''图像模态的前向处理'''</span>
        <span class="token comment"># Layernorm 归一化</span>
        img_modulated <span class="token operator">=</span> self<span class="token punctuation">.</span>img_norm1<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
        <span class="token comment"># 调制函数 modulate 进行标准化和缩放</span>
        img_modulated <span class="token operator">=</span> modulate<span class="token punctuation">(</span>
            img_modulated<span class="token punctuation">,</span> shift<span class="token operator">=</span>img_mod1_shift<span class="token punctuation">,</span> scale<span class="token operator">=</span>img_mod1_scale
        <span class="token punctuation">)</span>
        <span class="token comment"># 得到 Query、Key 和 Value</span>
        img_qkv <span class="token operator">=</span> self<span class="token punctuation">.</span>img_attn_qkv<span class="token punctuation">(</span>img_modulated<span class="token punctuation">)</span>
        img_q<span class="token punctuation">,</span> img_k<span class="token punctuation">,</span> img_v <span class="token operator">=</span> rearrange<span class="token punctuation">(</span>
            img_qkv<span class="token punctuation">,</span> <span class="token string">"B L (K H D) -&gt; K B L H D"</span><span class="token punctuation">,</span> K<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> H<span class="token operator">=</span>self<span class="token punctuation">.</span>heads_num
        <span class="token punctuation">)</span>
        <span class="token comment"># 对 Query 和 Key 进行归一化。</span>
        img_q <span class="token operator">=</span> self<span class="token punctuation">.</span>img_attn_q_norm<span class="token punctuation">(</span>img_q<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>img_v<span class="token punctuation">)</span>
        img_k <span class="token operator">=</span> self<span class="token punctuation">.</span>img_attn_k_norm<span class="token punctuation">(</span>img_k<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>img_v<span class="token punctuation">)</span>

        <span class="token comment"># 对 Query 和 Key 应用旋转位置编码。</span>
        <span class="token keyword">if</span> freqs_cis <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            img_qq<span class="token punctuation">,</span> img_kk <span class="token operator">=</span> apply_rotary_emb<span class="token punctuation">(</span>img_q<span class="token punctuation">,</span> img_k<span class="token punctuation">,</span> freqs_cis<span class="token punctuation">,</span> head_first<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>
                img_qq<span class="token punctuation">.</span>shape <span class="token operator">==</span> img_q<span class="token punctuation">.</span>shape <span class="token keyword">and</span> img_kk<span class="token punctuation">.</span>shape <span class="token operator">==</span> img_k<span class="token punctuation">.</span>shape
            <span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"img_kk: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>img_qq<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, img_q: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>img_q<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, img_kk: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>img_kk<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, img_k: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>img_k<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">"</span></span>
            img_q<span class="token punctuation">,</span> img_k <span class="token operator">=</span> img_qq<span class="token punctuation">,</span> img_kk

        <span class="token triple-quoted-string string">'''文本模态的前向处理'''</span>
        txt_modulated <span class="token operator">=</span> self<span class="token punctuation">.</span>txt_norm1<span class="token punctuation">(</span>txt<span class="token punctuation">)</span>
        txt_modulated <span class="token operator">=</span> modulate<span class="token punctuation">(</span>
            txt_modulated<span class="token punctuation">,</span> shift<span class="token operator">=</span>txt_mod1_shift<span class="token punctuation">,</span> scale<span class="token operator">=</span>txt_mod1_scale
        <span class="token punctuation">)</span>
        txt_qkv <span class="token operator">=</span> self<span class="token punctuation">.</span>txt_attn_qkv<span class="token punctuation">(</span>txt_modulated<span class="token punctuation">)</span>
        txt_q<span class="token punctuation">,</span> txt_k<span class="token punctuation">,</span> txt_v <span class="token operator">=</span> rearrange<span class="token punctuation">(</span>
            txt_qkv<span class="token punctuation">,</span> <span class="token string">"B L (K H D) -&gt; K B L H D"</span><span class="token punctuation">,</span> K<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> H<span class="token operator">=</span>self<span class="token punctuation">.</span>heads_num
        <span class="token punctuation">)</span>
        <span class="token comment"># Apply QK-Norm if needed.</span>
        txt_q <span class="token operator">=</span> self<span class="token punctuation">.</span>txt_attn_q_norm<span class="token punctuation">(</span>txt_q<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>txt_v<span class="token punctuation">)</span>
        txt_k <span class="token operator">=</span> self<span class="token punctuation">.</span>txt_attn_k_norm<span class="token punctuation">(</span>txt_k<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>txt_v<span class="token punctuation">)</span>

        <span class="token comment"># 将图像和文本的 Query、Key、Value 拼接</span>
        q <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>img_q<span class="token punctuation">,</span> txt_q<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        k <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>img_k<span class="token punctuation">,</span> txt_k<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        v <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>img_v<span class="token punctuation">,</span> txt_v<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>
            cu_seqlens_q<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">2</span> <span class="token operator">*</span> img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"cu_seqlens_q.shape:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>cu_seqlens_q<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, img.shape[0]:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span>
        
        <span class="token comment"># 多模态融合注意力计算</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>hybrid_seq_parallel_attn<span class="token punctuation">:</span>
            attn <span class="token operator">=</span> attention<span class="token punctuation">(</span>
                q<span class="token punctuation">,</span>
                k<span class="token punctuation">,</span>
                v<span class="token punctuation">,</span>
                cu_seqlens_q<span class="token operator">=</span>cu_seqlens_q<span class="token punctuation">,</span>
                cu_seqlens_kv<span class="token operator">=</span>cu_seqlens_kv<span class="token punctuation">,</span>
                max_seqlen_q<span class="token operator">=</span>max_seqlen_q<span class="token punctuation">,</span>
                max_seqlen_kv<span class="token operator">=</span>max_seqlen_kv<span class="token punctuation">,</span>
                batch_size<span class="token operator">=</span>img_k<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            attn <span class="token operator">=</span> parallel_attention<span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>hybrid_seq_parallel_attn<span class="token punctuation">,</span>
                q<span class="token punctuation">,</span>
                k<span class="token punctuation">,</span>
                v<span class="token punctuation">,</span>
                img_q_len<span class="token operator">=</span>img_q<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                img_kv_len<span class="token operator">=</span>img_k<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                cu_seqlens_q<span class="token operator">=</span>cu_seqlens_q<span class="token punctuation">,</span>
                cu_seqlens_kv<span class="token operator">=</span>cu_seqlens_kv
            <span class="token punctuation">)</span>
            
        <span class="token comment"># 最终将注意力结果拆分为图像部分 img_attn 和文本部分 txt_attn</span>
        img_attn<span class="token punctuation">,</span> txt_attn <span class="token operator">=</span> attn<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span> img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> attn<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>

        <span class="token triple-quoted-string string">'''图像模态的更新'''</span>
        <span class="token comment"># 将注意力结果通过残差连接更新图像特征，并通过 MLP 进一步增强</span>
        img <span class="token operator">=</span> img <span class="token operator">+</span> apply_gate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_attn_proj<span class="token punctuation">(</span>img_attn<span class="token punctuation">)</span><span class="token punctuation">,</span> gate<span class="token operator">=</span>img_mod1_gate<span class="token punctuation">)</span>
        img <span class="token operator">=</span> img <span class="token operator">+</span> apply_gate<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>img_mlp<span class="token punctuation">(</span>
                modulate<span class="token punctuation">(</span>
                    self<span class="token punctuation">.</span>img_norm2<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">,</span> shift<span class="token operator">=</span>img_mod2_shift<span class="token punctuation">,</span> scale<span class="token operator">=</span>img_mod2_scale
                <span class="token punctuation">)</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>
            gate<span class="token operator">=</span>img_mod2_gate<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        <span class="token triple-quoted-string string">'''文本模态的更新'''</span>
        txt <span class="token operator">=</span> txt <span class="token operator">+</span> apply_gate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>txt_attn_proj<span class="token punctuation">(</span>txt_attn<span class="token punctuation">)</span><span class="token punctuation">,</span> gate<span class="token operator">=</span>txt_mod1_gate<span class="token punctuation">)</span>
        txt <span class="token operator">=</span> txt <span class="token operator">+</span> apply_gate<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>txt_mlp<span class="token punctuation">(</span>
                modulate<span class="token punctuation">(</span>
                    self<span class="token punctuation">.</span>txt_norm2<span class="token punctuation">(</span>txt<span class="token punctuation">)</span><span class="token punctuation">,</span> shift<span class="token operator">=</span>txt_mod2_shift<span class="token punctuation">,</span> scale<span class="token operator">=</span>txt_mod2_scale
                <span class="token punctuation">)</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>
            gate<span class="token operator">=</span>txt_mod2_gate<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token comment"># 返回更新后的图像特征和文本特征</span>
        <span class="token keyword">return</span> img<span class="token punctuation">,</span> txt


</code></pre>
    <h4>
     <a id="342__MMSingleStreamBlock_1459">
     </a>
     3.4.2 单流块 （MMSingleStreamBlock）
    </h4>
    <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">MMSingleStreamBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A DiT block with parallel linear layers as described in
    https://arxiv.org/abs/2302.05442 and adapted modulation interface.
    Also refer to (SD3): https://arxiv.org/abs/2403.03206
                  (Flux.1): https://github.com/black-forest-labs/flux
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        hidden_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token comment"># 隐藏层的维度大小，用于表示特征的维度。</span>
        heads_num<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token comment"># 注意力头的数量。</span>
        mlp_width_ratio<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">4.0</span><span class="token punctuation">,</span> <span class="token comment"># 用于确定多层感知机 (MLP) 的隐藏层宽度比例，默认值为 4.0</span>
        mlp_act_type<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"gelu_tanh"</span><span class="token punctuation">,</span> <span class="token comment"># 激活函数类型</span>
        qk_norm<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># 决定是否对 Query 和 Key 应用归一化</span>
        qk_norm_type<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"rms"</span><span class="token punctuation">,</span> <span class="token comment"># 指定 Query 和 Key 的归一化方式，例如 rms（均方根归一化）</span>
        qk_scale<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token comment"># 自定义缩放因子（用于注意力分数计算中的缩放）</span>
        dtype<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>dtype<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token comment"># 控制数据类型</span>
        device<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token comment"># 控制缩放因子</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        factory_kwargs <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"device"</span><span class="token punctuation">:</span> device<span class="token punctuation">,</span> <span class="token string">"dtype"</span><span class="token punctuation">:</span> dtype<span class="token punctuation">}</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">False</span>
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size
        self<span class="token punctuation">.</span>heads_num <span class="token operator">=</span> heads_num
        head_dim <span class="token operator">=</span> hidden_size <span class="token operator">//</span> heads_num
        mlp_hidden_dim <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>hidden_size <span class="token operator">*</span> mlp_width_ratio<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>mlp_hidden_dim <span class="token operator">=</span> mlp_hidden_dim
        self<span class="token punctuation">.</span>scale <span class="token operator">=</span> qk_scale <span class="token keyword">or</span> head_dim <span class="token operator">**</span> <span class="token operator">-</span><span class="token number">0.5</span>

        <span class="token comment"># qkv and mlp_in</span>
        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span> hidden_size <span class="token operator">*</span> <span class="token number">3</span> <span class="token operator">+</span> mlp_hidden_dim<span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>
        <span class="token comment"># proj and mlp_out</span>
        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>
            hidden_size <span class="token operator">+</span> mlp_hidden_dim<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>

        qk_norm_layer <span class="token operator">=</span> get_norm_layer<span class="token punctuation">(</span>qk_norm_type<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>q_norm <span class="token operator">=</span> <span class="token punctuation">(</span>
            qk_norm_layer<span class="token punctuation">(</span>head_dim<span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs<span class="token punctuation">)</span>
            <span class="token keyword">if</span> qk_norm
            <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>k_norm <span class="token operator">=</span> <span class="token punctuation">(</span>
            qk_norm_layer<span class="token punctuation">(</span>head_dim<span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs<span class="token punctuation">)</span>
            <span class="token keyword">if</span> qk_norm
            <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>pre_norm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>mlp_act <span class="token operator">=</span> get_activation_layer<span class="token punctuation">(</span>mlp_act_type<span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>modulation <span class="token operator">=</span> ModulateDiT<span class="token punctuation">(</span>
            hidden_size<span class="token punctuation">,</span>
            factor<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
            act_layer<span class="token operator">=</span>get_activation_layer<span class="token punctuation">(</span><span class="token string">"silu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token operator">**</span>factory_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>hybrid_seq_parallel_attn <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">enable_deterministic</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>

    <span class="token keyword">def</span> <span class="token function">disable_deterministic</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">False</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        x<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> <span class="token comment"># x: 输入特征张量，形状为 (batch_size, seq_len, hidden_size)</span>
        vec<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> <span class="token comment"># vec: 辅助特征向量，通常来自调制器</span>
        txt_len<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token comment"># txt_len: 文本序列长度，用于区分图像和文本部分。</span>
        cu_seqlens_q<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 累积序列长度，用于高效的分段注意力计算。</span>
        cu_seqlens_kv<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        max_seqlen_q<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span><span class="token comment"># Query 和 Key/Value 的最大序列长度。</span>
        max_seqlen_kv<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        freqs_cis<span class="token punctuation">:</span> Tuple<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token comment"># 可选的旋转位置编码（RoPE）</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">:</span>
        <span class="token comment"># 调用 modulation 获取调制参数 mod_shift、mod_scale 和 mod_gate。</span>
        mod_shift<span class="token punctuation">,</span> mod_scale<span class="token punctuation">,</span> mod_gate <span class="token operator">=</span> self<span class="token punctuation">.</span>modulation<span class="token punctuation">(</span>vec<span class="token punctuation">)</span><span class="token punctuation">.</span>chunk<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 对输入 x 应用 LayerNorm，并进行调制（即元素级缩放和偏移）</span>
        x_mod <span class="token operator">=</span> modulate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pre_norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> shift<span class="token operator">=</span>mod_shift<span class="token punctuation">,</span> scale<span class="token operator">=</span>mod_scale<span class="token punctuation">)</span>
        <span class="token comment"># 将 x_mod 映射到 qkv 和 mlp 两个部分。</span>
        qkv<span class="token punctuation">,</span> mlp <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>x_mod<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>mlp_hidden_dim<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>
        <span class="token punctuation">)</span>
        <span class="token comment"># qkv 被分为 Query (q)、Key (k)、Value (v) 三个张量，形状为 (batch_size, seq_len, heads_num, head_dim)。</span>
        q<span class="token punctuation">,</span> k<span class="token punctuation">,</span> v <span class="token operator">=</span> rearrange<span class="token punctuation">(</span>qkv<span class="token punctuation">,</span> <span class="token string">"B L (K H D) -&gt; K B L H D"</span><span class="token punctuation">,</span> K<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> H<span class="token operator">=</span>self<span class="token punctuation">.</span>heads_num<span class="token punctuation">)</span>

        <span class="token comment"># 对 Query 和 Key 应用归一化。</span>
        q <span class="token operator">=</span> self<span class="token punctuation">.</span>q_norm<span class="token punctuation">(</span>q<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>v<span class="token punctuation">)</span>
        k <span class="token operator">=</span> self<span class="token punctuation">.</span>k_norm<span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>v<span class="token punctuation">)</span>

        <span class="token comment"># 旋转位置编码 (RoPE)</span>
        <span class="token keyword">if</span> freqs_cis <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            img_q<span class="token punctuation">,</span> txt_q <span class="token operator">=</span> q<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span>txt_len<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> q<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span>txt_len<span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
            img_k<span class="token punctuation">,</span> txt_k <span class="token operator">=</span> k<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span>txt_len<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> k<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span>txt_len<span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
            <span class="token comment"># 分别对图像和文本部分应用旋转位置编码</span>
            img_qq<span class="token punctuation">,</span> img_kk <span class="token operator">=</span> apply_rotary_emb<span class="token punctuation">(</span>img_q<span class="token punctuation">,</span> img_k<span class="token punctuation">,</span> freqs_cis<span class="token punctuation">,</span> head_first<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
            <span class="token keyword">assert</span> <span class="token punctuation">(</span>
                img_qq<span class="token punctuation">.</span>shape <span class="token operator">==</span> img_q<span class="token punctuation">.</span>shape <span class="token keyword">and</span> img_kk<span class="token punctuation">.</span>shape <span class="token operator">==</span> img_k<span class="token punctuation">.</span>shape
            <span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"img_kk: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>img_qq<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, img_q: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>img_q<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, img_kk: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>img_kk<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, img_k: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>img_k<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">"</span></span>
            img_q<span class="token punctuation">,</span> img_k <span class="token operator">=</span> img_qq<span class="token punctuation">,</span> img_kk
            <span class="token comment"># 图像部分和文本部分的 Query/Key 在编码后重新拼接。</span>
            q <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>img_q<span class="token punctuation">,</span> txt_q<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            k <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>img_k<span class="token punctuation">,</span> txt_k<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># Compute attention.</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>
            cu_seqlens_q<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">2</span> <span class="token operator">*</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"cu_seqlens_q.shape:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>cu_seqlens_q<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, x.shape[0]:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span>
        
        <span class="token comment"># attention computation start</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>hybrid_seq_parallel_attn<span class="token punctuation">:</span>
            <span class="token comment"># 如果没有启用并行注意力机制，调用标准注意力函数 attention</span>
            attn <span class="token operator">=</span> attention<span class="token punctuation">(</span>
                q<span class="token punctuation">,</span>
                k<span class="token punctuation">,</span>
                v<span class="token punctuation">,</span>
                cu_seqlens_q<span class="token operator">=</span>cu_seqlens_q<span class="token punctuation">,</span>
                cu_seqlens_kv<span class="token operator">=</span>cu_seqlens_kv<span class="token punctuation">,</span>
                max_seqlen_q<span class="token operator">=</span>max_seqlen_q<span class="token punctuation">,</span>
                max_seqlen_kv<span class="token operator">=</span>max_seqlen_kv<span class="token punctuation">,</span>
                batch_size<span class="token operator">=</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># 否则，使用并行注意力机制 parallel_attention</span>
            attn <span class="token operator">=</span> parallel_attention<span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>hybrid_seq_parallel_attn<span class="token punctuation">,</span>
                q<span class="token punctuation">,</span>
                k<span class="token punctuation">,</span>
                v<span class="token punctuation">,</span>
                img_q_len<span class="token operator">=</span>img_q<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                img_kv_len<span class="token operator">=</span>img_k<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                cu_seqlens_q<span class="token operator">=</span>cu_seqlens_q<span class="token punctuation">,</span>
                cu_seqlens_kv<span class="token operator">=</span>cu_seqlens_kv
            <span class="token punctuation">)</span>
        <span class="token comment"># attention computation end</span>

        <span class="token comment"># 将注意力结果和 MLP 激活结果拼接，通过线性层投影回输入维度。</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>attn<span class="token punctuation">,</span> self<span class="token punctuation">.</span>mlp_act<span class="token punctuation">(</span>mlp<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># 使用 mod_gate 进行门控融合，将残差连接后的结果返回。</span>
        <span class="token keyword">return</span> x <span class="token operator">+</span> apply_gate<span class="token punctuation">(</span>output<span class="token punctuation">,</span> gate<span class="token operator">=</span>mod_gate<span class="token punctuation">)</span>


</code></pre>
    <h4>
     <a id="343_HYVideoDiffusionTransformer_1613">
     </a>
     3.4.3 混元主干网络（HYVideoDiffusionTransformer）
    </h4>
    <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">HYVideoDiffusionTransformer</span><span class="token punctuation">(</span>ModelMixin<span class="token punctuation">,</span> ConfigMixin<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    HunyuanVideo Transformer backbone
    该类继承了 ModelMixin 和 ConfigMixin，使其与 diffusers 库的采样器（例如 StableDiffusionPipeline）兼容
    ModelMixin: 来自 diffusers 的模块，提供了模型的保存和加载功能。
    ConfigMixin: 使模型能够以字典形式保存和加载配置信息。

    Reference:
    [1] Flux.1: https://github.com/black-forest-labs/flux
    [2] MMDiT: http://arxiv.org/abs/2403.03206

    Parameters
    ----------
    args: argparse.Namespace
        传入的命令行参数，用于设置模型的配置。
    patch_size: list
        输入特征的分块尺寸。一般用于图像或视频的分块操作。
    in_channels: int
        输入数据的通道数（如 RGB 图像为 3 通道）。
    out_channels: int
        模型输出的通道数。
    hidden_size: int
        Transformer 模块中隐藏层的维度。
    heads_num: int
        多头注意力机制中的注意力头数量，通常用来分配不同的注意力特征。
    mlp_width_ratio: float
        MLP（多层感知机）中隐藏层维度相对于 hidden_size 的比例。
    mlp_act_type: str
        MLP 使用的激活函数类型，例如 ReLU、GELU 等。
    depth_double_blocks: int
        双 Transformer 块的数量。双块可能是指包含多层结构的单元。
    depth_single_blocks: int
        单 Transformer 块的数量。
    rope_dim_list: list
        为时空维度（t, h, w）设计的旋转位置编码（ROPE）的维度。
    qkv_bias: bool
        是否在 QKV（查询、键、值）线性层中使用偏置项。
    qk_norm: bool
        是否对 Q 和 K 应用归一化。
    qk_norm_type: str
        QK 归一化的类型。
    guidance_embed: bool
        是否使用指导嵌入（guidance embedding）来支持蒸馏训练。
    text_projection: str
        文本投影类型，默认为 single_refiner，可能用于文本引导的视频生成。
    use_attention_mask: bool
        是否在文本编码器中使用注意力掩码。
    dtype: torch.dtype
        模型参数的数据类型，例如 torch.float32 或 torch.float16。
    device: torch.device
        模型的运行设备，如 CPU 或 GPU。
    """</span>

    <span class="token decorator annotation punctuation">@register_to_config</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        args<span class="token punctuation">:</span> Any<span class="token punctuation">,</span> <span class="token comment">#</span>
        patch_size<span class="token punctuation">:</span> <span class="token builtin">list</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        in_channels<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token comment"># Should be VAE.config.latent_channels.</span>
        out_channels<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        hidden_size<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">3072</span><span class="token punctuation">,</span>
        heads_num<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">24</span><span class="token punctuation">,</span>
        mlp_width_ratio<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">4.0</span><span class="token punctuation">,</span>
        mlp_act_type<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"gelu_tanh"</span><span class="token punctuation">,</span>
        mm_double_blocks_depth<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span>
        mm_single_blocks_depth<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">40</span><span class="token punctuation">,</span>
        rope_dim_list<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        qkv_bias<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
        qk_norm<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
        qk_norm_type<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"rms"</span><span class="token punctuation">,</span>
        guidance_embed<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token comment"># For modulation.</span>
        text_projection<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"single_refiner"</span><span class="token punctuation">,</span>
        use_attention_mask<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
        dtype<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>dtype<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        device<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 用来传递设备和数据类型（如torch.float32）的参数，方便后续模块的初始化。</span>
        factory_kwargs <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"device"</span><span class="token punctuation">:</span> device<span class="token punctuation">,</span> <span class="token string">"dtype"</span><span class="token punctuation">:</span> dtype<span class="token punctuation">}</span>

        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>patch_size <span class="token operator">=</span> patch_size
        self<span class="token punctuation">.</span>in_channels <span class="token operator">=</span> in_channels
        self<span class="token punctuation">.</span>out_channels <span class="token operator">=</span> in_channels <span class="token keyword">if</span> out_channels <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">else</span> out_channels
        self<span class="token punctuation">.</span>unpatchify_channels <span class="token operator">=</span> self<span class="token punctuation">.</span>out_channels <span class="token comment"># 用来重新拼接patch时的通道数。</span>
        self<span class="token punctuation">.</span>guidance_embed <span class="token operator">=</span> guidance_embed
        self<span class="token punctuation">.</span>rope_dim_list <span class="token operator">=</span> rope_dim_list

        <span class="token comment"># Text projection. Default to linear projection.</span>
        <span class="token comment"># Alternative: TokenRefiner. See more details (LI-DiT): http://arxiv.org/abs/2406.11831</span>
        self<span class="token punctuation">.</span>use_attention_mask <span class="token operator">=</span> use_attention_mask
        self<span class="token punctuation">.</span>text_projection <span class="token operator">=</span> text_projection

        self<span class="token punctuation">.</span>text_states_dim <span class="token operator">=</span> args<span class="token punctuation">.</span>text_states_dim
        self<span class="token punctuation">.</span>text_states_dim_2 <span class="token operator">=</span> args<span class="token punctuation">.</span>text_states_dim_2
        <span class="token comment"># 确保每个头的维度是整数。</span>
        <span class="token keyword">if</span> hidden_size <span class="token operator">%</span> heads_num <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                <span class="token string-interpolation"><span class="token string">f"Hidden size </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>hidden_size<span class="token punctuation">}</span></span><span class="token string"> must be divisible by heads_num </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>heads_num<span class="token punctuation">}</span></span><span class="token string">"</span></span>
            <span class="token punctuation">)</span>
        pe_dim <span class="token operator">=</span> hidden_size <span class="token operator">//</span> heads_num
        <span class="token comment"># 确保位置嵌入的维度与Transformer头的维度一致。</span>
        <span class="token keyword">if</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>rope_dim_list<span class="token punctuation">)</span> <span class="token operator">!=</span> pe_dim<span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                <span class="token string-interpolation"><span class="token string">f"Got </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>rope_dim_list<span class="token punctuation">}</span></span><span class="token string"> but expected positional dim </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>pe_dim<span class="token punctuation">}</span></span><span class="token string">"</span></span>
            <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size
        self<span class="token punctuation">.</span>heads_num <span class="token operator">=</span> heads_num

        <span class="token comment"># 将输入图像分割为小块（patch），并映射到Transformer的隐藏空间hidden_size。</span>
        <span class="token comment"># 每个patch相当于一个Transformer的输入token。</span>
        self<span class="token punctuation">.</span>img_in <span class="token operator">=</span> PatchEmbed<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>patch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>in_channels<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>

        <span class="token comment"># 根据text_projection参数选择不同的文本投影方式：</span>
        <span class="token comment"># TextProjection：线性投影，直接将文本特征映射到模型隐藏空间。</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>text_projection <span class="token operator">==</span> <span class="token string">"linear"</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>txt_in <span class="token operator">=</span> TextProjection<span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>text_states_dim<span class="token punctuation">,</span>
                self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>
                get_activation_layer<span class="token punctuation">(</span><span class="token string">"silu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token operator">**</span>factory_kwargs<span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
        <span class="token comment"># SingleTokenRefiner：使用小型Transformer（深度为2）对文本特征进行细化处理。</span>
        <span class="token keyword">elif</span> self<span class="token punctuation">.</span>text_projection <span class="token operator">==</span> <span class="token string">"single_refiner"</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>txt_in <span class="token operator">=</span> SingleTokenRefiner<span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>text_states_dim<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> heads_num<span class="token punctuation">,</span> depth<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
            <span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> NotImplementedError<span class="token punctuation">(</span>
                <span class="token string-interpolation"><span class="token string">f"Unsupported text_projection: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>self<span class="token punctuation">.</span>text_projection<span class="token punctuation">}</span></span><span class="token string">"</span></span>
            <span class="token punctuation">)</span>

        <span class="token comment"># TimestepEmbedder：时间步嵌入模块，输入时间信息（例如视频帧的索引），并嵌入到Transformer隐藏空间。</span>
        self<span class="token punctuation">.</span>time_in <span class="token operator">=</span> TimestepEmbedder<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> get_activation_layer<span class="token punctuation">(</span><span class="token string">"silu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>

        <span class="token comment"># text modulation</span>
        <span class="token comment"># MLPEmbedder：用于处理来自文本或其他辅助信息的特征，并投影到隐藏空间。</span>
        self<span class="token punctuation">.</span>vector_in <span class="token operator">=</span> MLPEmbedder<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>text_states_dim_2<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
        <span class="token punctuation">)</span>

        <span class="token comment"># guidance_in：引导嵌入模块，用于处理额外的控制信号（如扩散模型中的引导提示）。</span>
        self<span class="token punctuation">.</span>guidance_in <span class="token operator">=</span> <span class="token punctuation">(</span>
            TimestepEmbedder<span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> get_activation_layer<span class="token punctuation">(</span><span class="token string">"silu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">**</span>factory_kwargs
            <span class="token punctuation">)</span>
            <span class="token keyword">if</span> guidance_embed
            <span class="token keyword">else</span> <span class="token boolean">None</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># MMDoubleStreamBlock：多模态双流块，融合了图像流和文本流信息。</span>
        self<span class="token punctuation">.</span>double_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>
            <span class="token punctuation">[</span>
                MMDoubleStreamBlock<span class="token punctuation">(</span>
                    self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>
                    self<span class="token punctuation">.</span>heads_num<span class="token punctuation">,</span>
                    mlp_width_ratio<span class="token operator">=</span>mlp_width_ratio<span class="token punctuation">,</span>
                    mlp_act_type<span class="token operator">=</span>mlp_act_type<span class="token punctuation">,</span>
                    qk_norm<span class="token operator">=</span>qk_norm<span class="token punctuation">,</span>
                    qk_norm_type<span class="token operator">=</span>qk_norm_type<span class="token punctuation">,</span>
                    qkv_bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">,</span>
                    <span class="token operator">**</span>factory_kwargs<span class="token punctuation">,</span>
                <span class="token punctuation">)</span>
                <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>mm_double_blocks_depth<span class="token punctuation">)</span>
            <span class="token punctuation">]</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># MMSingleStreamBlock：单流块，用于进一步处理多模态融合后的单一流特征。</span>
        self<span class="token punctuation">.</span>single_blocks <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>
            <span class="token punctuation">[</span>
                MMSingleStreamBlock<span class="token punctuation">(</span>
                    self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>
                    self<span class="token punctuation">.</span>heads_num<span class="token punctuation">,</span>
                    mlp_width_ratio<span class="token operator">=</span>mlp_width_ratio<span class="token punctuation">,</span>
                    mlp_act_type<span class="token operator">=</span>mlp_act_type<span class="token punctuation">,</span>
                    qk_norm<span class="token operator">=</span>qk_norm<span class="token punctuation">,</span>
                    qk_norm_type<span class="token operator">=</span>qk_norm_type<span class="token punctuation">,</span>
                    <span class="token operator">**</span>factory_kwargs<span class="token punctuation">,</span>
                <span class="token punctuation">)</span>
                <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>mm_single_blocks_depth<span class="token punctuation">)</span>
            <span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
        <span class="token comment"># FinalLayer：将Transformer隐藏空间中的token重新解码为图像patch，并还原到完整图像的分辨率。</span>
        self<span class="token punctuation">.</span>final_layer <span class="token operator">=</span> FinalLayer<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>patch_size<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>out_channels<span class="token punctuation">,</span>
            get_activation_layer<span class="token punctuation">(</span><span class="token string">"silu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token operator">**</span>factory_kwargs<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

    <span class="token comment"># 分别在模型中的 双流模块（double_blocks） 和 单流模块（single_blocks） 中启用或禁用确定性行为。</span>
    <span class="token keyword">def</span> <span class="token function">enable_deterministic</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 在深度学习中，启用确定性行为意味着模型在同样的输入和参数初始化条件下，无论多少次运行都能产生相同的输出结果。</span>
        <span class="token keyword">for</span> block <span class="token keyword">in</span> self<span class="token punctuation">.</span>double_blocks<span class="token punctuation">:</span>
            block<span class="token punctuation">.</span>enable_deterministic<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> block <span class="token keyword">in</span> self<span class="token punctuation">.</span>single_blocks<span class="token punctuation">:</span>
            block<span class="token punctuation">.</span>enable_deterministic<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">disable_deterministic</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 禁用确定性行为可能会允许使用非确定性的操作（如某些高效的并行实现），从而提升计算效率。</span>
        <span class="token keyword">for</span> block <span class="token keyword">in</span> self<span class="token punctuation">.</span>double_blocks<span class="token punctuation">:</span>
            block<span class="token punctuation">.</span>disable_deterministic<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> block <span class="token keyword">in</span> self<span class="token punctuation">.</span>single_blocks<span class="token punctuation">:</span>
            block<span class="token punctuation">.</span>disable_deterministic<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        x<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> <span class="token comment"># 输入图像张量，形状为 (N, C, T, H, W)。批量大小为 N，通道数为 C，时间步为 T，高度和宽度为 H 和 W。</span>
        t<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span>  <span class="token comment"># 时间步张量，用于时间嵌入。范围应为 [0, 1000]，可能对应扩散模型或时间相关的特征。</span>
        text_states<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token comment"># 文本嵌入，表示与图像配对的文本特征。</span>
        text_mask<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 文本掩码张量（可选）。当前未使用，可能用于控制哪些文本特征参与计算。</span>
        text_states_2<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 额外的文本嵌入，用于进一步调制（modulation）。在模型中可能是辅助的文本特征表示</span>
        freqs_cos<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token comment"># 正弦和余弦频率，用于位置编码或调制。</span>
        freqs_sin<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        guidance<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 引导调制强度，形状可能是 cfg_scale x 1000。通常用于引导生成（如扩散模型的分类引导）。</span>
        return_dict<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment"># 是否返回一个字典结果。默认为 True。</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Union<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        out <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
        img <span class="token operator">=</span> x
        txt <span class="token operator">=</span> text_states
        _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> ot<span class="token punctuation">,</span> oh<span class="token punctuation">,</span> ow <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        <span class="token comment"># 得到划分patch后的t,h,w</span>
        tt<span class="token punctuation">,</span> th<span class="token punctuation">,</span> tw <span class="token operator">=</span> <span class="token punctuation">(</span>
            ot <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            oh <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            ow <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># Prepare modulation vectors.</span>
        <span class="token comment"># 时间嵌入通过 self.time_in(t) 提取特征。</span>
        vec <span class="token operator">=</span> self<span class="token punctuation">.</span>time_in<span class="token punctuation">(</span>t<span class="token punctuation">)</span>

        <span class="token comment"># text modulation</span>
        <span class="token comment"># 如果有额外文本嵌入 text_states_2，则通过 self.vector_in 模块对 vec 进行调制。</span>
        vec <span class="token operator">=</span> vec <span class="token operator">+</span> self<span class="token punctuation">.</span>vector_in<span class="token punctuation">(</span>text_states_2<span class="token punctuation">)</span>

        <span class="token comment"># 启用了引导调制（self.guidance_embed），通过 self.guidance_in 引入引导特征。</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>guidance_embed<span class="token punctuation">:</span>
            <span class="token keyword">if</span> guidance <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                    <span class="token string">"Didn't get guidance strength for guidance distilled model."</span>
                <span class="token punctuation">)</span>

            <span class="token comment"># our timestep_embedding is merged into guidance_in(TimestepEmbedder)</span>
            vec <span class="token operator">=</span> vec <span class="token operator">+</span> self<span class="token punctuation">.</span>guidance_in<span class="token punctuation">(</span>guidance<span class="token punctuation">)</span>

        <span class="token comment"># Embed image and text.</span>
        <span class="token comment"># 图像嵌入</span>
        img <span class="token operator">=</span> self<span class="token punctuation">.</span>img_in<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
        <span class="token comment"># 文本嵌入</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>text_projection <span class="token operator">==</span> <span class="token string">"linear"</span><span class="token punctuation">:</span> <span class="token comment"># 线性投影</span>
            txt <span class="token operator">=</span> self<span class="token punctuation">.</span>txt_in<span class="token punctuation">(</span>txt<span class="token punctuation">)</span>
        <span class="token keyword">elif</span> self<span class="token punctuation">.</span>text_projection <span class="token operator">==</span> <span class="token string">"single_refiner"</span><span class="token punctuation">:</span> <span class="token comment"># 结合时间步 t 和文本掩码进行更复杂的处理。</span>
            txt <span class="token operator">=</span> self<span class="token punctuation">.</span>txt_in<span class="token punctuation">(</span>txt<span class="token punctuation">,</span> t<span class="token punctuation">,</span> text_mask <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_attention_mask <span class="token keyword">else</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> NotImplementedError<span class="token punctuation">(</span>
                <span class="token string-interpolation"><span class="token string">f"Unsupported text_projection: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>self<span class="token punctuation">.</span>text_projection<span class="token punctuation">}</span></span><span class="token string">"</span></span>
            <span class="token punctuation">)</span>

        txt_seq_len <span class="token operator">=</span> txt<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        img_seq_len <span class="token operator">=</span> img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token comment"># 计算序列长度和累积序列索引</span>
        <span class="token comment"># 用于 Flash Attention 的高效计算，cu_seqlens_* 和 max_seqlen_* 控制序列长度和最大长度。</span>
        <span class="token comment"># Compute cu_squlens and max_seqlen for flash attention</span>
        cu_seqlens_q <span class="token operator">=</span> get_cu_seqlens<span class="token punctuation">(</span>text_mask<span class="token punctuation">,</span> img_seq_len<span class="token punctuation">)</span>
        cu_seqlens_kv <span class="token operator">=</span> cu_seqlens_q
        max_seqlen_q <span class="token operator">=</span> img_seq_len <span class="token operator">+</span> txt_seq_len
        max_seqlen_kv <span class="token operator">=</span> max_seqlen_q

        freqs_cis <span class="token operator">=</span> <span class="token punctuation">(</span>freqs_cos<span class="token punctuation">,</span> freqs_sin<span class="token punctuation">)</span> <span class="token keyword">if</span> freqs_cos <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">else</span> <span class="token boolean">None</span>

        <span class="token comment"># --------------------- Pass through DiT blocks ------------------------</span>
        <span class="token keyword">for</span> _<span class="token punctuation">,</span> block <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>double_blocks<span class="token punctuation">)</span><span class="token punctuation">:</span>
            double_block_args <span class="token operator">=</span> <span class="token punctuation">[</span>
                img<span class="token punctuation">,</span>
                txt<span class="token punctuation">,</span>
                vec<span class="token punctuation">,</span>
                cu_seqlens_q<span class="token punctuation">,</span>
                cu_seqlens_kv<span class="token punctuation">,</span>
                max_seqlen_q<span class="token punctuation">,</span>
                max_seqlen_kv<span class="token punctuation">,</span>
                freqs_cis<span class="token punctuation">,</span>
            <span class="token punctuation">]</span>
            <span class="token comment"># 并行处理图像和文本信息，使用输入参数（包括嵌入和序列长度等）逐步更新 img 和 txt。</span>
            img<span class="token punctuation">,</span> txt <span class="token operator">=</span> block<span class="token punctuation">(</span><span class="token operator">*</span>double_block_args<span class="token punctuation">)</span>

        <span class="token comment"># 合并图像和文本并通过单流模块</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>img<span class="token punctuation">,</span> txt<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>single_blocks<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> _<span class="token punctuation">,</span> block <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>single_blocks<span class="token punctuation">)</span><span class="token punctuation">:</span>
                single_block_args <span class="token operator">=</span> <span class="token punctuation">[</span>
                    x<span class="token punctuation">,</span>
                    vec<span class="token punctuation">,</span>
                    txt_seq_len<span class="token punctuation">,</span>
                    cu_seqlens_q<span class="token punctuation">,</span>
                    cu_seqlens_kv<span class="token punctuation">,</span>
                    max_seqlen_q<span class="token punctuation">,</span>
                    max_seqlen_kv<span class="token punctuation">,</span>
                    <span class="token punctuation">(</span>freqs_cos<span class="token punctuation">,</span> freqs_sin<span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token punctuation">]</span>

                x <span class="token operator">=</span> block<span class="token punctuation">(</span><span class="token operator">*</span>single_block_args<span class="token punctuation">)</span>
        <span class="token comment"># 分离图像特征</span>
        img <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>img_seq_len<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>

        <span class="token comment"># ---------------------------- Final layer ------------------------------</span>
        <span class="token comment"># 图像特征通过 final_layer 提取最终结果</span>
        img <span class="token operator">=</span> self<span class="token punctuation">.</span>final_layer<span class="token punctuation">(</span>img<span class="token punctuation">,</span> vec<span class="token punctuation">)</span>  <span class="token comment"># (N, T, patch_size ** 2 * out_channels)</span>
        <span class="token comment"># 通过 unpatchify 恢复到原始分辨率。</span>
        img <span class="token operator">=</span> self<span class="token punctuation">.</span>unpatchify<span class="token punctuation">(</span>img<span class="token punctuation">,</span> tt<span class="token punctuation">,</span> th<span class="token punctuation">,</span> tw<span class="token punctuation">)</span>
        <span class="token keyword">if</span> return_dict<span class="token punctuation">:</span>
            out<span class="token punctuation">[</span><span class="token string">"x"</span><span class="token punctuation">]</span> <span class="token operator">=</span> img
            <span class="token keyword">return</span> out
        <span class="token keyword">return</span> img

    <span class="token keyword">def</span> <span class="token function">unpatchify</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 是将被切分为小块（patches）的特征重新还原成原始的张量形状，通常用于图像处理任务中，</span>
        <span class="token comment"># 例如在 ViT（Vision Transformer）模型的输出阶段将 patch 还原为完整图像的形式。</span>
        <span class="token triple-quoted-string string">"""
        x: (N, T, patch_size**2 * C)  （批量大小，时间帧数，每个patch中的通道数）
        imgs: (N, H, W, C)
        """</span>
        c <span class="token operator">=</span> self<span class="token punctuation">.</span>unpatchify_channels
        pt<span class="token punctuation">,</span> ph<span class="token punctuation">,</span> pw <span class="token operator">=</span> self<span class="token punctuation">.</span>patch_size
        <span class="token keyword">assert</span> t <span class="token operator">*</span> h <span class="token operator">*</span> w <span class="token operator">==</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

        x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> t<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">,</span> c<span class="token punctuation">,</span> pt<span class="token punctuation">,</span> ph<span class="token punctuation">,</span> pw<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">"nthwcopq-&gt;nctohpwq"</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        imgs <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token punctuation">,</span> t <span class="token operator">*</span> pt<span class="token punctuation">,</span> h <span class="token operator">*</span> ph<span class="token punctuation">,</span> w <span class="token operator">*</span> pw<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> imgs

    <span class="token keyword">def</span> <span class="token function">params_count</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 计算模型的参数数量，并将其按类别进行统计。它返回一个包含不同类别参数数量的字典，通常用于分析模型的规模或复杂度。</span>
        counts <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">"double"</span><span class="token punctuation">:</span> <span class="token builtin">sum</span><span class="token punctuation">(</span> <span class="token comment"># double_blocks 模块的所有参数数量</span>
                <span class="token punctuation">[</span>
                    <span class="token builtin">sum</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> block<span class="token punctuation">.</span>img_attn_qkv<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    <span class="token operator">+</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> block<span class="token punctuation">.</span>img_attn_proj<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    <span class="token operator">+</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> block<span class="token punctuation">.</span>img_mlp<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    <span class="token operator">+</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> block<span class="token punctuation">.</span>txt_attn_qkv<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    <span class="token operator">+</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> block<span class="token punctuation">.</span>txt_attn_proj<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    <span class="token operator">+</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> block<span class="token punctuation">.</span>txt_mlp<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    <span class="token keyword">for</span> block <span class="token keyword">in</span> self<span class="token punctuation">.</span>double_blocks
                <span class="token punctuation">]</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">"single"</span><span class="token punctuation">:</span> <span class="token builtin">sum</span><span class="token punctuation">(</span> <span class="token comment"># single_blocks 模块的所有参数数量</span>
                <span class="token punctuation">[</span>
                    <span class="token builtin">sum</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> block<span class="token punctuation">.</span>linear1<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    <span class="token operator">+</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> block<span class="token punctuation">.</span>linear2<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    <span class="token keyword">for</span> block <span class="token keyword">in</span> self<span class="token punctuation">.</span>single_blocks
                <span class="token punctuation">]</span>
            <span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">"total"</span><span class="token punctuation">:</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> self<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        <span class="token comment"># double 和 single 参数的总和，主要聚焦于注意力和 MLP 层。</span>
        counts<span class="token punctuation">[</span><span class="token string">"attn+mlp"</span><span class="token punctuation">]</span> <span class="token operator">=</span> counts<span class="token punctuation">[</span><span class="token string">"double"</span><span class="token punctuation">]</span> <span class="token operator">+</span> counts<span class="token punctuation">[</span><span class="token string">"single"</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> counts


</code></pre>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f67:2e6373646e2e6e65742f73696e61745f31363032303832352f:61727469636c652f64657461696c732f313436303739353633" class_="artid" style="display:none">
 </p>
</div>


