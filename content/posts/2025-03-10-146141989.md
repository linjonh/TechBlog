---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f35383730313939352f:61727469636c652f64657461696c732f313436313431393839"
layout: post
title: "论文阅读多模态CLIPasso"
date: 2025-03-10 00:58:14 +08:00
description: "CLIPasso提出基于CLIP与贝塞尔曲线的简笔画生成方法，通过语义损失（对齐CLIP特征）与几何损失（约束浅层特征）优化可微分光栅化的笔画参数，结合ViT显著性图初始化提升训练稳定性。支持任意语义类别，通过笔画数量控制抽象程度，但需预处理抠图且非序列生成。"
keywords: "【论文阅读】多模态——CLIPasso"
categories: ['论文阅读']
tags: ['计算机视觉', '深度学习', '机器学习']
artid: "146141989"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146141989
    alt: "论文阅读多模态CLIPasso"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146141989
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146141989
cover: https://bing.ee123.net/img/rand?artid=146141989
image: https://bing.ee123.net/img/rand?artid=146141989
img: https://bing.ee123.net/img/rand?artid=146141989
---

# 【论文阅读】多模态——CLIPasso

## 文献基本信息

* **标题：**
  CLIPasso: Semantically-Aware Object Sketching
* **作者：**
  Yael Vinker、Ehsan Pajouheshgar、Jessica Y. Bo、Roman Christian Bachmann、Amit Haim Bermano、Daniel Cohen-Or、Amir Zamir、Ariel Shamir
* **单位：**
  Swiss Federal Institute of Technology (EPFL)、Tel-Aviv University、Reichman University
* **会议/期刊：**
  TOG
* **发表时间：**
  2022年5月16日
* **代码：**
  [https://clipasso.github.io/clipasso/](https://clipasso.github.io/clipasso/ "https://clipasso.github.io/clipasso/")

## 背景与意义

* CLIPasso要做的事情如下图所示，要
  **由一张语义清晰的图像生成其对应的抽象简笔画**
  ，要求
  **用较少的比划勾勒出原图的轮廓**
  ，并且
  **与原图具有相同的语义内容**
  ，即原图是头公牛，生成的抽象简笔画也要能看出来是头公牛。

![](https://i-blog.csdnimg.cn/direct/2f7644fc7cf9483a976ccccfd351a22d.png)

![](https://i-blog.csdnimg.cn/direct/40266fec21384a7c898aafab61d0b469.png)

![](https://i-blog.csdnimg.cn/direct/2839df192d5d4f44a439857c1f079165.png)

![](https://i-blog.csdnimg.cn/direct/6c246a460703454cb0e231316a9be56f.png)

## 研究方法与创新点

* 生成简笔画的方法不是直接做图到图的生成，而是使用图形学中的
  **贝塞尔（贝兹）曲线**
  （随机初始化）来完成简笔绘画，贝塞尔曲线通过定义平面上的几个点来确定一条曲线。
* **CLIPasso**
  的模型框架如下图所示，中间的
  **Rasterizer**
  是图形学方向根据参数绘制贝塞尔曲线的一种方法，其将曲线画在空白的画布上使可视化。
* 本文方法的创新点主要在
  **损失函数**
  和
  **初始化方法**
  两个方面。

![](https://i-blog.csdnimg.cn/direct/bf0d91507f124a0aafc7724ac7a47fad.png)

* **贝塞尔曲线**
  是空间上一系列2维的点控制的曲线，本文里一个笔画用
  **四个点**
  表示，每个点在空间上是二维的，
  ![$P$](https://latex.csdn.net/eq?%24P%24)
  可以用
  ![$\left( {x,y} \right)$](https://latex.csdn.net/eq?%24%5Cleft%28%20%7Bx%2Cy%7D%20%5Cright%29%24)
  表示，通过模型训练更改四个点的位置，然后通过贝塞尔曲线的计算慢慢改变曲线形状得到简笔画。

![{\cal S} = {\cal R}\left( {\left\{ {p_1^j} \right\}_{j = 1}^4, \cdots ,\left\{ {p_n^j} \right\}_{j = 1}^4} \right)](https://latex.csdn.net/eq?%7B%5Ccal%20S%7D%20%3D%20%7B%5Ccal%20R%7D%5Cleft%28%20%7B%5Cleft%5C%7B%20%7Bp_1%5Ej%7D%20%5Cright%5C%7D_%7Bj%20%3D%201%7D%5E4%2C%20%5Ccdots%20%2C%5Cleft%5C%7B%20%7Bp_n%5Ej%7D%20%5Cright%5C%7D_%7Bj%20%3D%201%7D%5E4%7D%20%5Cright%29)

### 损失函数

* **生成的简笔画有两个要求：**

1. 要在
   **语义**
   上与输入图像一致，即马还是马，牛还是牛。
2. 生成的简笔画的
   **几何轮廓**
   也要与原图一致，不能虽然还是马，但是马头的朝向反了，或者是趴着的马。

* 即满足
  **语义**
  和
  **几何**
  需求，在CLIPasso中，这两个要求分别由两个损失函数——
  **几何损失**
  ![$L_g$](https://latex.csdn.net/eq?%24L_g%24)
  和
  **语义损失**
  ![$L_s$](https://latex.csdn.net/eq?%24L_s%24)
  来保证。

1. **语义损失**
   的思路与
   **蒸馏学习**
   类似，要让模型提取到的图像特征和CLIP图像编码器提取的特征接近，从而在语义上保证原图和简笔画图都是马，这样做的依据是
   **CLIP能做到对无论是自然图像、简笔画图等还是其他任何风格的图像，都能准确提取出语义特征**
   ，这种能力来自于CLIP的
   **400M**
   规模的训练数据。
2. **几何损失**
   类似于
   **感知损失**
   ，是在约束模型前几层的特征图，因为在模型的前几层，学习到的还是相对低层的几何纹理信息，而非高层语义信息，因此
   **约束浅层特征**
   可以保证原图和简笔画图的几何轮廓接近。

### 初始化

* **显著性（saliency）图**
  用来对贝塞尔曲线参数进行初始化，如果完全随初始化贝塞尔曲线的参数，会使得模型训练很
  **不稳定**
  ，因此使用显著性图来辅助贝塞尔曲线参数的初始化，
  **从语义明确的区域采点进行初始化**
  ，改善了训练的稳定性。
* 具体来说，将图片输入一个已经训练好的
  **ViT**
  ，把最后一层的多头自注意力做加权平均得到一个
  **显著性图**
  ，在这个图上观察哪些区域更显著，就在这些显著的区域上去确定点的位置，其实已经知道显著性区域是有一个物体的，即按照这个显著区域的边界去画贝塞尔曲线，所以初始化曲线与最后简笔画相差不多，提高生成性能。

![](https://i-blog.csdnimg.cn/direct/acbb539f866a419290e6aa6a249018c2.png)

1. 随机初始化得到右边简笔画，文中提出的方法对于头发部分笔画更少且五官清晰。
2. 增加
   **后处理**
   ，根据一张输入生成
   **三**
   张简笔画，再根据两个损失算算哪个简笔画损失最低，并当成最后的输出。

## 研究结论

![](https://i-blog.csdnimg.cn/direct/369607115a65484c9c9f93d46953a490.png)

* 模型训练2000个iteration，在第100个iteration时就可以看出简笔画形状。
* **模型训练很快**
  ，用一张V100GPU就能在6分钟时间里，完成2000个iteration。
* 可以给
  **不常见**
  的物体生成简笔画，得益于
  **CLIP模型zero-shot的能力**
  。
* 无论笔画多还是笔画少，本文模型都更具备
  **语义**
  的信息。

![](https://i-blog.csdnimg.cn/direct/acbbb5055eee4f9d95b5885dbd9781c1.png)

![](https://i-blog.csdnimg.cn/direct/b6955d2e99334ec8810c0f0d365461af.png)

## 存在的问题

1. **图像有背景时，模型效果大打折扣**
   ，必须在纯白背景上的物体效果才很好。本文使用U2NET先将带背景的物体抠出来，再去用CLIPasso生成简笔画，这样变成了
   **两阶段**
   ，
   **可能不是最优的方法**
   。
2. CLIPasso初始化笔画是
   **同时**
   生成的，而不是序列生成的，之后可以考虑为
   **序列**
   形式，即画了前一笔再去考虑下一笔画在哪里，一步一步生成简笔画。
3. 虽然可以通过控制笔画数控制抽象程度，但其实即使想得到同等程度抽象画，不同图片也是不同的笔画数，可以尝试把笔画数做成一个可优化的参数，
   **让模型自己考虑用多少笔画**
   。

## 启发与思考

1. 可以尝试
   **AI的跨界**
   ，像本文就是AI+艺术的跨界。
2. 进一步相信CLIP模型zero-shot的能力，可以多多尝试应用于涉及
   **不常见物体**
   的图像任务上。