---
layout: post
title: "论文阅读多模态CLIPasso"
date: 2025-03-10 00:58:14 +0800
description: "CLIPasso提出基于CLIP与贝塞尔曲线的简笔画生成方法，通过语义损失（对齐CLIP特征）与几何损失（约束浅层特征）优化可微分光栅化的笔画参数，结合ViT显著性图初始化提升训练稳定性。支持任意语义类别，通过笔画数量控制抽象程度，但需预处理抠图且非序列生成。"
keywords: "【论文阅读】多模态——CLIPasso"
categories: ['论文阅读']
tags: ['计算机视觉', '深度学习', '机器学习']
artid: "146141989"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146141989
    alt: "论文阅读多模态CLIPasso"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146141989
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146141989
cover: https://bing.ee123.net/img/rand?artid=146141989
image: https://bing.ee123.net/img/rand?artid=146141989
img: https://bing.ee123.net/img/rand?artid=146141989
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     【论文阅读】多模态——CLIPasso
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     文献基本信息
    </h2>
    <ul>
     <li>
      <strong>
       标题：
      </strong>
      CLIPasso: Semantically-Aware Object Sketching
     </li>
     <li>
      <strong>
       作者：
      </strong>
      Yael Vinker、Ehsan Pajouheshgar、Jessica Y. Bo、Roman Christian Bachmann、Amit Haim Bermano、Daniel Cohen-Or、Amir Zamir、Ariel Shamir
     </li>
     <li>
      <strong>
       单位：
      </strong>
      Swiss Federal Institute of Technology (EPFL)、Tel-Aviv University、Reichman University
     </li>
     <li>
      <strong>
       会议/期刊：
      </strong>
      TOG
     </li>
     <li>
      <strong>
       发表时间：
      </strong>
      2022年5月16日
     </li>
     <li>
      <strong>
       代码：
      </strong>
      <a class="link-info" href="https://clipasso.github.io/clipasso/" rel="nofollow" title="https://clipasso.github.io/clipasso/">
       https://clipasso.github.io/clipasso/
      </a>
     </li>
    </ul>
    <h2>
     背景与意义
    </h2>
    <ul>
     <li>
      CLIPasso要做的事情如下图所示，要
      <strong>
       由一张语义清晰的图像生成其对应的抽象简笔画
      </strong>
      ，要求
      <strong>
       用较少的比划勾勒出原图的轮廓
      </strong>
      ，并且
      <strong>
       与原图具有相同的语义内容
      </strong>
      ，即原图是头公牛，生成的抽象简笔画也要能看出来是头公牛。
     </li>
    </ul>
    <p style="text-align:center">
     <img alt="" height="150" src="https://i-blog.csdnimg.cn/direct/2f7644fc7cf9483a976ccccfd351a22d.png" width="455"/>
    </p>
    <p style="text-align:center">
     <img alt="" height="250" src="https://i-blog.csdnimg.cn/direct/40266fec21384a7c898aafab61d0b469.png" width="453"/>
    </p>
    <p style="text-align:center">
     <img alt="" height="300" src="https://i-blog.csdnimg.cn/direct/2839df192d5d4f44a439857c1f079165.png" width="289"/>
    </p>
    <p style="text-align:center">
     <img alt="" height="120" src="https://i-blog.csdnimg.cn/direct/6c246a460703454cb0e231316a9be56f.png" width="479"/>
    </p>
    <h2>
     研究方法与创新点
    </h2>
    <ul>
     <li>
      生成简笔画的方法不是直接做图到图的生成，而是使用图形学中的
      <strong>
       贝塞尔（贝兹）曲线
      </strong>
      （随机初始化）来完成简笔绘画，贝塞尔曲线通过定义平面上的几个点来确定一条曲线。
     </li>
     <li>
      <strong>
       CLIPasso
      </strong>
      的模型框架如下图所示，中间的
      <strong>
       Rasterizer
      </strong>
      是图形学方向根据参数绘制贝塞尔曲线的一种方法，其将曲线画在空白的画布上使可视化。
     </li>
     <li>
      本文方法的创新点主要在
      <strong>
       损失函数
      </strong>
      和
      <strong>
       初始化方法
      </strong>
      两个方面。
     </li>
    </ul>
    <p style="text-align:center">
     <img alt="" height="150" src="https://i-blog.csdnimg.cn/direct/bf0d91507f124a0aafc7724ac7a47fad.png" width="656"/>
    </p>
    <ul>
     <li>
      <strong>
       贝塞尔曲线
      </strong>
      是空间上一系列2维的点控制的曲线，本文里一个笔画用
      <strong>
       四个点
      </strong>
      表示，每个点在空间上是二维的，
      <img alt="$P$" class="mathcode" src="https://latex.csdn.net/eq?%24P%24">
       可以用
       <img alt="$\left( {x,y} \right)$" class="mathcode" src="https://latex.csdn.net/eq?%24%5Cleft%28%20%7Bx%2Cy%7D%20%5Cright%29%24">
        表示，通过模型训练更改四个点的位置，然后通过贝塞尔曲线的计算慢慢改变曲线形状得到简笔画。
       </img>
      </img>
     </li>
    </ul>
    <p style="text-align:center">
     <img alt="{\cal S} = {\cal R}\left( {\left\{ {p_1^j} \right\}_{j = 1}^4, \cdots ,\left\{ {p_n^j} \right\}_{j = 1}^4} \right)" class="mathcode" src="https://latex.csdn.net/eq?%7B%5Ccal%20S%7D%20%3D%20%7B%5Ccal%20R%7D%5Cleft%28%20%7B%5Cleft%5C%7B%20%7Bp_1%5Ej%7D%20%5Cright%5C%7D_%7Bj%20%3D%201%7D%5E4%2C%20%5Ccdots%20%2C%5Cleft%5C%7B%20%7Bp_n%5Ej%7D%20%5Cright%5C%7D_%7Bj%20%3D%201%7D%5E4%7D%20%5Cright%29"/>
    </p>
    <h3>
     损失函数
    </h3>
    <ul>
     <li>
      <strong>
       生成的简笔画有两个要求：
      </strong>
     </li>
    </ul>
    <ol>
     <li>
      要在
      <strong>
       语义
      </strong>
      上与输入图像一致，即马还是马，牛还是牛。
     </li>
     <li>
      生成的简笔画的
      <strong>
       几何轮廓
      </strong>
      也要与原图一致，不能虽然还是马，但是马头的朝向反了，或者是趴着的马。
     </li>
    </ol>
    <ul>
     <li>
      即满足
      <strong>
       语义
      </strong>
      和
      <strong>
       几何
      </strong>
      需求，在CLIPasso中，这两个要求分别由两个损失函数——
      <strong>
       几何损失
      </strong>
      <img alt="$L_g$" class="mathcode" src="https://latex.csdn.net/eq?%24L_g%24"/>
      和
      <strong>
       语义损失
      </strong>
      <img alt="$L_s$" class="mathcode" src="https://latex.csdn.net/eq?%24L_s%24"/>
      来保证。
     </li>
    </ul>
    <ol>
     <li>
      <strong>
       语义损失
      </strong>
      的思路与
      <strong>
       蒸馏学习
      </strong>
      类似，要让模型提取到的图像特征和CLIP图像编码器提取的特征接近，从而在语义上保证原图和简笔画图都是马，这样做的依据是
      <strong>
       CLIP能做到对无论是自然图像、简笔画图等还是其他任何风格的图像，都能准确提取出语义特征
      </strong>
      ，这种能力来自于CLIP的
      <strong>
       400M
      </strong>
      规模的训练数据。
     </li>
     <li>
      <strong>
       几何损失
      </strong>
      类似于
      <strong>
       感知损失
      </strong>
      ，是在约束模型前几层的特征图，因为在模型的前几层，学习到的还是相对低层的几何纹理信息，而非高层语义信息，因此
      <strong>
       约束浅层特征
      </strong>
      可以保证原图和简笔画图的几何轮廓接近。
     </li>
    </ol>
    <h3>
     初始化
    </h3>
    <ul>
     <li>
      <strong>
       显著性（saliency）图
      </strong>
      用来对贝塞尔曲线参数进行初始化，如果完全随初始化贝塞尔曲线的参数，会使得模型训练很
      <strong>
       不稳定
      </strong>
      ，因此使用显著性图来辅助贝塞尔曲线参数的初始化，
      <strong>
       从语义明确的区域采点进行初始化
      </strong>
      ，改善了训练的稳定性。
     </li>
     <li>
      具体来说，将图片输入一个已经训练好的
      <strong>
       ViT
      </strong>
      ，把最后一层的多头自注意力做加权平均得到一个
      <strong>
       显著性图
      </strong>
      ，在这个图上观察哪些区域更显著，就在这些显著的区域上去确定点的位置，其实已经知道显著性区域是有一个物体的，即按照这个显著区域的边界去画贝塞尔曲线，所以初始化曲线与最后简笔画相差不多，提高生成性能。
     </li>
    </ul>
    <p style="text-align:center">
     <img alt="" height="250" src="https://i-blog.csdnimg.cn/direct/acbb539f866a419290e6aa6a249018c2.png" width="417"/>
    </p>
    <ol>
     <li>
      随机初始化得到右边简笔画，文中提出的方法对于头发部分笔画更少且五官清晰。
     </li>
     <li>
      增加
      <strong>
       后处理
      </strong>
      ，根据一张输入生成
      <strong>
       三
      </strong>
      张简笔画，再根据两个损失算算哪个简笔画损失最低，并当成最后的输出。
     </li>
    </ol>
    <h2>
     研究结论
    </h2>
    <p style="text-align:center">
     <img alt="" height="100" src="https://i-blog.csdnimg.cn/direct/369607115a65484c9c9f93d46953a490.png" width="387"/>
    </p>
    <ul>
     <li>
      模型训练2000个iteration，在第100个iteration时就可以看出简笔画形状。
     </li>
     <li>
      <strong>
       模型训练很快
      </strong>
      ，用一张V100GPU就能在6分钟时间里，完成2000个iteration。
     </li>
     <li>
      可以给
      <strong>
       不常见
      </strong>
      的物体生成简笔画，得益于
      <strong>
       CLIP模型zero-shot的能力
      </strong>
      。
     </li>
     <li>
      无论笔画多还是笔画少，本文模型都更具备
      <strong>
       语义
      </strong>
      的信息。
     </li>
    </ul>
    <p style="text-align:center">
     <img alt="" height="100" src="https://i-blog.csdnimg.cn/direct/acbbb5055eee4f9d95b5885dbd9781c1.png" width="472"/>
    </p>
    <p style="text-align:center">
     <img alt="" height="300" src="https://i-blog.csdnimg.cn/direct/b6955d2e99334ec8810c0f0d365461af.png" width="486"/>
    </p>
    <h2>
     存在的问题
    </h2>
    <ol>
     <li>
      <strong>
       图像有背景时，模型效果大打折扣
      </strong>
      ，必须在纯白背景上的物体效果才很好。本文使用U2NET先将带背景的物体抠出来，再去用CLIPasso生成简笔画，这样变成了
      <strong>
       两阶段
      </strong>
      ，
      <strong>
       可能不是最优的方法
      </strong>
      。
     </li>
     <li>
      CLIPasso初始化笔画是
      <strong>
       同时
      </strong>
      生成的，而不是序列生成的，之后可以考虑为
      <strong>
       序列
      </strong>
      形式，即画了前一笔再去考虑下一笔画在哪里，一步一步生成简笔画。
     </li>
     <li>
      虽然可以通过控制笔画数控制抽象程度，但其实即使想得到同等程度抽象画，不同图片也是不同的笔画数，可以尝试把笔画数做成一个可优化的参数，
      <strong>
       让模型自己考虑用多少笔画
      </strong>
      。
     </li>
    </ol>
    <h2>
     启发与思考
    </h2>
    <ol>
     <li>
      可以尝试
      <strong>
       AI的跨界
      </strong>
      ，像本文就是AI+艺术的跨界。
     </li>
     <li>
      进一步相信CLIP模型zero-shot的能力，可以多多尝试应用于涉及
      <strong>
       不常见物体
      </strong>
      的图像任务上。
     </li>
    </ol>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f35383730313939352f:61727469636c652f64657461696c732f313436313431393839" class_="artid" style="display:none">
 </p>
</div>


