---
layout: post
title: "初识大模型大语言模型-LLMBook-学习一"
date: 2025-03-09 17:28:20 +0800
description: "1. GPT-1（2018）：开创预训练 + 微调范式🔹 关键优化点引入 Transformer 架构：相比 RNN 和 LSTM，Transformer 具备更强的并行计算能力，提升了训练效率。自回归预训练（Autoregressive Pre-training）：使用无监督学习训练，预测下一个词（Next Token Prediction）。微调（Fine-tuning）：在特定任务（如问答、情感分析）上进行微调，提高模型的任务适应性。参数规模：1.17 亿（1.17B）。🔹 局限性。"
keywords: "大语言模型培训文档"
categories: ['大模型从入门到实战', 'Yk']
tags: ['语言模型', '学习', '人工智能']
artid: "146134695"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146134695
    alt: "初识大模型大语言模型-LLMBook-学习一"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146134695
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146134695
cover: https://bing.ee123.net/img/rand?artid=146134695
image: https://bing.ee123.net/img/rand?artid=146134695
img: https://bing.ee123.net/img/rand?artid=146134695
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     初识大模型——大语言模型 LLMBook 学习（一）
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="1__0">
     </a>
     1. 大模型发展历程
    </h3>
    <h4>
     <a id="_1_1950s__1990s_1">
     </a>
     <strong>
      🔹 1. 早期阶段（1950s - 1990s）：基于规则和统计的方法
     </strong>
    </h4>
    <p>
     <strong>
      代表技术：
     </strong>
    </p>
    <ul>
     <li>
      <p>
       <strong>
        1950s-1960s：规则驱动的语言处理
       </strong>
      </p>
      <ul>
       <li>
        早期的 NLP 主要依赖
        <strong>
         基于规则的系统
        </strong>
        ，如 Noam Chomsky 提出的
        <strong>
         生成语法（Generative Grammar）
        </strong>
        。
       </li>
       <li>
        这些系统使用手工编写的规则来解析和生成句子，但扩展性差。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        1970s-1990s：统计语言模型（Statistical Language Models, SLM）
       </strong>
      </p>
      <ul>
       <li>
        1980s 以后，随着计算能力的提高，研究者开始使用
        <strong>
         统计方法
        </strong>
        处理语言，如
        <strong>
         n-gram 语言模型
        </strong>
        。
       </li>
       <li>
        1990s，
        <strong>
         隐马尔可夫模型（HMM）
        </strong>
        和
        <strong>
         条件随机场（CRF）
        </strong>
        被广泛用于语音识别和词性标注。
       </li>
      </ul>
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="_2_2000s__2018s_13">
     </a>
     <strong>
      🔹 2. 机器学习时代（2000s - 2018s）：神经网络与深度学习
     </strong>
    </h4>
    <p>
     <strong>
      代表技术：
     </strong>
    </p>
    <ul>
     <li>
      <p>
       <strong>
        2000s：基于神经网络的 NLP
       </strong>
      </p>
      <ul>
       <li>
        2003 年，
        <strong>
         Bengio 等人提出神经网络语言模型（Neural Language Model, NLM）
        </strong>
        ，引入了**词向量（Word Embeddings）**的概念。
       </li>
       <li>
        2013 年，Google 的
        <strong>
         Word2Vec
        </strong>
        算法问世，使得词向量学习成为 NLP 研究的标准方法。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        2014-2017：RNN、LSTM、Seq2Seq 和 Attention
       </strong>
      </p>
      <ul>
       <li>
        2014 年，
        <strong>
         循环神经网络（RNN）
        </strong>
        和
        <strong>
         长短时记忆网络（LSTM）
        </strong>
        被用于机器翻译。
       </li>
       <li>
        2015 年，Google 提出了
        <strong>
         Seq2Seq 模型
        </strong>
        ，用于机器翻译和文本摘要。
       </li>
       <li>
        2017 年，Google 发表论文《Attention Is All You Need》，提出
        <strong>
         Transformer
        </strong>
        模型，彻底改变 NLP 领域。
       </li>
      </ul>
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="_3_2018__Transformer__26">
     </a>
     <strong>
      🔹 3. 预训练大模型时代（2018 - 至今）：Transformer 和大规模语言模型
     </strong>
    </h4>
    <p>
     <strong>
      代表技术：
     </strong>
    </p>
    <ul>
     <li>
      <p>
       <strong>
        2018 年：BERT（Google）
       </strong>
      </p>
      <ul>
       <li>
        Google 发表
        <strong>
         BERT（Bidirectional Encoder Representations from Transformers）
        </strong>
        ，首次引入
        <strong>
         双向 Transformer 预训练
        </strong>
        ，显著提升 NLP 任务的表现。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        2019 年：GPT-2（OpenAI）
       </strong>
      </p>
      <ul>
       <li>
        OpenAI 推出
        <strong>
         GPT-2（Generative Pre-trained Transformer 2）
        </strong>
        ，展示了强大的文本生成能力，但由于担心滥用，最初未完全公开。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        2020 年：GPT-3（OpenAI）
       </strong>
      </p>
      <ul>
       <li>
        GPT-3 具有
        <strong>
         1750 亿参数
        </strong>
        ，是当时最大的语言模型，能够执行多种 NLP 任务，如写作、翻译、编程等。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        2021 年：T5、GPT-3.5、Codex
       </strong>
      </p>
      <ul>
       <li>
        Google 推出
        <strong>
         T5（Text-to-Text Transfer Transformer）
        </strong>
        ，强调统一 NLP 任务的架构。
       </li>
       <li>
        OpenAI 发布
        <strong>
         Codex
        </strong>
        ，用于代码生成，并成为 GitHub Copilot 的核心技术。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        2022 年：GPT-4、PaLM、BLOOM
       </strong>
      </p>
      <ul>
       <li>
        OpenAI 发布
        <strong>
         GPT-4
        </strong>
        ，具备更强的推理能力和多模态（文字+图片）处理能力。
       </li>
       <li>
        Google 推出
        <strong>
         PaLM（Pathways Language Model）
        </strong>
        ，支持更大的数据规模和更广泛的任务。
       </li>
       <li>
        由多个研究机构联合开发的
        <strong>
         BLOOM
        </strong>
        模型，作为开源替代方案。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        2023-2024 年：GPT-4 Turbo、Gemini、Claude
       </strong>
      </p>
      <ul>
       <li>
        OpenAI 推出
        <strong>
         GPT-4 Turbo
        </strong>
        ，在 GPT-4 的基础上优化了速度和成本。
       </li>
       <li>
        Google DeepMind 发布
        <strong>
         Gemini 1.5
        </strong>
        ，支持更长的上下文窗口（100 万 token）。
       </li>
       <li>
        Anthropic 公司推出
        <strong>
         Claude 3
        </strong>
        ，在推理和多模态能力上有所提升。
       </li>
      </ul>
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="__53">
     </a>
     <strong>
      🔹 未来趋势
     </strong>
    </h4>
    <ol>
     <li>
      <strong>
       更大规模、更高效的模型
      </strong>
      ：模型参数越来越大，但也在优化计算效率，如 Mixture-of-Experts（MoE）架构。
     </li>
     <li>
      <strong>
       多模态 AI
      </strong>
      ：不仅支持文本，还能理解和生成图像、音频、视频等内容。
     </li>
     <li>
      <strong>
       个性化 AI
      </strong>
      ：未来的 AI 可能会根据用户习惯进行个性化调整，提高交互体验。
     </li>
     <li>
      <strong>
       更强的推理与规划能力
      </strong>
      ：AI 可能会发展出更复杂的逻辑推理和长期规划能力。
     </li>
     <li>
      <strong>
       更安全和可控的 AI
      </strong>
      ：随着 AI 能力增强，如何避免滥用和确保安全性成为重要研究方向。
     </li>
    </ol>
    <hr/>
    <p>
     大语言模型具有以下能力：
    </p>
    <ol>
     <li>
      <strong>
       范围广泛的世界知识
      </strong>
     </li>
     <li>
      <strong>
       较强的人类指令遵循能力
      </strong>
     </li>
     <li>
      <strong>
       改进的复杂任务推理能力
      </strong>
     </li>
     <li>
      <strong>
       较强的通用任务解决能力
      </strong>
     </li>
     <li>
      <strong>
       较好的人类对齐能力
      </strong>
     </li>
     <li>
      <strong>
       较强的多轮对话交互能力
      </strong>
     </li>
    </ol>
    <p>
     这些能力使得大语言模型在知识问答、任务执行、逻辑推理、对话交互等方面表现出色，并推动 AI 技术在各个领域的应用与发展。 🚀
    </p>
    <hr/>
    <h3>
     <a id="2___74">
     </a>
     2. 大模型的到来引发的变革
    </h3>
    <p>
     大语言模型（LLM，如 GPT-4、Gemini、Claude 等）的发展，不仅提升了人工智能的能力，还在多个领域引发了深远的变革。以下是主要影响：
     <br/>
     <img alt="大模型发展历程" src="https://i-blog.csdnimg.cn/direct/032fc8f69c5842e7b44c6dab418da941.png"/>
    </p>
    <hr/>
    <h4>
     <a id="1__80">
     </a>
     <strong>
      1. 人工智能应用的普及
     </strong>
    </h4>
    <h5>
     <a id="__AI__AI__81">
     </a>
     <strong>
      🚀 传统 AI 向通用 AI 过渡
     </strong>
    </h5>
    <ul>
     <li>
      过去的 AI 主要是
      <strong>
       专用 AI
      </strong>
      （如语音助手、搜索引擎、翻译工具）。
     </li>
     <li>
      大模型推动了
      <strong>
       通用 AI
      </strong>
      （AGI）的发展，使 AI 能够处理更广泛的任务，如写作、编程、推理、创意生成等。
     </li>
    </ul>
    <p>
     ✅
     <strong>
      影响
     </strong>
     ：
    </p>
    <ul>
     <li>
      AI 由“工具”向“智能助手”转变，能自主执行复杂任务。
     </li>
     <li>
      AI 进入日常生活，如智能客服、虚拟助理、AI 生成内容（AIGC）。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="2_91">
     </a>
     <strong>
      2.生产力革命
     </strong>
    </h4>
    <h5>
     <a id="__92">
     </a>
     <strong>
      📈 提高工作效率，改变工作方式
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       自动化办公
      </strong>
      ：AI 生成报告、邮件、PPT，提升效率。
     </li>
     <li>
      <strong>
       智能编程
      </strong>
      ：AI 辅助代码开发（如 GitHub Copilot），减少重复劳动。
     </li>
     <li>
      <strong>
       数据分析
      </strong>
      ：AI 处理大规模数据，提高商业决策能力。
     </li>
    </ul>
    <p>
     ✅
     <strong>
      影响
     </strong>
     ：
    </p>
    <ul>
     <li>
      <strong>
       减少重复性工作
      </strong>
      ，让人类专注于创造性任务。
     </li>
     <li>
      <strong>
       降低技术门槛
      </strong>
      ，让非专业人士也能利用 AI 进行复杂任务。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="3_103">
     </a>
     <strong>
      3.产业变革
     </strong>
    </h4>
    <h5>
     <a id="__104">
     </a>
     <strong>
      🏭 传统行业的智能化升级
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       媒体与内容创作
      </strong>
      ：AI 生成文章、视频、音乐（AIGC）。
     </li>
     <li>
      <strong>
       教育
      </strong>
      ：智能辅导、个性化学习、自动批改作业。
     </li>
     <li>
      <strong>
       医疗
      </strong>
      ：AI 辅助诊断、药物研发、健康管理。
     </li>
     <li>
      <strong>
       法律
      </strong>
      ：合同审查、法律咨询自动化。
     </li>
     <li>
      <strong>
       金融
      </strong>
      ：智能投顾、风险评估、自动交易。
     </li>
    </ul>
    <p>
     ✅
     <strong>
      影响
     </strong>
     ：
    </p>
    <ul>
     <li>
      AI 让企业
      <strong>
       降本增效
      </strong>
      ，提高竞争力。
     </li>
     <li>
      传统行业加速
      <strong>
       数字化转型
      </strong>
      ，催生新商业模式。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="4_117">
     </a>
     <strong>
      4.人才市场的变化
     </strong>
    </h4>
    <h5>
     <a id="_AI__118">
     </a>
     <strong>
      👨‍💻 AI 取代部分岗位，催生新职业
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       减少低端重复性工作
      </strong>
      （如数据录入、基础客服）。
     </li>
     <li>
      <strong>
       催生新职业
      </strong>
      （如 AI 提示工程师、AI 伦理专家）。
     </li>
     <li>
      <strong>
       要求更高的技能
      </strong>
      （如 AI 驱动的决策、创造性思维）。
     </li>
    </ul>
    <p>
     ✅
     <strong>
      影响
     </strong>
     ：
    </p>
    <ul>
     <li>
      <strong>
       部分岗位被 AI 替代
      </strong>
      ，需要
      <strong>
       提升技能
      </strong>
      适应变化。
     </li>
     <li>
      <strong>
       人机协作成为主流
      </strong>
      ，AI 辅助人类完成更复杂的任务。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="5_129">
     </a>
     <strong>
      5.信息传播与认知变革
     </strong>
    </h4>
    <h5>
     <a id="_AI__130">
     </a>
     <strong>
      🌍 AI 影响人类获取和理解信息的方式
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       搜索引擎升级
      </strong>
      ：AI 直接回答问题，减少传统搜索需求。
     </li>
     <li>
      <strong>
       个性化推荐
      </strong>
      ：AI 根据用户偏好提供精准内容。
     </li>
     <li>
      <strong>
       信息生成
      </strong>
      ：AI 生成新闻、报告、社交媒体内容。
     </li>
    </ul>
    <p>
     ✅
     <strong>
      影响
     </strong>
     ：
    </p>
    <ul>
     <li>
      <strong>
       加速信息传播
      </strong>
      ，但也带来
      <strong>
       虚假信息
      </strong>
      风险。
     </li>
     <li>
      <strong>
       改变学习方式
      </strong>
      ，知识获取更加高效。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="6_141">
     </a>
     <strong>
      6.伦理与安全挑战
     </strong>
    </h4>
    <h5>
     <a id="_AI__142">
     </a>
     <strong>
      ⚠️ AI 发展带来的风险
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       假信息泛滥
      </strong>
      ：AI 生成的假新闻、深度伪造（deepfake）可能误导公众。
     </li>
     <li>
      <strong>
       数据隐私问题
      </strong>
      ：AI 需要大量数据，可能涉及隐私泄露。
     </li>
     <li>
      <strong>
       算法偏见
      </strong>
      ：AI 可能继承训练数据中的偏见，影响公平性。
     </li>
     <li>
      <strong>
       滥用问题
      </strong>
      ：AI 可能被用于诈骗、恶意攻击等。
     </li>
    </ul>
    <p>
     ✅
     <strong>
      影响
     </strong>
     ：
    </p>
    <ul>
     <li>
      需要
      <strong>
       加强 AI 监管
      </strong>
      ，制定
      <strong>
       伦理规范
      </strong>
      。
     </li>
     <li>
      促进
      <strong>
       可信 AI 发展
      </strong>
      ，确保 AI 透明、公正、安全。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="7_154">
     </a>
     <strong>
      7.科研与技术创新
     </strong>
    </h4>
    <h5>
     <a id="_AI__155">
     </a>
     <strong>
      🧠 AI 促进科学研究
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       加速新药研发
      </strong>
      ：AI 预测分子结构，缩短研发周期。
     </li>
     <li>
      <strong>
       物理与天文
      </strong>
      ：AI 处理大规模数据，加速科学发现。
     </li>
     <li>
      <strong>
       数学与理论研究
      </strong>
      ：AI 辅助证明数学定理。
     </li>
    </ul>
    <p>
     ✅
     <strong>
      影响
     </strong>
     ：
    </p>
    <ul>
     <li>
      AI 成为
      <strong>
       科研助手
      </strong>
      ，加速突破前沿科技。
     </li>
     <li>
      促进
      <strong>
       跨学科融合
      </strong>
      ，推动新技术发展。
     </li>
    </ul>
    <hr/>
    <p>
     大模型的到来不仅是 AI 领域的技术突破，更是
     <strong>
      社会、经济、文化
     </strong>
     领域的深刻变革。它提升了生产力，改变了产业格局，同时也带来了新的挑战和机遇。未来，我们需要
     <strong>
      合理利用 AI
     </strong>
     ，推动技术向更加
     <strong>
      安全、透明、可控
     </strong>
     的方向发展。🚀
    </p>
    <h3>
     <a id="3__167">
     </a>
     3. 大模型技术基础
    </h3>
    <h3>
     <a id="httpsiblogcsdnimgcndirect50d4e8a37b844fa0ad3255ca5c93cbe3png_168">
     </a>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/50d4e8a37b844fa0ad3255ca5c93cbe3.png"/>
    </h3>
    <h4>
     <a id="1_170">
     </a>
     <strong>
      1.大模型的定义
     </strong>
    </h4>
    <ul>
     <li>
      <strong>
       大语言模型
      </strong>
      指的是
      <strong>
       参数规模极大
      </strong>
      （通常数十亿到万亿级）的
      <strong>
       预训练语言模型
      </strong>
      ，能够理解和生成自然语言。
     </li>
     <li>
      这些模型通过
      <strong>
       大规模数据训练
      </strong>
      ，具备
      <strong>
       广泛的知识
      </strong>
      和
      <strong>
       语言理解能力
      </strong>
      。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="2_176">
     </a>
     <strong>
      2.大模型的架构
     </strong>
    </h4>
    <ul>
     <li>
      <strong>
       主要采用 Transformer 解码器架构
      </strong>
      <ul>
       <li>
        Transformer 是目前最先进的深度学习架构之一，具有
        <strong>
         并行计算能力强、长距离依赖建模能力强
        </strong>
        等特点。
       </li>
       <li>
        其中，大模型通常使用
        <strong>
         解码器（Decoder）
        </strong>
        结构，而非完整的编码器-解码器结构。
       </li>
      </ul>
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="3_183">
     </a>
     <strong>
      3.大模型的训练过程
     </strong>
    </h4>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/e3e0697643524fbca156b6747bddfb11.png">
      <br/>
      训练过程分为
      <strong>
       两大阶段
      </strong>
      ：
     </img>
    </p>
    <h5>
     <a id="_Pretraining__186">
     </a>
     <strong>
      🔹 预训练（Pre-training）—— 训练基础能力
     </strong>
    </h5>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/c0b426adf97f4c18a78c6dce70bcf947.png"/>
    </p>
    <ul>
     <li>
      <strong>
       数据
      </strong>
      ：使用
      <strong>
       海量文本数据
      </strong>
      （如书籍、论文、网页、对话等）。
     </li>
     <li>
      <strong>
       优化目标
      </strong>
      ：
      <strong>
       预测下一个词
      </strong>
      （Next Token Prediction）。
     </li>
     <li>
      <strong>
       结果
      </strong>
      ：训练出
      <strong>
       基础模型（Base Model）
      </strong>
      ，具备
      <strong>
       语言理解和生成能力
      </strong>
      ，但尚未针对具体任务优化。
     </li>
    </ul>
    <h5>
     <a id="_Finetuning__193">
     </a>
     <strong>
      🔹 后训练（Fine-tuning）—— 增强任务能力
     </strong>
    </h5>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/cbd80e66df5d4d2195b8209a2d273ce4.png"/>
    </p>
    <ul>
     <li>
      <strong>
       数据
      </strong>
      ：使用
      <strong>
       大量指令数据
      </strong>
      （如人类指令、对话数据、任务示例等）。
     </li>
     <li>
      <strong>
       优化方法
      </strong>
      ：
      <ul>
       <li>
        <strong>
         SFT（Supervised Fine-Tuning）
        </strong>
        ：监督微调，让模型更好地遵循人类指令。
       </li>
       <li>
        <strong>
         RLHF（Reinforcement Learning with Human Feedback）
        </strong>
        ：基于人类反馈的强化学习，使模型的回答更符合人类偏好。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       结果
      </strong>
      ：训练出
      <strong>
       指令模型（Instruct Model）
      </strong>
      ，能够更好地执行
      <strong>
       特定任务
      </strong>
      （如问答、代码生成、写作等）。
     </li>
    </ul>
    <hr/>
    <h5>
     <a id="_204">
     </a>
     拓展定律
    </h5>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/d2959d96ef0947f18b2dbef025a1fe6f.png"/>
    </p>
    <h6>
     <a id="_206">
     </a>
     核心观点
    </h6>
    <p>
     更大的模型（更多参数）+ 更多数据 + 更强算力 = 更强的 AI 能力
     <br/>
     通过扩展 计算量（Compute）、数据规模（Dataset Size） 和 模型参数（Parameters），可以系统性地降低模型的 测试损失（Test Loss），提升模型的表现。
     <br/>
     <strong>
      1. 计算量（Compute）
     </strong>
     <br/>
     计算量越大，模型训练得越充分，损失下降。
     <br/>
     但计算量的 回报递减，即增加计算量带来的收益逐渐减少。
     <br/>
     <strong>
      2. 数据规模（Dataset Size）
     </strong>
     <br/>
     训练数据越多，模型的泛化能力越强，损失下降更快。
     <br/>
     但如果数据质量低，单纯增加数据可能不会带来提升。
     <br/>
     <strong>
      3. 模型参数（Parameters）
     </strong>
     <br/>
     更大的模型（更多参数）通常表现更好，但前提是有足够的数据和计算资源支持。过大的模型如果数据不足，可能会导致 过拟合（overfitting）。
    </p>
    <ul>
     <li>
      <p>
       大模型为何有效？
      </p>
      <ul>
       <li>
        过去 AI 发展依赖于 算法优化，但大模型时代，规模扩展（Scaling）成为核心驱动力。
       </li>
       <li>
        只要 数据、算力、模型规模 继续增长，AI 仍能不断进步。
       </li>
      </ul>
     </li>
     <li>
      <p>
       GPT-4、Gemini 等大模型的成功
      </p>
      <ul>
       <li>
        这些模型的进化路径符合 扩展定律，即通过 增加参数、数据、算力 来提升能力。
       </li>
       <li>
        例如 GPT-4 相比 GPT-3，主要是 参数规模更大、数据更多、训练更充分，因此表现大幅提升。
       </li>
      </ul>
     </li>
     <li>
      <p>
       未来发展趋势
      </p>
      <ul>
       <li>
        目前的大模型仍在 扩展阶段，但未来可能会遇到 数据瓶颈 或 计算成本过高 的问题。
       </li>
       <li>
        研究人员正在探索 更高效的训练方法，如 混合专家模型（MoE）、自监督学习优化 等，以减少计算成本。
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <a id="_231">
     </a>
     <strong>
      涌现能力
     </strong>
    </h5>
    <h6>
     <a id="__232">
     </a>
     <strong>
      📌 什么是涌现能力？
     </strong>
    </h6>
    <p>
     <strong>
      涌现能力（Emergent Abilities）
     </strong>
     指的是
     <strong>
      在小型模型中不存在，但在大规模模型中突然出现的能力
     </strong>
     。
    </p>
    <hr/>
    <h6>
     <a id="1__237">
     </a>
     <strong>
      1. 涌现能力的定义
     </strong>
    </h6>
    <ul>
     <li>
      <strong>
       原始论文定义
      </strong>
      ：
      <blockquote>
       <p>
        “在小型模型中不存在，但在大模型中出现的能力。”
       </p>
      </blockquote>
     </li>
     <li>
      这意味着
      <strong>
       某些复杂任务的能力
      </strong>
      只有当模型达到
      <strong>
       足够大的规模
      </strong>
      时才会突然显现，而不是随着规模线性增长。
     </li>
    </ul>
    <hr/>
    <h6>
     <a id="2_244">
     </a>
     <strong>
      2.涌现能力的特点
     </strong>
    </h6>
    <ul>
     <li>
      <strong>
       非线性增长
      </strong>
      ：随着模型规模扩大，某些能力不会逐步提升，而是在
      <strong>
       达到某个临界点
      </strong>
      后突然跃升。
     </li>
     <li>
      <strong>
       超越随机水平
      </strong>
      ：在小模型中，模型的表现接近随机水平，但在大模型中，表现远超随机猜测。
     </li>
     <li>
      <strong>
       任务多样性
      </strong>
      ：涌现能力可以体现在
      <strong>
       数学推理、自然语言理解（NLU）、上下文推理
      </strong>
      等多个任务上。
     </li>
    </ul>
    <hr/>
    <h6>
     <a id="3__251">
     </a>
     <strong>
      3. 论文中的实验结果
     </strong>
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b0740ce500924ea1b154ac7c58315afe.png"/>
    </p>
    <ol>
     <li>
      <p>
       <strong>
        数学运算（Mod. Arithmetic）
       </strong>
      </p>
      <ul>
       <li>
        小模型几乎无法完成数学计算，但当模型规模达到 (10^{22}) 级别时，准确率突然大幅提升。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        多任务自然语言理解（Multi-task NLU）
       </strong>
      </p>
      <ul>
       <li>
        小模型的表现接近随机水平，但大模型在理解复杂语境时表现显著提升。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        上下文词义理解（Word in Context）
       </strong>
      </p>
      <ul>
       <li>
        只有当模型达到一定规模时，才能正确理解
        <strong>
         同一个词在不同上下文中的含义
        </strong>
        。
        <br/>
        <strong>
         某些能力只有当模型足够大时才会涌现
        </strong>
        ，而不是随着规模逐步提升。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h6>
     <a id="_266">
     </a>
     <strong>
      涌现能力的影响
     </strong>
    </h6>
    <ul>
     <li>
      <p>
       <strong>
        大模型的突破
       </strong>
       ：
      </p>
      <ul>
       <li>
        过去，AI 主要依赖
        <strong>
         手工设计规则
        </strong>
        或
        <strong>
         小规模模型优化
        </strong>
        ，但涌现能力表明
        <strong>
         规模本身就是一种优化手段
        </strong>
        。
       </li>
       <li>
        只要
        <strong>
         增加参数、数据和计算量
        </strong>
        ，AI 可能会自动学会某些复杂能力。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        AI 发展趋势
       </strong>
       ：
      </p>
      <ul>
       <li>
        未来 AI 可能会继续展现
        <strong>
         更多未曾预料的能力
        </strong>
        ，比如更强的推理、规划、甚至自主学习能力。
       </li>
       <li>
        研究人员需要探索
        <strong>
         如何控制和利用这些能力
        </strong>
        ，避免不可预测的风险。
       </li>
      </ul>
     </li>
    </ul>
    <hr/>
    <h3>
     <a id="4_277">
     </a>
     <strong>
      4.大模型核心技术解析
     </strong>
    </h3>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/a719164172454d81a46ec0f867fd2689.png"/>
    </p>
    <h4>
     <a id="1Scaling_280">
     </a>
     <strong>
      1.规模扩展（Scaling）
     </strong>
    </h4>
    <ul>
     <li>
      <strong>
       扩展定律（Scaling Laws）
      </strong>
      表明，
      <strong>
       增加模型参数、数据规模和计算量
      </strong>
      ，可显著提升模型能力。
     </li>
     <li>
      <strong>
       关键点
      </strong>
      ：参数规模增大（如 GPT-3 → GPT-4）、数据规模扩展、计算能力提升（GPU/TPU）。
     </li>
    </ul>
    <h4>
     <a id="2Data_Engineering_284">
     </a>
     <strong>
      2.数据工程（Data Engineering）
     </strong>
    </h4>
    <ul>
     <li>
      <strong>
       数据数量、质量和预处理方法
      </strong>
      直接决定模型性能。
     </li>
     <li>
      <strong>
       关键点
      </strong>
      ：海量高质量数据、数据清洗与增强、去噪处理。
     </li>
    </ul>
    <h4>
     <a id="3Efficient_Pretraining_288">
     </a>
     <strong>
      3.高效预训练（Efficient Pre-training）
     </strong>
    </h4>
    <ul>
     <li>
      <strong>
       大模型训练需要强大计算资源
      </strong>
      ，需建立高效、可扩展训练架构。
     </li>
     <li>
      <strong>
       关键点
      </strong>
      ：分布式训练、混合精度计算（FP16/FP8）、自监督学习。
     </li>
    </ul>
    <h4>
     <a id="4Capability_Activation_292">
     </a>
     <strong>
      4.能力激发（Capability Activation）
     </strong>
    </h4>
    <ul>
     <li>
      <strong>
       基础模型需微调（Fine-tuning）
      </strong>
      以适应特定任务。
     </li>
     <li>
      <strong>
       关键点
      </strong>
      ：微调、对齐技术（RLHF）、提示工程（Prompt Engineering）。
     </li>
    </ul>
    <h4>
     <a id="5Human_Alignment_296">
     </a>
     <strong>
      5.人类对齐（Human Alignment）
     </strong>
    </h4>
    <ul>
     <li>
      <strong>
       防止错误、有害或偏见内容
      </strong>
      ，确保 AI 可靠性。
     </li>
     <li>
      <strong>
       关键点
      </strong>
      ：安全性优化、减少幻觉（Hallucination）、伦理与公平性。
     </li>
    </ul>
    <h4>
     <a id="6Tool_Use_300">
     </a>
     <strong>
      6.工具使用（Tool Use）
     </strong>
    </h4>
    <ul>
     <li>
      <strong>
       结合外部工具增强能力，拓展应用范围
      </strong>
      。
     </li>
     <li>
      <strong>
       关键点
      </strong>
      ：代码执行（Python、SQL）、搜索引擎集成、插件（Plugins）。
     </li>
    </ul>
    <h3>
     <a id="5GPTDeepSeek_305">
     </a>
     5.GPT和DeepSeek介绍
    </h3>
    <h4>
     <a id="1_GPT_307">
     </a>
     1. GPT体系
    </h4>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/8c2cbba304fb4cc3a95893a0d79d772a.png"/>
    </p>
    <h4>
     <a id="2GPT_309">
     </a>
     2.GPT发展历程
    </h4>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/19a83aa498db41b0b77f277135916a40.png"/>
    </p>
    <h5>
     <a id="1_GPT12018___313">
     </a>
     <strong>
      1. GPT-1（2018）：开创预训练 + 微调范式
     </strong>
    </h5>
    <h6>
     <a id="__314">
     </a>
     <strong>
      🔹 关键优化点
     </strong>
    </h6>
    <ul>
     <li>
      <strong>
       引入 Transformer 架构
      </strong>
      ：相比 RNN 和 LSTM，Transformer 具备
      <strong>
       更强的并行计算能力
      </strong>
      ，提升了训练效率。
     </li>
     <li>
      <strong>
       自回归预训练（Autoregressive Pre-training）
      </strong>
      ：使用
      <strong>
       无监督学习
      </strong>
      训练，预测下一个词（Next Token Prediction）。
     </li>
     <li>
      <strong>
       微调（Fine-tuning）
      </strong>
      ：在特定任务（如问答、情感分析）上进行微调，提高模型的任务适应性。
     </li>
     <li>
      <strong>
       参数规模：1.17 亿
      </strong>
      （1.17B）。
     </li>
    </ul>
    <h6>
     <a id="__320">
     </a>
     <strong>
      🔹 局限性
     </strong>
    </h6>
    <ul>
     <li>
      <strong>
       数据规模较小
      </strong>
      （仅使用 BookCorpus 训练）。
     </li>
     <li>
      <strong>
       未使用大规模互联网数据
      </strong>
      ，知识覆盖有限。
     </li>
     <li>
      <strong>
       缺乏对齐技术
      </strong>
      ，容易生成不准确或不安全的内容。
     </li>
    </ul>
    <hr/>
    <h5>
     <a id="2GPT22019_327">
     </a>
     <strong>
      2.GPT-2（2019）：扩大规模，提升文本生成能力
     </strong>
    </h5>
    <h6>
     <a id="__328">
     </a>
     <strong>
      🔹 关键优化点
     </strong>
    </h6>
    <ul>
     <li>
      <strong>
       大规模数据训练
      </strong>
      ：使用
      <strong>
       WebText 数据集
      </strong>
      ，涵盖更广泛的文本内容。
     </li>
     <li>
      <strong>
       参数规模大幅增长
      </strong>
      ：
      <ul>
       <li>
        <strong>
         GPT-2 小型版
        </strong>
        ：1.5 亿（0.15B）
       </li>
       <li>
        <strong>
         GPT-2 完整版
        </strong>
        ：15 亿（1.5B）
       </li>
      </ul>
     </li>
     <li>
      <strong>
       更自然的文本生成
      </strong>
      ：生成的文本连贯性和上下文理解能力显著提升。
     </li>
     <li>
      <strong>
       零样本（Zero-shot）、少样本（Few-shot）学习
      </strong>
      ：在
      <strong>
       没有微调的情况下
      </strong>
      也能完成部分任务。
     </li>
    </ul>
    <h6>
     <a id="__336">
     </a>
     <strong>
      🔹 局限性
     </strong>
    </h6>
    <ul>
     <li>
      <strong>
       仍然存在幻觉（Hallucination）
      </strong>
      ，容易生成不真实的内容。
     </li>
     <li>
      <strong>
       缺乏人类对齐（Alignment）
      </strong>
      ，可能生成有害或偏见内容。
     </li>
     <li>
      <strong>
       计算成本较高
      </strong>
      ，训练难度增加。
     </li>
    </ul>
    <hr/>
    <h5>
     <a id="3GPT32020_343">
     </a>
     <strong>
      3.GPT-3（2020）：参数暴涨，涌现能力初现
     </strong>
    </h5>
    <h6>
     <a id="__344">
     </a>
     <strong>
      🔹 关键优化点
     </strong>
    </h6>
    <ul>
     <li>
      <strong>
       参数规模爆炸式增长
      </strong>
      ：
      <ul>
       <li>
        <strong>
         GPT-3
        </strong>
        ：1750 亿（175B）参数，远超 GPT-2。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       更强的涌现能力（Emergent Abilities）
      </strong>
      ：
      <ul>
       <li>
        <strong>
         数学运算、代码生成、逻辑推理
        </strong>
        等能力显著增强。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       少样本学习（Few-shot Learning）能力提升
      </strong>
      ：
      <ul>
       <li>
        通过
        <strong>
         提示工程（Prompt Engineering）
        </strong>
        ，模型可以在
        <strong>
         几乎不需要微调的情况下
        </strong>
        解决复杂任务。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       更丰富的数据训练
      </strong>
      ：
      <ul>
       <li>
        训练数据涵盖
        <strong>
         书籍、论文、代码、新闻、对话
        </strong>
        等多种文本来源。
       </li>
      </ul>
     </li>
    </ul>
    <h6>
     <a id="__354">
     </a>
     <strong>
      🔹 局限性
     </strong>
    </h6>
    <ul>
     <li>
      <strong>
       仍然缺乏 RLHF（人类反馈强化学习）
      </strong>
      ，容易生成不安全或有害内容。
     </li>
     <li>
      <strong>
       计算成本极高
      </strong>
      ，推理速度较慢。
     </li>
     <li>
      <strong>
       幻觉问题依然存在
      </strong>
      ，在事实性任务上仍有错误。
     </li>
    </ul>
    <hr/>
    <h5>
     <a id="4InstructGPT2022_RLHF_361">
     </a>
     <strong>
      4.InstructGPT（2022）：引入 RLHF，提高对齐性
     </strong>
    </h5>
    <h6>
     <a id="__362">
     </a>
     <strong>
      🔹 关键优化点
     </strong>
    </h6>
    <ul>
     <li>
      <strong>
       引入人类反馈强化学习（RLHF）
      </strong>
      ：
      <ul>
       <li>
        通过
        <strong>
         人类评分数据
        </strong>
        训练模型，使其更符合人类期望。
       </li>
       <li>
        <strong>
         减少有害内容
        </strong>
        ，提高回答的安全性和准确性。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       优化对话能力
      </strong>
      ：
      <ul>
       <li>
        <strong>
         更自然、更符合用户意图
        </strong>
        ，减少胡编乱造的情况。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       成为 ChatGPT 的基础
      </strong>
      ：
      <ul>
       <li>
        InstructGPT 是 ChatGPT 的前身，使 AI 更适合对话交互。
       </li>
      </ul>
     </li>
    </ul>
    <h6>
     <a id="__371">
     </a>
     <strong>
      🔹 局限性
     </strong>
    </h6>
    <ul>
     <li>
      <strong>
       仍然存在幻觉问题
      </strong>
      ，但比 GPT-3 有所改善。
     </li>
     <li>
      <strong>
       对话能力增强，但仍然无法进行深度推理和长期记忆
      </strong>
      。
     </li>
    </ul>
    <hr/>
    <h5>
     <a id="4GPT42023_377">
     </a>
     <strong>
      4.GPT-4（2023）：多模态增强，推理能力升级
     </strong>
    </h5>
    <h6>
     <a id="__378">
     </a>
     <strong>
      🔹 关键优化点
     </strong>
    </h6>
    <ul>
     <li>
      <strong>
       引入多模态能力（Multimodal）
      </strong>
      ：
      <ul>
       <li>
        <strong>
         支持图像输入
        </strong>
        ，可以理解图片内容（如 OpenAI 的 GPT-4V）。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       推理能力大幅提升
      </strong>
      ：
      <ul>
       <li>
        <strong>
         更强的逻辑推理、数学计算和代码生成能力
        </strong>
        。
       </li>
       <li>
        <strong>
         更长的上下文窗口
        </strong>
        ，可以处理更长的文本输入。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       更强的对齐技术
      </strong>
      ：
      <ul>
       <li>
        <strong>
         优化 RLHF 训练
        </strong>
        ，减少幻觉，提高事实性回答的准确率。
       </li>
       <li>
        <strong>
         更安全的内容生成
        </strong>
        ，降低偏见和错误信息。
       </li>
      </ul>
     </li>
    </ul>
    <h6>
     <a id="__388">
     </a>
     <strong>
      🔹 局限性
     </strong>
    </h6>
    <ul>
     <li>
      <strong>
       仍然无法完全消除幻觉问题
      </strong>
      ，在部分领域仍可能生成错误信息。
     </li>
     <li>
      <strong>
       计算成本极高
      </strong>
      ，推理速度仍然有限。
     </li>
     <li>
      <strong>
       对话记忆仍然有限
      </strong>
      ，无法进行长期上下文追踪。
     </li>
    </ul>
    <hr/>
    <h5>
     <a id="6GPT45__GPT5_395">
     </a>
     <strong>
      6.GPT-4.5 / GPT-5（未来预测）
     </strong>
    </h5>
    <h6>
     <a id="__396">
     </a>
     <strong>
      🔹 可能的优化点
     </strong>
    </h6>
    <ul>
     <li>
      <strong>
       更长的上下文窗口
      </strong>
      （如 100K+ tokens）。
     </li>
     <li>
      <strong>
       更强的多模态能力
      </strong>
      （结合视频、音频、3D 视觉等）。
     </li>
     <li>
      <strong>
       更高效的推理能力
      </strong>
      （更接近 AGI）。
     </li>
     <li>
      <strong>
       更低的计算成本
      </strong>
      ，使 AI 更容易普及。
     </li>
     <li>
      <strong>
       更强的个性化与记忆能力
      </strong>
      ，可以长期记住用户的偏好和对话历史。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="3DeepSeek_404">
     </a>
     3.DeepSeek技术
    </h4>
    <h5>
     <a id="_406">
     </a>
     发展历程
    </h5>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/a1e0693a17b7472a940ec272ff191db4.png"/>
    </p>
    <h5>
     <a id="_408">
     </a>
     改进点
    </h5>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/fcf3ef46726542b483bda0ed0982e05f.png"/>
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/13819c530bbf45b38b0f3b1e634a50b6.png"/>
    </p>
    <h5>
     <a id="DeepSeekV3_411">
     </a>
     DeepSeek-V3
    </h5>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/69cf0ff494a24d2292d6b9f403be6bf3.png"/>
    </p>
    <h5>
     <a id="DeepSeekR1_413">
     </a>
     DeepSeek-R1
    </h5>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b1be159bfa42473a9e281c8b2fe30bd4.png"/>
    </p>
    <h3>
     <a id="_416">
     </a>
     参考文献
    </h3>
    <p>
     <a href="https://www.datawhale.cn/learn/content/107/3294" rel="nofollow">
      Datawhale大模型组队学习地址
     </a>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34323931373335322f:61727469636c652f64657461696c732f313436313334363935" class_="artid" style="display:none">
 </p>
</div>


