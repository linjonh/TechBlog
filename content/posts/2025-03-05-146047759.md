---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f33303339383439392f:61727469636c652f64657461696c732f313436303437373539"
layout: post
title: "docker本地部署ollama"
date: 2025-03-05 17:07:19 +08:00
description: "前提是笔记本已配置NVIDIA的GPU驱动，可在shell中输入nvidia-smi查看详细情况。1.使用该命令启动CPU版运行本地AI模型。2.此命令用于启动GPU版本运行AI模型。启动ollama容器。"
keywords: "docker本地部署ollama"
categories: ['未分类']
tags: ['运维', '容器', 'Docker']
artid: "146047759"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146047759
    alt: "docker本地部署ollama"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146047759
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146047759
cover: https://bing.ee123.net/img/rand?artid=146047759
image: https://bing.ee123.net/img/rand?artid=146047759
img: https://bing.ee123.net/img/rand?artid=146047759
---

# docker本地部署ollama

启动ollama容器
  
1.使用该命令启动CPU版运行本地AI模型

docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
  
2.此命令用于启动GPU版本运行AI模型

前提是笔记本已配置NVIDIA的GPU驱动，可在shell中输入nvidia-smi查看详细情况

docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama