---
layout: post
title: "docker本地部署ollama"
date: 2025-03-05 17:07:19 +0800
description: "前提是笔记本已配置NVIDIA的GPU驱动，可在shell中输入nvidia-smi查看详细情况。1.使用该命令启动CPU版运行本地AI模型。2.此命令用于启动GPU版本运行AI模型。启动ollama容器。"
keywords: "docker本地部署ollama"
categories: ['未分类']
tags: ['运维', '容器', 'Docker']
artid: "146047759"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146047759
    alt: "docker本地部署ollama"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146047759
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146047759
cover: https://bing.ee123.net/img/rand?artid=146047759
image: https://bing.ee123.net/img/rand?artid=146047759
img: https://bing.ee123.net/img/rand?artid=146047759
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     docker本地部署ollama
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     启动ollama容器
     <br/>
     1.使用该命令启动CPU版运行本地AI模型
    </p>
    <p>
     docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
     <br/>
     2.此命令用于启动GPU版本运行AI模型
    </p>
    <p>
     前提是笔记本已配置NVIDIA的GPU驱动，可在shell中输入nvidia-smi查看详细情况
    </p>
    <p>
     docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
    </p>
    <p>
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f33303339383439392f:61727469636c652f64657461696c732f313436303437373539" class_="artid" style="display:none">
 </p>
</div>


