---
arturl_encode: "6874747073:3a2f2f626c6f672e6373646e2e6e65742f776873303332392f:61727469636c652f64657461696c732f313231383738313632"
layout: post
title: "关于IDEA出现报错-java.io.FileNotFoundException-HADOOP_HOME-and-hadoop.home.dir-are-unset."
date: 2025-01-08 22:15:30 +08:00
description: "今天在跑wc的时候，代码仔细确认很多遍没有问题，但就是一直报错如下：Exceptioninthrea"
keywords: "at wordcount。wordcountdriver . main(wordcountdriver. java:38 ) caused by: j"
categories: ['未分类']
tags: ['Java', 'Idea', 'Hadoop']
artid: "121878162"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=121878162
  alt: "关于IDEA出现报错-java.io.FileNotFoundException-HADOOP_HOME-and-hadoop.home.dir-are-unset."
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=121878162
featuredImagePreview: https://bing.ee123.net/img/rand?artid=121878162
---

# 关于IDEA出现报错： java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.、

今天在跑wc的时候，代码仔细确认很多遍没有问题，但就是一直报错如下：

Exception in thread "main" java.lang.RuntimeException: java.io.FileNotFoundException:
**java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems**
  
at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:736)
  
at org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:271)
  
at org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:287)
  
at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:867)
  
at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:549)
  
at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:589)
  
at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:561)
  
at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:588)
  
at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:566)
  
at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:332)
  
at org.apache.hadoop.mapreduce.JobSubmissionFiles.getStagingDir(JobSubmissionFiles.java:162)
  
at org.apache.hadoop.mapreduce.JobSubmissionFiles.getStagingDir(JobSubmissionFiles.java:113)
  
at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:148)
  
at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1565)
  
at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1562)
  
at java.security.AccessController.doPrivileged(Native Method)
  
at javax.security.auth.Subject.doAs(Subject.java:422)
  
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
  
at org.apache.hadoop.mapreduce.Job.submit(Job.java:1562)
  
at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1583)
  
at com.ruozedata.hadoop.mapreduce.wc.WordCountDriver.main(WordCountDriver.java:46)
  
Caused by: java.io.FileNotFoundException:
**java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems**
  
at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:548)
  
at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:569)
  
at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:592)
  
at org.apache.hadoop.util.Shell.<clinit>(Shell.java:689)
  
at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
  
at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1665)
  
at org.apache.hadoop.security.SecurityUtil.setConfigurationInternal(SecurityUtil.java:104)
  
at org.apache.hadoop.security.SecurityUtil.<clinit>(SecurityUtil.java:88)
  
at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:316)
  
at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:304)
  
at org.apache.hadoop.security.UserGroupInformation.doSubjectLogin(UserGroupInformation.java:1860)
  
at org.apache.hadoop.security.UserGroupInformation.createLoginUser(UserGroupInformation.java:718)
  
at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:668)
  
at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:579)
  
at org.apache.hadoop.mapreduce.task.JobContextImpl.<init>(JobContextImpl.java:72)
  
at org.apache.hadoop.mapreduce.Job.<init>(Job.java:150)
  
at org.apache.hadoop.mapreduce.Job.getInstance(Job.java:193)
  
at com.ruozedata.hadoop.mapreduce.wc.WordCountDriver.main(WordCountDriver.java:21)
  
Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.
  
at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:468)
  
at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:439)
  
at org.apache.hadoop.util.Shell.<clinit>(Shell.java:516)
  
... 14 more

问题扣出来就是：

![](https://i-blog.csdnimg.cn/blog_migrate/d32a1d3caac611d185146cdbbaec2782.png)

### 问题原因：

日志描述内容就是，没有设置  HADOOP_HOME 和 hadoop.home.dir 两项。而这两项就是配置在本地环境变量中的 Hadoop 地址，也就是需要我们在本地搭建Hadoop环境。

### 解决办法：

一、如果是远程连接
**Linux上的Hadoop集群**
，是不需要在本地再下载hadoop，只要
**下载winutils文件,然后配置环境变量，最后再把hadoop.dll文件放到 C:/windows/system32 下就可以了（
我亲测的也是这个
）**

二、
hadoop运行在windows系统上的，也是要下载
winutils
文件,然后配置环境变量，比上面多出一步就是，需要把你下的
**winutils文件下你需要的Hadoop版本的bin目录文件**
去
**替换**
你
**windows系统之前使用的Hadoop版本的bin目录文件，**
最后同样是把hadoop.dll文件放C:/windows/system32 下就可以（这个解决步骤在最后面）

### 解决步骤（一）：

1.下载
**winutils文件**

[GitHub - steveloughran/winutils: Windows binaries for Hadoop versions (built from the git commit ID used for the ASF relase)](https://github.com/steveloughran/winutils "GitHub - steveloughran/winutils: Windows binaries for Hadoop versions (built from the git commit ID used for the ASF relase)")

点击绿色的Code按钮，再选择Download Zip下载

![](https://i-blog.csdnimg.cn/blog_migrate/8d60216b3d1ed9095cd8c1d2de088182.png)

2.选择版本

如果没有和你版本一致的文件夹，就选择和你版本最相近的，因为我的Hadoop版本是3.2.2版本，所以我选择的是hadoop-3.0.0

![](https://i-blog.csdnimg.cn/blog_migrate/880c9af9e115ec457913b20821999ba9.png)

3.配置环境变量

配置系统环境变量：

新增 变量名：HADOOP_HOME   变量值：就是你上面选择的hadoop版本文件夹的位置地址

![](https://i-blog.csdnimg.cn/blog_migrate/084af459c3d15f41320caed57f5e5cb8.png)

在 变量名：path 中新增 变量值：%HADOOP_HOME%\bin
![](https://i-blog.csdnimg.cn/blog_migrate/f90aecad6523d64bef59a92e4ef25197.png)

4. 把hadoop.dll放到C:/windows/system32文件夹下

拷贝bin文件夹下的hadoop.dll文件

![](https://i-blog.csdnimg.cn/blog_migrate/77176fff44dc36bbb399c70e614329c2.png)

复制进C:/windows/system32文件夹下
![](https://i-blog.csdnimg.cn/blog_migrate/0a7b5ce925bb33738254434216cf818e.png)

6.重启IDEA，再次运行代码，跑成功。亲测哟！！！

**解决步骤（二）**
：哈哈哈！我没操作啦,但是你可以去下面这个链接操作

[java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. - 简书 (jianshu.com)](https://www.jianshu.com/p/6efd353c4b25 "java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. - 简书 (jianshu.com)")