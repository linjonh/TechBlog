---
layout: post
title: "文档图像前沿技术探索-多模态及图像安全"
date: 2023-10-19 17:56:52 +0800
description: "第六届中国模式识别与计算机视觉大会，文档图像前沿技术探索  |  多模态及图像安全"
keywords: "文档图像前沿技术探索 | 多模态及图像安全"
categories: ['前沿技术']
tags: ['多模态', '前沿技术', '人工智能']
artid: "133930763"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=133930763
    alt: "文档图像前沿技术探索-多模态及图像安全"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=133930763
featuredImagePreview: https://bing.ee123.net/img/rand?artid=133930763
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     文档图像前沿技术探索 | 多模态及图像安全
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p id="main-toc">
     <strong>
      目录
     </strong>
    </p>
    <p id="%E5%89%8D%E8%A8%80-toc" style="margin-left:0px;">
     <a href="#%E5%89%8D%E8%A8%80" rel="nofollow">
      前言
     </a>
    </p>
    <p id="%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E8%BF%9B%E5%B1%95%E4%B8%8E%E6%8E%A2%E7%B4%A2-toc" style="margin-left:0px;">
     <a href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E8%BF%9B%E5%B1%95%E4%B8%8E%E6%8E%A2%E7%B4%A2" rel="nofollow">
      多模态模型进展与探索
     </a>
    </p>
    <p id="%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89-toc" style="margin-left:40px;">
     <a href="#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89" rel="nofollow">
      大语言模型（LLM）
     </a>
    </p>
    <p id="%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88MLLM%EF%BC%89-toc" style="margin-left:40px;">
     <a href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88MLLM%EF%BC%89" rel="nofollow">
      多模态大语言模型（MLLM）
     </a>
    </p>
    <p id="%E5%9B%BE%E5%83%8F%E5%AE%89%E5%85%A8-toc" style="margin-left:0px;">
     <a href="#%E5%9B%BE%E5%83%8F%E5%AE%89%E5%85%A8" rel="nofollow">
      图像安全
     </a>
    </p>
    <p id="%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF-toc" style="margin-left:40px;">
     <a href="#%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF" rel="nofollow">
      研究背景
     </a>
    </p>
    <p id="%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84-toc" style="margin-left:40px;">
     <a href="#%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84" rel="nofollow">
      系统架构
     </a>
    </p>
    <p id="%E7%94%9F%E6%88%90%E5%BC%8FAI-toc" style="margin-left:40px;">
     <a href="#%E7%94%9F%E6%88%90%E5%BC%8FAI" rel="nofollow">
      生成式AI
     </a>
    </p>
    <p id="%E5%90%88%E5%90%88%E4%BF%A1%E6%81%AF-toc" style="margin-left:0px;">
     <a href="#%E5%90%88%E5%90%88%E4%BF%A1%E6%81%AF" rel="nofollow">
      合合信息
     </a>
    </p>
    <hr id="hr-toc"/>
    <p>
    </p>
    <h2 id="%E5%89%8D%E8%A8%80">
     前言
    </h2>
    <blockquote>
     <p>
      近期，
      <span style="color:#be191c;">
       <strong>
        第六届中国模式识别与计算机视觉大会（厦门PRCV 2023）顺利闭幕
       </strong>
      </span>
      。PRCV 2023
      <span style="color:#be191c;">
       大会由
       <strong>
        中国计算机学会
       </strong>
      </span>
      （CCF）、
      <span style="color:#be191c;">
       <strong>
        中国自动化学会
       </strong>
      </span>
      （CAA）
      <span style="color:#be191c;">
       、
       <strong>
        中国图象图形学学会
       </strong>
      </span>
      （CSIG）和
      <span style="color:#be191c;">
       <strong>
        中国人工智能学会
       </strong>
      </span>
      （CAAI）联合主办，厦门大学承办，是国内顶级的模式识别和计算机视觉领域学术盛会，CCF推荐会议(C类)。
     </p>
    </blockquote>
    <p>
     本次会议特邀合合信息智能技术平台事业部副总经理郭丰俊博士进行专题分享。
     <u>
      郭博士是上海交通大学模式识别与智能系统博士，长期从事文字识别（包括手写/OCR），图像处理研究，系CSIG文档图像分析与识别专委会常务委员
     </u>
     。对于文档图像的处理有着非常宝
     <span style="color:#be191c;">
      <strong>
       资深的经验
      </strong>
     </span>
     ，郭博士此次会议主要对
     <span style="color:#be191c;">
      <strong>
       多模态
      </strong>
     </span>
     和
     <span style="color:#be191c;">
      <strong>
       图像安全
      </strong>
     </span>
     两大模块进行干货分享。
    </p>
    <p>
     <img alt="" height="1074" src="https://i-blog.csdnimg.cn/blog_migrate/2f5fea7fff46e82ccd29b6c434ff8cf9.png" width="1200"/>
    </p>
    <p>
     <strong>
      多模态（GPT-4V）
     </strong>
    </p>
    <blockquote>
     <p>
      2023年3月15日，Open AI发布了
      <u>
       多模态预训练大模型GPT4.0
      </u>
      ，可以把多模态引入OCR当中。初步评估发现：英文OCR较好；中文OCR不理想；并且在识别图像时存在一些问题：
     </p>
    </blockquote>
    <p>
     ①出现缺少文本或字符（文字丢失）；
    </p>
    <p>
     ②缺少数学符号（对于数学公式的识别有问题）；
    </p>
    <p>
     ③无法识别空间位置和颜色（空间位置和文字颜色无法识别）；
    </p>
    <p>
     <img alt="" height="253" src="https://i-blog.csdnimg.cn/blog_migrate/6ab4d27f32e5c5c843b1156830c1820f.png" width="953"/>
    </p>
    <p>
     <strong>
      文档图像
     </strong>
    </p>
    <p>
     <u>
      文档图像
     </u>
     从表面上来看既是文字也是图像，本质上就是一个
     <u>
      天然多模态的属性
     </u>
     。所以可以通过
     <u>
      多模态的大模型
     </u>
     来做文档图像方面的任务。
    </p>
    <p>
     <img alt="" height="245" src="https://i-blog.csdnimg.cn/blog_migrate/14dadb2468f1d78f477542aee2c2c0ba.png" width="692"/>
    </p>
    <h3>
    </h3>
    <h2 id="%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E8%BF%9B%E5%B1%95%E4%B8%8E%E6%8E%A2%E7%B4%A2">
     多模态模型进展与探索
    </h2>
    <blockquote>
     <p>
      随着2022年11月30日OpenAI发布
      <strong>
       人工智能对话模型chatGPT
      </strong>
      以来，大模型技术掀起了新一轮人工智能浪潮。chatGPT在自然语言处理任务中表现出色，尤其是在生成式任务（如机器翻译、对话生成、文章摘要等）方面。越来越多的人开始关心
      <u>
       大模型
      </u>
      能否给我们的工作带来便捷？或者说忧虑会不会取代我们现在的工作岗位？
     </p>
    </blockquote>
    <h3 id="%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLM%EF%BC%89">
     大语言模型（LLM）
    </h3>
    <blockquote>
     <p>
      大语言模型（LLM），也称大型语言模型，是一种人工智能模型，旨在理解和生成人类语言。它们在大量的文本数据上进行训练，可以执行广泛的任务，包括文本总结、翻译、情感分析等等。LLM的特点是
      <u>
       规模庞大，包含数十亿的参数
      </u>
      ，帮助它们学习语言数据中的复杂模式。比较典型的代表就是chatGPT。
     </p>
    </blockquote>
    <p>
     <strong>
      LLM时代文档图像处理技术趋势
     </strong>
    </p>
    <blockquote>
     <p>
      输入端：采用多模态的方法；
     </p>
     <p>
      架构方面：采用Transformer Encoder / Decoder；
     </p>
     <p>
      数据层面：需要海量、高质量的数据；
     </p>
    </blockquote>
    <p>
     以上都满足了才能得到一个比较好的文档图像大模型的效果！
    </p>
    <p>
     <strong>
      LLM时代文档图像技术机会
     </strong>
    </p>
    <p>
     chatCPT-4的出世是不是就对以前做OCR的方法产生危机？前面说了要想得到高质量的文档图像大模型的效果，在
     <u>
      数据层面必须要有海量高质量的数据，而OCR本身就是一个提供高质量数据的工具
     </u>
    </p>
    <blockquote>
     <p>
      ①可以高效的录入；
     </p>
     <p>
      ②支持不同格式；
     </p>
    </blockquote>
    <p>
     <img alt="" height="331" src="https://i-blog.csdnimg.cn/blog_migrate/2f66ebfe520ff4becf1b0872da0182c8.png" width="1008"/>
    </p>
    <p>
     并且合合信息-华南理工大学文档图像分析识别与理解联合实验室对多模态和传统的OCR在文档图像识别方向展开了研究。从目前评测的情况来看，已知的多模态预训练系统在文档图像识别准确率上还逊于最先进的OCR识别系统。所以无论是大模型还是多态大模型的出世，OCR仍然是一个很有价值的技术！
    </p>
    <p>
    </p>
    <h3 id="%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88MLLM%EF%BC%89">
     多模态大语言模型（MLLM）
    </h3>
    <blockquote>
     <p>
      多模态大语言模型（Multimodal Large Language Model，MLLM）依赖于LLM丰富的知识储备以及强大的推理和泛化能力来解决多模态问题，目前已经涌现出一些令人惊叹的能力，比如看图写作和看图写代码。
     </p>
    </blockquote>
    <p>
     <strong>
      MLLM时代文档图像处理技术趋势
     </strong>
    </p>
    <p>
     知名系统：
    </p>
    <blockquote>
     <p>
      <strong>
       BLIP2 – Saleforce：
      </strong>
      Q-Former连接图像编码器(ViT)和LLM解码器; 仅需训练Q-Former部分
      <strong>
       Flamingo – DeepMind：
      </strong>
      在LLM中增加Gated Attention层引入视觉信息
     </p>
     <p>
      <strong>
       LLaVA – Miscrosoft：
      </strong>
      将CLIP ViT-L和LLaMA采用全连接层连接; 使用GPT-4和Self-Instruct生成高质量的158k instruction following数据
     </p>
     <p>
      <strong>
       MiniGPT – Vision CAIR Group, KAUST：
      </strong>
      ViT+ Q-Former + Vicuna
     </p>
     <p>
      <strong>
       Nougat – Meta：
      </strong>
      Swin Transformer + Transformer Decoder 图像到序列范式; 820万页文档的数据集
     </p>
     <p>
      <strong>
       Kosmos-2.5：
      </strong>
      Swin Transformer + Transformer Decoder 范式; 3.2亿的数据和1.3B的模型达到远超Nougat等Sota指标
     </p>
     <p>
      <strong>
       Donut – NAVER：
      </strong>
      无需OCR, 用于文档理解的Transformer模型
     </p>
    </blockquote>
    <p>
     性能分析：
    </p>
    <blockquote>
     <p>
      下面是知名文档图像大模型OCR性能分析与传统的OCR进行比较分析，性能方面对OCR的识别率还是不如传统的方式。
     </p>
    </blockquote>
    <p>
     <img alt="" height="199" src="https://i-blog.csdnimg.cn/blog_migrate/a43c65f5e94d63c733440586d373b665.png" width="957"/>
    </p>
    <p>
     结果：系统测评的系统性能还待提高； 可能原因：视觉编码器的分辨率和训练数据限制；
    </p>
    <p>
    </p>
    <h2 id="%E5%9B%BE%E5%83%8F%E5%AE%89%E5%85%A8">
     图像安全
    </h2>
    <blockquote>
     <p>
      生成式人工智能AIGC（Artificial Intelligence Generated Content）是
      <a href="https://baike.baidu.com/item/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/9180?fromModule=lemma_inlink" rel="nofollow" title="人工智能">
       人工智能
      </a>
      1.0时代进入2.0时代的重要标志。GAN、CLIP、Transformer、Diffusion、预训练模型、多模态技术、生成算法等技术的累积融合，催生了AIGC的爆发。算法不断迭代创新、预训练模型引发AIGC技术能力质变，多模态推动AIGC内容多边形，使得AIGC具有更通用和更强的基础能力。
     </p>
     <p>
      随着生成式人工智能（AIGC）的不断发展壮大，同时给社会带来了一系列严重的问题和挑战。其中包括截图伪造、生成式图片和身份信息泄露等方面。使得图像的真伪就难以辨别，
      <span style="color:#be191c;">
       <u>
        图像安全就变的越来越重要
       </u>
       。
      </span>
     </p>
    </blockquote>
    <h3 id="%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF">
     研究背景
    </h3>
    <blockquote>
     <p>
      大模型技术的不断突破让生成式AI拥有了更广泛的落地空间，同时也让图片伪造的门槛变得越来更低，这就给了一些不法分子可乘之机。AI图像安全为生成式人工智能（AIGC）健康发展、规模化应用保驾护航，解决负面社会问题。例如：
      <span style="color:#be191c;">
       <u>
        换脸
       </u>
      </span>
      、
      <span style="color:#be191c;">
       <u>
        证照的篡改
       </u>
      </span>
      。
     </p>
    </blockquote>
    <p>
     <strong>
      AI换脸
     </strong>
    </p>
    <blockquote>
     <p>
      近年来随着人工智能技术的迅速发展，AI 在图像领域的应用也日益广泛。2023年5月24日，中国互联网协会发文提示“AI换脸”新骗局，利用“AI换脸”“AI换声”等虚假音视频，进行诈骗、诽谤的违法行为屡见不鲜。合合信息发布的生成式图像鉴别技术，帮助个人及机构识别判断AI图片原始属性，规避可能存在的欺诈、伦理等方面的风险。
     </p>
    </blockquote>
    <p>
     <img alt="" height="425" src="https://i-blog.csdnimg.cn/blog_migrate/e2ee466a9f7d8f84b3926ecf8cb07fc3.png" width="990"/>
    </p>
    <p>
     主要应用场景：保险骗保、虚假积分，金融欺诈等
    </p>
    <p>
     <img alt="" height="394" src="https://i-blog.csdnimg.cn/blog_migrate/345f73bb6829c929760c7b866ff4c826.png" width="943"/>
    </p>
    <p>
    </p>
    <p>
     <strong>
      证件篡改
     </strong>
    </p>
    <blockquote>
     <p>
      随着经济社会的发展，公民在越来越多的经济社会活动中需要以居民身份证等身份证明文件证明身份。一方面，伪造、变造、买卖居民身份证、护照、社会保障卡、驾驶证等依法可以用于证明身份的证件的行为,为不法分子使用伪造、变造的或者盗用他人的身份证件提供了便利。另一方面，使用伪造、变造的或者盗用他人身份证件的行为，也为不法分子伪造、变造、买卖相关身份证件的行为提供了市场需求和驱动力。
     </p>
    </blockquote>
    <p>
     图像证件篡改的主要分为四种类型：
     <strong>
      <u>
       复制移动
      </u>
     </strong>
     、
     <strong>
      <u>
       拼接
      </u>
     </strong>
     、
     <strong>
      <u>
       擦
      </u>
      <u>
       除
      </u>
     </strong>
     、
     <strong>
      <u>
       重打印
      </u>
     </strong>
    </p>
    <p>
     ①复制移动即在原图中“抠”出关键要素再粘贴到另一处；
    </p>
    <p>
     ②拼接是将不同图像拼接成一张新图像；
    </p>
    <p>
     ③擦除能够不留痕迹地擦掉一些关键信息，如去除大面积复杂水印；
    </p>
    <p>
     ④重打印则是在擦除的基础上重新编辑新文档。
    </p>
    <p>
     <img alt="" height="353" src="https://i-blog.csdnimg.cn/blog_migrate/ab5320cbb2ffe17e98219107bc3e5f01.png" width="695"/>
    </p>
    <h3>
    </h3>
    <h3 id="%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84">
     系统架构
    </h3>
    <blockquote>
     <p>
      对于上述四种图像篡改的类型，需要先进的检测技术来大批量发现被篡改/伪造的信息，保障信息真实性，防止欺诈行为的发生！
     </p>
    </blockquote>
    <p>
     <span style="color:#be191c;">
      <strong>
       合合信息
      </strong>
     </span>
     提出了一种
     <span style="color:#be191c;">
      <strong>
       基于HRNet的编码器－解码器结构的图像真实性鉴别模型
      </strong>
     </span>
     ，使用分割模型，Backbone使用ConvNeXt作为编码器，用LightHam和EANet两个网络并行作为解码器，结合图像本身的信息包括但不限于噪声、频谱等，从而捕捉到细粒度的视觉差异，达到高精度鉴别目的。
    </p>
    <p>
     <img alt="" height="379" src="https://i-blog.csdnimg.cn/blog_migrate/0e71113fd63f0c6691bea444d723c5a7.png" width="675"/>
    </p>
    <p>
     <strong>
      技术挑战
     </strong>
    </p>
    <blockquote>
     <p>
      目前，图像篡改检测技术的应用也面临着篡改手段不断变化、场景复杂等系列挑战，不断提升检测系统的鲁棒性和泛化能力，是学术界与企业界需要深入合作的重要方向。
     </p>
    </blockquote>
    <p>
     泛化研究：通过大量数据的构建去调优
    </p>
    <p>
     <img alt="" height="349" src="https://i-blog.csdnimg.cn/blog_migrate/6e28468a431647d789cdfbb8e40b605f.png" width="964"/>
    </p>
    <p>
     <strong>
      落地现状
     </strong>
    </p>
    <blockquote>
     <p>
      已经落地的行业：证券、保险、银行、零售等............
     </p>
    </blockquote>
    <p>
     Textln开放平台：
     <a href="https://www.textin.com/market/detail/manipulation_detection" rel="nofollow" title="TextIn - 机器人市场 - PS检测通用版">
      TextIn - 机器人市场 - PS检测通用版
     </a>
    </p>
    <p>
     <img alt="" height="551" src="https://i-blog.csdnimg.cn/blog_migrate/5e10fe18b012b7b597bc8c588594081f.png" width="1125"/>
    </p>
    <h3>
    </h3>
    <h3 id="%E7%94%9F%E6%88%90%E5%BC%8FAI">
     生成式AI
    </h3>
    <p>
     <img alt="" height="336" src="https://i-blog.csdnimg.cn/blog_migrate/206c8e7652f57c928960afb5fd3e9fd2.png" width="1052"/>
    </p>
    <p>
     以人脸场景为例：
    </p>
    <blockquote>
     <p>
      模型结构：通过多个空间注意力头来关注空间特征，并使用纹理增强模块放大浅层特征中的细微伪影，增强模型对真实人脸和伪造人脸的感知与判断准确度。
     </p>
    </blockquote>
    <p>
     <img alt="" height="290" src="https://i-blog.csdnimg.cn/blog_migrate/3dd2255cd90a7eca6e3455d4f53d0e8e.png" width="930"/>
    </p>
    <p>
    </p>
    <p>
     结果可视化：
    </p>
    <p>
     <img alt="" height="386" src="https://i-blog.csdnimg.cn/blog_migrate/c608f5be9aa1a9c23b8aef1d4ecd6c72.png" width="807"/>
    </p>
    <p>
     应用范围及进展：
    </p>
    <blockquote>
     <p>
      <u>
       合合信息
      </u>
      研发了基于深度学习的图像篡改检测技术及相关系统，可检测出多种篡改形式，智能捕捉图像在篡改过程中留下的细微痕迹，并以热力图的形式展示图像区域篡改地点，相关技术已被应用于银行、保险等行业中。
     </p>
    </blockquote>
    <p>
     ①身份验证和访问控制
    </p>
    <p>
     ②移动设备的安全检测
    </p>
    <p>
     ③数字图像真实鉴定
    </p>
    <p>
     <img alt="" height="290" src="https://i-blog.csdnimg.cn/blog_migrate/8b1e77cc5fab4ee27f913514b941e99c.png" width="678"/>
    </p>
    <p>
    </p>
    <p>
     <strong>
      图像篡改检测标准制定
     </strong>
    </p>
    <blockquote>
     <p>
      由
      <u>
       中国信息通信研究院
      </u>
      牵头，联合
      <u>
       上海合合信息科技股份有限公司
      </u>
      、
      <u>
       中国图象图形学学会
      </u>
      、
      <u>
       中国科学技术大学
      </u>
      等知名学术机构、科技创新企业，启动《文档图像篡改检测标准》制定工作。希望持续推动AI技术在图像安全领域的广泛应用，带给用户更加安全、高效的工作和生活体验。
     </p>
    </blockquote>
    <p>
     <img alt="" height="397" src="https://i-blog.csdnimg.cn/blog_migrate/20196d8143471f17e2caf66f960fb9f1.png" width="1200"/>
    </p>
    <h3>
    </h3>
    <h2 id="%E5%90%88%E5%90%88%E4%BF%A1%E6%81%AF">
     合合信息
    </h2>
    <blockquote>
     <p>
      上海合合信息科技股份有限公司基于自主研发的领先的智能文字识别及商业大数据核心技术，为全球C端用户和多元行业B端客户提供数字化、智能化的产品及服务。
     </p>
    </blockquote>
    <p>
     <strong>
      1. C端产品：深受
      <u>
       全球用户
      </u>
      喜爱的效率工具
     </strong>
    </p>
    <blockquote>
     <p>
      公司C端业务主要为包括
      <span style="color:#be191c;">
       <u>
        扫描全能王
       </u>
      </span>
      （智能文字扫描及识别APP）、
      <u>
       名片全能王
      </u>
      （智能名片及人脉管理APP）、
      <span style="color:#be191c;">
       <u>
        启信宝
       </u>
      </span>
      （企业商业信息查询APP）3款核心产品。全球累计用户下载超 23亿
     </p>
    </blockquote>
    <p>
     <img alt="" height="347" src="https://i-blog.csdnimg.cn/blog_migrate/578b97a4992392b29726fd91788ca7db.png" width="676"/>
    </p>
    <p>
     <strong>
      2. B端服务：AI+大数据赋能数字化转型
     </strong>
    </p>
    <blockquote>
     <p>
      公司B端业务为面向企业客户提供以智能文字识别、商业大数据为核心的服务，形成了包括基础技术服务、标准化服务和场景化解决方案的业务矩阵，为客户提供降本增效、风险管理、智能营销等产品及服务，助力客户实现数字化与智能化的转型升级。
     </p>
    </blockquote>
    <p>
     <img alt="" height="312" src="https://i-blog.csdnimg.cn/blog_migrate/6f4d490e409daae58cdd62e036e836d9.png" width="677"/>
    </p>
    <p>
    </p>
    <p>
     <strong>
      3. 智能文字识别产品：
      <a href="https://www.textin.com/" rel="nofollow" title="TextIn">
       TextIn
      </a>
     </strong>
    </p>
    <blockquote>
     <p>
      TextIn是合合信息旗下的一站式OCR服务平台，该平台根据不同的业务场景和需求，将产品分为了通用识别、票据识别、企业证照识别、车辆相关识别、个人证件识别、港澳台证件识别、海外证件识别、文档格式转换和图像处理等，满足各种客户的图像识别和文档处理需求。
     </p>
    </blockquote>
    <p>
     <img alt="" height="397" src="https://i-blog.csdnimg.cn/blog_migrate/117c64e7ab9ed54cd2956a8c1a7f9388.png" width="1200"/>
    </p>
    <p>
     <strong>
      TextIn还可以对PS篡改检测进行体验，详细步骤如下：
     </strong>
    </p>
    <p>
     第一步：打开合合信息官网：
     <a href="https://b.intsig.com/ocr" rel="nofollow" title="合合信息_OCR识别|智能文字识别|图片识别文字">
      合合信息_OCR识别|智能文字识别|图片识别文字
     </a>
    </p>
    <p>
     <img alt="" height="764" src="https://i-blog.csdnimg.cn/blog_migrate/555f0a06e739700a7541cf07fa56ace8.png" width="1200"/>
    </p>
    <p>
     第二步：点击申请使用
    </p>
    <p>
     <img alt="" height="621" src="https://i-blog.csdnimg.cn/blog_migrate/85df444a21bf9040ff05210fcaa96e46.png" width="1200"/>
    </p>
    <p>
     第三步：仿纂改检测效果展示，
    </p>
    <p>
     <img alt="" height="338" src="https://i-blog.csdnimg.cn/blog_migrate/a973974fe474cdd1f0184f71b47072c4.png" width="915"/>
    </p>
    <p>
     <strong>
      总结：
     </strong>
    </p>
    <p>
     近年来，经过深度学习篡改生成的文本图像已广泛传播于互联网，对金融票据、证件和网页内容识别等多个行业领域产生了重要影响。但是目前对于文档图像分析识别与理解的技术也有很多难题。例如：
    </p>
    <blockquote>
     <p>
      ①场景及版式多样；例如：形状不可控、光照不可控
     </p>
     <p>
      ②采集设备不确定性；例如：收集摄像头、扫描仪、工业机器人、智能机器人
     </p>
     <p>
      ③用户需求多样性；例如：高精度：金融票据、可理解：教育、档案、办公
     </p>
     <p>
      ④文档图像质量退化严重；例如：看不清
     </p>
     <p>
      ⑤文字检测及版面分析困难；例如：看不准
     </p>
     <p>
      ⑥非限定条件文字识别率低；例如：认不全
     </p>
     <p>
      ⑦结构化智能理解能力差；例如：难理解
     </p>
    </blockquote>
    <p>
     合合信息智能文档处理技术覆盖了图像预处理、解析识别到AI安全等文档图像处理全生命周期，图像篡改检测技术不仅能够应用于自然场景，还能应用于资质证书、文档合同、银行保单等截图的鉴别上。针对图片生成式造假，合合信息基于空域与频域关系建模，利用多维度特征来分辨真实图片和生成式图片的细微差异，判断图片是否由AI生成。专注于智能文字识别、图像处理、自然语言处理（NLP）、知识图谱、大数据挖掘等技术，有着非常丰富的经验，感兴趣的小伙伴可以通过以下方式进行了解：
    </p>
    <p>
     <strong>
      <u>
       合合信息公众号
      </u>
      ：
     </strong>
     微信搜索【合合信息】
    </p>
    <p>
     <strong>
      <u>
       合合信息TextIn智能文字识别平台
      </u>
      ：
     </strong>
     <a href="https://www.textin.com/" rel="nofollow" title="TextIn">
      TextIn
     </a>
    </p>
   </div>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f36313933333937362f:61727469636c652f64657461696c732f313333393330373633" class_="artid" style="display:none">
 </p>
</div>


