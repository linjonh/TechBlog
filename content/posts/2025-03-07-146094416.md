---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34323838313736382f:61727469636c652f64657461696c732f313436303934343136"
layout: post
title: "使用Node.js从零搭建DeepSeek本地部署Express框架Ollama"
date: 2025-03-07 16:57:02 +0800
description: "使用Node.js从零搭建DeepSeek本地部署..."
keywords: "使用Node.js从零搭建DeepSeek本地部署（Express框架、Ollama）"
categories: ['大模型', 'Node', 'Express']
tags: ['Ollama', 'Node', 'Express', 'Deepseek']
artid: "146094416"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146094416
    alt: "使用Node.js从零搭建DeepSeek本地部署Express框架Ollama"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146094416
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146094416
cover: https://bing.ee123.net/img/rand?artid=146094416
image: https://bing.ee123.net/img/rand?artid=146094416
img: https://bing.ee123.net/img/rand?artid=146094416
---

# 使用Node.js从零搭建DeepSeek本地部署（Express框架、Ollama）

## 1.安装Node.js和npm

* 首先确保我们机器上已经安装了Node.js和npm。如果未安装，可以通过以下链接下载并安装适合我们操作系统的版本：
    
  [Node.js官方下载页面](https://nodejs.org/zh-cn?spm=5176.28103460.0.0.49e3451esLqOEJ)
* 关于Node.js的安装可以参考该篇文章：
    
  [Node.js的安装及环境配置【超详细】](https://blog.csdn.net/weixin_42881768/article/details/105028164?ops_request_misc=%257B%2522request%255Fid%2522%253A%25221ce436c31cab355f68387efb4a89562a%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=1ce436c31cab355f68387efb4a89562a&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-105028164-null-null.nonecase&utm_term=%E5%AE%89%E8%A3%85&spm=1018.2226.3001.4450)
* 安装完成后，可以通过以下命令检查是否安装成功：

```typescript
node -v
npm -v

```

* 安装成功界面：
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/d052b2a6383547289b7aa43b429e97fa.png)
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/714e85d58cf843ffbe6ce939400cc86a.png)

## 2.初始化项目

* 使用以下命令，创建一个新的文件夹作为项目目录，并初始化一个Node.js项目：

```typescript
mkdir deepseek-nodejs
cd deepseek-nodejs
npm init -y

```

* 如下图：
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c0ac4370504f4adda52b7c4da0d4922e.png)
* 以上命令会在当前目录下生成一个package.json文件，用于管理项目的依赖关系和其他配置信息。

## 3.安装Ollama

* 访问Ollama官网下载适合我们电脑操作系统的安装包，并按照提示进行安装：
    
  [Ollama官方下载页面](https://ollama.com/download/mac)
* 对于Linux用户，可以通过以下命令直接安装：

```typescript
curl -fsSL https://ollama.com/install.sh | sh

```

* 安装完成后，验证是否成功安装：

```typescript
ollama -v

```

* 如下图：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/df2dadd52287400f94b114b60b8efd54.png)

## 4.下载DeepSeek模型

* 安装完Ollama后，我们可以通过其界面选择并下载DeepSeek-R1模型。以下是下载并运行DeepSeek-R1 1.5B版本的示例命令：

```typescript
ollama run deepseek-r1:1.5b

```

根据我们机器的硬件配置，可以选择不同规模的模型版本，如7B、14B等

* 不同模型创建命令：
    
  [创建命令](https://ollama.com/library/deepseek-r1:1.5b)
* 不同规模的模型版本参数核心区别：

| 参数规模 | 特点和应用场景 | 部署需求和资源消耗 | 应用场景 |
| --- | --- | --- | --- |
| 1.5B | 适合简单的文本生成任务，如客服话术和短文案生成，但逻辑推理能力较弱‌ | 适合本地部署，资源消耗低，可以在消费级显卡上运行‌ | 生成食谱步骤和基础问答‌ |
| 7B-8B | 适合多轮对话和中等复杂度的任务，如代码补全和基础科研工作‌ | 适合本地部署，资源消耗低，可以在消费级显卡上运行‌ | ChatGPT级对话和中等复杂度代码生成‌ |
| 14B | 适合多轮对话和中等复杂度的任务，如代码补全和基础科研工作‌ | 需要在高性能GPU上运行，如A100/H100/H800等‌ | 科研论文辅助撰写和跨领域知识推理‌ |
| 32B | 具备接近人类水平的复杂任务处理能力，如法律文档分析和数学证明‌ | 需要在高性能GPU上运行，如A100/H100/H800等‌ | 科研论文辅助撰写和跨领域知识推理‌ |
| 70B | 适用于前沿研究和超高性能计算场景‌ | 需要多卡并行和云服务支持，适用于全球高并发场景‌ | 多模态融合和超长文本生成（如小说/剧本）‌ |
| 671B | 顶尖多任务能力，接近通用人工智能（AGI），适合科研和超大规模企业‌ | 需要多卡并行和云服务支持，适用于全球高并发场景‌ | 多模态融合和超长文本生成（如小说/剧本）‌ |

* 如下图：

> 注意：下载过程中，最开始下载速度可能要快一些，下载到后面可能就几十KB/s了，此时我们可以按Ctrl+C停止下载，然后再重新执行下载命令，此时的下载速度又恢复到了几MB/s了，如此循环往复操作，很快下载好

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/97bc106cb3a9431e806b8e4e2d053170.png)

* 执行成功，可以问答：
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/8f31d42552504d22ba398aac5f38b2b1.png)
* 使用 /bye 命令进行退出：
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/96825695159740d98b631a89da4fdd68.png)

## 5.创建Node.js服务器

* 为了使DeepSeek可以通过API接口访问，我们可以使用Express框架创建一个简单的Node.js服务器。首先，安装Express：

```typescript
npm install express

```

* 关于Express可以参考该篇文章：
    
  [当面试官问你关于Node.js的开发框架Express时，你怎么回答？](https://blog.csdn.net/weixin_42881768/article/details/105542994)
* 然后，在项目根目录下创建一个名为server.js的文件，并添加以下示例代码：

```typescript
const express = require('express');
const { exec } = require('child_process');

const app = express();
const PORT = process.env.PORT || 3000;

app.use(express.json());

app.post('/query', (req, res) => {
    const query = req.body.query;
    if (!query) {
        return res.status(400).send({ error: 'query必填'});
    }

    // 使用提供的查询执行ollama命令
    exec(`ollama run deepseek-r1:1.5b -- ${query}`, (error, stdout, stderr) => {
        if (error) {
            return res.status(500).send({ error: '请求出错' });
        }
        res.send({ response: stdout });
    });
});

app.listen(PORT, () => {
    console.log(`服务运行在${PORT}端口`);
});

```

* 这段代码设置了一个简单的HTTP服务器，监听/query端点上的POST请求，并将接收到的查询传递给Ollama执行的DeepSeek模型。响应结果将以JSON格式返回给客户端。

## 6.运行服务器

* 完成上述步骤后，可以在终端中通过以下命令启动服务器：

```typescript
node server.js

```

* 在postman或者apifox中访问http://localhost:3000/query，并通过发送POST请求来与DeepSeek模型进行交互：
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/f43e855fd6a14eb09a0156bf8697c700.png)

## 7.Web UI对话-Chrome插件-Page Assist

* 通过终端窗口进行对话不够直观，所以通过第三方Web UI来实现对话效果
* 通过谷歌浏览器官方插件地址搜索Page Assist，点击Page Assist - 本地 AI 模型的 Web UI：
    
  [谷歌应用商店](https://chromewebstore.google.com/search/Page%20Assist?hl=zh-CN&utm_source=ext_sidebar&pli=1)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/8049969f805d4cfba7a58c0f50b6b5fd.png)

* 安装完成后，将该插件固定到浏览器顶部，方便使用：
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/ac1fc950579a4336a1099b337a0b9ee0.png)
* 使用时，点击图标，会跳转到使用界面，可以看到画面中间的“Ollama is running”，因为我们的Ollama软件已启动，只有启动才可正常使用：
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/2eeb0fbc7474498893d368e73bff4e63.png)
* 设置为中文：
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3150071ccdd449aa9d0f1f730b9e1034.png)
* 选择模型，因为我们只配置了1.5B，所以只能选择1.5B：
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/077ed78b9f12441b9c03de053c2af222.png)
* 此时，即可正常使用，觉得1.5B不够，可以根据机器条件，下载其他更高版本的模型使用：
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/2c1e59d4f9db479ebe2410f3ad335b04.png)

---