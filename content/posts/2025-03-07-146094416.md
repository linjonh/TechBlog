---
layout: post
title: "使用Node.js从零搭建DeepSeek本地部署Express框架Ollama"
date: 2025-03-07 16:57:02 +0800
description: "使用Node.js从零搭建DeepSeek本地部署..."
keywords: "使用Node.js从零搭建DeepSeek本地部署（Express框架、Ollama）"
categories: ['大模型', 'Node', 'Express']
tags: ['Ollama', 'Node', 'Express', 'Deepseek']
artid: "146094416"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146094416
    alt: "使用Node.js从零搭建DeepSeek本地部署Express框架Ollama"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146094416
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146094416
cover: https://bing.ee123.net/img/rand?artid=146094416
image: https://bing.ee123.net/img/rand?artid=146094416
img: https://bing.ee123.net/img/rand?artid=146094416
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     使用Node.js从零搭建DeepSeek本地部署（Express框架、Ollama）
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="./../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="./../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
    </p>
    <p>
    </p>
    <h2>
     <a id="1Nodejsnpm_1">
     </a>
     1.安装Node.js和npm
    </h2>
    <ul>
     <li>
      首先确保我们机器上已经安装了Node.js和npm。如果未安装，可以通过以下链接下载并安装适合我们操作系统的版本：
      <br/>
      <a href="https://nodejs.org/zh-cn?spm=5176.28103460.0.0.49e3451esLqOEJ" rel="nofollow">
       Node.js官方下载页面
      </a>
     </li>
     <li>
      关于Node.js的安装可以参考该篇文章：
      <br/>
      <a href="https://blog.csdn.net/weixin_42881768/article/details/105028164?ops_request_misc=%257B%2522request%255Fid%2522%253A%25221ce436c31cab355f68387efb4a89562a%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=1ce436c31cab355f68387efb4a89562a&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-105028164-null-null.nonecase&amp;utm_term=%E5%AE%89%E8%A3%85&amp;spm=1018.2226.3001.4450">
       Node.js的安装及环境配置【超详细】
      </a>
     </li>
     <li>
      安装完成后，可以通过以下命令检查是否安装成功：
     </li>
    </ul>
    <pre><code class="prism language-typescript">node <span class="token operator">-</span>v
npm <span class="token operator">-</span>v
</code></pre>
    <ul>
     <li>
      安装成功界面：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/d052b2a6383547289b7aa43b429e97fa.png">
       <br/>
       <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/714e85d58cf843ffbe6ce939400cc86a.png"/>
      </img>
     </li>
    </ul>
    <h2>
     <a id="2_16">
     </a>
     2.初始化项目
    </h2>
    <ul>
     <li>
      使用以下命令，创建一个新的文件夹作为项目目录，并初始化一个Node.js项目：
     </li>
    </ul>
    <pre><code class="prism language-typescript">mkdir deepseek<span class="token operator">-</span>nodejs
cd deepseek<span class="token operator">-</span>nodejs
npm init <span class="token operator">-</span>y
</code></pre>
    <ul>
     <li>
      如下图：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/c0ac4370504f4adda52b7c4da0d4922e.png"/>
     </li>
     <li>
      以上命令会在当前目录下生成一个package.json文件，用于管理项目的依赖关系和其他配置信息。
     </li>
    </ul>
    <h2>
     <a id="3Ollama_28">
     </a>
     3.安装Ollama
    </h2>
    <ul>
     <li>
      访问Ollama官网下载适合我们电脑操作系统的安装包，并按照提示进行安装：
      <br/>
      <a href="https://ollama.com/download/mac" rel="nofollow">
       Ollama官方下载页面
      </a>
     </li>
     <li>
      对于Linux用户，可以通过以下命令直接安装：
     </li>
    </ul>
    <pre><code class="prism language-typescript">curl <span class="token operator">-</span>fsSL https<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>ollama<span class="token punctuation">.</span>com<span class="token operator">/</span>install<span class="token punctuation">.</span>sh <span class="token operator">|</span> sh
</code></pre>
    <ul>
     <li>
      安装完成后，验证是否成功安装：
     </li>
    </ul>
    <pre><code class="prism language-typescript">ollama <span class="token operator">-</span>v
</code></pre>
    <ul>
     <li>
      如下图：
     </li>
    </ul>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/df2dadd52287400f94b114b60b8efd54.png"/>
    </p>
    <h2>
     <a id="4DeepSeek_45">
     </a>
     4.下载DeepSeek模型
    </h2>
    <ul>
     <li>
      安装完Ollama后，我们可以通过其界面选择并下载DeepSeek-R1模型。以下是下载并运行DeepSeek-R1 1.5B版本的示例命令：
     </li>
    </ul>
    <pre><code class="prism language-typescript">ollama run deepseek<span class="token operator">-</span>r1<span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">.</span>5b
</code></pre>
    <p>
     根据我们机器的硬件配置，可以选择不同规模的模型版本，如7B、14B等
    </p>
    <ul>
     <li>
      不同模型创建命令：
      <br/>
      <a href="https://ollama.com/library/deepseek-r1:1.5b" rel="nofollow">
       创建命令
      </a>
     </li>
     <li>
      不同规模的模型版本参数核心区别：
     </li>
    </ul>
    <table>
     <thead>
      <tr>
       <th>
        参数规模
       </th>
       <th>
        特点和应用场景
       </th>
       <th>
        部署需求和资源消耗
       </th>
       <th>
        应用场景
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        1.5B
       </td>
       <td>
        适合简单的文本生成任务，如客服话术和短文案生成，但逻辑推理能力较弱‌
       </td>
       <td>
        适合本地部署，资源消耗低，可以在消费级显卡上运行‌
       </td>
       <td>
        生成食谱步骤和基础问答‌
       </td>
      </tr>
      <tr>
       <td>
        7B-8B
       </td>
       <td>
        适合多轮对话和中等复杂度的任务，如代码补全和基础科研工作‌
       </td>
       <td>
        适合本地部署，资源消耗低，可以在消费级显卡上运行‌
       </td>
       <td>
        ChatGPT级对话和中等复杂度代码生成‌
       </td>
      </tr>
      <tr>
       <td>
        14B
       </td>
       <td>
        适合多轮对话和中等复杂度的任务，如代码补全和基础科研工作‌
       </td>
       <td>
        需要在高性能GPU上运行，如A100/H100/H800等‌
       </td>
       <td>
        科研论文辅助撰写和跨领域知识推理‌
       </td>
      </tr>
      <tr>
       <td>
        32B
       </td>
       <td>
        具备接近人类水平的复杂任务处理能力，如法律文档分析和数学证明‌
       </td>
       <td>
        需要在高性能GPU上运行，如A100/H100/H800等‌
       </td>
       <td>
        科研论文辅助撰写和跨领域知识推理‌
       </td>
      </tr>
      <tr>
       <td>
        70B
       </td>
       <td>
        适用于前沿研究和超高性能计算场景‌
       </td>
       <td>
        需要多卡并行和云服务支持，适用于全球高并发场景‌
       </td>
       <td>
        多模态融合和超长文本生成（如小说/剧本）‌
       </td>
      </tr>
      <tr>
       <td>
        671B
       </td>
       <td>
        顶尖多任务能力，接近通用人工智能（AGI），适合科研和超大规模企业‌
       </td>
       <td>
        需要多卡并行和云服务支持，适用于全球高并发场景‌
       </td>
       <td>
        多模态融合和超长文本生成（如小说/剧本）‌
       </td>
      </tr>
     </tbody>
    </table>
    <ul>
     <li>
      如下图：
     </li>
    </ul>
    <blockquote>
     <p>
      注意：下载过程中，最开始下载速度可能要快一些，下载到后面可能就几十KB/s了，此时我们可以按Ctrl+C停止下载，然后再重新执行下载命令，此时的下载速度又恢复到了几MB/s了，如此循环往复操作，很快下载好
     </p>
    </blockquote>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/97bc106cb3a9431e806b8e4e2d053170.png"/>
    </p>
    <ul>
     <li>
      执行成功，可以问答：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/8f31d42552504d22ba398aac5f38b2b1.png"/>
     </li>
     <li>
      使用 /bye 命令进行退出：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/96825695159740d98b631a89da4fdd68.png"/>
     </li>
    </ul>
    <h2>
     <a id="5Nodejs_76">
     </a>
     5.创建Node.js服务器
    </h2>
    <ul>
     <li>
      为了使DeepSeek可以通过API接口访问，我们可以使用Express框架创建一个简单的Node.js服务器。首先，安装Express：
     </li>
    </ul>
    <pre><code class="prism language-typescript">npm install express
</code></pre>
    <ul>
     <li>
      关于Express可以参考该篇文章：
      <br/>
      <a href="https://blog.csdn.net/weixin_42881768/article/details/105542994">
       当面试官问你关于Node.js的开发框架Express时，你怎么回答？
      </a>
     </li>
     <li>
      然后，在项目根目录下创建一个名为server.js的文件，并添加以下示例代码：
     </li>
    </ul>
    <pre><code class="prism language-typescript"><span class="token keyword">const</span> express <span class="token operator">=</span> <span class="token keyword">require</span><span class="token punctuation">(</span><span class="token string">'express'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> <span class="token punctuation">{<!-- --></span> exec <span class="token punctuation">}</span> <span class="token operator">=</span> <span class="token keyword">require</span><span class="token punctuation">(</span><span class="token string">'child_process'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">const</span> app <span class="token operator">=</span> <span class="token function">express</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> <span class="token constant">PORT</span> <span class="token operator">=</span> process<span class="token punctuation">.</span>env<span class="token punctuation">.</span><span class="token constant">PORT</span> <span class="token operator">||</span> <span class="token number">3000</span><span class="token punctuation">;</span>

app<span class="token punctuation">.</span><span class="token function">use</span><span class="token punctuation">(</span>express<span class="token punctuation">.</span><span class="token function">json</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

app<span class="token punctuation">.</span><span class="token function">post</span><span class="token punctuation">(</span><span class="token string">'/query'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>req<span class="token punctuation">,</span> res<span class="token punctuation">)</span> <span class="token operator">=&gt;</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">const</span> query <span class="token operator">=</span> req<span class="token punctuation">.</span>body<span class="token punctuation">.</span>query<span class="token punctuation">;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>query<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">return</span> res<span class="token punctuation">.</span><span class="token function">status</span><span class="token punctuation">(</span><span class="token number">400</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span> error<span class="token operator">:</span> <span class="token string">'query必填'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">// 使用提供的查询执行ollama命令</span>
    <span class="token function">exec</span><span class="token punctuation">(</span><span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">ollama run deepseek-r1:1.5b -- </span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${<!-- --></span>query<span class="token interpolation-punctuation punctuation">}</span></span><span class="token template-punctuation string">`</span></span><span class="token punctuation">,</span> <span class="token punctuation">(</span>error<span class="token punctuation">,</span> stdout<span class="token punctuation">,</span> stderr<span class="token punctuation">)</span> <span class="token operator">=&gt;</span> <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>error<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">return</span> res<span class="token punctuation">.</span><span class="token function">status</span><span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span> error<span class="token operator">:</span> <span class="token string">'请求出错'</span> <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        res<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span> response<span class="token operator">:</span> stdout <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

app<span class="token punctuation">.</span><span class="token function">listen</span><span class="token punctuation">(</span><span class="token constant">PORT</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=&gt;</span> <span class="token punctuation">{<!-- --></span>
    <span class="token builtin">console</span><span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">服务运行在</span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${<!-- --></span><span class="token constant">PORT</span><span class="token interpolation-punctuation punctuation">}</span></span><span class="token string">端口</span><span class="token template-punctuation string">`</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
    <ul>
     <li>
      这段代码设置了一个简单的HTTP服务器，监听/query端点上的POST请求，并将接收到的查询传递给Ollama执行的DeepSeek模型。响应结果将以JSON格式返回给客户端。
     </li>
    </ul>
    <h2>
     <a id="6_117">
     </a>
     6.运行服务器
    </h2>
    <ul>
     <li>
      完成上述步骤后，可以在终端中通过以下命令启动服务器：
     </li>
    </ul>
    <pre><code class="prism language-typescript">node server<span class="token punctuation">.</span>js
</code></pre>
    <ul>
     <li>
      在postman或者apifox中访问http://localhost:3000/query，并通过发送POST请求来与DeepSeek模型进行交互：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/f43e855fd6a14eb09a0156bf8697c700.png"/>
     </li>
    </ul>
    <h2>
     <a id="7Web_UIChromePage_Assist_125">
     </a>
     7.Web UI对话-Chrome插件-Page Assist
    </h2>
    <ul>
     <li>
      通过终端窗口进行对话不够直观，所以通过第三方Web UI来实现对话效果
     </li>
     <li>
      通过谷歌浏览器官方插件地址搜索Page Assist，点击Page Assist - 本地 AI 模型的 Web UI：
      <br/>
      <a href="https://chromewebstore.google.com/search/Page%20Assist?hl=zh-CN&amp;utm_source=ext_sidebar&amp;pli=1" rel="nofollow">
       谷歌应用商店
      </a>
     </li>
    </ul>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/8049969f805d4cfba7a58c0f50b6b5fd.png"/>
    </p>
    <ul>
     <li>
      安装完成后，将该插件固定到浏览器顶部，方便使用：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/ac1fc950579a4336a1099b337a0b9ee0.png"/>
     </li>
     <li>
      使用时，点击图标，会跳转到使用界面，可以看到画面中间的“Ollama is running”，因为我们的Ollama软件已启动，只有启动才可正常使用：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/2eeb0fbc7474498893d368e73bff4e63.png"/>
     </li>
     <li>
      设置为中文：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/3150071ccdd449aa9d0f1f730b9e1034.png"/>
     </li>
     <li>
      选择模型，因为我们只配置了1.5B，所以只能选择1.5B：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/077ed78b9f12441b9c03de053c2af222.png"/>
     </li>
     <li>
      此时，即可正常使用，觉得1.5B不够，可以根据机器条件，下载其他更高版本的模型使用：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/2c1e59d4f9db479ebe2410f3ad335b04.png"/>
     </li>
    </ul>
    <hr/>
   </div>
   <link href="./../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="./../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34323838313736382f:61727469636c652f64657461696c732f313436303934343136" class_="artid" style="display:none">
 </p>
</div>


