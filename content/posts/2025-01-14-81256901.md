---
layout: post
title: "精品收藏GitHub人工智能AI开源项目"
date: 2025-01-14 07:23:45 +0800
description: "精品收藏：GitHub人工智能AI开源项目绝对精品！！！花了点时间"
keywords: "人工智能ai音效增强 git开源"
categories: ['未分类']
tags: ['人工智能', 'Github']
artid: "81256901"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=81256901
  alt: "精品收藏GitHub人工智能AI开源项目"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=81256901
featuredImagePreview: https://bing.ee123.net/img/rand?artid=81256901
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     精品收藏：GitHub人工智能AI开源项目
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2 id="%E7%B2%BE%E5%93%81%E6%94%B6%E8%97%8F%EF%BC%9AGitHub%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE">
     <a name="t0">
     </a>
     精品收藏：GitHub人工智能AI开源项目
    </h2>
    <p>
     绝对精品！！！花了点时间，鄙人把这几年收藏的开源精品项目，整理一下，方面以后查找。
     <strong>
      其中涵盖了姿态检测，图像分割，图像分类，美学评价、人脸识别、多尺度训练，移动端的AI 计算引擎，卫星图像，NLP，Python包，文字检测，NCRF，DALI 等开源项目。
     </strong>
    </p>
    <p>
     更多开源项目，持续更细中……
    </p>
    <hr/>
    <p id="main-toc">
     <strong>
      目录
     </strong>
    </p>
    <p id="%E7%B2%BE%E5%93%81%E6%94%B6%E8%97%8F%EF%BC%9AGitHub%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE-toc" style="margin-left:0px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#%E7%B2%BE%E5%93%81%E6%94%B6%E8%97%8F%EF%BC%9AGitHub%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BDAI%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE">
      <u>
       <span style="color:#0066cc;">
        精品收藏：GitHub人工智能AI开源项目
       </span>
      </u>
     </a>
    </p>
    <p id="1.%20DensePose-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#1.%20DensePose">
      <u>
       <span style="color:#0066cc;">
        DensePose-实时人体姿态估计
       </span>
      </u>
     </a>
    </p>
    <p id="AlphaPose-%E5%A7%BF%E6%80%81%E8%AF%86%E5%88%AB-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#AlphaPose-%E5%A7%BF%E6%80%81%E8%AF%86%E5%88%AB">
      <u>
       <span style="color:#0066cc;">
        AlphaPose-姿态识别
       </span>
      </u>
     </a>
    </p>
    <p id="MobilePose-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#MobilePose">
      <u>
       <span style="color:#0066cc;">
        MobilePose-支持移动设备、单人姿态估计框架
       </span>
      </u>
     </a>
    </p>
    <p id="FaceNet-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#FaceNet-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95">
      <u>
       <span style="color:#0066cc;">
        FaceNet-人脸识别算法
       </span>
      </u>
     </a>
    </p>
    <p id="Age%20and%20Gender%20Estimation-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#Age%20and%20Gender%20Estimation">
      <u>
       <span style="color:#0066cc;">
        Age and Gender Estimation-年龄和性别评估模型
       </span>
      </u>
     </a>
    </p>
    <p id="OD%20Annotation-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#OD%20Annotation">
      <u>
       <span style="color:#0066cc;">
        OD Annotation-目标检测数据集标注工具
       </span>
      </u>
     </a>
    </p>
    <p id="Semantic%20Segmentation%20PyTorch-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#Semantic%20Segmentation%20PyTorch">
      <u>
       <span style="color:#0066cc;">
        Semantic Segmentation PyTorch-语义分割工具包
       </span>
      </u>
     </a>
    </p>
    <p id="Photo%20Aesthetics%20Ranking%20Network%20-%E5%9B%BE%E5%83%8F%E7%BE%8E%E5%AD%A6%E6%8E%92%E5%90%8D%E7%BD%91%E7%BB%9C-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#Photo%20Aesthetics%20Ranking%20Network%20-%E5%9B%BE%E5%83%8F%E7%BE%8E%E5%AD%A6%E6%8E%92%E5%90%8D%E7%BD%91%E7%BB%9C">
      <u>
       <span style="color:#0066cc;">
        Photo Aesthetics Ranking Network -图像美学排名网络
       </span>
      </u>
     </a>
    </p>
    <p id="Non-local%20Neural%20Networks%20for%20Video%20Classification-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#Non-local%20Neural%20Networks%20for%20Video%20Classification">
      <u>
       <span style="color:#0066cc;">
        Non-local Neural Networks for Video Classification-视频分类开源代码和模型
       </span>
      </u>
     </a>
    </p>
    <p id="colornet-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#colornet">
      <u>
       <span style="color:#0066cc;">
        colornet-将灰度图转为彩色图
       </span>
      </u>
     </a>
    </p>
    <p id="Visual%20Search%20Server-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#Visual%20Search%20Server">
      <u>
       <span style="color:#0066cc;">
        Visual Search Server-可视化搜索服务器
       </span>
      </u>
     </a>
    </p>
    <p id="Darts-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#Darts">
      <u>
       <span style="color:#0066cc;">
        Darts-可微分的卷积循环网络结构
       </span>
      </u>
     </a>
    </p>
    <p id="%EF%BC%93.SNIPER-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#%EF%BC%93.SNIPER">
      <u>
       <span style="color:#0066cc;">
        SNIPER-高效的多尺度训练方法
       </span>
      </u>
     </a>
    </p>
    <p id="%C2%A0Mace-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#%C2%A0Mace">
      <u>
       <span style="color:#0066cc;">
        Mace-用于移动端的、异构计算平台的深度学习推理框架
       </span>
      </u>
     </a>
    </p>
    <p id="Robosat-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#Robosat">
      <u>
       <span style="color:#0066cc;">
        Robosat-端到端的特征提取方法
       </span>
      </u>
     </a>
    </p>
    <p id="DecaNLP-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#DecaNLP">
      <u>
       <span style="color:#0066cc;">
        DecaNLP-自然语言界的“十项全能”挑战
       </span>
      </u>
     </a>
    </p>
    <p id="Magnitude-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#Magnitude">
      <u>
       <span style="color:#0066cc;">
        Magnitude-快速高效的通用向量嵌入式实用程序包
       </span>
      </u>
     </a>
    </p>
    <p id="Porcupine-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#Porcupine">
      <u>
       <span style="color:#0066cc;">
        Porcupine-自助式的、高精度、轻量级文字检测引擎
       </span>
      </u>
     </a>
    </p>
    <p id="NCRF-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#NCRF">
      <u>
       <span style="color:#0066cc;">
        NCRF-神经条件随机场结构，能够将检测到的癌症转移到WSI 中
       </span>
      </u>
     </a>
    </p>
    <p id="DALI-toc" style="margin-left:40px;">
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084#DALI">
      <u>
       <span style="color:#0066cc;">
        DALI-数据加载库
       </span>
      </u>
     </a>
    </p>
    <hr id="hr-toc"/>
    <h3 id="1.%20DensePose">
     <a name="t1">
     </a>
     <strong>
      DensePose-
     </strong>
     实时人体姿态估计
    </h3>
    <p>
     DensePose 是Facebook 研究院开发的一种实时人体姿态估计方法，它能够将2D RGB 图像中的目标像素映射到3D 表面模型。DensePose 项目旨在通过这种基于3D 表面模型来理解图像中的人体姿态，并能够有效地计算2D RGB 图像和人体3D 表面模型之间的密集对应关系。与人体姿势估计需要使用10或20个人体关节(手腕，肘部等) 不同的是，DenPose 使用超过5000个节点来定义，由此产生的估计准确性和系统速度将加速AR和VR 工作的连接。
    </p>
    <p>
     <a href="https://camo.githubusercontent.com/9f6f691cbdbda95a6af9dd4e113c70d7293647ea/68747470733a2f2f64726976652e676f6f676c652e636f6d2f75633f6578706f72743d766965772669643d317166534f6b7075656f316b565a62584f75514a4a687961674b6a4d676570737a" rel="nofollow">
      <img alt="" class="has" src="https://camo.githubusercontent.com/9f6f691cbdbda95a6af9dd4e113c70d7293647ea/68747470733a2f2f64726976652e676f6f676c652e636f6d2f75633f6578706f72743d766965772669643d317166534f6b7075656f316b565a62584f75514a4a687961674b6a4d676570737a"/>
     </a>
    </p>
    <blockquote>
     <p>
      相关链接：
     </p>
     <p>
      https://research.fb.com/facebook-open-sources-densepose/
     </p>
     <p>
      Github 链接：
     </p>
     <p>
      https://github.com/facebookresearch/DensePose
     </p>
    </blockquote>
    <hr/>
    <h3 id="AlphaPose-%E5%A7%BF%E6%80%81%E8%AF%86%E5%88%AB">
     <a name="t2">
     </a>
     <strong>
      AlphaPose-
     </strong>
     姿态识别
    </h3>
    <p>
     由上海交通大学卢策吾团队发布的开源系统AlphaPose近日上线，该开源系统在标准测试集COCO上较现有最好姿态估计开源系统Mask-RCNN相对提高8.2%。Mask-RCNN是2017年以来计算机视觉领域的一个突破，获得了ICCV 2017最佳论文（马尔奖），涵盖了物体检测，分割，姿态估计。
    </p>
    <p>
     AlphaPose 是基于腾讯优图和卢策吾团队在 ICCV 2017 上的分区域多人姿态识别算法（RMPE），该算法主要为了解决在人物检测结果不准的情况下进行稳定的多人姿态识别问题
    </p>
    <p>
     <img alt="" class="has" src="https://i-blog.csdnimg.cn/blog_migrate/d7e4a1b8eb7325144c28f32881098452.gif">
      <img alt="" class="has" src="https://i-blog.csdnimg.cn/blog_migrate/e91eb3b6b195e80fed9687a99a58b32d.gif"/>
     </img>
    </p>
    <blockquote>
     <p>
      相关链接：
     </p>
     <p>
      <a href="http://mvig.sjtu.edu.cn/research/alphapose.html" rel="nofollow">
       <u>
        <span style="color:#0066cc;">
         http://mvig.sjtu.edu.cn/research/alphapose.html
        </span>
       </u>
      </a>
     </p>
     <p>
      Github 链接：
     </p>
     <p>
      <a href="https://github.com/MVIG-SJTU/AlphaPose">
       <u>
        <span style="color:#0066cc;">
         https://github.com/MVIG-SJTU/AlphaPose
        </span>
       </u>
      </a>
     </p>
    </blockquote>
    <hr/>
    <h3 id="MobilePose">
     <a name="t3">
     </a>
     <strong>
      MobilePose-支持移动设备、单人姿态
     </strong>
     估计框架
    </h3>
    <p>
     MobilePose 是一个轻量级的、基于 PyTorch 实现的
     <strong>
      支持移动设备、单人姿态
     </strong>
     估计框架。目标旨在提供一个模型训练/推理/评估接口，以及具有各种数据增强选项的数据采集器。最终训练的模型在速度、大小和精度方面均可满足移动设备的基本需求。
    </p>
    <blockquote>
     <p>
      项目链接
     </p>
     <p>
      https://github.com/YuliangXiu/MobilePose-pytorch
     </p>
    </blockquote>
    <hr/>
    <h3 id="FaceNet-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95">
     <a name="t4">
     </a>
     FaceNet-人脸识别算法
    </h3>
    <p>
     谷歌人脸检测算法，发表于 CVPR 2015，利用相同人脸在不同角度等姿态的照片下有高内聚性，不同人脸有低耦合性，提出使用 cnn + triplet mining 方法，在 LFW 数据集上准确度达到 99.63%，在 youtube 人脸数据集上准确度 95.12%，比以往准确度提升了将近 30%。
    </p>
    <blockquote>
     <p>
      论文地址：
     </p>
     <p>
      <a href="https://arxiv.org/abs/1503.03832" rel="nofollow">
       <u>
        <span style="color:#0066cc;">
         FaceNet: A Unified Embedding for Face Recognition and Clustering
        </span>
       </u>
      </a>
     </p>
     <p>
      项目链接：
     </p>
     <p>
      <a href="https://github.com/davidsandberg/facenet">
       <u>
        <span style="color:#0066cc;">
         https://github.com/davidsandberg/facenet
        </span>
       </u>
      </a>
     </p>
    </blockquote>
    <hr/>
    <h3 id="Age%20and%20Gender%20Estimation">
     <a name="t5">
     </a>
     Age and Gender Estimation-
     <strong>
      年龄和性别评估模型
     </strong>
    </h3>
    <p>
     该项目是一个基于 Keras 框架实现的 CNN 模型，
     <strong>
      用于
     </strong>
     <strong>
      根据人脸照片测算年龄和性别
     </strong>
     。
    </p>
    <p>
     <img alt="" class="has" src="https://github.com/yu4u/age-gender-estimation/wiki/images/result.png"/>
    </p>
    <blockquote>
     <p>
      Github 链接：
     </p>
     <p>
      <a href="https://github.com/yu4u/age-gender-estimation">
       <u>
        <span style="color:#0066cc;">
         https://github.com/yu4u/age-gender-estimation
        </span>
       </u>
      </a>
     </p>
    </blockquote>
    <hr/>
    <h3 id="OD%20Annotation">
     <a name="t6">
     </a>
     <strong>
      OD Annotation-目标检测数据集标注工具
     </strong>
    </h3>
    <p>
     本项目是一个
     <strong>
      目标检测数据集标注工具
     </strong>
     ，采用 Python-flask 框架开发，基于 B/S 方式交互，支持多人同时标注。
    </p>
    <p>
     <strong>
      项目特点如下：
     </strong>
    </p>
    <ul>
     <li>
      B/S 方式交互
     </li>
     <li>
      支持多人同时标注（可分配不同标注人员的标注范围，或不同人员标注不同类别）
     </li>
     <li>
      类别采用选择方式，免去手工输入类别工作
     </li>
     <li>
      支持拖拽方式修正标注区域
     </li>
     <li>
      支持键盘方向键切换标注样本
     </li>
    </ul>
    <p>
     <img alt="" class="has" src="https://github.com/hzylmf/od-annotation/raw/master/docs/ui2.png"/>
    </p>
    <blockquote>
     <p>
      Github 链接：
     </p>
     <p>
      https://github.com/hzylmf/od-annotation
     </p>
    </blockquote>
    <hr/>
    <h3 id="Semantic%20Segmentation%20PyTorch">
     <a name="t7">
     </a>
     <strong>
      Semantic Segmentation PyTorch-
     </strong>
     语义分割工具包
    </h3>
    <p>
     本项目是由 MIT CSAIL 实验室开源的 PyTorch 语义分割工具包，其中包含多种网络的实现和预训练模型。自带多卡同步 bn，能复现在 MIT ADE20K 上 SOTA 的结果。ADE20K 是由 MIT 计算机视觉团队开源的规模最大的语义分割和场景解析数据集。
    </p>
    <p>
     <a href="https://github.com/CSAILVision/semantic-segmentation-pytorch/blob/master/teaser/ADE_val_00000278.png">
      <img alt="" class="has" src="https://github.com/CSAILVision/semantic-segmentation-pytorch/raw/master/teaser/ADE_val_00000278.png"/>
     </a>
    </p>
    <p>
     <a href="https://github.com/CSAILVision/semantic-segmentation-pytorch/blob/master/teaser/ADE_val_00001519.png">
      <img alt="" class="has" src="https://github.com/CSAILVision/semantic-segmentation-pytorch/raw/master/teaser/ADE_val_00001519.png"/>
     </a>
    </p>
    <blockquote>
     <p>
      项目链接
     </p>
     <p>
      https://github.com/CSAILVision/semantic-segmentation-pytorch
     </p>
    </blockquote>
    <hr/>
    <h3 id="Photo%20Aesthetics%20Ranking%20Network%20-%E5%9B%BE%E5%83%8F%E7%BE%8E%E5%AD%A6%E6%8E%92%E5%90%8D%E7%BD%91%E7%BB%9C">
     <a name="t8">
     </a>
     Photo Aesthetics Ranking Network -图像美学排名网络
    </h3>
    <p>
     使用caffe实现的图像美学质量评价模型
    </p>
    <p>
     <a href="https://camo.githubusercontent.com/dfd7bf4eddcded59d7ff10c3ff2c99712f2a2ab4/687474703a2f2f7777772e6963732e7563692e6564752f253745736b6f6e67322f696d672f6165737468657469637344656d6f4669677572652e706e67" rel="nofollow">
      <img alt="alt text" class="has" src="https://camo.githubusercontent.com/dfd7bf4eddcded59d7ff10c3ff2c99712f2a2ab4/687474703a2f2f7777772e6963732e7563692e6564752f253745736b6f6e67322f696d672f6165737468657469637344656d6f4669677572652e706e67"/>
     </a>
    </p>
    <blockquote>
     <p>
      项目地址：
     </p>
     <p>
      <a href="https://github.com/aimerykong/deepImageAestheticsAnalysis">
       <u>
        <span style="color:#0066cc;">
         https://github.com/aimerykong/deepImageAestheticsAnalysis
        </span>
       </u>
      </a>
     </p>
    </blockquote>
    <hr/>
    <h3 id="Non-local%20Neural%20Networks%20for%20Video%20Classification">
     <a name="t9">
     </a>
     <strong>
      Non-local Neural Networks for Video Classification-视频分类开源代码和模型
     </strong>
    </h3>
    <p>
     本项目是
     <strong>
      Facebook 论文 Non-local Neural Networks 的视频分类开源代码和模型
     </strong>
     ，这个代码在视频分类效果和效率上都做到了很大的提升，
     <strong>
      ResNet-50 Non-local Net 基本能横扫只用 RGB 的视频分类模型。
     </strong>
     代码里面提供的模型可以作为许多其他任务的底层 representation，作者希望通过这个代码能把大规模视频相关的研究带进寻常百姓家。
    </p>
    <p>
     <img alt="640?" class="has" src="https://i-blog.csdnimg.cn/blog_migrate/41224d673dcd074f6448dcafb568f1b9.jpeg"/>
    </p>
    <blockquote>
     <p>
      项目链接
     </p>
     <p>
     </p>
     <p>
      https://github.com/facebookresearch/video-nonlocal-net
     </p>
    </blockquote>
    <hr/>
    <h3 id="colornet">
     <a name="t10">
     </a>
     <strong>
      <a href="https://github.com/pavelgonchar/colornet">
       <u>
        <span style="color:#0066cc;">
         colornet
        </span>
       </u>
      </a>
      -
     </strong>
     将灰度图转为彩色图
    </h3>
    <p>
     一个使用神经网络模型将灰度图转为RGB彩色图
    </p>
    <p>
     <img alt="" class="has" src="https://github.com/pavelgonchar/colornet/raw/master/summary/496000_0.png?raw=true"/>
    </p>
    <blockquote>
     <p>
      项目链接
     </p>
     <p>
      <a href="https://github.com/pavelgonchar/colornet">
       <u>
        <span style="color:#0066cc;">
         https://github.com/pavelgonchar/colornet
        </span>
       </u>
      </a>
     </p>
    </blockquote>
    <hr/>
    <h3 id="Visual%20Search%20Server">
     <a name="t11">
     </a>
     Visual Search Server-可视化搜索服务器
    </h3>
    <p>
     一个简单使用TensorFlow，InceptionV3模型和AWS GPU实例实现的视觉搜索服务器。代码实现两个方法，一个处理图像搜索的服务器和一个提取pool3功能的简单索引器。 最近邻搜索可以使用近似（更快）或使用精确方法（更慢）以近似方式执行。
    </p>
    <p>
    </p>
    <blockquote>
     <p>
      项目地址：
     </p>
     <p>
      https://github.com/AKSHAYUBHAT/VisualSearchServer
     </p>
    </blockquote>
    <hr/>
    <h3 id="Darts">
     <a name="t12">
     </a>
     <strong>
      Darts-
     </strong>
     可微分的卷积循环网络结构
    </h3>
    <p>
     Darts 是 CMU 联合DeepMind 团队研发的一种可微分的卷积循环网络结构，它能够基于结构表征的连续性，通过梯度下降法来更有效地进行结构搜索。在CIFAR-10，ImageNet，Penn Treebank 和WikiText-2 等大型数据库的实验验证了这种结构在卷积图像分类和循环语言建模方面的高效性能。
    </p>
    <p>
     <img alt="" class="has" src="https://github.com/quark0/darts/raw/master/img/darts.png"/>
    </p>
    <p>
     <a href="https://github.com/quark0/darts/blob/master/img/progress_convolutional.gif">
      <img alt="progress_convolutional" class="has" src="https://github.com/quark0/darts/raw/master/img/progress_convolutional.gif"/>
     </a>
     <a href="https://github.com/quark0/darts/blob/master/img/progress_recurrent.gif">
      <img alt="progress_recurrent" class="has" src="https://github.com/quark0/darts/raw/master/img/progress_recurrent.gif"/>
     </a>
    </p>
    <blockquote>
     <p>
      论文链接：
     </p>
     <p>
      https://arxiv.org/pdf/1806.09055.pdf
     </p>
     <p>
      Github 链接：
     </p>
     <p>
      https://github.com/quark0/darts
     </p>
    </blockquote>
    <hr/>
    <h3 id="%EF%BC%93.SNIPER">
     <a name="t13">
     </a>
     <strong>
      SNIPER-
     </strong>
     高效的多尺度训练方法
    </h3>
    <p>
     SNIPER 是一种高效的多尺度训练方法，可用于诸如目标检测，实例分割等图像识别任务。与图像金字塔处理图像中每个像素不同，SNIPER 是选择性地处理真实目标周围区域的像素。得益于其能在低分辨率的芯片上运行，这能够显着加速了多尺度训练进程。此外，高效的内存设计使得 SNIPER 在训练期间能够最大程度地受益于批量正则化方法 (BN)，还能在单个 GPU 上实现更大批量的图像识别任务。因此，SNIPER 不需要跨 GPU 同步批量地处理统计数据，你可以像处理图像分类一样地训练你的目标检测器，简单而高效！
    </p>
    <p>
     <a href="https://camo.githubusercontent.com/715b9d813a5b2f7da34d75b17f8ee3c1722f0d71/687474703a2f2f6c6567616379646972732e756d696163732e756d642e6564752f7e6e616a6962692f6769746875625f726561646d655f66696c65732f736e697065722e676966" rel="nofollow">
      <img alt="" class="has" src="https://camo.githubusercontent.com/715b9d813a5b2f7da34d75b17f8ee3c1722f0d71/687474703a2f2f6c6567616379646972732e756d696163732e756d642e6564752f7e6e616a6962692f6769746875625f726561646d655f66696c65732f736e697065722e676966"/>
     </a>
    </p>
    <blockquote>
     <p>
      论文链接：
     </p>
     <p>
      https://arxiv.org/pdf/1805.09300.pdf
     </p>
     <p>
      Github 链接：
     </p>
     <p>
      https://github.com/mahyarnajibi/SNIPER
     </p>
    </blockquote>
    <hr/>
    <h3 id="%C2%A0Mace">
     <a name="t14">
     </a>
     Mace-用于移动端的、异构计算平台的深度学习推理框架
    </h3>
    <p>
     Mace 是一个用于移动端的、异构计算平台的深度学习推理框架。在运行期间，它通过结合NEON，OpenCL 和Hexagon 进行优化，并引入Winograd 算法来加速卷积计算，因此初始化过程也将更快地优化。此外，它能很好地支持图级内存分配优化和缓冲器重用过程，试图保持最小的外部依赖性以减少内存占用空间。它还能良好地覆盖高通(Qualcomm)，联发科技(Media Tek)，Pinecone 和其他基于ARM 的芯片，以CPU 运行时还能与大多数的POSIX 系统和性能有限的体系结构兼容。
    </p>
    <p>
     <img alt="" class="has" src="https://github.com/XiaoMi/mace/raw/master/docs/mace-logo.png"/>
    </p>
    <blockquote>
     <p>
      Github 链接：
     </p>
     <p>
      https://github.com/XiaoMi/mace
     </p>
    </blockquote>
    <hr/>
    <h3 id="Robosat">
     <a name="t15">
     </a>
     <strong>
      Robosat-
     </strong>
     端到端的特征提取方法
    </h3>
    <p>
     Robosat 是一种端到端的特征提取方法，能够用于航空和卫星图像的目标特征提取，包括图像中的建筑物，停车场，道路，汽车等目标。该方法主要包括三部分内容：
    </p>
    <p>
     <img alt="" class="has" src="https://github.com/mapbox/robosat/raw/master/assets/buildings.png"/>
    </p>
    <ul>
     <li>
      数据准备：为训练特征提取模型创建一个数据集。
     </li>
     <li>
      训练和建模：为图像特征提取训练一个分割模型。
     </li>
     <li>
      后处理：将图像分割结果转为干净而简单的几何形状。
     </li>
    </ul>
    <blockquote>
     <p>
      Github 链接：
     </p>
     <p>
      https://github.com/mapbox/robosat
     </p>
    </blockquote>
    <hr/>
    <h3 id="DecaNLP">
     <a name="t16">
     </a>
     <a href="https://blog.csdn.net/guyuealian/article/details/81223084">
      <u>
       <span style="color:#0066cc;">
        https://blog.csdn.net/guyuealian/article/details/81223084
       </span>
      </u>
     </a>
    </h3>
    <h3>
    </h3>
    <h3>
     <strong>
      DecaNLP-
     </strong>
     自然语言界的“十项全能”挑战
    </h3>
    <p>
     DecaNLP 是由Saleforce 提出的一个自然语言界的“十项全能”挑战，其涵盖了十项自然语言任务：问答，机器翻译，摘要，自然语言推理，情感分析，语义角色标记，零目标关系提取，目标导向对话，语义分析和常识代词解析等任务。每种任务都被视为是一种问答问题，可以通过我们提出的多任务问答模型框架(Multitask Question Answering Network) 来解决。该模型能够联合学习DecaNLP 挑战中的所有任务，而不需要在多任务设置下设定某个特定任务的模块或超参数。
    </p>
    <p>
     <img alt="" class="has" src="https://github.com/salesforce/decaNLP/raw/master/decaNLP_logo.png"/>
    </p>
    <blockquote>
     <p>
      论文链接：
     </p>
     <p>
      https://arxiv.org/abs/1806.08730
     </p>
     <p>
      Github 链接：
     </p>
     <p>
      https://github.com/salesforce/decaNLP
     </p>
    </blockquote>
    <hr/>
    <h3 id="Magnitude">
     <a name="t17">
     </a>
     <strong>
      Magnitude-
     </strong>
     快速高效的通用向量嵌入式实用程序包
    </h3>
    <p>
     Magnitude 是一种快速高效的通用向量嵌入式实用程序包，含有功能丰富的Python 包和矢量存储文件格式，可用于在Plasticity 中以快速、高效而简单的方式将矢量嵌入用于机器学习模型。它主要是为Gensim 提供一种更简单快速的替代方案，但也可以作为一种通用的矢量存储方法应用于NLP 以外的领域。
    </p>
    <blockquote>
     <p>
      Github 链接：
     </p>
     <p>
      https://github.com/plasticityai/magnitude
     </p>
    </blockquote>
    <hr/>
    <h3 id="Porcupine">
     <a name="t18">
     </a>
     <strong>
      Porcupine-
     </strong>
     自助式的、高精度、轻量级文字检测引擎
    </h3>
    <p>
     Porcupine 是一种自助式的、高精度、轻量级文字检测引擎，它能够使开发人员构建语音应用程序平台。它具有以下几大优势：
    </p>
    <ul>
     <li>
      自助式服务：你可以在几秒内选择任何的唤醒词(wake word) 并构建模型。
     </li>
     <li>
      能够使用真实情况下训练的深度神经网络(即噪声和混响）。
     </li>
     <li>
      结构紧凑且计算效率高，能够适用于物联网应用。
     </li>
     <li>
      跨平台应用：以纯定点ANSIC 实现，目前可支持Raspberry Pi，Android，iOS，watchOS，Linux，Mac 和Windows 等平台。
     </li>
     <li>
      可扩展性强：它可以同时检测数十个唤醒词(wake word)，而几乎不需要额外的CPU /内存占用。
     </li>
    </ul>
    <p>
     <img alt="" class="has" src="https://github.com/Picovoice/Porcupine/raw/master/resources/images/demo.gif"/>
    </p>
    <blockquote>
     <p>
      Github 链接：
     </p>
     <p>
      https://github.com/Picovoice/Porcupine
     </p>
    </blockquote>
    <hr/>
    <h3 id="NCRF">
     <a name="t19">
     </a>
     <strong>
      NCRF-
     </strong>
     神经条件随机场结构，能够将检测到的癌症转移到WSI 中
    </h3>
    <p>
     NCRF是百度研究的一种神经条件随机场结构，能够将检测到的癌症转移到WSI 中。这种框架通过完全连接的条件随机场(CRF)，将相邻补丁之间的空间相关性直接并入CNN 结构的顶层特征提取器，并采用标准的端到端训练方式，以反向传播法进行优化。实验结果表明这种框架能够获得更佳质量的预测概率图，并取得不错的平均FROC 分数。
    </p>
    <p>
     <img alt="" class="has" src="https://github.com/baidu-research/NCRF/raw/master/doc/NCRF.png"/>
    </p>
    <blockquote>
     <p>
      论文链接：
     </p>
     <p>
      https://openreview.net/pdf?id=S1aY66iiM
     </p>
     <p>
      Github 链接：
     </p>
     <p>
      https://github.com/baidu-research/NCRF
     </p>
    </blockquote>
    <hr/>
    <h3 id="DALI">
     <a name="t20">
     </a>
     <strong>
      DALI-
     </strong>
     数据加载库
    </h3>
    <p>
     DALI 是NVIDA 提出的一个数据加载库，它是一个高度优化的构建模块和执行引擎集合，可用于加速深度学习应用程序中输入数据的预处理过程。此外，DALI 还提供了不同数据的加速提供了足够的性能和灵活性，并可以轻松集成到不同的深度学习训练和推理程序中。它具有以下几大优势：
    </p>
    <ul>
     <li>
      能够直接从磁盘加速读取全数据，并为训练和推理过程做准备。
     </li>
     <li>
      通过可配置的图形和自定义操作实现足够的灵活性。
     </li>
     <li>
      支持图像分类和分段工作负载。
     </li>
     <li>
      直接通过框架插件和开源绑定轻松实现集成。
     </li>
     <li>
      具有多种输入格式的便携式训练工作流程，包括JPEG，LMDB，RecordIO，TFRecord 等格式。
     </li>
    </ul>
    <blockquote>
     <p>
      Github 链接：
     </p>
     <p>
      https://github.com/NVIDIA/dali
     </p>
    </blockquote>
    <p>
     如果你觉得该帖子帮到你，还望贵人多多支持，鄙人会再接再厉，继续努力的~
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f67:2e6373646e2e6e65742f77656978696e5f3432313337373030:2f61727469636c652f64657461696c732f3831323536393031" class_="artid" style="display:none">
 </p>
</div>
