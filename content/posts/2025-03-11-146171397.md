---
layout: post
title: "图像识别技术与应用课后总结16"
date: 2025-03-11 10:26:24 +0800
description: "目标检测识别图片中有哪些物体并且找到物体的存在位置属于多任务操作，既要判断出图片中物体的类别，比如人、自行车等，还要通过边界框找到物体在图像中的具体位置。实际应用中会遇到多种问题，像目标种类与数量繁多，这要求算法能准确区分和检测大量不同物体；目标尺度不均，即物体在图像中的大小不一，可能有远距离的小物体，也有近距离的大物体；还有外部环境干扰，例如物体被遮挡或者图像存在噪声，这些都会影响检测的准确性 。目标检测的数据集VOC数据集：来自PASCAL VOC挑战赛，是计算机视觉领域的重要数据集。它分为4大类、20"
keywords: "图像识别技术与应用课后总结（16）"
categories: ['未分类']
tags: ['人工智能']
artid: "146171397"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146171397
    alt: "图像识别技术与应用课后总结16"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146171397
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146171397
cover: https://bing.ee123.net/img/rand?artid=146171397
image: https://bing.ee123.net/img/rand?artid=146171397
img: https://bing.ee123.net/img/rand?artid=146171397
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     图像识别技术与应用课后总结（16）
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     <strong>
      目标检测
     </strong>
    </p>
    <p>
     识别图片中有哪些物体并且找到物体的存在位置
    </p>
    <p style="text-align:center">
     <img src="https://i-blog.csdnimg.cn/direct/7ae1a077aca44491951290ff6758341f.jpg"/>
    </p>
    <p>
     属于多任务操作，既要判断出图片中物体的类别，比如人、自行车等，还要通过边界框找到物体在图像中的具体位置。
    </p>
    <p>
     实际应用中会遇到多种问题，像目标种类与数量繁多，这要求算法能准确区分和检测大量不同物体；目标尺度不均，即物体在图像中的大小不一，可能有远距离的小物体，也有近距离的大物体；还有外部环境干扰，例如物体被遮挡或者图像存在噪声，这些都会影响检测的准确性 。
    </p>
    <p>
     <strong>
      目标检测的数据集
     </strong>
    </p>
    <p>
     <strong>
      VOC数据集
     </strong>
     ：来自PASCAL VOC挑战赛，是计算机视觉领域的重要数据集。它分为4大类、20小类，像车辆类包含汽车、公交车等；家用类有椅子、沙发等。VOC 2007版本包含9963张图片和24640个目标，2012版本有23080张图片和54900个目标 ，主要用于研究在有限类别和数量下的目标检测问题。
    </p>
    <p style="text-align:center">
     <img src="https://i-blog.csdnimg.cn/direct/7398b3a902f844a9ad4ba0f7d1a178ee.jpg"/>
    </p>
    <p>
     <strong>
      COCO数据集
     </strong>
     ：由微软在2014年出资标注。它包含20万个图像，80个类别，超过50万个目标标注，平均每个图像的目标数是7.2 。相比VOC数据集，其图像和类别更多，场景更复杂，能更好地模拟现实世界中的目标检测情况。
    </p>
    <p style="text-align:center">
     <img src="https://i-blog.csdnimg.cn/direct/8d646260c46848898eb743daa17b9002.jpg"/>
    </p>
    <p>
     <strong>
      目标检测的Ground Truth
     </strong>
    </p>
    <p>
     <strong>
      Ground Truth概念
     </strong>
     ：指在目标检测中，准确标注出图像中目标物体的类别以及其真实边界框坐标，是评估目标检测算法准确性的参考标准。
    </p>
    <p>
     <strong>
      YOLO(TXT)格式
     </strong>
     ：用(x, y, w, h)表示，分别代表目标物体边界框的中心点坐标以及宽和高，且这些值均为归一化结果，取值范围在0到1之间。
    </p>
    <p style="text-align:center">
     <img src="https://i-blog.csdnimg.cn/direct/181f0241cb834b3bb84416cdf086e631.jpg"/>
    </p>
    <p>
     <strong>
      VOC(XML)格式：
     </strong>
     通过(Xmin, Ymin, Xmax, Ymax) 来确定边界框，分别代表左上角和右下角的坐标，记录了目标物体在图像中的位置范围。
    </p>
    <p style="text-align:center">
     <img src="https://i-blog.csdnimg.cn/direct/20fec719753946859d232a7a1be01e9c.jpg"/>
    </p>
    <p>
     <strong>
      COCO(JSON)格式
     </strong>
     ：(Xmin, Ymin, W, H) ，也是归一化后的数值，代表目标物体边界框的左上角坐标以及宽和高 。
    </p>
    <p style="text-align:center">
     <img src="https://i-blog.csdnimg.cn/direct/b88cb550e0c84fc19140367dce080872.jpg"/>
    </p>
    <p>
     <strong>
      目标检测的评估指标
     </strong>
    </p>
    <p>
     <strong>
      IoU（交并比）
     </strong>
     ：是预测边界框与真实边界框的交集面积除以并集面积的比值。IoU值越接近1，表示预测框与真实框越重合，预测结果越好。在实际应用中，会生成大量预测结果，先过滤掉低类别置信度的检测结果，再用IoU衡量边界框的正确性。
    </p>
    <p>
     <strong>
      检测结果的类别
     </strong>
     ：根据真实标注（Ground Truth）和预测结果，分为4种评价指标。
    </p>
    <p>
     TP（真正例）：真实为正样本，且被正确预测为正样本（IoU大于阈值）。
    </p>
    <p>
     FP（假正例）：真实为负样本，但被错误预测为正样本（IoU小于阈值）。
    </p>
    <p>
     TN（真负例）：真实为负样本，且被正确预测为负样本。
    </p>
    <p>
     FN（假负例）：真实为正样本，但被错误预测为负样本，即漏检目标。
    </p>
    <p>
     <strong>
      Precision（准确率、查准率）和Recall（召回率、查全率）
     </strong>
    </p>
    <p style="text-align:center">
     <img src="https://i-blog.csdnimg.cn/direct/c1282a9a95e7475a97581a012008cc1f.jpg"/>
    </p>
    <p>
     <strong>
      P-R曲线
     </strong>
     ：以召回率为横坐标，准确率为纵坐标绘制的曲线，可直观展示模型性能。
    </p>
    <p>
     <strong>
      mean AP（平均精度均值）
     </strong>
     ：每个类别AP（Average Precision，平均精度）的均值，用于综合评估模型在多个类别上的性能。AP计算方法涉及11点法等近似面积法。
    </p>
    <p>
     <strong>
      mean与average：
     </strong>
     mean即算术平均数，是常见的平均值计算方式。average含义更广，包含众数、中位数等其他度量指标。在目标检测中，Average P（平均精度）需要设计度量规则使其均衡；mean AP（平均精度均值）是在AP已经均衡的基础上直接计算算术平均。
    </p>
    <p style="text-align:center">
     <img src="https://i-blog.csdnimg.cn/direct/1e5322ca9c24499095c80cf3ae4212f4.jpg"/>
    </p>
    <p>
     <strong>
      案例：
     </strong>
     图片中目标检测的候选框情况，绿色框和红色框分别代表不同状态，旁边标有置信度。下方表格针对部分候选框，列出了图片编号、候选框编号、置信度以及判断结果（TP或FP），用于结合实际例子说明评估指标在目标检测中的应用 。
    </p>
    <p>
     <strong>
      AP计算方法
     </strong>
     ：11点法：在精确率-召回率曲线上，选取召回率R为[0, 0.1, 0.2, …, 0.9, 1]这11个点，找到对应的精确率P
    </p>
    <p>
     <strong>
      目标检测的传统方法——滑动窗口法：
     </strong>
    </p>
    <p>
     通过在图像上以不同大小和位置滑动窗口来检测目标。但该方法需要人工设计窗口尺寸，在检测过程中会产生大量冗余操作，而且对目标的定位准确性欠佳。
    </p>
    <p>
     <strong>
      目标检测的深度学习方法
     </strong>
    </p>
    <p>
     <strong>
      anchor box（锚框）
     </strong>
     ：
    </p>
    <p style="text-align:center">
     <img src="https://i-blog.csdnimg.cn/direct/cee14641ed9d4cccb39bb7f439cc4049.jpg"/>
    </p>
    <p>
     使用比例（ratio）和尺度（scale）来描述。在特征图（feature map）上，每个点对应一系列不同比例和尺度的锚框。锚框的位置由特征图上的点决定，尺度表示目标的大小
    </p>
    <p style="text-align:center">
     公式
     <img src="https://i-blog.csdnimg.cn/direct/4cb2d302a1cc4e3e97f914b85b0d4f07.jpg"/>
    </p>
    <p>
     <strong>
      anchor - base和anchor - free
     </strong>
     ：anchor - base方法是自顶向下的，类似于传统的滑动窗口法，会预先设置大量锚框，然后根据置信度等进行筛选；而anchor - free方法是自底向上的，无需预先设置锚框，能够自动生成检测目标的方式，避免了锚框预设过程。
    </p>
    <p>
     <strong>
      two stage算法流程
     </strong>
     ：
    </p>
    <p style="text-align:center">
     <img src="https://i-blog.csdnimg.cn/direct/67c62b3fc93e41559dfa28b3cd1cf3a8.jpg"/>
    </p>
    <p>
     输入图像先经过卷积神经网络（CNN）提取特征，然后生成候选区域（proposal）。接着通过感兴趣区域池化（ROI pooling）对候选区域特征进行处理，再经过全连接层（fc），最后分别进行类别预测和位置回归，并用非极大值抑制（NMS）处理结果。
    </p>
    <p>
     <strong>
      one stage算法流程
     </strong>
     ：
    </p>
    <p style="text-align:center">
     <img src="https://i-blog.csdnimg.cn/direct/6ca86837da084bce931df0a1d98f87ea.jpg"/>
    </p>
    <p>
     输入图像经CNN提取特征后，直接同时进行类别预测和位置回归，最后通过NMS处理得到最终检测结果。相比于two stage算法，one stage算法流程更为简洁。
    </p>
    <p>
     <strong>
      常见算法
     </strong>
    </p>
    <p>
     two stage算法：经典发展线有R - CNN、SPP - Net、Fast R - CNN、Faster R - CNN等；其他还包括Cascade R - CNN、Guided Anchoring等。
    </p>
    <p>
     one stage算法：主要有YOLO系列（v1 - v5）、SSD系列（SSD、DSSD、FSSD ）以及RefineDet等。
    </p>
    <p>
     <strong>
      非极大值抑制（NMS）：
     </strong>
     是目标检测中的常用技术。先设定目标框的置信度阈值（常用0.5左右），将候选框按置信度降序排列，把置信度最高的框A加入输出列表并从候选框列表删除。然后计算候选框列表中其余框与A的交并比（IoU），删除IoU大于阈值的候选框，以此消除重复的目标框 。
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f323430325f38323534303339322f:61727469636c652f64657461696c732f313436313731333937" class_="artid" style="display:none">
 </p>
</div>


