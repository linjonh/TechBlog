---
arturl_encode: "68747470:733a2f2f626c6f672e6373646e2e6e65742f6679686a75312f:61727469636c652f64657461696c732f313436303139303137"
layout: post
title: "DeepSeek本地接口调用Ollama"
date: 2025-03-04 16:45:46 +08:00
description: "上篇博文，我们通过Ollama搭建了本地的DeepSeek模型，本文主要是方便开发人员，如何通过代码或工具，通过API接口调用本地deepSeek模型。"
keywords: "ollama deepseek post 接口地址"
categories: ['部署']
tags: ['本地调用', 'Deepseek', 'Api']
artid: "146019017"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146019017
    alt: "DeepSeek本地接口调用Ollama"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146019017
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146019017
cover: https://bing.ee123.net/img/rand?artid=146019017
image: https://bing.ee123.net/img/rand?artid=146019017
img: https://bing.ee123.net/img/rand?artid=146019017
---

# DeepSeek本地接口调用（Ollama）

## 

## 前言

上篇博文，我们通过Ollama搭建了本地的DeepSeek模型，本文主要是方便开发人员，如何通过代码或工具，通过API接口调用本地deepSeek模型

前文：
[DeepSeek-R1本地搭建_deepseek 本地部署-CSDN博客](https://blog.csdn.net/fyhju1/article/details/145594936 "DeepSeek-R1本地搭建_deepseek 本地部署-CSDN博客")

**注：本文不仅仅适用DeepSeek, 通过Ollama安装的模型，都适用**

## 一：Ollama接口

上文中，我们采用ollama来搭建deepSeek r1模型，所有调用本地deepSeek模型，可以使用ollama开放的API来操作。

ollama默认开放端口：11434

ollama接口文档地址：
[https://github.com/ollama/ollama/blob/main/docs/api.md](https://github.com/ollama/ollama/blob/main/docs/api.md "https://github.com/ollama/ollama/blob/main/docs/api.md")

里面包含各种接口，包括如下：（访问文档，点击自行选择）

注意：文档是英文，看不懂用浏览器翻一下

![](https://i-blog.csdnimg.cn/direct/a8b2a3c8df704ee682cdc753cb9380b5.png)
​

## 二：调用案例（创建聊天）

API文档地址：（参考）
[https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-chat-completion

![](https://csdnimg.cn/release/blog_editor_html/release2.3.8/ckeditor/plugins/CsdnLink/icons/icon-default.png?t=P1C7)
https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-chat-completion](https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-chat-completion "https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-chat-completion")

接口地址：http://localhost:11434/api/chat

请求方式：POST

请求类型：JSON

请求内容：

```
{
  "model": "deepseek-r1:1.5b",
  "messages": [
    {
      "role": "user",
      "content": "你好?"
    }
  ]
}
```

注：这里model代码你的模型，content是你要聊天的内容，role指代角色，还要其他参数，请参考官方文档。

POSTMAN访问如下：
  
![](https://i-blog.csdnimg.cn/direct/6354c7fd26fa4fcd99b2ee40c6c47759.png)
​

## 三：调用案例（生成请求）

API文档地址:（参考）
[https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion

![](https://csdnimg.cn/release/blog_editor_html/release2.3.8/ckeditor/plugins/CsdnLink/icons/icon-default.png?t=P1C7)
https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion](https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion "https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion")

接口地址：http://localhost:11434/api/generate

请求方式：POST

请求类型：JSON

请求内容：

```
{
  "model": "deepseek-r1:1.5b",
  "prompt": "你好",
  "stream": false
}
```

注：如果
`stream`
设置为
`false`
，响应将是单个 JSON 对象

返回结果：

```
{
    "model": "deepseek-r1:1.5b",
    "created_at": "2025-03-04T08:40:06.4879238Z",
    "response": "<think>\n\n</think>\n\n你好！很高兴见到你，有什么我可以帮忙的吗？",
    "done": true,
    "done_reason": "stop",
    "total_duration": 951604700,
    "load_duration": 23765300,
    "prompt_eval_count": 4,
    "prompt_eval_duration": 57000000,
    "eval_count": 17,
    "eval_duration": 870000000
}
```

POSTMAN:

![](https://i-blog.csdnimg.cn/direct/1d86410aa763404195d69625c40f7c7b.png)
​

## 

## 四：其他API

请参考官方文档：

[https://github.com/ollama/ollama/blob/main/docs/api.md](https://github.com/ollama/ollama/blob/main/docs/api.md "https://github.com/ollama/ollama/blob/main/docs/api.md")

![](https://i-blog.csdnimg.cn/direct/cd0705716dc8406fb99c1be220ff0501.png)
​