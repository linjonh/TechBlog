---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f33333936363531392f:61727469636c652f64657461696c732f313436313737303230"
layout: post
title: "ollama-docker离线安装本地大模型"
date: 2025-03-11 14:01:07 +08:00
description: "3、下载完成，上传至docker部署的ollama目录，我这边放在了/home下，home目录下新建一个名为Modelfile的文件，参考ollama中的params和template文件。官网中，一一对应，注意，这边要下载gguf文件。2、我这边以qwq-32B为例，在。4、进入终端，创建大模型。5、查看是否安装成功。"
keywords: "ollama docker离线安装本地大模型"
categories: ['大模型', 'Ai']
tags: ['运维', '语言模型', '容器', 'Docker', 'Ai']
artid: "146177020"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146177020
    alt: "ollama-docker离线安装本地大模型"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146177020
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146177020
cover: https://bing.ee123.net/img/rand?artid=146177020
image: https://bing.ee123.net/img/rand?artid=146177020
img: https://bing.ee123.net/img/rand?artid=146177020
---

# ollama docker离线安装本地大模型

1、下载想要的模型：
[魔塔社区](https://modelscope.cn/models)
  
2、我这边以qwq-32B为例，在
[ollama](https://ollama.com/library/qwq:32b)
官网中，一一对应，注意，这边要下载gguf文件
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/14fae645dbf64a548018346857385007.png)
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4eb7dbedc2e649f79c8928bbfb6424ca.png)
  
3、下载完成，上传至docker部署的ollama目录，我这边放在了/home下，home目录下新建一个名为Modelfile的文件，参考ollama中的params和template文件
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/208dab1025434bb181df206d570dee3c.png)

```
FROM ./Qwq-33B-F16.gguf.gguf
# 直接复制 ollama 上的 Template 到如下三个双引号中间
TEMPLATE """
{{- if or .System .Tools }}<|im_start|>system
{{- if .System }}
{{ .System }}
{{- end }}
{{- if .Tools }}

# Tools

You may call one or more functions to assist with the user query.

You are provided with function signatures within <tools></tools> XML tags:
<tools>
{{- range .Tools }}
{"type": "function", "function": {{ .Function }}}
{{- end }}
</tools>

For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
<tool_call>
{"name": <function-name>, "arguments": <args-json-object>}
</tool_call>
{{- end }}<|im_end|>
{{ end }}
{{- range $i, $_ := .Messages }}
{{- $last := eq (len (slice $.Messages $i)) 1 -}}
{{- if eq .Role "user" }}<|im_start|>user
{{ .Content }}<|im_end|>
{{ else if eq .Role "assistant" }}<|im_start|>assistant
{{ if .Content }}{{ .Content }}
{{- else if .ToolCalls }}<tool_call>
{{ range .ToolCalls }}{"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments }}}
{{ end }}</tool_call>
{{- end }}{{ if not $last }}<|im_end|>
{{ end }}
{{- else if eq .Role "tool" }}<|im_start|>user
<tool_response>
{{ .Content }}
</tool_response><|im_end|>
{{ end }}
{{- if and (ne .Role "assistant") $last }}<|im_start|>assistant
{{ end }}
{{- end }}
"""

# 这一步参考 ollama 上的 parameters, 但是 ollama 上的Qwq-33B-F16 是没有参数的, 按照下面的格式添加即可
PARAMETER stop "<|im_start|>"
PARAMETER stop "<|im_end|>"


```

4、进入终端，创建大模型

```
ollama create 《your model name》 -f Modelfile

```

5、查看是否安装成功

```
ollama list 
ollama run 《your model name》

```

6、移除大模型

```
ollama rm 《your model name》

```

7、至此安装完成