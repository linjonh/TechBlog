---
layout: post
title: 2019-09-05-人工智能教程---目录
date: 2019-09-05 11:23:48 +08:00
categories: ['人工智能']
tags: ['神经网络', '深度学习', 'Ai', '人工智能', '机器学习']
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=77711593
  alt: 人工智能教程---目录
artid: 77711593
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=77711593
featuredImagePreview: https://bing.ee123.net/img/rand?artid=77711593
---

# 人工智能教程 - 目录

## 目录

### 请先看前言

### [前言](http://blog.csdn.net/jiangjunshow/article/details/77338485)

### 1 人工智能基础

#### [1.1 科普](https://www.captainbed.cn/whatisnn/)

##### [1.1.1 什么是神经网络](https://www.captainbed.cn/whatisnn/)

#### [1.2 基础知识](https://www.captainbed.cn/howtoinputdata/)

##### [1.2.1 如何将数据输入到神经网络中](https://www.captainbed.cn/howtoinputdata/)

##### [1.2.2 神经网络是如何进行预测的](https://www.captainbed.cn/howtopredict/)

##### 1.2.3 预测得准确吗

##### 1.2.4 网络是如何进行学习的

##### 1.2.5 计算图

##### 1.2.6 如何计算逻辑回归的偏导数

##### 1.2.7 向量化

##### 1.2.8 如何开始使用python

##### 1.2.9 如何向量化人工智能算法

##### 1.2.10 一些基础概念

##### 1.2.11 特征工程

##### 1.2.12 哪些特征是有价值的

##### 1.2.13 数据清理

##### 1.2.14 逻辑回归与分类阈值

##### 1.2.15 静态训练与动态训练

##### 【实战编程】教你编写第一个人工智能程序

#### 1.3 神经网络

##### 1.3.1 浅层神经网络

##### 1.3.2 如何计算浅层神经网络的前向传播

##### 1.3.3 如何计算浅层神经网络的反向传播

##### 1.3.4 为什么需要激活函数

##### 1.3.5 常见的激活函数

##### 1.3.6 激活函数的偏导数

##### 1.3.7 随机初始化参数

##### 1.3.8 非线性与激活函数

##### 【实战编程】教你编写浅层神经网络

##### 1.3.9 为什么需要深度神经网络

##### 1.3.10 如何计算深度神经网络

##### 1.3.11 核对矩阵的维度

##### 1.3.12 参数和超参数

##### 1.3.13 监督学习型神经网络

##### 1.3.14 什么使深度学习火起来了

##### 【实战编程】构建深度神经网络

#### 1.4 额外知识

##### 1.4.1 标量、向量、矩阵和张量

##### 1.4.2 深入了解矩阵

##### 1.4.3 范数

##### 1.4.4 什么是微积分

##### 1.4.5 古典微积分

##### 1.4.6 极限微积分

##### 1.4.7 偏导数

##### 1.4.8 方向导数

##### 1.4.9 什么是概率论

##### 1.4.10 条件概率

##### 1.4.11 什么是信息论

##### 1.4.12 条件熵

##### 1.4.13 互信息

##### 1.4.14 相对熵（KL散度）

##### 1.4.15 交叉熵

### 2 实战优化

#### 2.1 实战基础

##### 2.1.1 如何配置数据集

##### 2.1.2 欠拟合和过拟合

##### 2.1.3 如何解决欠拟合与过拟合

##### 2.1.4 L2正则化

##### 2.1.5 dropout

##### 2.1.6 数据增强

##### 2.1.7 将输入特征进行归一化处理

##### 2.1.8 梯度消失和梯度爆炸

##### 2.1.9 如何判断网络是否有bug

##### 2.1.10 H5文件

##### 【实战编程】参数初始化

##### 【实战编程】正则化

##### 【实战编程】梯度检验

#### 2.2 优化算法

##### 2.2.1 Mini-batch

##### 2.2.2 如何为mini-batch选择合理的大小

##### 2.2.3 指数加权平均

##### 2.2.4 深入理解指数加权平均

##### 2.2.5 指数加权平均的偏差修正

##### 2.2.6 动量梯度下降

##### 2.2.7 RMSprop

##### 2.2.8 Adam优化算法

##### 2.2.9 学习率衰减

##### 2.2.10 局部最优问题

##### 【实战编程】mini-batch梯度下降

##### 【实战编程】动量梯度下降

##### 【实战编程】Adam

##### 【实战编程】对比不同的优化算法

#### 2.3 调试神经网络

##### 2.3.1 调参

##### 2.3.2 为调参选择采样标尺

##### 2.3.3 各种调参经验

##### 2.3.4 调参模式和工具

##### 2.3.5 规范化隐藏层的输入

##### 2.3.6 BN的好处

##### 2.3.7 使用模型时的BN

##### 2.3.8 Softmax

##### 2.3.9 深入理解softmax

##### 2.3.10 如何选择深度学习框架

##### 2.3.11 手把手教你使用tensorflow

##### 【实战编程】手把手带你学习Tensorflow v1.x

##### 【实战编程】手把手教你用tensorflow1.x构建一个完整的人工智能程序

##### 【实战编程】手把手带你学习Tensorflow v2.x

### 3 深度学习项目实战

#### 3.1 项目实战一

##### 3.1.1 决策很重要

##### 3.1.2 正交化

##### 3.1.3 如何判断哪个网络更好？——F1分数

##### 3.1.4 如何做选择

##### 3.1.5 验证集与测试集的数据来源要一致

##### 3.1.6 数据集的获取与划分

##### 3.1.7 判定标准是可以变的

##### 3.1.8 AI能力与人类能力的关系

##### 3.1.9 利用贝叶斯误差来判断拟合度

##### 3.1.10 人类误差是多少呢？

##### 3.1.11 AI超越人类

##### 3.1.12 提升AI系统的一般流程

##### 3.1.13 数据集的偏见

##### 【实战编程】大项目神经网络

#### 3.2 实战项目二

##### 3.2.1 手工分析错误

##### 3.2.2 同时手工分析多个错误类别

##### 3.2.3 标签打错了

##### 3.2.4 如何修正错误标签

##### 3.2.5 快速地构建一个简单的系统

##### 3.2.6 验证集要反应出真实目的

##### 3.2.7 异源时的训练验证集

##### 3.2.8 不常用的误差分析

##### 3.2.9 如何解决异源问题

##### 3.2.10 迁移学习

##### 3.2.11 如何实现迁移学习

##### 3.2.12 什么时候才应该使用迁移学习？

##### 3.2.13 多任务学习

##### 3.2.14 深度理解多任务学习

##### 3.2.15 一步到位——端到端学习

##### 3.2.16 何时用端到端

##### 3.2.17 如何制作数据集

##### 【实战编程】优化大项目

### 4 人脸识别

#### 4.1 卷积神经网络

##### 4.1.1 智能视觉

##### 4.1.2 卷积运算

##### 4.1.3 边缘检测

##### 4.1.4 深入理解边缘检测

##### 4.1.5 padding

##### 4.1.6 卷积步长

##### 4.1.7 3D卷积

##### 4.1.8 多过滤器

##### 4.1.9 卷积层

##### 4.1.10 卷积神经网络

##### 4.1.11 池化层

##### 4.1.12 池化层（二）

##### 4.1.13 一个较完整的卷积网络

##### 4.1.14 卷积的好处

##### 【实战编程】手把手教你构建卷积神经网络（一）

##### 【实战编程】手把手教你构建卷积神经网络（二）

##### 【实战编程】使用TensorFlow构建卷积神经网络

#### 4.2 深度卷积网络

##### 4.2.1 学习一些牛逼的例子

##### 4.2.2 LeNet-5

##### 4.2.3 AlexNet

##### 4.2.4 VGG

##### 4.2.5 残差网络

##### 4.2.6 为什么残差网络能防止梯度问题

##### 4.2.7 1×1卷积

##### 4.2.8 Inception网络

##### 4.2.9 inception网络与1×1卷积

##### 4.2.10 完整的inception网络

##### 4.2.11 学会利用开源项目

##### 【实战编程】构建残差网络

#### 4.3 目标检测

##### 4.3.1 物体定位

##### 4.3.2 关键点探测

##### 4.3.3 床长人工智能教程-目标检测

##### 4.3.4 滑动窗口探测法

##### 4.3.5 卷积化滑动窗口

##### 4.3.6 如何判断定位是否精准

##### 4.3.7 如何避免一个物体被重复探测到？

##### 4.3.8 两个物体的中心在同一个格子怎么办？

##### 4.3.9 非极大值抑制的实现细节

##### 4.3.10 床长人工智能教程-候选区域

##### 【实战编程]】自动驾驶之车辆探测

#### 4.4 风格迁移

##### 4.4.1 风格迁移概述

##### 4.4.2 差异性验证

##### 4.4.3 如何实现差异性验证

##### 4.4.4 如何训练差异性验证网络

##### 4.4.5 差异性验证网络的训练技巧

##### 4.4.6 差异性验证网络的另一种训练方法

##### 4.4.7 神经网络每层到底都学会了什么？

##### 4.4.8 神经风格迁移网络

##### 4.4.9 内容损失函数

##### 4.4.10 什么是风格

##### 4.4.11 风格损失函数

##### 【实战编程】风格转换

##### 【实战编程】人脸识别

### 5 语音识别

#### 5.1 循环序列模型

##### 5.1.1 序列模型

##### 5.1.2 序列模型的数据集

##### 5.1.3 循环神经网络RNN

##### 5.1.4 RNN的计算过程

##### 5.1.5 各种结构的RNN

##### 5.1.6 人工智能写作

##### 5.1.7 普通RNN的记性不好

##### 5.1.8 使用LSTM来增强RNN的记忆力

##### 5.1.9 使用GRU来增强RNN的记忆力

##### 5.1.10 双向循环神经网络BRNN

##### 5.1.11 深度RNN

##### 5.1.12 纯pyhon构建RNN

##### 【实战编程】纯pyhon构建RNN

##### 【实战编程】智能写作

##### 【实战编程】智能音乐

##### 【实战编程】智能作曲

#### 5.2 自然语言处理与词嵌入

##### 5.2.1 什么是词嵌入

##### 5.2.2 如何使用词嵌入技术

##### 5.2.3 词嵌入与类比推理

##### 5.2.4 如何得到词嵌入矩阵表

##### 5.2.5 word2vector模型

##### 5.2.6 负采样

##### 5.2.7 Glove模型

##### 5.2.8 情感分类

##### 5.2.9 AI的偏见

##### 5.2.10 词嵌入除偏

##### 【实战编程】类比推理

##### 【实战编程】智能表情

##### 【实战编程]】智能表情-升级版

#### 5.3 序列模型和注意力机制

##### 5.3.1 seq2seq简介

##### 5.3.2 最佳翻译

##### 5.3.3 Beam搜索

##### 5.3.4 Beam搜索升级版

##### 5.3.5 问题是否出在Beam搜索上

##### 5.3.6 如何判断翻译得是否精准

##### 5.3.7 注意力模型

##### 5.3.8 注意力模型详述

##### 5.3.9 如何设置注意力权重？

##### 5.3.10 语音识别

##### 【实战编程】机器翻译

##### 【实战编程】唤醒词检测

### 6 生成对抗网络GANs

### 7 自动驾驶

### 8 强化学习

### 9 无监督学习

### 10 人工大脑

68747470733a2f2f62:6c6f672e6373646e2e6e65742f6a69616e676a756e73686f77:2f61727469636c652f64657461696c732f3737373131353933