---
layout: post
title: "人工智能基础2机器学习深度学习总结"
date: 2025-03-16 21:57:13 +0800
description: "【人工智能基础2】机器学习、深度学习总结"
keywords: "【人工智能基础2】机器学习、深度学习总结"
categories: ['人工智能习题']
tags: ['深度学习', '机器学习', '人工智能']
artid: "146302333"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146302333
    alt: "人工智能基础2机器学习深度学习总结"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146302333
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146302333
cover: https://bing.ee123.net/img/rand?artid=146302333
image: https://bing.ee123.net/img/rand?artid=146302333
img: https://bing.ee123.net/img/rand?artid=146302333
---

# 【人工智能基础2】机器学习、深度学习总结
### 一、人工智能关键技术
领域| 基础原理与逻辑
---|---
机器学习|
机器学习基于数据，研究从观测数据出发寻找规律，利用这些规律对未来数据进行预测。基于学习模式，机器学习可以分为监督、无监督、强化学习；基于学习方法，将机器学习分为传统机器学习和深度学习。
深度学习|
`深度学习是机器学习的一个子集，利用多层神经网络从大量数据中进行学习`。深度学习在搜索、数据挖掘、机器翻译、自然语言处理、语音识别、个性化推荐等相关领域都取得了很多成果。机器学习模仿人类的视听、思考，解决了很多复杂的模式识别难题。
计算机视觉| 利用计算机模仿人类视觉系统，实现对图像及图像序列的提取、处理、理解和分析。逻辑是依据不同类别，处理视觉信号，广泛应用于多个领域。
自然语言处理| 研究人与计算机之间通过自然语言进行沟通。通过机器翻译、语义理解、问答系统等方式，达成自然语言交互的目的。
知识图谱|
用于描述客观世界中概念、实体、事件及其关系，本质是结构化的语义知识库，采用由节点和边组成的图数据结构。以“实体—关系—实体”三元组等构建知识结构，应用于语义搜索等场景。
SLAM技术|
运动物体依靠传感器信息，同时计算自身位置并构建环境地图。旨在解决未知环境下机器人的定位与地图构建问题，依据传感器类型分为视觉SLAM和激光SLAM。
人机交互| 主要研究人和计算机之间的信息交换过程。借助传统交互设备以及新型的语音、情感、体感、脑机交互等技术，实现人机间的信息交流。
VR/AR/MR技术| 以计算机为核心，生成在视觉、听觉、触感等方面与真实环境高度近似的数字化环境，用户借助特定装备与该环境中的对象进行交互。
生物特征识别|
通过个体的生理特征或行为特征来识别认证身份，整个过程分为注册和识别两个阶段。注册时采集并存储特征，识别时采集待识别人的特征并与存储特征进行比对，以此完成身份辨认（一对多）与确认（一对一）。
知识图谱应用场景广泛，可用于语义搜索、智能问答、个性化推荐等。
1. 语义搜索
语义搜索首先将用户输入的问句进行解析，找出问句中的实体和关系，理解用户问句的含义，然后再知识图谱中匹配查询语句，找出答案，最后通过一定形式将结果呈现到用户面前。
2. 智能问答
智能问答，属于一问一答，只要一个答案，也就是将最相关的那个答案反馈给用户，如果像聊天一样不断地进行问答，问答不仅仅是在知识库中搜索，还要考虑前面的聊天内容，考虑的实体和关系更复杂，效果不如语义搜索。
3. 个性化推荐或精准营销
`
个性化推荐系统通过收集用户的兴趣爱好、属性，产品的分类、属性、内容等，分析用户之间的社会关系，用户和产品的关联关系，利用个性化算法，推断出用户的喜好和需求，从而为用户推荐感兴趣的产品或内容。`
### 二、机器学习基础
#### 1\. 监督、无监督、半监督学习
\* \*\*监督学习\*\* ：分为\*\*回归\*\* （函数拟合，捕捉输入到输出的函数映射关系）和\*\*分类\*\* （如决策树、逻辑回归、支持向量机）问题。
\* \*\*无监督学习\*\* ：训练数据无标签，旨在找出数据结构和模式，如聚类算法。k-means算法将样本划分为k个簇，简单高效但对初始簇中心敏感、需事先指定k值等；谱聚类基于图论，能处理非球形簇和高维数据，步骤包括构建相似度矩阵、计算拉普拉斯矩阵等，应用于图像分割、社交网络分析等领域。
#### 2\. 损失函数：四种损失函数
损失函数：表示预测与真实答案的距离。
用于回归：平方和绝对损失函数
用于分类：0-1、交叉熵损失函数
交叉熵损失函数在神经网络分类问题中常用，主要有以下原因：
\* \*\*与分类任务目标契合\*\* ：函数衡量真实分布与预测分布的\*\*差异\*\* ，输出概率分布与真实类别分布越接近，损失越小，很好地适配分类任务中让模型预测类别概率的目标。
\* \*\*计算效率高\*\* ：计算过程相对不复杂，在大规模数据和复杂网络训练中，能有效降低计算成本，提高训练效率。
\* \*\*梯度特性好\*\* ：能为神经网络的反向传播提供清晰且有效的梯度信息，有助于模型快速收敛，避免训练过程中出现梯度消失或爆炸等问题，使模型训练更稳定、高效。
#### 3\. 泛化与交叉验证
\* 泛化指模型对新数据的预测能力，一个良好的泛化能力的模型能够捕捉到数据的潜在规律；
\* 交叉验证是评估并提高模型预测性能的统计方法，通过分割数据减少偏差，常用K折交叉验证，将数据集分成K个子集，轮流作为验证集，其余为训练集，最终取结果平均值评估模型性能。
#### 4\. 过拟合与欠拟合
\* \*\*欠拟合\*\* ：模型在训练集和测试集上表现都差，解决办法包括增加特征数量、模型复杂度，减少正则化参数，增加训练数据，改进特征工程，使用更复杂算法或集成学习。
\* \*\*过拟合\*\* ：模型在训练集表现好但测试集表现差，解决办法有权值衰减、提前停止训练、正则化、减少模型参数、Dropout、数据增强、决策树剪枝、交叉验证等 。
#### 5\. 正则化
“正则”（Regularization）是一种用于控制模型复杂度，为了保证泛化性能，防止过拟合的技术手段。正则化通过在模型的目标函数（如损失函数）中\*\*添加一个惩罚项来实现对模型复杂度的约束\*\*
。
这个惩罚项一般是模型复杂度的单调递增函数：模型越复杂，正则化越大。
正则化的类型（L1(套索)、L2（岭））
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/7c3e300df36c4bc48f7a8bb82a3ade62.png)
L1是通过稀疏参数（减少参数的数量）来降低复杂度，L2是通过减小参数值的大小来降低复杂度。
#### 6\. 支持向量机
\* \*\*SVM 概念\*\* ：监督式学习的分类算法，目标是在特征空间中找最优超平面，使不同类别数据点尽可能分开，且超平面是让两类数据点到它的距离最大化的平面。
\* \*\*支持向量\*\* ：在支持向量机（SVM）里，当解决二分类问题时，会去寻找一个能把两类数据分开的超平面。超平面要使两类数据点到它的距离最大化，叫做最大间隔超平面。 二分类问题可用线性函数作分类器；训练后的模型只与支持向量相关，删除非支持向量样本点不影响模型。
\* \*\*核技巧：\*\* 当数据不完美可分时，通过核函数将原始数据隐式映射到高维特征空间，使原始空间线性不可分的数据在高维空间可能线性可分，且避免高维空间的复杂计算。
### 三、深度学习基础
#### 1、概念与原理
深度学习又称深度神经网络，模拟人类神经大脑系统神经元协同工作原理。通过构造多层神经网络，\*\*将底层特征逐步转换为高层特征表示\*\* ，实现复杂分类等任务。
典型的深度学习模型有卷积神经网络、循环神经网路、长短时记忆神经网络、深度置信网络。
传统机器学习需手工编码特征，耗时且依赖专业知识。深度学习则直接\*\*从数据自动学习特征\*\*
，采用端到端方式解决复杂问题。其模型结构深度大，隐藏层多，通过逐层特征变换，更能挖掘数据内在信息。
\* 语音识别：深度学习模型可直接从语音数据中学习到\*\*语音的特征，进而识别出语音内容\*\* 。
\* 图像分类
#### 2、学习方式
\* \*\*监督学习\*\* ：将训练样本输入神经网络，对比期望答案与实际输出的误差信号，以此调整权值优化模型。训练数据集中样本\*\*带有标签\*\* ，如\*\*Iris数据集\*\* 标注了\*\*花卉样本\*\* 所属品种，算法借此学习如何依据测量结果分类样本。
\* \*\*无监督学习\*\* ：无需数据标签，模型自动\*\*根据数据特征学习\*\* 。比如在\*\*图像聚类\*\* 中，可将相似特征的图像\*\*聚为一类\*\* ，像把不同风景图片按自然风光、城市景观等类别聚类。
\* \*\*半监督学习\*\* ：介于两者之间，无需明确数据标签，但需\*\*对神经网络输出评价以调整参数\*\* ，利用未标记样本和标记样本估计条件概率。如在文本情感分析中，\*\*少量已标注情感倾向的文本\*\* 和大量未标注文本可共同用于训练模型。
#### 3、多层神经网络训练方法
\*\*训练方法\*\* ：2006年Geoffrey Hinten提出\*\*有效训练多层神经网络\*\* 的方法。
第一步，自下（输入层）而上进行\*\*非监督学习\*\* ，逐层训练，上一层的输出作为下一层的输入。
> 逐层构建单层神经元，分层训练各层函数，学习各层参数。例如先训练第一层，再以其输出作为下一层输入继续训练。
第二步，自上（最后一层）而下进行监督学习：底层与标签对比，计算误差调整参数，接着将误差反向传播到下一层，逐层调整。
> \*
> 在完成了第一步逐层构建单层神经元并学习到各层参数后，此时已经得到了一个初步的多层神经网络模型。接下来，使用有标签的数据，\*\*将顶层的输出与实际标签进行对比，计算出误差\*\*
> ，然后根据这个误差来调整顶层的参数，使得顶层的输出更接近实际标签。
> \* 调整完顶层后，\*\*再将误差反向传播到下一层\*\*
> ，以此类推，从顶层开始依次向下调整各层的参数，让整个神经网络的输出结果能够更好地符合预期，从而提高模型的准确性和泛化能力。这种从顶层开始逐步向下调整参数的方式就被称为
> “自顶而下”。
>