---
arturl_encode: "68747470733a2f2f:626c6f672e6373646e2e6e65742f71715f3238383737313235:2f61727469636c652f64657461696c732f3934393038333934"
layout: post
title: "音视频开发基础知识音频基础"
date: 2019-07-06 22:59:17 +08:00
description: " 作为一个通信人音视频的基础知识也是我们专业的基础知识。数字音频 为了将模拟信号数字化，将会有三个操"
keywords: "音频算法基础知识介绍"
categories: ['音视频开发']
tags: ['音视频']
artid: "94908394"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=94908394
    alt: "音视频开发基础知识音频基础"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=94908394
featuredImagePreview: https://bing.ee123.net/img/rand?artid=94908394
---

# 【音视频开发】基础知识：音频基础

作为一个通信人音视频的基础知识也是我们专业的基础知识。

## 数字音频

为了将模拟信号数字化，将会有三个操作分别是
**采样**
、
**量化**
和
**编码**
。⾸先要对模拟信号进⾏采样，所谓采样就是在时间轴上对信号进⾏数字化。根据奈奎斯特定理（也称为采样定理），按⽐声⾳最⾼频率⾼2倍以上的频率对声⾳进⾏采样（也称为AD转换），对于⾼质量的⾳频信号，其频率范围（⼈⽿能够听到的频率范围）是20Hz～20kHz，所以采样频率⼀般为44.1kHz，这样就可以保证采样声⾳达到20kHz也能被数字化，从⽽使得经过数字化处理之后，⼈⽿听到的声⾳质量不会被降低。⽽所谓的44.1kHz就是代表1秒会采样44100次（如下图）。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/e0293efd6024e9772dd8c88b89c86e5f.png)
那么，具体的每个采样又该如何表⽰呢？这就涉及将要讲解的第⼆个概念：量化。量化是指在幅度轴上对信号进⾏数字化，⽐如⽤16⽐特的⼆进制信号来表⽰声⾳的⼀个采样，⽽16⽐特（C语言中⼀个short类型的长度）所表⽰的范围是[-32768，32767]，共有65536个可能取值，因此最终模拟的⾳频信号在幅度上也分为了65536层（如下图）。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/84ad572a81ca4fbcf34d71fee512cca8.png)
既然每⼀个量化都是⼀个采样，那么这么多的采样该如何进⾏存储呢？这就涉及将要讲解的第三个概念：编码。所谓编码，就是按照⼀定的格式记录采样和量化后的数字数据，⽐如顺序存储或压缩存储，等等。

这⾥⾯涉及了很多种格式，通常所说的音频的裸数据格式就是脉冲编码调制（Pulse Code Modulation，PCM）数据。描述⼀段PCM数据⼀般需要以下⼏个概念：量化格式（sampleFormat）、采样率（sampleRate）、声道数（channel）。以CD的音质为例：量化格式（有的地⽅描述为位深度）为16⽐特（2字节），采样率为44100，声道数为2，这些信息就描述了CD的⾳质。⽽对于声⾳格式，还有⼀个概念⽤来描述它的⼤⼩，称为数据⽐特率，即1秒时间内的⽐特数⽬，它⽤于衡量⾳频数据单位时间内的容量⼤⼩。⽽对于CD⾳质的数据，⽐特率为多少呢？计算如下：

```
44100 * 16 * 2 = 1378.125kbps

```

那么在1分钟⾥，这类CD⾳质的数据需要占据多⼤的存储空间呢？计算如下：

```
1378.125 * 60 / 8 / 1024 = 10.09MB

```

当然，如果sampleFormat更加精确（⽐如⽤4字节来描述⼀个采样），或者sampleRate更加密集（⽐如48kHz的采样率），那么所占的存储空间就会更⼤，同时能够描述的声音细节就会越精确。存储的这段⼆进制数据即表⽰将模拟信号转换为数字信号了，以后就可以对这段⼆进制数据进⾏存储、播放、复制，或者进⾏其他任何操作。

**麦克风采集声音**
  
麦克风⾥⾯有⼀层碳膜，⾮常薄⽽且⼗分敏感。声⾳其实是⼀种纵波，会压缩空⽓也会压缩这层碳膜，碳膜在受到挤压时也会发出振动，在碳膜的下⽅就是⼀个电极，碳膜在振动的时候会接触电极，接触时间的长短和频率与声波的振动幅度和频率有关，这样就完成了声⾳信号到电信号的转换。之后再经过放⼤电路处理，就可以实施后⾯的采样量化处理了。

前⾯提到过分贝，那么什么是分贝呢？分贝是⽤来表⽰声⾳强度的单位。⽇常⽣活中听到的声⾳，若以声压值来表⽰，由于其变化范围⾮常⼤，可以达到六个数量级以上，同时由于我们的⽿朵对声⾳信号强弱刺激的反应不是线性的，⽽是呈对数⽐例关系，所以引⼊分贝的概念来表达声学量值。所谓分贝是指两个相同的物理量（例如，A1和A0）之⽐取以10为底的对数并乘以10（或20），即：

```
N= 10 * lg（A1 / A0）

```

分贝符号为“dB”，它是⽆量纲的。式中A0是基准量（或参考量），A1是被量度量。

#### 音频编码

上面提到了CD⾳质的数据采样格式，曾计算出每分钟需要的存储空间约为10.1MB，如果仅仅是将其存放在存储设备（光盘、硬盘）中，可能是可以接受的，但是若要在⽹络中实时在线传播的话，那么这个数据量可能就太⼤了，所以必须对其进⾏压缩编码。压缩编码的基本指标之⼀就是压缩⽐，压缩⽐通常⼩于1（否则就没有必要去做压缩，因为压缩就是要减⼩数据容量）。压缩算法包括有损压缩和⽆损压缩。⽆损压缩是指解压后的数据可以完全复原。在常⽤的压缩格式中，⽤得较多的是有损压缩，有损压缩是指解压后的数据不能完全复原，会丢失⼀部分信息，压缩⽐越⼩，丢失的信息就越多，信号还原后的失真就会越⼤。根据不同的应⽤场景（包括存储设备、传输⽹络环境、播放设备等），可以选⽤不同的压缩编码算法，如PCM、WAV、AAC、MP3、Ogg等。

压缩编码的原理实际上是压缩掉冗余信号，冗余信号是指不能被⼈⽿感知到的信号，包含⼈⽿听觉范围之外的⾳频信号以及被掩蔽掉的⾳频信号等。⽽被掩蔽掉的⾳频信号则主要是因为⼈⽿的掩蔽效应，主要表现为频域掩蔽效应与时域掩蔽效应，⽆论是在时域还是频域上，被掩蔽掉的声⾳信号都被认为是冗余信息，不进⾏编码处理。

**下⾯介绍⼏种常⽤的压缩编码格式**

##### 1、WAV编码

PCM（脉冲编码调制）是Pulse Code Modulation的缩写。前⾯已经介绍过PCM⼤致的⼯作流程，⽽WAV编码的⼀种实现（有多种实现⽅式，但是都不会进⾏压缩操作）就是在PCM数据格式的前⾯加上44字节，分别⽤来描述PCM的采样率、声道数、数据格式等信息。

特点：⾳质⾮常好，⼤量软件都⽀持。
  
适⽤场合：多媒体开发的中间⽂件、保存⾳乐和⾳效素材。

##### 2、MP3编码

MP3具有不错的压缩⽐，使⽤LAME编码（MP3编码格式的⼀种实现）的中⾼码率的MP3⽂件，听感上⾮常接近源WAV⽂件，当然在不同的应⽤场景下，应该调整合适的参数以达到最好的效果。

特点：⾳质在128Kbit/s以上表现还不错，压缩⽐⽐较⾼，⼤量软件和硬件都⽀持，兼容性好。
  
适⽤场合：⾼⽐特率下对兼容性有要求的⾳乐欣赏。

##### 3、AAC编码

AAC是新⼀代的⾳频有损压缩技术，它通过⼀些附加的编码技术（⽐如PS、SBR等），衍⽣出了LC-AAC、HE-AAC、HE-AAC v2三种主要的编码格式。LC-AAC是⽐较传统的AAC，相对⽽⾔，其主要应⽤于中⾼码率场景的编码（≥80Kbit/s）；HE-AAC（相当于AAC+SBR）主要应⽤于中低码率场景的编码（≤80Kbit/s）；⽽新近推出的HE-AAC v2（相当于AAC+SBR+PS）主要应⽤于低码率场景的编码（≤48Kbit/s）。事实上⼤部分编码器都设置为≤48Kbit/s⾃动启⽤PS技术，⽽>48Kbit/s则不加PS，相当于普通的HE-AAC。

特点：在⼩于128Kbit/s的码率下表现优异，并且多⽤于视频中的⾳频编码。
  
适⽤场合：128Kbit/s以下的⾳频编码，多⽤于视频中⾳频轨的编码。

##### 4、Ogg编码

Ogg是⼀种⾮常有潜⼒的编码，在各种码率下都有⽐较优秀的表现，尤其是在中低码率场景下。Ogg除了⾳质好之外，还是完全免费的，这为Ogg获得更多的⽀持打好了基础。Ogg有着⾮常出⾊的算法，可以⽤更⼩的码率达到更好的⾳质，128Kbit/s的Ogg⽐192Kbit/s甚⾄更⾼码率的MP3还要出⾊。但⽬前因为还没有媒体服务软件的⽀持，因此基于Ogg的数字⼴播还⽆法实现。Ogg⽬前受⽀持的情况还不够好，⽆论是软件上的还是硬件上的⽀持，都⽆法和MP3相提并论。

特点：可以⽤⽐MP3更⼩的码率实现⽐MP3更好的⾳质，⾼中低码率下均有良好的表现，兼容性不够好，流媒体特性不⽀持。
  
适⽤场合：语⾳聊天的⾳频消息场景。