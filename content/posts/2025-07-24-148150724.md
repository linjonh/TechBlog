---
layout: post
title: "学习笔记机器学习Machine-Learning-第七章神经网络3"
date: 2025-07-24T14:04:45+0800
description: "本文基于吴恩达教授的课程，介绍了使用TensorFlow实现深度学习神经网络的基础知识。文章通过两个实例——咖啡烘焙程度预测模型和数字分类模型，详细讲解了如何构建和训练神经网络。咖啡烘焙模型通过温度和时长预测咖啡质量，而数字分类模型则通过多层全连接网络进行数字识别。文章还强调了numpy数组在数据处理中的重要性，并解释了激活向量的计算过程。通过这些案例，读者可以初步掌握TensorFlow的基本操作和神经网络模型的构建方法。"
keywords: "【学习笔记】机器学习(Machine Learning) | 第七章|神经网络(3)"
categories: ['未分类']
tags: ['笔记', '机器学习']
artid: "148150724"
arturl: "https://blog.csdn.net/2401_87688549/article/details/148150724"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=148150724
    alt: "学习笔记机器学习Machine-Learning-第七章神经网络3"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=148150724
featuredImagePreview: https://bing.ee123.net/img/rand?artid=148150724
cover: https://bing.ee123.net/img/rand?artid=148150724
image: https://bing.ee123.net/img/rand?artid=148150724
img: https://bing.ee123.net/img/rand?artid=148150724
---



# 【学习笔记】机器学习(Machine Learning) | 第七章|神经网络(3)



## 机器学习（Machine Learning）

### 简要声明

> 基于吴恩达教授(Andrew Ng)课程视频  
>  [BiliBili课程资源](https://www.bilibili.com/video/BV1owrpYKEtP?t=0.8)

---

---

## 神经网络中 TensorFlow 初步代码实现

### 一、引言

在机器学习蓬勃发展的今天，深度学习凭借强大的特征提取与模式识别能力，成为计算机视觉、自然语言处理等前沿领域的核心技术。而 TensorFlow 作为业界广泛应用的开源深度学习框架，以其灵活的架构和丰富的 API，为开发者构建神经网络模型提供了高效工具。  
 本篇博客初步掌握了 TensorFlow 在深度学习神经网络中的基础代码实现，对简单模型的搭建和核心概念有了基础认知。深入探索如何构建更复杂、更具实际应用价值的神经网络架构，并结合具体案例，逐步掌握其在不同场景下的实践技巧。

### 二、实例分析

#### （一）咖啡烘焙程度预测模型

**模型原理**：该模型聚焦咖啡烘焙场景，以温度（Temperature）和烘焙时长（Duration）为核心特征，通过神经网络构建二维平面上的决策边界，将烘焙结果划分为烘焙不足（undercooked）、烘焙过度（overcooked）和优质咖啡（good coffee）三类。

**数学表达**：设输入特征向量 
x
⃗
=
[
x
1
,
x
2
]
\vec{x} = [x_1, x_2]
x


=[x1​,x2​]，其中 
x
1
x_1
x1​ 代表温度，
x
2
x_2
x2​ 代表时长。经神经网络计算得到输出 
a
1
[
2
]
a^{[2]}_1
a1[2]​ ，以阈值 
0.5
0.5
0.5 为判断标准：当 
a
1
[
2
]
≥
0.5
a^{[2]}_1 \geq 0.5
a1[2]​≥0.5 时，预测结果 
y
^
=
1
\hat{y} = 1
y^​=1（优质咖啡）；反之，
y
^
=
0
\hat{y} = 0
y^​=0 。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a5a7651994e7414c85a39a0553c7d2f1.png#pic_center)

**代码实现**

```python
import numpy as np
import tensorflow as tf

# 输入特征，形状为(1, 2)，表示1个样本，2个特征
x = np.array([[200.0, 17.0]]) 
# 第一层全连接层，配置3个神经元，采用sigmoid激活函数，将输入映射到非线性空间
layer_1 = tf.keras.layers.Dense(units=3, activation='sigmoid') 
a1 = layer_1(x)
# 第二层全连接层，单神经元输出，sigmoid激活后得到最终预测概率
layer_2 = tf.keras.layers.Dense(units=1, activation='sigmoid') 
a2 = layer_2(a1)

# 根据预测概率进行类别判定
if a2 >= 0.5:
    yhat = 1
else:
    yhat = 0

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/728fbe99206c4fd69c4fb3e924f364f9.png)

#### （二）数字分类模型

**模型结构**：构建一个包含三层的全连接神经网络，输入层接收特征向量 
x
⃗
\vec{x}
x


 ，依次经过 25 个神经元的第一层、15 个神经元的第二层，最终由单神经元的第三层输出分类结果。每层均采用 sigmoid 激活函数引入非线性。

**数学公式**：设输入向量为 
x
⃗
\vec{x}
x


 ，各层输出分别为 
a
[
1
]
a^{[1]}
a[1] 、
a
[
2
]
a^{[2]}
a[2] 、
a
[
3
]
a^{[3]}
a[3] 。通过矩阵乘法与激活函数运算生成最终输出 
a
1
[
3
]
a^{[3]}_1
a1[3]​ ，同样以 
0.5
0.5
0.5 为阈值判断预测类别 
y
^
\hat{y}
y^​ 。

**代码实现**

```python
import numpy as np
import tensorflow as tf

# 输入特征，实际应用中需填充完整样本数据
x = np.array([[0.0,...,245,...,240,...0]]) 
# 第一层全连接层，25个神经元扩展特征维度
layer_1 = tf.keras.layers.Dense(units=25, activation='sigmoid') 
a1 = layer_1(x)
# 第二层全连接层，进一步提炼特征
layer_2 = tf.keras.layers.Dense(units=15, activation='sigmoid') 
a2 = layer_2(a1)
# 第三层全连接层，输出最终预测概率
layer_3 = tf.keras.layers.Dense(units=1, activation='sigmoid') 
a3 = layer_3(a2)

# 预测结果判定
if a3 >= 0.5:
    yhat = 1
else:
    yhat = 0

```

#### （三）numpy 数组相关要点

在 TensorFlow 开发中，numpy 数组是处理数据的重要载体，其创建方式与形状特性对模型输入输出影响显著：

| 创建方式 | 示例代码 | 数组形状 | 说明 |
| --- | --- | --- | --- |
| 标准二维数组 | `x = np.array([[1, 2, 3], [4, 5, 6]])` | 2 × 3 2 \times 3 2×3 | 构建 2 行 3 列的矩阵，常用于批量样本特征存储 |
| 多样本特征数组 | `x = np.array([[0.1, 0.2], [-3.0, -4.0], [-0.5, -0.6], [7.0, 8.0]])` | 4 × 2 4 \times 2 4×2 | 表示 4 个样本，每个样本含 2 个特征 |
| 单行样本数组 | `x = np.array([[200, 17]])` | 1 × 2 1 \times 2 1×2 | 单样本双特征，需保持二维结构适配模型输入 |
| 单列特征数组 | `x = np.array([[200], [17]])` | 2 × 1 2 \times 1 2×1 | 常用于表示含 2 个样本的单特征数据 |
| 一维向量 | `x = np.array([200,17])` | 一维 | 本质为向量，在特定场景下需转换为二维结构 |

#### （四）激活向量相关

以咖啡烘焙模型第二层计算为例，深入理解激活向量机制：

1. **层定义**：`layer_2 = Dense(units=1, activation='sigmoid')` 构建单神经元输出层，sigmoid 函数将输出值域压缩至 (0, 1) 区间，便于概率解释。
2. **激活计算**：`a2 = layer_2(a1)` 基于上一层输出 
   a
   [
   1
   ]
   a^{[1]}
   a[1] 计算当前层激活向量 
   a
   [
   2
   ]
   a^{[2]}
   a[2] 。假设输出为 
   a
   [
   2
   ]
   =
   [
   [
   0.8
   ]
   ]
   a^{[2]} = [[0.8]]
   a[2]=[[0.8]] ，其形状为 
   (
   1
   ,
   1
   )
   (1, 1)
   (1,1) ，在 TensorFlow 中以 `tf.Tensor` 类型存储。如需与 numpy 协同处理，可调用 `a2.numpy()` 转换为 numpy 数组。

---

### 三、构建神经网络架构

#### （一）简单神经网络架构示例

我们从一个直观的案例入手，解读 “Building a neural network architecture” 图中的网络结构：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/f60db11a32b940f89bf88394a5dba782.png)

* **网络结构解析**：这是一个两层神经网络，输入层接收特征向量 
  x
  ⃗
  \vec{x}
  x


   ，第一层包含 3 个神经元，采用 sigmoid 激活函数，能将线性输入转换为非线性输出；第二层仅有 1 个神经元，同样使用 sigmoid 函数，用于输出最终预测概率。使用 TensorFlow 的 Sequential 模型可轻松实现该结构：

```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
    Dense(units=3, activation="sigmoid"),
    Dense(units=1, activation="sigmoid")
])

```

* **数据准备要点**：输入数据 `x` 是形状为 `4 x 2` 的 numpy 数组，意味着包含 4 个样本，每个样本具有 2 个特征；目标数据 `y` 则是对应的标签数据，同样以 numpy 数组形式呈现。例如：

```python
x = np.array([[200.0, 17.0],
              [120.0, 5.0],
              [425.0, 20.0],
              [212.0, 18.0]])
y = np.array([1, 0, 0, 1])

```

* **模型训练与预测流程**：尽管图中 `model.compile(...)` 部分未详细展开，但我们知道这一步至关重要，需配置优化器、损失函数等关键参数。通过 `model.fit(x, y)` 进行模型训练，使其学习输入特征与目标标签的映射关系。训练完成后，使用 `model.predict(x_new)` 即可对新数据进行预测。

#### （二）数字分类模型架构

接下来分析 “Digit classification model” 图中的复杂神经网络架构：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/0f859915e1bc4e279dcf5d08ad7cfee1.png)

* **网络深度与设计**：该网络包含三层，第一层 25 个神经元用于初步特征提取，第二层 15 个神经元进一步提炼特征，第三层单神经元输出最终预测结果，每层均采用 sigmoid 激活函数。我们可以分步定义各层，再组合成 Sequential 模型：

```python
layer_1 = Dense(units=25, activation="sigmoid")
layer_2 = Dense(units=15, activation="sigmoid")
layer_3 = Dense(units=1, activation="sigmoid")

model = Sequential([layer_1, layer_2, layer_3])

```

* **数据特征与标签**：输入数据 `x` 是代表数字图像特征的 numpy 数组（如像素值等），由于图像数据维度较高，这里仅展示部分数据结构；目标数据 `y` 则是对应数字标签，例如：

```python
x = np.array([[0..., 245,..., 17],
              [0..., 200,..., 184]])
y = np.array([1, 0])

```

* **完整训练预测链路**：与简单模型类似，先通过 `model.compile(...)` 配置训练参数，再使用 `model.fit(x, y)` 完成训练，最终利用训练好的模型对新图像数据进行预测。

### 四、构建神经网络的关键要点

#### （一）层的选择与设计策略

在神经网络构建中，层的选择直接决定模型性能：

* **全连接层（Dense）**：适用于多种数据类型，其神经元全连接特性使其能捕捉全局特征关系，但计算复杂度较高。
* **卷积层（Conv）**：专为图像数据设计，通过卷积核自动提取局部特征，大幅减少参数数量，有效避免过拟合，是计算机视觉领域的核心层。
* **循环层（RNN 及变体 LSTM、GRU）**：擅长处理序列数据，如时间序列、文本等，能记忆历史信息，捕捉长距离依赖关系。

#### （二）激活函数的应用场景

激活函数是赋予神经网络非线性能力的关键：

* **sigmoid 函数**：将输出压缩至 (0, 1) 区间，常用于二分类问题的输出层，但存在梯度消失问题，不适用于深层网络。
* **ReLU 函数**：以 
  f
  (
  x
  )
  =
  m
  a
  x
  (
  0
  ,
  x
  )
  f(x) = max(0, x)
  f(x)=max(0,x) 为核心逻辑，有效缓解梯度消失，加速训练，是隐藏层的常用选择。
* **tanh 函数**：输出值域为 (-1, 1)，相比 sigmoid 有更好的中心化效果，在某些特定场景表现优异。

#### （三）数据预处理的核心操作

高质量的数据是模型训练的基础：

* **归一化处理**：将图像像素值从 [0, 255] 归一化到 [0, 1]，或使用标准化方法将数据转换为均值为 0、方差为 1 的分布，可提升模型稳定性与收敛速度。
* **维度校验**：确保输入数据维度与模型要求一致，如图像数据需注意通道数、尺寸等维度信息，避免因维度错误导致训练失败。

### 五、总结

通过咖啡烘焙预测与数字分类两个典型案例，我们系统学习了 TensorFlow 构建神经网络的基础流程，涵盖数据输入处理、网络层搭建、激活函数应用及结果判定，掌握了 numpy 数组在数据组织中的关键作用，以及激活向量的计算与数据类型转换。同时，我们构建了更复杂、更具实际应用价值的神经网络架构。

---

continue…



