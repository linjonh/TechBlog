---
layout: post
title: "ClickHouse-中出现-DBException-Too-many-parts-错误"
date: 2025-03-06 20:15:18 +0800
description: "**`background_pool_size`** 控制后台线程池的大小，用于处理合并（Merge）、物化视图刷新、数据插入（Insert）等后台任务。- **`number_of_free_entries_in_pool_to_execute_mutation`**：控制突变任务触发阈值。- **任务积压减少**：检查 `system.merges` 和 `system.metrics`。- **`max_background_merges`**：控制合并任务并发数（默认 16）。"
keywords: "ClickHouse 中出现 DB::Exception: Too many parts 错误"
categories: ['未分类']
tags: ['数据库', '前端', 'Java']
artid: "146079281"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146079281
    alt: "ClickHouse-中出现-DBException-Too-many-parts-错误"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146079281
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146079281
cover: https://bing.ee123.net/img/rand?artid=146079281
image: https://bing.ee123.net/img/rand?artid=146079281
img: https://bing.ee123.net/img/rand?artid=146079281
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     ClickHouse 中出现 DB::Exception: Too many parts 错误
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="./../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="./../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     在 ClickHouse 中出现
     <code>
      DB::Exception: Too many parts
     </code>
     错误，通常是由于表中数据分片（parts）数量超过系统限制，导致合并（merge）操作无法及时处理。以下是逐步解决方案：
    </p>
    <hr/>
    <h4>
     <strong>
      1. 理解问题原因
     </strong>
    </h4>
    <ul>
     <li>
      <strong>
       MergeTree 表引擎特性
      </strong>
      ：ClickHouse 的 MergeTree 引擎表会将数据划分为多个 parts，后台线程定期合并小 parts 成大 part。如果写入速度远快于合并速度，parts 数量会累积。
     </li>
     <li>
      <strong>
       直接原因
      </strong>
      ：当前表有 600 个 parts（平均大小 10.82 MiB），超过默认阈值（通常为 300）。
     </li>
    </ul>
    <hr/>
    <h4>
     <strong>
      2. 临时应急措施
     </strong>
    </h4>
    <h5>
     <strong>
      手动触发合并
     </strong>
    </h5>
    <pre><code>OPTIMIZE TABLE your_table FINAL;
</code></pre>
    <ul>
     <li>
      <strong>
       作用
      </strong>
      ：强制合并所有 parts，但可能耗时较长，生产环境需谨慎。
     </li>
     <li>
      <strong>
       注意
      </strong>
      ：
      <code>
       FINAL
      </code>
      关键字会强制合并，即使数据已经合并过。
     </li>
    </ul>
    <hr/>
    <h4>
     <strong>
      3. 优化写入策略
     </strong>
    </h4>
    <h5>
     <strong>
      减少小批量写入频率
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       推荐批量大小
      </strong>
      ：单次插入数据量建议在
      <strong>
       100MB~1GB
      </strong>
      之间（根据硬件调整）。
     </li>
     <li>
      <strong>
       示例
      </strong>
      ：将每秒写入 100 次 1MB 的数据，改为每 10 秒写入 1 次 100MB 的数据。
     </li>
    </ul>
    <h5>
     <strong>
      使用 Buffer 表缓冲写入
     </strong>
    </h5>
    <pre><code>CREATE TABLE your_table_buffer AS your_table
ENGINE = Buffer(default, your_table, 16, 10, 100, 10000, 1000000, 10000000, 100000000);
</code></pre>
    <ul>
     <li>
      <strong>
       作用
      </strong>
      ：通过内存缓冲表累积小批量写入，批量刷入目标表。
     </li>
    </ul>
    <hr/>
    <h4>
     <strong>
      4. 调整合并参数
     </strong>
    </h4>
    <h5>
     <strong>
      修改
      <code>
       merge_tree
      </code>
      配置（在
      <code>
       config.xml
      </code>
      或
      <code>
       users.xml
      </code>
      ）
     </strong>
    </h5>
    <pre><code>&lt;merge_tree&gt;
    &lt;max_suspicious_broken_parts&gt;5&lt;/max_suspicious_broken_parts&gt;
    &lt;max_parts_in_total&gt;1000&lt;/max_parts_in_total&gt;  &lt;!-- 调高阈值 --&gt;
    &lt;parts_to_delay_insert&gt;500&lt;/parts_to_delay_insert&gt;  &lt;!-- 插入延迟阈值 --&gt;
    &lt;parts_to_throw_insert&gt;600&lt;/parts_to_throw_insert&gt;  &lt;!-- 插入报错阈值 --&gt;
&lt;/merge_tree&gt;
</code></pre>
    <ul>
     <li>
      <strong>
       关键参数
      </strong>
      ：
      <ul>
       <li>
        <code>
         max_parts_in_total
        </code>
        : 允许的最大 parts 总数。
       </li>
       <li>
        <code>
         parts_to_delay_insert
        </code>
        : 达到此数量后，新插入会延迟。
       </li>
       <li>
        <code>
         parts_to_throw_insert
        </code>
        : 达到此数量后，新插入会报错。
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <strong>
      增加后台合并线程数
     </strong>
    </h5>
    <pre><code>&lt;background_pool_size&gt;16&lt;/background_pool_size&gt;       &lt;!-- 默认 16 --&gt;
&lt;background_schedule_pool_size&gt;16&lt;/background_schedule_pool_size&gt;
</code></pre>
    <ul>
     <li>
      <strong>
       注意
      </strong>
      ：根据 CPU 核心数调整，避免过度占用资源。
     </li>
    </ul>
    <hr/>
    <h4>
     <strong>
      5. 优化表结构
     </strong>
    </h4>
    <h5>
     <strong>
      调整分区粒度
     </strong>
    </h5>
    <pre><code>CREATE TABLE your_table (
    ...
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(date_column)  -- 按月度分区，而非按天
ORDER BY (timestamp, id);
</code></pre>
    <ul>
     <li>
      <strong>
       作用
      </strong>
      ：减少分区数量，降低每个分区的 parts 数量。
     </li>
    </ul>
    <h5>
     <strong>
      使用 TTL 自动清理旧数据
     </strong>
    </h5>
    <pre><code>ALTER TABLE your_table MODIFY TTL date_column + INTERVAL 30 DAY;
</code></pre>
    <ul>
     <li>
      <strong>
       作用
      </strong>
      ：自动删除过期数据，减少 parts 总数。
     </li>
    </ul>
    <hr/>
    <h4>
     <strong>
      6. 监控与维护
     </strong>
    </h4>
    <h5>
     <strong>
      查询当前 parts 状态
     </strong>
    </h5>
    <pre><code>SELECT
    table,
    count() AS parts_count,
    formatReadableSize(sum(bytes)) AS total_size
FROM system.parts
WHERE active
GROUP BY table;
</code></pre>
    <h5>
     <strong>
      定期检查合并状态
     </strong>
    </h5>
    <pre><code>SELECT
    database,
    table,
    elapsed,
    progress,
    is_mutation
FROM system.merges;
</code></pre>
    <hr/>
    <h4>
     <strong>
      7. 高级方案（可选）
     </strong>
    </h4>
    <h5>
     <strong>
      使用 Kafka 引擎表 + Materialized View
     </strong>
    </h5>
    <pre><code>CREATE TABLE your_kafka_source
ENGINE = Kafka()
SETTINGS ...;

CREATE MATERIALIZED VIEW your_mv TO your_table AS
SELECT * FROM your_kafka_source;
</code></pre>
    <ul>
     <li>
      <strong>
       作用
      </strong>
      ：通过 Kafka 引擎表批量消费数据，减少写入频率。
     </li>
    </ul>
    <hr/>
    <h4>
     <strong>
      总结
     </strong>
    </h4>
    <ol>
     <li>
      <strong>
       立即执行
      </strong>
      ：手动
      <code>
       OPTIMIZE TABLE
      </code>
      缓解问题。
     </li>
     <li>
      <strong>
       短期调整
      </strong>
      ：调高
      <code>
       max_parts_in_total
      </code>
      阈值。
     </li>
     <li>
      <strong>
       长期根治
      </strong>
      ：优化写入批量大小、使用 Buffer 表或 Kafka 管道。
     </li>
     <li>
      <strong>
       预防措施
      </strong>
      ：监控 parts 数量，调整分区策略和 TTL。
     </li>
    </ol>
    <p>
     通过组合使用这些方法，可有效避免
     <code>
      Too many parts
     </code>
     错误，确保 ClickHouse 稳定运行。
    </p>
    <p>
    </p>
    <p>
     优化 ClickHouse 的 `background_pool_size` 需要结合硬件资源、工作负载类型和监控指标逐步调整。以下是分步指南：
    </p>
    <p>
     ---
    </p>
    <p>
     ### **1. 理解参数作用**
     <br/>
     - **`background_pool_size`** 控制后台线程池的大小，用于处理合并（Merge）、物化视图刷新、数据插入（Insert）等后台任务。
     <br/>
     - 线程不足会导致任务积压（如合并延迟、写入卡顿）；过多可能导致资源争用（CPU/IO）或上下文切换开销。
    </p>
    <p>
     ---
    </p>
    <p>
     ### **2. 查看当前状态**
     <br/>
     #### **检查后台任务积压**
     <br/>
     ```sql
     <br/>
     SELECT
     <br/>
     database,
     <br/>
     table,
     <br/>
     elapsed,
     <br/>
     progress
     <br/>
     FROM system.merges;  -- 查看合并任务进度和耗时
    </p>
    <p>
     SELECT * FROM system.metrics
     <br/>
     WHERE metric IN ('BackgroundPoolTask', 'BackgroundSchedulePoolTask');  -- 等待执行的任务数
     <br/>
     ```
     <br/>
     - 如果 `elapsed` 值高或任务堆积，可能是线程不足。
    </p>
    <p>
     #### **监控系统指标**
     <br/>
     ```sql
     <br/>
     SELECT
     <br/>
     value AS threads_num,
     <br/>
     'background_pool_size' AS param
     <br/>
     FROM system.settings
     <br/>
     WHERE name = 'background_pool_size';
     <br/>
     ```
     <br/>
     - 对比当前线程数与实际负载。
    </p>
    <p>
     ---
    </p>
    <p>
     ### **3. 设置建议值**
     <br/>
     #### **初始建议值**
     <br/>
     - **CPU 核心数**：通常设置为物理 CPU 核心数的 **50%~100%**。
     <br/>
     - 例如：16 核 CPU → 初始值设为 `8~16`。
     <br/>
     - **存储类型**：
     <br/>
     - **HDD**：保守设置（避免 IO 争用）。
     <br/>
     - **SSD/NVMe**：可适当调高（IO 吞吐更高）。
    </p>
    <p>
     #### **写入/合并密集型场景**
     <br/>
     - 高频写入或大分区合并时，可逐步增加线程数（例如从 `16` 调整到 `24`），但需观察资源瓶颈。
    </p>
    <p>
     ---
    </p>
    <p>
     ### **4. 调整并验证**
     <br/>
     #### **修改配置**
     <br/>
     在 `config.xml` 或 `users.xml` 中调整：
     <br/>
     ```xml
     <br/>
     &lt;background_pool_size&gt;24&lt;/background_pool_size&gt;
     <br/>
     ```
     <br/>
     重启 ClickHouse 服务生效。
    </p>
    <p>
     #### **验证效果**
     <br/>
     - **任务积压减少**：检查 `system.merges` 和 `system.metrics`。
     <br/>
     - **资源利用率**：监控 CPU、IO 使用率（避免长期超过 80%）。
     <br/>
     - **查询性能**：确保前台查询未因资源争用而变慢。
    </p>
    <p>
     ---
    </p>
    <p>
     ### **5. 高级优化**
     <br/>
     #### **区分任务优先级**
     <br/>
     - 使用 `background_processing_pool_size`（社区版需手动调整）分离合并和插入任务。
     <br/>
     - 通过 `SET max_threads = ...` 限制单个查询资源，避免后台任务被阻塞。
    </p>
    <p>
     #### **结合其他参数**
     <br/>
     - **`max_background_merges`**：控制合并任务并发数（默认 16）。
     <br/>
     - **`number_of_free_entries_in_pool_to_execute_mutation`**：控制突变任务触发阈值。
    </p>
    <p>
     ---
    </p>
    <p>
     ### **6. 监控工具**
     <br/>
     - **Prometheus + Grafana**：集成 `ClickHouse Exporter` 监控后台任务队列、CPU/IO。
     <br/>
     - **内置表**：定期检查 `system.asynchronous_metrics` 和 `system.events`。
    </p>
    <p>
     ---
    </p>
    <p>
     ### **示例配置**
     <br/>
     ```xml
     <br/>
     &lt;!-- 针对 32 核 SSD 服务器，高写入场景 --&gt;
     <br/>
     &lt;background_pool_size&gt;24&lt;/background_pool_size&gt;
     <br/>
     &lt;max_background_merges&gt;16&lt;/max_background_merges&gt;
     <br/>
     &lt;number_of_free_entries_in_pool_to_execute_mutation&gt;8&lt;/number_of_free_entries_in_pool_to_execute_mutation&gt;
     <br/>
     ```
    </p>
    <p>
     ---
    </p>
    <p>
     ### **总结**
     <br/>
     - 从默认值开始，逐步调整并观察监控指标。
     <br/>
     - 平衡后台任务和前台查询的资源占用。
     <br/>
     - 磁盘 IO 或 CPU 瓶颈时，优先优化硬件或数据分布（如分区键设计）。
    </p>
    <p>
     通过以上步骤，可有效优化 `background_pool_size` 提升 ClickHouse 后台任务处理效率。
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f71797138383838382f:61727469636c652f64657461696c732f313436303739323831" class_="artid" style="display:none">
 </p>
</div>


