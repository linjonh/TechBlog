---
arturl_encode: "68747470733a2f2f626c6f:672e6373646e2e6e65742f323430325f38373037363337362f:61727469636c652f64657461696c732f313436313433323435"
layout: post
title: "Sparkscp命令,rsync命令,ssh命令"
date: 2025-03-10 13:38:23 +0800
description: "eg命令：scp -r /opt/module/jdk1.8.0_212/ root@hadoop102:/opt/module/jdk1.8.0_212/命令：rsync -av /opt/conf/1.txt root@roothadoop102:/opt/conf/eg：目标：hadoop100通过ssh访问hadoop101,hadoop102时不需要密码，其他两台设备也类似。此时，我们去查看文件，可以看到它的颜色是灰色的，不具备执行权限（如下图）。这个部分的代码不需要会写，能看懂，了解即可。"
keywords: "Spark；scp命令，rsync命令，ssh命令"
categories: ['未分类']
tags: ['大数据', '分布式', 'Spark']
artid: "146143245"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146143245
    alt: "Sparkscp命令,rsync命令,ssh命令"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146143245
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146143245
cover: https://bing.ee123.net/img/rand?artid=146143245
image: https://bing.ee123.net/img/rand?artid=146143245
img: https://bing.ee123.net/img/rand?artid=146143245
---

# Spark；scp命令，rsync命令，ssh命令

### hadoop的运行模式

**本地运行：**
在一台单机上运行，没有分布式文件系统，直接读写本地操作系统的文件系统。
**特点**
：不对配置文件进行修改，Hadoop 不会启动

**伪分布式**
：也是在一台单机上运行，但用不同的 Java 进程模仿分布式运行中的各类节点，
**特点**
：Hadoop 启动的这些守护进程都在同一台机器上运行，是相互独立的 Java 进程。

**完全分布式：**
数据存储在HDFS，多台服务器工作，企业中大量使用

### scp命令

scp命令 ：可实现服务器与服务器之间的数据拷贝

-r 表示递归拷贝

$pdir/$fname ：要拷贝的文件路径 / 名称

$user@host:$pdir/$fname ：目的地用户@主机:目的地路径 / 名称

eg命令：scp -r /opt/module/jdk1.8.0\_212/ root@hadoop102:/opt/module/jdk1.8.0\_212/

### rsync命令

rsync 主要用于备份和镜像

rsync和scp的区别是rsync只对差异文件做更新，而scp是把所有文件都复制过去。故rsync效率更高

-a ：归档拷贝，尽可能让拷贝的

-v ：显示拷贝过程

$pdir/$fname ：要拷贝的文件路径 / 名称

命令：rsync -av /opt/conf/1.txt root@roothadoop102:/opt/conf/

#### ****xsync**** ****脚本**** ****集群**** ****之间的同步****

（1）在/root/bin目录下创建xsync文件。

（2）在该文件中编写如下代码。这个部分的代码不需要会写，能看懂，了解即可。

```
#!/bin/bash
#1. 判断参数个数
if [ $# -lt 1 ]
then
    echo Not Enough Arguement!
    exit;
fi
#2. 遍历集群所有机器
for host in hadoop100 hadoop101 hadoop102
do
    echo ====================  $host  ====================
    #3. 遍历所有目录，挨个发送
    for file in $@
    do
        #4. 判断文件是否存在
        if [ -e $file ]
            then
                #5. 获取父目录
                pdir=$(cd -P $(dirname $file); pwd)
                #6. 获取当前文件的名称
                fname=$(basename $file)
                ssh $host "mkdir -p $pdir"
                rsync -av $pdir/$fname $host:$pdir
            else
                echo $file does not exists!
        fi
    done
done
```

（3）修改执行权限。此时，我们去查看文件，可以看到它的颜色是灰色的，不具备执行权限（如下图）。

![](https://i-blog.csdnimg.cn/direct/e650fdd76b6948c59f0ee956537bf80a.png)

接下来要通过命令： chmod +x xsync（或者是chmod 777 xsync）

重新查看它的颜色，绿色即可执行，它现在已经变成执行的脚本了（如上右图）。

![](https://i-blog.csdnimg.cn/direct/2703bd5487b24b3a967dcb308ad66ea7.png)

（4）测试使用。把这个脚本同步到其他的机器中。

[

root@hadoop100 ~]$ xsync /root/bin/

### ssh命令

ssh命令无需密码也可登录

eg：目标：hadoop100通过ssh访问hadoop101,hadoop102时不需要密码，其他两台设备也类似。

具体操作如下：

1.在hadoop100中生成公钥和密码。ssh-keygen -t rsa 三次回车

2.在hadoop100中，把自己的公钥传递给hadoop101,hadoop102。命令如下

ssh-copy-id hadoop101

ssh-copy-id hadoop102

hadoop101 无密登录 hadoop100,hadoop102 与(1)类似

hadoop102 无密登录 hadoop100,hadoop101 与(1)类似

eg：从hadoop100进入hadoop101的命令就是

ssh root@hadoop102

退出命令就是：
exit

![](https://i-blog.csdnimg.cn/direct/8301477567f94e169a4c1cfc9e3c7c90.png)