---
layout: post
title: "XGBoost模型调参GridSearchCV方法网格搜索优化参数"
date: 2022-12-31 12:23:31 +0800
description: "GridSearchCV是XGBoost模型最常用的调参方法。本文主要介绍了如何使用GridSear"
keywords: "xgboost网格搜索"
categories: ['机器学习']
tags: ['模型优化', '机器学习', '参数调优', 'Xgboost', 'Gridsearchcv']
artid: "128503855"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=128503855
    alt: "XGBoost模型调参GridSearchCV方法网格搜索优化参数"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=128503855
featuredImagePreview: https://bing.ee123.net/img/rand?artid=128503855
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     XGBoost模型调参：GridSearchCV方法网格搜索优化参数
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
    </p>
    <div class="toc">
     <h4>
      文章目录
     </h4>
     <ul>
      <li>
       <a href="#_1" rel="nofollow">
        一、前言
       </a>
      </li>
      <li>
       <a href="#_3" rel="nofollow">
        二、数据处理
       </a>
      </li>
      <li>
       <a href="#XGBoost_27" rel="nofollow">
        三、XGBoost参数调优
       </a>
      </li>
      <li>
       <ul>
        <li>
         <a href="#31__28" rel="nofollow">
          3.1 常见可调参数
         </a>
        </li>
        <li>
         <a href="#32_GridSearchCV_61" rel="nofollow">
          3.2 GridSearchCV调参函数
         </a>
        </li>
        <li>
         <a href="#33__73" rel="nofollow">
          3.3 一般调参顺序
         </a>
        </li>
        <li>
         <a href="#34__103" rel="nofollow">
          3.4 调参结果可视化
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a href="#_121" rel="nofollow">
        四、总结
       </a>
      </li>
     </ul>
    </div>
    <p>
    </p>
    <h2>
     <a id="_1">
     </a>
     一、前言
    </h2>
    <p>
     本篇文章是继上一篇文章：
     <a href="https://blog.csdn.net/qq_44949041/article/details/128500239">
      使用K-Fold训练和预测XGBoost模型的方法
     </a>
     ，探讨对XGBoost模型调优的方法，所使用的代码和数据文件均是基于上一篇文章的，需要的小伙伴可以跳转链接自行获取。
    </p>
    <h2>
     <a id="_3">
     </a>
     二、数据处理
    </h2>
    <p>
     程序和上篇文章中的完全一致，不再赘述。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> xgboost <span class="token keyword">import</span> XGBRegressor

feature_file <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"./DataHousePricePrediction/train.csv"</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment"># 特征数据</span>
y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment"># 标签</span>
<span class="token keyword">for</span> index <span class="token keyword">in</span> feature_file<span class="token punctuation">.</span>index<span class="token punctuation">.</span>values<span class="token punctuation">:</span>
    <span class="token comment">#print('index', index)</span>
    <span class="token comment">#print(feature_file.values[0])</span>
    <span class="token comment">#print(feature_file.ix[index].values) </span>
    x<span class="token punctuation">.</span>append<span class="token punctuation">(</span>feature_file<span class="token punctuation">.</span>values<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 从原文件中提取输入变量数据</span>
    y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>feature_file<span class="token punctuation">.</span>values<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     <span class="token comment"># 从原文件中提取输出变量标签</span>
   
x<span class="token punctuation">,</span> y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
<span class="token comment"># 划分训练集和验证集</span>
X_train<span class="token punctuation">,</span>X_valid<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_valid <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">12345</span><span class="token punctuation">)</span>
</code></pre>
    <h2>
     <a id="XGBoost_27">
     </a>
     三、XGBoost参数调优
    </h2>
    <h3>
     <a id="31__28">
     </a>
     3.1 常见可调参数
    </h3>
    <p>
     一般调参会考虑以下几个超参数(需要在模型中初始化)：
    </p>
    <blockquote>
     <p>
      • learning_rate
      <br/>
      • n_estimators
      <br/>
      • max_depth
      <br/>
      • min_child_weight
      <br/>
      • subsample
      <br/>
      • colsample_bytree
      <br/>
      • gamma
      <br/>
      • reg_alpha
      <br/>
      • reg_lambda
     </p>
    </blockquote>
    <p>
     这些参数的具体含义可见：
     <a href="https://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters" rel="nofollow">
      XGBoost常用参数
     </a>
     <br/>
     定义模型：
    </p>
    <pre><code class="prism language-python"><span class="token comment">#定义xgboost模型</span>
xgb <span class="token operator">=</span> XGBRegressor<span class="token punctuation">(</span>learning_rate <span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
                   n_estimators<span class="token operator">=</span><span class="token number">150</span><span class="token punctuation">,</span> 
                   max_depth<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
                   min_child_weight<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                   gamma<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
                   subsample<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span>
                   colsample_bytree<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span>
                   objective<span class="token operator">=</span> <span class="token string">'reg:squarederror'</span><span class="token punctuation">,</span>
                   reg_alpha<span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>
                   reg_lambda<span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
                   nthread<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>
                   scale_pos_weight<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                   seed<span class="token operator">=</span><span class="token number">27</span><span class="token punctuation">)</span>

</code></pre>
    <h3>
     <a id="32_GridSearchCV_61">
     </a>
     3.2 GridSearchCV调参函数
    </h3>
    <p>
     不同于CV领域的神经网络，Scikit-learn为XGBoost模型提供了一个网格搜索最优化参数的方法：GridSearchCV(网格搜索交叉验证调参)。详细介绍见：
     <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" rel="nofollow">
      sklearn.model_selection.GridSearchCV
     </a>
    </p>
    <p>
     在本文中，主要使用到了GridSearchCV中的以下几个参数：
    </p>
    <blockquote>
     <ul>
      <li>
       estimator：表示所要调优的模型。
      </li>
      <li>
       param_grid：字典类型变量。主要存储的是要尝试的参数，每一个参数中要尝试的值组成一个列表，不同的参数列表构成一个字典。
      </li>
      <li>
       n_jobs，int类型，表示要并行运行的作业数，-1表示使用所有的处理器。通过此参数可以认为控制使用CPU的核数。
      </li>
      <li>
       cv，int类型，表示要交叉验证拆分的数量，也就是K-Fold的数量。
      </li>
     </ul>
    </blockquote>
    <p>
     <strong>
      GridSearchCV搜索原理
     </strong>
     ：对param_grid中要尝试的变量进行排列组合，遍历每一种组合，通过交叉验证的方式返回所有参数组合下的评价指标得分，最后选择分数最高的组合对应的参数作为最优值。简单来说，
     <font color="red">
      GridSearchCV的搜索原理就是枚举，暴力搜索
     </font>
     。
    </p>
    <h3>
     <a id="33__73">
     </a>
     3.3 一般调参顺序
    </h3>
    <p>
     <font color="red">
      调参的要旨是：每次调一个或两个超参数，然后将找到的最优超参数代入到模型中继续调余下的参数
     </font>
     。
     <br/>
     XGBoost一般的调参顺序和排列组合是：
    </p>
    <blockquote>
     <ol>
      <li>
       最佳迭代次数(树模型的个数)：n_estimators
      </li>
      <li>
       min_child_weight以及max_depth
      </li>
      <li>
       gamma
      </li>
      <li>
       subsample以及colsample_bytree
      </li>
      <li>
       reg_alpha以及reg_lambda
      </li>
      <li>
       learning_rate
      </li>
     </ol>
    </blockquote>
    <p>
     下面以min_child_weight以及max_depth两个参数为例展示对应的调参程序：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCV
<span class="token comment">#Need to research</span>
<span class="token comment">#research_one: n_epoch</span>
<span class="token comment">#research_one: max_depth</span>
param_test1 <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">'min_child_weight'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">'max_depth'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span>
    <span class="token punctuation">}</span>

xgb_res <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>estimator <span class="token operator">=</span> xgb<span class="token punctuation">,</span> 
                       param_grid <span class="token operator">=</span> param_test1<span class="token punctuation">,</span> 
                       n_jobs<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> 
                       cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>

xgb_res<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="34__103">
     </a>
     3.4 调参结果可视化
    </h3>
    <p>
     在搜索完成后，本文使用了
     <code>
      cv_results_、best_params_、best_score_
     </code>
     作为搜索输出，这三个方法都是
     <code>
      GridSearchCV
     </code>
     方法的对象，含义是：
    </p>
    <ul>
     <li>
      <code>
       cv_results_
      </code>
      :输出cv（交叉验证）结果的，可以是字典形式也可以是numpy形式，还可以转换成DataFrame格式
     </li>
     <li>
      <code>
       best_params_
      </code>
      ：通过网格搜索得到的score最好对应的参数
     </li>
     <li>
      <code>
       best_score_
      </code>
      ：输出最好的成绩
     </li>
    </ul>
    <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'max_depth_min_child_weight'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'gsearch1.grid_scores_'</span><span class="token punctuation">,</span> xgb_res<span class="token punctuation">.</span>cv_results_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'gsearch1.best_params_'</span><span class="token punctuation">,</span> xgb_res<span class="token punctuation">.</span>best_params_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'gsearch1.best_score_'</span><span class="token punctuation">,</span> xgb_res<span class="token punctuation">.</span>best_score_<span class="token punctuation">)</span>
</code></pre>
    <p>
     程序的输出为：
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/b1c1fb6c21e866166f2c6cd38cfa8d94.jpeg#pic_center">
      <br/>
      从输出的结果看出，GridSearchCV搜索确定了最佳的max_depth为3，最佳的min_child_weight为3，综合两种参数下模型的最佳得分为：0.65，获得了我们要的结果。
      <br/>
      注:这里没有展示
      <code>
       xgb_res.cv_results_
      </code>
      的输出结果（太长了），从上面的对
      <code>
       param_test1
      </code>
      的定义可知，此次搜索中min_child_weight有3中取值，max_depth有6种取值，进行排列组合后有18种可能。
      <code>
       cv_results_
      </code>
      展示的就是这18种情况对应的交叉验证值。
     </img>
    </p>
    <h2>
     <a id="_121">
     </a>
     四、总结
    </h2>
    <p>
     <code>
      GridSearchCV
     </code>
     是XGBoost模型最常用的调参方法，在调参时要注意调参顺序并且要有效设置参数的变化范围，提高效率。受限于暴力搜索的设计逻辑，
     <code>
      GridSearchCV
     </code>
     并不适用于数据量大和超参数数量多的场景。当数据量大时，可以考虑
     <font color="red">
      坐标下降
     </font>
     方法；当所调超参数数量多时，可以考虑使用
     <font color="red">
      随机搜索
      <code>
       RandomizedSearchCV
      </code>
     </font>
     方法。
     <br/>
     总的来说，
     <font color="red">
      有效的数据清洗和挖掘、符合使用场景的模型、灵活的训练和调参技巧
     </font>
     是提高预测准确度的三大手段。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34343934393034312f:61727469636c652f64657461696c732f313238353033383535" class_="artid" style="display:none">
 </p>
</div>


