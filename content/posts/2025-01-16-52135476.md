---
layout: post
title: "Android在MediaMuxer和MediaCodec录制视频示例-audiovideo"
date: 2025-01-16 22:36:13 +0800
description: "在Android多媒体类，MediaMuxer和MediaCodec这是一个相对年轻，他们是JB 4"
keywords: "mediacodec视频录制来源surface"
categories: ['Android']
tags: ['视频', 'Android']
artid: "52135476"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=52135476
    alt: "Android在MediaMuxer和MediaCodec录制视频示例-audiovideo"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=52135476
featuredImagePreview: https://bing.ee123.net/img/rand?artid=52135476
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Android在MediaMuxer和MediaCodec录制视频示例 - audio+video
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     <span style="color:rgb(63,63,63); font-size:14px; line-height:30px">
     </span>
    </p>
    <div>
    </div>
    <p>
    </p>
    <p style="color:rgb(51,51,51); font-family:Arial; font-size:14px; line-height:26px; margin-top:0px; margin-bottom:0px">
     <span style="font-size:24px; color:rgb(255,0,0)">
      <strong>
       博主QQ：1356438802
      </strong>
     </span>
    </p>
    <p style="color:rgb(51,51,51); font-family:Arial; font-size:14px; line-height:26px; margin-top:0px; margin-bottom:0px">
     <span style="font-size:24px; color:rgb(255,0,0)">
      <strong>
       QQ群：473383394——UVC&amp;
       <a class="replace_word" href="http://lib.csdn.net/base/opencv" rel="nofollow noopener noreferrer" style="color:rgb(223,52,52); text-decoration:none" target="_blank" title="OpenCV知识库">
        OpenCV
       </a>
       <span style="color:rgb(255,255,255); font-family:微软雅黑,Tahoma,宋体; font-size:14px; line-height:29px; widows:auto">
        47
       </span>
      </strong>
     </span>
    </p>
    <br/>
    <p>
     <span style="color:rgb(63,63,63); font-size:14px; line-height:30px">
      <br/>
     </span>
    </p>
    <p>
     <span style="color:rgb(63,63,63); font-size:14px; line-height:30px">
      在Android多媒体类，MediaMuxer和MediaCodec这是一个相对年轻，他们是JB 4.1和JB 4.3据介绍。
     </span>
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     前者被用来产生一个混合的音频和视频的多媒体文件。的缺点是，现在可以只支持一个audio track而一个video track，而唯一支持mp4出口。然是新生事物，相信之后的版本号应该会有大的改进。MediaCodec用于将音视频进行压缩编码，它有个比較牛X的地方是能够对Surface内容进行编码，如KK 4.4中屏幕录像功能就是用它实现的。
     <br style="padding:0px"/>
     <br style="padding:0px"/>
     注意它们和其他一些多媒体相关类的关系和差别：MediaExtractor用于音视频分路，和MediaMuxer正好是反过程。MediaFormat用于描写叙述多媒体数据的格式。MediaRecorder用于录像+压缩编码。生成编码好的文件如mp4, 3gpp，视频主要是用于录制Camera preview。MediaPlayer用于播放压缩编码后的音视频文件。
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     AudioRecord用于录制PCM数据。AudioTrack用于播放PCM数据。PCM即原始音频採样数据。能够用如vlc播放器播放。
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     当然了，通道採样率之类的要自己设。由于原始採样数据是没有文件头的，如：
     <br style="padding:0px"/>
     vlc --demux=rawaud --rawaud-channels 2 --rawaud-samplerate 44100 audio.pcm
     <br style="padding:0px"/>
     <br style="padding:0px"/>
     回到MediaMuxer和MediaCodec这两个类，它们的參考文档见http://developer.android.com/reference/android/media/MediaMuxer.html和http://developer.android.com/reference/android/media/MediaCodec.html。里边有使用的框架。这个组合能够实现非常多功能，比方音视频文件的编辑（结合MediaExtractor），用OpenGL绘制Surface并生成mp4文件，屏幕录像以及类似Camera app里的录像功能（尽管这个用MediaRecorder更合适）等。
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     <br style="padding:0px"/>
     <br style="padding:0px"/>
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     这里以一个非常无聊的功能为例，就是在一个Surface上绘图编码生成视频。同一时候用MIC录音编码生成音频，然后将音视频混合生成mp4文件。
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     程序本身没什么用。可是演示样例了MediaMuxer和MediaCodec的基本使用方法。本程序主要是基于两个測试程序：一个是Grafika中的SoftInputSurfaceActivity和HWEncoderExperiments。它们一个是生成视频，一个生成音频，这里把它们结合一下，同一时候生成音频和视频。基本框架和流程例如以下：
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     <img alt="技术分享" src="https://img-blog.csdn.net/20140619074822984" style="padding:0px; max-width:680px; overflow:hidden">
      <br style="padding:0px"/>
     </img>
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     首先是录音线程，主要參考HWEncoderExperiments。
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     通过AudioRecord类接收来自麦克风的採样数据，然后丢给Encoder准备编码：
     <br style="padding:0px"/>
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
    </p>
    <pre><code class="language-java">AudioRecord audio_recorder;
audio_recorder = new AudioRecord(MediaRecorder.AudioSource.MIC,       
        SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT, buffer_size);                        
// ...
audio_recorder.startRecording();
while (is_recording) {
    byte[] this_buffer = new byte[frame_buffer_size];
    read_result = audio_recorder.read(this_buffer, 0, frame_buffer_size); // read audio raw data
    // …
    presentationTimeStamp = System.nanoTime() / 1000;
    audioEncoder.offerAudioEncoder(this_buffer.clone(), presentationTimeStamp);  // feed to audio encoder

}</code></pre>
    <span style="color:rgb(63,63,63); font-size:14px; line-height:30px">
     这里也能够设置AudioRecord的回调（通过setRecordPositionUpdateListener()）来触发音频数据的读取。offerAudioEncoder()里主要是把audio採样数据送入音频MediaCodec的InputBuffer进行编码：
    </span>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
    </p>
    <pre><code class="language-java">ByteBuffer[] inputBuffers = mAudioEncoder.getInputBuffers();
int inputBufferIndex = mAudioEncoder.dequeueInputBuffer(-1); 
if (inputBufferIndex &gt;= 0) {
    ByteBuffer inputBuffer = inputBuffers[inputBufferIndex];
    inputBuffer.clear();
    inputBuffer.put(this_buffer);
    ...
    mAudioEncoder.queueInputBuffer(inputBufferIndex, 0, this_buffer.length, presentationTimeStamp, 0);
}</code></pre>
    <span style="color:rgb(63,63,63); font-size:14px; line-height:30px">
     以下，參考Grafika-SoftInputSurfaceActivity，并增加音频处理。
    </span>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     主循环大体分四部分：
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
    </p>
    <pre><code class="language-java">try {
    // Part 1
    prepareEncoder(outputFile);
    ...
    // Part 2
    for (int i = 0; i &lt; NUM_FRAMES; i++) {
        generateFrame(i);
        drainVideoEncoder(false);
        drainAudioEncoder(false);
    }
    // Part 3
    ...
    drainVideoEncoder(true);
    drainAudioEncoder(true);
}  catch (IOException ioe) {
    throw new RuntimeException(ioe);
} finally {
    // Part 4
    releaseEncoder();
}</code></pre>
    <span style="color:rgb(63,63,63); font-size:14px; line-height:30px">
     第1部分是准备工作。除了video的MediaCodec，这里还初始化了audio的MediaCodec：
    </span>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
    </p>
    <pre><code class="language-java">MediaFormat audioFormat = new MediaFormat();
audioFormat.setInteger(MediaFormat.KEY_SAMPLE_RATE, 44100);
audioFormat.setInteger(MediaFormat.KEY_CHANNEL_COUNT, 1);
...        
mAudioEncoder = MediaCodec.createEncoderByType(AUDIO_MIME_TYPE);
mAudioEncoder.configure(audioFormat, null, null, MediaCodec.CONFIGURE_FLAG_ENCODE);
mAudioEncoder.start();</code></pre>
    <span style="color:rgb(63,63,63); font-size:14px; line-height:30px">
     第2部分进入主循环，app在Surface上直接画图，因为这个Surface是从MediaCodec中用createInputSurface()申请来的，所以画完后不用显式用queueInputBuffer()交给Encoder。
    </span>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     drainVideoEncoder()和drainAudioEncoder()分别将编码好的音视频从buffer中拿出来（通过dequeueOutputBuffer()），然后交由MediaMuxer进行混合（通过writeSampleData()）。
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     注意音视频通过PTS（Presentation time stamp。决定了某一帧的音视频数据何时显示或播放）来同步，音频的time stamp需在AudioRecord从MIC採集到数据时获取并放到对应的bufferInfo中，视频因为是在Surface上画，因此直接用dequeueOutputBuffer()出来的bufferInfo中的即可，最后将编码好的数据送去MediaMuxer进行多路混合。
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     <br style="padding:0px"/>
     <br style="padding:0px"/>
     注意这里Muxer要等把audio track和video track都增加了再開始。
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     MediaCodec在一開始调用dequeueOutputBuffer()时会返回一次INFO_OUTPUT_FORMAT_CHANGED消息。
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     我们仅仅需在这里获取该MediaCodec的format，并注冊到MediaMuxer里。
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     接着推断当前audio track和video track是否都已就绪，假设是的话就启动Muxer。
     <br style="padding:0px"/>
     <br style="padding:0px"/>
     总结来说，drainVideoEncoder()的主逻辑大致例如以下，drainAudioEncoder也是类似的。仅仅是把video的MediaCodec换成audio的MediaCodec就可以。
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     <br style="padding:0px"/>
    </p>
    <pre><code class="language-java">while(true) {
    int encoderStatus = mVideoEncoder.dequeueOutputBuffer(mBufferInfo, TIMEOUT_USEC);
    if (encoderStatus == MediaCodec.INFO_TRY_AGAIN_LATER) {
        ...
    } else if (encoderStatus == MediaCodec.INFO_OUTPUT_BUFFERS_CHANGED) {
        encoderOutputBuffers = mVideoEncoder.getOutputBuffers();
    } else if (encoderStatus == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) {
        MediaFormat newFormat = mAudioEncoder.getOutputFormat();
        mAudioTrackIndex = mMuxer.addTrack(newFormat);
        mNumTracksAdded++;
        if (mNumTracksAdded == TOTAL_NUM_TRACKS) {
            mMuxer.start();
        }
    } else if (encoderStatus &lt; 0) {
        ...
    } else {
        ByteBuffer encodedData = encoderOutputBuffers[encoderStatus];
        ...
        if (mBufferInfo.size != 0) {
            mMuxer.writeSampleData(mVideoTrackIndex, encodedData, mBufferInfo);
        }
        mVideoEncoder.releaseOutputBuffer(encoderStatus, false);
        if ((mBufferInfo.flags &amp; MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0) {
            break;        
        }
    }

}</code></pre>
    <span style="color:rgb(63,63,63); font-size:14px; line-height:30px">
     第3部分是结束录制。发送EOS信息。这样在drainVideoEncoder()和drainAudioEncoder中就能够依据EOS退出内循环。
    </span>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     第4部分为清理工作。
    </p>
    <p style="padding-top:0px; padding-bottom:0px; font-size:14px; color:rgb(63,63,63); line-height:30px">
     把audio和video的MediaCodec，MediaCodec用的Surface及MediaMuxer对象释放。
     <br style="padding:0px"/>
     <br style="padding:0px"/>
     最后几点注意：
     <br style="padding:0px"/>
     <span style="padding:0px; white-space:pre">
     </span>
     1. 在AndroidManifest.xml里加上录音权限，否则创建AudioRecord对象时铁定失败：
     <br style="padding:0px"/>
     &lt;uses-permission android:name="android.permission.RECORD_AUDIO"/&gt;
     <br style="padding:0px"/>
     <span style="padding:0px; white-space:pre">
     </span>
     2. 音视频通过PTS同步，两个的单位要一致。
     <br style="padding:0px"/>
     <span style="padding:0px; white-space:pre">
     </span>
     3. MediaMuxer的使用要依照Constructor -&gt; addTrack -&gt; start -&gt; writeSampleData -&gt; stop 的顺序。假设既有音频又有视频，在stop前两个都要writeSampleData()过。
     <br style="padding:0px"/>
     <br style="padding:0px"/>
     Code references：
     <br style="padding:0px"/>
     Grafika: https://github.com/google/grafika
     <br style="padding:0px"/>
     Bigflake: http://bigflake.com/mediacodec/
     <br style="padding:0px"/>
     HWEncoderExperiments：https://github.com/OnlyInAmerica/HWEncoderExperiments/tree/audioonly/HWEncoderExperiments/src/main/java/net/openwatch/hwencoderexperiments
     <br style="padding:0px"/>
     Android test：http://androidxref.com/4.4.2_r2/xref/cts/tests/tests/media/src/android/media/cts/
     <br style="padding:0px"/>
     http://androidxref.com/4.4.2_r2/xref/pdk/apps/TestingCamera2/src/com/android/testingcamera2/CameraRecordingStream.java
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f6c756f796f7572656e:2f61727469636c652f64657461696c732f3532313335343736" class_="artid" style="display:none">
 </p>
</div>


