---
layout: post
title: "蛋白质功能预测论文阅读记录2025DPFuncProtCLIP"
date: 2025-03-12 19:21:50 +0800
description: "目前更新了蛋白质功能预测论文DPFunc、ProtCLIP，后续会继续更新相关论文"
keywords: "蛋白质功能预测论文阅读记录2025（DPFunc、ProtCLIP）"
categories: ['生物信息学', '机器学习', '总结']
tags: ['论文阅读']
artid: "146164632"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146164632
    alt: "蛋白质功能预测论文阅读记录2025DPFuncProtCLIP"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146164632
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146164632
cover: https://bing.ee123.net/img/rand?artid=146164632
image: https://bing.ee123.net/img/rand?artid=146164632
img: https://bing.ee123.net/img/rand?artid=146164632
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     蛋白质功能预测论文阅读记录2025（DPFunc、ProtCLIP）
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     前言
    </h2>
    <p>
     最近研究到瓶颈了，怎么优化都提升不了，遂开始看点最新的论文。
    </p>
    <h2>
     DPFunc
    </h2>
    <p>
     2025.1.2 Nature Communication 中南大学
    </p>
    <p>
     论文地址：
     <a href="https://www.nature.com/articles/s41467-024-54816-8" rel="nofollow" title="DPFunc: accurately predicting protein function via deep learning with domain-guided structure information | Nature Communications">
      DPFunc: accurately predicting protein function via deep learning with domain-guided structure information | Nature Communications
     </a>
    </p>
    <p>
     github仓库：
     <a href="https://github.com/CSUBioGroup/DPFunc" title="CSUBioGroup/DPFunc">
      CSUBioGroup/DPFunc
     </a>
    </p>
    <p>
     数据集：PDB（被认为test与train的序列相似度较高，在review中被指出）、CAFA3（在论文中说的是large_scale dataset）
    </p>
    <p>
     使用蛋白质序列、结构、结构域数据
    </p>
    <p>
     模型结构：
    </p>
    <p>
     <img alt="" height="489" src="https://i-blog.csdnimg.cn/direct/ee3ef420bcfe48e7b56f97b1fc61919f.png" width="562"/>
    </p>
    <p>
     非常清晰的模型结构，序列特征用的ESM-1b，结构特征提取用的GCN，结构域用的Embedding，最后使用MLP分类
    </p>
    <p>
     建图依然是接触图
    </p>
    <p>
     融合的交叉注意力是值得关注的地方，这里用的domain作为Q，序列+结构作为K、V，主观感觉十分合理
    </p>
    <p>
     另一个值得关注的地方是关键残基的预测算法：（论文中还有几个蛋白质的实例分析，非常细节）
    </p>
    <p>
     <img alt="" height="432" src="https://i-blog.csdnimg.cn/direct/559c690eed55465c80b22b1638e946f3.png" width="682"/>
    </p>
    <p>
     简单来说就是，先按照每个残基位置的注意力得分进行排序，然后根据下图的方法选择。
    </p>
    <p>
     <img alt="" height="303" src="https://i-blog.csdnimg.cn/direct/8515b9b6e01b4be98050ffabded33b36.png" width="438"/>
    </p>
    <p>
     结果：
    </p>
    <p>
     PDB数据集：（虽然总标签数少，但结果也相当不错了）
    </p>
    <p>
     <img alt="" height="241" src="https://i-blog.csdnimg.cn/direct/4938939bd48e4b688ec69e17a0ff5c80.png" width="466"/>
    </p>
    <p>
     <img alt="" height="88" src="https://i-blog.csdnimg.cn/direct/8d53656a492a4e5cad312acb83b93ff3.png" width="420"/>
    </p>
    <p>
     CAFA3数据集：（结果有所下降，毕竟标签数有28000+个）
    </p>
    <p>
     <img alt="" height="1118" src="https://i-blog.csdnimg.cn/direct/c8825f41f696487587532b351802136e.png" width="1366"/>
    </p>
    <p>
    </p>
    <h2>
     ProtCLIP
    </h2>
    <p>
     2024.12.28 还在arxiv上AAAI  浙江大学
    </p>
    <p>
     论文地址：
     <a href="https://arxiv.org/abs/2412.20014" rel="nofollow" title="[2412.20014] ProtCLIP: Function-Informed Protein Multi-Modal Learning">
      [2412.20014] ProtCLIP: Function-Informed Protein Multi-Modal Learning
     </a>
    </p>
    <p>
     github仓库：
     <a href="https://github.com/diaoshaoyou/ProtCLIP" title="diaoshaoyou/ProtCLIP">
      diaoshaoyou/ProtCLIP
     </a>
    </p>
    <p>
     该模型是利用蛋白质序列和蛋白质相关的描述文本进行对比学习预训练，然后再做下游任务预测，在22个下游任务中都取得了sota，相当nb
    </p>
    <p>
     <img alt="" height="486" src="https://i-blog.csdnimg.cn/direct/a22a833c6e60439b8a438fdbb7f7518a.png" width="2021"/>
    </p>
    <p>
     使用的数据是自己整理的两个数据集，ProtAnno-S和ProtAnno-D。
    </p>
    <p>
     其中S数据集是量比较少，数据置信度高，D数据集是数据密集，但置信度稍低于S
    </p>
    <p>
     模型结构：
    </p>
    <p>
     <img alt="" height="612" src="https://i-blog.csdnimg.cn/direct/b212a97bfd294a6495f5c8b7a7b37de1.png" width="1890"/>
    </p>
    <p>
     序列特征提取用的ESM2-650M，蛋白质文本描述特征提取使用的PubMed-BERT
    </p>
    <p>
     论文中定义了一个蛋白质簇u的Property属性P，C表示置信度、R表示覆盖率（文中的这个覆盖率定义还不是很清晰，看起来就是某个簇在总集中的占比吧）、N表示簇的大小
    </p>
    <p>
     <img alt="" height="70" src="https://i-blog.csdnimg.cn/direct/80112c1aea274bbfb29260edf162d5d0.png" width="248"/>
    </p>
    <p>
     在选取训练数据时，根据这个P值作为概率分布来进行数据采样
    </p>
    <p>
     预训练有四个任务loss，GC、MLM、PDA和BSR
    </p>
    <p>
     GC就是普通的CLIP对比学习损失，MLM就是对文本mask重建的损失。
    </p>
    <h3>
     PDA（Property-Grouped Dynamic Segment Alignment）
    </h3>
    <p>
     直译就是根据文本属性（比如蛋白质名、功能、用途之类的描述）分组，然后动态区间对齐。按照论文的意思，就是蛋白质的每个氨基酸和文本中的原型（大概就是聚类的文本含义）求相似度，过一个阈值，把每个原型对应的相似度和蛋白质氨基酸求点积，得到每个原型的得分，最后再来对齐。
    </p>
    <p>
     大致公式如下：（其实和对比学习损失差不多）
    </p>
    <p>
     <img alt="" height="141" src="https://i-blog.csdnimg.cn/direct/75ec3a82132a4767b68173cf98cb47e1.png" width="566"/>
    </p>
    <p>
     <img alt="" height="88" src="https://i-blog.csdnimg.cn/direct/6db08860f7784354adfdd05d260e1e42.png" width="853"/>
    </p>
    <p>
     这里的公式似乎有些问题，不是求集合，而是求点积（按照示例图的含义）
    </p>
    <h3>
     BSR（Biotext-guided Static Segment Reconstruction）
    </h3>
    <p>
     直译就是基于生物文本引导的静态区间重建
    </p>
    <p>
     它首先在蛋白质序列上进行区间采样，每次选一个长度为L（在5~10之间均匀分布）的区间（与之前的区间不重叠），直到采样区间总长度达到蛋白质序列总长度的15%。
    </p>
    <p>
     然后把这些采样的区间mask之后，用生物文本的特征来重建这些区间，使用的交叉注意力+MLP+GELU，最后重建结果用以下的损失函数：
    </p>
    <p>
     <img alt="" height="116" src="https://i-blog.csdnimg.cn/direct/0a1dc33c64f04887a3849420042613d2.png" width="553"/>
    </p>
    <p>
     其实就是对每个mask位置的预测做一个交叉熵损失，求一个平均值。
    </p>
    <h3>
     下游任务表现
    </h3>
    <p>
     各个下游任务的模型结构：
    </p>
    <p>
     <img alt="" height="796" src="https://i-blog.csdnimg.cn/direct/006de7240afb47809869c38cd8692a62.png" width="1835"/>
    </p>
    <h4>
     蛋白质功能预测
    </h4>
    <p>
     <img alt="" height="386" src="https://i-blog.csdnimg.cn/direct/75b263430531477e9b30ffd67798d5fb.png" width="565"/>
    </p>
    <p>
     相当恐怖的结果，在BP上能够达到0.567的AUPR，但在CC上却没有特别高，之前的论文在CC的Fmax一般都能上0.6（例如Domain-PFP），可能是下游模型比较简单，所以结果并不高。
    </p>
    <p>
     另外一个值得注意的点，论文并没有明确指出使用的GO数据集，因为其本身的训练数据也很大，不好说是否训练集是否包含测试信息。
    </p>
    <p>
     前SOTA ProtST论文地址
     <a href="https://arxiv.org/pdf/2301.12040" rel="nofollow" title="2301.12040">
      2301.12040
     </a>
     ，用的方法和数据也是和这篇论文类似的，具有可比性。
    </p>
    <h4>
     突变效应预测
    </h4>
    <p>
     既然都看了这么多了，就不拘泥于蛋白质功能预测这一个任务指标，看看其他任务的表现
    </p>
    <p>
     突变效应预测属于回归任务，使用的数据集是two vs many和human（与FLIP论文相同）
    </p>
    <p>
     使用的是5个landscape的Spearman相关系数来衡量预测结果，分别是：
    </p>
    <p>
     β-lactamase酶相关的特性、腺病毒相关特性、热力学特性、荧光性、稳定性
    </p>
    <p>
     根据图例，应该是找一个位点，突变成不同的氨基酸，然后预测各个突变的fitness值
    </p>
    <p>
     不过确实没看懂这个预测的是什么东西，怎么来的数据，论文也没细讲（我也没怎么了解过，之后多看点这方面的论文吧）
    </p>
    <p>
     <img alt="" height="807" src="https://i-blog.csdnimg.cn/direct/2571ee9aad3543ba963de129590c89da.png" width="944"/>
    </p>
    <h4>
     跨模态转移
    </h4>
    <p>
     这个就相对好懂一些，也是比较类似对比学习的相似性计算，不过这个衡量标准是MRR（推荐系统的常用指标）（这个图的match就是MRR的计算）。
    </p>
    <p>
     <img alt="" height="258" src="https://i-blog.csdnimg.cn/direct/9604e18357df42c6a65855bf7d3be238.png" width="215"/>
     <img alt="" height="253" src="https://i-blog.csdnimg.cn/direct/43f996a1d3c84436a21d9cf6e2f01edb.png" width="332"/>
     （右图来自poe）
    </p>
    <p>
     <img alt="" height="164" src="https://i-blog.csdnimg.cn/direct/2f2cf72a3b7f4589bd62e229a964d6f7.png" width="429"/>
    </p>
    <h4>
     语义相似性预测
    </h4>
    <p>
     这个是检测biotext-encoder性能的实验
    </p>
    <p>
     通过biotext-encoder对GO标签计算embedding，然后计算他们之间的曼哈顿距离
    </p>
    <p>
     然后和GO标签之间的林相似度作比较，计算spearman系数（
     <strong>
      没想到之前IC值计算里面的困惑居然在这里解决了
     </strong>
     ）
    </p>
    <p>
     <img alt="" height="418" src="https://i-blog.csdnimg.cn/direct/ff425cbfdbc743d3800facd867616e60.png" width="507"/>
     （图来自poe）
    </p>
    <p>
     由于出现了太多次spearman系数，还是复习一下：
    </p>
    <p>
     <img alt="" height="466" src="https://i-blog.csdnimg.cn/direct/13d6b4f624fe4066835460255a8e3b67.png" width="518"/>
     （图来自poe）
    </p>
    <p>
     在这里是用来计算预测值和ground truth值的相关性的
    </p>
    <p>
     计算两个相似度矩阵的spearman相关系数流程其实也是一样的，求得每个矩阵位置的预测值、真实值各自的大小排名，然后把每个位置的排名差值平方加起来，最后归一化。
    </p>
    <p>
     至于归一化系数为什么是6/(n(n^2-1))
    </p>
    <p>
     考虑最坏情况，两个序列完全相反，1~n对应n~1，Σdi^2则是Σ(i-(n-i+1))^2   (i -&gt; 1~n)
    </p>
    <p>
     =Σ(n-2i+1)^2
    </p>
    <p>
     =2n(n+1)(2n+1)/3​−(n^3+2n^2+n)  （这里跳过了一大堆运算化简）
    </p>
    <p>
     =(4n^3+6n^2+2n-3n^3-6n^2-3n)/3 = (n^3-n)/3 = n*(n^2-1)/3
    </p>
    <p>
     Σdi^2最大取值就是上述式子，所以为了把spearman系数转换到[-1,1]区间中，我们用公式1-6/(n(n^2-1))*Σdi^2进行了归一化和转换，1表示正相关性，-1表示负相关性
    </p>
    <p>
     <img alt="" height="161" src="https://i-blog.csdnimg.cn/direct/52a943f0f0744e5f897610b50c441163.png" width="423"/>
    </p>
    <h4>
     PPI预测
    </h4>
    <p>
     这个就是连接预测任务了，没什么好说的
    </p>
    <p>
     用的数据集是SHS27K、SHS148K、STRING，其实提升并不大
    </p>
    <h3>
     消融实验
    </h3>
    <p>
     这里的下游指标就只用了EC标签分类和Prot2MF模态跨转移
    </p>
    <p>
     消融的目标是预训练数据集和预训练任务，可以看到PDA任务影响很大，ProtAnno-S（高质量数据集）的影响也较大。
    </p>
    <p>
     <img alt="" height="378" src="https://i-blog.csdnimg.cn/direct/42d17ce6ea0b4dd2ad364cf2a0082f20.png" width="477"/>
    </p>
    <p>
     有点奇怪的是这里的EC分类效果比前面对比实验的效果低了许多
    </p>
    <p>
     最后还对loss权重进行了消融，没想到loss权重对训练效果的影响这么大
    </p>
    <p>
     <img alt="" height="223" src="https://i-blog.csdnimg.cn/direct/6b0bebd249c243d7a5d5812e77cdc9cc.png" width="471"/>
    </p>
    <p>
     <img alt="" height="246" src="https://i-blog.csdnimg.cn/direct/83efea2877d84c879e0cebd097d3bf63.png" width="446"/>
    </p>
    <h3>
     个人总结
    </h3>
    <p>
     这篇论文确实很好，可惜代码还没有开源，只有一个空仓库
    </p>
    <p>
     用protein-biotext的预训练完成了下游任务的各项提升，尤其对类别众多的bp标签分类任务提升很大，已经跳出了用蛋白质本身信息端到端地预测蛋白质功能的传统方法。
    </p>
    <p>
     除此之外，各种预训练的任务设计也很巧妙（或许这些方法在多模态学习领域已经见怪不怪了，但是对于我这种只在一个领域研究的来说，确实开拓了我的视野。只能说，
     <strong>
      不要闭门造车，还得多读、多看、多实践
     </strong>
     ）
    </p>
    <p>
     缺点就是，64张V100跑了10000个GPU小时，可能很少有实验室有复现的算力资源，而且如此繁杂的数据搜集整理以及下游任务，感觉一个人很难完成吧，应该是一个团队合力做出来的项目。
    </p>
    <p>
     另外使用的下游蛋白质功能预测的数据集还不知道具体情况，等出了代码看看能不能对比。
    </p>
    <p>
     <s>
      本来说简写一点，结果快写成ProtCLIP的专门介绍了
     </s>
    </p>
    <p>
    </p>
    <p>
     后续有空会继续更新
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f4332303138303630325f6373712f:61727469636c652f64657461696c732f313436313634363332" class_="artid" style="display:none">
 </p>
</div>


