---
layout: post
title: "Docker-运行-GPUStack-的详细教程"
date: 2025-03-09 21:23:54 +0800
description: "CUDA（Compute Unified Device Architecture）是 NVIDIA 提供的一个并行计算平台和编程模型，它使开发者可以使用 NVIDIA GPU 进行高性能计算。通过本指南，您可以在支持 NVIDIA GPU 的 Linux 环境中快速部署 GPUStack，并实现异构 GPU 集群的管理与大模型服务。页面，支持从 Hugging Face 或本地导入模型。通过以上步骤，您可快速搭建一个支持异构 GPU 资源调度的企业级大模型服务平台，实现从单机到集群的高效扩展。"
keywords: "Docker 运行 GPUStack 的详细教程"
categories: ['Deepseek']
tags: ['运维', '容器', 'Docker']
artid: "146139022"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146139022
    alt: "Docker-运行-GPUStack-的详细教程"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146139022
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146139022
cover: https://bing.ee123.net/img/rand?artid=146139022
image: https://bing.ee123.net/img/rand?artid=146139022
img: https://bing.ee123.net/img/rand?artid=146139022
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Docker 运行 GPUStack 的详细教程
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="GPUStack_0">
     </a>
     GPUStack
    </h3>
    <p>
     GPUStack 是一个用于运行 AI 模型的开源 GPU 集群管理器。它具有广泛的硬件兼容性，支持多种品牌的 GPU，并能在 Apple MacBook、Windows PC 和 Linux 服务器上运行。GPUStack 支持各种 AI 模型，包括大型语言模型（LLMs）、扩散模型、音频模型、嵌入模型和重新排序模型。GPUStack 可以轻松扩展，只需添加更多 GPU 或节点即可扩展操作。它支持单节点多 GPU 和多节点推理和服务，并提供多种推理后端，如
     <code>
      llama-box
     </code>
     、
     <code>
      vox-box
     </code>
     和
     <code>
      vLLM
     </code>
     。GPUStack 是一个轻量级的 Python 包，具有最小的依赖项和操作开销，并且提供与 OpenAI 标准兼容的 API。此外，它还简化了用户和 API 密钥的管理，提供了 GPU 性能和利用率的实时监控，以及令牌使用和速率限制的有效跟踪。
    </p>
    <h4>
     <a id="_4">
     </a>
     关键特性
    </h4>
    <ul>
     <li>
      <strong>
       广泛的硬件兼容性
      </strong>
      ：支持管理 Apple Mac、Windows PC 和 Linux 服务器上不同品牌的 GPU。
     </li>
     <li>
      <strong>
       广泛的模型支持
      </strong>
      ：支持从大语言模型（LLMs）、多模态模型（VLMs）、扩散模型、语音模型到嵌入和重新排序模型的广泛模型。
     </li>
     <li>
      <strong>
       异构 GPU 支持与扩展
      </strong>
      ：能够轻松添加异构 GPU 资源，并按需扩展算力规模。
     </li>
     <li>
      <strong>
       分布式推理
      </strong>
      ：支持单机多卡并行和多机多卡并行推理。
     </li>
     <li>
      <strong>
       多推理后端支持
      </strong>
      ：支持
      <code>
       llama-box
      </code>
      （基于 llama.cpp 和 stable-diffusion.cpp）、
      <code>
       vox-box
      </code>
      和
      <code>
       vLLM
      </code>
      作为推理后端。
     </li>
     <li>
      <strong>
       轻量级 Python 包
      </strong>
      ：最小的依赖和操作开销。
     </li>
     <li>
      <strong>
       OpenAI 兼容 API
      </strong>
      ：提供兼容 OpenAI 标准的 API 服务。
     </li>
     <li>
      <strong>
       用户和 API 密钥管理
      </strong>
      ：简化用户和 API 密钥的管理流程。
     </li>
     <li>
      <strong>
       GPU 指标监控
      </strong>
      ：实时监控 GPU 性能和利用率。
     </li>
     <li>
      <strong>
       Token 使用和速率统计
      </strong>
      ：有效跟踪 token 使用情况，并管理速率限制。
     </li>
    </ul>
    <h4>
     <a id="_17">
     </a>
     支持的硬件平台
    </h4>
    <ul>
     <li>
      <strong>
       Apple Metal
      </strong>
      （M 系列芯片）
     </li>
     <li>
      <strong>
       NVIDIA CUDA
      </strong>
      （计算能力 6.0 及以上）
     </li>
     <li>
      <strong>
       AMD ROCm
      </strong>
     </li>
     <li>
      <strong>
       华为昇腾
      </strong>
      （CANN）
     </li>
     <li>
      <strong>
       摩尔线程
      </strong>
      （MUSA）
     </li>
     <li>
      <strong>
       海光 DTK
      </strong>
     </li>
    </ul>
    <h4>
     <a id="_26">
     </a>
     支持的模型类型
    </h4>
    <ul>
     <li>
      <strong>
       大语言模型（LLMs）
      </strong>
      ：如 Qwen、LLaMA、Mistral、Deepseek、Phi、Yi 等。
     </li>
     <li>
      <strong>
       多模态模型（VLMs）
      </strong>
      ：如 Llama3.2-Vision、Pixtral、Qwen2-VL、LLaVA、InternVL2.5 等。
     </li>
     <li>
      <strong>
       扩散模型
      </strong>
      ：如 Stable Diffusion、FLUX 等。
     </li>
     <li>
      <strong>
       嵌入模型
      </strong>
      ：如 BGE、BCE、Jina 等。
     </li>
     <li>
      <strong>
       重新排序模型
      </strong>
      ：如 BGE、BCE、Jina 等。
     </li>
     <li>
      <strong>
       语音模型
      </strong>
      ：如 Whisper（语音转文本）、CosyVoice（文本转语音）等。
     </li>
    </ul>
    <h4>
     <a id="_35">
     </a>
     使用场景
    </h4>
    <p>
     GPUStack 适用于需要高效管理和调度 GPU 资源的场景，特别是在运行 AI 模型时。它支持单节点多 GPU 和多节点推理及服务，并提供多种推理后端，如
     <code>
      llama-box
     </code>
     、
     <code>
      vox-box
     </code>
     和
     <code>
      vLLM
     </code>
     。GPUStack 是一个轻量级的 Python 包，具有最小的依赖项和操作开销，并且提供与 OpenAI 标准兼容的 API。此外，它还简化了用户和 API 密钥的管理，提供了 GPU 性能和利用率的实时监控，以及令牌使用和速率限制的有效跟踪。
    </p>
    <h3>
     <a id="Docker__GPUStack__39">
     </a>
     Docker 运行 GPUStack 的详细教程
    </h3>
    <p>
     <a href="https://docs.gpustack.ai/latest/installation/docker-installation/" rel="nofollow">
      https://docs.gpustack.ai/latest/installation/docker-installation/
     </a>
    </p>
    <p>
     以下是使用 Docker 运行 GPUStack 的详细教程，结合官方文档与社区实践整理而成。通过本指南，您可以在支持 NVIDIA GPU 的 Linux 环境中快速部署 GPUStack，并实现异构 GPU 集群的管理与大模型服务。
    </p>
    <hr/>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/a756c72585d84eb392d3ea8262ba877f.png#pic_center">
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/d2c9411b5b9644a8a05756aecf733f00.png#pic_center"/>
     </img>
    </p>
    <h4>
     <a id="_50">
     </a>
     一、环境准备
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        硬件与系统要求
       </strong>
      </p>
      <ul>
       <li>
        确保系统已安装 NVIDIA GPU，并验证驱动兼容性（支持 CUDA 11.0 及以上版本）。
       </li>
       <li>
        推荐使用 Ubuntu 22.04 LTS 或 CentOS 7+ 系统。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        验证 GPU 与依赖项
       </strong>
      </p>
      <pre><code class="prism language-bash"><span class="token comment"># 检查 NVIDIA GPU 是否识别</span>
lspci <span class="token operator">|</span> <span class="token function">grep</span> <span class="token parameter variable">-i</span> nvidia

root@i-28e6iose:/home/ubuntu<span class="token comment"># lspci | grep -i nvidia</span>
00:0c.0 VGA compatible controller: NVIDIA Corporation TU102 <span class="token punctuation">[</span>GeForce RTX <span class="token number">2080</span> Ti<span class="token punctuation">]</span> <span class="token punctuation">(</span>rev a1<span class="token punctuation">)</span>
00:0d.0 Audio device: NVIDIA Corporation TU102 High Definition Audio Controller <span class="token punctuation">(</span>rev a1<span class="token punctuation">)</span>

<span class="token comment"># 确认 GCC 已安装</span>
gcc <span class="token parameter variable">--version</span>

root@i-28e6iose:/home/ubuntu<span class="token comment"># gcc --version</span>
gcc <span class="token punctuation">(</span>Ubuntu <span class="token number">9.5</span>.0-6ubuntu2<span class="token punctuation">)</span> <span class="token number">9.5</span>.0
Copyright <span class="token punctuation">(</span>C<span class="token punctuation">)</span> <span class="token number">2019</span> Free Software Foundation, Inc.
This is <span class="token function">free</span> software<span class="token punctuation">;</span> see the <span class="token builtin class-name">source</span> <span class="token keyword">for</span> copying conditions.  There is NO
warranty<span class="token punctuation">;</span> not even <span class="token keyword">for</span> MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
</code></pre>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_NVIDIA__Docker_76">
     </a>
     二、安装 NVIDIA 驱动与 Docker
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        安装 NVIDIA 驱动
       </strong>
      </p>
      <pre><code class="prism language-bash"><span class="token comment"># 安装内核头文件</span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> linux-headers-<span class="token variable"><span class="token variable">$(</span><span class="token function">uname</span> <span class="token parameter variable">-r</span><span class="token variable">)</span></span>
<span class="token comment"># 添加 CUDA 仓库并安装驱动</span>
<span class="token function">wget</span> https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
<span class="token function">sudo</span> dpkg <span class="token parameter variable">-i</span> cuda-keyring_1.1-1_all.deb
<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> nvidia-driver-535 <span class="token parameter variable">-y</span>
<span class="token function">sudo</span> <span class="token function">reboot</span>
<span class="token comment"># 验证驱动</span>
nvidia-smi


root@i-28e6iose:/home/ubuntu<span class="token comment"># nvidia-smi</span>
Sun Mar  <span class="token number">9</span> <span class="token number">20</span>:48:43 <span class="token number">2025</span>
+-----------------------------------------------------------------------------------------+
<span class="token operator">|</span> NVIDIA-SMI <span class="token number">570.124</span>.06             Driver Version: <span class="token number">570.124</span>.06     CUDA Version: <span class="token number">12.8</span>     <span class="token operator">|</span>
<span class="token operator">|</span>-----------------------------------------+------------------------+----------------------+
<span class="token operator">|</span> GPU  Name                 Persistence-M <span class="token operator">|</span> Bus-Id          Disp.A <span class="token operator">|</span> Volatile Uncorr. ECC <span class="token operator">|</span>
<span class="token operator">|</span> Fan  Temp   Perf          Pwr:Usage/Cap <span class="token operator">|</span>           Memory-Usage <span class="token operator">|</span> GPU-Util  Compute M. <span class="token operator">|</span>
<span class="token operator">|</span>                                         <span class="token operator">|</span>                        <span class="token operator">|</span>               MIG M. <span class="token operator">|</span>
<span class="token operator">|</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">+=</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">+=</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">|</span>
<span class="token operator">|</span>   <span class="token number">0</span>  NVIDIA GeForce RTX <span class="token number">2080</span> Ti     Off <span class="token operator">|</span>   00000000:00:0C.0 Off <span class="token operator">|</span>                  N/A <span class="token operator">|</span>
<span class="token operator">|</span> <span class="token number">22</span>%   29C    P8             20W /  250W <span class="token operator">|</span>       4MiB /  11264MiB <span class="token operator">|</span>      <span class="token number">0</span>%      Default <span class="token operator">|</span>
<span class="token operator">|</span>                                         <span class="token operator">|</span>                        <span class="token operator">|</span>                  N/A <span class="token operator">|</span>
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
<span class="token operator">|</span> Processes:                                                                              <span class="token operator">|</span>
<span class="token operator">|</span>  GPU   GI   CI              PID   Type   Process name                        GPU Memory <span class="token operator">|</span>
<span class="token operator">|</span>        ID   ID                                                               Usage      <span class="token operator">|</span>
<span class="token operator">|</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">|</span>
<span class="token operator">|</span>  No running processes found                                                             <span class="token operator">|</span>
+-----------------------------------------------------------------------------------------+
</code></pre>
     </li>
     <li>
      <p>
       <strong>
        安装 Docker Engine
       </strong>
      </p>
      <pre><code class="prism language-bash"><span class="token comment"># 卸载旧版本 Docker（如有）</span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> remove docker.io docker-doc containerd
<span class="token comment"># 添加 Docker 官方源</span>
<span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg <span class="token operator">|</span> <span class="token function">sudo</span> gpg <span class="token parameter variable">--dearmor</span> <span class="token parameter variable">-o</span> /etc/apt/keyrings/docker.gpg
<span class="token builtin class-name">echo</span> <span class="token string">"deb [arch=<span class="token variable"><span class="token variable">$(</span>dpkg --print-architecture<span class="token variable">)</span></span> signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu <span class="token variable"><span class="token variable">$(</span>lsb_release <span class="token parameter variable">-cs</span><span class="token variable">)</span></span> stable"</span> <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/docker.list <span class="token operator">&gt;</span> /dev/null
<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> docker-ce docker-ce-cli containerd.io <span class="token parameter variable">-y</span>
<span class="token comment"># 验证 Docker</span>
<span class="token function">docker</span> info

root@i-28e6iose:/home/ubuntu<span class="token comment"># docker info</span>
Client: Docker Engine - Community
 Version:    <span class="token number">28.0</span>.1
 Context:    default
 Debug Mode: <span class="token boolean">false</span>
 Plugins:
  buildx: Docker Buildx <span class="token punctuation">(</span>Docker Inc.<span class="token punctuation">)</span>
    Version:  v0.21.1
    Path:     /usr/libexec/docker/cli-plugins/docker-buildx
  compose: Docker Compose <span class="token punctuation">(</span>Docker Inc.<span class="token punctuation">)</span>
    Version:  v2.33.1
    Path:     /usr/libexec/docker/cli-plugins/docker-compose

Server:
 Containers: <span class="token number">10</span>
  Running: <span class="token number">10</span>
  Paused: <span class="token number">0</span>
  Stopped: <span class="token number">0</span>
 Images: <span class="token number">10</span>
 Server Version: <span class="token number">28.0</span>.1
</code></pre>
     </li>
     <li>
      <p>
       <strong>
        配置 NVIDIA Container Toolkit
       </strong>
       <br/>
       <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/eac1f88707354902a9ac9f792d1f6448.png#pic_center"/>
      </p>
      <p>
       <code>
        nvidia/cuda:12.2.0-base-ubuntu22.04
       </code>
       是一个基于 Ubuntu 22.04 操作系统的 NVIDIA CUDA 基础镜像，用于运行需要 GPU 加速的计算环境。CUDA（Compute Unified Device Architecture）是 NVIDIA 提供的一个并行计算平台和编程模型，它使开发者可以使用 NVIDIA GPU 进行高性能计算。
      </p>
      <p>
       这个镜像提供了 CUDA 12.2.0 版本，适用于需要利用 NVIDIA GPU 进行深度学习、科学计算和其他计算密集型任务的场景。CUDA 12.2.0 版本带来了许多改进和新特性，包括对新架构的支持、性能优化和新 API
      </p>
      <p>
       <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html" rel="nofollow">
        https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html
       </a>
      </p>
      <pre><code class="prism language-bash"><span class="token comment"># 添加仓库并安装工具包</span>
<span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://nvidia.github.io/libnvidia-container/gpgkey <span class="token operator">|</span> <span class="token function">sudo</span> gpg <span class="token parameter variable">--dearmor</span> <span class="token parameter variable">-o</span> /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
<span class="token function">curl</span> <span class="token parameter variable">-s</span> <span class="token parameter variable">-L</span> https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/nvidia-container-toolkit.list
<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> nvidia-container-toolkit <span class="token parameter variable">-y</span>
<span class="token comment"># 配置 Docker 运行时</span>
<span class="token function">sudo</span> nvidia-ctk runtime configure <span class="token parameter variable">--runtime</span><span class="token operator">=</span>docker
<span class="token function">sudo</span> systemctl restart <span class="token function">docker</span>

root@i-28e6iose:/home/ubuntu<span class="token comment"># sudo nvidia-ctk runtime configure --runtime=docker</span>
INFO<span class="token punctuation">[</span>0000<span class="token punctuation">]</span> Loading config from /etc/docker/daemon.json
INFO<span class="token punctuation">[</span>0000<span class="token punctuation">]</span> Wrote updated config to /etc/docker/daemon.json
INFO<span class="token punctuation">[</span>0000<span class="token punctuation">]</span> It is recommended that <span class="token function">docker</span> daemon be restarted.

<span class="token comment"># 验证 CUDA 容器</span>
<span class="token function">docker</span> run <span class="token parameter variable">--rm</span> <span class="token parameter variable">--gpus</span> all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi

root@i-28e6iose:/home/ubuntu<span class="token comment"># docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi</span>
Sun Mar  <span class="token number">9</span> <span class="token number">13</span>:10:55 <span class="token number">2025</span>
+-----------------------------------------------------------------------------------------+
<span class="token operator">|</span> NVIDIA-SMI <span class="token number">570.124</span>.06             Driver Version: <span class="token number">570.124</span>.06     CUDA Version: <span class="token number">12.8</span>     <span class="token operator">|</span>
<span class="token operator">|</span>-----------------------------------------+------------------------+----------------------+
<span class="token operator">|</span> GPU  Name                 Persistence-M <span class="token operator">|</span> Bus-Id          Disp.A <span class="token operator">|</span> Volatile Uncorr. ECC <span class="token operator">|</span>
<span class="token operator">|</span> Fan  Temp   Perf          Pwr:Usage/Cap <span class="token operator">|</span>           Memory-Usage <span class="token operator">|</span> GPU-Util  Compute M. <span class="token operator">|</span>
<span class="token operator">|</span>                                         <span class="token operator">|</span>                        <span class="token operator">|</span>               MIG M. <span class="token operator">|</span>
<span class="token operator">|</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">+=</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">+=</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">|</span>
<span class="token operator">|</span>   <span class="token number">0</span>  NVIDIA GeForce RTX <span class="token number">2080</span> Ti     Off <span class="token operator">|</span>   00000000:00:0C.0 Off <span class="token operator">|</span>                  N/A <span class="token operator">|</span>
<span class="token operator">|</span> <span class="token number">22</span>%   26C    P8             21W /  250W <span class="token operator">|</span>       4MiB /  11264MiB <span class="token operator">|</span>      <span class="token number">0</span>%      Default <span class="token operator">|</span>
<span class="token operator">|</span>                                         <span class="token operator">|</span>                        <span class="token operator">|</span>                  N/A <span class="token operator">|</span>
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
<span class="token operator">|</span> Processes:                                                                              <span class="token operator">|</span>
<span class="token operator">|</span>  GPU   GI   CI              PID   Type   Process name                        GPU Memory <span class="token operator">|</span>
<span class="token operator">|</span>        ID   ID                                                               Usage      <span class="token operator">|</span>
<span class="token operator">|</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">|</span>
<span class="token operator">|</span>  No running processes found                                                             <span class="token operator">|</span>
+-----------------------------------------------------------------------------------------+
</code></pre>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_GPUStack__200">
     </a>
     三、部署 GPUStack 容器
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        运行 GPUStack 主节点
       </strong>
      </p>
      <pre><code class="prism language-bash"><span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--gpus</span> all <span class="token punctuation">\</span>
  <span class="token parameter variable">-p</span> <span class="token number">890</span>:80 <span class="token punctuation">\</span>
  <span class="token parameter variable">--ipc</span><span class="token operator">=</span>host <span class="token punctuation">\</span>
  <span class="token parameter variable">--name</span> gpustack <span class="token punctuation">\</span>
  <span class="token parameter variable">-v</span> gpustack-data:/var/lib/gpustack <span class="token punctuation">\</span>
  gpustack/gpustack:latest
</code></pre>
      <ul>
       <li>
        <strong>
         参数说明
        </strong>
        <ul>
         <li>
          <code>
           --gpus all
          </code>
          ：启用所有 GPU 资源。
         </li>
         <li>
          <code>
           --ipc=host
          </code>
          ：共享主机 IPC 命名空间，提升性能。
         </li>
         <li>
          <code>
           -v gpustack-data
          </code>
          ：持久化存储配置与模型数据。
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        获取初始密码
       </strong>
      </p>
      <pre><code class="prism language-bash"><span class="token function">docker</span> <span class="token builtin class-name">exec</span> <span class="token parameter variable">-it</span> gpustack <span class="token function">cat</span> /var/lib/gpustack/initial_admin_password

root@i-28e6iose:/home/ubuntu<span class="token comment"># docker exec -it gpustack cat /var/lib/gpustack/initial_admin_password</span>
rjl@Ainm3dtQ

<span class="token comment">#账户信息：</span>
admin/rjl@Ainm3dtQ
<span class="token comment">#修改密码：P@88w0rd</span>
</code></pre>
      <p>
       访问
       <code>
        http://&lt;服务器IP&gt;
       </code>
       ，使用用户名
       <code>
        admin
       </code>
       和上述密码登录，首次需重置密码。
      </p>
     </li>
    </ol>
    <hr/>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/5663b6e9ee7b43b28416abb276397c4a.png#pic_center"/>
    </p>
    <h4>
     <a id="_GPU__233">
     </a>
     四、扩展 GPU 集群
    </h4>
    <ol>
     <li>
      <strong>
       添加 Worker 节点
      </strong>
      <ul>
       <li>
        在主节点获取 Token：
        <pre><code class="prism language-bash"><span class="token function">docker</span> <span class="token builtin class-name">exec</span> <span class="token parameter variable">-it</span> gpustack <span class="token function">cat</span> /var/lib/gpustack/token
</code></pre>
       </li>
       <li>
        在 Worker 节点运行：
        <pre><code class="prism language-bash"><span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--gpus</span> all <span class="token punctuation">\</span>
  <span class="token parameter variable">--network</span><span class="token operator">=</span>host <span class="token punctuation">\</span>
  <span class="token parameter variable">--ipc</span><span class="token operator">=</span>host <span class="token punctuation">\</span>
  gpustack/gpustack <span class="token punctuation">\</span>
  --server-url http://<span class="token operator">&lt;</span>主节点IP<span class="token operator">&gt;</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--token</span> <span class="token operator">&lt;</span>获取的Token<span class="token operator">&gt;</span>
</code></pre>
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_252">
     </a>
     五、功能使用示例
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        部署大模型
       </strong>
       <br/>
       在 GPUStack 控制台的
       <strong>
        Models
       </strong>
       页面，支持从 Hugging Face 或本地导入模型。例如部署 Llama3.2 模型时，系统会自动分配 GPU 资源并生成 API 端点。
      </p>
     </li>
     <li>
      <p>
       <strong>
        Playground 调测
       </strong>
       <br/>
       在 Playground 中可测试多模态模型（如 Stable Diffusion）、文本嵌入模型（BERT）等，支持多模型对比与参数优化。
      </p>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_262">
     </a>
     六、常见问题
    </h4>
    <ul>
     <li>
      <strong>
       GPU 未识别
      </strong>
      ：检查
      <code>
       nvidia-smi
      </code>
      是否正常，并确认 Docker 运行时配置正确。
     </li>
     <li>
      <strong>
       容器启动失败
      </strong>
      ：确保已启用
      <code>
       --ipc=host
      </code>
      并挂载持久化卷。
     </li>
     <li>
      <strong>
       网络问题
      </strong>
      ：跨节点通信需开放防火墙的 80 端口及内部 RPC 端口（默认为 6789）。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="_269">
     </a>
     七、参考资源
    </h4>
    <ul>
     <li>
      <a href="https://docs.gpustack.ai/latest/installation/docker-installation/" rel="nofollow">
       GPUStack 官方 Docker 部署文档
      </a>
     </li>
     <li>
      <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html" rel="nofollow">
       NVIDIA Container Toolkit 配置指南
      </a>
     </li>
    </ul>
    <p>
     通过以上步骤，您可快速搭建一个支持异构 GPU 资源调度的企业级大模型服务平台，实现从单机到集群的高效扩展。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f7368656e686f6e676c6569313233342f:61727469636c652f64657461696c732f313436313339303232" class_="artid" style="display:none">
 </p>
</div>


