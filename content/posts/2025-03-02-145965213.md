---
layout: post
title: "PyCharm接入本地部署DeepSeek-实现AI编程支持windows与linux"
date: 2025-03-02 17:20:05 +0800
description: "一般情况下，我们选择安装deepseek-r1:1.5b或者7b，可以支持我们普通配置（消费级显卡或者无显卡）的电脑、笔记本，适合个人开发者或者边缘计算设备。我自己尝试了以后，发现网络不太行，下载很缓慢，所以就采取了手动安装。今天尝试在pycharm上接入了本地部署的deepseek，实现了AI编程，体验还是很棒的。我的版本是pycharm 2023.3.7，有的高级版本可能直接在刚才的首页就可以找到后面所要的东西，请自己尝试。推荐，这样每次登陆服务器，就可以自启动了，不需要每次都手动地开启服务。"
keywords: "python插入deepseek proxy ai"
categories: ['深度学习', '常用工具']
tags: ['Ai']
artid: "145965213"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145965213
    alt: "PyCharm接入本地部署DeepSeek-实现AI编程支持windows与linux"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145965213
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145965213
cover: https://bing.ee123.net/img/rand?artid=145965213
image: https://bing.ee123.net/img/rand?artid=145965213
img: https://bing.ee123.net/img/rand?artid=145965213
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     PyCharm接入本地部署DeepSeek 实现AI编程！【支持windows与linux】
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     今天尝试在pycharm上接入了本地部署的deepseek，实现了AI编程，体验还是很棒的。下面详细叙述整个安装过程。
    </p>
    <p>
     本次搭建的框架组合是
     <span style="color:#fe2c24">
      <strong>
       DeepSeek-r1:1.5b/7b
      </strong>
     </span>
     <span style="color:#0d0016">
      <strong>
       +
      </strong>
     </span>
     <span style="color:#fe2c24">
      <strong>
       Pycharm专业版或者社区版
      </strong>
     </span>
     <span style="color:#0d0016">
      <strong>
       +
      </strong>
     </span>
     <span style="color:#fe2c24">
      <strong>
       Proxy AI（CodeGPT）
      </strong>
     </span>
    </p>
    <p>
     首先了解不同版本的deepseek区别：
     <br/>
     <a href="https://ollama.com/library/deepseek-r1" rel="nofollow" title="deepseek-r1">
      deepseek-r1
     </a>
    </p>
    <p>
     <img alt="" height="257" src="https://i-blog.csdnimg.cn/direct/0a8f8df811444f2da19f115b5c23104f.png" width="596"/>
    </p>
    <p>
     <img alt="" height="526" src="https://i-blog.csdnimg.cn/direct/7a2347a40eb440d0a00710cba1cd219d.png" width="762"/>
    </p>
    <p>
     根据：
     <a href="https://docs.coreshub.cn/console/big_model_server/introduce/model_choose/" rel="nofollow" title="DeepSeek 系列模型选择 - AI 智算产品文档">
      DeepSeek 系列模型选择 - AI 智算产品文档
     </a>
    </p>
    <p>
     <img alt="" height="376" src="https://i-blog.csdnimg.cn/direct/c193fe58b8df414da75ba63c33cc14a8.png" width="1252"/>
    </p>
    <p>
     一般情况下，我们选择安装deepseek-r1:1.5b或者7b，可以支持我们普通配置（消费级显卡或者无显卡）的电脑、笔记本，适合个人开发者或者边缘计算设备。
    </p>
    <p>
     接下来，我们具体开始安装本地版deepseek.
     <br/>
     1. 安装pycharm:
     <a href="https://www.jetbrains.com/pycharm/" rel="nofollow" title="https://www.jetbrains.com/pycharm/">
      https://www.jetbrains.com/pycharm/
     </a>
     <br/>
     可以装专业版（Professional）或者社区版（Community），均可以。
     <br/>
     <br/>
     2. 下载安装ollama (
     <a href="https://ollama.com/download" rel="nofollow" title="https://ollama.com/download">
      https://ollama.com/download
     </a>
     )
     <br/>
     <img alt="" height="325" src="https://i-blog.csdnimg.cn/direct/1fbf09ceea894f6497d6cb31d8394bcb.png" width="425"/>
    </p>
    <p>
     windows版本直接下载安装即可，傻瓜式安装，很简单。linux稍微复杂一些。下面着重谈一下linux（以ubuntu为例）的安装。
     <br/>
     <img alt="" height="390" src="https://i-blog.csdnimg.cn/direct/0723c83795774641bf83961253dccf6e.png" width="610">
      <br/>
      如果网络比较流畅，可以直接用官方提供的命令行快速安装。我自己尝试了以后，发现网络不太行，下载很缓慢，所以就采取了手动安装。注意linux要求有root权限。
      <br/>
      <strong>
       2.1 下载并解压与操作系统匹配的安装包
      </strong>
      <br/>
      <br/>
      首先进入到某一个下载目录（自定义，哪里都行），然后执行下面的命令
     </img>
    </p>
    <pre><code>curl -L https://ollama.com/download/ollama-linux-amd64.tgz -o ollama-linux-amd64.tgz
sudo tar -C /usr -xzf ollama-linux-amd64.tgz</code></pre>
    <p>
     如果
     <span style="color:#fe2c24">
      第一行代码
     </span>
     下载缓慢，可以直接从浏览器下载，下载地址为：
     <a href="https://ollama.com/download/ollama-linux-amd64.tgz" rel="nofollow" title="https://ollama.com/download/ollama-linux-amd64.tgz">
      https://ollama.com/download/ollama-linux-amd64.tgz
     </a>
     <br/>
     然后将其上传到上面的自定义目录中，最后运行
     <span style="color:#fe2c24">
      第二行代码
     </span>
     将其解压到/usr目录中。
     <br/>
     <strong>
      2.2 启动 Ollama并验证
     </strong>
     <br/>
     输入以下命令启动 Ollama：
    </p>
    <pre><code>ollama serve</code></pre>
    <p>
     另开启一个终端，输入以下命令，验证ollama是否运行成功
    </p>
    <pre><code>ollama -v</code></pre>
    <p>
     <strong>
      2.3 将 Ollama 添加为自启动服务（
      <span style="color:#956fe7">
       推荐，这样每次登陆服务器，就可以自启动了，不需要每次都手动地开启服务
      </span>
      ）
     </strong>
     <br/>
     首先，为 Ollama 创建用户和组：
    </p>
    <pre><code>sudo useradd -r -s /bin/false -U -m -d /usr/share/ollama ollama
sudo usermod -a -G ollama $(whoami)</code></pre>
    <p>
     然后在该位置：
     <code>
      /etc/systemd/system/ollama.service
     </code>
     创建服务文件
     <br/>
     具体步骤为：
     <br/>
     a.
     <strong>
      输入以下命令以使用
      <code>
       vim
      </code>
      打开（或创建）服务文件
     </strong>
    </p>
    <pre><code>sudo vim /etc/systemd/system/ollama.service</code></pre>
    <p>
     b.
     <strong>
      进入插入模式编辑文件
     </strong>
     <br/>
     <img alt="" height="105" src="https://i-blog.csdnimg.cn/direct/56408d9e293b4eec8e687fff2a90eefa.png" width="623"/>
    </p>
    <p>
     c.
     <strong>
      在 Vim 编辑器中拷贝输入以下内容：
     </strong>
     <br/>
     拷贝下面内容，然后粘贴到上述vim编辑器中即可。
    </p>
    <pre><code>[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=/usr/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment="PATH=$PATH"

[Install]
WantedBy=default.target</code></pre>
    <p>
     d.
     <strong>
      保存并退出 Vim
     </strong>
     <br/>
     <img alt="" height="268" src="https://i-blog.csdnimg.cn/direct/c427a033faf647d395406ebd16febc4f.png" width="658"/>
    </p>
    <p>
     e.
     <strong>
      验证文件是否保存成功
     </strong>
     <br/>
     为了确保文件已正确保存，可以查看文件内容：
    </p>
    <pre><code>cat /etc/systemd/system/ollama.service</code></pre>
    <p>
     f.
     <strong>
      重新加载 systemd 配置
     </strong>
     <br/>
     让 systemd 识别新创建的服务文件：
    </p>
    <pre><code>sudo systemctl daemon-reload</code></pre>
    <p>
     g.
     <strong>
      启动并启用服务
     </strong>
     <br/>
     启动 Ollama 服务并设置为开机自启：
    </p>
    <pre><code>sudo systemctl start ollama.service
sudo systemctl enable ollama.service</code></pre>
    <p>
     h.
     <strong>
      检查服务状态
     </strong>
     <br/>
     验证服务是否正在运行：
    </p>
    <pre><code>sudo systemctl status ollama.service</code></pre>
    <p>
     你应该看到类似以下的输出，表示服务正在运行：
    </p>
    <p>
     <img alt="" height="107" src="https://i-blog.csdnimg.cn/direct/922b6c0f9d604fcb8867a5ec5e0e070e.png" width="686"/>
    </p>
    <p>
     3. 下载deepseek-r1:1.5b 、deepseek-r1:7b （
     <a href="https://ollama.com/library/deepseek-r1" rel="nofollow" title="https://ollama.com/library/deepseek-r1">
      https://ollama.com/library/deepseek-r1
     </a>
     ）
     <br/>
     打开windows cmd命令行或者linux命令行，输入:
    </p>
    <pre><code>ollama run deepseek-r1:1.5b</code></pre>
    <p>
     即可下载
     <strong>
      DeepSeek-R1-Distill-Qwen-1.5B
     </strong>
     到自己的电脑上。
    </p>
    <p>
     <strong>
      输入
     </strong>
    </p>
    <pre><code>ollama run deepseek-r1:7b</code></pre>
    <p>
     即可下载
     <strong>
      DeepSeek-R1-Distill-Qwen-7B
     </strong>
     到自己的电脑上。
    </p>
    <p>
     默认模型保存位置如下：
    </p>
    <ul>
     <li>
      macOS:
      <code>
       ~/.ollama/models
      </code>
     </li>
     <li>
      Linux:
      <code>
       /usr/share/ollama/.ollama/models
      </code>
     </li>
     <li>
      Windows:
      <code>
       C:\Users\%username%\.ollama\models
      </code>
     </li>
    </ul>
    <p>
     下载安装后可以进入命令行中进行验证：
     <br/>
     <img alt="" height="81" src="https://i-blog.csdnimg.cn/direct/5cb738afa2ae4c588e5f37a45e1853ec.png" width="494"/>
    </p>
    <p>
     4. 加入deepseek到pycharm中
     <br/>
     1）启动 PyCharm 客户端，点击左侧导航栏中的
     <strong>
      Plugins
     </strong>
     ，进入
     <strong>
      Maeketplace
     </strong>
     ，在搜索框中输入
     <strong>
      <a class="link-info" href="https://plugins.jetbrains.com/plugin/21056-proxy-ai" rel="nofollow" title="Proxy AI">
       Proxy AI
      </a>
      （内含CodeGPT）
     </strong>
     ，查找相应扩展应用，并点击
     <strong>
      安装
     </strong>
     。
     <br/>
     <img alt="" height="849" src="https://i-blog.csdnimg.cn/direct/ba84f22e18b748ddbed2b858254917e9.png" width="1910"/>
    </p>
    <p>
     2）选择
     <strong>
      已安装
     </strong>
     页签，可查看到
     <strong>
      Proxy AI
     </strong>
     插件，显示在列。
    </p>
    <p>
     3) 在pycharm中创建一个python工程（
     <span style="background-color:#a2e043">
      我的版本是pycharm 2023.3.7，有的高级版本可能直接在刚才的首页就可以找到后面所要的东西，请自己尝试
     </span>
     ），然后点击 PyCharm 主界面，选择File按钮, 点击Settings按钮。在弹出的窗口中，选择
     <strong>
      Tools
     </strong>
     &gt;
     <strong>
      CodeGPT
     </strong>
     &gt;
     <strong>
      Providers
     </strong>
     。
    </p>
    <p>
     <img alt="" height="720" src="https://i-blog.csdnimg.cn/direct/ac6822448cff48e59d5ace7db3d13c7f.png" width="999"/>
    </p>
    <p>
     4) 找到Ollama(Local)，选择刚刚安装的
     <code>
      deepseek-r1:1.5b
     </code>
     ，点击OK就可以了：
     <br/>
     <img alt="" height="822" src="https://i-blog.csdnimg.cn/direct/44f4be436c8d46e6bade45d04748722a.png" width="1240"/>
    </p>
    <p>
     5) 完成上述操作后，就可以愉快的在PyCharm中使用DeepSeek-r1实现AI编程学习了，左侧是代码编辑界面，右侧是r1大模型，直接对话式提问，省去了来回不同页面折腾的麻烦：
    </p>
    <p>
     <img alt="" height="892" src="https://i-blog.csdnimg.cn/direct/e3018bc147d640c0a996a9d9f7af1951.png" width="1526"/>
    </p>
    <p>
     大家可以自行感受一下
     <code>
      DeepSeek-r1:1.5b
     </code>
     大模型的回复延时，几乎1~2秒钟就可以响应，效果还算可以。
    </p>
    <p>
     另外，
     <code>
      CodeGPT
     </code>
     插件显示了Tokens数，只是一个数字统计，
     <strong>
      <span style="color:#956fe7">
       无任何费用，因为使用的是本地自己电脑的算力哦。
      </span>
     </strong>
    </p>
    <p>
    </p>
    <p>
     参考文献：
     <br/>
     1.
     <a href="https://www.cnblogs.com/jinjiangongzuoshi/p/18714724" rel="nofollow" title="超详细，DeepSeek 接入PyCharm实现AI编程！（支持本地部署DeepSeek及官方DeepSeek接入），建议收藏！ - 狂师 - 博客园">
      超详细，DeepSeek 接入PyCharm实现AI编程！（支持本地部署DeepSeek及官方DeepSeek接入），建议收藏！ - 狂师 - 博客园
     </a>
    </p>
    <p>
     2.
     <a href="https://www.cnblogs.com/longronglang/p/18697688" rel="nofollow" title="PyCharm接入本地DeepSeek R1实现AI编程 - 久曲健 - 博客园">
      PyCharm接入本地DeepSeek R1实现AI编程 - 久曲健 - 博客园
     </a>
    </p>
    <p>
     3.
     <a href="https://blog.csdn.net/huachangzai/article/details/138523773" title="Ubuntu 环境安装和使用Ollama_3ubuntu ollama phi-CSDN博客">
      Ubuntu 环境安装和使用Ollama_3ubuntu ollama phi-CSDN博客
     </a>
    </p>
    <p>
     4.
     <a href="https://docs.coreshub.cn/console/big_model_server/call_scenario/pycharm/" rel="nofollow" title="在 PyCharm 中使用 - AI 智算产品文档">
      在 PyCharm 中使用 - AI 智算产品文档
     </a>
    </p>
    <p>
     5.
     <a class="link-info" href="https://github.com/datawhalechina/handy-ollama/blob/main/docs/C2/3.%20Ollama%20%E5%9C%A8%20Linux%20%E4%B8%8B%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE.md" title="Ollama 安装与配置 - Linux 系统篇">
      Ollama 安装与配置 - Linux 系统篇
     </a>
     【
     <span style="color:#fe2c24">
      推荐看这个，和英文版一样的
     </span>
     】
    </p>
    <p>
     6.
     <a class="link-info" href="https://github.com/ollama/ollama/blob/main/docs/linux.md" title="Ollama 安装与配置 - Linux 系统篇-官方英文版教程">
      Ollama 安装与配置 - Linux 系统篇-官方英文版教程
     </a>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f7869616d656e74696e6774616f2f:61727469636c652f64657461696c732f313435393635323133" class_="artid" style="display:none">
 </p>
</div>


