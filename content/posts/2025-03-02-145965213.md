---
layout: post
title: "PyCharm接入本地部署DeepSeek-实现AI编程支持windows与linux"
date: 2025-03-02 17:20:05 +0800
description: "一般情况下，我们选择安装deepseek-r1:1.5b或者7b，可以支持我们普通配置（消费级显卡或者无显卡）的电脑、笔记本，适合个人开发者或者边缘计算设备。我自己尝试了以后，发现网络不太行，下载很缓慢，所以就采取了手动安装。今天尝试在pycharm上接入了本地部署的deepseek，实现了AI编程，体验还是很棒的。我的版本是pycharm 2023.3.7，有的高级版本可能直接在刚才的首页就可以找到后面所要的东西，请自己尝试。推荐，这样每次登陆服务器，就可以自启动了，不需要每次都手动地开启服务。"
keywords: "python用本地部署的deepseek开发ai应用"
categories: ['深度学习', '常用工具']
tags: ['Ai']
artid: "145965213"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145965213
    alt: "PyCharm接入本地部署DeepSeek-实现AI编程支持windows与linux"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145965213
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145965213
cover: https://bing.ee123.net/img/rand?artid=145965213
image: https://bing.ee123.net/img/rand?artid=145965213
img: https://bing.ee123.net/img/rand?artid=145965213
---

# PyCharm接入本地部署DeepSeek 实现AI编程！【支持windows与linux】
今天尝试在pycharm上接入了本地部署的deepseek，实现了AI编程，体验还是很棒的。下面详细叙述整个安装过程。
本次搭建的框架组合是 \*\*DeepSeek-r1:1.5b/7b\*\*\*\*+\*\*\*\*Pycharm专业版或者社区版\*\*\*\*+\*\*\*\*Proxy
AI（CodeGPT）\*\*
首先了解不同版本的deepseek区别：
[deepseek-r1](https://ollama.com/library/deepseek-r1 "deepseek-r1")
![](https://i-blog.csdnimg.cn/direct/0a8f8df811444f2da19f115b5c23104f.png)
![](https://i-blog.csdnimg.cn/direct/7a2347a40eb440d0a00710cba1cd219d.png)
根据：[DeepSeek 系列模型选择 - AI
智算产品文档](https://docs.coreshub.cn/console/big\_model\_server/introduce/model\_choose/
"DeepSeek 系列模型选择 - AI 智算产品文档")
![](https://i-blog.csdnimg.cn/direct/c193fe58b8df414da75ba63c33cc14a8.png)
一般情况下，我们选择安装deepseek-r1:1.5b或者7b，可以支持我们普通配置（消费级显卡或者无显卡）的电脑、笔记本，适合个人开发者或者边缘计算设备。
接下来，我们具体开始安装本地版deepseek.
1\. 安装pycharm: 
可以装专业版（Professional）或者社区版（Community），均可以。
2\. 下载安装ollama ( )
![](https://i-blog.csdnimg.cn/direct/1fbf09ceea894f6497d6cb31d8394bcb.png)
windows版本直接下载安装即可，傻瓜式安装，很简单。linux稍微复杂一些。下面着重谈一下linux（以ubuntu为例）的安装。
![](https://i-blog.csdnimg.cn/direct/0723c83795774641bf83961253dccf6e.png)
如果网络比较流畅，可以直接用官方提供的命令行快速安装。我自己尝试了以后，发现网络不太行，下载很缓慢，所以就采取了手动安装。注意linux要求有root权限。
\*\*2.1 下载并解压与操作系统匹配的安装包\*\*
首先进入到某一个下载目录（自定义，哪里都行），然后执行下面的命令
curl -L https://ollama.com/download/ollama-linux-amd64.tgz -o ollama-linux-amd64.tgz
sudo tar -C /usr -xzf ollama-linux-amd64.tgz
如果第一行代码下载缓慢，可以直接从浏览器下载，下载地址为：
然后将其上传到上面的自定义目录中，最后运行第二行代码将其解压到/usr目录中。
\*\*2.2 启动 Ollama并验证\*\*
输入以下命令启动 Ollama：
ollama serve
另开启一个终端，输入以下命令，验证ollama是否运行成功
ollama -v
\*\*2.3 将 Ollama 添加为自启动服务（ 推荐，这样每次登陆服务器，就可以自启动了，不需要每次都手动地开启服务）\*\*
首先，为 Ollama 创建用户和组：
sudo useradd -r -s /bin/false -U -m -d /usr/share/ollama ollama
sudo usermod -a -G ollama $(whoami)
然后在该位置：`/etc/systemd/system/ollama.service` 创建服务文件
具体步骤为：
a. \*\*输入以下命令以使用`vim` 打开（或创建）服务文件\*\*
sudo vim /etc/systemd/system/ollama.service
b. \*\*进入插入模式编辑文件\*\*
![](https://i-blog.csdnimg.cn/direct/56408d9e293b4eec8e687fff2a90eefa.png)
c. \*\*在 Vim 编辑器中拷贝输入以下内容：\*\*
拷贝下面内容，然后粘贴到上述vim编辑器中即可。
[Unit]
Description=Ollama Service
After=network-online.target
[Service]
ExecStart=/usr/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment="PATH=$PATH"
[Install]
WantedBy=default.target
d. \*\*保存并退出 Vim\*\*
![](https://i-blog.csdnimg.cn/direct/c427a033faf647d395406ebd16febc4f.png)
e. \*\*验证文件是否保存成功\*\*
为了确保文件已正确保存，可以查看文件内容：
cat /etc/systemd/system/ollama.service
f. \*\*重新加载 systemd 配置\*\*
让 systemd 识别新创建的服务文件：
sudo systemctl daemon-reload
g. \*\*启动并启用服务\*\*
启动 Ollama 服务并设置为开机自启：
sudo systemctl start ollama.service
sudo systemctl enable ollama.service
h. \*\*检查服务状态\*\*
验证服务是否正在运行：
sudo systemctl status ollama.service
你应该看到类似以下的输出，表示服务正在运行：
![](https://i-blog.csdnimg.cn/direct/922b6c0f9d604fcb8867a5ec5e0e070e.png)
3\. 下载deepseek-r1:1.5b 、deepseek-r1:7b
（）
打开windows cmd命令行或者linux命令行，输入:
ollama run deepseek-r1:1.5b
即可下载\*\*DeepSeek-R1-Distill-Qwen-1.5B\*\* 到自己的电脑上。
\*\*输入\*\*
ollama run deepseek-r1:7b
即可下载\*\*DeepSeek-R1-Distill-Qwen-7B\*\* 到自己的电脑上。
默认模型保存位置如下：
\* macOS: `~/.ollama/models`
\* Linux: `/usr/share/ollama/.ollama/models`
\* Windows: `C:\Users\%username%\.ollama\models`
下载安装后可以进入命令行中进行验证：
![](https://i-blog.csdnimg.cn/direct/5cb738afa2ae4c588e5f37a45e1853ec.png)
4\. 加入deepseek到pycharm中
1）启动 PyCharm 客户端，点击左侧导航栏中的\*\*Plugins\*\* ，进入 \*\*Maeketplace\*\* ，在搜索框中输入 \*\*[Proxy
AI](https://plugins.jetbrains.com/plugin/21056-proxy-ai "Proxy
AI")（内含CodeGPT）\*\*，查找相应扩展应用，并点击\*\*安装\*\* 。
![](https://i-blog.csdnimg.cn/direct/ba84f22e18b748ddbed2b858254917e9.png)
2）选择\*\*已安装\*\* 页签，可查看到\*\*Proxy AI\*\* 插件，显示在列。
3) 在pycharm中创建一个python工程（我的版本是pycharm
2023.3.7，有的高级版本可能直接在刚才的首页就可以找到后面所要的东西，请自己尝试），然后点击 PyCharm 主界面，选择File按钮,
点击Settings按钮。在弹出的窗口中，选择\*\*Tools\*\* > \*\*CodeGPT\*\* > \*\*Providers\*\* 。
![](https://i-blog.csdnimg.cn/direct/ac6822448cff48e59d5ace7db3d13c7f.png)
4) 找到Ollama(Local)，选择刚刚安装的`deepseek-r1:1.5b`，点击OK就可以了：
![](https://i-blog.csdnimg.cn/direct/44f4be436c8d46e6bade45d04748722a.png)
5)
完成上述操作后，就可以愉快的在PyCharm中使用DeepSeek-r1实现AI编程学习了，左侧是代码编辑界面，右侧是r1大模型，直接对话式提问，省去了来回不同页面折腾的麻烦：
![](https://i-blog.csdnimg.cn/direct/e3018bc147d640c0a996a9d9f7af1951.png)
大家可以自行感受一下`DeepSeek-r1:1.5b`大模型的回复延时，几乎1~2秒钟就可以响应，效果还算可以。
另外，`CodeGPT`插件显示了Tokens数，只是一个数字统计，\*\*无任何费用，因为使用的是本地自己电脑的算力哦。\*\*
参考文献：
1\. [超详细，DeepSeek 接入PyCharm实现AI编程！（支持本地部署DeepSeek及官方DeepSeek接入），建议收藏！ - 狂师 -
博客园](https://www.cnblogs.com/jinjiangongzuoshi/p/18714724 "超详细，DeepSeek
接入PyCharm实现AI编程！（支持本地部署DeepSeek及官方DeepSeek接入），建议收藏！ - 狂师 - 博客园")
2\. [PyCharm接入本地DeepSeek R1实现AI编程 - 久曲健 -
博客园](https://www.cnblogs.com/longronglang/p/18697688 "PyCharm接入本地DeepSeek
R1实现AI编程 - 久曲健 - 博客园")
3\. [Ubuntu 环境安装和使用Ollama\_3ubuntu ollama phi-
CSDN博客](https://blog.csdn.net/huachangzai/article/details/138523773 "Ubuntu
环境安装和使用Ollama\_3ubuntu ollama phi-CSDN博客")
4\. [在 PyCharm 中使用 - AI
智算产品文档](https://docs.coreshub.cn/console/big\_model\_server/call\_scenario/pycharm/
"在 PyCharm 中使用 - AI 智算产品文档")
5\. [Ollama 安装与配置 - Linux 系统篇](https://github.com/datawhalechina/handy-
ollama/blob/main/docs/C2/3.%20Ollama%20%E5%9C%A8%20Linux%20%E4%B8%8B%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE.md
"Ollama 安装与配置 - Linux 系统篇") 【推荐看这个，和英文版一样的】
6\. [Ollama 安装与配置 - Linux 系统篇-
官方英文版教程](https://github.com/ollama/ollama/blob/main/docs/linux.md "Ollama
安装与配置 - Linux 系统篇-官方英文版教程")