---
layout: post
title: "深入探讨RAID-5的性能与容错能力实验与分析磁盘阵列"
date: 2025-03-15 01:00:00 +0800
description: "本实验旨在探讨 RAID 5 的性能和容错能力。通过创建 RAID 5 阵列并进行一系列读写性能测试及故障模拟，我们将观察 RAID 5 在数据冗余和故障恢复方面的表现，以验证其在实际应用中的可靠性和效率。首先说明：最少三块硬盘, 使用 4 块硬盘确实能获得更好的性能和更大的存储空间。让我们用 4 块硬盘（nvme0n2 到 nvme0n5）来构建 RAID 5。最少三块，我这边用四块做实验。你的硬盘类型可能和我的不一样 不过没有关系不影响操作实验。"
keywords: "深入探讨RAID 5的性能与容错能力：实验与分析(磁盘阵列)"
categories: ['Linux']
tags: ['键盘', '服务器', 'Python', 'Linux']
artid: "146255934"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146255934
    alt: "深入探讨RAID-5的性能与容错能力实验与分析磁盘阵列"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146255934
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146255934
cover: https://bing.ee123.net/img/rand?artid=146255934
image: https://bing.ee123.net/img/rand?artid=146255934
img: https://bing.ee123.net/img/rand?artid=146255934
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     深入探讨RAID 5的性能与容错能力：实验与分析(磁盘阵列)
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h4 id="TGUO4" style="background-color:transparent">
     前言——
    </h4>
    <p id="u08a12232">
     本实验旨在探讨 RAID 5 的性能和容错能力。通过创建 RAID 5 阵列并进行一系列读写性能测试及故障模拟，我们将观察 RAID 5 在数据冗余和故障恢复方面的表现，以验证其在实际应用中的可靠性和效率。
    </p>
    <p id="u734e6bc0">
    </p>
    <p id="u5743f3b1">
     首先说明：最少三块硬盘, 使用 4 块硬盘确实能获得更好的性能和更大的存储空间。让我们用 4 块硬盘（nvme0n2 到 nvme0n5）来构建 RAID 5。
    </p>
    <p id="u607ebde3">
    </p>
    <p id="u7a4c4cf9">
     <strong>
      最少三块，我这边用四块做实验。
     </strong>
    </p>
    <p id="u9cead698">
     你的硬盘类型可能和我的不一样 不过没有关系不影响操作实验
    </p>
    <h4 id="a92116b0">
     实验环境说明
    </h4>
    <ul>
     <li id="u85665023">
      系统盘：nvme0n1（不参与 RAID）
     </li>
     <li id="u8cdb8ed0">
      可用磁盘：
     </li>
    </ul>
    <ul>
     <li>
      <ul>
       <li id="ue4ec1e16">
        nvme0n2（20GB）
       </li>
       <li id="u6d6cc3f6">
        nvme0n3（20GB）
       </li>
       <li id="uba4ec835">
        nvme0n4（20GB）
       </li>
       <li id="u6c089809">
        nvme0n5（20GB）
       </li>
      </ul>
     </li>
    </ul>
    <p id="ue427dc77">
    </p>
    <p class="img-center">
     <img alt="" height="487" id="ue39a30b1" src="https://i-blog.csdnimg.cn/img_convert/ed8f60330a221e6a01639244c497b426.png" width="732"/>
    </p>
    <p id="u7595c48d">
    </p>
    <h4 id="0a26c6fe">
     实验步骤
    </h4>
    <h5 id="CeJ12">
     1.确认安装 mdadm
    </h5>
    <pre id="HphOX"><code>sudo yum install mdadm -y</code></pre>
    <h5 id="X1pDH">
     2.清理现有分区
    </h5>
    <p id="uc7a199a1">
     （因为已经有分区，需要先清理）清楚分区会删除数据 慎重操作
    </p>
    <pre id="E7eR9"><code># 删除现有分区
sudo fdisk /dev/nvme0n2
# 输入 d 删除现有分区
# 输入 w 保存并退出

# 对其他磁盘重复相同操作
sudo fdisk /dev/nvme0n3
sudo fdisk /dev/nvme0n4
sudo fdisk /dev/nvme0n5</code></pre>
    <h5 id="Jo0SK">
     3.创建新的 RAID 分区
    </h5>
    <p id="u22365d88">
     对每个磁盘创建新分区：
    </p>
    <pre id="iSbu7"><code>sudo fdisk /dev/nvme0n2</code></pre>
    <p id="u0d8eab4d">
     <strong>
      在 fdisk 中
     </strong>
     ：
    </p>
    <ol>
     <li id="u9125d28f">
      输入
      <code>
       n
      </code>
      创建新分区
     </li>
     <li id="u5ed63366">
      选择
      <code>
       p
      </code>
      创建主分区
     </li>
     <li id="u6d46031f">
      分区号按默认（1）
     </li>
     <li id="u9ca16932">
      起始扇区按默认
     </li>
     <li id="ue1ad81a8">
      结束扇区输入
      <code>
       +15G
      </code>
      （给每个磁盘分配15GB用于RAID）
     </li>
     <li id="u12a02ac9">
      输入
      <code>
       t
      </code>
      修改分区类型
     </li>
     <li id="u75eb072b">
      输入
      <code>
       fd
      </code>
      设置为 Linux RAID
     </li>
     <li id="u8463f6a4">
      输入
      <code>
       w
      </code>
      保存并退出
     </li>
    </ol>
    <p id="u98c0e74a">
     <strong>
      按照顺序来 具体分配多少空间根据你的需求
     </strong>
    </p>
    <p id="u152701f3">
     对 nvme0n3、nvme0n4、nvme0n5 重复相同操作。
    </p>
    <h5 id="Sbxjo">
     4.创建 RAID 5 阵列
    </h5>
    <pre id="JcPKA"><code>sudo mdadm -Cv /dev/md0 -l 5 -n 4 /dev/nvme0n2p1 /dev/nvme0n3p1 /dev/nvme0n4p1 /dev/nvme0n5p1</code></pre>
    <p id="u7122b426">
     给大家介绍一下每一个参数的作用 （
     <strong>
      不理解的话做出来也没有用
     </strong>
     ）
    </p>
    <h5 id="VjVYo">
     命令分解
    </h5>
    <ul>
     <li id="u67d79a55">
      <code>
       mdadm
      </code>
      : 用于管理Linux软件RAID设备的工具。
     </li>
     <li id="ucd2ab571">
      <code>
       -C
      </code>
      : 创建一个新的RAID设备。
     </li>
     <li id="u258297f6">
      <code>
       -v
      </code>
      : 显示详细输出，便于调试和查看进程。
     </li>
     <li id="u87aed632">
      <code>
       /dev/md0
      </code>
      : 创建的RAID设备的名称，表示第一个RAID设备。
     </li>
     <li id="u06270faa">
      <code>
       -l 5
      </code>
      :
      <strong>
       指定RAID级别为5
      </strong>
      。RAID 5使用条带化和奇偶校验，提供较好的读性能和容错能力。
     </li>
     <li id="u0ba1258b">
      <code>
       -n 4
      </code>
      :
      <strong>
       指定RAID阵列中的磁盘数量为4
      </strong>
      。这意味着RAID 5将使用4个设备来存储数据和奇偶校验信息。
     </li>
     <li id="ub9cd8793">
      <code>
       /dev/nvme0n2p1 /dev/nvme0n3p1 /dev/nvme0n4p1 /dev/nvme0n5p1
      </code>
      : 指
      <strong>
       定参与RAID阵列的具体设备。这些是四个NVMe设备的分区。
      </strong>
     </li>
    </ul>
    <p id="u232ab706">
    </p>
    <p id="u57d0dd02">
    </p>
    <p id="u1e34f42b">
    </p>
    <h5 id="V3yZt">
     5.查看 RAID 状态
    </h5>
    <pre id="pnwMa"><code>cat /proc/mdstat</code></pre>
    <p id="u0d6fb004">
    </p>
    <p class="img-center">
     <img alt="" height="382" id="ci7Km" src="https://i-blog.csdnimg.cn/img_convert/56db1b948c97292430919686e6c975e8.png" width="1359"/>
    </p>
    <p id="ua44eb46e">
     <strong>
      可能会有疑惑 不是刚格式化创建好的分区，并没有创建什么文件数据之类的，为什么还要同步数据
     </strong>
     ：
    </p>
    <ul>
     <li id="u05fa59c5">
      在RAID阵列创建过程中，系统会将所有参与的设备视为一个整体，并进行必要的操作（如奇偶校验的计算和写入），这就是为什么你看到有恢复进度。
     </li>
    </ul>
    <p id="ua026a985">
    </p>
    <p id="u39e68569">
     创建文件系统
    </p>
    <pre id="OyGSG"><code>sudo mkfs.xfs /dev/md0    #创建文件系统

log stripe unit (524288 bytes) is too large (maximum is 256KiB)
log stripe unit adjusted to 32KiB
meta-data=/dev/md0               isize=512    agcount=16, agsize=491008 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=1, sparse=1, rmapbt=0
         =                       reflink=1    bigtime=0 inobtcount=0
data     =                       bsize=4096   blocks=7856128, imaxpct=25
         =                       sunit=128    swidth=384 blks
naming   =version 2              bsize=4096   ascii-ci=0, ftype=1
log      =internal log           bsize=4096   blocks=3840, version=2
         =                       sectsz=512   sunit=8 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0</code></pre>
    <p id="u76b28fbd">
     创建挂载点并挂载
    </p>
    <pre id="QeSEW"><code>sudo mkdir /raiddata
sudo mount /dev/md0 /raiddata</code></pre>
    <p id="u72292f3c">
     设置开机自动挂载
    </p>
    <pre id="PBkhu"><code>echo '/dev/md0 /raiddata xfs defaults 0 0' | sudo tee -a /etc/fstab</code></pre>
    <p id="u1bfa9146">
     验证挂载
    </p>
    <pre id="pNphx"><code>df -hT</code></pre>
    <p id="u7b175329">
     对于四个10GB的磁盘，实际可用空间计算为： 可用空间=(磁盘数量−1)×每个磁盘的容量可用空间=(磁盘数量−1)×每个磁盘的容量 可用空间=(4−1)×10GB=30GB可用空间=(4−1)×10GB=30GB
    </p>
    <p class="img-center">
     <img alt="" height="308" id="u9783a560" src="https://i-blog.csdnimg.cn/img_convert/2a03ff79ad79f3f5a727643658f8bf49.png" width="1009"/>
    </p>
    <p id="ued2d43d2">
    </p>
    <p id="u4aa3ca1c">
    </p>
    <h5 id="GMpu4">
     6.如果需要删除 RAID
    </h5>
    <p id="u33aadfeb">
     如果配置出错需要重来，可以使用以下命令：
    </p>
    <pre id="FUC2b"><code>bash
复制
# 停止 RAID
sudo mdadm --stop /dev/md0

# 清除超级块
sudo mdadm --zero-superblock /dev/nvme0n2p1
sudo mdadm --zero-superblock /dev/nvme0n3p1
sudo mdadm --zero-superblock /dev/nvme0n4p1
sudo mdadm --zero-superblock /dev/nvme0n5p1

# 从 fstab 中删除挂载项
sudo sed -i '/\/dev\/md0/d' /etc/fstab</code></pre>
    <p id="uaf3ca69a">
    </p>
    <h4 id="X5ibv">
     性能测试实验
    </h4>
    <p id="ua85468c0">
     设计一系列实验来测试 RAID 5 的性能和容错能力。这些测试将展示 RAID 5 的主要特性：读写性能、数据冗余和故障恢复能力
    </p>
    <p id="ub1cea0dc">
     <strong>
      这些测试将展示
     </strong>
     ：
    </p>
    <ol>
     <li id="u81984735">
      RAID 5 的读写性能
     </li>
     <li id="u30d7a8dd">
      数据冗余和容错能力
     </li>
     <li id="u62bf8368">
      在磁盘故障时的系统行为
     </li>
     <li id="ua4f2f6cf">
      重建过程的自动化
     </li>
    </ol>
    <p id="ua2dd6c15">
    </p>
    <h4 id="e538bae7">
     实验一：基础性能测试
    </h4>
    <p id="u30986a8a">
     首先创建一个测试文件
    </p>
    <pre id="CyGKU"><code>dd if=/dev/zero of=/raiddata/testfile bs=1M count=1024</code></pre>
    <p id="uf434fe1c">
     这会创建一个 1GB 的测试文件
    </p>
    <p id="u21e63684">
     测试读取速度
    </p>
    <pre id="vVBdz"><code>dd if=/raiddata/testfile of=/dev/null bs=1M</code></pre>
    <p id="u7b7d5010">
     测试写入速度
    </p>
    <pre id="a2se9"><code>dd if=/dev/zero of=/raiddata/testfile2 bs=1M count=1024 conv=fdatasync</code></pre>
    <p id="u2fc7364a">
    </p>
    <p class="img-center">
     <img alt="" height="343" id="u6c3d120e" src="https://i-blog.csdnimg.cn/img_convert/372cbd48c9ab31d616983c284fd0341e.png" width="1136"/>
    </p>
    <p id="u5da7e4ee">
    </p>
    <p id="u10fc118e">
    </p>
    <h4 id="ed541fa3">
     实验二：容错性测试（模拟磁盘故障）
    </h4>
    <ol>
     <li id="uba0801f4">
      首先创建一些重要数据
     </li>
    </ol>
    <pre id="Q4IUU"><code># 创建测试目录
mkdir /raiddata/important_data

# 创建一些测试文件
for i in {1..5}; do
    dd if=/dev/urandom of=/raiddata/important_data/file$i bs=1M count=100
done

# 计算文件的 MD5 值以便后续验证
[root@Centos8 ~]# md5sum /raiddata/important_data/* &gt; /root/checksums.txt
[root@Centos8 ~]# cat /root/checksums.txt 
6640f67939d03071c27bda6ba5cf3c3d  /raiddata/important_data/file1
f5d97e43cb0678fe4f07f2a2221912ac  /raiddata/important_data/file2
16c63489a2ab7a15b857d6a265f33cdd  /raiddata/important_data/file3
af4cde80c4affa9480a56cf7887466dc  /raiddata/important_data/file4
3cadc5fc4dbd6a21d5d0d4e73374a306  /raiddata/important_data/file5</code></pre>
    <p id="u57fc5cde">
    </p>
    <p class="img-center">
     <img alt="" height="492" id="BXOio" src="https://i-blog.csdnimg.cn/img_convert/162cc12b4cca4f11634c809d932491e7.png" width="1061"/>
    </p>
    <p id="u392048a0">
    </p>
    <p id="ud22995cf">
     模拟磁盘故障
    </p>
    <pre id="B0wvU"><code># 查看当前 RAID 状态
cat /proc/mdstat

# 标记其中一个磁盘为故障
sudo mdadm /dev/md0 --fail /dev/nvme0n2p1

# 查看 RAID 状态
cat /proc/mdstat
mdadm --detail /dev/md0</code></pre>
    <p id="u26bf750b">
    </p>
    <p class="img-center">
     <img alt="" height="462" id="uf6bd48b8" src="https://i-blog.csdnimg.cn/img_convert/769e34f7e42ab63d4a91ff1e1100ffe5.png" width="1072"/>
    </p>
    <p id="u539026cd">
    </p>
    <p id="udea8aec0">
     验证数据完整性
    </p>
    <pre id="MTAo3"><code># 验证之前创建的文件是否仍然可以访问
ls -l /raiddata/important_data/

# 验证文件内容是否完整
md5sum -c /root/checksums.txt</code></pre>
    <p id="ub1b8ebb8">
    </p>
    <p class="img-center">
     <img alt="" height="365" id="ufc5da518" src="https://i-blog.csdnimg.cn/img_convert/dc3e677c304b8b811d0a2b4ab5c52c2c.png" width="936"/>
    </p>
    <p id="ube814188">
    </p>
    <h4 id="b46028b2">
     实验三：重建测试
    </h4>
    <p id="uaf8bd2c5">
     移除故障磁盘
    </p>
    <pre id="gNIPZ"><code>sudo mdadm /dev/md0 --remove /dev/nvme0n2p1</code></pre>
    <p id="u5e11d4a0">
     添加新磁盘（假设我们修复了原来的磁盘）
    </p>
    <pre id="Dwltb"><code>sudo mdadm /dev/md0 --add /dev/nvme0n2p1</code></pre>
    <p id="u6c3600b5">
     观察重建过程
    </p>
    <pre id="ZhWUU"><code># 实时监控重建进度
watch -n 1 cat /proc/mdstat</code></pre>
    <p id="uf20ee8d6">
    </p>
    <h4 id="1dc93091">
     实验四：性能测试
    </h4>
    <ol>
     <li id="ued12b2e6">
      安装性能测试工具
     </li>
    </ol>
    <pre id="tbYEG"><code>bash
复制
sudo yum install fio -y</code></pre>
    <ol>
     <li id="u40a8e15a">
      运行综合性能测试
     </li>
    </ol>
    <pre id="KXHgN"><code>bash
复制
# 创建测试配置文件
cat &gt; raid_test.fio &lt;&lt; EOF
[global]
ioengine=libaio
direct=1
group_reporting
time_based
runtime=60

[sequential-read]
stonewall
rw=read
size=1g
directory=/raiddata
bs=1M

[sequential-write]
stonewall
rw=write
size=1g
directory=/raiddata
bs=1M

[random-read]
stonewall
rw=randread
size=1g
directory=/raiddata
bs=4k

[random-write]
stonewall
rw=randwrite
size=1g
directory=/raiddata
bs=4k
EOF

# 运行测试
fio raid_test.fio</code></pre>
    <p id="u0311bdd2">
     执行完成脚本等待性能测试 然后输出各种参数和结果
    </p>
    <p id="u6de06a9f">
    </p>
    <p class="img-center">
     <img alt="" height="344" id="ud25e297f" src="https://i-blog.csdnimg.cn/img_convert/1c3f87f4e2e0291421ee9fa1fcb1ea0d.png" width="1524"/>
    </p>
    <p id="u8629d492">
    </p>
    <h4 id="iZWHV" style="background-color:transparent">
     实验总结
    </h4>
    <p id="u65719492">
     通过本实验，我们成功验证了 RAID 5 的高效读写性能和良好的容错能力。在模拟磁盘故障的情况下，数据仍然保持完整，且重建过程顺利进行。这表明 RAID 5 是一种可靠的存储解决方案，适合需要高可用性和数据安全性的场景。
    </p>
    <p id="u75968a55">
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f6a786a6468646e642f:61727469636c652f64657461696c732f313436323535393334" class_="artid" style="display:none">
 </p>
</div>


