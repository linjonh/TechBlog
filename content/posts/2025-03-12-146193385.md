---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34343837323637352f:61727469636c652f64657461696c732f313436313933333835"
layout: post
title: "从需求文档到测试点基于-OCR-和智能接口的高效图片信息提取与分析"
date: 2025-03-12 00:51:17 +08:00
description: "然而，随着项目规模的不断扩大，需求文档中的内容变得越来越复杂，特别是图片信息往往承载了核心的业务逻辑、流程图、UI 设计、表格说明以及潜在测试点。然而，手动逐页翻阅文档提取图片内容是一项耗时且容易忽略细节的工作，尤其当文档中图片数量较多时，效率问题尤为突出。自动化处理需求文档中的图片信息，不仅是测试工程师提升效率的重要手段，更是未来智能测试的必然趋势。为了帮助测试工程师高效、精准地提取图片信息，并结合智能分析技术实现测试点推理，本文将分享一套完整的技术解决方案。"
keywords: "从需求文档到测试点：基于 OCR 和智能接口的高效图片信息提取与分析"
categories: ['未分类']
tags: ['Python', 'Ocr']
artid: "146193385"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146193385
    alt: "从需求文档到测试点基于-OCR-和智能接口的高效图片信息提取与分析"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146193385
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146193385
cover: https://bing.ee123.net/img/rand?artid=146193385
image: https://bing.ee123.net/img/rand?artid=146193385
img: https://bing.ee123.net/img/rand?artid=146193385
---

# 从需求文档到测试点：基于 OCR 和智能接口的高效图片信息提取与分析

在软件测试的实际工作中，需求文档是测试工程师的重要工具。然而，随着项目规模的不断扩大，需求文档中的内容变得越来越复杂，特别是图片信息往往承载了核心的业务逻辑、流程图、UI 设计、表格说明以及潜在测试点。这些图片信息是测试计划和测试用例设计的关键，但手动解析这些内容不仅耗费时间，还容易遗漏重要细节。

为了帮助测试工程师高效、精准地提取图片信息，并结合智能分析技术实现测试点推理，本文将分享一套完整的技术解决方案。我们将结合
**PaddleOCR**
和
**阿里云百联 deepseek-r1 接口**
，构建一个从需求文档到测试点的自动化处理流程。通过这套流程，测试工程师可以轻松完成图片信息的提取、文字识别、测试点推理以及结果管理。

---

### **1. 为什么图片信息如此重要？**

在现代软件测试中，需求文档中的图片往往包含了以下关键内容：

* **流程图**
  ：展示用户操作流程或系统的核心逻辑。
* **UI 原型图**
  ：定义界面布局、按钮交互逻辑或视觉设计要求。
* **表格说明**
  ：列出字段约束、输入输出规则或接口对接信息。
* **测试点提示**
  ：图片中可能直接或间接暗示功能点或需要验证的逻辑。

这些内容对于测试工程师来说至关重要，直接影响测试用例的设计和测试覆盖率。然而，手动逐页翻阅文档提取图片内容是一项耗时且容易忽略细节的工作，尤其当文档中图片数量较多时，效率问题尤为突出。

---

### **2. 图片信息提取的挑战**

尽管图片信息的重要性不言而喻，但其提取和分析存在以下技术挑战：

1. **识别难度高**
     
   图片中的文字可能因为模糊、噪声、复杂背景而难以识别，OCR （光学字符识别）技术需要足够的准确性来支持多语言和复杂内容。
2. **表格结构复杂**
     
   表格中的内容需要保留结构化信息，且字段间的逻辑关系不能丢失。
3. **多语言支持**
     
   在国际化项目中，图片可能包含中英文混合内容，OCR 必须支持多语言识别。
4. **错误处理和健壮性**
     
   OCR 识别错误可能导致测试点推理失败，需要对结果进行自动校验和纠错。
5. **智能化分析不足**
     
   仅仅识别文字内容并不足够，测试工程师需要从中推导出测试点，这需要结合上下文和业务逻辑进行智能化分析。

---

### **3. 技术解决方案**

为了解决上述问题，我们提出以下技术方案：

1. **图片提取**
     
   使用
   `python-docx`
   库，从需求文档中的目标标题下提取图片，确保处理的内容与测试相关。
2. **OCR 文字识别**
     
   使用 PaddleOCR 进行文字识别，支持中英文混合内容、方向分类，并兼容复杂表格。
3. **错误处理与校验**
     
   通过拼写检查和上下文规则，对 OCR 识别结果进行自动校正，提升健壮性。
4. **智能测试点推理**
     
   将 OCR 结果传递给
   **阿里云百联 deepseek-r1 接口**
   ，通过智能分析引擎推导测试点。
5. **结果管理与输出**
     
   将识别结果与测试点推理结果以结构化方式输出，便于进一步使用。

---

### **4. 技术实现**

以下是完整的技术实现，涵盖图片提取、OCR 识别、测试点推理和接口对接。

#### **4.1 提取需求文档中的图片**

需求文档通常以
`.docx`
格式存储，图片嵌入在指定标题下。通过
`python-docx`
，我们可以精准提取目标标题下的图片：

```python
from docx import Document
from PIL import Image
from io import BytesIO

def extract_images_from_docx(docx_file, target_titles):
    """
    从指定的 docx 文件中提取目标标题下的图片。
    :param docx_file: str - docx 文件路径
    :param target_titles: list - 目标标题列表
    :return: list - 提取的图片（以 PIL Image 格式返回）
    """
    document = Document(docx_file)
    images = []
    capture_images = False

    for paragraph in document.paragraphs:
        # 判断当前段落是否为目标标题
        if paragraph.style.name.startswith("Heading") and paragraph.text.strip() in target_titles:
            capture_images = True
        elif paragraph.style.name.startswith("Heading"):
            capture_images = False

        # 如果在目标标题下，提取图片
        if capture_images:
            for run in paragraph.runs:
                if run.element.xpath('.//w:drawing'):
                    for drawing in run.element.xpath('.//w:blip/@r:embed'):
                        rel = document.part.rels[drawing]
                        image_data = rel.target_part.blob
                        image = Image.open(BytesIO(image_data))
                        images.append(image)

    return images

```

#### **4.2 使用 PaddleOCR 识别图片内容**

PaddleOCR 是一种高精度的 OCR 解决方案，支持中英文内容、方向分类以及复杂表格的识别：

```python
from paddleocr import PaddleOCR
import cv2
import numpy as np

# 初始化 PaddleOCR
ocr = PaddleOCR(use_angle_cls=True, lang="ch")  # 中英文混合识别

def perform_ocr_with_paddle(images):
    """
    使用 PaddleOCR 对图片进行文字识别。
    :param images: list - PIL Image 对象列表
    :return: list - 每张图片的识别结果，按行分组的文本内容
    """
    results = []
    for image in images:
        # OCR 识别
        try:
            # 将 PIL Image 转换为 OpenCV 格式
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            ocr_result = ocr.ocr(cv_image, cls=True)

            # 提取文字
            text_lines = [line[1][0] for line in ocr_result[0]]  # line[1][0] 是识别的文字
            results.append("\n".join(text_lines))  # 每张图片的文本按行拼接
        except Exception as e:
            results.append(f"OCR 识别失败: {e}")
    return results

```

#### **4.3 将结果传递给阿里云百联 deepseek-r1 接口**

为了实现更智能的分析，我们将 OCR 识别的结果传递给阿里云百联 deepseek-r1 接口，由其进行智能化测试点推理：

```python
import requests
import json

def send_to_deepseek(ocr_texts):
    """
    将 OCR 识别结果发送到阿里云百联 deepseek-r1 接口。
    :param ocr_texts: list - OCR 识别的文字内容
    :return: list - deepseek 接口返回的结果
    """
    # 初始化OpenAI客户端
    client = OpenAI(
        # 如果没有配置环境变量，请用百炼API Key替换：api_key="sk-xxx"
        api_key='sk-xxx',  # todo 此处需更换
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )

    reasoning_content = ""  # 定义完整思考过程
    answer_content = ""  # 定义完整回复
    is_answering = False  # 判断是否结束思考过程并开始回复

    # 创建聊天完成请求
    completion = client.chat.completions.create(
        model="deepseek-r1",  # 此处以 deepseek-r1 为例，可按需更换模型名称
        messages=[
            {'role': 'user', 'content': f'识别内容： {ocr_texts}， 提示词：{prompt_param}'}
        ],
        stream=True,
        # 解除以下注释会在最后一个chunk返回Token使用量
        # stream_options={
        #     "include_usage": True
        # }
    )

    print("\n" + "=" * 20 + "思考过程" + "=" * 20 + "\n")

    for chunk in completion:
        # 如果chunk.choices为空，则打印usage
        if not chunk.choices:
            print("\nUsage:")
            print(chunk.usage)
        else:
            delta = chunk.choices[0].delta
            # 打印思考过程
            if hasattr(delta, 'reasoning_content') and delta.reasoning_content != None:
                print(delta.reasoning_content, end='', flush=True)
                reasoning_content += delta.reasoning_content
            else:
                # 开始回复
                if delta.content != "" and not is_answering:
                    print("\n" + "=" * 20 + "完整回复" + "=" * 20 + "\n")
                    is_answering = True
                # 打印回复过程
                print(delta.content, end='', flush=True)
                answer_content += delta.content
    return answer_content

```

#### **4.4 主流程**

整合上述功能，形成完整的主流程：

```python
def main():
    # 配置输入文件路径和目标标题
    docx_file = "需求文档.docx"  # 替换为实际文件路径
    target_titles = ["功能需求", "测试用例"]  # 替换为实际标题
    api_url = "https://deepseek.aliyun.com/api/v1/r1"  # 替换为实际 deepseek 接口地址
    api_key = "your_api_key_here"  # 替换为实际 API Key

    # 提取图片
    images = extract_images_from_docx(docx_file, target_titles)
    if not images:
        print("未找到任何图片，请检查标题是否正确。")
        return

    # OCR 识别
    ocr_texts = perform_ocr_with_paddle(images)

    # 发送到 deepseek 接口
    deepseek_results = send_to_deepseek(ocr_texts, api_url, api_key)

    # 输出结果
    for i, (ocr_text, result) in enumerate(zip(ocr_texts, deepseek_results), 1):
        print(f"\n图片 {i} 识别的文字内容：")
        print(ocr_text)
        print(f"\n图片 {i} 的 deepseek 返回结果：")
        print(json.dumps(result, indent=2, ensure_ascii=False))

```

---

### **5. 效果与总结**

通过本文提供的方案，测试工程师可以：

1. **高效提取图片信息**
   ：无需手动逐页翻阅文档，自动提取指定标题下的图片。
2. **精准识别文字内容**
   ：结合 PaddleOCR，支持中英文混合内容和复杂表格。
3. **智能测试点推理**
   ：通过 deepseek 接口，将图片内容转化为有价值的测试点。
4. **提升工作效率**
   ：显著减少人工操作时间，降低错误率。

自动化处理需求文档中的图片信息，不仅是测试工程师提升效率的重要手段，更是未来智能测试的必然趋势。希望本文的解决方案能为您的工作带来实质性的帮助！