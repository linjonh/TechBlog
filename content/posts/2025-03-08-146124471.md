---
arturl_encode: "68747470733a2f2f:626c6f672e6373646e2e6e65742f6c756f636f6e673332312f:61727469636c652f64657461696c732f313436313234343731"
layout: post
title: "结合-Pandas-使用-SQLite3-实战"
date: 2025-03-08 22:50:49 +0800
description: "通过 Pandas + SQLite3 的组合，你可以：✅快速导入/导出数据：告别手动拼接 SQL 语句。✅无缝衔接数据分析：清洗、计算、可视化后直接入库。✅处理海量数据：分块读写避免内存爆炸。下一步建议尝试将 Excel/CSV 文件自动同步到 SQLite3 数据库。学习使用sqlalchemy库增强 SQL 操作能力。"
keywords: "结合 Pandas 使用 SQLite3 实战"
categories: ['未分类']
tags: ['数据库', 'Sqlite', 'Pandas']
artid: "146124471"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146124471
    alt: "结合-Pandas-使用-SQLite3-实战"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146124471
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146124471
cover: https://bing.ee123.net/img/rand?artid=146124471
image: https://bing.ee123.net/img/rand?artid=146124471
img: https://bing.ee123.net/img/rand?artid=146124471
---

# 结合 Pandas 使用 SQLite3 实战

## 结合 Pandas 使用 SQLite3 实战

**让数据分析更高效！用 Pandas 直接读写 SQLite3 数据，告别手动拼接 SQL 语句！**

---

### 1 环境准备

确保已安装
`pandas`
和
`sqlite3`
（前者需单独安装，后者是 Python 内置）：

```bash
pip install pandas

```

---

### 2 从 SQLite3 读取数据到 DataFrame

### 基础用法：读取整个表

```python
import pandas as pd
import sqlite3

# 连接到数据库
conn = sqlite3.connect('test.db')

# 读取 users 表到 DataFrame
df = pd.read_sql('SELECT * FROM users', conn)
print(df.head())  # 查看前5行数据

# 关闭连接
conn.close()

```

### 高级用法：筛选和聚合

```python
query = '''
    SELECT 
        name, 
        AVG(age) as avg_age   -- 计算平均年龄
    FROM users 
    WHERE age > 20 
    GROUP BY name
'''
df = pd.read_sql(query, conn)
print(df)

```

---

### 3 将 DataFrame 写入 SQLite3

### 基本写入（全量覆盖）

```python
# 创建一个示例 DataFrame
data = {
    'name': ['David', 'Eve'],
    'age': [28, 32],
    'email': ['david@test.com', 'eve@test.com']
}
df = pd.DataFrame(data)

# 写入到 users 表（全量覆盖）
df.to_sql(
    name='users',     # 表名
    con=conn,         # 数据库连接
    if_exists='replace',  # 如果表存在，直接替换（慎用！）
    index=False       # 不保存 DataFrame 的索引列
)
conn.commit()

```

### 追加数据（增量写入）

```python
df.to_sql(
    name='users',
    con=conn,
    if_exists='append',  # 追加到现有表
    index=False
)
conn.commit()

```

---

### 4 实战场景：数据清洗 + 入库

假设有一个 CSV 文件
`dirty_data.csv`
，需要清洗后存入 SQLite3：

```csv
id,name,age,email
1, Alice,30,alice@example.com
2, Bob , invalid, bob@example.com  # 错误年龄
3, Charlie,35,missing_email

```

### 步骤 1：用 Pandas 清洗数据

```python
# 读取 CSV
df = pd.read_csv('dirty_data.csv')

# 清洗操作
df['age'] = pd.to_numeric(df['age'], errors='coerce')  # 无效年龄转为 NaN
df = df.dropna(subset=['age'])                        # 删除年龄无效的行
df['email'] = df['email'].fillna('unknown')            # 填充缺失邮箱
df['name'] = df['name'].str.strip()                   # 去除名字前后空格

print(df)

```

### 步骤 2：写入数据库

```python
with sqlite3.connect('test.db') as conn:
    # 写入新表 cleaned_users
    df.to_sql('cleaned_users', conn, index=False, if_exists='replace')
    
    # 验证写入结果
    df_check = pd.read_sql('SELECT * FROM cleaned_users', conn)
    print(df_check)

```

---

### 5 性能优化：分块写入大数据

处理超大型数据时（如 10 万行），避免一次性加载到内存：

```python
# 分块读取 CSV（每次读 1 万行）
chunk_iter = pd.read_csv('big_data.csv', chunksize=1000)

with sqlite3.connect('big_db.db') as conn:
    for chunk in chunk_iter:
        # 对每个块做简单处理
        chunk['timestamp'] = pd.to_datetime(chunk['timestamp'])
        # 分块写入数据库
        chunk.to_sql(
            name='big_table',
            con=conn,
            if_exists='append',  # 追加模式
            index=False
        )
    print("全部写入完成！")

```

---

### 6 高级技巧：直接执行 SQL 操作

Pandas 虽然强大，但复杂查询仍需直接操作 SQL：

```python
# 创建临时 DataFrame
df = pd.DataFrame({'product': ['A', 'B', 'C'], 'price': [10, 200, 150]})

# 写入 products 表
df.to_sql('products', conn, index=False, if_exists='replace')

# 执行复杂查询（连接 users 和 orders 表）
query = '''
    SELECT 
        u.name,
        p.product,
        p.price
    FROM users u
    JOIN orders o ON u.id = o.user_id
    JOIN products p ON o.product_id = p.id
    WHERE p.price > 10
'''
result_df = pd.read_sql(query, conn)
print(result_df)

```

---

### 7 避坑指南

**数据类型匹配问题**
：

* SQLite 默认所有列为
  `TEXT`
  ，但 Pandas 会自动推断类型。
* 写入时可用
  `dtype`
  参数手动指定类型：

  ```python
  df.to_sql('table', conn, dtype={'age': 'INTEGER', 'price': 'REAL'})

  ```

2. **主键和索引**
   ：

   * Pandas 不会自动创建主键或索引，需提前用 SQL 语句定义表结构。
3. **性能瓶颈**
   ：

   * 写入大量数据时，关闭事务自动提交可提速：

     ```python
     with conn:
         df.to_sql(...)  # 使用上下文管理器自动提交

     ```

---

### 8 总结

通过 Pandas + SQLite3 的组合，你可以：
  
✅
**快速导入/导出数据**
：告别手动拼接 SQL 语句。
  
✅
**无缝衔接数据分析**
：清洗、计算、可视化后直接入库。
  
✅
**处理海量数据**
：分块读写避免内存爆炸。

**下一步建议**
：

* 尝试将 Excel/CSV 文件自动同步到 SQLite3 数据库。
* 学习使用
  `sqlalchemy`
  库增强 SQL 操作能力。