---
layout: post
title: "前沿重器18-KDD21-淘宝向量检索"
date: 2024-11-26 11:00:41 +0800
description: "前沿重器栏目主要给大家分享各种大厂、顶会的论文和分享，从中抽取关键精华的部分和大家分享，和大家一起把"
keywords: "embedding-based product retrieval in taobao search代码"
categories: ['未分类']
tags: ['算法', '机器学习', '推荐系统', '大数据', '人工智能']
artid: "121200235"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=121200235
  alt: "前沿重器18-KDD21-淘宝向量检索"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=121200235
featuredImagePreview: https://bing.ee123.net/img/rand?artid=121200235
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     前沿重器[18] | KDD21-淘宝向量检索
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="./../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="./../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <div id="js_content">
     <p style="text-align:center;">
      <strong>
       前沿重器
      </strong>
     </p>
     <p>
      栏目主要给大家分享各种大厂、顶会的论文和分享，从中抽取关键精华的部分和大家分享，和大家一起把握前沿技术。具体介绍：
      <a href="https://blog.csdn.net/baidu_25854831/article/details/120258845">
       仓颉专项：飞机大炮我都会，利器心法我还有
      </a>
     </p>
     <p>
      近期，我再次总结了我的历史文章，累积起来有50w字，百余篇文章了，有兴趣可以拿来看看，获取方式：
      <a href="https://blog.csdn.net/baidu_25854831/article/details/120644275">
       七夕清流，百余篇累计50w字文章合集发布
      </a>
      。
     </p>
     <p>
      往期回顾
     </p>
     <ul>
      <li>
       <p>
        <a href="https://blog.csdn.net/baidu_25854831/article/details/120928865">
         前沿重器[13] | 知乎query改写思路启示
        </a>
       </p>
      </li>
      <li>
       <p>
        <a href="https://blog.csdn.net/baidu_25854831/article/details/120928865">
         前沿重器[14] | 美团小样本学习技术总结
        </a>
       </p>
      </li>
      <li>
       <p>
        <a href="https://blog.csdn.net/weixin_43935696/article/details/120593112">
         前沿重器[15] | R-Dropout——一次不行就两次
        </a>
       </p>
      </li>
      <li>
       <p>
        <a href="https://blog.csdn.net/baidu_25854831/article/details/120928865">
         前沿重器[16] | 美团搜索ner技术启示（上）
        </a>
       </p>
      </li>
      <li>
       <p>
        <a href="https://blog.csdn.net/baidu_25854831/article/details/120818958">
         前沿重器[17] | 美团搜索ner技术启示（下）
        </a>
       </p>
      </li>
     </ul>
     <p>
      KDD21中其实涌现了不少搜索相关的文章，其中我自己比较喜欢的一篇就是淘宝的这篇，这篇看着工业风非常浓厚，作者对搜索场景，尤其是自己的电商景非常熟悉，在这个理解下，文章有很多针对性的策略和思考，业务效果的有效提升根源便在此，我们来一起看看这篇文章吧。
     </p>
     <ul>
      <li>
       <p>
        原论文：
        <strong>
         Embedding-based Product Retrieval in Taobao Search
        </strong>
       </p>
      </li>
      <li>
       <p>
        知乎文章：https://zhuanlan.zhihu.com/p/409390150
       </p>
      </li>
     </ul>
     <p>
      这里可能部分内容会涉及向量检索和向量表征的背景知识，可以看看之前我写的这篇：
      <a href="https://blog.csdn.net/baidu_25854831/article/details/109567836">
       心法利器[16] | 向量表征和向量召回
      </a>
     </p>
     <h3>
      出发点和思考
     </h3>
     <p>
      向量召回的确是一个新潮的玩意，现在很多人也很喜欢直接就开始尝试，但是在这篇文章中，给出了现在向量召回的一些比较本质的问题点，一方面是针对实际应用，另一方面是针对现在研究论文焦点和方法的问题，大概总结如下：
     </p>
     <ul>
      <li>
       <p>
        搜索query大都较短，且一定程度缺少语法结构，例如“鸿星尔克球鞋”之类的，是光杆名词。
       </p>
      </li>
      <li>
       <p>
        虽然大多数都有用户的历史数据，可以计算偏好，但是一般而言搜索是独立的，query本身代表一个简单需求，虽然可以用历史数据，但是需要经过挑选。
       </p>
      </li>
      <li>
       <p>
        时效性问题，模型短期内效果还行，但是长期效果会下降。
       </p>
      </li>
      <li>
       <p>
        重个性化轻相关性，搜索本质是为query服务，太重视个性化就会导致不一定能满足用户当前的需求，模型的长期效果不行一定程度和这个是有关系的。
       </p>
      </li>
     </ul>
     <p>
      因此作者提出了一系列的方案对向量检索表征进行调整，主要的贡献点如下：
     </p>
     <ul>
      <li>
       <p>
        提出一个多粒度深度语义检索模型，能动态捕捉用户当前query和历史个人行为的关系并体现在在线行为推理上。
       </p>
      </li>
      <li>
       <p>
        用softmax交叉熵替换hinge作为训练目标，提升预测效果和收敛速度。
       </p>
      </li>
      <li>
       <p>
        提出两种方式令搜索得到的内容更加可控相关。
       </p>
      </li>
      <li>
       <p>
        效果试验和分析。
       </p>
      </li>
     </ul>
     <h3>
      模型整体设计
     </h3>
     <p>
      模型依旧是论文的根本（这个基本还是跑不掉的），先来看看吧，这里直接引用蘑菇先生的图吧：
     </p>
     <img alt="e0bbf7cf9b50476d76a50ab5e5231519.png" src="https://i-blog.csdnimg.cn/blog_migrate/a8c5eaeca5a3d5791a9a306128fd5757.png">
      <p>
       整个模型可谓是非常壮观了，所谓外行看热闹内行看门道，这里我们来看看这里建具体都做了什么东西吧。
      </p>
      <p>
       我理解这里其实还是双塔，用户塔和物料塔，这个非常符合向量搜索表征的需要，用户塔非常重，里面又有两个大块，分别是query塔和行为序列塔，而物料塔则比较简单，主要是一些和title、id有关的信息处理和表征。
      </p>
      <p>
       后面我们就来一个一个看。
      </p>
      <h4>
       query理解塔
      </h4>
      <p>
       em，专业说法是多粒度语义单元，就“非常有次时代的感觉”，其实就是一个做query理解的，这里非常潮流的采用了“多粒度”的方案，大事比多粒度来的更加热闹，这里总共倒腾出了6个表征方式，这6个表征直接concat：
      </p>
      <ol>
       <li>
        <p>
         字级别unigram的mean pooling。
        </p>
       </li>
       <li>
        <p>
         字级别的bigram的mean pooling。
        </p>
       </li>
       <li>
        <p>
         词级别的mean pooling。
        </p>
       </li>
       <li>
        <p>
         词级别过了transformer后的mean pooling。（为啥不用流行点的CLS呢，并不知道，问就是效果不好吧）
        </p>
       </li>
       <li>
        <p>
         历史词级别，基于词级别的mean pooling的attention。
        </p>
       </li>
       <li>
        <p>
         1-5的求和。
        </p>
       </li>
      </ol>
      <p>
       这里的关注点是5，来看看5的公式：
      </p>
      <p>
       attention应该是被作者玩明白了，其实就是找历史query中和当前query最接近的部分，这个信息无疑对用户当前的query的理解更加深入了。
      </p>
      <h4>
       行为序列塔
      </h4>
      <p>
       行为上，就是3剑客，实时、短期和长期，这里对应的就是用户点击的序列，对物品的表征也就是ID和其他商品信息（类目信息、品牌信息等）做嵌入，然后做pooling后拼接。
      </p>
      <p>
       广告和推荐那就是目标注意力机制，那搜索里用的就是query了，结合query的表征，开始做attention。
      </p>
      <p>
       而与之不同的是，这里作者加了个0向量到点击行为序列前，这个细节文章没有聊但是其实背后的思想却很有借鉴意义，这里体现了搜索的“需求独立性”，这个名字是我起的，但是的确如此，用户query的搜素需求是相对独立，这次的很大可能是和之前的行为无关的，之前搜索过“洗衣机”的用户，最近可能搜的是“乐高积木”，此时还把历史信息引入，意义就不太大（这里非常克制，用的是不太大，不见的没有，例如点击的洗衣机物料很可能代表了用户的消费偏好，这个消费偏好会体现了用户会需要什么样的乐高积木），所以这个0向量背后体现了对搜索业务和用户需求特点的理解。
      </p>
      <p>
       继续聊实时、短期、长期三个用户行为序列的不同处理，无论是图上还是公式推导表达，都体现了这点，也很大程度体现了作者对这些业务的理解。
      </p>
      <ul>
       <li>
        <p>
         实时序列用的是LSTM+多头自注意力机制，因为实时点击能体现用户当前需求，甚至还有一定的需求演化，然后用dot注意力融合query和实时序列信息表征。
        </p>
       </li>
       <li>
        <p>
         短期序列则直接用多头注意力，相比实时序列不太去捕捉需求的演化了，而是抽取里面比较关键的信息，然后用dot注意力融合query和实时序列信息表征。
        </p>
       </li>
       <li>
        <p>
         长期序列用的点击行为比较多，物料、商店、叶子节点类目、品牌，每个行为又有点击、购买和收藏，融合后进行注意力机制再用dot注意力融合query和实时序列信息表征。
        </p>
       </li>
      </ul>
      <h4>
       行为序列和query理解的融合
      </h4>
      <p>
       这里用了concat+self-att的融合，同时非常“BERT”地加了个'[CLS]'。
      </p>
      <h4>
       物料层
      </h4>
      <p>
       物料层很简单，真的很简单，看公式：
      </p>
      <p>
       就是把词及其对应的embedding进行平均化，这里作者提出一个观点，LSTM和Transformer效果都不如简单的平均化，这里我的观点是现在淘宝商家的标题大都也没啥语法结构，句内也是很多优化过的检索词，所以没必要做过多复杂的抽取。
      </p>
      <p>
       有关两者的融合，这里不再展开，向量检索由于最近邻检索的原因，融合的相似度计算就局限在了余弦、欧式等几种简单的形式了。
      </p>
      <h3>
       损失和训练
      </h3>
      <h4>
       softmax交叉熵代替hinge
      </h4>
      <p>
       与之前的论文聊的不同，这里作者提出的是用softmax交叉熵代替hinge，这里的原因和搜索中召回TOP-K有关，所以此处需要全局的相关性对比，显然hinge并不够，因为长尾部分直接就没算了，而softmax交叉熵却可以，另一方面从预测性能来看，准确性和收敛性（有空可以自己去推一下损失）也会好很多。对于triple形式的数据有：
      </p>
      <h4>
       平滑噪音数据
      </h4>
      <p>
       虽然搜索下用户的核心要求是找到和query相关的内容，但不代表文字越接近用户就会点，除了一些涉黄猎奇之类的无关也可能点的东西外，还会有一些类似图片、标题、好评的因素会影响用户的点击，但是我们目前没考虑进去，这个有没有方式解决，作者给出的答案是有的，其重要的假设就是“不完全信任用户的点击标签”，这里引入了一个温度参数，意在控制模型对标签的信任程度，越小（趋向于0），则越信任，反之则越不信任，作者构造的公式是这样的：
      </p>
      <h4>
       生成难负例
      </h4>
      <p>
       这一直是个语义相似度的难题，其根本的收益在于让模型在训练过程中了解分类的真实边界，而不是一个两点之间任意方向任意位置均可的边界，作者提出了一个方法，给定一个triple样本，这个是一个随机负例，首先用在物料池中找到点积最大的负样本集（看好，是集），用加权的方式混入一下正样本的信息：
      </p>
      <p>
       其中是一个服从均匀分布（）的随机变量，因为是一个混合因子，所以肯定有。显然越大，混合样本的正样本含量越高。
      </p>
      <h3>
       淘宝搜索内部架构
      </h3>
      <img alt="b370a5daa38c1af74b24608a3d4276b6.png" src="https://i-blog.csdnimg.cn/blog_migrate/53576f5aaa826498208ebfa0e550341e.png">
       <p>
        论文总是会讲述新的东西，但是经典可靠的好东西总不会丢弃，成为最稳固基本的存在。
       </p>
       <p>
        首先可以看到，在召回阶段，除了本文提到的基于embedding的搜索，协同过滤和倒排索引依旧存在，可以侧面说明，向量检索在现阶段很难独立存在于搜索系统中，这点大家在架构设计中需要保证。
       </p>
       <p>
        第二，排序不是一个简单的排序就完事了，可以看到这里经过了非常多轮的排序，预排序、相关性排序、正式的排序、重排序和加入了内容视频、广告的混合排序，各个排序有各个排序的作用，作者提到，前面几层排序其实本质是删掉那些肯定不对的召回内容。
       </p>
       <p>
        展开来说，模型这个东西，肯定要考虑在线和离线的。作者提到，离线部分主要是构造和训练模型，当然还有一些提前可以训练好的东西，最直接的就是这个物料了，当然了由于物料众多，所以需要KMEANS或者是INT8之类的方式缩小从而提升效率。在线部分则比较直接了，基本就是推理和查询。
       </p>
       <p>
        而另外更加要聊的，就是相关性控制这个问题了，众所周知向量召回考虑的是语义，反而忽略了文本层面的相似性（要知道，用户角度更多考虑的是字面的信息），尤其是精准的全匹配，所以此处要充分考虑好文本层面的匹配，这里可以采用query理解得到的信息进行约束，例如这样：
       </p>
       <blockquote>
        <p>
         (All Ann results) and (Brand=Adids) and (Category: shoes)
        </p>
       </blockquote>
       <h3>
        小结
       </h3>
       <p>
        整篇文章读下来，真的感觉很实用，作者对搜索的业务理解很深，能洞察搜索的业务特点，例如query的特定，也能够发现目前一些方案的缺点（例如效果短期好长期差，文本层面相似度不足等），同时对模型的理解也很深，从多粒度的query理解到其融合和attention计算，是非常值得学习和讨论的，知识点上，业务理解能力上，还有整体方法论上。
       </p>
       <p style="text-align:center;">
        <img alt="6d47b2b602afc26d5611e2ed709e4cb6.png" src="https://i-blog.csdnimg.cn/blog_migrate/1b0a2da87874776acc123f5da1c74b5e.png"/>
       </p>
      </img>
     </img>
    </div>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f67:2e6373646e2e6e65742f62616964755f32353835343833312f:61727469636c652f64657461696c732f313231323030323335" class_="artid" style="display:none">
 </p>
</div>
