---
arturl_encode: "68747470733a2f2f:626c6f672e6373646e2e6e65742f6b3331363337383038352f:61727469636c652f64657461696c732f313436333033353935"
layout: post
title: "新手村数据预处理-特征缩放"
date: 2025-03-16 23:25:07 +08:00
description: "方法描述适用场景优点缺点标准化将特征转换为均值为0，标准差为1的标准正态分布。线性回归、逻辑回归、SVM、KNN、神经网络等。不受数据范围影响，适用于大多数算法。对异常值较为敏感，可能导致极端值的影响被放大。归一化（Min-Max缩放）将特征缩放到一个特定范围（通常是[0, 1]）。需要将数据限制在特定范围内的情况。数据范围固定，适用于需要严格控制输出范围的场景。受数据范围影响较大，对异常值敏感，可能导致信息丢失。"
keywords: "新手村：数据预处理-特征缩放"
categories: ['机器学习']
tags: ['线性回归', '算法', '机器学习']
artid: "146303595"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146303595
    alt: "新手村数据预处理-特征缩放"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146303595
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146303595
cover: https://bing.ee123.net/img/rand?artid=146303595
image: https://bing.ee123.net/img/rand?artid=146303595
img: https://bing.ee123.net/img/rand?artid=146303595
---

# 新手村：数据预处理-特征缩放

## 新手村：数据预处理-特征缩放

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/978c2a5927814f988c755eb75d397ce9.png)

> `特征缩放（Feature Scaling`
> ）是数据预处理中的一个重要步骤，特别是在应用某些机器学习算法时。特征缩放可以使不同尺度的特征具有相同的量级，从而提高模型训练的效率和性能。常见的特征缩放方法包括标准化（Standardization）和归一化（Normalization）。

#### 常见的特征缩放方法

1. **标准化（Standardization）**

   * 将特征转换为均值为0，标准差为1的标准正态分布。
   * 公式：

     x
     ′
     =
     x
     −
     μ
     σ
     x' = \frac{x - \mu}{\sigma}






     x










     ′



     =

















     σ












     x

     −

     μ

     ​

     + x
       ′
       x'






       x










       ′
       是缩放后的特征值
     + x
       x





       x
       是原始特征值
     + μ
       \mu





       μ
       是特征的均值
     + σ
       \sigma





       σ
       是特征的标准差
2. **归一化（Normalization）**

   * 将特征缩放到一个特定范围（通常是[0, 1]或[-1, 1]）。
   * 最常用的归一化方法是Min-Max缩放：
     + 公式：

       x
       ′
       =
       x
       −
       x
       min
       x
       max
       −
       x
       min
       x' = \frac{x - x_{\text{min}}}{x_{\text{max}} - x_{\text{min}}}






       x










       ′



       =


















       x











       max

       ​


       −


       x











       min

       ​













       x

       −


       x











       min

       ​


       ​

       - x
         ′
         x'






         x










         ′
         是缩放后的特征值
       - x
         x





         x
         是原始特征值
       - x
         min
         x_{\text{min}}






         x











         min

         ​

         和

         x
         max
         x_{\text{max}}






         x











         max

         ​

         分别是特征的最小值和最大值

#### 特征缩放的应用场景

* **需要特征缩放的算法**
  ：

  + 线性回归、逻辑回归、支持向量机（SVM）、K近邻（KNN）、神经网络等。
  + 这些算法对特征的尺度敏感，特征缩放可以加快收敛速度并提高模型性能。
* **不需要特征缩放的算法**
  ：

  + 决策树、随机森林等基于树的算法，这些算法不依赖于特征的尺度。

#### 示例代码

以下是一个使用Python和
`scikit-learn`
库进行特征缩放的示例代码：

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# 创建一个示例数据集
data = {
    'A': [1, 2, 3, 4, 5],
    'B': [100, 200, 300, 400, 500],
    'C': [0.1, 0.2, 0.3, 0.4, 0.5]
}

df = pd.DataFrame(data)

print("原始数据：")
print(df)

# 标准化
scaler_standard = StandardScaler()
df_standardized = pd.DataFrame(scaler_standard.fit_transform(df), columns=df.columns)
print("\n标准化后的数据：")
print(df_standardized)

# 归一化（Min-Max缩放）
scaler_minmax = MinMaxScaler()
df_normalized = pd.DataFrame(scaler_minmax.fit_transform(df), columns=df.columns)
print("\n归一化后的数据：")
print(df_normalized)

```

#### 输出结果解释

##### 原始数据

```plaintext
原始数据：
     A      B    C
0    1    100  0.1
1    2    200  0.2
2    3    300  0.3
3    4    400  0.4
4    5    500  0.5

```

##### 标准化后的数据

```plaintext
标准化后的数据：
          A         B         C
0 -1.414214 -1.414214 -1.414214
1 -0.707107 -0.707107 -0.707107
2  0.000000  0.000000  0.000000
3  0.707107  0.707107  0.707107
4  1.414214  1.414214  1.414214

```

##### 归一化后的数据

```plaintext
归一化后的数据：
     A    B    C
0  0.0  0.0  0.0
1  0.25 0.25 0.25
2  0.5  0.5  0.5
3  0.75 0.75 0.75
4  1.0  1.0  1.0

```

#### 总结表格

| 方法 | 描述 | 适用场景 | 优点 | 缺点 |
| --- | --- | --- | --- | --- |
| **标准化** | 将特征转换为均值为0，标准差为1的标准正态分布。 | 线性回归、逻辑回归、SVM、KNN、神经网络等。 | 不受数据范围影响，适用于大多数算法。 | 对异常值较为敏感，可能导致极端值的影响被放大。 |
| **归一化（Min-Max缩放）** | 将特征缩放到一个特定范围（通常是[0, 1]）。 | 需要将数据限制在特定范围内的情况。 | 数据范围固定，适用于需要严格控制输出范围的场景。 | 受数据范围影响较大，对异常值敏感，可能导致信息丢失。 |