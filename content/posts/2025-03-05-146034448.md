---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f6c69756775697a686f6e672f:61727469636c652f64657461696c732f313436303334343438"
layout: post
title: "OllamaDeepseek-R1Continue本地集成VScode"
date: 2025-03-05 09:47:16 +0800
description: "成功把 Ollama、Deepseek - R1 和 Continue 集成到 VScode 之后，确实避免了很多问题！先说说数据安全，以前总在网络搜索，心里总有点不踏实，现在都在本地搞定，再也不用担心信息泄露了，做涉及敏感信息的项目，安全感满满，对咱开发者来说，这可太香了。不过，这集成也不是十全十美的。对电脑硬件要求有点高，如果电脑配置不太给力，模型响应速度就会变慢，有时候等得还挺着急，多少还是会影响点效率。但总体来说，这次集成真的让我学到了不少，绝对是一次超值得尝试的技术实践！强烈推荐大家也试试！"
keywords: "continue本地自动完成"
categories: ['未分类']
tags: ['编辑器', 'Vscode', 'Llama', 'Ide', 'Deepseek']
artid: "146034448"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146034448
    alt: "OllamaDeepseek-R1Continue本地集成VScode"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146034448
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146034448
cover: https://bing.ee123.net/img/rand?artid=146034448
image: https://bing.ee123.net/img/rand?artid=146034448
img: https://bing.ee123.net/img/rand?artid=146034448
---

# Ollama+Deepseek-R1+Continue本地集成VScode

### **一、** Ollama+Deepseek-R1+Continue **本地集成VScode**

##### 1）安装前知识点

Continue 介绍

详情可参照官网：
[continue官网](https://www.continue.dev/ "continue官网")

Continue 是 Visual Studio Code 和 JetBrains 中领先的开源 AI 代码助手。

•在侧边栏中进行聊天以理解和迭代代码。

•自动补全，以便在输入时接收内联代码建议。

•编辑功能可让你无需离开当前文件即可修改代码。

•操作功能用于为常见用例建立快捷方式。

##### 2）安装 VSCode

首先，确保你已经安装了 VS Code 编辑器。如果尚未安装，可以从 VSCode 官网（
[Download Visual Studio Code - Mac, Linux, Windows](https://code.visualstudio.com/download "Download Visual Studio Code - Mac, Linux, Windows")
）下载并安装。

##### 3）安装conitinue插件

a.打开 VSCode 编辑器。

b.在 VSCode 的插件中心，搜索 “Continue”。

c.找到 “Continue” 插件后，点击 “安装” 按钮进行安装。安装完成后，在 VSCode 左侧侧栏中会增加一个对应的图标，这就是 Continue 的主界面。

![](https://i-blog.csdnimg.cn/img_convert/986238bc12ef5d28a3e6adce98cfe80f.png)

安装完成之后，重启下continue，vscode上就会出现continue图标，点击“continue”出现主界面

##### 4）本地集成VScode配置

点击continue输入框的左下角，点击“+ Add Chat model”，然后进行配置

![](https://i-blog.csdnimg.cn/img_convert/94fbf98aa4a2417c189dcb5d42830447.png)

配置Provider为“Ollama”，Modal选择“Autodetect”，点击“Connect”

![](https://i-blog.csdnimg.cn/img_convert/8ffacf4323b1fa93871bed1664ae0dd9.png)

到这里就配置完成了，让我们测试下成果吧，输入问题“你是什么模型？”

![](https://i-blog.csdnimg.cn/img_convert/44b15eeca1143588d3b5d4b38b99e0d3.png)

通过以上步骤，你就完成了 Continue 在 VSCode 中的本地集成，能够借助其强大的功能提升编程效率，享受更加智能、便捷的开发体验。

### 二、总结

成功把 Ollama、Deepseek - R1 和 Continue 集成到 VScode 之后，确实避免了很多问题！先说说数据安全，以前总在网络搜索，心里总有点不踏实，现在都在本地搞定，再也不用担心信息泄露了，做涉及敏感信息的项目，安全感满满，对咱开发者来说，这可太香了。

不过，这集成也不是十全十美的。对电脑硬件要求有点高，如果电脑配置不太给力，模型响应速度就会变慢，有时候等得还挺着急，多少还是会影响点效率。但总体来说，这次集成真的让我学到了不少，绝对是一次超值得尝试的技术实践！强烈推荐大家也试试！