---
layout: post
title: 学习大数据必须掌握哪些核心技术
date: 2024-11-26 17:05:49 +08:00
categories: ['数据库']
tags: ['数据库', '学习', '大数据', 'Hadoop', 'Docker']
image:
    path: https://img-blog.csdnimg.cn/4c1871c445b24202bc145b08000e18df.png?x-oss-process=image/resize,m_fixed,h_150
    alt: 学习大数据必须掌握哪些核心技术
artid: 126590224
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=126590224
featuredImagePreview: https://bing.ee123.net/img/rand?artid=126590224
---

# 学习大数据必须掌握哪些核心技术？

大数据发展到今天，已经是越来越成熟，无论是大型互联网公司，还是小型的创业公司，都能看见大数据的身影。那么，学习大数据必须掌握哪些核心技术呢？

**一、数据采集与预处理**

数据采集就是将这些包括移动互联网数据、社交网络的数据等各种来源的数据，写入数据仓库中，把零散的数据整合在一起，对这些数据进行综合分析。

Flume NG作为实时日志收集系统，支持在日志系统中定制各类数据发送方，用于收集数据，同时，对数据进行简单处理，并写到各种数据接收方(比如文本，HDFS，Hbase等)。

NDC，Netease Data Canal，直译为网易数据运河系统，是网易针对结构化数据库的数据实时迁移、同步和订阅的平台化解决方案。

Logstash是开源的服务器端数据处理管道，能够同时从多个来源采集数据、转换数据，然后将数据发送到您最喜欢的 “存储库” 中。

Sqoop，用来将关系型数据库和Hadoop中的数据进行相互转移的工具，可以将一个关系型数据库(例如Mysql、Oracle)中的数据导入到Hadoop(例如HDFS、Hive、Hbase)中，也可以将Hadoop(例如HDFS、Hive、Hbase)中的数据导入到关系型数据库(例如Mysql、Oracle)中。

Strom集群结构是有一个主节点(nimbus)和多个工作节点(supervisor)组成的主从结构，主节点通过配置静态指定或者在运行时动态选举，nimbus与supervisor都是Storm提供的后台守护进程，之间的通信是结合Zookeeper的状态变更通知和监控通知来处理。

Zookeeper是一个分布式的，开放源码的分布式应用程序协调服务，提供数据同步服务。

**二、数据存储**

Hadoop作为一个开源的框架，专为离线和大规模数据分析而设计，HDFS作为其核心的存储引擎，已被广泛用于数据存储。

HBase，是一个分布式的、面向列的开源数据库，可以认为是hdfs的封装，本质是数据存储、NoSQL数据库。

Phoenix，相当于一个Java中间件，帮助开发工程师能够像使用JDBC访问关系型数据库一样访问NoSQL数据库HBase。

Yarn是一种Hadoop资源管理器，可为上层应用提供统一的资源管理和调度，它的引入为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处。

Mesos是一款开源的集群管理软件，支持Hadoop、ElasticSearch、Spark、Storm 和Kafka等应用架构。

Redis是一种速度非常快的非关系数据库，可以存储键与5种不同类型的值之间的映射，可以将存储在内存的键值对数据持久化到硬盘中，使用复制特性来扩展性能，还可以使用客户端分片来扩展写性能。

Atlas是一个位于应用程序与MySQL之间的中间件。

Kudu是围绕Hadoop生态圈建立的存储引擎，Kudu拥有和Hadoop生态圈共同的设计理念，它运行在普通的服务器上、可分布式规模化部署、并且满足工业界的高可用要求。

**三、数据清洗**

MapReduce作为Hadoop的查询引擎，用于大规模数据集的并行计算，”Map(映射)”和”Reduce(归约)”，是它的主要思想。它极大的方便了编程人员在不会分布式并行编程的情况下，将自己的程序运行在分布式系统中。

随着业务数据量的增多，需要进行训练和清洗的数据会变得越来越复杂，这个时候就需要任务调度系统，比如oozie或者azkaban，对关键任务进行调度和监控。

**四、数据查询分析**

Hive的核心工作就是把SQL语句翻译成MR程序，可以将结构化的数据映射为一张数据库表，并提供 HQL(Hive SQL)查询功能。

Hive是为大数据批量处理而生的，Hive的出现解决了传统的关系型数据库(MySql、Oracle)在大数据处理上的瓶颈

Impala是对Hive的一个补充，可以实现高效的SQL查询。使用Impala来实现SQL on Hadoop，用来进行大数据实时查询分析。

Spark拥有Hadoop MapReduce所具有的特点，它将Job中间输出结果保存在内存中，从而不需要读取HDFS。Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载

Nutch 是一个开源Java 实现的搜索引擎。它提供了我们运行自己的搜索引擎所需的全部工具，包括全文搜索和Web爬虫。

Solr用Java编写、运行在Servlet容器(如Apache Tomcat或Jetty)的一个独立的企业级搜索应用的全文搜索服务器。

Elasticsearch是一个开源的全文搜索引擎，基于Lucene的搜索服务器，可以快速的储存、搜索和分析海量的数据。

**五、数据可视化**

对接一些BI平台，将分析得到的数据进行可视化，用于指导决策服务。主流的BI平台比如，国外的敏捷BI Tableau、Qlikview、PowrerBI等，国内的SmallBI和新兴的网易有数等。

大数据技术的体系庞大且复杂，每年都会涌现出大量新的技术，目前大数据行业所涉及到的核心技术主要就是：数据采集、数据存储、数据清洗、数据查询分析和数据可视化。

猎聘大数据研究院发布了《2022未来人才就业趋势报告》

从排名来看，2022年1-4月各行业中高端人才平均年薪来看，人工智能行业中高端人才平均年薪最高，为31.04万元；金融行业中高端人才以27.69万元的平均年薪位居第二；通信、大数据行业中高端人才平均年薪分别为27.51万元、25.23万元，位列第三、第四；IT/互联网行业中高端人才平均年薪23.02万元，位列第七。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/54f02bc9c87cfce4fd169b32443fef50.png)
  
图表来源：《2022未来人才就业趋势报告》

如果你觉得很高，被平均了这样？那么打开Boss直聘，搜大数据工程师：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/c252bda355627ce69e7f95696fd6f999.png)
  
我们来做下数据分析：

薪资那一列都有一个最低薪资和最高薪资，我们通过不同城市来对比分析一下，发现北京的工资水平最高，最低为22k，最高为38k。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/abf2ee414696cb4209aa72c8faa57ee6.png)
  
工作年限也是一个制约工资水平的很大因素，从图中可以看出，即使是刚毕业，也能达到一个11-20k的薪资范围。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/58c21529cb5539359ca772434733cc22.png)
  
而学历要求来说，大部分为本科，其次为大专和硕士，其他比较少，以至于在图中并没有显示出来。
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/7d3b66ca9d8fef4283ca9b1f93f0f0a7.png)
  
企业对不同岗位的要求以3-5年的居多，企业当然是需要有一定工作经验的员工，但是在实际招聘中，如果你有项目经验，且理论知识没问题，企业也会放宽条件。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/d79b0315df997672369b2f914df478aa.png)
  
分析不同行业， 我们发现，大数据岗位需求分布在各行各业，主要还是在计算机软件和互联网最多，也有可能是这个招聘软件决定的，毕竟Boss直聘还是以互联网行业为主。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/3d033a8f5dba595cd506dea28e806f59.png)
  
来看看哪些公司在招聘大数据相关岗位，从这个超过15的数量来看，华为，腾讯，阿里，字节，这些大厂对这个岗位的需求量还是很大的。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/f8217b8b049a5e9a7922d38547f640e1.png)

根据国内的发展形势，大数据未来的发展前景会非常好。自 2018 年企业纷纷开始数字化转型，一二线城市对大数据领域的人才需求非常强烈，未来几年，三四线城市的人才需求也会大增。

在大数据领域，国内发展的比较晚，从 2016 年开始，仅有 200 多所大学开设了大数据相关的专业，也就是说 2020 年第一批毕业生才刚刚步入社会，我国市场环境处于急需大数据人才但人才不足的阶段，所以未来大数据领域会有很多的就业机遇。
  
**薪资高、缺口大，自然成为职场人的“薪”选择！**

任何学习过程都需要一个科学合理的学习路线，才能够有条不紊的完成我们的学习目标。Python+大数据所需学习的内容纷繁复杂，难度较大，为大家整理了一个全面的Python+大数据学习路线图，帮大家理清思路，攻破难关！

Python+大数据学习路线图详细介绍

### 第一阶段 大数据开发入门

学前导读：从传统关系型数据库入手，掌握数据迁移工具、BI数据可视化工具、SQL，对后续学习打下坚实基础。

**1.大数据数据开发基础MySQL8.0从入门到精通**

MySQL是整个IT基础课程，SQL贯穿整个IT人生，俗话说，SQL写的好，工作随便找。本课程从零到高阶全面讲解MySQL8.0，学习本课程之后可以具备基本开发所需的SQL水平。

[2022最新MySQL知识精讲+mysql实战案例_零基础mysql数据库入门到高级全套教程](https://www.bilibili.com/video/BV1iF411z7Pu)

### **第二阶段 大数据核心基础**

学前导读：学习Linux、Hadoop、Hive，掌握大数据基础技术。

2022版大数据Hadoop入门教程
  
Hadoop离线是大数据生态圈的核心与基石，是整个大数据开发的入门，是为后期的Spark、Flink打下坚实基础的课程。掌握课程三部分内容：Linux、Hadoop、Hive，就可以独立的基于数据仓库实现离线数据分析的可视化报表开发。

[2022最新大数据Hadoop入门视频教程，最适合零基础自学的大数据Hadoop教程](https://www.bilibili.com/video/BV1CU4y1N7Sh)

### 第三阶段 千亿级数仓技术

学前导读：本阶段课程以真实项目为驱动，学习离线数仓技术。

数据离线数据仓库，企业级在线教育项目实战（Hive数仓项目完整流程）
  
本课程会、建立集团数据仓库，统一集团数据中心，把分散的业务数据集中存储和处理 ；目从需求调研、设计、版本控制、研发、测试到落地上线，涵盖了项目的完整工序 ；掘分析海量用户行为数据，定制多维数据集合，形成数据集市，供各个场景主题使用。

[大数据项目实战教程_大数据企业级离线数据仓库，在线教育项目实战（Hive数仓项目完整流程）](https://www.bilibili.com/video/BV1ef4y1B7KX)

### 第四阶段 PB内存计算

学前导读：Spark官方已经在自己首页中将Python作为第一语言，在3.2版本的更新中，高亮提示内置捆绑Pandas；课程完全顺应技术社区和招聘岗位需求的趋势，全网首家加入Python on Spark的内容。

**1.python入门到精通（19天全）**

python基础学习课程，从搭建环境。判断语句，再到基础的数据类型，之后对函数进行学习掌握，熟悉文件操作，初步构建面向对象的编程思想，最后以一个案例带领同学进入python的编程殿堂。

[全套Python教程_Python基础入门视频教程，零基础小白自学Python必备教程](https://www.bilibili.com/video/BV1o4411M71o)

**2.python编程进阶从零到搭建网站**

学完本课程会掌握Python高级语法、多任务编程以及网络编程。

[Python高级语法进阶教程_python多任务及网络编程，从零搭建网站全套教程](https://www.bilibili.com/video/BV1Ex411x7Xn)

**3.spark3.2从基础到精通**

Spark是大数据体系的明星产品，是一款高性能的分布式内存迭代计算框架，可以处理海量规模的数据。本课程基于Python语言学习Spark3.2开发，课程的讲解注重理论联系实际，高效快捷，深入浅出，让初学者也能快速掌握。让有经验的工程师也能有所收获。

[Spark全套视频教程，大数据spark3.2从基础到精通，全网首套基于Python语言的spark教程](https://www.bilibili.com/video/BV1Jq4y1z7VP)

**4.大数据Hive+Spark离线数仓工业项目实战**

通过大数据技术架构，解决工业物联网制造行业的数据存储和分析、可视化、个性化推荐问题。一站制造项目主要基于Hive数仓分层来存储各个业务指标数据，基于sparkSQL做数据分析。核心业务涉及运营商、呼叫中心、工单、油站、仓储物料。

[全网首次披露大数据Spark离线数仓工业项目实战，Hive+Spark构建企业级大数据平台](https://www.bilibili.com/video/BV1Tv411B7Cf)