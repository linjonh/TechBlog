---
layout: post
title: "多模态大模型Qwen2.5-vl本地部署指南"
date: 2025-03-11 16:59:16 +0800
description: "Qwen2.5-VL 是通义千问系列的最新多模态大模型，具备图文理解、视觉推理、文档解析等强大能力，广泛应用于智能搜索、内容生成、企业文档处理等领域。🔹 主要功能✅ 多模态问答：解析图片、图表、文档，回答问题，支持 OCR 识别。✅ 复杂文档解析：提取发票、合同、PPT、表格等文件中的结构化信息。✅ 高级视觉推理：理解图像中的关系，如因果推理、数据分析。✅ 智能摘要与生成：自动生成图片描述、文档摘要，提高信息获取效率。"
keywords: "多模态大模型Qwen2.5 vl本地部署指南"
categories: ['大模型']
tags: ['人工智能']
artid: "146181056"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146181056
    alt: "多模态大模型Qwen2.5-vl本地部署指南"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146181056
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146181056
cover: https://bing.ee123.net/img/rand?artid=146181056
image: https://bing.ee123.net/img/rand?artid=146181056
img: https://bing.ee123.net/img/rand?artid=146181056
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     多模态大模型Qwen2.5 vl本地部署指南
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/9b8e39aceb4b4a9387d3cb3ab1f4d4b2.png">
      <br/>
      Qwen2.5-VL 是通义千问系列的最新多模态大模型，具备图文理解、视觉推理、文档解析等强大能力，广泛应用于智能搜索、内容生成、企业文档处理等领域。
     </img>
    </p>
    <p>
     🔹 主要功能
     <br/>
     ✅ 多模态问答：解析图片、图表、文档，回答问题，支持 OCR 识别。
     <br/>
     ✅ 复杂文档解析：提取发票、合同、PPT、表格等文件中的结构化信息。
     <br/>
     ✅ 高级视觉推理：理解图像中的关系，如因果推理、数据分析。
     <br/>
     ✅ 智能摘要与生成：自动生成图片描述、文档摘要，提高信息获取效率。
     <br/>
     ✅ 代码与 UI 解析：识别截图中的代码/UI 设计，生成可执行代码或交互说明。
    </p>
    <h3>
     <a id="__9">
     </a>
     一. 环境准备
    </h3>
    <p>
     机器：4090
     <br/>
     python: 3.10
     <br/>
     cuda: 12.2
    </p>
    <pre><code class="prism language-bash"><span class="token comment"># 网络不好，可能需要尝试几次</span>
pip <span class="token function">install</span> git+https://github.com/huggingface/transformers accelerate
pip <span class="token function">install</span> qwen-vl-utils<span class="token punctuation">[</span>decord<span class="token punctuation">]</span>

<span class="token comment"># 跑代码时缺少包</span>
pip <span class="token function">install</span> <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.19</span>.0
</code></pre>
    <h3>
     <a id="__22">
     </a>
     二. 下载模型
    </h3>
    <pre><code class="prism language-python"><span class="token keyword">from</span> modelscope <span class="token keyword">import</span> snapshot_download
model_dir <span class="token operator">=</span> snapshot_download<span class="token punctuation">(</span><span class="token string">'Qwen/Qwen2.5-VL-7B'</span><span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="__29">
     </a>
     三. 推理代码封装
    </h3>
    <pre><code class="prism language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> Qwen2_5_VLForConditionalGeneration<span class="token punctuation">,</span> AutoProcessor
<span class="token keyword">from</span> qwen_vl_utils <span class="token keyword">import</span> process_vision_info
<span class="token keyword">import</span> torch


<span class="token keyword">class</span> <span class="token class-name">QwenVLModel</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model_path<span class="token operator">=</span><span class="token string">"./Qwen2.5-VL-7B-Instruct"</span><span class="token punctuation">,</span> use_flash_attention<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        初始化Qwen VL模型
        Args:
            model_path: 模型路径
            use_flash_attention: 是否使用flash attention加速
        """</span>
        <span class="token comment"># 加载模型</span>
        <span class="token keyword">if</span> use_flash_attention<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>model <span class="token operator">=</span> Qwen2_5_VLForConditionalGeneration<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
                model_path<span class="token punctuation">,</span>
                torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bfloat16<span class="token punctuation">,</span>
                attn_implementation<span class="token operator">=</span><span class="token string">"flash_attention_2"</span><span class="token punctuation">,</span>
                device_map<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>model <span class="token operator">=</span> Qwen2_5_VLForConditionalGeneration<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
                model_path<span class="token punctuation">,</span> torch_dtype<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">,</span> device_map<span class="token operator">=</span><span class="token string">"auto"</span>
            <span class="token punctuation">)</span>

        <span class="token comment"># 初始化处理器</span>
        min_pixels <span class="token operator">=</span> <span class="token number">256</span><span class="token operator">*</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span>
        max_pixels <span class="token operator">=</span> <span class="token number">1280</span><span class="token operator">*</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span>
        self<span class="token punctuation">.</span>processor <span class="token operator">=</span> AutoProcessor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
            model_path<span class="token punctuation">,</span> 
            min_pixels<span class="token operator">=</span>min_pixels<span class="token punctuation">,</span> 
            max_pixels<span class="token operator">=</span>max_pixels<span class="token punctuation">,</span> 
            use_fast<span class="token operator">=</span><span class="token boolean">True</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_image</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image_path<span class="token punctuation">,</span> prompt<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        处理图片并生成输出
        Args:
            image_path: 图片路径
            prompt: 提示文本
        Returns:
            生成的文本输出
        """</span>
        messages <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token punctuation">{<!-- --></span>
                <span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span>
                <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
                    <span class="token punctuation">{<!-- --></span>
                        <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"image"</span><span class="token punctuation">,</span>
                        <span class="token string">"image"</span><span class="token punctuation">:</span> image_path<span class="token punctuation">,</span>
                    <span class="token punctuation">}</span><span class="token punctuation">,</span>
                    <span class="token punctuation">{<!-- --></span><span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"text"</span><span class="token punctuation">,</span> <span class="token string">"text"</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span><span class="token punctuation">,</span>
                <span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">]</span>

        <span class="token comment"># 准备推理输入</span>
        text <span class="token operator">=</span> self<span class="token punctuation">.</span>processor<span class="token punctuation">.</span>apply_chat_template<span class="token punctuation">(</span>
            messages<span class="token punctuation">,</span> tokenize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> add_generation_prompt<span class="token operator">=</span><span class="token boolean">True</span>
        <span class="token punctuation">)</span>
        image_inputs<span class="token punctuation">,</span> video_inputs <span class="token operator">=</span> process_vision_info<span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
        inputs <span class="token operator">=</span> self<span class="token punctuation">.</span>processor<span class="token punctuation">(</span>
            text<span class="token operator">=</span><span class="token punctuation">[</span>text<span class="token punctuation">]</span><span class="token punctuation">,</span>
            images<span class="token operator">=</span>image_inputs<span class="token punctuation">,</span>
            videos<span class="token operator">=</span>video_inputs<span class="token punctuation">,</span>
            padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

        <span class="token comment"># 生成输出</span>
        generated_ids <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">,</span> max_new_tokens<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">)</span>
        generated_ids_trimmed <span class="token operator">=</span> <span class="token punctuation">[</span>
            out_ids<span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>in_ids<span class="token punctuation">)</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token keyword">for</span> in_ids<span class="token punctuation">,</span> out_ids <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>input_ids<span class="token punctuation">,</span> generated_ids<span class="token punctuation">)</span>
        <span class="token punctuation">]</span>
        output_text <span class="token operator">=</span> self<span class="token punctuation">.</span>processor<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>
            generated_ids_trimmed<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> clean_up_tokenization_spaces<span class="token operator">=</span><span class="token boolean">False</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">return</span> output_text



<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> QwenVLModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
    img_path <span class="token operator">=</span> <span class="token string">"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg"</span>
    output_text <span class="token operator">=</span> model<span class="token punctuation">.</span>process_image<span class="token punctuation">(</span>
        img_path<span class="token punctuation">,</span>
        <span class="token string">"请用中文描述一下这张图片"</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"输出信息: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>output_text<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="__125">
     </a>
     四. 测试效果
    </h3>
    <p>
     图片
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/6f9823500cd5429da097732ddf0fd12d.jpeg">
      <br/>
      模型输出结果：
     </img>
    </p>
    <pre><code class="prism language-bash">输出信息: <span class="token punctuation">[</span><span class="token string">'这张图片展示了一位女士和一只狗在海滩上互动的场景。女士坐在沙滩上，穿着格子衬衫和黑色裤子，面带微笑，似乎在与狗进行友好互动。狗戴着彩色的项圈，正伸出前爪与女士的手相触碰，显得非常亲密和愉快。背景是广阔的海洋和天空，夕阳的余晖洒在沙滩上，营造出一种温馨和谐的氛围。整个画面给人一种轻松愉快的感觉。'</span><span class="token punctuation">]</span>
</code></pre>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f47756f5f507974686f6e2f:61727469636c652f64657461696c732f313436313831303536" class_="artid" style="display:none">
 </p>
</div>


