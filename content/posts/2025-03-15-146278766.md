---
layout: post
title: "PyTorch系列教程基于LSTM构建情感分析模型"
date: 2025-03-15 14:20:54 +0800
description: "本文详细介绍了如何使用PyTorch和LSTMs构建情感分析管道的全过程，从环境设置到模型训练和评估。通过遵循本文的指导，读者可以掌握情感分析的基本技能，并为进一步的研究和开发打下坚实的基础。"
keywords: "PyTorch系列教程：基于LSTM构建情感分析模型"
categories: ['人工智能', 'Python']
tags: ['人工智能', 'Pytorch', 'Lstm']
artid: "146278766"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146278766
    alt: "PyTorch系列教程基于LSTM构建情感分析模型"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146278766
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146278766
cover: https://bing.ee123.net/img/rand?artid=146278766
image: https://bing.ee123.net/img/rand?artid=146278766
img: https://bing.ee123.net/img/rand?artid=146278766
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     PyTorch系列教程：基于LSTM构建情感分析模型
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <blockquote>
     <p>
      情感分析是一种强大的自然语言处理（NLP）技术，用于确定文本背后的情绪基调。它常用于理解客户对产品或服务的意见和反馈。本文将介绍如何使用PyTorch和长短期记忆网络（LSTMs）创建一个情感分析管道，LSTMs在处理序列数据方面非常有效。
     </p>
    </blockquote>
    <h3>
     <a id="_6">
     </a>
     环境准备
    </h3>
    <p>
     在深入实现之前，确保你已经安装了PyTorch和NLTK，一个流行的NLP库。可以通过执行以下命令来安装：
    </p>
    <pre><code class="prism language-python">pip install torch nltk
</code></pre>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/bc83242f9c61459caec432eeb5f3b245.png"/>
    </p>
    <h4>
     <a id="_15">
     </a>
     准备数据集
    </h4>
    <p>
     我们将使用IMDb数据集，这是情感分析的一个著名基准。要加载和预处理此数据，请运行以下脚本：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> nltk
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> imdb

<span class="token keyword">def</span> <span class="token function">download_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'imdb'</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> imdb<span class="token punctuation">.</span>load<span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token string">'--data_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> data

dataset <span class="token operator">=</span> download_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="_31">
     </a>
     数据预处理
    </h4>
    <p>
     文本预处理涉及清理和准备文本以供建模。以下函数将句子分词，转换为小写，并移除标点符号。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> re
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> word_tokenize

<span class="token keyword">def</span> <span class="token function">preprocess_text</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
    sentence <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"[^a-z ]"</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> sentence<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 移除标点符号</span>
    tokens <span class="token operator">=</span> word_tokenize<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
    <span class="token keyword">return</span> tokens

processed_data <span class="token operator">=</span> <span class="token punctuation">[</span>preprocess_text<span class="token punctuation">(</span>review<span class="token punctuation">)</span> <span class="token keyword">for</span> review <span class="token keyword">in</span> dataset<span class="token punctuation">]</span>
</code></pre>
    <h4>
     <a id="_47">
     </a>
     词汇表和编码
    </h4>
    <p>
     神经网络需要数值输入，因此我们必须将单词转换为索引。我们创建一个词汇表，并将每个单词映射到一个整数。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter

vocabulary <span class="token operator">=</span> Counter<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> review <span class="token keyword">in</span> processed_data<span class="token punctuation">:</span>
    vocabulary<span class="token punctuation">.</span>update<span class="token punctuation">(</span>review<span class="token punctuation">)</span>

word2idx <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>word<span class="token punctuation">:</span> idx <span class="token keyword">for</span> idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>word<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>vocabulary<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
encoded_reviews <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>word2idx<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> review<span class="token punctuation">]</span> <span class="token keyword">for</span> review <span class="token keyword">in</span> processed_data<span class="token punctuation">]</span>
</code></pre>
    <h3>
     <a id="LSTM_62">
     </a>
     构建LSTM模型
    </h3>
    <p>
     数据准备就绪后，让我们在PyTorch中构建我们的LSTM模型。我们将定义一个简单的架构来执行情感分析任务。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn

<span class="token keyword">class</span> <span class="token class-name">SentimentLSTM</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> embed_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SentimentLSTM<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embed_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>embed_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        lstm_out<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>lstm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        final_hidden <span class="token operator">=</span> lstm_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>final_hidden<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out
</code></pre>
    <h3>
     <a id="_85">
     </a>
     训练模型
    </h3>
    <p>
     要训练模型，指定损失函数和优化器。我们将使用CrossEntropyLoss和Adam优化器。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">train_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> reviews<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>reviews<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="_101">
     </a>
     评估和可视化结果
    </h3>
    <p>
     训练完成后，在测试集上评估模型以确定其性能，并可视化输出。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">evaluate_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    correct_count <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> reviews<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>reviews<span class="token punctuation">)</span>
            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            correct_count <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    accuracy <span class="token operator">=</span> correct_count <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>
    <span class="token keyword">return</span> accuracy

test_accuracy <span class="token operator">=</span> evaluate_model<span class="token punctuation">(</span>lstm_model<span class="token punctuation">,</span> test_loader<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Test Accuracy: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>test_accuracy<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">%'</span></span><span class="token punctuation">)</span>
</code></pre>
    <p>
     使用PyTorch和LSTMs构建情感分析管道涉及几个关键步骤，包括数据预处理、文本编码、构建模型、训练和评估。这个基本管道可以作为更复杂问题的基础，并可以通过高级技术扩展以提高模型性能。
    </p>
    <h3>
     <a id="_123">
     </a>
     总结
    </h3>
    <p>
     本文详细介绍了如何使用PyTorch和LSTMs构建情感分析管道的全过程，从环境设置到模型训练和评估。通过遵循本文的指导，读者可以掌握情感分析的基本技能，并为进一步的研究和开发打下坚实的基础。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f6e65776561737473756e2f:61727469636c652f64657461696c732f313436323738373636" class_="artid" style="display:none">
 </p>
</div>


