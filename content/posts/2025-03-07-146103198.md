---
arturl_encode: "68747470733a2f2f:626c6f672e6373646e2e6e65742f753031303334323231332f:61727469636c652f64657461696c732f313436313033313938"
layout: post
title: "Flinkæ·±å…¥æµ…å‡ºä¹‹04æ—¶é—´æ°´å°TableSQL"
date: 2025-03-07 23:47:49 +08:00
description: "åœ¨Sparkä¸­æœ‰DataFrameè¿™æ ·çš„å…³ç³»å‹ç¼–ç¨‹æ¥å£ï¼Œå› å…¶å¼ºå¤§ä¸”çµæ´»çš„è¡¨è¾¾èƒ½åŠ›ï¼Œèƒ½å¤Ÿè®©ç”¨æˆ·é€šè¿‡éå¸¸ä¸°å¯Œçš„æ¥å£å¯¹æ•°æ®è¿›è¡Œå¤„ç†ï¼Œæœ‰æ•ˆé™ä½äº†ç”¨æˆ·çš„ä½¿ç”¨æˆæœ¬ã€‚Flinkä¹Ÿæä¾›äº†å…³ç³»å‹ç¼–ç¨‹æ¥å£ Table API ä»¥åŠåŸºäºTable API çš„ SQL APIï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿé€šè¿‡ä½¿ç”¨ç»“æ„åŒ–ç¼–ç¨‹æ¥å£é«˜æ•ˆåœ°æ„å»ºFlinkåº”ç”¨ã€‚åŒæ—¶Table API ä»¥åŠ SQL èƒ½å¤Ÿç»Ÿä¸€å¤„ç†æ‰¹é‡å’Œå®æ—¶è®¡ç®—ä¸šåŠ¡ï¼Œæ— é¡»åˆ‡æ¢ä¿®æ”¹ä»»ä½•åº”ç”¨ä»£ç å°±èƒ½å¤ŸåŸºäºåŒä¸€å¥— API ç¼–å†™æµå¼åº”ç”¨å’Œæ‰¹é‡åº”ç”¨ï¼Œä»è€Œè¾¾åˆ°çœŸæ­£æ„ä¹‰çš„æ‰¹æµç»Ÿä¸€ã€‚"
keywords: "Flinkæ·±å…¥æµ…å‡ºä¹‹04ï¼šæ—¶é—´ã€æ°´å°ã€Table&SQL"
categories: ['å¤§æ•°æ®æŠ€æœ¯å­¦ä¹ ']
tags: ['æ•°æ®åº“', 'Sql', 'Flink']
artid: "146103198"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146103198
    alt: "Flinkæ·±å…¥æµ…å‡ºä¹‹04æ—¶é—´æ°´å°TableSQL"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146103198
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146103198
cover: https://bing.ee123.net/img/rand?artid=146103198
image: https://bing.ee123.net/img/rand?artid=146103198
img: https://bing.ee123.net/img/rand?artid=146103198
---

# Flinkæ·±å…¥æµ…å‡ºä¹‹04ï¼šæ—¶é—´ã€æ°´å°ã€Table&SQL

### æ·±å…¥ç†è§£Flinkçš„waterMarkçš„æœºåˆ¶ã€Flink Tableå’ŒSQLå¼€å‘

### 3ï¸âƒ£ ç›®æ ‡

1. æŒæ¡WaterMarkçš„çš„åŸç†
2. æŒæ¡WaterMarkçš„è¿ç”¨
3. æŒæ¡Flink Tableå’ŒSQLå¼€å‘

### 4ï¸âƒ£ è¦ç‚¹

### ğŸ“– 1. Flinkä¸­çš„Timeæ¦‚å¿µ

* å¯¹äºæµå¼æ•°æ®å¤„ç†ï¼Œæœ€å¤§çš„ç‰¹ç‚¹æ˜¯æ•°æ®ä¸Šå…·æœ‰æ—¶é—´çš„å±æ€§ç‰¹å¾
* Flinkæ ¹æ®æ—¶é—´äº§ç”Ÿçš„ä½ç½®ä¸åŒï¼Œå¯ä»¥å°†æ—¶é—´åŒºåˆ†ä¸ºä¸‰ç§æ—¶é—´æ¦‚å¿µ

  + Event Time
    ï¼ˆäº‹ä»¶ç”Ÿæˆæ—¶é—´ï¼‰
    - äº‹ä»¶äº§ç”Ÿçš„æ—¶é—´ï¼Œå®ƒé€šå¸¸ç”±äº‹ä»¶ä¸­çš„æ—¶é—´æˆ³æè¿°
  + Ingestion time
    ï¼ˆäº‹ä»¶æ¥å…¥æ—¶é—´ï¼‰
    - äº‹ä»¶è¿›å…¥Flinkç¨‹åºçš„æ—¶é—´
  + Processing Time
    ï¼ˆäº‹ä»¶å¤„ç†æ—¶é—´ï¼‰
    - äº‹ä»¶è¢«å¤„ç†æ—¶å½“å‰ç³»ç»Ÿçš„æ—¶é—´

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/826ec0aef5164a009102259070b97b96.png)

* Flinkåœ¨æµå¤„ç†ç¨‹åºä¸­æ”¯æŒä¸åŒçš„æ—¶é—´æ¦‚å¿µã€‚

##### 1.1 EventTime

* 1ã€äº‹ä»¶ç”Ÿæˆæ—¶çš„æ—¶é—´ï¼Œåœ¨è¿›å…¥Flinkä¹‹å‰å°±å·²ç»å­˜åœ¨ï¼Œå¯ä»¥ä»eventçš„å­—æ®µä¸­æŠ½å–
* 2ã€å¿…é¡»æŒ‡å®šwatermarksï¼ˆæ°´ä½çº¿ï¼‰çš„ç”Ÿæˆæ–¹å¼
* 3ã€ä¼˜åŠ¿ï¼šç¡®å®šæ€§ï¼Œä¹±åºã€å»¶æ—¶ã€æˆ–è€…æ•°æ®é‡æ”¾ç­‰æƒ…å†µï¼Œéƒ½èƒ½ç»™å‡ºæ­£ç¡®çš„ç»“æœ
* 4ã€å¼±ç‚¹ï¼šå¤„ç†æ— åºäº‹ä»¶æ—¶æ€§èƒ½å’Œå»¶è¿Ÿå—åˆ°å½±å“

##### 1.2 IngestTime

* 1ã€äº‹ä»¶è¿›å…¥flinkçš„æ—¶é—´ï¼Œå³åœ¨sourceé‡Œè·å–çš„å½“å‰ç³»ç»Ÿçš„æ—¶é—´ï¼Œåç»­æ“ä½œç»Ÿä¸€ä½¿ç”¨è¯¥æ—¶é—´ã€‚
* 2ã€ä¸éœ€è¦æŒ‡å®šwatermarksçš„ç”Ÿæˆæ–¹å¼(è‡ªåŠ¨ç”Ÿæˆ)
* 3ã€å¼±ç‚¹ï¼šä¸èƒ½å¤„ç†æ— åºäº‹ä»¶å’Œå»¶è¿Ÿæ•°æ®

##### 1.3 ProcessingTime

* 1ã€æ‰§è¡Œæ“ä½œçš„æœºå™¨çš„å½“å‰ç³»ç»Ÿæ—¶é—´(æ¯ä¸ªç®—å­éƒ½ä¸ä¸€æ ·)
* 2ã€ä¸éœ€è¦æµå’Œæœºå™¨ä¹‹é—´çš„åè°ƒ
* 3ã€ä¼˜åŠ¿ï¼šæœ€ä½³çš„æ€§èƒ½å’Œæœ€ä½çš„å»¶è¿Ÿ
* 4ã€å¼±ç‚¹ï¼šä¸ç¡®å®šæ€§ ï¼Œå®¹æ˜“å—åˆ°å„ç§å› ç´ å½±åƒ(eventäº§ç”Ÿçš„é€Ÿåº¦ã€åˆ°è¾¾flinkçš„é€Ÿåº¦ã€åœ¨ç®—å­ä¹‹é—´ä¼ è¾“é€Ÿåº¦ç­‰)ï¼Œå‹æ ¹å°±ä¸ç®¡é¡ºåºå’Œå»¶è¿Ÿ

##### 1.4 ä¸‰ç§æ—¶é—´çš„ç»¼åˆæ¯”è¾ƒ

* æ€§èƒ½

  + ProcessingTime > IngestTime > EventTime
* å»¶è¿Ÿ

  + ProcessingTime < IngestTime < EventTime
* ç¡®å®šæ€§

  + EventTime > IngestTime > ProcessingTime

##### 1.5 è®¾ç½® Time ç±»å‹

* å¯ä»¥ä½ çš„æµå¤„ç†ç¨‹åºæ˜¯ä»¥å“ªä¸€ç§æ—¶é—´ä¸ºæ ‡å¿—çš„ã€‚

  + åœ¨æˆ‘ä»¬åˆ›å»ºStreamExecutionEnvironmentçš„æ—¶å€™å¯ä»¥è®¾ç½®Timeç±»å‹ï¼Œä¸è®¾ç½®Timeç±»å‹ï¼Œé»˜è®¤æ˜¯ProcessingTimeã€‚
  + å¦‚æœè®¾ç½®Timeç±»å‹ä¸ºEventTimeæˆ–è€…IngestTimeï¼Œéœ€è¦åœ¨åˆ›å»ºStreamExecutionEnvironmentä¸­è°ƒç”¨setStreamTimeCharacteristic() æ–¹æ³•æŒ‡å®šã€‚

  ```scala
  val environment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

  //ä¸è®¾ç½®Time ç±»å‹ï¼Œé»˜è®¤æ˜¯processingTimeã€‚
  environment.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime);

  //æŒ‡å®šæµå¤„ç†ç¨‹åºä»¥IngestionTimeä¸ºå‡†
  //environment.setStreamTimeCharacteristic(TimeCharacteristic.IngestionTime);

  //æŒ‡å®šæµå¤„ç†ç¨‹åºä»¥EventTimeä¸ºå‡†
  //environment.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);


  ```

##### 1.6 ProcessWindowFunctionå®ç°æ—¶é—´ç¡®å®š

* éœ€æ±‚

  + é€šè¿‡processå®ç°å¤„ç†æ—¶é—´çš„ç¡®å®šï¼ŒåŒ…æ‹¬æ•°æ®æ—¶é—´ã€windowæ—¶é—´ç­‰
* ä»£ç å¼€å‘

  ```scala
  package com.kaikeba.time

  import org.apache.commons.lang3.time.FastDateFormat
  import org.apache.flink.api.java.tuple.Tuple
  import org.apache.flink.streaming.api.scala.function.ProcessWindowFunction
  import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}
  import org.apache.flink.streaming.api.windowing.time.Time
  import org.apache.flink.streaming.api.windowing.windows.TimeWindow
  import org.apache.flink.util.Collector

  /**
    * é€šè¿‡processå®ç°å¤„ç†æ—¶é—´çš„ç¡®å®šï¼ŒåŒ…æ‹¬æ•°æ®æ—¶é—´ï¼Œwindowæ—¶é—´ç­‰
    */
  object TimeWindowWordCount {

    def main(args: Array[String]): Unit = {

      val environment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
      import org.apache.flink.api.scala._

      val socketSource: DataStream[String] = environment.socketTextStream("node01",9999)
       //å¯¹æ•°æ®è¿›è¡Œå¤„ç†
      socketSource.flatMap(x => x.split(" "))
                  .map(x =>(x,1))
                  .keyBy(0)
                  .timeWindow(Time.seconds(2),Time.seconds(1))
                  .process(new SumProcessFunction)
                  .print()

      environment.execute()
    }

  }

  class SumProcessFunction extends ProcessWindowFunction[(String,Int),(String,Int),Tuple,TimeWindow]{

    val format: FastDateFormat = FastDateFormat.getInstance("HH:mm:ss")

    override def process(key: Tuple, context: Context, elements: Iterable[(String, Int)], out: Collector[(String, Int)]): Unit = {

      println("å½“å‰ç³»ç»Ÿæ—¶é—´ä¸ºï¼š"+format.format(System.currentTimeMillis()))
      println("windowçš„å¤„ç†æ—¶é—´ä¸ºï¼š"+format.format(context.currentProcessingTime))
      println("windowçš„å¼€å§‹æ—¶é—´ä¸ºï¼š"+format.format(context.window.getStart))
      println("windowçš„ç»“æŸæ—¶é—´ä¸ºï¼š"+format.format(context.window.getEnd))
      var sum:Int = 0
      for(eachElement <- elements){
        sum += eachElement._2
      }
      out.collect((key.getField(0),sum))

    }

  }


  ```

### ğŸ“– 2. Watermarkæœºåˆ¶

##### 2.1 Watermarkçš„æ¦‚å¿µ

```
   é€šå¸¸æƒ…å†µä¸‹ç”±äºç½‘ç»œæˆ–è€…ç³»ç»Ÿç­‰å¤–éƒ¨å› ç´ å½±å“ä¸‹ï¼Œ
   äº‹ä»¶æ•°æ®å¾€å¾€ä¸èƒ½åŠæ—¶ä¼ è¾“è‡³FLinkç³»ç»Ÿä¸­ï¼Œ
   å¯¼è‡´ç³»ç»Ÿçš„ä¸ç¨³å®šè€Œé€ æˆæ•°æ®ä¹±åºåˆ°è¾¾æˆ–è€…å»¶è¿Ÿè¾¾åˆ°ç­‰é—®é¢˜ï¼Œ
   å› æ­¤éœ€è¦æœ‰ä¸€ç§æœºåˆ¶èƒ½å¤Ÿæ§åˆ¶æ•°æ®å¤„ç†çš„è¿›åº¦ã€‚
   
   å…·ä½“æ¥è®²ï¼Œåœ¨åˆ›å»ºä¸€ä¸ªåŸºäºæ—¶é—´çš„windowåï¼Œéœ€è¦ç¡®å®šå±äºè¯¥windowçš„æ•°æ®å…ƒç´ æ˜¯å¦å·²ç»å…¨éƒ¨åˆ°è¾¾ï¼Œ
   ç¡®å®šåæ‰å¯ä»¥å¯¹windowä¸­çš„æ‰€æœ‰æ•°æ®åšè®¡ç®—å¤„ç†ï¼ˆå¦‚æ±‡æ€»ã€åˆ†ç»„ï¼‰ï¼Œ
   å¦‚æœæ•°æ®å¹¶æ²¡æœ‰å…¨éƒ¨åˆ°è¾¾ï¼Œåˆ™ç»§ç»­ç­‰å¾…è¯¥çª—å£çš„æ•°æ®å…¨éƒ¨åˆ°è¾¾åå†å¼€å§‹è®¡ç®—ã€‚
	
   ä½†æ˜¯å¯¹äºä½†æ˜¯å¯¹äºlate elementï¼Œæˆ‘ä»¬åˆä¸èƒ½æ— é™æœŸçš„ç­‰ä¸‹å»ï¼Œå¿…é¡»è¦æœ‰ä¸ªæœºåˆ¶æ¥ä¿è¯ä¸€ä¸ªç‰¹å®šçš„æ—¶é—´åï¼Œå¿…é¡»è§¦å‘windowå»è¿›è¡Œè®¡ç®—äº†ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹å°±éœ€è¦ç”¨åˆ°æ°´ä½çº¿ (Watermark) æœºåˆ¶ã€‚


```

##### 2.2 Watermarkçš„ä½œç”¨

```
    å®ƒèƒ½å¤Ÿè¡¡é‡æ•°æ®å¤„ç†è¿›åº¦ï¼Œä¿è¯äº‹ä»¶æ•°æ®å…¨éƒ¨åˆ°è¾¾Flinkç³»ç»Ÿï¼Œå³ä½¿æ•°æ®ä¹±åºæˆ–è€…å»¶è¿Ÿåˆ°è¾¾ï¼Œä¹Ÿèƒ½å¤Ÿåƒé¢„æœŸä¸€æ ·è®¡ç®—å‡ºæ­£ç¡®å’Œè¿ç»­çš„ç»“æœã€‚é€šå¸¸watermarkæ˜¯ç»“åˆwindowæ¥å®ç°ã€‚

```

##### 2.3 Watermarkçš„åŸç†

```
   åœ¨ Flink çš„çª—å£å¤„ç†è¿‡ç¨‹ä¸­ï¼Œå¦‚æœç¡®å®šå…¨éƒ¨æ•°æ®åˆ°è¾¾ï¼Œå°±å¯ä»¥å¯¹ Window çš„æ‰€æœ‰æ•°æ®åšçª—å£è®¡ç®—æ“ä½œï¼ˆå¦‚æ±‡æ€»ã€åˆ†ç»„ç­‰ï¼‰ï¼Œ
   å¦‚æœæ•°æ®æ²¡æœ‰å…¨éƒ¨åˆ°è¾¾ï¼Œåˆ™ç»§ç»­ç­‰å¾…è¯¥çª—å£ä¸­çš„æ•°æ®å…¨éƒ¨åˆ°è¾¾æ‰å¼€å§‹å¤„ç†ã€‚
   è¿™ç§æƒ…å†µä¸‹å°±éœ€è¦ç”¨åˆ°æ°´ä½çº¿ï¼ˆWaterMarksï¼‰æœºåˆ¶ï¼Œå®ƒèƒ½å¤Ÿè¡¡é‡æ•°æ®å¤„ç†è¿›åº¦ï¼ˆè¡¨è¾¾æ•°æ®åˆ°è¾¾çš„å®Œæ•´æ€§ï¼‰ï¼Œ
   ä¿è¯äº‹ä»¶æ•°æ®ï¼ˆå…¨éƒ¨ï¼‰åˆ°è¾¾Flinkç³»ç»Ÿï¼Œ
   æˆ–è€…åœ¨ä¹±åºåŠå»¶è¿Ÿåˆ°è¾¾æ—¶ï¼Œ
   ä¹Ÿèƒ½å¤Ÿåƒé¢„æœŸä¸€æ ·è®¡ç®—å‡ºæ­£ç¡®å¹¶ä¸”è¿ç»­çš„ç»“æœã€‚
   å½“ä»»ä½• Event è¿›å…¥åˆ° Flink ç³»ç»Ÿæ—¶ï¼Œä¼šæ ¹æ®å½“å‰æœ€å¤§äº‹ä»¶æ—¶é—´äº§ç”Ÿ Watermarks æ—¶é—´æˆ³ã€‚ 
   

```

* é‚£ä¹ˆ Flink æ˜¯æ€ä¹ˆè®¡ç®— Watermark çš„å€¼å‘¢ï¼Ÿ
    
  â­ï¸

  + Watermark = è¿›å…¥ Flink çš„æœ€å¤§çš„äº‹ä»¶äº§ç”Ÿæ—¶é—´ï¼ˆmaxEventTimeï¼‰â€” æŒ‡å®šçš„ä¹±åºæ—¶é—´ï¼ˆtï¼‰
* é‚£ä¹ˆæœ‰ Watermark çš„ Window æ˜¯æ€ä¹ˆè§¦å‘çª—å£å‡½æ•°çš„å‘¢ï¼Ÿ

> ï¼ˆ1ï¼‰ watermark >= windowçš„ç»“æŸæ—¶é—´
>   
> ï¼ˆ2ï¼‰ è¯¥çª—å£å¿…é¡»æœ‰æ•°æ® æ³¨æ„ï¼š[window_start_time,window_end_time) ä¸­æœ‰æ•°æ®å­˜åœ¨ï¼Œå‰é—­åå¼€åŒºé—´

* æ³¨æ„
  ï¼šWatermark æœ¬è´¨å¯ä»¥ç†è§£æˆä¸€ä¸ªå»¶è¿Ÿè§¦å‘æœºåˆ¶ã€‚

##### 2.4 Watermark çš„ä½¿ç”¨å­˜åœ¨ä¸‰ç§æƒ…å†µ

* ï¼ˆ1ï¼‰æœ‰åºçš„æ•°æ®æµä¸­çš„watermark

  ```
  	å¦‚æœæ•°æ®å…ƒç´ çš„äº‹ä»¶æ—¶é—´æ˜¯æœ‰åºçš„ï¼ŒWatermark æ—¶é—´æˆ³ä¼šéšç€æ•°æ®å…ƒç´ çš„äº‹ä»¶æ—¶é—´æŒ‰é¡ºåºç”Ÿæˆï¼Œ
  	æ­¤æ—¶æ°´ä½çº¿çš„å˜åŒ–å’Œäº‹ä»¶æ—¶é—´ä¿æŒä¸€ç›´ï¼ˆå› ä¸ºæ—¢ç„¶æ˜¯æœ‰åºçš„æ—¶é—´ï¼Œå°±ä¸éœ€è¦è®¾ç½®å»¶è¿Ÿäº†ï¼Œé‚£ä¹ˆ t å°±æ˜¯ 0ã€‚
  	æ‰€ä»¥ watermark=maxtime-0 = maxtimeï¼‰ï¼Œä¹Ÿå°±æ˜¯ç†æƒ³çŠ¶æ€ä¸‹çš„æ°´ä½çº¿ã€‚
  	å½“ Watermark æ—¶é—´å¤§äº Windows ç»“æŸæ—¶é—´å°±ä¼šè§¦å‘å¯¹ Windows çš„æ•°æ®è®¡ç®—ï¼Œ
  	ä»¥æ­¤ç±»æ¨ï¼Œ ä¸‹ä¸€ä¸ª Window ä¹Ÿæ˜¯ä¸€æ ·ã€‚

  ```

  ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/30c7be7e2e93440f83d22481cf7a7500.png)
* ï¼ˆ2ï¼‰ä¹±åºçš„æ•°æ®æµwatermark

  ```
  	ç°å®æƒ…å†µä¸‹æ•°æ®å…ƒç´ å¾€å¾€å¹¶ä¸æ˜¯æŒ‰ç…§å…¶äº§ç”Ÿé¡ºåºæ¥å…¥åˆ° Flink ç³»ç»Ÿä¸­è¿›è¡Œå¤„ç†ï¼Œ
  	è€Œé¢‘ç¹å‡ºç°ä¹±åºæˆ–è¿Ÿåˆ°çš„æƒ…å†µï¼Œè¿™ç§æƒ…å†µå°±éœ€è¦ä½¿ç”¨ Watermarks æ¥åº”å¯¹ã€‚
  	æ¯”å¦‚ä¸‹å›¾ï¼Œè®¾ç½®å»¶è¿Ÿæ—¶é—´tä¸º2ã€‚

  ```

  ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/0e2bafa323b143aea4da02e3d4d59a5c.png)
* ï¼ˆ3ï¼‰å¹¶è¡Œæ•°æ®æµä¸­çš„ Watermark

  ```
  	åœ¨å¤šå¹¶è¡Œåº¦çš„æƒ…å†µä¸‹ï¼ŒWatermark ä¼šæœ‰ä¸€ä¸ªå¯¹é½æœºåˆ¶ï¼Œè¿™ä¸ªå¯¹é½æœºåˆ¶ä¼šå–æ‰€æœ‰ Channel ä¸­æœ€å°çš„ Watermarkã€‚

  ```

  ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/f221cedd57984ffca69ade8583883606.png)

##### 2.5 å¼•å…¥watermarkå’Œeventtime

###### 2.5.1 æœ‰åºæ•°æ®æµä¸­å¼•å…¥ Watermark å’Œ EventTime

* å®ƒä¼šå°†æ•°æ®ä¸­çš„timestampæ ¹æ®æŒ‡å®šçš„å­—æ®µæå–å¾—åˆ°Eventtimeï¼Œç„¶åä½¿ç”¨Eventtimeä½œä¸ºæœ€æ–°çš„watermark, è¿™ç§é€‚åˆäºäº‹ä»¶æŒ‰é¡ºåºç”Ÿæˆï¼Œæ²¡æœ‰ä¹±åºäº‹ä»¶çš„æƒ…å†µã€‚
* å¯¹äºæœ‰åºçš„æ•°æ®ï¼Œä»£ç æ¯”è¾ƒç®€æ´ï¼Œä¸»è¦éœ€è¦ä»æº Event ä¸­æŠ½å– EventTimeã€‚
* éœ€æ±‚

  + å¯¹socketä¸­æœ‰åºï¼ˆæŒ‰ç…§æ—¶é—´é€’å¢ï¼‰çš„æ•°æ®æµï¼Œè¿›è¡Œæ¯5så¤„ç†ä¸€æ¬¡
* ä»£ç æ¼”ç¤º

```scala
package com.kaikeba.watermark

import org.apache.commons.lang3.time.FastDateFormat
import org.apache.flink.api.common.functions.{MapFunction}
import org.apache.flink.api.java.tuple.Tuple
import org.apache.flink.streaming.api.TimeCharacteristic
import org.apache.flink.streaming.api.scala.function.ProcessWindowFunction
import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}
import org.apache.flink.streaming.api.windowing.time.Time
import org.apache.flink.streaming.api.windowing.windows.TimeWindow
import org.apache.flink.util.Collector

object OrderedStreamWaterMark {

  def main(args: Array[String]): Unit = {

      //todo:1.æ„å»ºæµå¼å¤„ç†ç¯å¢ƒ
      val environment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
      import org.apache.flink.api.scala._
      environment.setParallelism(1)

     //todo:2.è®¾ç½®æ—¶é—´ç±»å‹
     environment.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)

    //todo:3.è·å–æ•°æ®æº
      val sourceStream: DataStream[String] = environment.socketTextStream("node01",9999)

    //todo:4. æ•°æ®å¤„ç†
      val mapStream: DataStream[(String, Long)] = sourceStream.map(x=>(x.split(",")(0),x.split(",")(1).toLong))

    //todo: 5.ä»æºEventä¸­æŠ½å–eventTime
        val watermarkStream: DataStream[(String, Long)] = mapStream.assignAscendingTimestamps(x=>x._2)


    //todo:6. æ•°æ®è®¡ç®—
     watermarkStream.keyBy(0)
                    .timeWindow(Time.seconds(5))
                    .process(new ProcessWindowFunction[(String, Long),(String,Long),Tuple,TimeWindow] {
                        override def process(key: Tuple, context: Context, elements: Iterable[(String, Long)], out: Collector[(String, Long)]): Unit = {

                          val value: String = key.getField[String](0)

                          //çª—å£çš„å¼€å§‹æ—¶é—´
                          val startTime: Long = context.window.getStart
                          //çª—å£çš„ç»“æŸæ—¶é—´
                          val startEnd: Long = context.window.getEnd

                          //è·å–å½“å‰çš„ watermark
                          val watermark: Long = context.currentWatermark

                          var sum:Long = 0
                          val toList: List[(String, Long)] = elements.toList
                          for(eachElement <-  toList){
                            sum +=1
                          }


                          println("çª—å£çš„æ•°æ®æ¡æ•°:"+sum+
                            " |çª—å£çš„ç¬¬ä¸€æ¡æ•°æ®ï¼š"+toList.head+
                            " |çª—å£çš„æœ€åä¸€æ¡æ•°æ®ï¼š"+toList.last+
                            " |çª—å£çš„å¼€å§‹æ—¶é—´ï¼š "+ startTime+
                            " |çª—å£çš„ç»“æŸæ—¶é—´ï¼š "+ startEnd+
                            " |å½“å‰çš„watermark:"+ watermark)

                          out.collect((value,sum))

                        }
              }).print()

    environment.execute()

  }

}


```

* å‘é€æ•°æ®

```
000001,1461756862000
000001,1461756866000
000001,1461756872000
000001,1461756873000
000001,1461756874000
000001,1461756875000

```

###### 2.5.2 ä¹±åºæ•°æ®æµä¸­å¼•å…¥ Watermark å’Œ EventTime

å¯¹äºä¹±åºæ•°æ®æµï¼Œæœ‰ä¸¤ç§å¸¸è§çš„å¼•å…¥æ–¹æ³•ï¼šå‘¨æœŸæ€§å’Œé—´æ–­æ€§

* 1ã€With Periodicï¼ˆå‘¨æœŸæ€§çš„ï¼‰ Watermark

  ```
  	å‘¨æœŸæ€§åœ°ç”Ÿæˆ Watermark çš„ç”Ÿæˆï¼Œé»˜è®¤æ˜¯ 100msã€‚æ¯éš” N æ¯«ç§’è‡ªåŠ¨å‘æµé‡Œæ³¨å…¥ä¸€ä¸ª Watermarkï¼Œæ—¶é—´é—´éš”ç”± streamEnv.getConfig.setAutoWatermarkInterval()å†³å®šã€‚

  ```

  + éœ€æ±‚
    - å¯¹socketä¸­æ— åºæ•°æ®æµï¼Œè¿›è¡Œæ¯5så¤„ç†ä¸€æ¬¡ï¼Œæ•°æ®ä¸­ä¼šæœ‰å»¶è¿Ÿ
  + ä»£ç æ¼”ç¤º

  ```scala
  package com.kaikeba.watermark

  import org.apache.flink.api.java.tuple.Tuple
  import org.apache.flink.streaming.api.TimeCharacteristic
  import org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks
  import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}
  import org.apache.flink.streaming.api.scala.function.ProcessWindowFunction
  import org.apache.flink.streaming.api.watermark.Watermark
  import org.apache.flink.streaming.api.windowing.time.Time
  import org.apache.flink.streaming.api.windowing.windows.TimeWindow
  import org.apache.flink.util.Collector
    //å¯¹æ— åºçš„æ•°æ®æµå‘¨æœŸæ€§çš„æ·»åŠ æ°´å°
    object OutOfOrderStreamPeriodicWaterMark {
      def main(args: Array[String]): Unit = {
           //todo:1.æ„å»ºæµå¼å¤„ç†ç¯å¢ƒ
      val environment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
      import org.apache.flink.api.scala._
      environment.setParallelism(1)
           //todo:2.è®¾ç½®æ—¶é—´ç±»å‹
     environment.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)

    //todo:3.è·å–æ•°æ®æº
      val sourceStream: DataStream[String] = environment.socketTextStream("node01",9999)

    //todo:4. æ•°æ®å¤„ç†
      val mapStream: DataStream[(String, Long)] = sourceStream.map(x=>(x.split(",")(0),x.split(",")(1).toLong))
          //todo:5. æ·»åŠ æ°´ä½çº¿
    mapStream.assignTimestampsAndWatermarks(
        new AssignerWithPeriodicWatermarks[(String, Long)] {

        //å®šä¹‰å»¶è¿Ÿæ—¶é—´é•¿åº¦
        //è¡¨ç¤ºåœ¨5ç§’ä»¥å†…çš„æ•°æ®å»¶æ—¶æœ‰æ•ˆï¼Œè¶…è¿‡5ç§’çš„æ•°æ®è¢«è®¤å®šä¸ºè¿Ÿåˆ°äº‹ä»¶

        val maxOutOfOrderness=5000L
        //å†å²æœ€å¤§äº‹ä»¶æ—¶é—´
        var currentMaxTimestamp:Long=_

        var watermark:Watermark=_

         //å‘¨æœŸæ€§çš„ç”Ÿæˆæ°´ä½çº¿watermark
        override def getCurrentWatermark: Watermark ={
          watermark =  new Watermark(currentMaxTimestamp -maxOutOfOrderness)
          watermark
        }

        //æŠ½å–äº‹ä»¶æ—¶é—´
        override def extractTimestamp(element: (String, Long), previousElementTimestamp: Long): Long ={
            //è·å–äº‹ä»¶æ—¶é—´
            val currentElementEventTime: Long = element._2

            //å¯¹æ¯”å½“å‰äº‹ä»¶æ—¶é—´å’Œå†å²æœ€å¤§äº‹ä»¶æ—¶é—´, å°†è¾ƒå¤§å€¼é‡æ–°èµ‹å€¼ç»™currentMaxTimestamp
            currentMaxTimestamp=Math.max(currentMaxTimestamp,currentElementEventTime)
            println("æ¥å—åˆ°çš„äº‹ä»¶ï¼š"+element+" |äº‹ä»¶æ—¶é—´ï¼š "+currentElementEventTime)

            currentElementEventTime
        }
      })
          .keyBy(0)
          .timeWindow(Time.seconds(5))
          .process(new ProcessWindowFunction[(String, Long),(String,Long),Tuple,TimeWindow] {
            override def process(key: Tuple, context: Context, elements: Iterable[(String, Long)], out: Collector[(String, Long)]): Unit = {
         val value: String = key.getField[String](0)
             //çª—å£çš„å¼€å§‹æ—¶é—´
              val startTime: Long = context.window.getStart
              //çª—å£çš„ç»“æŸæ—¶é—´
              val startEnd: Long = context.window.getEnd

              //è·å–å½“å‰çš„ watermark
              val watermark: Long = context.currentWatermark

              var sum:Long = 0
              val toList: List[(String, Long)] = elements.toList
              for(eachElement <-  toList){
                sum +=1
              }
              //çª—å£çš„å¼€å§‹æ—¶é—´
              val startTime: Long = context.window.getStart
              //çª—å£çš„ç»“æŸæ—¶é—´
              val startEnd: Long = context.window.getEnd

              //è·å–å½“å‰çš„ watermark
              val watermark: Long = context.currentWatermark

              var sum:Long = 0
              val toList: List[(String, Long)] = elements.toList
              for(eachElement <-  toList){
                sum +=1
              }  
              println("çª—å£çš„æ•°æ®æ¡æ•°:"+sum+
                " |çª—å£çš„ç¬¬ä¸€æ¡æ•°æ®ï¼š"+toList.head+
                " |çª—å£çš„æœ€åä¸€æ¡æ•°æ®ï¼š"+toList.last+
                " |çª—å£çš„å¼€å§‹æ—¶é—´ï¼š "+  startTime +
                " |çª—å£çš„ç»“æŸæ—¶é—´ï¼š "+ startEnd+
                " |å½“å‰çš„watermark:"+watermark)

              out.collect((value,sum))

            }
          }).print()       
         environment.execute() 
      }  
    }     

  ```

  + å‘é€æ•°æ®

  ```
  000001,1461756862000
  000001,1461756872000
  000001,1461756866000
  000001,1461756873000
  000001,1461756874000
  000001,1461756875000
  000001,1461756879000
  000001,1461756880000

  ```
* 2ã€With Punctuatedï¼ˆé—´æ–­æ€§çš„ï¼‰ Watermark

  ```
    é—´æ–­æ€§çš„ç”Ÿæˆ Watermark ä¸€èˆ¬æ˜¯åŸºäºæŸäº›äº‹ä»¶è§¦å‘ Watermark çš„ç”Ÿæˆå’Œå‘é€ã€‚
    æ¯”å¦‚è¯´åªç»™ç”¨æˆ·idä¸º000001çš„æ·»åŠ watermarkï¼Œå…¶ä»–çš„ç”¨æˆ·å°±ä¸æ·»åŠ 

  ```

  + éœ€æ±‚

    - å¯¹socketä¸­æ— åºæ•°æ®æµï¼Œè¿›è¡Œæ¯5så¤„ç†ä¸€æ¬¡ï¼Œæ•°æ®ä¸­ä¼šæœ‰å»¶è¿Ÿ
  + ä»£ç æ¼”ç¤º

  ```scala
    package com.kaikeba.watermark

          import org.apache.commons.lang3.time.FastDateFormat
          import org.apache.flink.api.common.functions.MapFunction
          import org.apache.flink.api.java.tuple.Tuple
          import org.apache.flink.streaming.api.TimeCharacteristic
          import org.apache.flink.streaming.api.functions.{AssignerWithPeriodicWatermarks, AssignerWithPunctuatedWatermarks}
          import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}
          import org.apache.flink.streaming.api.scala.function.ProcessWindowFunction
          import org.apache.flink.streaming.api.watermark.Watermark
          import org.apache.flink.streaming.api.windowing.time.Time
          import org.apache.flink.streaming.api.windowing.windows.TimeWindow
          import org.apache.flink.util.Collector

          //å¯¹æ— åºçš„æ•°æ®æµé—´æ–­æ€§çš„æ·»åŠ æ°´å°
          object OutOfOrderStreamPunctuatedWaterMark {

            def main(args: Array[String]): Unit = {
                        //todo:1.æ„å»ºæµå¼å¤„ç†ç¯å¢ƒ
                val environment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
                import org.apache.flink.api.scala._
                environment.setParallelism(1)
                        //todo:2.è®¾ç½®æ—¶é—´ç±»å‹
                environment.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
        
                //todo:3.è·å–æ•°æ®æº
                val sourceStream: DataStream[String] = environment.socketTextStream("node01",9999)
        
                //todo:4. æ•°æ®å¤„ç†
                val mapStream: DataStream[(String, Long)] = sourceStream.map(x=>(x.split(",")(0),x.split(",")(1).toLong))
                        //todo:5. æ·»åŠ æ°´ä½çº¿
                mapStream.assignTimestampsAndWatermarks(
                  new AssignerWithPunctuatedWatermarks[(String, Long)] {
        
                    //å®šä¹‰å»¶è¿Ÿæ—¶é—´é•¿åº¦
                    //è¡¨ç¤ºåœ¨5ç§’ä»¥å†…çš„æ•°æ®å»¶æ—¶æœ‰æ•ˆï¼Œè¶…è¿‡5ç§’çš„æ•°æ®è¢«è®¤å®šä¸ºè¿Ÿåˆ°äº‹ä»¶
                    val maxOutOfOrderness=5000L
                    //å†å²æœ€å¤§äº‹ä»¶æ—¶é—´
                    var currentMaxTimestamp:Long=_
        
                    override def checkAndGetNextWatermark(lastElement: (String, Long), extractedTimestamp: Long): Watermark ={
                            //å½“ç”¨æˆ·idä¸º000001ç”Ÿæˆwatermark
                           if(lastElement._1.equals("000001")){
        
                              val watermark=  new Watermark(currentMaxTimestamp-maxOutOfOrderness)
        
                              watermark
                           }else{
                             //å…¶ä»–æƒ…å†µä¸‹ä¸è¿”å›æ°´ä½çº¿
                              null
                           }
        
                    }
        
                    override def extractTimestamp(element: (String, Long), previousElementTimestamp: Long): Long = {
                      //è·å–äº‹ä»¶æ—¶é—´
                      val currentElementEventTime: Long = element._2
        
                      //å¯¹æ¯”å½“å‰äº‹ä»¶æ—¶é—´å’Œå†å²æœ€å¤§äº‹ä»¶æ—¶é—´, å°†è¾ƒå¤§å€¼é‡æ–°èµ‹å€¼ç»™currentMaxTimestamp
                      currentMaxTimestamp=Math.max(currentMaxTimestamp,currentElementEventTime)
        
                      println("æ¥å—åˆ°çš„äº‹ä»¶ï¼š"+element+" |äº‹ä»¶æ—¶é—´ï¼š "+currentElementEventTime )
        
                      currentElementEventTime
        
                    }
                  })
                  .keyBy(0)
                  .timeWindow(Time.seconds(5))
                  .process(new ProcessWindowFunction[(String, Long),(String,Long),Tuple,TimeWindow] {
                      override def process(key: Tuple, context: Context, elements: Iterable[(String, Long)], out: Collector[(String, Long)]): Unit = {
        
                        val value: String = key.getField[String](0)
        
                        //çª—å£çš„å¼€å§‹æ—¶é—´
                        val startTime: Long = context.window.getStart
                        //çª—å£çš„ç»“æŸæ—¶é—´
                        val startEnd: Long = context.window.getEnd
        
                        //è·å–å½“å‰çš„ watermark
                        val watermark: Long = context.currentWatermark
        
                        var sum:Long = 0
                        val toList: List[(String, Long)] = elements.toList
                        for(eachElement <-  toList){
                          sum +=1
                        }
        
                        println("çª—å£çš„æ•°æ®æ¡æ•°:"+sum+
                          " |çª—å£çš„ç¬¬ä¸€æ¡æ•°æ®ï¼š"+toList.head+
                          " |çª—å£çš„æœ€åä¸€æ¡æ•°æ®ï¼š"+toList.last+
                          " |çª—å£çš„å¼€å§‹æ—¶é—´ï¼š "+startTime +
                          " |çª—å£çš„ç»“æŸæ—¶é—´ï¼š "+startEnd+
                          " |å½“å‰çš„watermark:"+watermark)
        
                        out.collect((value,sum))
        
                      }
                    }).print()
                 environment.execute()
                }
             }        

  ```

  + å‘é€æ•°æ®

  ```
  000001,1461756862000
  000001,1461756866000
  000001,1461756872000
  000002,1461756867000
  000002,1461756868000
  000002,1461756875000
  000001,1461756875000

  ```

###### 2.5.3 Window çš„allowedLatenesså¤„ç†å»¶è¿Ÿå¤ªå¤§çš„æ•°æ®

```
	åŸºäº Event-Time çš„çª—å£å¤„ç†æµå¼æ•°æ®ï¼Œè™½ç„¶æä¾›äº† Watermark æœºåˆ¶ï¼Œå´åªèƒ½åœ¨ä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº†æ•°æ®ä¹±åºçš„é—®é¢˜ã€‚ä½†åœ¨æŸäº›æƒ…å†µä¸‹æ•°æ®å¯èƒ½å»¶æ—¶ä¼šéå¸¸ä¸¥é‡ï¼Œå³ä½¿é€šè¿‡ Watermark æœºåˆ¶ä¹Ÿæ— æ³•ç­‰åˆ°æ•°æ®å…¨éƒ¨è¿›å…¥çª—å£å†è¿›è¡Œå¤„ç†ã€‚
	
	Flink ä¸­é»˜è®¤ä¼šå°†è¿™äº›è¿Ÿåˆ°çš„æ•°æ®åšä¸¢å¼ƒå¤„ç†ï¼Œä½†æ˜¯æœ‰äº›æ—¶å€™ç”¨æˆ·å¸Œæœ›å³ä½¿æ•°æ®å»¶è¿Ÿåˆ°è¾¾çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½å¤Ÿæ­£å¸¸æŒ‰ç…§æµç¨‹å¤„ç†å¹¶è¾“å‡ºç»“æœï¼Œæ­¤æ—¶å°±éœ€è¦ä½¿ç”¨ Allowed Lateness æœºåˆ¶æ¥å¯¹è¿Ÿåˆ°çš„æ•°æ®è¿›è¡Œé¢å¤–çš„å¤„ç†ã€‚

```

* è¿Ÿåˆ°æ•°æ®çš„å¤„ç†æœºåˆ¶

  + 1ã€ç›´æ¥ä¸¢å¼ƒ
  + 2ã€æŒ‡å®šå…è®¸å†æ¬¡è¿Ÿåˆ°çš„æ—¶é—´

    ```scala
    //ä¾‹å¦‚
    assignTimestampsAndWatermarks(new EventTimeExtractor() )
                    .keyBy(0)
                    .timeWindow(Time.seconds(3))
                    .allowedLateness(Time.seconds(2)) // å…è®¸äº‹ä»¶å†è¿Ÿåˆ°2ç§’
                    .process(new SumProcessWindowFunction())
                    .print().setParallelism(1);

    //æ³¨æ„ï¼š
    //ï¼ˆ1ï¼‰. å½“æˆ‘ä»¬è®¾ç½®å…è®¸è¿Ÿåˆ°2ç§’çš„äº‹ä»¶ï¼Œç¬¬ä¸€æ¬¡ window è§¦å‘çš„æ¡ä»¶æ˜¯ watermark >= window_end_time
    //ï¼ˆ2ï¼‰. ç¬¬äºŒæ¬¡(æˆ–è€…å¤šæ¬¡)è§¦å‘çš„æ¡ä»¶æ˜¯watermark < window_end_time + allowedLateness

    ```
  + 3ã€æ”¶é›†è¿Ÿåˆ°å¤ªå¤šçš„æ•°æ®

    ```scala
    //ä¾‹å¦‚
    assignTimestampsAndWatermarks(new EventTimeExtractor() )
                    .keyBy(0)
                    .timeWindow(Time.seconds(3))
                    .allowedLateness(Time.seconds(2)) //å…è®¸äº‹ä»¶è¿Ÿåˆ°2ç§’
                    .sideOutputLateData(outputTag)    //æ”¶é›†è¿Ÿåˆ°å¤ªå¤šçš„æ•°æ®
                    .process(new SumProcessWindowFunction())
                    .print().setParallelism(1);

    ```
* ä»£ç æ¼”ç¤º

  ```scala
  package com.kaikeba.watermark

  import org.apache.commons.lang3.time.FastDateFormat
  import org.apache.flink.api.common.functions.MapFunction
  import org.apache.flink.api.java.tuple.Tuple
  import org.apache.flink.streaming.api.TimeCharacteristic
  import org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks
  import org.apache.flink.streaming.api.scala.{DataStream, OutputTag, StreamExecutionEnvironment}
  import org.apache.flink.streaming.api.scala.function.ProcessWindowFunction
  import org.apache.flink.streaming.api.watermark.Watermark
  import org.apache.flink.streaming.api.windowing.time.Time
  import org.apache.flink.streaming.api.windowing.windows.TimeWindow
  import org.apache.flink.util.Collector

  //è¿è¡Œæ•°æ®å†æ¬¡å»¶å»¶è¿Ÿä¸€æ®µæ—¶é—´ï¼Œå¹¶ä¸”å¯¹å»¶è¿Ÿå¤ªå¤šçš„æ•°æ®è¿›è¡Œæ”¶é›†
  object AllowedLatenessTest {

    def main(args: Array[String]): Unit = {
        //todo:1.æ„å»ºæµå¼å¤„ç†ç¯å¢ƒ
        val environment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
        import org.apache.flink.api.scala._
        environment.setParallelism(1)
        //todo:2.è®¾ç½®æ—¶é—´ç±»å‹
     environment.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)

    //todo:3.è·å–æ•°æ®æº
      val sourceStream: DataStream[String] = environment.socketTextStream("node01",9999)

    //todo:4. æ•°æ®å¤„ç†
      val mapStream: DataStream[(String, Long)] = sourceStream.map(x=>(x.split(",")(0),x.split(",")(1).toLong))

    //å®šä¹‰ä¸€ä¸ªä¾§è¾“å‡ºæµçš„æ ‡ç­¾ï¼Œç”¨äºæ”¶é›†è¿Ÿåˆ°å¤ªå¤šçš„æ•°æ®
      val lateTag=new OutputTag[(String, Long)]("late")

    //todo:5.  æ•°æ®è®¡ç®—--æ·»åŠ æ°´ä½çº¿
    val result: DataStream[(String, Long)] = mapStream.assignTimestampsAndWatermarks(
            new AssignerWithPeriodicWatermarks[(String, Long)] {

              //å®šä¹‰å»¶è¿Ÿæ—¶é—´é•¿åº¦
              //è¡¨ç¤ºåœ¨5ç§’ä»¥å†…çš„æ•°æ®å»¶æ—¶æœ‰æ•ˆï¼Œè¶…è¿‡5ç§’çš„æ•°æ®è¢«è®¤å®šä¸ºè¿Ÿåˆ°äº‹ä»¶
              val maxOutOfOrderness = 5000L
              //å†å²æœ€å¤§äº‹ä»¶æ—¶é—´
              var currentMaxTimestamp: Long = _ 
                    //å‘¨æœŸæ€§çš„ç”Ÿæˆæ°´ä½çº¿watermark
              override def getCurrentWatermark: Watermark = {
                val watermark = new Watermark(currentMaxTimestamp - maxOutOfOrderness)
                watermark
              }

              //æŠ½å–äº‹ä»¶æ—¶é—´
              override def extractTimestamp(element: (String, Long), previousElementTimestamp: Long): Long = {
                //è·å–äº‹ä»¶æ—¶é—´
                val currentElementEventTime: Long = element._2

                //å¯¹æ¯”å½“å‰äº‹ä»¶æ—¶é—´å’Œå†å²æœ€å¤§äº‹ä»¶æ—¶é—´, å°†è¾ƒå¤§å€¼é‡æ–°èµ‹å€¼ç»™currentMaxTimestamp
                currentMaxTimestamp = Math.max(currentMaxTimestamp, currentElementEventTime)

                println("æ¥å—åˆ°çš„äº‹ä»¶ï¼š" + element + " |äº‹ä»¶æ—¶é—´ï¼š " + currentElementEventTime )

                currentElementEventTime
              }
      })
              .keyBy(0)
              .timeWindow(Time.seconds(5))
              .allowedLateness(Time.seconds(2)) //å…è®¸æ•°æ®å»¶è¿Ÿ2s
              .sideOutputLateData(lateTag)     //æ”¶é›†å»¶è¿Ÿå¤§å¤šçš„æ•°æ®
              .process(new ProcessWindowFunction[(String, Long), (String, Long), Tuple, TimeWindow] {
                        override def process(key: Tuple, context: Context, elements: Iterable[(String, Long)], out: Collector[(String, Long)]): Unit = {

                          val value: String = key.getField[String](0)

                          //çª—å£çš„å¼€å§‹æ—¶é—´
                          val startTime: Long = context.window.getStart
                          //çª—å£çš„ç»“æŸæ—¶é—´
                          val startEnd: Long = context.window.getEnd

                          //è·å–å½“å‰çš„ watermark
                          val watermark: Long = context.currentWatermark

                          var sum: Long = 0
                          val toList: List[(String, Long)] = elements.toList

                          for (eachElement <- toList) {
                            sum += 1
                          }
                                println("çª—å£çš„æ•°æ®æ¡æ•°:" + sum +
                            " |çª—å£çš„ç¬¬ä¸€æ¡æ•°æ®ï¼š" + toList.head +
                            " |çª—å£çš„æœ€åä¸€æ¡æ•°æ®ï¼š" + toList.last +
                            " |çª—å£çš„å¼€å§‹æ—¶é—´ï¼š " + startTime +
                            " |çª—å£çš„ç»“æŸæ—¶é—´ï¼š " + startEnd +
                            " |å½“å‰çš„watermark:" + watermark)

                          out.collect((value, sum))

              }
            })

    //æ‰“å°å»¶è¿Ÿå¤ªå¤šçš„æ•°æ®
    result.getSideOutput(lateTag).print("late")

    //æ‰“å°
    result.print("ok")
        
    environment.execute()
      
    }
  }                  

  ```
* å‘é€æ•°æ®

  ```
  000001,1461756862000
  000001,1461756866000
  000001,1461756868000
  000001,1461756869000
  000001,1461756870000
  000001,1461756862000
  000001,1461756871000
  000001,1461756872000
  000001,1461756862000
  000001,1461756863000

  ```

###### 2.5.4 å¤šå¹¶è¡Œåº¦ä¸‹çš„WaterMark

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/69eccf0550ac42efa678bb61e6eda9d5.png)

```
æœ¬åœ°æµ‹è¯•çš„è¿‡ç¨‹ä¸­ï¼Œå¦‚æœä¸è®¾ç½®å¹¶è¡Œåº¦çš„è¯ï¼Œ
é»˜è®¤è¯»å–æœ¬æœºCPUæ•°é‡è®¾ç½®å¹¶è¡Œåº¦ï¼Œ
å¯ä»¥æ‰‹åŠ¨è®¾ç½®å¹¶è¡Œåº¦environment.setParallelism(1)ï¼Œæ¯ä¸€ä¸ªçº¿ç¨‹éƒ½ä¼šæœ‰ä¸€ä¸ªwatermark.
å¤šå¹¶è¡Œåº¦çš„æƒ…å†µä¸‹,ä¸€ä¸ªwindowå¯èƒ½ä¼šæ¥å—åˆ°å¤šä¸ªä¸åŒçº¿ç¨‹waterMarkï¼Œ

```

* watermarkå¯¹é½ä¼šå–æ‰€æœ‰channelæœ€å°çš„watermarkï¼Œä»¥æœ€å°çš„watermarkä¸ºå‡†ã€‚
* æ¡ˆä¾‹æ¼”ç¤º

  ```scala

  package com.kaikeba.watermark

  import org.apache.flink.api.java.tuple.Tuple
  import org.apache.flink.streaming.api.TimeCharacteristic
  import org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks
  import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}
  import org.apache.flink.streaming.api.scala.function.ProcessWindowFunction
  import org.apache.flink.streaming.api.watermark.Watermark
  import org.apache.flink.streaming.api.windowing.time.Time
  import org.apache.flink.streaming.api.windowing.windows.TimeWindow
  import org.apache.flink.util.Collector

  /**
    * å¾—åˆ°å¹¶æ‰“å°æ¯éš” 5 ç§’é’Ÿç»Ÿè®¡å‰ 5ç§’å†…çš„ç›¸åŒçš„ key çš„æ‰€æœ‰çš„äº‹ä»¶
    * æµ‹è¯•å¤šå¹¶è¡Œåº¦ä¸‹çš„watermark
    */
  object WaterMarkWindowWithMultipart {

    def main(args: Array[String]): Unit = {
          //todo:1.æ„å»ºæµå¼å¤„ç†ç¯å¢ƒ
    val environment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
    import org.apache.flink.api.scala._
    
    //è®¾ç½®å¹¶è¡Œåº¦ä¸º2
    environment.setParallelism(2)
    //todo:2.è®¾ç½®æ—¶é—´ç±»å‹
    environment.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)

    //todo:3.è·å–æ•°æ®æº
    val sourceStream: DataStream[String] = environment.socketTextStream("node01",9999)

    //todo:4. æ•°æ®å¤„ç†
    val mapStream: DataStream[(String, Long)] = sourceStream.map(x=>(x.split(",")(0),x.split(",")(1).toLong))

    //todo:5. æ·»åŠ æ°´ä½çº¿
    mapStream.assignTimestampsAndWatermarks(
      new AssignerWithPeriodicWatermarks[(String, Long)] {

        //å®šä¹‰å»¶è¿Ÿæ—¶é—´é•¿åº¦
        //è¡¨ç¤ºåœ¨5ç§’ä»¥å†…çš„æ•°æ®å»¶æ—¶æœ‰æ•ˆï¼Œè¶…è¿‡5ç§’çš„æ•°æ®è¢«è®¤å®šä¸ºè¿Ÿåˆ°äº‹ä»¶

        val maxOutOfOrderness=5000L
        //å†å²æœ€å¤§äº‹ä»¶æ—¶é—´
        var currentMaxTimestamp:Long=_
               //å‘¨æœŸæ€§çš„ç”Ÿæˆæ°´ä½çº¿watermark
        override def getCurrentWatermark: Watermark ={
         val  watermark =  new Watermark(currentMaxTimestamp -maxOutOfOrderness)
          watermark
        }

        //æŠ½å–äº‹ä»¶æ—¶é—´
        override def extractTimestamp(element: (String, Long), previousElementTimestamp: Long): Long ={
          //è·å–äº‹ä»¶æ—¶é—´
          val currentElementEventTime: Long = element._2

          //å¯¹æ¯”å½“å‰äº‹ä»¶æ—¶é—´å’Œå†å²æœ€å¤§äº‹ä»¶æ—¶é—´, å°†è¾ƒå¤§å€¼é‡æ–°èµ‹å€¼ç»™currentMaxTimestamp
          currentMaxTimestamp=Math.max(currentMaxTimestamp,currentElementEventTime)

          val id: Long = Thread.currentThread.getId
          println("å½“å‰çš„çº¿ç¨‹id:"+id+" |æ¥å—åˆ°çš„äº‹ä»¶ï¼š"+element+" |äº‹ä»¶æ—¶é—´ï¼š "+currentElementEventTime+" |å½“å‰å€¼çš„watermark:"+getCurrentWatermark().getTimestamp())

          currentElementEventTime
        }
      })
      .keyBy(0)
      .timeWindow(Time.seconds(5))
      .process(new ProcessWindowFunction[(String, Long),(String,Long),Tuple,TimeWindow] {
        override def process(key: Tuple, context: Context, elements: Iterable[(String, Long)], out: Collector[(String, Long)]): Unit = {

          val value: String = key.getField[String](0)

          //çª—å£çš„å¼€å§‹æ—¶é—´
          val startTime: Long = context.window.getStart
          //çª—å£çš„ç»“æŸæ—¶é—´
          val startEnd: Long = context.window.getEnd

          //è·å–å½“å‰çš„ watermark
          val watermark: Long = context.currentWatermark

          var sum:Long = 0
          val toList: List[(String, Long)] = elements.toList
          for(eachElement <-  toList){
            sum +=1
          } 
               println("çª—å£çš„æ•°æ®æ¡æ•°:"+sum+
            " |çª—å£çš„ç¬¬ä¸€æ¡æ•°æ®ï¼š"+toList.head+
            " |çª—å£çš„æœ€åä¸€æ¡æ•°æ®ï¼š"+toList.last+
            " |çª—å£çš„å¼€å§‹æ—¶é—´ï¼š "+  startTime +
            " |çª—å£çš„ç»“æŸæ—¶é—´ï¼š "+ startEnd+
            " |å½“å‰çš„watermark:"+ watermark)

          out.collect((value,sum))

        }
      }).print()
      environment.execute()

  		}    
      }

  ```
* è¾“å…¥æ•°æ®

  ```
  000001,1461756862000
  000001,1461756864000
  000001,1461756866000
  000001,1461756870000
  000001,1461756871000

  ```
* è¾“å‡ºç»“æœ

  ```
  å½“å‰çš„çº¿ç¨‹id:65 |æ¥å—åˆ°çš„äº‹ä»¶ï¼š(000001,1461756862000) |äº‹ä»¶æ—¶é—´ï¼š 1461756862000 |å½“å‰å€¼çš„watermark:1461756857000
  å½“å‰çš„çº¿ç¨‹id:64 |æ¥å—åˆ°çš„äº‹ä»¶ï¼š(000001,1461756864000) |äº‹ä»¶æ—¶é—´ï¼š 1461756864000 |å½“å‰å€¼çš„watermark:1461756859000
  å½“å‰çš„çº¿ç¨‹id:65 |æ¥å—åˆ°çš„äº‹ä»¶ï¼š(000001,1461756866000) |äº‹ä»¶æ—¶é—´ï¼š 1461756866000 |å½“å‰å€¼çš„watermark:1461756861000
  å½“å‰çš„çº¿ç¨‹id:64 |æ¥å—åˆ°çš„äº‹ä»¶ï¼š(000001,1461756870000) |äº‹ä»¶æ—¶é—´ï¼š 1461756870000 |å½“å‰å€¼çš„watermark:1461756865000
  å½“å‰çš„çº¿ç¨‹id:65 |æ¥å—åˆ°çš„äº‹ä»¶ï¼š(000001,1461756871000) |äº‹ä»¶æ—¶é—´ï¼š 1461756871000 |å½“å‰å€¼çš„watermark:1461756866000
  çª—å£çš„æ•°æ®æ¡æ•°:2 |çª—å£çš„ç¬¬ä¸€æ¡æ•°æ®ï¼š(000001,1461756862000) |çª—å£çš„æœ€åä¸€æ¡æ•°æ®ï¼š(000001,1461756864000) |çª—å£çš„å¼€å§‹æ—¶é—´ï¼š 1461756860000 |çª—å£çš„ç»“æŸæ—¶é—´ï¼š 1461756865000 |å½“å‰çš„watermark:1461756865000
  2> (000001,2)

  ```
* ç»“æœåˆ†æ

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/f80483414e684a5e88fe033bfa9d9698.png)

### ğŸ“– 3. Flinkçš„Tableå’ŒSQL

##### 3.1 Tableä¸SQLåŸºæœ¬ä»‹ç»

```
	åœ¨Sparkä¸­æœ‰DataFrameè¿™æ ·çš„å…³ç³»å‹ç¼–ç¨‹æ¥å£ï¼Œå› å…¶å¼ºå¤§ä¸”çµæ´»çš„è¡¨è¾¾èƒ½åŠ›ï¼Œ
	èƒ½å¤Ÿè®©ç”¨æˆ·é€šè¿‡éå¸¸ä¸°å¯Œçš„æ¥å£å¯¹æ•°æ®è¿›è¡Œå¤„ç†ï¼Œæœ‰æ•ˆé™ä½äº†ç”¨æˆ·çš„ä½¿ç”¨æˆæœ¬ã€‚

	Flinkä¹Ÿæä¾›äº†å…³ç³»å‹ç¼–ç¨‹æ¥å£ Table API ä»¥åŠåŸºäºTable API çš„ SQL APIï¼Œ
	è®©ç”¨æˆ·èƒ½å¤Ÿé€šè¿‡ä½¿ç”¨ç»“æ„åŒ–ç¼–ç¨‹æ¥å£é«˜æ•ˆåœ°æ„å»ºFlinkåº”ç”¨ã€‚
	åŒæ—¶Table API ä»¥åŠ SQL èƒ½å¤Ÿç»Ÿä¸€å¤„ç†æ‰¹é‡å’Œå®æ—¶è®¡ç®—ä¸šåŠ¡ï¼Œ 
	æ— é¡»åˆ‡æ¢ä¿®æ”¹ä»»ä½•åº”ç”¨ä»£ç å°±èƒ½å¤ŸåŸºäºåŒä¸€å¥— API ç¼–å†™æµå¼åº”ç”¨å’Œæ‰¹é‡åº”ç”¨ï¼Œä»è€Œè¾¾åˆ°çœŸæ­£æ„ä¹‰çš„æ‰¹æµç»Ÿä¸€ã€‚

```

* Apache Flink å…·æœ‰ä¸¤ä¸ªå…³ç³»å‹APIï¼šTable API å’ŒSQLï¼Œç”¨äºç»Ÿä¸€æµå’Œæ‰¹å¤„ç†
* Table API æ˜¯ç”¨äº Scala å’Œ Java è¯­è¨€çš„æŸ¥è¯¢APIï¼Œå…è®¸ä»¥éå¸¸ç›´è§‚çš„æ–¹å¼ç»„åˆå…³ç³»è¿ç®—ç¬¦çš„æŸ¥è¯¢ï¼Œä¾‹å¦‚ selectï¼Œfilter å’Œ joinã€‚Flink SQL çš„æ”¯æŒæ˜¯åŸºäºå®ç°äº†SQLæ ‡å‡†çš„ Apache Calciteã€‚æ— è®ºè¾“å…¥æ˜¯æ‰¹è¾“å…¥ï¼ˆDataSetï¼‰è¿˜æ˜¯æµè¾“å…¥ï¼ˆDataStreamï¼‰ï¼Œä»»ä¸€æ¥å£ä¸­æŒ‡å®šçš„æŸ¥è¯¢éƒ½å…·æœ‰ç›¸åŒçš„è¯­ä¹‰å¹¶æŒ‡å®šç›¸åŒçš„ç»“æœã€‚
* Table APIå’ŒSQLæ¥å£å½¼æ­¤é›†æˆï¼ŒFlinkçš„DataStreamå’ŒDataSet APIäº¦æ˜¯å¦‚æ­¤ã€‚æˆ‘ä»¬å¯ä»¥è½»æ¾åœ°åœ¨åŸºäºAPIæ„å»ºçš„æ‰€æœ‰APIå’Œåº“ä¹‹é—´åˆ‡æ¢ã€‚
* æ³¨æ„ï¼Œåˆ°ç›®å‰æœ€æ–°ç‰ˆæœ¬ä¸ºæ­¢ï¼ŒTable APIå’ŒSQLè¿˜æœ‰å¾ˆå¤šåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ã€‚ å¹¶é[Table APIï¼ŒSQL]å’Œ[streamï¼Œbatch]è¾“å…¥çš„æ¯ç§ç»„åˆéƒ½æ”¯æŒæ‰€æœ‰æ“ä½œ

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/a38684e85d2a47f985a71a34182f4b46.png)

##### 3.2 ä¸ºä»€ä¹ˆéœ€è¦SQL

* Table API æ˜¯ä¸€ç§å…³ç³»å‹APIï¼Œç±» SQL çš„APIï¼Œç”¨æˆ·å¯ä»¥åƒæ“ä½œè¡¨ä¸€æ ·åœ°æ“ä½œæ•°æ®ï¼Œ éå¸¸çš„ç›´è§‚å’Œæ–¹ä¾¿ã€‚
* SQL ä½œä¸ºä¸€ä¸ª"äººæ‰€çš†çŸ¥"çš„è¯­è¨€ï¼Œå¦‚æœä¸€ä¸ªå¼•æ“æä¾› SQLï¼Œå®ƒå°†å¾ˆå®¹æ˜“è¢«äººä»¬æ¥å—ã€‚è¿™å·²ç»æ˜¯ä¸šç•Œå¾ˆå¸¸è§çš„ç°è±¡äº†ã€‚
* Table & SQL API è¿˜æœ‰å¦ä¸€ä¸ªèŒè´£ï¼Œå°±æ˜¯æµå¤„ç†å’Œæ‰¹å¤„ç†ç»Ÿä¸€çš„APIå±‚ã€‚

  ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/bc5e12b0c68a4d0a8d28e293807cd78f.png)

##### 3.3 å¼€å‘ç¯å¢ƒæ„å»º

* åœ¨ Flink 1.9 ä¸­ï¼ŒTable æ¨¡å—è¿æ¥äº†æ ¸å¿ƒæ¶æ„çš„å‡çº§ï¼Œå¼•å…¥äº†é˜¿é‡Œå·´å·´ Blink å›¢é˜Ÿè´¡çŒ®çš„è¯¸å¤šåŠŸèƒ½ï¼Œå–åå«ï¼š Blink Plannerã€‚
* åœ¨ä½¿ç”¨ Table API å’Œ SQL å¼€å‘ Flink åº”ç”¨ä¹‹å‰ï¼Œé€šè¿‡æ·»åŠ  Maven çš„ä¾èµ–é…ç½®åˆ°é¡¹ç›®ä¸­ï¼Œåœ¨æœ¬åœ°å·¥ç¨‹ä¸­å¼•å…¥ç›¸åº”çš„ä¾èµ–åº“ï¼Œåº“ä¸­åŒ…å«äº† Table API å’Œ SQL æ¥å£ã€‚
* æ·»åŠ pomä¾èµ–

  ```xml
   <dependency>
       <groupId>org.apache.flink</groupId>
       <artifactId>flink-table-planner_2.11</artifactId>
       <version>1.9.2</version>
   </dependency>

   <dependency>
       <groupId>org.apache.flink</groupId>
       <artifactId>flink-table-api-scala-bridge_2.11</artifactId>
       <version>1.9.2</version>
   </dependency>

  ```

##### 3.4 TableEnvironmentæ„å»º

* å’Œ DataStream API ä¸€æ ·ï¼ŒTable API å’Œ SQL ä¸­å…·æœ‰ç›¸åŒçš„åŸºæœ¬ç¼–ç¨‹æ¨¡å‹ã€‚é¦–å…ˆéœ€è¦æ„å»ºå¯¹åº”çš„ TableEnviroment åˆ›å»ºå…³ç³»å‹ç¼–ç¨‹ç¯å¢ƒï¼Œæ‰èƒ½å¤Ÿåœ¨ç¨‹åºä¸­ä½¿ç”¨ Table API å’Œ SQLæ¥ç¼–å†™åº”ç”¨ç¨‹åºï¼Œå¦å¤– Table API å’Œ SQL æ¥å£å¯ä»¥åœ¨åº”ç”¨ä¸­åŒæ—¶ä½¿ç”¨ï¼ŒFlink SQL åŸºäº Apache Calcite æ¡†æ¶å®ç°äº† SQL æ ‡å‡†åè®®ï¼Œæ˜¯æ„å»ºåœ¨ Table API ä¹‹ä¸Šçš„æ›´é«˜çº§æ¥å£ã€‚
* é¦–å…ˆéœ€è¦åœ¨ç¯å¢ƒä¸­åˆ›å»º TableEnvironment å¯¹è±¡ï¼ŒTableEnvironment ä¸­æä¾›äº†æ³¨å†Œå†…éƒ¨è¡¨ã€æ‰§è¡Œ Flink SQL è¯­å¥ã€æ³¨å†Œè‡ªå®šä¹‰å‡½æ•°ç­‰åŠŸèƒ½ã€‚æ ¹æ®åº”ç”¨ç±»å‹çš„ä¸åŒï¼ŒTableEnvironment åˆ›å»ºæ–¹å¼ä¹Ÿæœ‰æ‰€ä¸åŒï¼Œä½†æ˜¯éƒ½æ˜¯é€šè¿‡è°ƒç”¨ create()æ–¹æ³•åˆ›å»ºã€‚
* æµè®¡ç®—ç¯å¢ƒä¸‹åˆ›å»º TableEnviroment

  ```scala
  //åˆå§‹åŒ–Flinkçš„Streamingï¼ˆæµè®¡ç®—ï¼‰ä¸Šä¸‹æ–‡æ‰§è¡Œç¯å¢ƒ 
  val streamEnv: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment 
  //åˆå§‹åŒ–Table APIçš„ä¸Šä¸‹æ–‡ç¯å¢ƒ 
  val tableEvn =StreamTableEnvironment.create(streamEnv)

  ```
* åœ¨ Flink1.9 ä¹‹åç”±äºå¼•å…¥äº† Blink Planner

  ```scala
  val bsSettings = EnvironmentSettings.newInstance().useOldPlanner().inStreamingMode().build() 
  val bsTableEnv = StreamTableEnvironment.create(streamEnv, bsSettings)

  ```
* æ³¨æ„

  + Flink ç¤¾åŒºå®Œæ•´ä¿ç•™åŸæœ‰ Flink Planner (Old Planner)ï¼ŒåŒæ—¶åˆå¼•å…¥äº†æ–°çš„Blink Plannerï¼Œç”¨æˆ·å¯ä»¥è‡ªè¡Œé€‰æ‹©ä½¿ç”¨ Old Planner è¿˜æ˜¯ Blink Plannerã€‚å®˜æ–¹æ¨èæš‚æ—¶ä½¿ç”¨ Old Plannerã€‚

##### 3.5 Table API

* åœ¨ Flink ä¸­åˆ›å»ºä¸€å¼ è¡¨æœ‰ä¸¤ç§æ–¹æ³•ï¼š
  + ï¼ˆ1ï¼‰ä»ä¸€ä¸ªæ–‡ä»¶ä¸­å¯¼å…¥è¡¨ç»“æ„ï¼ˆStructureï¼‰ï¼ˆå¸¸ç”¨äºæ‰¹è®¡ç®—ï¼‰ï¼ˆé™æ€ï¼‰
  + ï¼ˆ2ï¼‰ä» DataStream æˆ–è€… DataSet è½¬æ¢æˆ Table ï¼ˆåŠ¨æ€ï¼‰

###### 3.5.1 åˆ›å»º Table

* Table API ä¸­å·²ç»æä¾›äº† TableSource ä»å¤–éƒ¨ç³»ç»Ÿè·å–æ•°æ®ï¼Œä¾‹å¦‚å¸¸è§çš„æ•°æ®åº“ã€æ–‡ä»¶ç³»ç»Ÿå’Œ Kafka æ¶ˆæ¯é˜Ÿåˆ—ç­‰å¤–éƒ¨ç³»ç»Ÿã€‚
* **1ã€ä»æ–‡ä»¶ä¸­åˆ›å»º Tableï¼ˆé™æ€è¡¨ï¼‰**

  + éœ€æ±‚

    - è¯»å–csvæ–‡ä»¶ï¼Œæ–‡ä»¶å†…å®¹å‚è§è¯¾ä»¶å½“ä¸­çš„flinksql.csvæ–‡ä»¶ï¼ŒæŸ¥è¯¢å¹´é¾„å¤§äº18å²çš„äººï¼Œå¹¶å°†ç»“æœå†™å…¥åˆ°csvæ–‡ä»¶é‡Œé¢å»ï¼Œè¿™é‡Œæ¶‰åŠåˆ°flinkçš„connectçš„å„ç§ä¸å…¶ä»–å¤–éƒ¨ç³»ç»Ÿçš„è¿æ¥ï¼Œå‚è§
    - https://ci.apache.org/projects/flink/flink-docs-release-1.9/dev/table/connect.html
  + ä»£ç å¼€å‘

    ```scala
    package com.kaikeba.table

    import org.apache.flink.api.common.typeinfo.TypeInformation
    import org.apache.flink.core.fs.FileSystem.WriteMode
    import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}
    import org.apache.flink.table.api.{Table, Types}
    import org.apache.flink.table.api.scala.StreamTableEnvironment
    import org.apache.flink.table.sinks.CsvTableSink
    import org.apache.flink.table.sources.CsvTableSource
    import org.apache.flink.api.scala._
    /**
      * flink tableåŠ è½½csvæ–‡ä»¶
      */
    object TableCsvSource {

      def main(args: Array[String]): Unit = {
         //todo:1ã€æ„å»ºæµå¤„ç†ç¯å¢ƒ
          val environment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

        //todo:2ã€æ„å»ºTableEnvironment
        val tableEnvironment: StreamTableEnvironment = StreamTableEnvironment.create(environment)
            //todo:3ã€æ„å»ºcsvæ•°æ®æº
        val csvSource = CsvTableSource.builder().path("d:\\flinksql.csv")
                                       .field("id", Types.INT())
                                       .field("name", Types.STRING())
                                       .field("age", Types.INT())
                                       .fieldDelimiter(",") //å­—æ®µçš„åˆ†éš”ç¬¦
                                       .ignoreParseErrors() //å¿½ç•¥è§£æé”™è¯¯
                                       .ignoreFirstLine()   //å¿½ç•¥ç¬¬ä¸€è¡Œ
                                       .build()

        //todo:4ã€æ³¨å†Œè¡¨
        tableEnvironment.registerTableSource("myUser", csvSource)

        //todo: 5ã€æŸ¥è¯¢ç»“æœ
        val result: Table = tableEnvironment.scan("myUser").filter("age>25").select("id,name,age")
        result.printSchema()

        //todo: 6ã€æ„å»ºSink
        val tableSink = new CsvTableSink("./out/tableSink.txt","\t",1,WriteMode.OVERWRITE)

        //todo:7ã€æ³¨å†Œsink
        tableEnvironment.registerTableSink("csvOutputTable",
                                            Array[String]("f1","f2","f3"),
                                            Array[TypeInformation[_]](Types.INT,Types.STRING,Types.INT) ,
                                            tableSink)

        //todo:8ã€å†™æ•°æ®åˆ°sink
        result.insertInto("csvOutputTable")

        environment.execute("TableCsvSource")

      }
    }


    ```
* **2ã€ä»DataStreamä¸­åˆ›å»º Tableï¼ˆåŠ¨æ€è¡¨ï¼‰**

  + éœ€æ±‚

    - ä½¿ç”¨TableApiå®ŒæˆåŸºäºæµæ•°æ®çš„å¤„ç†
  + ä»£ç å¼€å‘

    ```scala
    package com.kaikeba.table

    import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}
    import org.apache.flink.table.api.{Table, Types}
    import org.apache.flink.table.api.scala.StreamTableEnvironment
    import org.apache.flink.types.Row
    /**
      * ä½¿ç”¨TableApiå®ŒæˆåŸºäºæµæ•°æ®çš„å¤„ç†
      */
    object TableFromDataStream {

      //todo:å®šä¹‰æ ·ä¾‹ç±»
      case class User(id:Int,name:String,age:Int)
        def main(args: Array[String]): Unit = {
               //todo:1ã€æ„å»ºæµå¤„ç†ç¯å¢ƒ
            val streamEnv: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
        streamEnv.setParallelism(1)

         //todo:2ã€æ„å»ºTableEnvironment
            val tableEnvironment: StreamTableEnvironment = StreamTableEnvironment.create(streamEnv)
            import org.apache.flink.api.scala._

        /**
          * 101,zhangsan,18
          * 102,lisi,28
          * 103,wangwu,25
          * 104,zhaoliu,30
          */
         //todo:3ã€æ¥å—socketæ•°æ®
            val socketStream: DataStream[String] = streamEnv.socketTextStream("node01",9999)

         //todo:4ã€å¯¹æ•°æ®è¿›è¡Œå¤„ç†
           val userStream: DataStream[User] = socketStream.map(x=>x.split(",")).map(x=>User(x(0).toInt,x(1),x(2).toInt))

         //todo:5ã€å°†æµæ³¨å†Œæˆä¸€å¼ è¡¨
          tableEnvironment.registerDataStream("userTable",userStream)

        //todo:6ã€ä½¿ç”¨table çš„apiæŸ¥è¯¢å¹´é¾„å¤§äº20å²çš„äºº
          val result:Table = tableEnvironment.scan("userTable").filter("age >20")
      //todoï¼š7ã€å°†tableè½¬åŒ–æˆæµ
         tableEnvironment.toAppendStream[Row](result).print()      
            //todo:8ã€å¯åŠ¨
         tableEnvironment.execute("TableFromDataStream")

      }

    }  

    ```
  + å‘é€æ•°æ®

    ```shell
    nc -lk 9999

    101,zhangsan,18
    102,lisi,28
    103,wangwu,25
    104,zhaoliu,30

    ```
  + DataStreamè½¬æ¢æˆTableé€»è¾‘

    - æ„å»ºStreamExecutionEnvironmentå’ŒStreamTableEnvironmentå¯¹è±¡
      * StreamTableEnvironment.fromDataStream(dataStream: DataStream)
      * StreamTableEnvironment.registerDataStream(dataStream: DataStream)
* æ›´å¤šçš„table APIæ“ä½œè¯¦ç»†è§å®˜ç½‘

  + <https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/tableApi.html>

  ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/b342bf737e4d4c14a2fb772d26d8a704.png)

###### 3.5.2 Tableä¸­çš„window

* Flink æ”¯æŒ ProcessTimeã€EventTime å’Œ IngestionTime ä¸‰ç§æ—¶é—´æ¦‚å¿µï¼Œé’ˆå¯¹æ¯ç§æ—¶é—´æ¦‚å¿µï¼ŒFlink Table API ä¸­ä½¿ç”¨
  `Schema`
  ä¸­å•ç‹¬çš„å­—æ®µæ¥è¡¨ç¤ºæ—¶é—´å±æ€§ï¼Œå½“æ—¶é—´å­—æ®µè¢«æŒ‡å®šåï¼Œå°±å¯ä»¥åœ¨åŸºäºæ—¶é—´çš„æ“ä½œç®—å­ä¸­ä½¿ç”¨ç›¸åº”çš„æ—¶é—´å±æ€§ã€‚
* åœ¨ Table API ä¸­é€šè¿‡ä½¿ç”¨==.rowtime æ¥å®šä¹‰ EventTime å­—æ®µ==ï¼Œåœ¨ ProcessTime æ—¶é—´å­—æ®µååä½¿ç”¨.proctime åç¼€æ¥æŒ‡å®š ProcessTime æ—¶é—´å±æ€§
* éœ€æ±‚

  + ç»Ÿè®¡æœ€è¿‘ 5 ç§’é’Ÿï¼Œæ¯ä¸ªå•è¯å‡ºç°çš„æ¬¡æ•°
* ä»£ç å¼€å‘

  ```scala
  package com.kaikeba.table

  import org.apache.flink.streaming.api.TimeCharacteristic
  import org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks
  import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}
  import org.apache.flink.streaming.api.watermark.Watermark
  import org.apache.flink.table.api.{GroupWindowedTable, Table, Tumble}
  import org.apache.flink.table.api.scala.StreamTableEnvironment
  import org.apache.flink.types.Row

  /**
    * åŸºäºtableçš„windowçª—å£æ“ä½œå¤„ç†å»¶è¿Ÿæ•°æ®
    */
  object TableWindowWaterMark {

    //å®šä¹‰æ ·ä¾‹ç±»
    case class Message(word:String,createTime:Long)

    def main(args: Array[String]): Unit = {
      //todo:1ã€æ„å»ºæµå¤„ç†ç¯å¢ƒ
       val streamEnv: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
      streamEnv.setParallelism(1)

        import org.apache.flink.api.scala._

      //æŒ‡å®šEventTimeä¸ºæ—¶é—´è¯­ä¹‰
       streamEnv.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)

     //todo: 2ã€æ„å»ºStreamTableEnvironment
        val tableEnvironment: StreamTableEnvironment = StreamTableEnvironment.create(streamEnv)

    //todoï¼š 3ã€æ¥å—socketæ•°æ®
        val sourceStream: DataStream[String] = streamEnv.socketTextStream("node01",9999)

    //todo: 4ã€æ•°æ®åˆ‡åˆ†å¤„ç†
      val mapStream: DataStream[Message] = sourceStream.map(x=>Message(x.split(",")(0),x.split(",")(1).toLong))

     //todo: 5ã€æ·»åŠ watermark
      val watermarksStream: DataStream[Message] = mapStream.assignTimestampsAndWatermarks(new AssignerWithPeriodicWatermarks[Message] {

        //å®šä¹‰å»¶è¿Ÿæ—¶é•¿
        val maxOutOfOrderness = 5000L
        //å†å²æœ€å¤§äº‹ä»¶æ—¶é—´
        var currentMaxTimestamp: Long = _

        override def getCurrentWatermark: Watermark = {
          val watermark = new Watermark(currentMaxTimestamp - maxOutOfOrderness)
          watermark
        }

        override def extractTimestamp(element: Message, previousElementTimestamp: Long): Long = {

          val eventTime: Long = element.createTime
          currentMaxTimestamp = Math.max(eventTime, currentMaxTimestamp)
          eventTime
        }
      })

      
      //todo:6ã€æ„å»ºTable , è®¾ç½®æ—¶é—´å±æ€§
      import org.apache.flink.table.api.scala._
       val table: Table = tableEnvironment.fromDataStream(watermarksStream,'word,'createTime.rowtime)
      //todo:7ã€æ·»åŠ window
        //æ»šåŠ¨çª—å£ç¬¬ä¸€ç§å†™æ³•
    //val windowedTable: GroupWindowedTable = table.window(Tumble.over("5.second").on("createTime").as("window"))

       //æ»šåŠ¨çª—å£çš„ç¬¬äºŒç§å†™æ³•
   val windowedTable: GroupWindowedTable = table.window(Tumble over 5.second on 'createTime as 'window)

    //todo:8ã€å¯¹çª—å£æ•°æ®è¿›è¡Œå¤„ç†
       // ä½¿ç”¨2ä¸ªå­—æ®µåˆ†ç»„ï¼Œçª—å£åç§°å’Œå•è¯
    val result: Table = windowedTable.groupBy('window,'word)
           //å•è¯ã€çª—å£çš„å¼€å§‹ã€ç»“æŸeã€èšåˆè®¡ç®—
                                         .select('word,'window.start,'window.end,'word.count)
      //todo:9ã€å°†tableè½¬æ¢æˆDataStream
     val resultStream: DataStream[(Boolean, Row)] = tableEnvironment.toRetractStream[Row](result)

     resultStream.filter(x =>x._1 ==true).print()

     tableEnvironment.execute("table")
  }
  }
      

  ```
* å‘é€æ•°æ®

  ```
  hadoop,1461756862000
  hadoop,1461756866000
  hadoop,1461756864000
  hadoop,1461756870000
  hadoop,1461756875000

  ```

##### 3.6 SQLä½¿ç”¨

* SQL ä½œä¸º Flink ä¸­æä¾›çš„æ¥å£ä¹‹ä¸€ï¼Œå æ®ç€éå¸¸é‡è¦çš„åœ°ä½ï¼Œä¸»è¦æ˜¯å› ä¸º SQL å…·æœ‰çµæ´»å’Œä¸°å¯Œçš„è¯­æ³•ï¼Œèƒ½å¤Ÿåº”ç”¨äºå¤§éƒ¨åˆ†çš„è®¡ç®—åœºæ™¯ã€‚
* Flink SQL åº•å±‚ä½¿ç”¨ Apache Calcite æ¡†æ¶ï¼Œ å°†æ ‡å‡†çš„ Flink SQL è¯­å¥è§£æå¹¶è½¬æ¢æˆåº•å±‚çš„ç®—å­å¤„ç†é€»è¾‘ï¼Œå¹¶åœ¨è½¬æ¢è¿‡ç¨‹ä¸­åŸºäºè¯­æ³•è§„åˆ™å±‚é¢è¿›è¡Œæ€§èƒ½ä¼˜åŒ–ï¼Œæ¯”å¦‚è°“è¯ä¸‹æ¨ç­‰ã€‚å¦å¤–ç”¨æˆ·åœ¨ä½¿ç”¨ SQL ç¼–å†™ Flink åº”ç”¨æ—¶ï¼Œèƒ½å¤Ÿå±è”½åº•å±‚æŠ€æœ¯ç»†èŠ‚ï¼Œèƒ½å¤Ÿæ›´åŠ æ–¹ä¾¿ä¸”é«˜æ•ˆåœ°é€šè¿‡SQLè¯­å¥æ¥æ„å»ºFlinkåº”ç”¨ã€‚
* Flink SQLæ„å»ºåœ¨Table API ä¹‹ä¸Šï¼Œå¹¶å«ç›–äº†å¤§éƒ¨åˆ†çš„ Table API åŠŸèƒ½ç‰¹æ€§ã€‚åŒæ—¶ Flink SQL å¯ä»¥å’Œ Table API æ··ç”¨ï¼ŒFlink æœ€ç»ˆä¼šåœ¨æ•´ä½“ä¸Šå°†ä»£ç åˆå¹¶åœ¨åŒä¸€å¥—ä»£ç é€»è¾‘ä¸­

###### 3.6.1 SQLæ“ä½œ

* ä»£ç å¼€å‘æ¼”ç¤º

  ```scala

    package com.kaikeba.table

    import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}
    import org.apache.flink.table.api.Table
    import org.apache.flink.table.api.scala.StreamTableEnvironment
    import org.apache.flink.types.Row

    object FlinkSQLTest {

      //todo:å®šä¹‰æ ·ä¾‹ç±»
      case class User(id:Int,name:String,age:Int)
       def main(args: Array[String]): Unit = { 
            //todo:1ã€æ„å»ºæµå¤„ç†ç¯å¢ƒ
          val streamEnv: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
      streamEnv.setParallelism(1)

       //todo:2ã€æ„å»ºTableEnvironment
          val tableEnvironment: StreamTableEnvironment = StreamTableEnvironment.create(streamEnv)
          import org.apache.flink.api.scala._

      /**
        * 101,zhangsan,18
        * 102,lisi,20
        * 103,wangwu,25
        * 104,zhaoliu,15
        */
       //todo:3ã€æ¥å—socketæ•°æ®
          val socketStream: DataStream[String] = streamEnv.socketTextStream("node01",9999)

       //todo:4ã€å¯¹æ•°æ®è¿›è¡Œå¤„ç†
         val userStream: DataStream[User] = socketStream.map(x=>x.split(",")).map(x=>User(x(0).toInt,x(1),x(2).toInt))

       //todo:5ã€å°†æµæ³¨å†Œæˆä¸€å¼ è¡¨
        tableEnvironment.registerDataStream("userTable",userStream)

      //todo:6ã€ä½¿ç”¨table çš„apiæŸ¥è¯¢å¹´é¾„å¤§äº20å²çš„äºº
        val result:Table = tableEnvironment.sqlQuery("select * from userTable where age >20")
          //todoï¼š7ã€å°†tableè½¬åŒ–æˆæµ
       tableEnvironment.toAppendStream[Row](result).print()
        //todo:8ã€å¯åŠ¨
       tableEnvironment.execute("TableFromDataStream")

    }

  }   

  ```
* å‘é€æ•°æ®

  ```
  101,zhangsan,18
  102,lisi,20
  103,wangwu,25
  104,zhaoliu,15

  ```
* å°†Tableè½¬æ¢æˆä¸ºDataStreamçš„ä¸¤ç§æ¨¡å¼

  + ç¬¬ä¸€ç§æ–¹å¼ï¼šAppendMode(è¿½åŠ æ¨¡å¼)

    ```
       å°†è¡¨é™„åŠ åˆ°æµæ•°æ®ï¼Œè¡¨å½“ä¸­åªèƒ½æœ‰æŸ¥è¯¢æˆ–è€…æ·»åŠ æ“ä½œï¼Œå¦‚æœæœ‰updateæˆ–è€…deleteæ“ä½œï¼Œé‚£ä¹ˆå°±ä¼šå¤±è´¥ã€‚
     åªæœ‰åœ¨åŠ¨æ€Tableä»…é€šè¿‡INSERTæ—¶æ‰èƒ½ä½¿ç”¨æ­¤æ¨¡å¼ï¼Œå³å®ƒä»…é™„åŠ ï¼Œå¹¶ä¸”ä»¥å‰å‘å‡ºçš„ç»“æœæ°¸è¿œä¸ä¼šæ›´æ–°ã€‚
     å¦‚æœæ›´æ–°æˆ–åˆ é™¤æ“ä½œä½¿ç”¨è¿½åŠ æ¨¡å¼ä¼šå¤±è´¥æŠ¥é”™ã€‚

    ```
  + ç¬¬äºŒç§æ¨¡å¼ï¼šRetractModeï¼ˆæ’¤å›æ¨¡å¼ï¼‰

    ```
         å§‹ç»ˆå¯ä»¥ä½¿ç”¨æ­¤æ¨¡å¼ã€‚è¿”å›å€¼æ˜¯booleanç±»å‹ã€‚
         å®ƒç”¨trueæˆ–falseæ¥æ ‡è®°æ•°æ®çš„æ’å…¥å’Œæ’¤å›ï¼Œè¿”å›trueä»£è¡¨æ•°æ®æ’å…¥ï¼Œfalseä»£è¡¨æ•°æ®çš„æ’¤å›ã€‚

    ```
* æŒ‰ç…§å®˜ç½‘çš„ç†è§£å¦‚æœæ•°æ®åªæ˜¯ä¸æ–­æ·»åŠ ï¼Œå¯ä»¥ä½¿ç”¨è¿½åŠ æ¨¡å¼ï¼Œå…¶ä½™æ–¹å¼åˆ™ä¸å¯ä»¥ä½¿ç”¨è¿½åŠ æ¨¡å¼ï¼Œè€Œæ’¤å›æ¨¡å¼ä¾§å¯ä»¥é€‚ç”¨äºæ›´æ–°ï¼Œåˆ é™¤ç­‰åœºæ™¯ã€‚å…·ä½“çš„åŒºåˆ« å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

  ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/4164122060e040aebb8ae2edcb7ff5e1.png)

  ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/ef5057757336486a87e7c62e5d953d4b.png)
* é€šè¿‡ä¸Šå›¾å¯ä»¥æ¸…æ™°çš„çœ‹åˆ°ä¸¤ç§æ–¹å¼çš„åŒºåˆ«ï¼Œæˆ‘ä»¬åœ¨åˆ©ç”¨flinkSQLå¤„ç†å®æ—¶æ•°æ®æŠŠè¡¨è½¬åŒ–æˆæµçš„æ—¶å€™ï¼Œå¦‚æœä½¿ç”¨çš„sqlè¯­å¥åŒ…å«ï¼šcountï¼ˆï¼‰ group byæ—¶ï¼Œå¿…é¡»ä½¿ç”¨RetractModeæ’¤å›æ¨¡å¼ã€‚

###### 3.6.2 SQLä¸­çš„window

* Flink SQL ä¹Ÿæ”¯æŒä¸‰ç§çª—å£ç±»å‹ï¼Œåˆ†åˆ«ä¸º Tumble Windowsã€HOP Windows å’Œ Session Windowsï¼Œå…¶ä¸­ HOP Windows å¯¹åº” Table API ä¸­çš„ Sliding Windowï¼ŒåŒæ—¶æ¯ç§çª—å£åˆ†åˆ«æœ‰ç›¸åº”çš„ä½¿ç”¨åœºæ™¯å’Œæ–¹æ³•ã€‚
* éœ€æ±‚

  + ç»Ÿè®¡æœ€è¿‘ 5 ç§’é’Ÿï¼Œæ¯ä¸ªå•è¯å‡ºç°çš„æ¬¡æ•°
* ä»£ç å¼€å‘

  ```scala
  package com.kaikeba.table

  import org.apache.flink.streaming.api.TimeCharacteristic
  import org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks
  import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}
  import org.apache.flink.streaming.api.watermark.Watermark
  import org.apache.flink.table.api.scala.StreamTableEnvironment
  import org.apache.flink.table.api.{GroupWindowedTable, Table, Tumble}
  import org.apache.flink.types.Row

  /**
    * åŸºäºSQLçš„windowçª—å£æ“ä½œå¤„ç†å»¶è¿Ÿæ•°æ®
    */
  object SQLWindowWaterMark {

    //å®šä¹‰æ ·ä¾‹ç±»
    case class Message(word:String,createTime:Long)

    def main(args: Array[String]): Unit = {
      //todo:1ã€æ„å»ºæµå¤„ç†ç¯å¢ƒ
       val streamEnv: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
      streamEnv.setParallelism(1)

        import org.apache.flink.api.scala._

      //æŒ‡å®šEventTimeä¸ºæ—¶é—´è¯­ä¹‰
       streamEnv.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)

     //todo: 2ã€æ„å»ºStreamTableEnvironment
        val tableEnvironment: StreamTableEnvironment = StreamTableEnvironment.create(streamEnv)

    //todoï¼š 3ã€æ¥å—socketæ•°æ®
        val sourceStream: DataStream[String] = streamEnv.socketTextStream("node01",9999)

    //todo: 4ã€æ•°æ®åˆ‡åˆ†å¤„ç†
      val mapStream: DataStream[Message] = sourceStream.map(x=>Message(x.split(",")(0),x.split(",")(1).toLong))

     //todo: 5ã€æ·»åŠ watermark
      val watermarksStream: DataStream[Message] = mapStream.assignTimestampsAndWatermarks(new AssignerWithPeriodicWatermarks[Message] {

        //å®šä¹‰å»¶è¿Ÿæ—¶é•¿
        val maxOutOfOrderness = 5000L
        //å†å²æœ€å¤§äº‹ä»¶æ—¶é—´
        var currentMaxTimestamp: Long = _

        override def getCurrentWatermark: Watermark = {
          val watermark = new Watermark(currentMaxTimestamp - maxOutOfOrderness)
          watermark
        }

        override def extractTimestamp(element: Message, previousElementTimestamp: Long): Long = {

          val eventTime: Long = element.createTime
          currentMaxTimestamp = Math.max(eventTime, currentMaxTimestamp)
          eventTime
        }
      })
        //todo:6ã€æ³¨å†ŒDataStreamæˆè¡¨ ï¼Œè®¾ç½®æ—¶é—´å±æ€§
       import org.apache.flink.table.api.scala._
      tableEnvironment.registerDataStream("t_socket",watermarksStream,'word,'createTime.rowtime)  
     //todo:7ã€sqlæŸ¥è¯¢---æ·»åŠ window---æ»šåŠ¨çª—å£----çª—å£é•¿åº¦5s
    val result: Table = tableEnvironment.sqlQuery("select word,count(*) from t_socket group by tumble(createTime,interval '5' second),word")   
     //todo:8ã€å°†tableè½¬æ¢æˆDataStream
     val resultStream: DataStream[(Boolean, Row)] = tableEnvironment.toRetractStream[Row](result)

     resultStream.filter(x =>x._1 ==true).print()

     tableEnvironment.execute("table")
    }   
    }  

  ```
* å‘é€æ•°æ®

```
hadoop,1461756862000
hadoop,1461756865000
hadoop,1461756863000
hadoop,1461756868000
hadoop,1461756870000
hadoop,1461756875000
hadoop,1461756880000

```

* æ›´å¤šçš„SQLæ“ä½œè¯¦ç»†è§å®˜ç½‘

  + <https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/sql/queries.html>

    ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/direct/1025b20325974516857e0715f06771b9.png)

### æŠŠæ‰€æœ‰çš„ä»£ç éƒ½æ•²ä¸€é