---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34333239303337302f:61727469636c652f64657461696c732f313435343933343139"
layout: post
title: "macOS-和-Windows-系统的-DeepSeek详细教程"
date: 2025-02-07 13:45:32 +08:00
description: "涵盖环境配置、模型加载、可视化交互及问题排查，按步骤操作即可完成部署。通过以上步骤，您已成功在本地部署。或 DeepSeek 的。"
keywords: "macos安装deepseek"
categories: ['Deepseek']
tags: ['深度学习', 'Chatgpt']
artid: "145493419"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145493419
    alt: "macOS-和-Windows-系统的-DeepSeek详细教程"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145493419
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145493419
cover: https://bing.ee123.net/img/rand?artid=145493419
image: https://bing.ee123.net/img/rand?artid=145493419
img: https://bing.ee123.net/img/rand?artid=145493419
---

# macOS 和 Windows 系统的 DeepSeek详细教程

以下是针对
**macOS 和 Windows 系统**
的
**DeepSeek 本地部署超详细教程**
，涵盖环境配置、模型加载、可视化交互及问题排查，按步骤操作即可完成部署。

---

#### **一、环境准备（硬件与系统）**

##### **1. macOS 用户**

* **硬件要求**
  ：
  + **入门级**
    ：Apple Silicon（M1/M2/M3 芯片），16GB 内存，30GB 存储空间（支持 1.5B/7B 模型）。
  + **高性能级**
    ：M2 Ultra/M3 Max 芯片，64GB 内存，100GB 存储（支持 14B/32B 模型）。
* **系统要求**
  ：macOS Ventura（13.0）或更高版本，确保已安装 Xcode 命令行工具：

  ```bash
  xcode-select --install

  ```

##### **2. Windows 用户**

* **硬件要求**
  ：
  + **CPU 模式**
    ：支持 AVX2 指令集的 Intel/AMD CPU（如 i5-8xxx 或 Ryzen 5 以上），16GB 内存，30GB 存储（仅运行 1.5B 模型）。
  + **GPU 加速**
    ：NVIDIA RTX 3060 或更高（显存 ≥8GB），32GB 内存（支持 7B/14B 模型）。
* **系统要求**
  ：Windows 10/11 64位，需安装：
  + [NVIDIA 显卡驱动](https://www.nvidia.com/Download/index.aspx)
    （GPU 用户必装）
  + [CUDA Toolkit 12.1+](https://developer.nvidia.com/cuda-toolkit)
    （GPU 加速依赖）

---

#### **二、安装 Ollama（核心工具）**

##### **1. macOS 安装步骤**

1. **下载安装包**
   ：
   * 访问
     [Ollama 官网](https://ollama.com/download)
     ，选择
     **macOS（Apple Silicon）**
     下载
     `.dmg`
     文件。
2. **安装与权限**
   ：
   * 双击下载的
     `.dmg`
     文件，将 Ollama 图标拖拽到
     `Applications`
     文件夹。
   * 首次运行时，系统可能提示“无法验证开发者”，需手动授权：
     + 进入
       **系统设置 → 隐私与安全性 → 安全性**
       ，点击
       **仍要打开**
       。
3. **验证安装**
   ：

   ```bash
   ollama --version
   # 输出示例：ollama version 0.1.20

   ```

##### **2. Windows 安装步骤**

1. **下载安装包**
   ：
   * 从
     [Ollama 官网](https://ollama.com/download)
     下载
     `OllamaSetup.exe`
     。
2. **安装与配置**
   ：
   * 右键以管理员身份运行安装程序，默认路径安装（建议保持
     `C:\Program Files\Ollama`
     ）。
   * 安装完成后，Ollama 会自动启动并注册为系统服务。
3. **验证安装**
   ：
   * 打开 PowerShell 或 CMD，输入：

     ```powershell
     ollama -v
     # 输出示例：ollama version 0.1.20

     ```

---

#### **三、下载与加载 DeepSeek 模型**

##### **1. 模型选择建议**

| 模型版本 | 适用场景 | 最低显存/内存 | 文件大小 |
| --- | --- | --- | --- |
| 1.5B | 轻量级文本生成 | 4GB | 1.1GB |
| 7B | 通用任务（推荐） | 8GB | 5GB |
| 14B | 复杂推理与代码生成 | 16GB | 12GB |

##### **2. 命令行下载模型**

* **通用命令**
  （以 7B 模型为例）：

  ```bash
  ollama run deepseek-r1:7b

  ```

  + 首次运行会自动下载模型，终端显示进度条：

    ```
    pulling manifest...
    downloading 7b...  [██████████████████] 100%

    ```

##### **3. 国内网络加速（可选）**

* 若下载缓慢，可配置镜像源：

  ```bash
  # macOS/Linux
  export OLLAMA_HOST=mirror.ghproxy.com

  # Windows（PowerShell）
  $env:OLLAMA_HOST="mirror.ghproxy.com"

  ```

---

#### **四、测试模型基础功能**

##### **1. 命令行交互测试**

* 启动模型交互模式：

  ```bash
  ollama run deepseek-r1:7b

  ```
* 输入测试指令：

  ```text
  >>> 生成一个快速排序的Python代码

  ```

  + 预期输出：

    ```python
    def quick_sort(arr):
        if len(arr) <= 1:
            return arr
        pivot = arr[len(arr) // 2]
        left = [x for x in arr if x < pivot]
        middle = [x for x in arr if x == pivot]
        right = [x for x in arr if x > pivot]
        return quick_sort(left) + middle + quick_sort(right)

    ```

##### **2. 验证 GPU 加速（Windows）**

* 查看 Ollama 日志，确认是否启用 CUDA：

  ```powershell
  ollama serve
  # 输出中出现 "CUDA capability detected" 表示 GPU 加速已启用

  ```

---

#### **五、配置可视化界面（Chatbox）**

##### **1. 安装 Chatbox 客户端**

* **下载地址**
  ：
  [Chatbox 官网](https://chatboxai.app/)
  + 选择对应系统的安装包（支持 macOS/Windows/Linux）。

##### **2. 连接本地模型**

1. 打开 Chatbox，进入
   **Settings → Model**
   。
2. 选择
   **Ollama**
   作为后端，填写模型名称（与下载的模型一致）：

   ```
   Model Name: deepseek-r1:7b
   Base URL: http://localhost:11434

   ```
3. 点击
   **Test Connection**
   ，显示绿色成功提示即配置完成。

##### **3. Windows 额外配置**

* **环境变量设置**
  （解决跨域问题）：
  1. 右键
     **此电脑 → 属性 → 高级系统设置 → 环境变量**
     。
  2. 新建系统变量：
     + 变量名：
       `OLLAMA_ORIGINS`
     + 变量值：
       `*`
  3. 重启 Ollama 服务：

     ```powershell
     Restart-Service Ollama

     ```

---

#### **六、常见问题与解决方案**

##### **1. 模型加载失败**

* **现象**
  ：
  `Error: model 'deepseek-r1:7b' not found`
* **解决方法**
  ：

  ```bash
  # 重新拉取模型
  ollama pull deepseek-r1:7b

  ```

##### **2. 显存/内存不足**

* **现象**
  ：
  `CUDA out of memory`
  或程序崩溃
* **解决方案**
  ：
  + 降低模型版本（如从 14B 切换到 7B）。
  + 添加
    `--num-gpu-layers`
    参数（仅限 GPU 用户）：

    ```bash
    ollama run deepseek-r1:7b --num-gpu-layers 20

    ```

##### **3. 响应速度慢**

* **优化方法**
  ：
  + **macOS**
    ：启用 Metal 加速（Apple Silicon 专用）：

    ```bash
    OLLAMA_METAL=1 ollama run deepseek-r1:7b

    ```
  + **Windows**
    ：确保 CUDA 和显卡驱动为最新版本。

---

#### **七、高级部署选项**

##### **1. Docker 部署（跨平台）**

* 使用 Docker 运行 Ollama：

  ```bash
  docker run -d -p 11434:11434 --name ollama ollama/ollama

  ```
* 拉取模型：

  ```bash
  docker exec -it ollama ollama pull deepseek-r1:7b

  ```

##### **2. Open Web UI 集成**

* 部署开源交互界面：

  ```bash
  docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui ghcr.io/open-webui/open-webui:main

  ```

  + 访问
    `http://localhost:3000`
    使用 Web 界面。

---

#### **总结**

通过以上步骤，您已成功在本地部署
**DeepSeek 大模型**
。关键要点：

1. 根据硬件选择合适模型（
   **7B 为平衡性能与资源的推荐版本**
   ）。
2. Windows 用户务必配置 CUDA 和显卡驱动以启用 GPU 加速。
3. 使用 Chatbox 或 Open Web UI 提升交互体验。

如需进一步优化，可参考
[Ollama 官方文档](https://github.com/ollama/ollama)
或 DeepSeek 的
[Hugging Face 页面](https://huggingface.co/deepseek-ai)
。