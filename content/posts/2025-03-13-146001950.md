---
arturl_encode: "68747470733a2f2f626c6f:672e6373646e2e6e65742f323430325f38363230393136312f:61727469636c652f64657461696c732f313436303031393530"
layout: post
title: "Linux云计算SRE-第二十周"
date: 2025-03-13 02:14:45 +0800
description: "3、安装elasticsearch集群、kibana、cerebro，配置node6(10.0.0.160)，node7(10.0.0.170)，node8(10.0.0.180)，利用kibana和cerebro查看收集的日志。1、安装nginx和filebeat，配置node0(10.0.0.100)，node1(10.0.0.110)，node2(10.0.0.120)，采用filebeat收集nignx日志，并发送到kafka集群。"
keywords: "Linux云计算SRE-第二十周"
categories: ['未分类']
tags: ['运维', '云计算', 'Linux']
artid: "146001950"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146001950
    alt: "Linux云计算SRE-第二十周"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146001950
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146001950
cover: https://bing.ee123.net/img/rand?artid=146001950
image: https://bing.ee123.net/img/rand?artid=146001950
img: https://bing.ee123.net/img/rand?artid=146001950
---

# Linux云计算SRE-第二十周

### 完成ELK综合案例里面的实验，搭建完整的环境

#### 一、

![](https://i-blog.csdnimg.cn/direct/9f78f3a27cf349c38af990fa48dddc3b.png)

1、安装nginx和filebeat，配置node0(10.0.0.100)，node1(10.0.0.110)，node2(10.0.0.120)，采用filebeat收集nignx日志。

```bash
#node0、node1、node2采用以下相同方式收集nginx日志
 
# 更新软件包列表并安装nginx
[root@node0 ~]# apt update && apt -y install nginx
 
# 编辑nginx的主配置文件，以自定义日志格式
[root@node0 ~]# vim /etc/nginx/nginx.conf
# 在http块中定义一个新的日志格式access_json，该格式将日志记录为JSON
http {
  ...
  log_format access_json '{
        "@timestamp": "$time_iso8601",  # 日志时间戳
        "host": "$server_addr",         # 服务器IP地址
        "clientip": "$remote_addr",     # 客户端IP地址
        "size": $body_bytes_sent,       # 发送的字节数
        "responsetime": $request_time,  # 请求处理时间
        "upstreamtime": "$upstream_response_time",  # 上游服务器响应时间
        "upstreamhost": "$upstream_addr",  # 上游服务器地址
        "http_host": "$host",           # 请求的host头
        "uri": "$uri",                  # 请求的URI
        "domain": "$host",              # 同http_host，请求的域名
        "xff": "$http_x_forwarded_for", # X-Forwarded-For头，用于识别通过HTTP代理或负载均衡器连接到web服务器的客户端的原始IP地址
        "referer": "$http_referer",     # Referer头，表示请求的来源页面
        "tcp_xff": "$proxy_protocol_addr",  # 如果使用了Proxy Protocol，这是客户端的真实IP地址
        "http_user_agent": "$http_user_agent",  # 用户代理字符串
        "status": "$status",            # HTTP响应状态码
        "request_method": "$request_method"  # 请求方法（GET, POST等）
  }';
# 使用新定义的日志格式记录访问日志
access_log /var/log/nginx/access_json.log access_json;
# 错误日志配置保持不变
error_log /var/log/nginx/error.log;
}
 
# 编辑nginx的默认站点配置文件，注释掉默认的try_files指令
[root@node0 ~]# vim /etc/nginx/sites-available/default
location / {
    ...
    #try_files $uri $uri/ =404;  # 注释掉这一行，意味着可以自定义处理请求的方式
}
 
# 重启nginx以应用更改
[root@node0 ~]# systemctl restart nginx.service

# 安装filebeat的deb包
[root@node0 ~]# dpkg -i filebeat-8.12.2-amd64.deb  # 安装filebeat
 
# 备份filebeat的配置文件
[root@node0 ~]# cp /etc/filebeat/filebeat.yml{,.bak}
 
# 编辑filebeat的配置文件
[root@node0 ~]# vim /etc/filebeat/filebeat.yml
# 配置filebeat的输入，包括nginx访问日志、错误日志和系统日志
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /var/log/nginx/access_json.log
    json.keys_under_root: true  # 将JSON字段作为顶级字段输出
    json.overwrite_keys: true   # 如果键冲突，覆盖旧值
    tags: ["nginx-access"]
 
  - type: log
    enabled: true
    paths:
      - /var/log/nginx/error.log
    tags: ["nginx-error"]
 
  - type: log
    enabled: true
    paths:
      - /var/log/syslog
    tags: ["syslog"]
 
# 配置filebeat的输出到Redis
output.redis:
  hosts: ["10.0.0.130:6379"]  # Redis服务器地址和端口
  password: "123456"          # Redis密码
  db: 0                       # 使用Redis的0号数据库
 
# 启用并启动filebeat服务
[root@node0 ~]# systemctl enable --now filebeat
```

![](https://i-blog.csdnimg.cn/direct/ba69594756ba49deb91545e6dffb8651.png)

2、安装redis和logstash，配置node3(10.0.0.130)，node4(10.0.0.140)，采用logstash转发nginx日志到elasticsearch集群。

```bash
# 在node3节点上更新软件包列表并安装Redis服务器
[root@node3 ~]# apt update && apt -y install redis
 
# 编辑Redis配置文件，以允许来自任何IP地址的连接，并禁用自动保存功能
[root@node3 ~]# vim /etc/redis/redis.conf
# 允许Redis监听所有网络接口
bind 0.0.0.0
# 禁用所有的save命令，这意味着Redis不会将数据自动保存到磁盘上
# 下面的三行是被注释掉的，表示原本的保存策略被禁用
#save 900 1
#save 300 10
#save 60 10000
# 设置Redis的访问密码
requirepass 123456
 
# 重启Redis服务以应用配置更改
[root@node3 ~]# systemctl restart redis
 
# 在node4节点上更新软件包列表并安装OpenJDK 17
[root@node4 ~]# apt update && apt -y install openjdk-17-jdk
 
# 安装Logstash，logstash-8.12.2-amd64.deb包已经传输到node4节点
[root@node4 ~]# dpkg -i logstash-8.12.2-amd64.deb 
 
# 编辑Logstash的配置文件，设置从Redis读取数据并输出到Elasticsearch
[root@node4 ~]# vim /etc/logstash/conf.d/redis-to-es.conf
# 输入部分，配置Logstash从Redis读取数据
input {
  redis {
    # Redis服务器的主机地址
    host => "10.0.0.130"
    # Redis服务器的端口
    port => 6379
    # Redis的访问密码
    password => "123456"
    # 使用Redis的哪个数据库
    db => 0
    # Redis中数据的key
    key => "filebeat"
    # 数据类型，这里设置为list
    data_type => "list"
  }
}
 
# 输出部分，根据条件将数据输出到不同的Elasticsearch索引
output {
  # 如果数据标签中包含"syslog"，则输出到指定的Elasticsearch索引
  if "syslog" in [tags] {
    elasticsearch {
      # Elasticsearch集群的节点地址
      hosts => ["10.0.0.160:9200", "10.0.0.170:9200", "10.0.0.180:9200"]
      # 使用的索引名称，包含日期信息
      index => "syslog-%{+YYYY.MM.dd}"
    }
  }
  # 如果数据标签中包含"nginx-access"，则输出到另一个索引
  if "nginx-access" in [tags] {
    elasticsearch {
      hosts => ["10.0.0.160:9200", "10.0.0.170:9200", "10.0.0.180:9200"]
      index => "nginx-accesslog-%{+YYYY.MM.dd}"
      # 允许覆盖模板设置
      template_overwrite => true
    }
  }
  # 如果数据标签中包含"nginx-error"，则输出到另一个索引
  if "nginx-error" in [tags] {
    elasticsearch {
      hosts => ["10.0.0.160:9200", "10.0.0.170:9200", "10.0.0.180:9200"]
      index => "nginx-errorlog-%{+YYYY.MM.dd}"
      template_overwrite => true
    }
  }
}
 
# 重启Logstash服务以应用配置更改
[root@node4 ~]# systemctl restart logstash
```

![](https://i-blog.csdnimg.cn/direct/a0a66579f061454ca5387ec6e0fd55d7.png)

![](https://i-blog.csdnimg.cn/direct/a17cc46258154db9a1c01548f98237b9.png)

3、安装elasticsearch集群、kibana、cerebro，配置node6(10.0.0.160)，node7(10.0.0.170)，node8(10.0.0.180)，利用kibana和cerebro查看收集的日志。

```bash
# 在node6节点上安装Kibana的deb包
[root@node6 ~]# dpkg -i kibana-8.12.2-amd64.deb
 
# 编辑Kibana的配置文件，设置监听端口、主机地址、公共基础URL、Elasticsearch集群地址以及界面语言
[root@node6 ~]# vim /etc/kibana/kibana.yml
server.port: 5601  # Kibana服务监听端口
server.host: "0.0.0.0"  # Kibana监听的主机地址，0.0.0.0表示监听所有IP
server.publicBaseUrl: "http://kibana.zhangyao.com"  # Kibana的公共基础URL
elasticsearch.hosts:  # Elasticsearch集群的地址列表
  ["http://10.0.0.160:9200","http://10.0.0.170:9200","http://10.0.0.180:9200"]
i18n.locale: "zh-CN"  # 界面语言设置为中文
 
# 重启Kibana服务以应用更改
[root@node6 ~]# systemctl restart kibana
 
# 在node6节点上安装OpenJDK 11 JDK
[root@node6 ~]# apt -y install openjdk-11-jdk
 
# 在node6节点上安装Cerebro的deb包，Cerebro是一个Elasticsearch的Web UI管理工具
[root@node6 ~]# wegt https://github.com/lmenezes/cerebro/releases/download/v0.9.4/cerebro_0.9.4_all.deb
[root@node6 ~]# dpkg -i cerebro_0.9.4_all.deb
 
# 编辑Cerebro的配置文件，设置数据存储路径
[root@node6 ~]# vim /etc/cerebro/application.conf
data.path: "/var/lib/cerebro/cerebro.db"  # Cerebro的数据存储路径
#data.path = "./cerebro.db"  # 注释掉默认路径
 
# 重启Cerebro服务以应用更改
[root@node6 ~]# systemctl restart cerebro.service
 
# 在node6、node7、node8节点上分别安装Elasticsearch的deb包
[root@node6 ~]# dpkg -i elasticsearch-8.12.2-amd64.deb 
[root@node7 ~]# dpkg -i elasticsearch-8.12.2-amd64.deb 
[root@node8 ~]# dpkg -i elasticsearch-8.12.2-amd64.deb 
 
# 编辑node6上的Elasticsearch配置文件，设置集群名称、节点名称、监听主机、发现主机列表、禁用安全功能以及初始主节点列表
[root@node6 ~]# vim /etc/elasticsearch/elasticsearch.yml
cluster.name: cls-cluster  # 集群名称
node.name: node-1  # 节点名称
network.host: 0.0.0.0  # 监听主机地址
discovery.seed_hosts: ["10.0.0.160","10.0.0.170","10.0.0.180"]  # 发现主机列表
xpack.security.enabled: false  # 禁用安全功能
cluster.initial_master_nodes: ["10.0.0.160","10.0.0.170","10.0.0.180"]  # 初始主节点列表
 
# 编辑JVM选项，设置最小和最大堆内存大小
[root@node6 ~]# vim /etc/elasticsearch/jvm.options
-Xms512m  # 最小堆内存大小
-Xmx512m  # 最大堆内存大小
 
# 使用rsync将Elasticsearch的配置文件同步到node7和node8节点
[root@node6 ~]# rsync  /etc/elasticsearch/elasticsearch.yml 10.0.0.170:/etc/elasticsearch/elasticsearch.yml
[root@node6 ~]# rsync  /etc/elasticsearch/elasticsearch.yml 10.0.0.180:/etc/elasticsearch/elasticsearch.yml
[root@node6 ~]# rsync /etc/elasticsearch/jvm.options 10.0.0.170:/etc/elasticsearch/jvm.options
[root@node6 ~]# rsync /etc/elasticsearch/jvm.options 10.0.0.180:/etc/elasticsearch/jvm.options 
 
# 分别编辑node7和node8上的Elasticsearch配置文件，仅更改节点名称
[root@node7 ~]# vim /etc/elasticsearch/elasticsearch.yml
node.name: node-2
[root@node8 ~]# vim /etc/elasticsearch/elasticsearch.yml
node.name: node-3
 
# 在node6、node7、node8节点上分别重新加载systemd守护进程、启用Elasticsearch服务并启动服务
[root@node6 ~]# sudo systemctl daemon-reload
[root@node6 ~]# sudo systemctl enable elasticsearch.service
[root@node6 ~]# sudo systemctl restart elasticsearch.service
[root@node7 ~]# sudo systemctl daemon-reload
[root@node7 ~]# sudo systemctl enable elasticsearch.service
[root@node7 ~]# sudo systemctl start elasticsearch.service
[root@node8 ~]# sudo systemctl daemon-reload
[root@node8 ~]# sudo systemctl enable elasticsearch.service
[root@node8 ~]# sudo systemctl start elasticsearch.service
 
# 在node6节点上使用curl命令检查Elasticsearch集群中的节点信息
[root@node6 ~]# curl 'http://127.0.0.1:9200/_cat/nodes?v'
# 输出显示了集群中每个节点的IP地址、各种性能指标以及节点名称等信息
ip         heap.percent ram.percent cpu load_1m load_5m load_15m node.role   master name
10.0.0.180           44          95   5    0.56    0.38     0.29 cdfhilmrstw *      node-3
10.0.0.170           39          95   5    0.32    0.19     0.12 cdfhilmrstw -      node-2
10.0.0.160           33          60   1    0.19    0.28     0.22 cdfhilmrstw -      node-1
 
# 在node6节点上使用curl命令访问nginx服务器，生成访问日志
[root@node6 ~]# curl http://10.0.0.100
[root@node6 ~]# curl http://10.0.0.110
[root@node6 ~]# curl http://10.0.0.120
 
#修改windows的配置文件C:\Windows\System32\drivers\etc
10.0.0.160 kibana.zhangyao.com
```

![](https://i-blog.csdnimg.cn/direct/3755ffffdea748e9972a7a136e016d09.png)
![](https://i-blog.csdnimg.cn/direct/9bd789db2ee044eb8400d484d435e91c.png)
![](https://i-blog.csdnimg.cn/direct/ca475a91d30342f29f98c25b00f7ae89.png)
![](https://i-blog.csdnimg.cn/direct/62ccea9bd0f346558e4c20877f727a16.png)

#### 二、

![](https://i-blog.csdnimg.cn/direct/d452f0335fd04f48977e4645a0b5ef35.png)

1、安装nginx和filebeat，配置node0(10.0.0.100)，node1(10.0.0.110)，node2(10.0.0.120)，采用filebeat收集nignx日志，并发送到kafka集群。

```bash
#node0、node1、node2采用以下相同方式收集nginx日志
 
# 更新软件包列表并安装nginx
[root@node0 ~]# apt update && apt -y install nginx
 
# 编辑nginx的主配置文件，以自定义日志格式
[root@node0 ~]# vim /etc/nginx/nginx.conf
# 在http块中定义一个新的日志格式access_json，该格式将日志记录为JSON
http {
  ...
  log_format access_json '{
        "@timestamp": "$time_iso8601",  # 日志时间戳
        "host": "$server_addr",         # 服务器IP地址
        "clientip": "$remote_addr",     # 客户端IP地址
        "size": $body_bytes_sent,       # 发送的字节数
        "responsetime": $request_time,  # 请求处理时间
        "upstreamtime": "$upstream_response_time",  # 上游服务器响应时间
        "upstreamhost": "$upstream_addr",  # 上游服务器地址
        "http_host": "$host",           # 请求的host头
        "uri": "$uri",                  # 请求的URI
        "domain": "$host",              # 同http_host，请求的域名
        "xff": "$http_x_forwarded_for", # X-Forwarded-For头，用于识别通过HTTP代理或负载均衡器连接到web服务器的客户端的原始IP地址
        "referer": "$http_referer",     # Referer头，表示请求的来源页面
        "tcp_xff": "$proxy_protocol_addr",  # 如果使用了Proxy Protocol，这是客户端的真实IP地址
        "http_user_agent": "$http_user_agent",  # 用户代理字符串
        "status": "$status",            # HTTP响应状态码
        "request_method": "$request_method"  # 请求方法（GET, POST等）
 }';
# 使用新定义的日志格式记录访问日志
access_log /var/log/nginx/access_json.log access_json;
# 错误日志配置保持不变
error_log /var/log/nginx/error.log;
}
 
# 编辑nginx的默认站点配置文件，注释掉默认的try_files指令
[root@node0 ~]# vim /etc/nginx/sites-available/default
location / {
    ...
    #try_files $uri $uri/ =404;  # 注释掉这一行，意味着可以自定义处理请求的方式
}
 
# 重启nginx以应用更改
[root@node0 ~]# systemctl restart nginx

# 安装filebeat的deb包
[root@node0 ~]# dpkg -i filebeat-8.12.2-amd64.deb  # 安装filebeat
 
# 备份filebeat的配置文件
[root@node0 ~]# cp /etc/filebeat/filebeat.yml{,.bak}
 
# 编辑filebeat的配置文件
[root@node0 ~]# vim /etc/filebeat/filebeat.yml
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /var/log/nginx/access_json.log
    json.keys_under_root: true
    json.overwrite_keys: true
    tags: ["nginx-access"]
 
  - type: log
    enabled: true
    paths:
      - /var/log/nginx/error.log
    tags: ["nginx-error"]
 
  - type: log
    enabled: true
    paths:
      - /var/log/syslog
    tags: ["syslog"]
 
output.kafka:
  hosts: ["10.0.0.130:9092", "10.0.0.140:9092", "10.0.0.150:9092"]
  topic: filebeat-log
  partition.round_robin:
    reachable_only: true
  required_acks: 1
  compression: gzip
  max_message_bytes: 1000000
 
 
# 启用并启动filebeat服务
[root@node0 ~]# systemctl enable --now filebeat
```

2、安装kafka集群和logstash，mysql，配置node3(10.0.0.130)，node4(10.0.0.140)，node5(10.0.0.150)采用logstash转发nginx日志到elasticsearch集群。

```bash
# 在 node3 节点上执行 install_kafka_cluster.sh 脚本，用于安装 Kafka 集群相关组件
[root@node3 ~]# bash install_kafka_cluster.sh
# 在 node4 节点上执行 install_kafka_cluster.sh 脚本，用于安装 Kafka 集群相关组件
[root@node4 ~]# bash install_kafka_cluster.sh
# 在 node5 节点上执行 install_kafka_cluster.sh 脚本，用于安装 Kafka 集群相关组件
[root@node5 ~]# bash install_kafka_cluster.sh
 
# 在 node3 节点上启动 Kafka 服务，使用指定的配置文件
[root@node3 ~]# /usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties
# 在 node4 节点上启动 Kafka 服务，使用指定的配置文件
[root@node4 ~]# /usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties
# 在 node5 节点上启动 Kafka 服务，使用指定的配置文件
[root@node5 ~]# /usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties
 
 
# 在 node4 节点上更新系统软件包列表，并安装 OpenJDK 17，因为 Logstash 依赖 Java 环境
[root@node4 ~]# apt update && apt -y install openjdk-17-jdk
# 在 node4 节点上使用 dpkg 工具安装 Logstash 的 deb 包
[root@node4 ~]# dpkg -i logstash-8.12.2-amd64.deb 
 
# 在 node4 节点上使用 vim 编辑器编辑 Logstash 的配置文件 kafka-to-es.conf
# 此配置文件用于将 Kafka 中的数据转发到 Elasticsearch
[root@node4 ~]# vim /etc/logstash/conf.d/kafka-to-es.conf
# Logstash 的输入配置部分，使用 Kafka 作为数据源
input {
    kafka {
        # 指定 Kafka 集群的引导服务器地址，用于连接 Kafka 集群
        bootstrap_servers => "10.0.0.130:9092,10.0.0.140:9092,10.0.0.150:9092"
        # 指定要消费的 Kafka 主题
        topics => "filebeat-log"
        # 指定消息的编解码器为 JSON，用于解析 Kafka 中的消息
        codec => "json"
    }
}
 
# Logstash 的输出配置部分，根据日志的标签将数据输出到不同的 Elasticsearch 索引
output {
    # 如果日志标签包含 "nginx-access"，则将数据发送到 Elasticsearch
    if "nginx-access" in [tags] {
        elasticsearch {
            # 指定 Elasticsearch 集群的节点地址
            hosts => ["10.0.0.160:9200", "10.0.0.170:9200", "10.0.0.180:9200"]
            # 指定 Elasticsearch 中的索引名称，按日期生成
            index => "logstash-kafka-nginx-accesslog-%{+YYYY.MM.dd}"
            # 允许覆盖现有的索引模板
            template_overwrite => true
        }
         jdbc {
           # 配置 JDBC 连接字符串
           connection_string => "jdbc:mysql://10.0.0.150/elk?user=elk&password=123456&useUnicode=true&characterEncoding=UTF8"
           # 配置 SQL 插入语句，使用占位符
           statement => "INSERT INTO elklog (clientip, responsetime, uri, status) VALUES (?, ?, ?, ?)"
           # 配置占位符对应的字段
           statement_params => {
             "1" => "clientip",
             "2" => "responsetime",
             "3" => "uri",
             "4" => "status"
           }
        }
    } 
    # 如果日志标签包含 "nginx-error"，则将数据发送到 Elasticsearch
    else if "nginx-error" in [tags] {
        elasticsearch {
            # 指定 Elasticsearch 集群的节点地址
            hosts =>  ["10.0.0.160:9200", "10.0.0.170:9200", "10.0.0.180:9200"]
            # 指定 Elasticsearch 中的索引名称，按日期生成
            index => "logstash-kafka-nginx-errorlog-%{+YYYY.MM.dd}"
            # 允许覆盖现有的索引模板
            template_overwrite => true
        }
    } 
    # 如果日志标签包含 "syslog"，则将数据发送到 Elasticsearch
    else if "syslog" in [tags] {
        elasticsearch {
            # 指定 Elasticsearch 集群的节点地址
            hosts =>  ["10.0.0.160:9200", "10.0.0.170:9200", "10.0.0.180:9200"]
            # 指定 Elasticsearch 中的索引名称，按日期生成
            index => "logstash-kafka-syslog-%{+YYYY.MM.dd}"
            # 允许覆盖现有的索引模板
            template_overwrite => true
        }
    }
}
 
# 在node4节点上，使用dpkg命令安装mysql-connector-j的deb包，该包适用于ubuntu22.04系统，版本为8.0.33
[root@node4 ~]# dpkg -i mysql-connector-j_8.0.33-1ubuntu22.04_all.deb  
 
# 在node4节点上，创建目录路径 /usr/share/logstash/vendor/jar/jdbc，如果父目录不存在则一并创建
[root@node4 ~]# mkdir -p /usr/share/logstash/vendor/jar/jdbc  
 
# 在node4节点上，将mysql-connector-j-8.0.33.jar文件从 /usr/share/java/ 复制到 /usr/share/logstash/vendor/jar/jdbc/ 目录下
[root@node4 ~]# cp /usr/share/java/mysql-connector-j-8.0.33.jar /usr/share/logstash/vendor/jar/jdbc/  
 
# 在node4节点上，递归修改 /usr/share/logstash/vendor/jar/ 目录及其所有子目录和文件的所有者为logstash用户，所属组为logstash组
[root@node4 ~]# chown -R logstash.logstash /usr/share/logstash/vendor/jar/  
 
# 在node4节点上，更新软件包列表并安装ruby语言环境
[root@node4 ~]# apt update && apt -y install ruby  
 
# 在node4节点上，修改ruby的gem源，添加国内的ruby-china源，并移除默认的rubygems.org源
[root@node4 ~]# gem sources --add https://gems.ruby-china.com/ --remove https://rubygems.org/  
 
# 在node4节点上，使用logstash的插件安装命令，安装logstash-output-jdbc插件
[root@node4 ~]# /usr/share/logstash/bin/logstash-plugin install logstash-output-jdbc
#如果无法在线安装，可以先从已经安装的主机导出插件，再导入
[root@ubuntu22 ~]# /usr/share/logstash/bin/logstash-plugin prepare-offline-pack logstash-output-jdbc
[root@node4 ~]# /usr/share/logstash/bin/logstash-plugin install file:///usr/share/logstash-offline-plugins-8.12.2.zip
#检查插件安装成功
[root@node4 ~]# /usr/share/logstash/bin/logstash-plugin|grep jdbc
 
# 在node4节点上，重启logstash服务
[root@node4 ~]# systemctl restart logstash  
 
 
# 在node5节点上，更新软件包列表并安装mysql服务器
[root@node5 ~]# apt update && apt -y install mysql-server  
 
# 在node5节点上，使用vim编辑器打开mysql配置文件mysqld.cnf，修改其中的绑定地址相关配置
[root@node5 ~]# vim /etc/mysql/mysql.conf.d/mysqld.cnf  
# 将mysql服务的绑定地址修改为0.0.0.0，允许所有IP地址访问
bind-address        = 0.0.0.0  
# 将mysqlx协议的绑定地址也修改为0.0.0.0，允许所有IP地址访问
mysqlx-bind-address = 0.0.0.0  
 
# 在node5节点上，重启mysql服务使配置生效
[root@node5 ~]# systemctl restart mysql.service  
 
# 在node5节点上，进入mysql命令行客户端
[root@node5 ~]# mysql  
 
# 在mysql中，创建名为elk的数据库
[root@node5 ~]# create database elk;  
 
# 在mysql中，创建用户elk，允许来自10.0.0.0/24网段的主机连接，密码为123456
[root@node5 ~]# create user elk@"10.0.0.%" identified by '123456';  
 
# 在mysql中，授予用户elk对elk数据库下所有表的所有权限
[root@node5 ~]# grant all privileges on elk.* to elk@"10.0.0.%";  
 
# 在mysql中，刷新权限使配置立即生效
[root@node5 ~]# flush privileges;  
 
# 在mysql中，切换到elk数据库
[root@node5 ~]# use elk;  
 
# 在elk数据库中，创建名为elklog的表，包含clientip、responsetime、uri、status、time字段，time字段默认值为当前时间戳
[root@node5 ~]# CREATE TABLE elklog ( clientip VARCHAR(39),responsetime DECIMAL(10, 3),uri VARCHAR(256),status CHAR(3),time TIMESTAMP DEFAULT CURRENT_TIMESTAMP);
```

3、安装elasticsearch集群、kibana、cerebro，配置node6(10.0.0.160)，node7(10.0.0.170)，node8(10.0.0.180)，利用kibana和cerebro查看收集的日志。

```bash
# 在node6节点上安装Kibana的deb包
[root@node6 ~]# dpkg -i kibana-8.12.2-amd64.deb
 
# 编辑Kibana的配置文件，设置监听端口、主机地址、公共基础URL、Elasticsearch集群地址以及界面语言
[root@node6 ~]# vim /etc/kibana/kibana.yml
server.port: 5601  # Kibana服务监听端口
server.host: "0.0.0.0"  # Kibana监听的主机地址，0.0.0.0表示监听所有IP
server.publicBaseUrl: "http://kibana.zhangyao.com"  # Kibana的公共基础URL
elasticsearch.hosts:  # Elasticsearch集群的地址列表
  ["http://10.0.0.160:9200","http://10.0.0.170:9200","http://10.0.0.180:9200"]
i18n.locale: "zh-CN"  # 界面语言设置为中文
 
# 重启Kibana服务以应用更改
[root@node6 ~]# systemctl restart kibana
 
# 在node6节点上安装OpenJDK 11 JDK
[root@node6 ~]# apt -y install openjdk-11-jdk
 
# 在node6节点上安装Cerebro的deb包，Cerebro是一个Elasticsearch的Web UI管理工具
[root@node6 ~]# dpkg -i cerebro_0.9.4_all.deb
 
# 编辑Cerebro的配置文件，设置数据存储路径
[root@node6 ~]# vim /etc/cerebro/application.conf
data.path: "/var/lib/cerebro/cerebro.db"  # Cerebro的数据存储路径
#data.path = "./cerebro.db"  # 注释掉默认路径
 
# 重启Cerebro服务以应用更改
[root@node6 ~]# systemctl restart cerebro.service
 
# 在node6、node7、node8节点上分别安装Elasticsearch的deb包
[root@node6 ~]# dpkg -i elasticsearch-8.12.2-amd64.deb 
[root@node7 ~]# dpkg -i elasticsearch-8.12.2-amd64.deb 
[root@node8 ~]# dpkg -i elasticsearch-8.12.2-amd64.deb 
 
# 编辑node6上的Elasticsearch配置文件，设置集群名称、节点名称、监听主机、发现主机列表、禁用安全功能以及初始主节点列表
[root@node6 ~]# vim /etc/elasticsearch/elasticsearch.yml
cluster.name: zjy-cluster  # 集群名称
node.name: node-6  # 节点名称
network.host: 0.0.0.0  # 监听主机地址
discovery.seed_hosts: ["10.0.0.160","10.0.0.170","10.0.0.180"]  # 发现主机列表
xpack.security.enabled: false  # 禁用安全功能
cluster.initial_master_nodes: ["10.0.0.160","10.0.0.170","10.0.0.180"]  # 初始主节点列表
 
# 编辑JVM选项，设置最小和最大堆内存大小
[root@node6 ~]# vim /etc/elasticsearch/jvm.options
-Xms1g  # 最小堆内存大小
-Xmx1g  # 最大堆内存大小
 
# 使用rsync将Elasticsearch的配置文件同步到node7和node8节点
[root@node6 ~]# rsync  /etc/elasticsearch/elasticsearch.yml 10.0.0.170:/etc/elasticsearch/elasticsearch.yml
[root@node6 ~]# rsync  /etc/elasticsearch/elasticsearch.yml 10.0.0.180:/etc/elasticsearch/elasticsearch.yml
[root@node6 ~]# rsync /etc/elasticsearch/jvm.options 10.0.0.170:/etc/elasticsearch/jvm.options
[root@node6 ~]# rsync /etc/elasticsearch/jvm.options 10.0.0.180:/etc/elasticsearch/jvm.options 
 
# 分别编辑node7和node8上的Elasticsearch配置文件，仅更改节点名称
[root@node7 ~]# vim /etc/elasticsearch/elasticsearch.yml
node.name: node-7
[root@node8 ~]# vim /etc/elasticsearch/elasticsearch.yml
node.name: node-8
 
# 在node6、node7、node8节点上分别重新加载systemd守护进程、启用Elasticsearch服务并启动服务
[root@node6 ~]# sudo systemctl daemon-reload
[root@node6 ~]# sudo systemctl enable elasticsearch.service
[root@node6 ~]# sudo systemctl restart elasticsearch.service
[root@node7 ~]# sudo systemctl daemon-reload
[root@node7 ~]# sudo systemctl enable elasticsearch.service
[root@node7 ~]# sudo systemctl restart elasticsearch.service
[root@node8 ~]# sudo systemctl daemon-reload
[root@node8 ~]# sudo systemctl enable elasticsearch.service
[root@node8 ~]# sudo systemctl restart elasticsearch.service
 
# 在node6节点上使用curl命令检查Elasticsearch集群中的节点信息
[root@node6 ~]# curl 'http://127.0.0.1:9200/_cat/nodes?v'
# 输出显示了集群中每个节点的IP地址、各种性能指标以及节点名称等信息
ip         heap.percent ram.percent cpu load_1m load_5m load_15m node.role   master name
10.0.0.170           36          97   2    0.31    0.16     0.07 cdfhilmrstw -      node-7
10.0.0.180           31          95   4    0.54    0.38     0.27 cdfhilmrstw -      node-8
10.0.0.160           31          96  13    2.38    1.43     0.73 cdfhilmrstw *      node-6
 
# 在node6节点上使用curl命令访问nginx服务器，生成访问日志
[root@node6 ~]# curl http://10.0.0.100
[root@node6 ~]# curl http://10.0.0.110
[root@node6 ~]# curl http://10.0.0.120
 
#修改windows的配置文件C:\Windows\System32\drivers\etc
10.0.0.160 kibana.zhangyao.com
```

```bash
浏览器访问kibana.zhangyao.com:5601和kibana.zhangyao.com:9000
```

![](https://i-blog.csdnimg.cn/direct/d1d9573b55e14672a4fd8cf25f49485f.png)
![](https://i-blog.csdnimg.cn/direct/1b8f76e7c6194f30a364c7a12f876183.png)