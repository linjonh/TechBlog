---
layout: post
title: "推荐系统局部敏感哈希解决Embedding最近邻搜索问题"
date: 2024-10-11 14:40:36 +0800
description: "文章目录快速Embedding最近邻搜索问题聚类、索引搜索最近邻聚类搜索最近邻快速Embedding"
keywords: "局部敏感哈希可以快速的embedding最近邻搜索"
categories: ['推荐系统']
tags: ['推荐算法', '人工智能']
artid: "123577062"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=123577062
    alt: "推荐系统局部敏感哈希解决Embedding最近邻搜索问题"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=123577062
featuredImagePreview: https://bing.ee123.net/img/rand?artid=123577062
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     推荐系统局部敏感哈希解决Embedding最近邻搜索问题
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
    </p>
    <div class="toc">
     <h4>
      文章目录
     </h4>
     <ul>
      <li>
       <ul>
        <li>
         <a href="#Embedding_1" rel="nofollow">
          快速Embedding最近邻搜索问题
         </a>
        </li>
        <li>
         <a href="#_6" rel="nofollow">
          聚类、索引搜索最近邻
         </a>
        </li>
        <li>
         <ul>
          <li>
           <a href="#_7" rel="nofollow">
            聚类搜索最近邻
           </a>
          </li>
          <li>
           <a href="#_22" rel="nofollow">
            索引搜索最近邻
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a href="#_30" rel="nofollow">
          局部敏感哈希及多桶策略
         </a>
        </li>
        <li>
         <ul>
          <li>
           <a href="#_32" rel="nofollow">
            局部敏感哈希的基本原理
           </a>
          </li>
          <li>
           <a href="#_40" rel="nofollow">
            局部敏感哈希的多桶策略
           </a>
          </li>
          <li>
           <a href="#_44" rel="nofollow">
            局部敏感哈希代码实现
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <p>
    </p>
    <h3>
     <a id="Embedding_1">
     </a>
     快速Embedding最近邻搜索问题
    </h3>
    <ul>
     <li>
      在深度学习推荐系统中，我们经常会使用Embedding方法对用户-物品进行向量化。在训练物品和用户的Embedding向量时，如果二者的 Embedding在同一个向量空间内，我们就可以通过内积、余弦、欧式距离等相似度计算方法，来计算它们之间的相似度，从而通过用户-物品相似度进行个性化推荐，或者通过物品-物品相似度进行相似物品查找。
     </li>
     <li>
      假设用户-物品的Embedding都在一个k维的Embedding空间中，物品总数为n，那么用户和所有物品向量相似度的时间复杂度是 O(k×n)。如果物品总数n过大时，线性的时间复杂度也是线上服务器无法承受的。
     </li>
     <li>
      用户-物品的Embedding在一个向量空间内，因此
      <strong>
       召回与用户向量最相似的物品Embedding向量这一问题，其实就是在向量空间内搜索最近邻的过程
      </strong>
      。
     </li>
    </ul>
    <h3>
     <a id="_6">
     </a>
     聚类、索引搜索最近邻
    </h3>
    <h4>
     <a id="_7">
     </a>
     聚类搜索最近邻
    </h4>
    <ul>
     <li>
      <p>
       聚类就是把相似的点聚类到一起，从而找到最近邻。
      </p>
     </li>
     <li>
      <p>
       对于聚类搜索最近邻问题，最常见的方法就是K-means算法，步骤如下：
      </p>
      <ul>
       <li>
        随机指定 k 个中心点；
       </li>
       <li>
        每个中心点代表一个类，把所有的点按照距离的远近指定给距离最近的中心点代表的类；
       </li>
       <li>
        计算每个类包含点的平均值作为新的中心点位置；
       </li>
       <li>
        确定好新的中心点位置后，迭代进入第 2 步，直到中心点位置收敛，不再移动。
       </li>
      </ul>
     </li>
     <li>
      <p>
       3中心点K-means迭代过程如下图：
       <br/>
       <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/0910c7b93221e696e87c5d4747b63bea.png"/>
      </p>
     </li>
     <li>
      <p>
       如果我们能够在离线计算好每个Embedding向量的类别，在线上我们只需要在同一个类别内的Embedding向量中搜索就可以了。
      </p>
     </li>
     <li>
      <p>
       K-means聚类的缺点：
      </p>
      <ul>
       <li>
        对于边界情况不好处理。比如，聚类边缘的点的最近邻往往会包括相邻聚类的点，如果我们只在类别内搜索，就会遗漏这些近似点。
       </li>
       <li>
        k的数量也不那么好确定，
        <strong>
         k大，离线迭代慢，k小，在线搜索范围大，无法节约时间
        </strong>
        。
       </li>
      </ul>
     </li>
    </ul>
    <h4>
     <a id="_22">
     </a>
     索引搜索最近邻
    </h4>
    <p>
     我们还可以尝试一下经典的向量空间索引算法：Kd-tree（K-dimension tree）。与聚类不同，它是为空间中的点 / 向量建立一个索引。如下图：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/ca54b9fd3705f3129f2b458f75fb916b.png"/>
    </p>
    <ul>
     <li>
      红色的线把点云一分为二，再用深蓝色的线把各自片区的点云一分为二，以此类推，直到每个片区只剩下一个点，这就完成了空间索引的构建。如果我们能够把这套索引搬到线上，就可以利用二叉树的结构快速找到邻接点。
     </li>
     <li>
      Kd-tree索引的缺点：
      <ul>
       <li>
        无法完全解决边缘点最近邻的问题。对于点q来说，它的邻接片区是右上角的片区，但是它的最近邻点却是深蓝色切分线下方的那个点。所以按照Kd-tree的索引方法，我们还是会遗漏掉最近邻点，它只能保证快速搜索到近似的最近邻点集合。
       </li>
       <li>
        Kd-tree索引结构复杂，离线和在线维护的过程也相对复杂。
       </li>
      </ul>
     </li>
    </ul>
    <h3>
     <a id="_30">
     </a>
     局部敏感哈希及多桶策略
    </h3>
    <ul>
     <li>
      局部敏感哈希（Locality Sensitive Hashing,LSH）用简洁而高效的方法几乎完美地解决了这一召回层所出现的问题。
     </li>
    </ul>
    <h4>
     <a id="_32">
     </a>
     局部敏感哈希的基本原理
    </h4>
    <ul>
     <li>
      局部敏感哈希的基本思想是希望让相邻的点落入同一个桶，这样在进行最近邻搜索时，我们仅需要在一个桶内，或相邻几个桶内的元素中进行搜索即可。如果保持每个桶中的元素个数在一个常数附近，我们就可以把最近邻搜索的时间复杂度降低到常数级别。
     </li>
     <li>
      欧式空间中，
      <strong>
       将高维空间的点映射到低维空间，原本接近的点在低维空间中肯定依然接近，但原本远离的点则有一定概率变成接近的点
      </strong>
      。利用低维空间可以保留高维空间相近距离关系的性质，我们就可以构造局部敏感哈希桶。由于Embedding大量使用内积操作计算相似度，因此就可以用内积操作来构建局部敏感哈希桶。假设v是高维空间中的k维Embedding向量，x是随机生成的k维映射向量。那我们利用内积操作可以将v映射到一维空间，得到数值 h(v)=v⋅x。
     </li>
     <li>
      哈希分桶函数h(v) 公式如下（向下取整）：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/66e4552954d0422a4006d975307c3917.png">
       <br/>
       w是分桶宽度，b是0到w间的一个均匀分布随机变量，避免分桶边界固化。
      </img>
     </li>
     <li>
      因为映射操作会损失部分距离信息，如果我们仅采用一个哈希函数进行分桶，必然存在相近点误判的情况。因此，我们可以采用m个哈希函数同时进行分桶。如果两个点同时掉进了m个桶，那它们是相似点的概率将大大增加。通过分桶找到相邻点的候选集合后，我们就可以在有限的候选集合中通过遍历找到目标点真正的K近邻了。
     </li>
    </ul>
    <h4>
     <a id="_40">
     </a>
     局部敏感哈希的多桶策略
    </h4>
    <ul>
     <li>
      如果有多个分桶函数的话，具体应该如何处理不同桶之间的关系？举个例子：假设有 A、B、C、D、E 五个点，有h1和h2两个分桶函数。使用h1来分桶时，一个桶内是A、B，另一个是C、D、E；使用h2来分桶时，一个桶内是A、C、D，另一个是B、E。C的最近邻点，如何找？可以通过与方法（AND）来处理两个分桶结果之间的关系。结果得出D为最近邻点。同样还有一种方法叫或(Or)，这样候选集就有三个点A、D、E。虽然增加了候选集的规模，但同样也增加计算开销。至于如何权衡与和或的方法主要是看具体项目而定。这里有以下两点建议：
      <ol>
       <li>
        点数越多，分桶函数h中桶的个数也要越多；点数越少，桶的个数也要减少。
       </li>
       <li>
        Embedding维度越大，哈希函数的数量增加，尽量采用且的方式作为多桶策略；反之，Embedding维度越小，哈希函数的数量减小，尽量采用或的方式作为多桶策略。
       </li>
      </ol>
     </li>
    </ul>
    <h4>
     <a id="_44">
     </a>
     局部敏感哈希代码实现
    </h4>
    <pre><code class="prism language-scala">
<span class="token keyword">def</span> embeddingLSH<span class="token punctuation">(</span>spark<span class="token operator">:</span>SparkSession<span class="token punctuation">,</span> movieEmbMap<span class="token operator">:</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> Array<span class="token punctuation">[</span><span class="token builtin">Float</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
  <span class="token comment">//将电影embedding数据转换成dense Vector的形式，便于之后处理</span>
  <span class="token keyword">val</span> movieEmbSeq <span class="token operator">=</span> movieEmbMap<span class="token punctuation">.</span>toSeq<span class="token punctuation">.</span>map<span class="token punctuation">(</span>item <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>item<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> Vectors<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>item<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>map<span class="token punctuation">(</span>f <span class="token keyword">=&gt;</span> f<span class="token punctuation">.</span>toDouble<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> movieEmbDF <span class="token operator">=</span> spark<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>movieEmbSeq<span class="token punctuation">)</span><span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token string">"movieId"</span><span class="token punctuation">,</span> <span class="token string">"emb"</span><span class="token punctuation">)</span>


  <span class="token comment">//利用Spark MLlib创建LSH分桶模型</span>
  <span class="token keyword">val</span> bucketProjectionLSH <span class="token operator">=</span> <span class="token keyword">new</span> BucketedRandomProjectionLSH<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">//分桶公式中的分桶宽度w</span>
    <span class="token punctuation">.</span>setBucketLength<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>
    <span class="token comment">//多桶策略中的分桶次数</span>
    <span class="token punctuation">.</span>setNumHashTables<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>setInputCol<span class="token punctuation">(</span><span class="token string">"emb"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>setOutputCol<span class="token punctuation">(</span><span class="token string">"bucketId"</span><span class="token punctuation">)</span>
  <span class="token comment">//训练LSH分桶模型</span>
  <span class="token keyword">val</span> bucketModel <span class="token operator">=</span> bucketProjectionLSH<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>movieEmbDF<span class="token punctuation">)</span>
  <span class="token comment">//进行分桶</span>
  <span class="token keyword">val</span> embBucketResult <span class="token operator">=</span> bucketModel<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>movieEmbDF<span class="token punctuation">)</span>
  
  <span class="token comment">//打印分桶结果</span>
  println<span class="token punctuation">(</span><span class="token string">"movieId, emb, bucketId schema:"</span><span class="token punctuation">)</span>
  embBucketResult<span class="token punctuation">.</span>printSchema<span class="token punctuation">(</span><span class="token punctuation">)</span>
  println<span class="token punctuation">(</span><span class="token string">"movieId, emb, bucketId data result:"</span><span class="token punctuation">)</span>
  embBucketResult<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> truncate <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">)</span>
  
  <span class="token comment">//尝试对一个示例Embedding查找最近邻</span>
  println<span class="token punctuation">(</span><span class="token string">"Approximately searching for 5 nearest neighbors of the sample embedding:"</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> sampleEmb <span class="token operator">=</span> Vectors<span class="token punctuation">.</span>dense<span class="token punctuation">(</span><span class="token number">0.795</span><span class="token punctuation">,</span><span class="token number">0.583</span><span class="token punctuation">,</span><span class="token number">1.120</span><span class="token punctuation">,</span><span class="token number">0.850</span><span class="token punctuation">,</span><span class="token number">0.174</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.839</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.0633</span><span class="token punctuation">,</span><span class="token number">0.249</span><span class="token punctuation">,</span><span class="token number">0.673</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.237</span><span class="token punctuation">)</span>
  bucketModel<span class="token punctuation">.</span>approxNearestNeighbors<span class="token punctuation">(</span>movieEmbDF<span class="token punctuation">,</span> sampleEmb<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span>truncate <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>

</code></pre>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f67:2e6373646e2e6e65742f73696e61745f33313835343936372f:61727469636c652f64657461696c732f313233353737303632" class_="artid" style="display:none">
 </p>
</div>


