---
arturl_encode: "68747470733a2f2f:626c6f672e6373646e2e6e65742f753031333636393931322f:61727469636c652f64657461696c732f313431333838323433"
layout: post
title: "发展史-深度学习-云计算"
date: 2025-03-08 01:06:59 +0800
description: "……"
keywords: "发展史 | 深度学习 / 云计算"
categories: ['Science', 'Computer']
tags: ['深度学习', '云计算']
artid: "141388243"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=141388243
    alt: "发展史-深度学习-云计算"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=141388243
featuredImagePreview: https://bing.ee123.net/img/rand?artid=141388243
cover: https://bing.ee123.net/img/rand?artid=141388243
image: https://bing.ee123.net/img/rand?artid=141388243
img: https://bing.ee123.net/img/rand?artid=141388243
---

# 发展史 | 深度学习 / 云计算

**注：本文为来自 csdn 不错的“深度学习 / 云计算发展史 ” 相关文章合辑**
。

略作重排。

---

## 深度学习发展史（1943-2024 编年体）（The History of Deep Learning）

*Hefin\_H 已于 2024-05-23 15:54:45 修改*

![img](https://i-blog.csdnimg.cn/blog_migrate/ce327182d298e8eb058091bcca826c03.png)

深度学习是人工智能领域的一个重要分支，它在图像识别、语音识别、自然语言处理等方面取得了显著的进展。

学习任一门知识都应该先从其历史开始，把握了历史，也就抓住了现在与未来 。

那么深度学习到底是经历了一段怎样的发展过程呢？下面我们就来了解一下深度学习发展史。

### **1940s-1950s：早期神经网络概念**

**1943 年**
，Warren McCulloch 和 Walter Pitts 发表论文 “
*A logical calculus of the ideas immanent in nervous activity”（神经活动中内在思想的逻辑演算）*
，建立了神经网络和数学模型，称为
**MCP 模型**
。奠定了神经网络和数学模型的基础。

MCP 当时是希望能够用计算机来模拟人的神经元反应的过程，该模型将神经元简化为了三个过程：输入信号线性加权，求和，非线性激活（阈值法）。如下图所示：

![图片](https://i-blog.csdnimg.cn/blog_migrate/35dd123d715b5fd46ccdf06530ba409d.png)

图：MCP 模型

**1949 年**
，Donald Hebb 提出了
***Hebbian 学习规则***
，该规则表明，如果神经元 A 在接收到神经元 B 的输入后，持续发放输出，那么神经元 A 与神经元 B 之间的连接强度将增强：

Hebb 学习规则与 “条件反射” 机理一致，并且已经得到了神经细胞学说的证实。Hebbian 学习规则为神经元连接强度的学习机制提供了理论支持。

### **1950s-1960s：感知机和早期模型**

**1958 年**
，计算机科学家 Frank Rosenblatt 提出了两层神经元组成的神经网络，称之为
***感知器 (Perceptrons)***
，使用 MCP 模型对输入的多维数据进行二分类，且能够使用梯度下降法从训练样本中自动学习更新权值。

**1969 年**
，Marvin Minsky 和 Seymour Papert 在他们的书《
*Perceptrons*
》中指出
**感知器本质上是一种线性模型**
，只能处理线性分类问题，就连最简单的 XOR（异或）问题都无法正确分类。

![图片](https://i-blog.csdnimg.cn/blog_migrate/765ae4be4a78db0080a3d3c27b8d5659.jpeg)

图：异或（XOR）问题：没有一条直线能将绿点和红点分开

### **1980s-1990s：多层感知机和反向传播**

**1985 年**
，Geoffrey Hinton 等人发表论文
*A learning algorithm for boltzmann machines*
，提出了
**受限玻尔兹曼机 (RBM)**
。一种用于无监督学习的随机神经网络。可用于特征提取、降维。后来成为深度信念网络的组成块进而流行。

**1986 年**
，Geoffrey Hinton 发明了适用于多层感知器（MLP）的
**BP（Backpropagation）算法**
，并采用 Sigmoid 进行非线性映射，有效解决了非线性分类和训练的问题。该方法引起了神经网络的第二次热潮。

**1989 年**
， Yann LeCun 等人发表论文
*Backpropagation Applied to Handwritten Zip Code Recognition（反向传播应用于手写邮政编码识别）*
，使用 BP 算法训练
***卷积神经网络（CNN）***
用于手写数字识别。

![图片](https://i-blog.csdnimg.cn/blog_migrate/275d54ec9e44b1bd11d1ef14fee7f55f.png)

图：CNN 模型

### **1990** s-2000：深度学习领域的形成期

**1990 年，**
Jeffrey Elman 发表论文
*Finding structure in time*
提出
**SRNs（也叫 Elman Networks）**
，其核心概念就是今天所熟知的
***循环神经网络（RNN）***
。

**1991 年，**
Sepp Hochreiter 在他的毕业论文中阐述了
**梯度消失问题**
，当梯度通过深度神经网络中的各层反向传播时，它们往往会变得非常小，导致较早的层训练速度非常慢或完全不训练。这个问题在循环神经网络（RNN）和深度前馈网络中尤其严重。

**1993 年**
，Geoffrey Hinton 发表论文
*Autoencoders, minimum description length and Helmholtz free energy，*
发表了关于
**自编码器（Autoencoders）**
的研究，自编码器的概念至少在 1993 年之前就已经存在并被学术界所探讨。

**1997 年**
，Sepp Hochreiter 和 Jürgen Schmidhuber发表了论文
***Long Short-Term Memory***
，为了解决 RNN 的梯度消失问题，提出了
**LSTM**
。

**1998 年**
，Yann LeCun 等人发表论文
*Gradient-based learning applied to document recognition*
，改进了之前的 CNN，提出了
**LeNet-5**
，专为 MNIST 数据集手写数字识别而设计，LeNet-5 引入了
**卷积、池化和激活函数**
的使用等关键概念，这些概念已成为现代深度学习的基础。

### **2000s：深度学习的复兴**

**2006 年**
，Geoffrey Hinton 等人发表论文
*A Fast Learning Algorithm for Deep Belief Nets*
，提出
**深度信念网络（DBN）**
。这篇论文被认为是近代的深度学习方法的开始。

**同年**
，还是 Geoffrey Hinton 等人发表论文
*Reducing the Dimensionality of Data with Neural Networks*
，提出深度自编码器。以上这两篇论文都提出深层网络训练中
**梯度消失问题的解决方案：逐层贪心预训练**
，即通过无监督预训练对权值进行初始化 + 有监督训练微调。

还是
**2006 年**
，NVIDIA 推出
**CUDA 框架**
，利用 GPU 的并行处理能力，将 GPU 用作通用并行计算设备，以加速各种计算任务，而不仅限于图形处理。CUDA 框架大大提升了深度学习算法的效率。

### **2010s: 深度学习的突破与普及**

**2012 年**
，Alex Krizhevsky、Ilya Sutskever 和 Geoffrey Hinton 的
**AlexNet**
在 ImageNet 大规模视觉识别挑战赛 (ILSVRC) 中取得了巨大成功，首次采用
**ReLU 激活函数**
，从根本上解决了梯度消失问题，于是抛弃了预训练 + 微调的方法，完全采用有监督训练。AlexNet 展示了卷积神经网络 (CNN) 的强大功能，并标志着计算机视觉的转折点，普及了深度学习技术。

**2013 年 12 月 19 日**
，Google DeepMind 发表论文
*Playing Atari with Deep Reinforcement Learning*
，提出了
**Deep Q-Network (DQN)，将深度学习与强化学习相结合。**
DQN 通过使用卷积神经网络 (CNN) 估计 Q 值，成功在 Atari 游戏中实现了超越人类的表现。DQN 对人工智能和自动化控制系统产生了深远影响。

**2013 年 12 月 20 日**
，Kingma 和 Welling 发表论文
*Auto-Encoding Variational Bayes*
，提出了
**变分自编码器（VAE）**
，展示了一种
**结合贝叶斯推理和深度学习的生成模型**
。VAE 通过编码器 - 解码器结构学习数据的潜在表示，并能够生成新样本。VAE 在图像生成、异常检测、数据压缩等领域取得显著成果。其创新方法为生成模型提供了概率框架，推动了深度学习在生成任务中的应用和发展。

**2014 年 6 月 10 日**
，Ian Goodfellow 等人发表论文
*Generative Adversarial Nets*
提出
**生成对抗网络（GAN）**
，在图像生成、图像修复、超分辨率等领域取得了显著成果，为生成模型带来了新的方向。

![图片](https://i-blog.csdnimg.cn/blog_migrate/abe7a717e26fa81a2caaee8a0ac79ff5.png)

图：GAN 模型

**2014 年 6 月 24 日**
，Google DeepMind 发表
*Recurrent Models of Visual Attention*
，使得
**注意力机制（Attention Mechanism）**
开始受到广泛关注。该论文采用了循环神经网络（RNN）模型，并集成了注意力机制来处理图像分类任务，开创了将注意力机制应用于深度学习模型的先河。

**2014 年 9 月 1 日**
，Dzmitry Bahdanau、KyungHyun Cho 和 Yoshua Bengio 发表论文
*Neural Machine Translation by Jointly Learning to Align and Translate*
，将注意力机制（Attention Mechanism）引入机器翻译，以提高长序列处理能力。它在机器翻译的历史中标志着一个重要的转折点。

**2015 年 5 月 18 日**
，Ronneberger 等人发表论文
*U-Net: Convolutional Networks for Biomedical Image Segmentation*
，提出了
**U-Net**
，U-Net 采用对称的 U 形架构，通过跳跃连接融合不同层次的特征信息，实现高精度的分割。其设计有效解决了小样本问题，广泛应用于医学影像分析、遥感图像处理等领域，对图像分割任务的发展产生了深远影响。

![图片](https://i-blog.csdnimg.cn/blog_migrate/69baf61d89eddc071a5956451128313d.png)

图：U-Net

**2015 年 12 月 10 日**
，何凯明等人发表论文
*Deep Residual Learning for Image Recognition*
，提出了
**ResNet（残差网络）**
，展示了一种通过残差连接解决深层神经网络训练难题的方法。ResNet 在 ILSVRC 2015 竞赛中获得冠军，显著提高了深度学习模型的性能和可训练性。其创新架构允许构建更深的网络，推动了图像识别、目标检测等计算机视觉任务的发展，成为深度学习领域的重要基石。

![图片](https://i-blog.csdnimg.cn/blog_migrate/79fa22afdbd8ebaea47f815087702910.png)

图：ResNet

**2015 年 - 2016 年**
，Google，Facebook 相继推出
**TensorFlow、PyTorch 和 Keras**
，极大地促进了深度学习研究和应用的发展，使得复杂的神经网络模型的开发和训练变得更加便捷和高效。

**2016 年**
， Google DeepMind 开发的
**AlphaGo**
击败了围棋世界冠军李世石，展示了深度强化学习的潜力。

**2017 年**
，Google Brain 发表了
*Attention is All You Need*
，提出了
**Transformer**
，彻底放弃了传统的循环神经网络（RNN）和卷积神经网络（CNN）结构，转而完全采用注意力机制来执行机器翻译任务。这一创新犹如火星撞地球一般迅速横扫了整个自然语言处理学术界。彻底改变了自然语言处理（NLP）领域。对后续的 BERT、GPT 等模型产生了深远影响。

![图片](https://i-blog.csdnimg.cn/blog_migrate/e2c5979372e27ba59cd91773c1565abf.png)

图：Transformer

**2018 年 6 月**
，OpenAI 发表了
*Improving Language Understanding by Generative Pre-Training*
，提出了
**GPT**
，这是一个具有里程碑意义的大规模预训练模型。

**2018 年 10 月 11 日**
，Google AI Language 发表了
*BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding*
，提出了
**BERT**
，GPT 和 BERT，它们分别使用自回归语言建模和自编码语言建模作为预训练目标。所有
**后续的大规模预训练模型都是这两个模型的变体**
。

![图片](https://i-blog.csdnimg.cn/blog_migrate/b441a8c68e800e8ff9cd5c6fe3b576dd.jpeg)

图：BERT

### **2020s: 深度学习的扩展与应用**

**2020 年 10 月 22 日**
，Google 团队发表
*An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale*
，提出了
**Vision Transformer（ViT）**
，虽然不是第一篇将 Transformer 应用在视觉任务的论文，但是因为其模型 “简单” 且效果好，可扩展性强（scalable，模型越大效果越好），成为了 transformer 在 CV 领域应用的里程碑著作，也引爆了后续相关研究。

**2021 年 2 月 26 日**
，OpenAI 发表了
*Learning Transferable Visual Models From Natural Language Supervision*
，提出了
**CLIP**
，通过对比学习方法，将图像与自然语言文本进行配对，实现了多模态学习。具备零样本学习能力。为多模态 AI 的研究和应用奠定了基础，推动了图像生成、理解和交互等领域的发展。

**2021 年 7 月 15 日和 7 月 22 日**
，Google DeepMind 在 Natrue 分别发表论文
*Highly accurate protein structure prediction with AlphaFold*
，
*Highly accurate protein structure prediction for the human proteome*
，发布了
**AlphaFold 2**
，AlphaFold 2 在第十四届国际蛋白质结构预测竞赛（CASP）上取得惊人的准确度，多数预测模型与实验测得的蛋白质结构模型高度一致，引起举世瞩目。对生物医学研究、药物设计和生命科学产生了深远影响。

**2022 年 12 月 20 日**
，Stability AI 发表论文
*High-Resolution Image Synthesis with Latent Diffusion Models*
，发布了完全开源的
**Stable Diffusion**
，展示了一种利用扩散过程生成图像的方法，是 AI 绘画领域的一个核心模型，能够进行文生图（txt2img）和图生图（img2img）等图像生成任务。

![图片](https://i-blog.csdnimg.cn/blog_migrate/b49708769d691356e1f82d52d32ffa42.jpeg)

图：Diffusion Model

**2022 年 7 月 12 日**
，David Holz 发布了
**Midjourney**
，一个基于生成对抗网络（GANs）和深度学习的 AI 平台，通过用户提供的文本描述生成高质量图像。

**2022 年 11 月 30 日**
，OpenAI 发布了
**GPT-3.5**
，其产品 ChatGPT 瞬间成为全球爆品。引起了全球学术界和工业界的大语言模型热潮。以 ChatGPT 为代表的大语言模型向世人展露出了前所未有的能力。一大波大语言、多模态的预训练模型如雨后春笋般迅速出现。

![图片](https://i-blog.csdnimg.cn/blog_migrate/c8f2f6d1070d5a30c9074c3651a31218.jpeg)

图：ChatGPT

以后有机会专门出一期大模型的介绍。

**2023 年 12 月 1 日**
，Albert Gu 和 Tri Dao 发表了论文
*Mamba: Linear-Time Sequence Modeling with Selective State Spaces*
，提出了
**Mamba**
，这是一种新的不同于 Transformer 的处理长序列数据的神经网络架构，能够在保持高效率的同时，提供出色的性能。对于需要处理大量数据的应用场景，如自然语言处理、语音识别和生物信息学等领域，具有重要的实际应用价值。

![图片](https://i-blog.csdnimg.cn/blog_migrate/199c45c79704fc1f497201c7a8550de9.jpeg)

图：Mamba

**2024 年 2 月 18 日**
，OpenAI 发布了
**SORA**
，一种通过文本生成视频的模型，结合了先进的 Transformer 和 GAN 架构，更多地使用了 CLIP，实现了高质量的文本到视频生成。

![图片](https://i-blog.csdnimg.cn/blog_migrate/8f358187035feeddf6ca5b39166695c8.png)

图：SORA 生成的视频

**2024 年 5 月 8 日**
，DeepMind 发表论文
*Accurate structure prediction of biomolecular interactions with AlphaFold 3*
，提出了
**AlphaFold 3**
，以前所未有的精确度成功预测了所有生命分子（蛋白质、DNA、RNA、配体等）的结构和相互作用。与现有的预测方法相比，AlphaFold 3 发现蛋白质与其他分子类型的相互作用最高提高了一倍。

![图片](https://i-blog.csdnimg.cn/blog_migrate/4b39d1b0f3361e4b38d80a3a81d6588d.png)

图：AlphaFold 3 生成的蛋白质结构

综上所述，本文详细介绍了深度学习领域从 1940 年代至今的演变历程，涵盖了早期神经网络模型、感知器、多层感知机、反向传播算法、循环神经网络、自编码器、深度信念网络、生成对抗网络、Transformer 等重要里程碑。

然而，本文仍有一些不足之处和未尽事宜。比如，有文献指出 1970 年 Seppo Linnainmaa 率先发表了反向传播算法，但本文采用了较为普遍的说法，将其归功于 Geoffrey Hinton。Hinton 本人也在 2019 年澄清，他并非反向传播算法的发明者，而是将其发扬光大的重要推动者。

此外，由于深度学习近年来发展迅猛，本文未能涵盖深度学习在各个行业和新兴研究领域的最新整合进展和趋势。也未能涵盖近两年各大企业和学术机构的大模型产品，希望未来能有更多的研究和讨论，进一步完善和深化对这一领域的理解。

---

## 云计算技术发展编年史

*范桂飓已于 2024-05-02 18:26:35 修改*

### 1605，诞生二进制与莱布尼茨之梦

**1605 年**
，英国哲学家、政治家、科学家、法学家、演说家和散文作家
**弗朗西斯・培根**
（Francis Bacon）
**基于二元组合提出了一套系统，可以把 26 个字母转化为 “二进制数”**
，在十六世纪用于传递机密信件。编写密码时，一组为五个字母。例如：aaaaa 表示字母 A，aaaab 表示字母 B。以此类推，5 位序列可以表示 32 个可能值，通过改变字母的写法来达到加密的效果。

培根曾道，这个实现思路可用于任何事物：“只要这些事物的差异是简单对立的，比如铃铛和喇叭响或不响，灯光和手电筒亮或不亮”。这是二进制数系统相对原始的提出及应用，证实了
**通过二元组合法是可以使用具有简易双重特征的事物来描述逻辑的**
。例如：使用数字 0、1 来表述逻辑是、非。这就是布尔代数的原型。

![img](https://i-blog.csdnimg.cn/blog_migrate/c02365078e0ee202db36455c476e3ac3.png)

**现代二进制记数系统**
由德国哲学家、数学家戈特弗里德・莱布尼茨（德语：Gottfried Wilhelm Leibniz）于 1679 年设计，并写于《二进制算术》一文。
**1701 年**
，莱布尼茨向巴黎皇家学会提交了一篇正式论文《数字科学新论》但却遭到时任科学院院长封单内（De Fontenelle）的拒绝，理由是看不出二进制的用处。

随后，莱布尼茨在研究并补充了中国伏羲先天圆图（先天六十四卦方圆图）来佐证二进制的用途之后，于
**1703 年**
5 月 5 日在法国《皇家科学院院刊》发表了标题为《二进位算术的阐述》，副标题为《论只使用符号 0 和 1 的二进制算术，兼论其用途及它赋予伏羲所使用的古老图形的意义》的论文，该论文完整的介绍了二进制数的表示、计算与换算。

莱布尼茨使用数字 0 表示空位，数字 1 表示实位。这样一来，所有的自然数都可以使用 0 和 1 这两个数字来表示。例如：0001 的数值为 2 的 0 次方，0010 的数值为 2 的 1 次方，0100 的数值为 2 的 2 次方，1000 的数值为 2 的 3 次方。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/24ac0db1fca71c73ee551ae901a0128d.png)

由于这篇文章的关系，早期曾有人认为现代计算机的二进制系统来自八卦图，但实际上这只是一个美丽的误解，梁启超先生对此还曾有过证明。其实与二进制数相关的系统早在古埃及、古印度和古中国都有出现。莱布尼茨又是比较早接触中国文化的西方学者，他对中国文化一直抱有浓厚的兴趣。所以当他在机缘巧合之下从一位法国传教士白晋（字明远，原名若阿基姆・布韦，法语：Joachim Bouvet）手上中得到了得到了邵雍先生（字尧夫，自号安乐先生，人又称百源先生，谥康节，后世称邵康节，北宋五子之一，易学家、思想家、诗人）的先天圆图之后，便晓有兴致的进行了研究并发现了可以通过二进制来对齐其进行解读，以至于在发表文章中说明先天圆图中已经包含了他所发明的东西。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/14e333097c1a4b1a44cc2f01be89c6dc.png)

《易经》中的伏羲先天八卦图由符号系统和概念系统组成，符号系统叫挂（八卦和六十四卦），概念系统就是与挂爻符号相匹配的缀辞（彖辞或象辞），用于占筮。其中，符号系统就是我们所熟悉的：太极生两仪，两仪生四象，四象生八卦，八卦相重生六十四卦。两仪就是阳爻（连线）和阴爻（断线）。四象就是两个符号组成一个组合的全排列。以此类推，三个符号一组的全排列就是八卦。六个符号一组的全排列就是六十四卦。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/bd98059e01cac8d0b46d7e437801d83a.png)

莱布尼茨曾在《1 与 0，一切数字的神奇渊源。这是造物的秘密美妙的典范，因为，一切无非都来自上帝》这篇手稿中断言：“二进制乃是具有世界普遍性的、最完美的逻辑语言”。只是二进制在莱布尼茨的时代并没有得到推广，直到计算机被发明后，二进制才真正实现了其应用。数字电子电路中，逻辑门的实现直接应用了二进制，因此现代的计算机和依赖计算机的设备里都用到二进制。每个数字（0 或 1）称为一个比或比特（Bit，Binary digit 的缩写）。

在数学领域，莱布尼茨更为著名的是与牛顿各自独立地创建了微积分。我们至今仍在沿用的微分符号 “dx”、“dy” 与积分符号 “∫x” 正是由莱布尼茨发明的，他认为通过选择良好的符号，可以大大的简化运算的复杂性，人们不用过多思考就可以很容易地进行复杂的演算，甚至将这样的运算变成一种天然的过程。

莱布尼茨是一位世间少有的天才及通才，除了数学领域，还在物理学、自然学、政治学、哲学、神学、伦理学、历史学、语言学等领域中都留有著作。他梦想所有的知识都可以通过数学语言表达出来，而演算规则将会揭示这些命题之间所有的逻辑关系。为了发展这一种逻辑演算，莱布尼茨进行了很多尝试，他得到的一些结果已经具有后来布尔的逻辑代数的雏形。也许就是这么一位天才，才得以提出这样一个伟大的构想：莱布尼茨希望可以将人类的思维像代数运算那样
**符号化，规则化**
，从而让笨的人通过掌握这样的规则变得聪明，更进一步的制造出可以进行思维运算的机器，将人类从思考中解放。很难说这一构想不是对未来计算机以及人工智能的预言，这一伟大构想被后世称之为莱布尼茨之梦！

### 1725，诞生穿孔纸带

**1725 年**
，法国人
**巴西尔・布尚**
（Basile Bouchon）发明了
**穿孔纸带**
，它是历史上最早的的数据存储介质之一。穿孔纸带是一种很薄的纸片，面积为 190×84 毫米，最初用于储存纺织机工作过程控制的信息。

它的工作原理如下图，纺织机在编织过程中，编织针会往复滑动，同时编织针会根据穿孔纸带上的小孔是否存在来判断是否应该进行勾线，继而编织出不同的图案。

这种根据 “存储” 在穿孔纸带上的 “图案程序” 来进行编织作业的方式，被认为是半自动化机械领域中的第一个工业应用。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/9d52f612bd9a8a7a73781b7fe5b503d3.png)

**1801 年**
，法国人
**约瑟夫・玛丽・雅卡尔**
（Joseph Marie Jacquard）在巴西尔・布尚发明的基础上对早期纺织机进行了改良，基于类似的原理，实现了更加高效的自动化编织复杂的图案，大大提高了编织效率和质量。这种成熟的机器后来被称为
**Jacquard 编织机**
，是工业革命早期自动化机械的重要里程碑之一。

18 世纪末期到 19 世纪后期，穿孔纸带被广泛用于 “程序化” 的织机和其他工业机器。现在回头看，Jacquard 编织机的发明影响深远，不仅推动了纺织业的发展，还为
**计算机诞生提供了启示**
，这种根据需要进行制作穿孔纸带的工作也被视为
**现代 “编程” 的起源**
。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/c1f1c7634040f4220c108c4d047f0afd.png)

### 1846，诞生穿孔指令带

**1846 年**
，苏格兰人
**亚历山大・贝恩**
（Alexander Bain）发明了
**电报打字机**
（Electric printing telegraph），它能够将电信号转化为可打印的文字，这被认为是第一台现代打印机的雏形。

亚历山大・贝恩在电报打字机中沿用了穿孔纸带的思路，改进为了体积更小的
**穿孔指令带**
。穿孔指令带上的
**每一行代表一个字符，利用 01 二进制编码，以规定格式排列就可以代表规定的信息**
。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/4241746d2bd6dc7665ace86813da690d.png)

### 1890，诞生穿孔卡制表机

1890 年，美国统计学家赫尔曼・何勒里斯（Herman Hollerith）发明了穿孔卡制表机。通过该机器可以制作同时
**最多存储 960bits 数据量的穿孔卡**
。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/5636ec6c8112d34180621946558ec1fc.png)

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/9b0a9458707f0770a791de4e4030d98c.png)

结合穿孔卡读取设备，它能将穿孔卡以 01 二进制方式进行读取并完成数据统计。这项技术最早应用于美国人口普查局的人口普查工作中，后来被广泛应用在工业检索以及数据统计领域，也
**标志着半自动化数据处理系统时代的开始**
。

![・](https://i-blog.csdnimg.cn/blog_migrate/11220e6f663b358fe3e34fdc6ed830fb.png)

**1896 年**
，赫尔曼・何勒里斯成立了制表机公司，这也是后来 IBM 公司的前身。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/9bb707cd805b26a763b80f128246f84b.png)

### 1936，诞生图灵完备性和图灵机

20 世纪初的数学界最炙手可热的讨论话题莫过于
**哥德尔的不完全定理**
（Gödel’s incompleteness theorem）。

在该定理提出之前，数学家们总是认为一个数学问题的求解也许困难重重，但理论上总会有一个确定的答案。一个数学命题，要么是真的，要么是假的。但哥德尔的不完全定理表明，在任何一种包括基本算术的公理化形式系统中，必然存在一些无法被证明（True）或证伪（False）的命题。

对此，数学家们的信仰被震撼，这意味着，即使是最基础的数学理论也无法完全证明其内部所有命题的真假。于是数学家们开始寄希望于与数学紧密相依的逻辑学，试图为陷入了危机的数学找到一条出路。

这些逻辑学家包括当时在剑桥的贝特朗・罗素、阿尔弗雷德・怀特海等，而当时正在剑桥求学的阿兰・图灵（Alan Mathison Turing）也同样被纠缠到这个数学困境中。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/a648feafe15f1ee44f4bea02a1359dca.png)

直到
**1936 年**
，图灵向伦敦的数学杂志投了一篇题为《On Computable Numbers, with an Application to the Entscheidungsproblem》（论可计算数及其在判定性问题上的应用）的论文。该论文中提到了一种数学模型，该模型讨论的是一种有穷的、构造性的问题的求解思路。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/0016ddbe8ffeed715bf92436875109a6.png)

图灵以数学领域的
**布尔代数**
（Boolean，Ture or False）为基础，将逻辑领域中的任意命题（可转化为数学符号）都用一种通用的机器来表示和演算，并且能按照一定的规则推导出结论，即：将论据（输入）基于某种规则（指令集）来进行论证（计算）之后就肯定能得到结论（输出）。这就是
**可计算性理论**
，是一种严格的逻辑和数学框架，限定了什么样的问题是求解的，什么样的问题是无法求解的。也就是所谓
**图灵完备**
的。

而图灵机（Turing Machine）就是一种实现了图灵完备的演算机器，能制作图灵机的数学问题，它必然有解。图灵在论文中给出了图灵机的设计思想，利用机器来模拟人使用纸笔进行数学运算的过程，通过一个机械操作的读写头去模拟笔和眼睛，可以在纸带上写上或者擦除某个符号，也可以像眼一样移动到纸的另一个位置。为了模拟人的这种行为，一个典型的图灵机应该具有以下组成部分：

1.
**一条无限长的穿孔指令带（输入 / 输出存储）**
：指令带被划分为一个个小格子，每个格子用于表示一个有限字母表上的符号。

2.
**一个穿孔指令带读写头（读 / 写）**
：读写头可以在指令带上左右移动，它能读出当前格子上的符号，并能改变当前格子上的符号。

3.
**一套控制规则（指令集）**
：它根据当前机器所处的状态以及当前读写头所指的格子上的符号来确定读写头下一步的动作，并改变状态寄存器的值，令机器进入一个新的状态。

4.
**一个状态寄存器（Register）**
：它用来保存图灵机当前所处的状态，并具有一个有限的状态机。

尽管图灵机当时还只是一纸空文，但其思想奠定了整个现代计算机发展的理论基础。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/4688ff966fda0ea77b89ec74d56c6ace.png)

### 1942，诞生世界上第一台专用计算机

在
**1937-1942 年**
间，美国工程师
**约翰・阿塔纳索夫**
（John Atanasoff）和
**克利福特・贝瑞**
（Clifford Berry）基于图灵机的理论基础设计并研制了实际上第一台专用计算机 Atanasoff-Berry Computer（阿塔纳索夫 - 贝瑞计算机），简称
**ABC 计算机**
。

之所以称之为 “专用”，是因为
**ABC 不可以进行编程，仅能用于求解线性方程组**
。但 ABC 的诞生仍开创了多项现代计算机的基础要素，包括二进制算术方式和电子开关器件。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/e41ba82fb24e83c6723877a81b11fe53.png)

### 1945，诞生冯・诺依曼体系结构

1945 年，冯・诺依曼（John von Neumann）在论文《
[First Draft of Report o the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC)
》（第一份草案）中提出了冯・诺依曼体系结构，又称：存储程序计算机。即：程序本身是存储在主机内存中的，可以通过加载不同的程序来解决不同的问题。

**冯・诺依曼体系结构奠定了现代计算机的体系结构**
，它包含
*5 大计算机组成部分*
，我们现在也习惯称之为
**主机和外设**
。

**主机**
：

* **CPU**
  （Central Processing Unit，中央处理器）
* **处理单元（Processing Unit，PU）**
  ：又称数据通路（Data Path）或运算器，包含了算术逻辑单元（Arithmetic Logic Unit，ALU）和处理器寄存器（Processor Register）。用于完成各种算术和逻辑运算。
* **控制器单元（Control Unit，CU）**
  ：包含了指令寄存器（Instruction Register）和程序计数器（Program Counter）。用于控制程序的流程（程序流），通常是条件判断和跳转。
* **内存**
  ：包括用于存储数据（Data）和指令（Instruction）的主存储器和容量更大但速度却慢的外部存储器。

**外设**
：

* **输入 / 输出设备**
  ：键盘、鼠标属于输入设备，显示器是输出设备，网卡即是输入设备又是输出设备。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/8ad660cf6cfe778b35cf9affa5bf9ea5.png)

回头看，现代计算机的诞生经历了
*3 个重大的历史节点*
：

1.
**阿兰・图灵**
（Alan Mathison Turing）
**揭示了计算机能不能做出来**
：从理论上证明了计算机的可行性。

2.
**阿塔那索夫**
（John Vincent Atanasoff）
**把计算机做出来**
：把世界上第一台计算机做了出来。

3.
**冯・诺依曼**
（John von Neumann）
**指示了计算机应该怎么做**
：存储程序计算机，奠定了现代计算机的体系结构。

### 1946，诞生了世界上第一台通用计算机

1946 年 2 月 14 日，世界上第一台通用计算机
**ENIAC**
（Electronic Numerical Integrator And Computer，电子数值积分计算机）于美国宾夕法尼亚大学诞生，发明人是美国人
**莫克利**
（John W.Mauchly）和艾克特（J.PresperEckert）。

ENIAC 是第一代电子管计算机，是图灵完备的，并且能够重新编程以解决各种计算问题。同时，ENIAC 也是一个不折不扣的庞然大物，用了 18000 个电子管，占地 150 平方米，重达 30 吨，耗电功率约 150 千瓦，每秒钟可进行 5000 次运算。由于使用的电子管体积很大，耗电量大，易发热。因而，ENIAC 的工作时间不能太长，最初只用于帮助美国陆军的弹道研究实验室（BRL）计算火炮的火力表。

* ENIAC 程序员在工作，实际上，女性才是最早的程序员主力军。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/1e78c966b517cdc1248d98db31ffdba2.png)

### 1955，第一次提出了分时多用户共享的概念

#### 串行系统

最初的计算机系统都是串行运作的，一次只能录入执行一个程序，当程序进行缓慢的 I/O 操作时，CPU 只好空转等待。这不仅造成了 CPU 的浪费，也造成了其他计算机硬件资源的浪费。

#### 批处理处理系统

那时的计算机科学家们都在思考如何能够提高 CPU 的利用率，直到提出了
**多道程序设计**
（Multi-Programming），这也是批处理 / 多任务处理系统的前身。多道程序设计的运行原理就是一次性把一批任务都提交给计算机，然后等待执行结果。并且中途不能和计算机进行交互。

在整个
**20 世纪 50-60 年代**
，多道程序设计的讨论非常流行。它使得 CPU 能够一次性读取多个程序到内存，先运行第一个程序直到它出现了 I/O 操作，此时 CPU 切换到运行第二个程序，即：第 n+1 个程序得以执行的条件是第 n 个程序进行 I/O 操作或已经运行完毕。

可见，
*多道程序设计的特征就是：多道程序、宏观上并行、微观上串行*
。有效的提高了 CPU 的利用率，也充分发挥着其他计算机系统部件的并行性。

但多道程序设计存在一个问题， 就是它并不会考虑分配给各个程序的时间是否均等，很可能第一个程序运行了几个小时都不会出现 I/O 操作，故第二个程序没有运行。

最初，这个问题是让人接受的，因为那时的科学家们更在意最终的输出结果，而不是谁先谁后的问题。直到有人提出了新的需求 —— 多用户同时使用计算机。

#### 分时系统（多用户共享交互式操作系统）

1955 年，美国麻省理工学院（MIT）的
**约翰・麦卡锡**
（John McCarthy，AI 概念提出者，1971 年获图灵奖）教授提出了 Time-Sharing（分时）系统的概念，希望以此来解决多人同时使用一台计算机的诉求。

所谓 “分时” 的含义是将 CPU 占用切分为多个极短（1/100sec）的时间片，每个时间片之间轮询地执行着不同的程序。在一个分时系统中，能够允许几个、几十个甚至几百个用户通过终端机连接到同一台大型主机，将 CPU 时间分片与内存空间按一定的时间周期，轮流地切换给各终端用户的程序使用。由于时间间隔很短，所以让每个用户感觉像是独占了计算机一样。

分时系统实现了让多个程序共享计算机硬件和软件资源的效果，本质是一个多用户交互式操作系统。

### 1959，第一次提出了虚拟化技术的概念

**1959 年**
6 月 15 日，牛津大学的计算机教授，
**克里斯托弗・斯特雷奇**
（Christopher Strachey）在国际信息处理大会（International Conference on Information Processing）上发表了一篇名为《
**大型高速计算机中的分时系统**
》（“Time sharing in large fast computers”）的学术报告，他在
**文中首次提出了 “虚拟化” 的基本概念，还论述了什么是虚拟化技术**
。这篇文章被认为是最早的虚拟化技术论述，
**从此拉开了虚拟化发展的帷幕**
。

* Christopher Strachey，这篇文章记录了斯特雷奇的生平
    
  <https://history.computer.org/pioneers/strachey.html>

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/99ab3a291d866003912df514b390517e.png)

* 《Time sharing in large fast computers》影印
    
  <https://archive.org/details/large-fast-computers>

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/a5be62e14ba167117113fe1f63223335.png)

斯特雷奇在论文的开头这么写到：

> *Time sharing, in the sense of causing the main computer to interrupt its program to perform the arithmetic and control operations required by external or peripheral equipment, has been used on a limited scale for a long time. this paper explores the possibility of applying time sharing to a large fast computer on a very extensive scale.*
>   
>   
> “分时（Time sharing）是指使计算机中断正在运行的程序以执行外围设备所需要的算术与控制操作，长期以来一直在有限的范围内使用。本文探讨了将分时（Time sharing）的概念应用到大型高速计算机中的可能性。”

本质上，斯特雷奇是在讨论如何将分时系统的实现方式融入到多道程序设计的方式当中，从而实现一个可多用户操作（CPU 时间切片），又具有多程序设计效益（CPU 中断让出）的虚拟化系统。可见，虚拟化概念最初的提出就是为了满足多用户同时操作大型计算机，并充分利用大型计算机各部件资源的现实需求。而对这一需求的实现与演进，贯穿了整个大型机与小型机虚拟化技术的发展历程。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/7111da97f58f7addf53631e4c425c117.png)

### 1962，诞生了第一台超级计算机和专用操作系统 — Atlas

1960 年，英国启动 Atlas 超级计算机（Super Computer）项目。

超级计算机（Super Computer），又称巨型机，有着极强的计算速度，通常用于科学与工程上的计算，譬如天气预测、气候研究、运算化学、分子模型、天体物理模拟、汽车设计模拟、密码分析等。超级计算机的创新设计在于把复杂的工作细分为可以同时处理的工作并分配到不同的 CPU 上。它们在进行特定的运算方面表现突出，但在通用运算方面却表现一般。

超级计算机的计算速度与内存性能有关，所以程序的数据结构需要经过精心的设计来确保内存数据的读写效率，传输速率的细微差别可以导致运算能力的巨大差别。

**1962 年**
12 月 7 日，第一台 Atlas 超级计算机
**Atlas 1**
诞生，Atlas 是第二代晶体管计算机，被认为是当时世界上最强大的计算机。Atlas 开创了许多沿用至今的软件概念，包括第一次实现了名为 Atlas Supervisor 的底层资源管理组件，Supervisor 通过特殊的指令或代码来管理主机的硬件资源。还第一次实现了
**内存分页技术**
（Paging Techniques）以及当时被称为一级存储（One-Level Store）的虚拟内存（Virtual Memory）技术。

Supervisor 就是我们现在称之为
**Operating System（操作系统）的前身**
，还被叫过一段时间的 Master Control Program（主控程序），但最终更贴切的 Operating System 胜出了。另外，Hypervisor（虚拟机管理程序）的命名也来源于 Supervisor。在西文中，Super 和 Hyper 是同意词，意为超级，但词义上 Hyper 比 Super 还要高级一些。

* Atlas 1 超级计算机。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/e99d04da530d4f7730fe2da1e815c5a1.png)

### 1964，诞生了第一个分时共享操作系统 — Multics

1961 年 11 月，由麻省理工学院的
**费尔南多・科尔巴托**
（Fernando Corbato，1990 年获得图灵奖）教授带领团队开始研发
**CTSS**
（Compatible Time-Sharing System，兼容性分时系统）项目，并由 IBM 提供主机设备和工程师进行支持。CTSS 开创性的实习了多用户硬件隔离和多用户独立的文件系统技术，极大地影响了后来的分时系统的设计，包括 IBM 著名的 TSS（Time Sharing System）技术。

同年，在麻省理工学院百周年纪念典礼上，
**约翰・麦卡锡**
（John McCarthy）第一次提出了
**Utility Computing**
（公共计算）的概念。约翰・麦卡锡认为：“如果我设想的那种计算机（即：分时系统，同时支持多人同时使用的计算机）能够成真，那么计算或许某天会像电话一样被组织成公共服务（Utility Computing，公共计算服务），就像生活中的水、电、煤气一样，被每一个人寻常地使用。那将是一种全新的重要工业的基础。”

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/b3e0e0c9468d22c476e41d8332de21f5.png)

**1964 年**
，麦卡锡在大西洋月刊发表了一篇题为《The Computers of Tomorrow（明日计算机）》的文章，详细分析了 Utility Computing Service（公共计算服务）与公共电网之间的异同点。文章指出，计算想要成为像电网那样的公共服务，需要关注三个问题：

1.
**接口**
：用户如何和资源进行对接？

2.
**服务设备**
：用户通过什么设备将资源转换成服务？

3.
**产品同质性**
：电总归是电，而计算是一种复杂的服务，存在多样性，存在不同的编程语言和硬件，如何兼容、交互？

这似乎是云计算最初的远景，只是那时还没有网络将人们连接起来。

在《The Computers of Tomorrow》的影响下，麻省理工学院（MIT）和 DARPA（美国国防高级研究计划局）下属的 IPTO（信息处理技术办公室）共同启动了著名的
**MAC**
（Multiple Access Computing，
**多址计算**
）项目。

DARPA 还专门提供了约 200 万美元的项目津贴。其目的是在 CTSS 所取得的经验之上，开发出一种具有多用户交互能力的、且具有多道程序处理能力的分时共享操作系统（多人可同时使用的电脑系统）—
**Multics**
系统，以取代当时广泛使用的批处理操作系统。

Multics（Multiplexed information and Computing Service，多路信息计算系统）意为多用户、多任务、多层次（Multi-User、Multi-Processor、Multi-Level），目标是连接 1000 部终端机，同时支持 300 个用户在线。Multics 项目是
**Unix 操作系统的前身**
。

MAC 项目组最终由贝尔实验室（Bell Labs），麻省理工学院（MIT）以及通用电气公司（General Electric）组成。其中，由于 GE（通用电气公司）被选为硬件供应商，IBM 被踢出局。

### 1965，IBM 开启了大型计算机的虚拟化之路

**1964 年**
，从 MAC 项目中出局的 IBM，在 Thomas J. Watson Research Center（纽约沃森研究中心）进行 M44/44X 计算机项目的研究。M44/44X 项目基于 IBM 7044 大型机（M44），并通过软件和硬件结合的方式来模拟出多个 7044 虚拟机（44X）。

他们为操作系统的每一部分建立一个 7044 镜像。每个镜像叫做 7044（M44）/44X。允许用户在同一台主机上运行多个操作系统，让用户尽可能的充分利用昂贵的大型机资源。M44/44X 实现了多个具有突破性的虚拟化概念，包括部分 / 半硬件共享（Partial Hardware Sharing）、分时（Time Sharing）、内存分页（Memory Paging）以及虚拟内存（Virtual Memory）。
**M44/44X 项目首次使用了 “Virtual Machine” 这一术语，所以被认为是世界上第一个支持虚拟机的计算机系统**
。

现在看来，虽然 M44/44X 只实现了部分的虚拟化功能，但其最大的成功在于证明了虚拟机的运行效率并不一定比传统的方式更低。使得 IBM 的工程师们更好地理解了多道程序设计（Multi-Programming）的理念。M44/44X 是 IBM 虚拟机概念的开端。他们认为，虚拟机就是真实机器的副本，只是内存减少了。

**1965 年 8 月**
，IBM 推出了著名的
**System/360**
（简称 S/360）大型计算机系统。System/360 取自一圈 360 度，意为满足每个用户的需要而设计。你或许有所耳闻，System/360 的开发过程被称为计算机发展史上最大的一次豪赌。为了研发 System/360，IBM 征召了六万多名新员工，创建了五座新工厂，投资 50 亿美元。即便如此，System/360 的出货时间仍被不断推延。
**理佛瑞德・布鲁克斯**
（Frederick P. Brooks, Jr.）是当时的项目经理，他事后根据这项计划的开发经验写出了同样著名的《
**人月神话：软件项目管理之道**
》（“The Mythical Man-Month: Essays on Software Engineering”），记述了人类工程史上一项里程碑式的大型复杂软件系统的开发经验，至今被称为软件项目管理的圣经。System/360 是第三代中小规模集成电路计算机，同时也是世界上第一台大型机。

注：大型计算机使用了专用的处理器指令集、操作系统和应用软件，是硬件和专属软件一体化的计算机系统。大型机与超级计算机不同，大型机追求的 RAS（Reliability, Availability, Serviceability）高可靠性、可用性和可维护性。大型机的性能并不能用单一的每秒并行浮点计算能力来体现，大型机的运算任务主要受数据传输与转移、可靠性及并发处理性能所限制。大型机更倾向整数运算，如订单数据、银行业务数据等，超级计算机则是更强调浮点计算性能如天气预报，大型机在处理数据的同时需要读写或传输大量信息，如海量的交易信息、航班信息等等。

* System/360 大型计算机。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/e9bd4406c4a10b70b3f163493b8534f3.png)

* 《人月神话：软件项目管理之道》。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/1d5c23df621ae239dd077c6b2cf1be38.png)

**1967 年**
，科学家 L.W. Comeau 和 R.J. Creasy 为 System/360 大型机量身研发了
**CP-40/CMS 分时共享操作系统**
。

CP-40/CMS 被认为是
**第一个实现了基于硬件的完全虚拟化操作系统**
（Full Hardware Virtualization）。支持 TSS（Time Sharing System，最原始的 CPU 虚拟化技术）、虚拟内存、多任务处理，还支持通过捕获特权指令（例如 I/O 操作）和内存缺页（Page Faults）等异常，然后交由控制程序（Control Program）进行模拟的方式来实现虚拟机（最多可提供 14 个虚拟机）。用户可以在虚拟机之上安装其他的操作系统，多个操作系统之间互相隔离，就像运行在一台独立的主机之上。

CP-40/CMS 最大的成就在于提出并实现了
**Trap-And-Emulate**
（捕获 - 模拟）这一经典的虚拟机运行方式，早期的 VMware 虚拟机也沿用着这一设计。其基本架构和用户界面也被延续到了 IBM 具有革命性意义的 CP/CMS 操作系统系列中。CP/CMS 系列为 System/360 大型机的成功打下了坚实的基础，逐渐发展成为了 IBM 的 PowerVM（运行于 Power 服务器）和 z/VM（运行于 IBM Z 和 IBM LinuxONE 服务器）的大型机虚拟化产品线。

现在我们知道，IBM System/360 取得了巨大的商业成功。System/360 不仅提供了新型的 CP-40/CMS 分时共享操作系统，还解决了当时 IBM 低端系统与高端系统无法兼容的问题。使得单一操作系统可以适用于整个大型机系列的产品，这就是 System/360 系列大型机获得成功的关键之一。

综上可见，虚拟化技术的应用和发展源于大型机对分时系统的需求。这种通过硬件的方式来生成多个可以运行独立操作系统软件的虚拟机实例，解决了早期大型计算机只能单任务处理而不能分时多任务处理的问题。

### 1965，诞生了第一台小型计算机

**1960 年**
，DEC（Digital Equipment Corporation，数字设备公司，是计算机历史上最有影响力的公司之一）推出试验性的
**PDP-1**
（Programmed Data Processor，程序数据处理机）小型计算机。直到 1965 年 3 月 28 日，DEC 才正式推出了世界上第一台真正意义上的小型机（Mini Computer）
**PDP-8**
。

关于 Mini Computer 名字的由来有这样的一个小故事，时任 DEC 海外销售主管的约翰・格伦将 PDP-8 运到英国，发现伦敦街头正在流行 “迷你裙”（Mini），姑娘们争相穿上短过膝盖的裙子，活泼轻盈，显得那么妩媚动人。他突然发现 PDP 与迷你裙之间的联系，所以创造了
**Mini Computer**
这个有趣的名字。

PDP-8 小型机简化了大型机的功能，但相对也价格低廉，在当时它的售价只有 18500 美元，比当时任何公司的电脑产品都低，很快便成为 DEC 的主力产品，并引发了当时计算机市场的小型化革命。而
**PDP-8 则被认为是 PC（个人电脑）的先驱者**
。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/8a91c767cf2da5113fcf1ecd9702ddd0.png)

### 1973-1977，诞生 C 语言和可移植的 UNIX 分时共享操作系统

**1950 年代末期**
，随着操作系统的发展，大量的计算机编程语言也随之涌现。最初，这些编程语言都是围绕着单个操作系统展开的，只能为 UNIVAC、IBM700 等主机编写应用程序。这样的状况使得不同操作系统之间的程序移植几乎不可能完成。对此，一些美国计算机科学家们开始提倡研究和开发出一种与硬件无关的科学用程序设计语言。

1958 年 5 月 27 日至 6 月 1 日，GAMM（Gesellschaft für Angewandte Mathematik und Mechanik，德国的应用数学和力学学会）和 ACM（Association for Computing Machinery，国际计算机学会）联合为新的设备无关编程语言定下研究目标，并命名为
**IAL**
（International Algebraic Language，国际代数语言），后改名为
**ALGOL**
（ALGOrithmic Language，算法语言）。

不久后，
**艾伦·佩利**
（Alan J.Perlis，图灵奖获得者）在巴黎举行的软件专家讨论会上发表了《算法语言
**ALGOL 60**
报告》，
**标志着程序设计语言成为了一门独立的科学学科**
。ALGOL 60 是计算机发展史上
**第一个清晰定义的高级编程语言**
，2002 年，图灵奖得主 Edsger Dijstra 将 ALGOL 60 的诞生称为 “一个绝对的奇迹”，
**标志着 “计算机科学” 的诞生**
。

**1963 年**
，英国剑桥大学在 ALGOL 60 的基础上推出了
**CPL**
（Combined Programming Language）编程语言，相较于 ALGOL 60，CPL 更加接近硬件，但也更加复杂，难以开发大规模程序。

**1967 年**
，编程语言和编译器科学家马丁・理查兹（Martin Richards）在访问麻省理工学院的时候在 CPL 的基础上做了简化后推出了
**BCPL**
（Base Combined Programming Language，基础组合程序设计语言）编程语言。BCPL 是一门 “无类型” 的编程语言，它仅能操作机器字（Machine word）这一种数据类型。

回到操作系统发展的主线，
**1969 年**
，Multics 项目的交付已经延期了两年（Multics 始于 1964 年，最初的交付期限是 1967 年），远远超出了预算。由于受不了 Multics 项目的缓慢进展，Bell（贝尔实验室）决定退出 Multics 计划。

作为项目成员之一，来自 Bell 的 Ken Thompson（肯・汤普逊）负责以 BCPL 语言为基础，又作了进一步的简化，设计出了很简单且很接近硬件的
**B 语言**
。其名字取的是 BCPL 的第一个字母。Thompson 还用 B 语言编写了一个叫做 Space Travel（太空大战）的游戏，这个游戏需要运行在 Multics 上。但是当 Bell 退出了 Multics 后，也就意味着 Thompson 失去了玩 Space Travel 的主机。

由于 Thompson 对这个自己开发出来的游戏非常喜爱，所以他找来了一台空闲的
**DEC PDP-7**
小型机，但是这台主机并没有操作系统，于是 Thompson 着手为 DEC PDP-7 开发一个。在独自经过 4 个星期的奋斗后，Thompson 以汇编语言写出了一组内核程序，包括：一个汇编器、一个简单的 Shell（命令解析器）、以及一个小的文件系统，用于运行 Space Travel。

当完成之后，Thompson 怀着激动的心情把身边同事 Dennis M.Ritchie（丹尼斯・里奇）叫过来一起游戏。很可惜，Ritchie 表示对他的游戏不感兴趣，但是对他编写的操作系统很感兴趣，并加入一起开发。

也许是对 Multics 项目的怨念，最初 Thompson 将自己的这个操作系统取名为
**Uni-plexed Information and Computing Service**
（没路信息计算系统），与 Multiplexed information and Computing Service（多路信息计算系统）相反，简称为 UNICS，后来取其谐音，就称其为 UNIX 了。

那时候的 UNIX 是使用汇编语言写的，Thompson 和 Ritchie 在做内核移植开发时，感觉使用汇编语言很难实现。所以开始切换到 B 语言来。后来在 PDP-11 发布后，由于 PDP-11 提供了多种不同规格大小的基本对象，例如：一字节长的字符、两字节长的整型数、四字节长的浮点数等等。又由于 B 语言是一种无类型的编程语言，无法处理这些不同规格大小的对象，也没有提供单独的操作符去操作它们。所以为了将 UNIX 移植到 PDP-11，Ritchie 开始着手改进 Thompson 的 B 语言。

**1972 年**
，Ritchie 以 B 语言为基础开发了
**C 语言**
（取 B 的下一个字母），并为其创造了一系列数据类型。C 语言最初尝试通过向 B 语言中增加数据类型的想法来处理那些不同类型的数据。和大多数语言一样，在 C 中，每个对象都有一个类型以及一个数值。类型决定了可用于数值的操作的函数，以及数值占用的内存空间大小。

1973 年初，C 语言的主体完成了，它既保持了 B 语言的优点（精炼、接近硬件），又克服了 B 语言的缺点（过于简单，数据无类型）。于是 Thompson 和 Ritchie 开始着手使用 C 语言在 PDP-11 上重写 UNIX。这是 C 语言第一次被应用在操作系统的内核开发上。可见，从一开始，C 语言就是为系统级编程而设计，程序的运行效率至关重要。

* PDP-11 前面的 Ken Thompson（坐着）和 Dennis M.Ritchie（站着）。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/af2ffc42076fa6af37c203244684b4f2.png)

**1974 年**
，Thompson 和 Ritchie 发表了第一篇关于 UNIX 的论文《The UNIX Time Sharing System》（UNIX 分时共享操作系统），从此 UNIX 广为人知。

**1977 年**
，Dennis M.Ritchie 跨时代的论文《可移植的 C 语言编译程序》，标志 UNIX 成为了世界上第一个可移植的操作系统。
**与主机硬件设备完全解耦的 C 语言和 UNIX 使得程序员这门职业得以诞生**
，计算机技术不再是科学家们的专属，程序员们走向了台前。

**1978 年**
，Thompson 和 Ritchie 合作出版了《
**C 程序设计语言**
》的第一版，也被 C 程序员称作 “K&R C”。这是是第一本系统性介绍 C 语言编程方法的书籍，在 C 语言的发展和普及过程中起到了非常重要的作用，也被视为是 C 语言的业界标准规范，誉为 “C 语言圣经”，至今仍然广泛使用。

Thompson 和 Ritchie 因在计算机领域做出的杰出贡献，于 1983 年获得了图灵奖。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/5182f3438f28a11eee2ed9e1f48202c1.png)

就这样 UNIX 和 C 语言完美地结合成为了生命共同体，随着 UNIX 的发展，C 语言也得到了不断的完善。因为 C 是编写 UNIX 的语言，因此后来也成了最受欢迎的系统程序语言之一。

UNIX 和 C 语言的结合是一个伟大的时刻，在此之前，使用汇编语言来编写能够发挥计算机最高效能的操作系统是业界共识。而 C 语言为 UNIX 所带来的可移植性在那时可以说是极具创新意义。从此以后，当一款新的主机出现时，程序员再也不用需要重复发明轮子了。

### 1974，第一次提出了 VMM 的概念

**1974 年**
，
**杰拉尔德・J・波佩克**
（Gerald J. Popek）和
**罗伯特・P・戈德堡**
（Robert P. Goldberg）在合作论文《可虚拟第三代架构的规范化条件》（Formal Requirements for Virtualizable Third Generation Architectures）中提出了一组称为
**虚拟化准则的充分条件**
，又称
**波佩克与戈德堡虚拟化需求**
（Popek and Goldberg virtualization requirements）。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/7116ac75f121ba122d3f26283c18c4b5.png)

论文中定义了
**虚拟化系统结构的三个基本条件**
。满足这些条件的控制程序才可以被称为虚拟机监控器（Virtual Machine Monitor，简称
**VMM**
）：

1.
**资源控制（Resource Control）**
：控制程序必须能够管理所有的系统资源。

2.
**等价性（Equivalence）**
：在控制程序管理下运行的程序（包括操作系统），除时序和资源可用性之外的行为应该与在没有控制程序的时候保持完全一致，且预先编写的特权指令可以自由地执行。

3.
**效率性（Efficiency）**
：绝大多数的客户机指令应该由主机硬件直接执行而无需控制程序的参与。

该论文尽管基于简化的假设，但上述条件仍为评判一个计算机体系结构是否能够有效地支持虚拟化提供了一个便利方法，也为设计可虚拟化的计算机架构给出了指导原则。
**为未来 40 多年的虚拟化技术的快速演进奠定了理论基础：定义了什么样的技术才能叫做虚拟化，什么样的条件才能满足虚拟化的定义**
。

同时，Gerald J. Popek 和 Robert P. Goldberg 还在论文中介绍了两种 Hypervisor 类型。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/fcfed791c802b48c5c40e1ad3afc823a.png)

* **类型 I（裸金属 Hypervisor）**
  ：这些虚拟机管理程序直接运行在宿主机（Host）的硬件上来控制硬件和管理虚拟机。特点是：1）需要硬件支持；2）VMM 作为宿主机操作系统（Host OS）；3）运行效率高。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/1a623da78ea0f6d7db4ec158ffd41f0f.png)

* **类型 II（寄居式 Hypervisor）**
  ：VMM 运行在传统的宿主机操作系统（Host OS）上，就像其他应用程序那样运行。特点是：1）VMM 作为应用程序运行在宿主机操作系统之上；2）运行效率一般较类型 I 低。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/61cec49fa612667593bf3e38d41a60b2.png)

现在回看，由于当时技术的原因，早期的 VMM 产品大多实现的是寄居式，例如：VMware 5.5 以前的版本、Xen 3.0 以前的版本。随着硬件虚拟化技术的诞生，几乎所有的 VMM 产品都转向了裸金属 Hypervisor 实现。例如：VMware 5.5 及以后版本、Xen 3.0 及以后版本以及 KVM。

### 1978，诞生了第一片 x86 处理器和提出了摩尔定律

在上世纪 60 到 70 年代末，大型机和虚拟化技术互相成就了对方，并且在相当长的一段时间里，虚拟化技术也只被应用于大型机中。其实也可以理解，以当时 Micro-CPU（微处理器）的处理能力，应付一两个应用程序已然捉襟见肘，的确没有更多的资源分与虚拟化应用了。直到摩尔定律开始生效为止。

**1965 年**
，Intel（英特尔）创始人之一戈登・摩尔提出了
**摩尔定律**
（Moore’s law）：“在成本不变的前提下，半导体芯片上的晶体管密度（运算速度），约每隔两年便会增加一倍。”

从提出开始算起，半导体行业已经按照摩尔定律发展了半个多世纪，对二十世纪后半叶的世界经济增长做出了贡献，PC（个人电脑）、Internet、智能手机等技术的创新都离不开摩尔定律的延续。

* 摩尔定律：半导体行业预计摩尔定律将至少持续到 2020 年，但实际上在 2013 年就已经放缓。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/10bdce1ed3d65303b3f479679b8d3af8.png)

**1971 年**
，Intel 设计了世界上第一个微处理器芯片
**Intel 4004**
，并以它为核心组成了世界上第一台微型计算机
**MCS-4**
，从此揭开了微型计算机发展的序幕。微型计算机是第四代大规模集成电路计算机的典型代表。

**1978 年 6 月 8 日**
，Intel 发布了新款的
**16 位微处理器 8086**
，是世界上第一款 x86 架构。（注：x86 架构并非指某一个芯片的信号，而是指 Intel 通用计算机系列的标准编号缩写，也标识一套通用的计算机指令集合。）

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/81002a9cb90c65cb0e30ee22676bd48a.png)

### 1980，Wintel 个人微型计算机时代来临

自微型计算机诞生以来，消费者们对微机的热情几近疯狂，美国新闻界就曾对群众进行过问卷调查，问人们是否希望在不久的将来拥有一台家用计算机，结果超 80% 的人表达了这个愿望。往后的几年里，面对巨大的市场和商机，直接体现为全球计算机的产量逐渐从巨大、昂贵的小型计算机转变为更小型的、便宜的微型计算机。各种各样的微处理器和微型计算机如潮水般地涌入市场，尤其是以 IBM 推出的 PC（Personal Computer，个人计算机）电脑在早期几乎形成了垄断地位。

**1980 年**
，微软和英特尔组成
**Wintel 商业联盟**
，希望以此来取代 IBM PC 在个人计算机市场上的主导地位。依靠英特尔的摩尔定律和微软 Windows 桌面（Desktop）操作系统的升级换代，双方通过共同辖制下游 PC 生产商而不断攫取巨额暴利，以至于在全球个人电脑产业形成了所谓的 “双寡头垄断” 格局。直到 2016 年微软在 WinHEC 上宣布 Windows 10 可以运行在 ARM 架构之上，标志着垄断桌面端长达 20 多年的 Wintel 联盟正式破裂。但不可否认的是，正因为有了 Wintel 的强悍联合，才使个人电脑的发展日新月异。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/b3bce1ae0882f1c5917d4060a01831ec.png)

### 1984，GUN 计划启动

**1974 年 7 月**
，经过不断改良的 UNIX 发展到第 5 个版本，Bell 选择了公开 UNIX 的源码，引起了学术界的广泛兴趣。所以，UNIX 第 5 版就以 “仅用于教育目的” 的协议，提供给各大学作为教学之用，成为当时操作系统课程的范例教材。

**1978 年**
，柏克利大学 （UC Berkeley）推出了基于 UNIX 第 6 版的
**BSD**
（Berkeley Software Distribution，伯克利分发版）分支，这就是著名的 “1 BSD（1st Berkeley Software Distribution）”。

于是乎 UNIX 在当时就存在了 2 个分支，一个归 Bell 所有，一个归 BSD 所有。另外，由于当时 Bell 所属的 AT&T 受到了美国《谢尔曼反托拉斯法》的影响，不能销售除了电话机、电报机等之外的商品，甚至后来被拆解成 “AT&T 七子 “。

AT&T 被拆解后，从法律许可上可以开始对外售卖 UNIX 了，意味着 UNIX 正式走向了商业化。在那时，用户如果想继续使用 Bell UNIX 就需要购买 4 万美元一份的授权。

**1979 年**
，AT&T 推出基于第七版 UNIX 的
**System V**
，支持 x86 架构。但同时特别声明 “不再对学校提供源码”。虽然 AT&T 的 System V 也是非常优秀的 UNIX 发行版本，但由于 BSD Unix 一直坚持开源，所以后者在开发者群体中的影响力更大。

直到
**1992 年**
，AT&T UNIX 系统实验室指控 BSDI（一家发行商业 BSD UNIX 的公司），违反了 AT&T 的许可权，并进一步指控伯克利计算机系统研究组泄漏了 UNIX 的商业机密（注：实际上此时的 BSD UNIX 4.3 中来自 AT&T UNIX 的代码已经不足 10%）。这个官司影响了很多 UNIX 用户，使他们不得不从 BSD UNIX 转向 AT&T System V 以避免法律问题。以至于当今大多数商业 UNIX 发行版都是基于 System V 的。

这场官司一直打到 AT&T 将自己的 UNIX 系统实验室卖掉都还没有结束，这时已经是
**1993 年**
。新接手 UNIX 的 Novell 公司采取了一种比较开明的做法，允许 BSDI 自由发布自己的 BSD UNIX，但是前提是必须将来自于 AT&T 的代码完全删除，于是诞生了
**BSD UNIX 4.4 Lite**
版本。由于这个版本不存在法律问题，所以 BSD UNIX 4.4 Lite 成为了现代 BSD 系统的基础版本。

由于 BSD UNIX 已经十分成熟，作为对操作系统进行研究的目标已经达到，伯克利计算机系统研究组（CSRG）在发布了 BSD UNIX 4.4 Lite2 之后就解散了，小组的科研人员有些进入了 UNIX 商业公司，有些继续进行其他计算机领域的研究。此时，严格意义上的 System V 和 BSD UNIX 都不复存在了，存在的只是他们的各种后续版本。BSD UNIX 的开发也走向了几个不同的方向，并最终促使了 FreeBSD、 OpenBSD 和 NetBSD 的出现。其中的
**FreeBSD 就是 MacOS 的前身**
。

另外，后来 Novell 又将 UNIX 版权出售给了 SCO（这一事实双方尚存在争议）。有很多大公司在取得了 UNIX 的授权之后，继续开发了自己的 UNIX 产品。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/c93cf47058c1d638e90c003eb8933657.png)

综上可见，在 1970-80 年代，应用最为广泛的 UNIX 操作系统更多的是一个闭源的商业软件。让当时许多 UNIX 的爱好者和软件开发者们感到相当的痛心和忧虑，他们认为商业化的种种限制并不利于产生的发展，还可能会产品出现诸多的问题。于是，这群 “反叛者们 “ 开始有组织地结成联盟，以此对抗欺行罢市的 UNIX 商业化行为。

**1983 年**
，麻省理工学院的程序员 Richard Stallman（理查德・斯托曼）认为 UNIX 是一个相当好的操作系统，如果大家都能够将自己所学贡献出来，那么这个系统将会更加的优异，并提出了 \*\*GNU（GNU’s Not Unix）\*\*计划。

Richard 最早只是在 net.unix-wizards 新闻组上公布该消息，并附带一份《GNU 宣言》等解释为何发起该计划的文章，其中一个理由就是要 “重现当年软件界合作互助的团结精神”。Richard 倡导 Open Source 的理念，希望发展出一套完整的、开发源代码的操作系统以取代 UNIX，志在创建一个完全兼容 UNIX 的自由软件生态环境。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/81cd273e7246c7dd8360ca841affb429.png)

为保证 GNU 软件可以自由地 “使用、复制、修改和发布”，所有 GNU 软件都在一份在禁止其他人添加任何限制的情况下授权所有权利给任何人的协议条款。

**GNU 包含了 3 个协议条款**
：

1. **GPL**
   （GNU General Public License，GNU 通用公共许可证），即 “反版权”（Copyleft）概念。
2. **LGPL**
   （GNU Lesser General Public License，GNU 较宽松公共许可证）。
3. **GFDL**
   （GNU Free Documentation License，GNU 自由文档许可证）。

**1985 年**
， Richard 又创立了
**FSF**
（Free Software Foundation，自由软件基金会）来为 GNU 计划提供技术、法律以及财政支持。

现在我们知道，一个完整的操作系统是需要包含许多软件的，除了最重要的 Kernel 之外，还需要有编辑器，编译器，Shell、视窗系统等等一系列软件作为支撑。Richard 早期的捐助者大都是新踏入 UNIX 土地的老牌 ARPANET（阿帕网）黑客，他们对代码共享的使命感异常强烈。

尽管 GNU 计划大部分时候是由个人自愿无偿贡献，但 FSF 有时还是会聘请程序员帮助编写。当 GNU 计划开始逐渐获得成功时，一些商业公司开始介入开发和技术支持。当中最著名的就是之后被 Red Hat 兼并的 Cygnus Solutions。

到了
**1990 年**
，GNU 已经开发出的一系列的开源软件，被称为 GNU 套件，包括：
**GCC**
（GNU Compiler Collection，GNU 编译器集合），
**GLIB**
C（libraries，函数库）、
**GDB**
（debugs，调试工具）、
**TeX**
（文本编辑器）、
**Emacs**
（一个功能强大的文字编辑器）、
**X Window**
视窗系统、
**Apache HTTP**
服务器，以及
**UNIX Shell**
等等。

你可能会发现，上面唯独缺少了一个操作系统 Kernel。

### 1991，Linux 诞生

在 UNIX 需要支付昂贵的授权费用后，很多大学不得不停止对其的研究。

**1987 年**
，荷兰有个大学教授 Andy Tanenbaum（安德鲁）写了一个
**Minix**
操作系统，类似于 UNIX，专用于教学。当 Minix 流传开来之后，世界各地的黑客们纷纷开始使用并改进，希望把改进的东西合并到 Minix 中，但是安德鲁觉得他的系统是用于教学的，不能破坏纯净性，于是拒绝了。

**1990 年**
，Linus Torvalds 还是芬兰赫尔辛基大学的一名学生，最初是用汇编语言写了一个在 Intel 80386 保护模式下处理多任务切换的程序，后来从 Minix 得到灵感，进一步产生了写一个比 Minix 更好的操作系统的想法。

于是 Linus 开始写了一些硬件的设备驱动程序，以及一个小的文件系统。就这样诞生了
**Linux 0.0.1**
（Linus’s Unix）版本。但是它只具有一个操作系统内核的雏形，甚至不能运行，还必须在有 Minix 的主机上完成编译后才能运行。但这时的 Linus 已经完全沉迷其中，决定踢开 Minix，于是在 1991 年 10 月 5 号发布 Linux 0.0.2 版本，在这个版本中已经可以运行 Bash 和 GUN GCC 了。

**1991 年**
，Linus Torvalds 编写出了与 UNIX 兼容的
**Linux Kernel**
并在 GPL 条款下发布。随即引起了黑客们的注意，通过网络加入到了 Linux Kernel 的开发。由于一批高水平黑客的加入，使 Linux 发展迅猛，几乎一两个礼拜就有新版或修正版的出现。

\*\*
**1993 年底**
，\*\*Linux 1.0 终于诞生了！

Linux 1.0 已经是一个功能完备的操作系统 Kernel，代码实现紧凑而高效，可以充分发挥硬件的性能，在 4M 内存的 Intel 80386 主机上也表现得非常好。直至今天，Linux 社区的开发者们依然认为在 Linux Kernel 里进行开发才是真正的编程。

后来开源运动的吹鼓手 Eric Raymond（埃里克・雷蒙德）写了一篇文章《大教堂与集市》来分析 Linux 的开发模式。大教堂要设计好图纸，动用优秀的工匠，有序的工程计划才能修筑，闹哄哄无序如菜市场的一拨人能不能修一座大教堂？答案是可以的，因为他们建成了。

关于 “大教堂”（集权、封闭、受控、保密）和 “集市”（分权、公开、精细的同僚复审）两种开发模式的对比成为了新思潮的中心思想。这个新思潮对 IT 业产生了非常深远影响。为整个计算机世界带来了革命性的价值观。

### 1992，Linux 与 GUN 伟大结合

由于 Linux 诞生即开源，其良好的开放性使得几乎所有 GNU 计划中的、运行于用户空间的软件都可以在 Linux 上使用。1992 年，Linux 与 GNU 套件结合，一个完全自由的操作系统诞生了。

由于其所具有的开放性和自主性，越来越多的开发者开始从 UNIX 转向 Linux，并参与了 Linux 的开发与修改，Linux 也逐步成为了最受欢迎的 GNU 软件开发及运行平台。在软件的世界，开源意味着自由，是 “秩序反叛者们 “ 的乐园。

当时，Richard 主张，因为 Linux 使用了许多的 GNU 软件，所以应该正名为 GNU/Linux，但这一提议并没有得到 Linux 社区的一致认同，后来还引发了 GNU/Linux 命名争议。但不管如何，虽然 Linux 本身并不属于 GNU 计划的一部份，但两者的关系早已宛如一体共生。

**1995 年**
，Linux 从 Apache 基金会找到了自己的杀手级应用 — Apache HTTP Web Server。

很快，运行 Apache HTTP 的 Linux 服务器成了全球 ISP 平台的首选。当时，约 60% 的网站选用 Apache。时至今日，LAMP（Linux、Apache、MySQL、PHP）仍是一个非常经典的组合。

* UNIX-Like 操作系统的主干脉络图。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/575eabd0eb5f1ce0e03030eb11f08f72.png)

### 1987，微机虚拟化时代全面启动

随着 x86 服务器（Server）和桌面（Desktop）部署的增长也为企业 IT 基础架构带来了新的难题：

* **IT 运维成本高**
  。
* **基础设施利用率低下**
  。
* **故障切换和灾难保护不足**
  。

而解决这些难题就是新时代付予虚拟化技术的历史任务，自上世纪 80 年代开始，微机虚拟化技术及公司如同雨后春笋般涌现，它们都是云计算时代的奠基者。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/35981a6508ca0f392e2ef2c20ce2ed92.png)

#### 操作系统模拟器

**1987 年**
，Insignia Solutions 公司演示了一个称为 SoftPC 的软件模拟器，这个模拟器允许用户在 UNIX Workstations 上运行 DOS 应用。当时一个可以运行 Microsoft DOS 的 PC 需要 1,500 美金，而使用 SoftPC 模拟，就可以直接在大型工作站上运行 Microsoft DOS 了。

**1989 年**
，Insignia Solutions 发布了 Mac 版的 SoftPC，使苹果用户不仅能运行 DOS，还能运行 Windows 操作系统。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/9f54bbcc45489d3a1d0a52f52f2dcf7d.png)

**1998 年**
，著名的 x86 仿真模拟器 Bochs 发布。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/5b2195d41ec0744ba3bca9f7bf93133c.png)

#### VMware ESXi 虚拟化

**1998 年**
，VMware 公司成立并首次实现了基于 x86 CPU 的虚拟技术，这是一种称之为 “二进制翻译（Binary Translation）” 的技术。可以通过运行在 Windows NT 上的 VMware 来启动 Windows 95 虚拟机。

**1999 年**
，VMware 率先推出针对 x86 平台推出了可以流畅运行的商业虚拟化软件 VMaware Workstation。

**2001 年**
，VMware 发布 ESX 和 GSX，是 ESXi 的前身。

VMware 商业化的成功，也标志着虚拟化技术已经从大型机开始走进微机。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/4b236e6b234b17b6750bca8144a2715d.png)

在那时，由于 Intel x86 CPU 完全不具有虚拟化支撑能力，所以 VMware 的二进制翻译技术需要完全捕获虚拟机发出的特权指令，然后再通过陷入模拟的方式进行指令翻译，这种方式也被称为完全软件实现的虚拟化技术，缺点是实现复杂且性能底下。

* **特权解除（优先级压缩）**
  ：当 GuestOS 需要调用运行 Ring0 的指令时，VMM 就会动态的将内核态指令捕获，并调用若干运行在用户态的指令来模拟出期望得到的效果，从而将内核态的特权解除。解除了内核心的特权后，就能够在 GuestOS 中执行大部分的内核态的指令了。但是，这仍然不能完美的解决问题。因为在一个 OS 的指令集中还存在着一种敏感指令（可能是内核态，也可能是用户态）。此时就需要陷入模拟的实现。
* **陷入模拟（二进制翻译）**
  ：无论是 HostOS 还是 GuestOS，只要是一个 OS 都必然会存在有敏感指令（e.g. reboot、shutdown 等）。试想如果我们希望将 GuestOS 重启，并在 GuestOS 中执行了 reboot 指令，但是却将 HostOS 给重启了，这将会非常糟糕。VMM 的陷入模拟机制就是为了解决这个问题。例如：在 GuestOS 中执行了敏感指令 reboot 时，VMM 首先会将敏感指令 reboot 捕获、检测并判定其为敏感指令。此时 VMM 就会陷入模拟，将敏感指令 reboot 模拟成一个只针对 GuestOS 进行操作的、非敏感的、并且运行在非核心态上的 “reboot” 指令，最后 VMM 执行虚拟机的重启操作。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/652f412f2ee420be7097e6573946e587.png)

#### Citrix XenServer 虚拟化

**1990 年**
，英国剑桥大学的 Keir Fraser 和 Ian Pratt 创建了 XenServer 的初始代码工程。

**2000 年**
，Citrix（思杰）桌面虚拟化产品发布。

**2003 年**
，成立了 XenSource 公司并创立了开源虚拟化项目 Xen 1.0，通过半虚拟化技术（Para-Virtualization）为 x86-64 提供虚拟化支持。往后，基于 Xen 虚拟化解决方案陆续被 Redhat、Novell 和 Sun 等的 Linux 发行版集成，作为默认的虚拟化解决方案。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/143a55d9640cdc8b83088eff1b3b017b.png)

Xen 实现的半虚拟化 VMM 在处理敏感指令和内核态指令的流程上相对更简单一些，把 Guest OS 原本要在 Ring0 上执行的特权指令改造成对 VMM 的调用（Hypercells），这样 Guest OS 就不需要也不会执行 Ring0 的指令了。比较麻烦的就是要改造操作系统代码，所以无法支持闭源的 Windows OS。

另外，虽然 Xen 实现了 CPU 和内存虚拟化，但是虚拟机的 I/O 功能，包括网络和存储等，还需要通过虚拟机中的一个 Front-end（前端模块）与 Domain 0 中的 Backend（后端模块）进行交互，并最终由 Domain 0 中的 Device drivers 实现。

这里的 Domain 0 是 Xen 的一个特权虚拟机（唯一运行在 Xen Hypervisor 之上的虚拟机），运行着被修改过的 Linux kernel，它拥有访问物理 I/O 资源的权限。Domain 0 需要在其它的业务虚拟机启动之前启动，并用于提供业务虚拟机的外设模拟仿真功能。

在那时，Xen 之父 Ian Pratt 也曾表示：“这个项目是由我本人和剑桥大学计算机科学实验室的一些学生共同做的。我们当时就意识到要想使得虚拟化的工作越来越好，必须需要得到硬件方面的帮助，而且要不断地改变 CPU，改变芯片组，以及改变一些 I/O 的装置，使得他们能够适应虚拟化的需要。”

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/4723d2e01482ddf37f2e03894e5cbfa1.png)

#### Intel CPU 硬件虚拟化

**2003 年**
，Intel 对外宣布将在 x86 CPU 上支持硬件虚拟化技术。

**2005 年 8 月**
，Intel 公布了 Vanderpool 的技术细节。Vanderpool 是 Intel VT 技术的前身，通过增加了新的针对虚拟化场景的 CPU 指令，使得 Intel CPU 能够从硬件层面支持虚拟化。

**2005 年 11 月**
，Intel 发布了 Xeon MP 7000 系列 CPU，并宣布将 Vanderpool 更名为 VT（Virtualization Technology）。

**2006 年**
，Intel 和 AMD 等芯片厂商相继推出对虚拟化技术的硬件支持（AMD-V，Intel VT-x），使得原本完全软件实现的各项功能可以用借助硬件的力量来实现提速。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/148c55811aa5271ab01acd9a2e687a70.png)

CPU 硬件辅助的虚拟化技术，通过引入新的 CPU 运行模式（root mode、not root mode）和新的指令集，使得 HostOS 和 GuestOS 分别占用一个运行模式，并且都支持所有的 Ring。GuestOS 运行于 non-Root Mode（受控模式），原来的一些敏感指令在受控模式下会全部陷入 VMM，由 VMM 来实现模拟，这样就解决了部分非内核态敏感指令的陷入（模拟难题）。而且模式切换时，上下文的保存恢复由硬件来完成，这样就大大提高了陷入（模拟时上下文切换）的效率。

比如用户态的程序需要执行一个 I/O 操作：

```c
int nread = read (fd, buffer, 1024);

```

当 CPU 执行到此段代码时，首先查找到系统调用号并保存到寄存器 eax，然后会将对应的参数压栈，再产生一个系统调用中断，对应的是 int $0x80。产生了系统调用中断后，CPU 将切换到 Ring0 模式，内核通过寄存器读取到参数，并完成 I/O 后续操作，操作完成后返回 Ring3 模式。

```c
movel　　$3,% eax
movel　　fd,% ebx
movel　　buffer,% ecx
movel　　1024,% edx
int　　  $0x80

```

而在具有硬件虚拟化特性的 CPU 中，VMM 自己运行在 VMX root operation 模式，VMX non-root operation 模式则由 Guest OS 使用。两种操作模式都支持 Ring 0 及以上特权级，因此 VMM 和 Guest OS 都可以自由选择它们所期望的运行级别（0~3），以此解决了纯软件实现的全虚拟化的 Host OS 和 Guest OS 运行特权级交叉的难题，不再需要使用软件（VMM）来模拟硬件指令集，VM 的指令集可以直接运行在宿主机处理器上。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/2e64f4a1bf99723f55cfbccdde859f7b.png)

**2006 年**
，Xen 3.0.0 发布，该版本可以在 32 位服务器上运行，作为第一个支持 Intel VT-x 技术的虚拟机监控程序。从而使得 Xen 虚拟机可以运行完全没有被修改过的操作系统，该版本是 Xen 真正意义上可用的版本。同年，红帽将 Xen 虚拟机作为企业版 RHEL 的默认特性。

**2007 年**
，Novell 在推出的企业级 SLES（Suse Linux Enterprise Server）10 中添加了 Xen 虚拟化软件。

**2007 年 6 月**
，RedHat 在所有平台和管理工具中包含了 Xen 虚拟化功能。

**2007 年 10 月**
，Citrix 公司出资 5 亿美金收购了 XenSource，变成了 Xen 虚拟机项目的东家。之后推出了虚拟化产品 “Citrix 交付中心”。

![**加粗样式**](https://i-blog.csdnimg.cn/blog_migrate/3ddcc6659a53e1944a33ce9c7297515f.png)

#### Windows Hyper-V 虚拟化

**1997 年**
，苹果发布了 Virtual PC 产品，后来又卖给了 Connectix 公司。

**2003 年**
，Microsoft 收购 Connectix 获得 Virtual PC 虚拟化技术进入桌面虚拟化领域，之后很快推出了 Virtual Server 免费版。

**2004 年**
，微软发布 Virtual Server 2005 计划，业界评价为：“虚拟化正从一个小市场向主流市场转变”。

**2008 年第一季度**
，微软同时发布了 Windows Server 2008 R2 及虚拟化产品 Hyper-V。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/44779ccc230a1e709d20811649735b78.png)

#### QEMU-KVM 虚拟化

**2001**
，Fabrice Bellard 发布了目前最流行的、采用了动态二进制翻译技术的开源虚拟化软件
**QEMU**
（Quick EMUlator）。QEMU 可以模拟 x86、x86\_64、ARM、MIPS、SPARC、PowerPC 等多种 CPU 架构，支持无修改地运行这些架构上的操作系统。18 年后的 2019 年，QEMU 4.0.0 发布并对外宣称几乎可以模拟所有的物理设备，这简直就是个奇迹般的伟大软件。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/f08ce96b401781f9cd0de809632721e1.png)

* Fabrice Bellard

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/cbad911ab8b9545c71f4357274a13d9a.png)

**2006 年 10 月**
，以色列的创业公司 Qumranet 在完成了虚拟化 Hypervisor 基本功能、动态迁移以及主要的性能优化之后，正式对外宣布了
**KVM**
（Kernel-based Virtual Machine，基于内核的虚拟机）的诞生。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/6ce7753c71c7b5916ce25f69de407131.png)

**2007 年 2 月**
，Linux Kernel 2.6.20 合入了 KVM 内核模块，使用 KVM 的前提是 CPU 必须要支持 VT-x 或 AMD-V 硬件虚拟化技术。

**2008 年 9 月 4 日**
，RedHat 收购了 Qumranet，并着手使用 KVM 替换在 RedHat 中的使用的 Xen。

**2009 年 9 月**
，RedHat 发布 RHEL 5.4，在保存 Xen 虚拟化基础上，将 KVM 虚拟化添加进来。

**2010 年 11 月**
，红帽发布 RHEL 6.0，这个版本将默认安装的 Xen 虚拟化机制彻底去除，仅提供 KVM 虚拟化机制。

当年，Xen 虽然作为一项广泛应用于 Linux 发行版中的虚拟化技术，但却迟迟没有集成到 Linux Kernel 中，红帽也许是出于对这种脱离内核的维护方式感到不爽，加之当时思杰和微软表现的很非常亲密，导致红帽萌生了放弃 Xen 的想法，并在正式采用 KVM 的一年后，就宣布彻底放弃 Xen。硬件辅助虚拟化的到来，Xen 引以为傲的半虚拟化技术也随之在主流 Linux 发行厂商中衰落了。

**2011 年初**
，IBM 找上老搭档红帽，表示 KVM 这个东西值得加大力度去做。于是到了 5 月，IBM 和红帽，联合惠普和英特尔一起，
**成立了开放虚拟化联盟**
（Open Virtualization Alliance），加速 KVM 投入市场的速度，由此避免 VMware 一家独大的情况出现。

联盟成立之时，红帽的发言人表示：“大家都希望除 VMware 之外还有一种开源选择。未来的云基础设施一定会基于开源。我们想要营造一个小厂商们可以轻松加入的生态环境。”

#### 操作系统虚拟化（容器）

**1979 年**
，
**UNIX 的第 7 个版本**
引入了
**chroot 机制**
，被认为是
**第一个操作系统虚拟化技术**
（OS-level virtualization）。chroot 是直到现在我们依然在使用的一个 System call，这个系统调用会让一个进程把指定的目录作为根目录，它的所有文件系统操作都只能在这个指定目录中进行，本质是一种文件系统层的隔离。操作系统虚拟化这个说法你或许会感到陌生，但容器（Container）这一称呼你应该非常熟悉。

**2000 年**
，
**FreeBSD jail**
，真正意义上的
**第一个功能完整的操作系统虚拟化技术**
。利用这个技术，FreeBSD 的系统管理者，可以创造出几个小型的软件系统，这些软件系统被称为
**Chroot Jails**
（监狱）。

**2004 年**
，谷歌开始使用容器技术，到 2006 年，谷歌发布了
**Process Container**
（进程容器）技术。Process Container 的目的是希望能够像虚拟化技术一样，给进程提供操作系统级别的资源限制、优先级控制、资源审计能力和进程控制能力。

**2005 年**
，
**OpenVZ**
发布，这是 Linux 操作系统的容器化技术实现，同时也是
**LXC 的核心实现**
。

**2007 年**
，Process Container 技术进入 Linux Kernel。因为在 Linux Kernel 中，Container（容器）这一名词具有许多不同的意义，所以
**为了避免混乱，Process Container 就更名为了 Control Groups，简称 Cgroups**
。

**2008 年**
，Linux 发布了
**LXC**
（Linux Container，包括：Cgroups、Namespace、Chroot 技术）0.1.0 版本，将 Cgroups 的资源配额管理能力和 Namespace 的资源视图隔离能力组合在一起，实现了轻量级的进程隔离。

**2013 年 3 月 15 日**
，在加利福尼亚州圣克拉拉召开的 Python 开发者大会上，DotCloud 的创始人兼首席执行官 Solomon Hvkes 在一场仅五分钟的微型演讲中，首次发布了
**Docker Container**
，并于会后将其源码开源并托管到 Github。最初的 Docker 就是使用了 LXC 再封装了其他的一些功能。可以看出，Docker 的成功，与其说是技术的创新，还不如说是一次组合式的创新。

**2014 年 6 月**
，Docker 发布了第一个正式版本 v1.0。同年，Redhat 和 AWS 就宣布了为 Docker 提供官方支持。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/ce29bff050c6713e3eab39df7efa5c5f.png)

### 2006，云计算与大数据时代

#### 1984，第一次提出了网格计算的概念

**1984 年**
，SUN 公司联合创始人 John Gage（约翰・盖奇）提出 “
**网络就是计算机**
（The Network is the Computer）” 这个重要的猜想，用于描述分布式计算技术带来的新世界。分布式计算正是云计算和大数据的基本架构形式。

然而那时的人们仍然没有对这一说法引起足够的关注。直到 90 年代，相关的理念重新回到了人们的视野。不过这次它换了一个更简单的名字，叫做
**网格计算**
（Grid Computing）。

**网格（Grid）的叫法**
，和我们日常理解的 “网格化管理” 有很大不同，它是直接
**照搬自电网的概念**
（Electric Power Grid）。它的本质目的，还是把大量机器整合成一个虚拟的超级机器，给分布在世界各地的人们使用，也就是
**公共计算服务**
。

* 约翰・盖奇。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/d2f752444a34fb727eeff903f67a8892.png)

#### 1996，第一次提出云计算的概念

**1996 年**
，Compaq（康柏）公司的一群技术主管在讨论计算业务的发展时，
**首次**
使用了
**Cloud Computing**
这个词，他们认为商业计算会向 Cloud Computing 的方向转移。这是 Cloud Computing（云计算）概念的真正首次出现。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/539cf84449bfa68374f00f7482c0958d.png)

**1997 年**
，美国教授 Ramnath K. Chellappa（拉姆纳特・K・切拉帕）对 Cloud Computing 这个名次做出了首个
**学术定义**
：“计算边界由经济而并非完全由技术决定的计算模式”。

这一学术定义，揭示了
**云计算的本质是一种新型的商业模式，其次才是技术创新**
。

* 拉姆纳特・K・切拉帕（印度裔）。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/0071c3e5df397e5627adf6c67b0aa275.png)

#### 1999，Salesforce 成立

**1999 年**
，当时 37 岁的甲骨文（Oracle）高级副总裁，俄罗斯裔美国人马克・贝尼奥夫（Marc Benioff）创办了 Salesforce 公司，是第一家通过网站提供企业级应用程序的公司。通过租赁式网页
**CRM**
（Customer Relationship Management，客户关系管理）软件服务，开启了
**SaaS**
（Software as a service）交付模式。初创企业只要每月按月支付租赁费用，不用再购买任何软件硬件，也不用花费人力成本在软件运营上。

Marc Benioff 后来回忆到：“在那个时期，任何商业天才都难以想象会有公司愿意把它的 CRM，这个关系到公司生命线的系统，从坐落在自己精密机房内的一排排嗡嗡作响的 IBM 主机服务器上，然后挪到一个小小的浏览器内，况且这个浏览器访问的数据中心还完全不在这家公司的掌控之中。但是 Salesforce 做到了，并且做得非常成功。”

Salesforce 的 Customers 包括通用、荷兰航空、富国银行、Comcast 和 NBC 等公司。这些公司选择 Salesforce.com 的原因并不是因为它们买不起服务器，而是因为它们选择了更为高效的在线方案。这充分说明了基于云的服务不仅仅是大型业务系统的廉价替代品，更重要的是，它真正提高了企业的运营效率，促进了业务发展，同时在可靠性上也能维持一个极高的标准。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/174882a5b92f28579dd6e9e93c938b70.png)

#### 2006，AWS 成立

**2000 年**
，当时的 Amazon 正在开发电商服务平台 Merchant.com，旨在帮助第三方公司在 Amazon 上构建自己的在线购物网站。不过，因为架构设计能力和管理流程等方面的问题，这个项目进展缓慢。于是，亚马逊的管理层开始考虑，是不是可以将已有的代码进行解耦，设计成
**独立的 API 服务，然后让内部或外部应用进行服务调用**
。这样，既可以节约后续的开发工作量，也可以增强系统的灵活性和复用度。

**2002 年**
，出版商 O’Reilly 向 Amazon CEO 贝佐斯展示了一个叫做 Amarank 的工具，它可以每隔数小时访问一次 Amazon.com，并复制 O’Reilly 的销售数据及其竞争对手数据排名。O’Reilly 建议亚马逊开发一个 API，让第三方公司可以通过这个接口获取其产品、价格和销售排名。

一方面，基于出版商客户的需求，Amazon 构建
**Web Service**
的想法开始萌芽。另一方面，Amazon 乃至全球知名的在线零售商规模不断发展，但是同时也发现 Amazon 的数据中心在大部分时间只有不到 10% 的利用率，而超过 90% 的资源除了缓冲圣诞购物季这种高峰时段的流量外都在空转和闲置中度过。于是 Amazon 开始行动，将资源从单一的、特定的业务中解放出来，在空闲时提供给其他用户使用。

贝佐斯觉得这个想法不错，或许可以借此转型成技术公司。巧合的是，亚马逊内部已经在进行这项研究，并设计了一些 API。在贝佐斯的推动下，更丰富的
**APIs**
被陆续推出。天才的贝佐斯发现：这些服务器的运作能力，能够当成虚拟货品卖给开发者和初创企业，这和当时毛利率百分之二的主业务电子商务比起来，简直就是一笔 “横财”。

同年，亚马逊启用了 Amazon Web Services（AWS）平台。当时该免费服务可以让企业将 Amazon.com 的功能整合到自家网站上。

**2003 年**
，安迪・杰西（Andy Jassy），当时杰夫・贝索斯（Jeff Bezos，亚马逊创始人）的秘书长，现在 AWS 的 CEO，在贝索斯的家里召开了一次管理层会议。会上，大家决定要把应用开发的通用部分抽离出来，做一个公共基础设施服务平台，让内外部开发者可以基于这个平台开发自己的应用。

随后，他们整理了一系列可以成为
**公共服务的候选模块**
，并从中挑了
**服务器、存储和数据库**
三个部分开始。不仅因为这三个需求最多，还因为 Amazon 最擅长这部分，毕竟低利润率商业模式让他在如何降低数据中心的运营成本上颇有积累。

* 安迪・杰西。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/45175d7f2568a18f45ee29eb54ba4d78.png)

**2006 年**
，Amazon Web Services（AWS）推出了两款重磅产品，开始以 Web 服务的形式，将其
**弹性计算能力作为云服务**
进行售卖时，标志着
**云计算这种新的商业模式的诞生**
。AWS 向企业提供 IT 基础设施服务，包括：
**弹性计算网云**
（Elastic Compute Cloud，EC2）、
**简单储存服务**
（Sample Storage Service，S3）、
**简单数据库**
（SimpleDB）等，
**现在通常称为云计算服务**
。

其中 EC2 推出了
**第一个采用 Xen 虚拟化的实例类型 m1.small**
。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/08f8be9e5ec8b0f7525e35db22ec9210.png)

**2010 年**
，Netflix 宣布全量上 AWS 云 ，就给市场注入了强心剂。后来者纷纷加码，2016 年微软耗费 260 亿美元收购 LinkedIn，拓展企业用户，2018 年 6 月微软又以 75 亿美元收购 GitHub，进一步提升企业服务能力。

**2013 年**
，美国中央情报局（CIA）价值 6 亿美元的高利润私有云合同最终选择了 AWS 而放弃了 IBM，AWS 作为企业级云供应商的资质，进一步获得了政府的认可。

**2015 年**
，AWS 以 46 亿美元的营收数据，不仅让外界知道了亚马逊的实力，也让大众清楚地认识到了云计算广阔的发展前景，当然也推动了亚马逊市值的水涨船高。

**2017 年 10 月**
，AWS 已经宣布已经
**创建了新的基于 KVM 的虚拟化引擎，新的 C5 实例和未来的虚拟机将不使用 XEN**
，而是核心的 KVM 技术。

**2017 年 11 月**
，AWS 推出 C5，首次采用了 KVM 虚拟化。

#### 2006，Hadoop 成立

**2002 年**
，Apache 推出了
**Nutch**
，一个使用 Java 实现的开源搜索引擎，其包括了全文搜索和 Web 爬虫工具。

**2003 年**
，Google 发布了引爆大数据时代的三驾马车之一《
**The Google File System**
》，讲述了一种
**可扩展的分布式文件系统**
，其运行于廉价的普通硬件上，具有很好的容错能力等特性，可应用于大型的、分布式的、对大量数据进行访问的应用。

**2004 年**
，Nutch 创始人 Doug Cutting 基于 Google 的
**GFS**
论文实现了分布式文件存储系统名为
**NDFS**
。

**2004 年**
，Google 发布了引爆大数据时代的三驾马车之二《
**MapReduce: Simplified Data Processing on Large Clusters**
》，讲述了
**大数据的分布式计算方式**
，即将任务分解然后在多台处理能力较弱的计算节点中同时处理，然后将结果合并从而完成大数据处理。

**2005 年**
，Doug Cutting 又基于 MapReduce，在 Nutch 搜索引擎实现了该功能。

**2006 年**
，Google 发布了引爆大数据时代的三驾马车之三《
**Bigtable: A Distributed Storage System for Structured Data**
》，讲述了
**用于存储和管理结构化数据的分布式存储系统，其建立在 GFS、MapReduce 等基础之上**
。该论文启发了后期的很多的 NoSQL 数据库，包括 Cassandra、HBase 等。

**2006 年**
，Yahoo 雇用了 Doug Cutting，
**Doug Cutting 将 NDFS 和 MapReduce 升级命名为 Hadoop**
，Yahoo 开建了一个独立的团队给 Doug Cutting 专门研究发展 Hadoop。

#### 2008，GCP 成立

**2006 年**
，27 岁的 Google 高级工程师克里斯托夫・比希利亚第一次向 Google 董事长兼 CEO 施密特提出 “云端计算” 的想法。在施密特的支持下，Google 推出了 “Google 101 计划”。Google 首席执行官埃里克・施密特（Eric Schmidt）在搜索引擎大会（SES San Jose 2006）再次提出 “云计算（Cloud Computing）” 的概念。

**2008 年 4 月**
，Google “起个大早，赶个晚集”，终于发布了 Google App Engine（GAE），是 Google 管理的数据中心中用于 WEB 应用程序的开发和托管的平台。这是一种
**PaaS**
类型的云服务产品。GAE 通过专有 Web 框架，搭建了一个完整的 Web 开发环境，用户可以在浏览器里面开发和调试自己的代码，并部署在 Google 的基础设施之上。

**2008 年 9 月**
，Google 推出 Google Chrome，以谷歌应用程序为代表的基于浏览器的应用软件发布，将浏览器融入了云计算时代。

**2009 年 7 月**
，Google 宣布将推出 Chrome OS。

* 克里斯托夫・比希利亚

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/1d1e608a3bf202b10664ae8648a15f21.png)

#### 2008，Microsoft Azure 成立

**2008 年 10 月**
，微软发布公有云计算战略和平台
**Windows Azure Platform**
，尝试将技术和服务托管化、线上化。主要目标是为开发者提供一个平台，帮助开发可运行在云服务器、数据中心、Web 和 PC 上的应用程序。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/62f74343bd5d28d6d4c2d021225a0344.png)

**2010 年 1 月**
，Microsoft 正式发布 Microsoft Azure 云平台服务。

**2014 年 3 月**
，微软正式宣布 Microsoft Azure 在中国正式商用，由世纪互联运营，名为 Windows Azure；同年 4 月，微软 Office 365 正式落地中国。

**2016 年 1 月**
，微软公司首席执行官萨提亚・纳德拉在达沃斯论坛上宣布了一项全新的计划 — Microsoft Philanthropies。作为计划的其中一部分，微软将在未来三年为 7 万家非营利组织以及高校科研机构提供价值 10 亿美元的微软云计算服务，借助云计算提供的数据存储、分析及预测等技术，帮助公益事业构建长期发展能力。

**2018 年**
，微软收购 Github，无论好坏，开源的历史会记住这一天。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/36561cffc5f5457c28fbbca94dec1840.png)

#### 2009，阿里云成立

2009 年，阿里云写下第一行代码，采用的是 Xen 虚拟化技术。

2014 年，阿里云切换为 KVM 虚拟化技术，并进行了深度的定制化。

2015 年开始探索，2016 年开始立项，2017 年首次发布 X-Dragon 神龙架构，真正使用软硬融合、软硬件协同设计的模式，改变了传统虚拟化技术和当前的计算架构不友好的地方。

* 经典的第一行代码。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/827a7d2c7584759dcdfb91375809570e.png)

#### 2009，VMware vCloud 成立

**2003 年**
，存储设备厂商
**EMC**
宣布以 6.35 亿美元的价格
**收购**
了创立仅 5 年的虚拟技术公司
**VMware**
，成为 EMC 迄今最成功的一笔收购。

**2007 年 7 月**
，
**Intel**
向 VMware 投资 2.185 亿美元。

**2007 年 8 月**
，
**Cisco**
向 VMware 投资 1.5 亿美元。

**2009 年 4 月**
，Cisco 与 EMC、VMware 建立虚拟计算环境联盟。不久后 VMware 推出业界首款私有云操作系统 VMware vSphere。Cisco 与 VMware 在 VMworld 大会上宣布联合推出下一代软件交换机 Nexus 1000v，几乎是一个一比一的复刻版 OpenFlow 软件交换机，替代了 vSphere 本身的 vSwitch 软件交换机，通过 vSphere 的开放 API 管理虚拟化平台的流量。

**2009 年 9 月**
，VMware 启动 vCloud 计划构建全新的云服务。

**2012 年**
，VMware 以 12.6 亿美元收购了 OpenFlow SDN 初创公司 Nicira（由 SDN 开创者 Martin Casado、Nick McKeown 和 Scott Shenker 合伙成立），随后 VMware 基于 Nicira 的核心产品 NVP（Network Virtualization Platform，网络虚拟化平台）推出了 NSX 网络虚拟化解决方案，结合 vSAN 存储虚拟化解决方案，提出了软件定义数据中心 SDDC 的构想。

**2015 年 10 月**
，Dell 宣布将以 670 亿美元收购 EMC，从而成为全球科技市场最大规模的并购交易。

**2016 年 10 月**
，VMware 和亚马逊旗下公司 Amazon Web Services 达成战略联盟，将 VMware 软件定义数据中心（SDDC）带入 AWS Cloud，支持客户在基于 VMware vSphere 私有云、公有云以及混合云环境下运行各种应用，并获得对 AWS 服务的最佳访问。

**2017 年 8 月**
，在 VMworld 2017 大会上，VMware 和 Amazon Web Services 共同宣布 VMware Cloud on AWS 初步可用。

#### 2010，OpenStack 开源项目成立

**2010 年 7 月**
，NASA 贡献了云计算管理平台 Nova 代码，Rackspace 云存储（对象存储）代码，发起了
**OpenStack**
云操作系统开源项目。同年 10 月 21 日，发布了首个版本 Austin（奥斯丁）。OpenStack 挽手自主可控的口号，推动了云计算在国内的全面爆发。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/6678baf232c23b0de9f538b8ab7a9522.png)

**2012 年 4 月**
，OpenStack 发布了 Essex 版本，其在试用组件中提供了 Quantum 网络组件，用于实现类似于 VMware NSX 的网络虚拟化功能。该组件在 2012.10 OpenStack Folsom 版本中进行了正式发布；后因为商标侵权的原因，OpenStack 在 Havana 版本上将 Quantum 更名为 Neutron。

**2019 年**
，Open Infrastructure Summit 相继在上海举办。中国的开源会铭记这一天。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/ee77c9ee9bf570a8be1466e2466aa9fb.png)

### 2015，云原生时代

#### 2014，Kubernetes 开源项目成立

**2013 年**
，Pivotal 公司（敏捷开发领域的领导者）的 Matt Stine 首次提出
**云原生**
（CloudNative）的概念。

**2014 年**
，
**Kubernetes**
容器编排平台也正式发布。Kubernetes 项目的初衷，就是为了提供一种方便、快速、优雅地 Containers 管理平台。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/e8d64ea9824a555f71a09cec09c719b4.png)

**2015 年**
，为了对抗当时大红大紫的 Docker 公司在容器圈一家独大的局面，同时也是出于对容器技术将会对传统 IT 生产运营模式带来变革的深刻理解。由 Google、Redhat 以及 Microsoft 等大型云计算厂商牵头成立了
**CNCF**
（Cloud Native Computing Foundation，云原生计算基金会），隶属于 Linux 基金会旗下，致力于培育和维护一个厂商中立的开源生态社区，并以此来推广云原生技术。而 Kubernetes 则是 CNCF 托管的第一个开源项目。

CNCF 中托管的一系列项目，都致力于云原生应用整个生命周期的管理，从部署平台、日志收集、Service Mesh（服务网格）、服务发现、分布式追踪、监控以及安全等各个领域通过开源软件为我们提供一整套解决方案。CNCF 的成立标志着进入云原生时代。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/69eba8cdfebf944aaebee7975e39d072.png#pic_center)

早期，关于云原生的定义一直处于百家争鸣的状况。

2015 年，Matt Stine 在《迁移到云原生架构》一书中定义了符合云原生架构的几个特征：
**12 因素**
（12-factors）、微服务、自敏捷架构、基于 API 协作、扛脆弱性。其中 12-factors 为：

* **基准代码**
  ：一份基准代码，多份部署。
* **依赖**
  ：显式声明依赖关系。
* **配置**
  ：在环境中存储配置。
* **后端服务**
  ：把后端服务当作附加资源。
* **构建，发布，运行**
  ：严格分离构建和运行。
* **进程**
  ：以一个或多个无状态进程运行应用。
* **端口绑定**
  ：通过端口绑定提供服务。
* **并发**
  ：通过进程模型进行扩展。
* **易处理**
  ：快速启动和优雅终止可最大化健壮性。
* **开发环境与线上环境等价**
  ：尽可能的保持开发，预发布，线上环境相同。
* **日志**
  ：把日志当作事件流。
* **管理进程**
  ：后台管理任务当作一次性进程运行

2017 年，Matt Stine 将云原生架构归纳为 6 大特质：

1. 模块化（Modularity）
2. 可观测性（Observability）
3. 可部署性（Deployability）
4. 可测试性（Testability）
5. 可处理性（Disposability）
6. 可替换性（Replaceability）

Matt Stine 认为云原生它是一个思想的集合，包括：

* DevOps
* 持续交付（Continuous Delivery）
* 微服务（MicroServices）
* 敏捷基础设施（Agile Infrastructure）
* 康威定律（Conways Law）

Pivotal 官方则对云原生概括为 4 个要点：1）容器；2）微服务；3）持续交付；4）DevOps。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/8f34158f77f5d6046aa522fc9777bcd6.png#pic_center)

不同的公司、不同的人对云原生都有着不同的定义，同一家公司在不同的时间阶段定义也不一样，可以预见未来对于云原生的定义还会不断变化。

* Pivotal 定位于 PaaS 层端到端的解决方案及数字化转型，从文化、流程、方法论、蓝图规划、软件开发方式等，都有一套模式，主要用户是传统大中型企业 CIO，整体策略是自顶向下。
* CNCF 立足于整个云计算生态和技术创新、变革者，偏重于技术、工具链和底层基础设施，主要用户是开源社区的开发者、互联网及新兴企业，影响力可想而知，整体策略是自底向上。

所以，可以肯定的是，Pivotal 是 Cloud Native 概念和方法论的先行者， CNCF 是 Cloud Native 的最佳实践者。

笔者则认为，云原生是一套方法论（Pivotal）和一系列技术堆栈（CNCF）的有机组合，指导进行新型 IT 软件架构设计与研发，使其 “生在云上、长在云上”，能够最大化地发挥云的价值，并赋能企业高速成长。所以云原生的时代，得开发者得天下。

**2019 年**
，全球最大的开源盛会 KubeCon + CloudNativeCon + Open Source Summit 在上海举办。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/9b3e40d5d324eec439384d64d8b43978.png)

截止 2020 年 2 月，CNCF 已有 433 个会员，其中不乏国内各个行业的的龙头企业。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/ecb0af87935e82bcb8335f79a63ec253.png#pic_center)

### 2023 年，云化 AIGC 时代

至此，即使笔者的脑力已经几近枯竭，但还是不能不提到现在已经来到眼前的 AIGC 时代，或者我更愿意称之为 “云化 AIGC 时代 “，相信朋友们能够理解其中的含义。

AIGC 技术将会以集约式算力中心为基础，站在云计算商业和服务模式的肩膀上，作为一种新型的 LLMaaS，深刻影响个人及社会等各方面的生产活动。从个人的角度出发，人们有望借助 AIGC 从个体进化为一个超级个体。

**个体**
：人作为一个个体是独立存在的，具有独特的身份、特征和意识。

* **独立性**
  ：拥有自己的身份和个性，不同于其他人。
* **身份特征**
  ：拥有自己的外貌、性格、兴趣和经历，这些特征形成了个体的身份认知。
* **自我意识**
  ：拥有自己的意识，能够感知、思考、表达和决策。
* **自我实现**
  ：拥有自己的理想和目标，追求自我实现和发展。
* **社会性**
  ：拥有自己的社会地位，能够与他人产生联系、互相依存、互相协作。社会环境对个人的发展具有重要影响。

**超级个体**
：可以定义为具有高度发展的身体、智力和精神能力的独立存在，能够在现代社会中迅速适应和创新，并对社会、经济、科技和文化等方面产生深远的影响。一个超级个体应该具备以下特征：

1.
**具有健康的身体和强健的体魄**
：以应对高强度的工作和挑战，保持高度的工作效率和创造力。

2.
**具有多样化的技能和知识**
：包括技术、管理、创新、沟通和领导等方面，以应对不同领域的挑战和机遇。

3.
**具有全球化的视野和跨文化交流能力**
：能够理解和适应不同文化、语言、价值观和习惯，有效地进行跨国合作和交流。

4.
**具有强大的创新能力和敏锐的市场洞察力**
：能够预见未来趋势、发现机遇、创造价值，并在市场竞争中保持领先地位。

5.
**具有高度的社会责任感和领袖魅力**
：能够在社会中发挥重要的作用，推动社会进步和创造社会价值。

---

| 年份 | 事件 |
| --- | --- |
| 1605 | 弗朗西斯・培根基于二元组合提出加密系统；戈特弗里德・莱布尼茨设计现代二进制记数系统 |
| 1725 | 巴西尔・布尚发明穿孔纸带 |
| 1801 | 约瑟夫・玛丽・雅卡尔改良纺织机，实现自动化编织 |
| 1846 | 亚历山大・贝恩发明电报打字机，改进出穿孔指令带 |
| 1890 | 赫尔曼・何勒里斯发明穿孔卡制表机 |
| 1896 | 赫尔曼・何勒里斯成立制表机公司，后为 IBM 前身 |
| 1936 | 阿兰・图灵提出图灵完备性和图灵机 |
| 1942 | 约翰・阿塔纳索夫和克利福特・贝瑞研制出第一台专用计算机 ABC |
| 1945 | 冯・诺依曼提出冯・诺依曼体系结构 |
| 1946 | 世界上第一台通用计算机 ENIAC 诞生 |
| 1955 | 约翰・麦卡锡提出分时系统概念 |
| 1959 | 克里斯托弗・斯特雷奇首次提出虚拟化技术概念 |
| 1962 | 第一台超级计算机 Atlas 1 诞生，实现多项软件创新 |
| 1964 | 第一个分时共享操作系统 Multics 开始研发 |
| 1965 | IBM 推出 System/360 大型计算机系统；DEC 推出第一台真正意义的小型机 PDP-8 |
| 1967 | L.W. Comeau 和 R.J. Creasy 为 System/360 研发 CP-40/CMS 分时共享操作系统 |
| 1973 - 1977 | C 语言和可移植的 UNIX 分时共享操作系统诞生 |
| 1974 | Gerald J. Popek 和 Robert P. Goldberg 提出 VMM 概念 |
| 1978 | 第一片 x86 处理器发布；戈登・摩尔提出摩尔定律 |
| 1980 | 微软和英特尔组成 Wintel 商业联盟 |
| 1983 | Richard Stallman 启动 GNU 计划 |
| 1984 | John Gage 提出网格计算概念 |
| 1987 | Insignia Solutions 公司演示 SoftPC 软件模拟器；微机虚拟化时代启动 |
| 1991 | Linus Torvalds 发布 Linux Kernel |
| 1992 | Linux 与 GNU 套件结合 |
| 1996 | Compaq 公司首次使用 Cloud Computing 一词 |
| 1997 | 美国教授 Ramnath K. Chellappa 对云计算做出学术定义 |
| 1998 | VMware 公司成立，实现基于 x86 CPU 的虚拟技术 |
| 1999 | Salesforce 成立，开启 SaaS 交付模式 |
| 2000 | FreeBSD jail 出现，是第一个功能完整的操作系统虚拟化技术 |
| 2002 | Apache 推出 Nutch；Google 发布《The Google File System》 |
| 2003 | Google 发布《MapReduce: Simplified Data Processing on Large Clusters》；XenSource 公司创立开源虚拟化项目 Xen 1.0 |
| 2004 | Doug Cutting 基于 Google 论文实现 NDFS；Google 发布《Bigtable: A Distributed Storage System for Structured Data》 |
| 2005 | OpenVZ 发布；Intel 公布 Vanderpool 技术细节 |
| 2006 | Amazon 推出 AWS 云计算服务；Doug Cutting 将 NDFS 和 MapReduce 升级命名为 Hadoop；Google 提出 “云端计算” 想法；Microsoft 推出 Virtual Server 2005 计划 |
| 2007 | Linux Kernel 合入 KVM 内核模块；Process Container 技术进入 Linux Kernel 并更名为 Cgroups；Citrix 收购 XenSource |
| 2008 | Google 发布 Google App Engine；Microsoft 发布 Windows Server 2008 R2 及虚拟化产品 Hyper-V；Linux 发布 LXC 0.1.0 版本；DotCloud 的创始人首次发布 Docker Container |
| 2009 | 阿里云成立；VMware 启动 vCloud 计划 |
| 2010 | OpenStack 开源项目成立；Microsoft 正式发布 Microsoft Azure 云平台服务；Netflix 全量上 AWS 云 |
| 2014 | Kubernetes 开源项目成立；Docker 发布第一个正式版本 v1.0；Redhat 和 AWS 宣布为 Docker 提供官方支持；阿里云切换为 KVM 虚拟化技术 |
| 2015 | 云原生时代开启；CNCF 成立；AWS 以 46 亿美元营收展示云计算前景 |
| 2016 | 微软收购 LinkedIn；VMware 和 AWS 达成战略联盟 |
| 2017 | AWS 推出基于 KVM 的虚拟化引擎及 C5 实例；VMware Cloud on AWS 初步可用 |
| 2018 | 微软收购 GitHub；Google Chrome OS 发布 |
| 2019 | 全球最大的开源盛会 KubeCon + CloudNativeCon + Open Source Summit 在上海举办 |
| 2023 | 云化 AIGC 时代到来 |

---

## 回顾深度学习的崛起背景，近 10 年在各行各业中的典型应用

*言有三于 2021-02-23 11:14:20 发布*

![img](https://i-blog.csdnimg.cn/blog_migrate/ce33cc724c0b0707c793909319e5f960.png)

笔者作为一个从业 5 年多的技术人员，吃到了深度学习的早期红利，这次来聊一聊深度学习的崛起背景、当下的典型应用领域，算作给尚未或者正打算拥抱这门技术的朋友们一个较为全面的科普。

### 深度学习为什么能够崛起

一架飞机要成功在天上飞行，离不开 3 大要素，优良的结构设计，强劲的发动机，足够的燃料。对于深度学习来说，要成功也需要满足这 3 个前提条件，即先进的算法模型，强劲的计算资源，足够的学习数据。

![img](https://i-blog.csdnimg.cn/blog_migrate/6da98ab8bf70f3da161902407f44dce0.png)

深度学习的成功不是一蹴而就，正是这三个条件长时间积累后的集中爆发，换一种更具体的说法就是大数据时代的来临，GPU 的发展，神经网络相关工程理论的改进。

### 大数据时代的来临

人类的文明历史，经过了从结绳记事，文字记事，到如今的图片，视频记事的发展历史，正所谓一图胜千言。

![img](https://i-blog.csdnimg.cn/blog_migrate/1f4ce4f692048b06452783d3f984d9ee.png)

在文字被发明之前，人类文明其实没有多少记录，比如我们对夏朝及其以前的历史其实就不太熟悉。而商朝时古人发明了甲骨文，于是文明通过文字的形式传承下来。不过在纸张被发明之前，记录下的信息并不多。古人形容一个人有学识，要用学富五车来形容，这个五车就是实实在在的信息的度量方式，因为当时的文字存在于竹简上。后面纸张被发明，记录文字的效率才得到提升。

随着现代文明的中心转移到了西方，1826 年前后法国科学家 Joseph Nicéphore Niépce 发明第一张可以永久记录的模拟照片，美国发明家爱迪生则在 1877 年前后发明了留声机。在第一次世界大战后的两年，数字图像也被发明了，被用于新闻行业，从此人类记录的信息变得更加丰富。

1969 年因特网的前身 ARPANET 被发明，随着计算机技术的迭代更新，我们开始逐渐进入互联网信息时代，数据的形式开始变得更加高维和复杂，以网页为代表的数据形式，同时包括了文本、图像、语音、超链接等信息。

根据 2012 年的畅销书《大数据时代》的统计结果：2000 年的时候， 数字存储信息只占全球数据量的四分之一；另外四分之三的信息都存储在报纸、 胶片、黑胶唱片和盒式磁带这类传统的媒介上，这个时期个人依旧是被动式的接收中心节点整理好的信息，数据量有限，更新频率低。

![img](https://i-blog.csdnimg.cn/blog_migrate/66fe4cfe07750163bb6db71dae197d75.png)

但时间到了 2007 年， 所有数据中只有 7% 是存储在报纸、 书籍、 图片等媒介上的模拟数据， 其余全部是数字数据，个人开始主动创造数据并传送到中心节点，数据量庞大，更新频率高。

我们打开 APP，拍照上传，发帖评论，浏览网页，播放视频，点击广告，搜索信息，收藏购买，在线支付，即时通信，点赞转发，心跳血压，每时每刻都在制造数据。

![img](https://i-blog.csdnimg.cn/blog_migrate/369d2c86e91e6219abdb99f80ceed4b7.png)

本图来自清华大学 - 大数据应用人才培养系列教材

当时互联网每天产生的全部内容可以刻满 6.4 亿张 DVD，全球每秒发送 290 万封电子邮件，一分钟读一篇的话，足够一个人昼夜不停地读 5.5 年。

![img](https://i-blog.csdnimg.cn/blog_migrate/f11a43232ba566d29351c0b5dbe543ea.png)

基于此，杰姆・格雷（Jim Gray）提出数据领域的 “新摩尔定律”，即人类有史以来的数据总量，每过 18 个月就会翻一番。

![img](https://i-blog.csdnimg.cn/blog_migrate/a1114c86b798ae94a6e45e2475107797.png)

自此我们进入了大数据时代，大数据时代的特点在于，我们处理问题的思维方式发生了变化，我们习惯从数据中进行统计学习，从追求因果关系到追求相关关系。

大数据时代对我们生活的改变是深远的，譬如在 2012 年数以万计的美国人进行模型侧写， 平均凭借一个 Facebook 用户的 68 个 “赞”，模型就能够估计出他们的肤色（准确率为 95%）、性取向（准确率为 88%）和党派（民主党或共和党，准确率为 85%）。基于此，Cambridge Analytica 公司使用大数据挖掘和心理侧写 (Psychological profiling) 等技术手段，采取不同的传媒策略 (主要是社交媒体上的精准投放)，在 2016 年帮助英国脱欧公投阵营赢得脱欧公投、在美国大选中操纵选情帮助特朗普总统赢得大选。

![img](https://i-blog.csdnimg.cn/blog_migrate/7087b0c4573c8a9542b6b439a6c86102.png)

研究人员有了更多的数据，就可以开始解决更加复杂的问题。以计算机视觉任务为例，1998 年发布的手写数字识别数据集 MNIST，共 60000 图片，10 个类别，2009 年发布的 ImageNet 数据集，共 1400 多万图片，2 万多个类别，百万标注框。如果不是大数据时代的积累，我们就没有 ImageNet 这样的行业基准来推动计算机视觉领域的快速进步。

大数据还催生了新的职业，如数据标注工程师，诞生了许多相关的公司、大数据社区。

![img](https://i-blog.csdnimg.cn/blog_migrate/13837f47b4f6f2cacb11f0b97ed278fd.png)

![img](https://i-blog.csdnimg.cn/blog_migrate/d48b5aba0d4f3f534628c32c7550e354.png)

没有大数据，不可能有足够的‘养料’喂养出深度学习模型，而深度学习的崛起，正是从 2010 年左右，我们进入数据快速增长的大数据时期开始。

### GPU 的发展

现在我们都知道做深度学习任务 GPU 是必不可少的，其结构和 CPU 相比有很大不同。

CPU（ Central processing unit ）需要很强的通用性来处理各种不同的数据类型，同时在大量的逻辑判断中，包含了大量的分支跳转和中断处理，使得 CPU 的内部结构异常复杂，不擅长于快速计算。

而 GPU（Graphic Processing Unit）则专为图像处理设计，采用了数量众多的计算单元（arithmetic and logic unit）和超长的流水线，但只有非常简单的控制逻辑并省去了 Cache。

这使得 GPU 拥有高带宽的独立显存；浮点运算性能高；几何处理能力强；适合处理并行与重复计算任务；适合图像或视频处理任务；

![img](https://i-blog.csdnimg.cn/blog_migrate/8818adcc91e291c65b5bca2b9e4f0411.png)

CPU 的峰值计算能力 = CPU 频率 ×CPU 核心数 × 浮点运算单元数，如 i7-8700K 的 CPU 频率 = 3.7GHZ，核数为 6，浮点运算单元数为 16，浮点运算能力是 3.7
*16*
6<360 Gflops 以下。而 TITAN V 峰值浮点性能为 110 TFlops (1T=1024G)，TESLA v100 峰值浮点性能为 125 TFlops ，因此 GPU 有超过 CPU 几个数量级的速度优势。

![img](https://i-blog.csdnimg.cn/blog_migrate/c672f2ea6240a66acd0696fe18a8a000.png)

不过 GPU 也不是一开始就拥有如此强劲的计算能力，简单来说经历了 3 个时期。

第 1 时期是固定架构时代（ fixed function architecture，1995-2000 年）。1999 年，NVIDIA 推出第一款 GPU Geforce256，拥有完整的顶点变换、光照计算、参数设置以及渲染等四种 3D 计算引擎，每秒处理至少 1000 万个多边形，极大加快了计算机 3D 程序运行速度。2000 年， NVIDIA 推出全球首款针对笔记本的 GPU——GeForce2 Go。

![img](https://i-blog.csdnimg.cn/blog_migrate/aac92595dbf323b0b54ae4e15dee42a1.png)

第 2 时期是分离渲染架构时代（ separated shader architecture，2001-2005 年）。1999 年到 2002 年， NVIDIA 推出了业界首款独立的可编程 GPU Geforce3，ATI（2006 年被 AMD 收购）推出了 Radeon8500。这个时期的 GPU 用可编程的顶点渲染器（Vertex Shader）替换了变换与光照相关的固定单元，用可编程的像素渲染器（Pixel Shader）替换了纹理采样与混合相关的固定单元，这两部分是实现图形特效最密集的部分，使用渲染器大大加强了图形处理的灵活性与表现力。两个渲染器呈现流处理器 (stream processor) 的特点，不过在物理上是两部分硬件，不可相互通用。

![img](https://i-blog.csdnimg.cn/blog_migrate/342f90626e42bf5596988e2e29197f98.png)

第 3 时期是统一渲染架构时代（ unified shader architecture，2006 年至今）。2006 年 NVIDIA 与 ATI 分别推出了 CUDA (Computer Unified Device Architecture，统一计算架构) 编程环境和 CTM (Close To the Metal) 编程环境，这使 GPU 通用计算编程的复杂性大幅度降低。这个时代的 GPU 首次提供几何渲染程序 (geometry shader program) 功能，并动态调度统一的渲染硬件 (unified shader) 来执行顶点、几何、像素程序，在体系结构上不再是流水线的形式，而呈现并行机的特征。

2006 年，研究人员使用 NVIDIA GeForce 7800 训练了 4 层的卷积神经网络，相比 CPU 的 BLAS 优化有 24%–47% 的提升，这也是早期 GPU 在模型训练中的尝试。

随后 NVIDIA 的 GPU 产品线迭代速度明显加快，其设计架构从 40nm Fermi、28nm Kepler、28nm Maxwell、16nm Pascal 到如今的 12nm Volta、Turing，推出了 NVIDIA Tesla，GeForce GTX 600，GeForce GTX TITAN， GeForce GTX 980，GeForce GTX 1080，Tegra K1，GeForce GTX TITAN X，Tesla V100，Tesla P100 等众多消费者熟知的产品，对于深度学习模型的训练产生了深远的影响。

![img](https://i-blog.csdnimg.cn/blog_migrate/a5b1d99a3809a83211bf9216093d8872.png)

2009 年，Hinton 的团队使用 Nvidia GTX 280 训练 2 层的 Deep Belief Network (DBN) 。

2012 年，同样是 Hinton 的团队使用 2 个 NVIDIA GTX580 在 ImageNet 数据集上训练 8 层的 AlexNet，训练时间为 6 天，这成为了深度学习在计算机视觉领域中的里程碑事件。

2018 年，Facebook 团队使用 256 个 NVIDIA Tesla P100 在 ImageNet 数据集上训练 ResNet50，训练时间 1 小时。

2018 年，腾讯团队使用 2048 个 NVIDIA Tesla P40 在 ImageNet 数据集上训练 ResNet-50，训练时间 6.6 分钟。

2018 年，日本索尼的神经网络库 NNL，使用 3456 个 NVIDIA Tesla v100，在 ImageNet 数据集上训练 ResNet-50，将其训练时间缩短到了 112 秒。

正是第三个时期的 GPU 架构的快速发展，为深度学习模型的训练提供了可能，催生了一代又一代新的更复杂的模型架构的诞生。

### 神经网络相关工程理论的发展

什么是深度学习，它本质上是一个复杂的非线性变换构成的抽象算法，对数据进行表征学习（representation learning）。

传统机器学习算法的研究流程是：手工特征 + 机器学习模型。而深度学习算法的研究流程是：从数据中自动学习特征，提高机器学习模型的性能，它们的主要区别在于特征提取这里。

![img](https://i-blog.csdnimg.cn/blog_migrate/7bae7ad23b829187be014b08e81db75e.png)

神经网络由于其结构非常适合于逐层进行数据的抽象表达，因此我们平常说深度学习，指的就是深度神经网络，其中 “深” 表示网络层数深，从传统的几层到成百上千层。

![img](https://i-blog.csdnimg.cn/blog_migrate/e7427d325886101e650746c8ce126d24.png)

深度学习并不是全新的概念，神经网络在上个世纪中期就已经诞生，其核心优化理论，反向传播算法 (Back-Propagation, BP 算法) 由保罗・韦尔博斯 (Paul Werbos) 在 1974 年发明，1986 年戴维・鲁梅哈特 (David Rumelhart)，杰弗里・辛顿 (Geoffrey Hinton) 等人将其进行推广完善。

![img](https://i-blog.csdnimg.cn/blog_migrate/84ebb674356c5fd644397a3d4bda4289.png)

在 2006 年，Geoffrey Hinton 团队发表了两篇经典研究。第一篇是 “Learning Multiple Layers of Representation”，提出了不同于以往学习一个分类器的目标，而是希望学习生成模型（generative model）的观点，以期学习到更好的特征表达，摆脱对大量训练数据的依赖，因此早期的深度学习也被称为表示学习。另一篇论文 “Reducing the dimensionality of data with neural networks”，则提出了逐层无监督预训练玻尔兹曼机的方式，通过 “预训练 + 微调” 有效地解决了深层模型难以训练的问题，这具有非常重要的工程意义。

![img](https://i-blog.csdnimg.cn/blog_migrate/c0105ebef37243161cf055e1e7d1b13d.png)

2011 年，Glorot 等人提出 ReLU 激活函数，有效地抑制了深层网络的梯度消失问题，简单而有效。

2012 年，Hinton 等人提出 Dropout 技术，有效地抑制了深层网络的过拟合问题。它消除或者减弱了神经元节点间的联合，降低了网络对单个神经元的依赖，从而增强了泛化能力。

紧接着就是 2012 年 Alex Krizhevsky 在论文 “ImageNet classification with deep convolutional neural networks” 中正式提出了 AlexNet 网络，包含 8 个网络层，其中 5 个卷积层，3 个全连接层，以低约 10% 的错误率，大幅度超过竞争对手，意味着深度学习的黄金时代真正到来了。

![img](https://i-blog.csdnimg.cn/blog_migrate/3c70f3268f2ec85d44b8813511ccc6d2.png)

AlexNet 模型的成功，就得益于当时最大的数据集 ImageNet 提供了足够的样本进行学习、当时最大的 GPU 以训练超过 55M 的参数量，以及一系列神经网络相关工程技术的使用，包括 ReLU 激活函数，LRN 归一化，Dropout，数据增强，这就是深度学习发展需要的三驾马车。

麻省理工科技评论在 2013 年评选出十大突破性科学技术，深度学习位居榜首，随后产业界开始重视深度学习。

![img](https://i-blog.csdnimg.cn/blog_migrate/285073a9181e9afcd114a0c18b0a612e.png)

2010 年，斯坦福教授吴恩达（ Andrew Ng）会见了 Google 当时的 CEO， 决定开发 Google Brain；

2012 年，Google 的一个由 16000 台电脑集群组成的人工神经网络通过 YouTube 上有关于猫的资料自行训练而能够识别出 “猫” 这一概念；

2012 年，华为成立诺亚方舟实验室；

2013 年，谷歌聘用了深度学习宗师 Geoffrey Hinton；

2013 年，百度深度学习研究院（ Institute of Deep Learning ）建立；

2013 年，FaceBook 在纽约成立了 FAIR（Facebook AI. Research），聘用了 Yann LeCun 作为首席科学家；

2014 年，谷歌以未公布的价格并购了英国 DeepMind 公司；

由此我们进入了长达将近 10 年的深度学习发展黄金时期，并且还将继续下去。

深度学习在产业界的应用

从 2012 年至今已有将近 10 年的发展，深度学习在各行各业中不断创造商业价值，这里我们从 4 个大的研究方向来看，即语音处理，计算机视觉，自然语言处理，推荐系统。

### 语音处理

在传统的研究方法里，语音识别经历了几次重要的技术发展。从 20 世纪 70 年代的隐含马尔科夫模型声学建模，20 世纪 80 年代的 N 元组语言模型，20 世纪 90 年代的隐含马尔科夫模型状态绑定和自适应技术，到 21 世纪第一个十年的 GMM-HMM 模型。尽管这些技术取得了不错的进步，但是仍然无法让语音识别达到可商用的地步，直到深度学习的到来，一举让语音识别错误率相比以往最好的方法还下降了 30% 以上，突破了语音识别技术可以商用的临界点。

在 2009 年 neural information processing systems（NIPS）会议上，邓力和 Geoffrey Hinton 联合组织了 Deep Learning for Speech Recognition and Related Applications workshop。他们首次证明使用新方法训练的深度神经网络在大量语音识别基准上优于之前的方法，并联合发表了论文 “Deep Neural Networks for Acoustic Modeling in Speech Recognition”。

2012 年 Abdel-Hamid 等人证实卷积神经网络可以在频率坐标轴上有效归一化说话人的差异，并在 TIMIT 音素识别任务上讲错误率从 20.7% 降低到 20%。

之后俞栋，邓力以及 Geoffrey Hinton 等人致力于将深度学习技术广泛引入语音识别中，并撰写了书籍《Deep learning: methods and applications》。

![](https://i-blog.csdnimg.cn/img_convert/677c2dfe87511c3d7d0e5da22e2b6ac8.jpeg)

2016 年，微软率先实现语音识别系统 5.9% 的低错误率，在 Switchboard 对话语音识别任务中已经达到人类对等的水平。

现如今深度学习在语音分类、语音质量评测、语音增强、音频指纹识别、语音检索与唤醒、语音识别、声纹 / 说话人识别、语音合成与生成中应用非常广泛。

语音分类和音频指纹识别的典型应用即听歌识曲，相信许多朋友都使用它识别过歌曲。

![img](https://i-blog.csdnimg.cn/blog_migrate/364bbc82114f1835c1dd7dcd840512aa.png)

语音检索识别的应用自不用说，智能音箱、语音输入法、同声传译、实时字幕生成，这些都是非常高频的应用，大大便利了我们的日常生活。

![img](https://i-blog.csdnimg.cn/blog_migrate/bf0dd101828dd871ce1d67c3f6832b37.png)

语音合成（Text To Speech）技术在智能配音、虚拟主播、有声阅读、地图导航、智能客服等领域中也已经普及，以下展示的就是几个 AI 语音助手一起演唱歌曲的应用。

点击边框调出视频工具条

而最先进的语音处理技术，当属语音生成，可以从头创作不存在的语音，乐曲，国内外都有非常多优秀的案例。如平安人工智能研究院创作的交响曲《我和我的祖国》，网易研究院创作的歌曲《醒来》，由 AI 完成词、曲、编、唱这个全链路的工作，大家不妨来收听感受一下。

![img](https://i-blog.csdnimg.cn/blog_migrate/a84781699e50bc1b52f36d0841450541.png)

这些应用的落地，都得益于深度学习技术的进步，使得我们通过语音与世界的交互变得更加便利和智能。

### 计算机视觉

由于人类接触到的 70% 以上的信息都是视觉信息，因此计算机视觉是深度学习应用最广泛也是最成熟的领域，研究领域本身就覆盖了图像分类、目标检测、图像分割、目标识别、目标跟踪、图像质量分析、图像降噪与修复、图像增强、图像去模糊、图像超分辨、图像翻译与风格化、图像生成、三维重建、图像编辑等方向……

而应用领域则覆盖了交通行业，安防行业，娱乐创作行业、教育行业、医疗行业、电商零售行业、制造行业、养殖行业等范围。

自 2012 年 AlexNet 图像分类网络取得成功后，一系列新的基准模型被提出，使得图像识别领域率先取得商业大规模应用落地，其中最典型的当属 Google 图片、百度识图等以图搜图的图片检索引擎，可以应用于各类物品检索。

![img](https://i-blog.csdnimg.cn/blog_migrate/f3252b0328d33220c455010970db1512.png)

2015 年以后，人脸识别算法取得不断突破，如今在日常考勤，金融支付中已经是标准化技术，还可以被应用于犯罪分子抓捕、走失儿童与老人寻找，社会价值巨大。

![img](https://i-blog.csdnimg.cn/blog_migrate/3a19b8aba9abddfb465dfc5fa810960d.png)

随着目标检测与识别等技术的成熟，自动驾驶领域中的行人检测 、车辆检测、交通标志检测等感知能力大大提升，推动了自动驾驶商业化落地的进程。

![img](https://i-blog.csdnimg.cn/blog_migrate/d31302454f12e0d9d616cc1291592a07.png)

各类场景中的文字与标志识别精度达到了商业化落地水平，在诸如文档识别、身份证识别、车票识别、银行卡识别、车牌识别、发票识别、快递单识别、仪表盘读数识别等方向取得了落地，提高了这些任务的自动化水准。

![img](https://i-blog.csdnimg.cn/blog_migrate/08bf79961aabb206eb2196147e64ff45.png)

目标检测算法使得工业制造中的缺陷检测、目标计数也可以变得更加智能，降低人力成本和产品损耗，提高生产效率。

![img](https://i-blog.csdnimg.cn/blog_migrate/7e57a8836fccdd1bb619b89e47f8ee97.png)

除了识别相关的任务，深度学习在更底层的图像处理任务中也取得了长足的进步，典型的应用包括图像的自动裁剪，图像的自动增强，老照片的修复，图像分辨率的提升，图像的风格化等。

![img](https://i-blog.csdnimg.cn/blog_migrate/2edbd2f84110d89d689b03467ca87811.png)

![img](https://i-blog.csdnimg.cn/blog_migrate/3aef8cd0cdd8fcdd032d12a2880cdd06.png)

![img](https://i-blog.csdnimg.cn/blog_migrate/ca79b205213baf3a5a24bda825f808c6.png)

说到视觉里最前沿的技术，当属图像和视频的生成，随着 GAN 等技术的发展，如今已经可以生成纤毫毕现的图片和视频，达到真假难辨的水平，比如下图分别展示了生成的人脸和换脸的结果。

![img](https://i-blog.csdnimg.cn/blog_migrate/bd7fcff9cf30c9ac35beaa69eb408056.png)

![img](https://i-blog.csdnimg.cn/blog_migrate/52ac10d62d6ac45e69e6641780131cca.png)

随着二维图片的处理渐趋成熟，三维的图片处理成为了当下的热门，在表情驱动、人体驱动、姿态编辑、虚拟主播 、关键点定位、虚拟试妆中有着广阔的应用场景。

![img](https://i-blog.csdnimg.cn/blog_migrate/6d5bef03a0c3013210cba5e2b7033ae6.png)

下面视频中展示的虚拟主播，就应用到了三维人脸重建的技术。

点击边框调出视频工具条

当下我们还处于将图片处理技术迁移到视频中的重要时期，诸如视频分类、行为分析、视频生成与预测、视频检索、光流估计、关键帧提取、视频描述、视频剪辑等都是热门技术，这些都得益于深度学习技术的发展。

### 自然语言处理

自然语言处理技术被誉为人工智能皇冠上的明珠，自然语言处理的发展可以追溯到上个世纪 50 年代的图灵测试，经历了从规则到统计，再到现在的深度学习的发展过程。早期基于传统机器学习模型的自然语言处理算法一般都基于浅层模型 (如 SVM 和 logistic 回归)，这些模型都在非常高维和稀疏的特征 (one-hot encoding) 上进行训练和学习，会面临着维度爆炸等难以解决的问题。

现如今深度学习在自然语言处理领域也发挥着巨大的价值，典型的研究领域包括文本分类与聚类、文章标签与摘要提取、文本审核与舆情分析、机器翻译、阅读理解、问答系统与聊天机器人、搜索引擎、知识图谱、自然语言生成等方向……

在 2003 年，Bengio 等人在论文《A Neural Probabilistic Language Model》中提出了神经网络语言模型，作为副产品的词向量，掀开了用稠密的多维向量来编码词义的方式。Mikolov 等人在 2013 年做出的研究《Distributed Representations of Words and Phrases and their Compositionality》中真正使得从大规模语料中获得词向量变为现实。

此后，一些基本的方向包括词向量化，分词，词性标注，命名实体识别，文本结构化等研究逐渐成熟。

![img](https://i-blog.csdnimg.cn/blog_migrate/ed22e834a9b235e575dfaf73b248bf35.png)

它们可以直接被用于一些基础的文本处理任务，诸如快递地址自动识别与填充，文本文件的分类，文章标签与摘要提取，标题生成等。

![img](https://i-blog.csdnimg.cn/blog_migrate/b9b80a1b20ea762fa3f818171b997c2b.png)

![img](https://i-blog.csdnimg.cn/blog_migrate/0e2577a98ef74deae4332459abc7d36e.png)

随着互联网文本信息的增加，对文本中夹杂的色情、推广、辱骂、违禁违法等内容的检测有助于维护更健康的网络环境，自然语言处理在其中发挥着重要作用。

![img](https://i-blog.csdnimg.cn/blog_migrate/2bcba4c0bdfda6a01c569b39da632eb0.png)

同时，对带有情感色彩的主观性文本进行分析、处理和抽取，也在电影影评分析、商品口碑分析中有着重要作用，有助于提升消费者的使用体验。

![img](https://i-blog.csdnimg.cn/blog_migrate/f80ebb962100a8a3f4e52f593b5089c8.png)

作为一个非常具有难度而又商业价值巨大的领域，机器翻译一直是自然语言处理的核心问题，随着深度学习模型的发展，以 Google 为代表的公司已经开发出了非常强大的机器翻译算法，在各类翻译词典、翻译机、跨语言检索、语音同传应用中大大便利了人们的日常交流。

![img](https://i-blog.csdnimg.cn/blog_migrate/32338b4704b4b8b11d14651a5af2b190.png)

我们对于以机器人为代表的人工智能技术总是充满着非常高的期望，当下以百度小度为代表的问答机器人，阿里小蜜为代表的客服机器人，微软小冰为代表的聊天机器人，都已经在商业环境中正式上岗。

![img](https://i-blog.csdnimg.cn/blog_migrate/94ddbfc73943908d9592071d7e174590.png)

阅读理解，一向是复杂度非常高的人类推理行为，是深度学习大大推进了当下机器阅读理解的发展，利用算法使计算机理解文章语义并回答相关问题的技术，AI 在选择题、问答题、填充题等多项任务中不断取得突破，在某一些领域中甚至超过了人类水平。

![img](https://i-blog.csdnimg.cn/blog_migrate/4b2eb789b33b0f1177b5a241285d6113.png)

搜索引擎是当下我们获取信息的主要来源，通过自然语言理解技术，我们从基于关键字查询的检索迈入了面向自然语言理解的检索，不仅可以检索匹配关键词相关内容，还可以理解用户意图。当你搜索‘唐三的女儿和儿子叫什么’时，直接给出的是答案，而不是一些相关网页链接。

![img](https://i-blog.csdnimg.cn/blog_migrate/d96d06c1cc418a68edacaf089e130d2e.png)

而知识图谱的构建，则让信息的展示变得更加条理清晰，这得益于自然语言处理中的多项关键技术。

![img](https://i-blog.csdnimg.cn/blog_migrate/f820dac624cbda53d0866009bc698993.png)

当下基于深度学习的自然语言处理的最时髦的研究，莫过于自然语言生成 / 文本生成技术，不管是写新闻，写对联，还是写诗，都信手拈来。微软小冰甚至创作并且出版了人类历史上第一部 100% 由人工智能创造的诗集。

“树影压在秋天的报纸上 \ 中间隔着一片梦幻的海洋我凝视着一池湖水的天空 "，这般优美的诗句，都是来自 AI 的诗意。

![img](https://i-blog.csdnimg.cn/blog_migrate/449a26ce1b65fe6fbee9a43d5c1bc70d.png)

![img](https://i-blog.csdnimg.cn/blog_migrate/4a3b81d511238a5bde82b95388d6f9da.png)

在此之前，微软还让小冰在天涯、豆瓣、简书等平台，用 27 个笔名发表自己的诗歌，读者们还不知道 “骆梦”、“风的指尖”、“一荷”、“微笑的白” 这些笔名背后的诗人，其实并非人类。

当下自然语言处理已经能够完成较为复杂的任务，如何处理更多艺术和情感相关的任务，也是研究人员在慢慢解决的问题，人类与 AI 共存的时代，已然降临了。

### 推荐系统

人类从来没有像今天这样，被推荐系统如此深刻地支配过，仿佛找到了对抗选择强迫症的方法，不再需要自己去思考和搜索，只需要接受系统推荐过来的信息即可。

我们在互联网上留下的所有足迹，都被小心地搜集起来，然后被抽象成具体的标签，得到了千人千面的用户画像，被服务商用来推送有针对性的内容，所以你会感叹最懂你的不再是家人或者朋友，而是手机。

![img](https://i-blog.csdnimg.cn/blog_migrate/4c9b6c57c9e7585d8945e66fafde28c5.png)

从用户角度来看，推荐系统可以帮用户从海量信息中便捷地筛选出感兴趣的内容，在用户面对陌生领域时提供参考意见，满足用户的好奇心。而从系统角度来看，推荐系统可以帮系统筛选出高质量的用户群，提高留存率，提高广告的商业变现率，降低运营成本，提高内容的时效性、多样性，解决长尾信息的阅读问题。

所以你打开头条看到的是你想读的新闻， 打开淘宝看到的是你可能购买的商品，打开微信刷感兴趣的文章和视频，打开微博关注喜欢的博主，推送过来的东西精准又高效，这就是个性化推荐的效果。

![img](https://i-blog.csdnimg.cn/blog_migrate/8e73782d2a47c92b5c73fd751999bcad.png)

![img](https://i-blog.csdnimg.cn/blog_migrate/ccd7e431383e929b0b26242528d445ab.png)

![img](https://i-blog.csdnimg.cn/blog_migrate/80ac0757850273d265564918e2dfcc76.png)

![img](https://i-blog.csdnimg.cn/blog_migrate/62c40f1eedca904339e8b6995d794538.png)

能做到如此高效的推荐系统，背后得益于深度学习模型建模复杂特征，挖掘复杂关系的能力。如今商品推荐、新闻推荐、视频推荐、音乐推荐、美食推荐等已经成为了上网的标配，彻底改变了我们从互联网的信息海洋中获取自己感兴趣信息的方式。

### 结语

深度学习，并非是近十年诞生的新技术，而更像是新瓶装旧酒，在大数据的爆发，硬件计算能力飞速提升的大背景下，一系列新的工程技术不断被创新，让我们进入了一个更加智能化的时代，不断重组人们的生活和工作方式，创造商业传奇，这是值得当下每一个人关注的技术。

---

## 深度学习和云计算的关系

深度学习和云计算相互融合、相互促进，共同推动人工智能和信息技术的发展，在实际应用中，两者紧密结合，为各行业带来创新解决方案。

### 1. 云计算为深度学习提供支撑

#### 强大的计算能力

深度学习模型训练需要海量计算资源，如处理图像识别的卷积神经网络（CNN）、自然语言处理的循环神经网络（RNN）。云计算通过集群计算和并行处理技术，提供强大的计算能力。例如，亚马逊云科技的弹性计算云（EC2）允许用户按需获取计算资源，灵活调整配置，满足深度学习模型训练对计算力的高要求，加速训练过程，缩短研发周期。

#### 存储资源

深度学习涉及大量数据存储，如训练图像、文本等。云计算的分布式存储系统，如阿里云的对象存储 OSS，可提供高扩展性和可靠性的存储服务，方便存储和管理大规模数据，保障数据安全，便于数据共享和协作。

#### 降低成本

企业和研究机构采用云计算，无需自行构建和维护昂贵的硬件设施，按使用量付费，降低前期投入和运营成本，使更多组织能开展深度学习研究和应用开发。

#### 便捷的开发环境

云计算平台提供深度学习框架和工具，如 Google 的 TensorFlow、微软的 Azure Machine Learning，用户可直接使用，无需复杂安装和配置，提高开发效率。

### 2. 深度学习提升云计算服务能力

#### 优化资源调度

通过深度学习算法，如强化学习和时间序列预测，可以对云计算资源使用情况进行分析和预测，实现智能资源调度。根据用户需求和任务优先级，合理分配计算、存储和网络资源，提高资源利用率，降低能耗。

#### 提升服务质量

利用深度学习进行故障预测和智能运维，提前发现云计算系统潜在故障，及时采取措施，提高系统稳定性和可靠性。例如，通过分析系统日志和指标，识别异常模式，实现异常检测。还能优化网络流量管理，提升用户体验。

#### 拓展云计算应用场景

深度学习推动云计算在智能客服、图像和视频处理、智能推荐等领域的应用。智能客服借助深度学习理解用户问题并提供准确回答；图像和视频处理利用深度学习实现智能剪辑、内容识别；智能推荐系统基于深度学习分析用户行为和偏好，实现精准推荐。

### 3. 前沿发展趋势

#### 边缘计算

将深度学习模型部署到边缘设备，在本地进行数据处理，减少数据传输延迟，提高响应速度。例如，在智能交通系统中，边缘设备可以实时处理交通数据，提高交通管理效率。

#### 联邦学习

在保护用户数据隐私的前提下，利用多个客户端的数据进行模型训练。联邦学习允许不同的数据源共同训练模型，而不需要将数据集中到一个地方，从而提高数据隐私和安全性。

#### 无服务器深度学习

利用无服务器计算平台（如 AWS Lambda）运行深度学习模型，无需管理服务器，降低运维成本。无服务器架构可以自动扩展，根据需求动态调整资源，提高系统的灵活性和可靠性。

### 4. 对比分析

#### 使用云计算和深度学习的优势

在使用云计算和深度学习之前，企业可能需要花费大量时间和金钱来构建和维护自己的数据中心。通过云计算，企业可以按需获取计算资源，降低前期投入和运营成本。深度学习则可以通过智能资源调度和故障预测，提高系统的效率和稳定性。

#### 不使用云计算和深度学习的挑战

没有云计算和深度学习的支持，企业可能面临以下挑战：

* **高昂的硬件成本**
  ：需要自行构建和维护昂贵的硬件设施。
* **低效的资源利用**
  ：无法实现智能资源调度，导致资源利用率低。
* **高运维成本**
  ：需要大量的人力资源进行系统维护和故障排除。
* **低效的开发环境**
  ：开发人员需要花费大量时间进行复杂的安装和配置。

---

## via:

* 云计算技术 — 云计算技术发展编年史\_1846 穿孔指令带 - CSDN 博客
    
  <https://is-cloud.blog.csdn.net/article/details/99675664>
* 深度学习发展史（1943-2024 编年体）（The History of Deep Learning）-CSDN 博客
    
  <https://blog.csdn.net/dirolamo/article/details/139053653>
* 【杂谈】万字长文回顾深度学习的崛起背景，近10年在各行各业中的典型应用-CSDN博客
    
  <https://blog.csdn.net/hacker_long/article/details/114006159>