---
layout: post
title: "5个值得一试的开源大语言模型"
date: 2025-01-16 02:31:48 +0800
description: "本文为大家整理了5个效果优秀和开源大语言模型，供大家学"
keywords: "开源大语言模型"
categories: ['生成Ai']
tags: ['语言模型', '自然语言处理', '人工智能', 'Nlp', 'Chatgpt']
artid: "130812095"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=130812095
    alt: "5个值得一试的开源大语言模型"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=130812095
featuredImagePreview: https://bing.ee123.net/img/rand?artid=130812095
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     5个值得一试的开源大语言模型
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-tomorrow-night" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h2 align="center">
     5个值得一试的开源大语言模型
    </h2>
    <p>
     人工智能已经成为我们生活中不可或缺的一部分，而LLM（大型语言模型）处于这一变化的最前沿。 在对话式人工智能方面，大语言模型的性能最为关键。 虽然像 OpenAI 的 GPT-4 这样的商业大语言模型已经引起了所有人的关注，但开源模型在性能和流行度方面正在迅速赶上。 在社区和机构的不断贡献下，开发人员现在有机会访问更强大的开源对话式 AI 模型。这些开源模型得益于源代码开放的天然优势，可以提供更好的灵活性、更广泛的社区支持、更透明的技术细节，关键是可以极大节约时间和降低成本。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/510d4958f97b5d7a1308339d432a7c44.png#pic_center"/>
    </p>
    <p>
     “模型开源”与“代码开源”不完全相同。虽然“开源”一词通常意味着源代码可供任何人使用、修改和分发，但人工智能模型开源可能并非总是如此。 例如，一些“开源”模型是部分开源的，因为它们是从 LLaMA 进行微调的，而 LLaMA 并未完全向公众开源，而且模型训练的数据集有时也是私有不开放的。另外需要注意的是，这些模型可能是开源的，但具有限制它们使用方式的限制性许可条件。因此，大家在使用开源模型时，一定要仔细考虑“开源”在每个特定情况下的含义，并且仔细阅读开源许可和使用条款。
    </p>
    <p>
    </p>
    <div class="toc">
     <h4>
      文章目录
     </h4>
     <ul>
      <li>
       <ul>
        <li>
         <a href="#_11" rel="nofollow">
          半开源模型
         </a>
        </li>
        <li>
         <ul>
          <li>
           <a href="#1_Vicuna_13" rel="nofollow">
            1. Vicuna
           </a>
          </li>
          <li>
           <a href="#2_GPT4ALL_29" rel="nofollow">
            2. GPT4ALL
           </a>
          </li>
          <li>
           <a href="#3_Koala_46" rel="nofollow">
            3. Koala
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a href="#_62" rel="nofollow">
          全开源模型
         </a>
        </li>
        <li>
         <ul>
          <li>
           <a href="#4_Dolly_20_64" rel="nofollow">
            4. Dolly 2.0
           </a>
          </li>
          <li>
           <a href="#5_OpenAssistant_85" rel="nofollow">
            5. OpenAssistant
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <p>
    </p>
    <h3>
     <a id="_11">
     </a>
     半开源模型
    </h3>
    <h4>
     <a id="1_Vicuna_13">
     </a>
     1. Vicuna
    </h4>
    <p>
     <img alt="img" src="https://i-blog.csdnimg.cn/blog_migrate/bbad5a6bfcedbc34c3133ea9c859a45c.jpeg#pic_center"/>
    </p>
    <ul>
     <li>
      <strong>
       官网
      </strong>
      : https://vicuna.lmsys.org/
     </li>
     <li>
      <strong>
       GitHub
      </strong>
      : https://github.com/lm-sys/FastChat
     </li>
     <li>
      <strong>
       Demo
      </strong>
      : https://chat.lmsys.org/
     </li>
    </ul>
    <p>
     Vicuna 是最近最炙手可热的开源聊天机器人模型。 据说该模型效果接近 90% 的 ChatGPT 质量，令人印象深刻。该模型基于经过微调的 LLaMa-13B 模型，由一群来自美国多个著名机构的天才开发者开发。 Vicuna 根据从 ShareGPT 获取的对话数据集进行了微调，ShareGPT 是一个可以发布使用 ChatGPT 进行的不同对话的网站。
    </p>
    <p>
     为了对 Vicuna 进行基准测试，开发人员使用了一种有趣的方法。 他们向 Alpaca、Bard 和 ChatGPT 等不同模型提供提示，然后为每个模型生成一个分数。 结果，LLaMa 得分最低，因为它没有微调，而 Alpaca 表现不错。 然而，Vicuna 的表现优于 Alpaca，并且在测试中非常接近 Bard。 ChatGPT 得分为 100%，因为这是对标的模型。
    </p>
    <p>
     值得注意的是，为聊天机器人构建评估体系依然是一个悬而未决的问题，需要进一步研究。 如何针对不同的模型制定出最佳的提示策略是研究的重要方向之一，因此针对单一模型的评估方法仍然很有价值。
    </p>
    <p>
     <img alt="img" src="https://i-blog.csdnimg.cn/blog_migrate/29fd68dd7c87df08cc1653b8747943af.png#pic_center"/>
    </p>
    <h4>
     <a id="2_GPT4ALL_29">
     </a>
     2. GPT4ALL
    </h4>
    <p>
     <img alt="img" src="https://i-blog.csdnimg.cn/blog_migrate/3f691da8e1381ce6e185dd926ee2fc5d.png#pic_center"/>
    </p>
    <ul>
     <li>
      <strong>
       官网
      </strong>
      : https://gpt4all.io/index.html
     </li>
     <li>
      <strong>
       GitHub
      </strong>
      : https://github.com/nomic-ai/gpt4all
     </li>
     <li>
      <strong>
       Python API
      </strong>
      : https://github.com/nomic-ai/pygpt4all
     </li>
     <li>
      <strong>
       Web UI
      </strong>
      : https://github.com/nomic-ai/gpt4all-ui
     </li>
    </ul>
    <p>
     GPT4ALL 是最近发布的语言模型，一经推出就在 NLP 社区引起轰动。 它是由一家名为 Nomic AI 的公司在 LLaMA 语言模型之上构建的，可以用于商业目的（有在 Apache-2 许可下发布的 GPT4ALL-J）。 然而，需要注意的是，用于训练模型的数据是使用 OpenAI 的 GPT-3.5 turbo API 生成的，这可能是会违反 OpenAI 的服务条款。 因此，在更好地理解其训练数据的法律含义之前，不建议将该模型用于商业目的。
    </p>
    <p>
     GPT4ALL 是一个有趣的项目，它建立在 Alpaca 和其他语言模型的工作之上，使用特定数据集微调语言模型并对其进行扩展，通过使用大量的提示-响应对来训练更健壮和通用的模型。 提示-响应对使用 GPT-3.5 turbo 生成，生成的数据集使用 Nomic AI 开发的工具进行过滤，该工具可以轻松搜索和过滤提示-响应对。
    </p>
    <p>
     GPT4ALL 另一个有趣的特性是它能够在 Apple 的 M1 和 M2 芯片上运行。这个特性让 GPT4ALL 可以在笔记本电脑、手机等便携式设备上运行。GPT4ALL 的创建者提供了在这些设备上设置模型的详细说明，这使得用户可以轻松上手该工具。
    </p>
    <p>
     性能方面，GPT4ALL 可与一众最先进的语言模型相媲美。 Nomic AI 报告称，该模型实现了较低的事实困惑度，这是语言模型广泛使用的基准。这表明 GPT4ALL 能够对范围广阔的提示生成高质量的响应，并且能够处理复杂而细微的语言任务。
    </p>
    <h4>
     <a id="3_Koala_46">
     </a>
     3. Koala
    </h4>
    <p>
     <img alt="img" src="https://i-blog.csdnimg.cn/blog_migrate/19298b83b1fb44a962a7404ac072af18.png#pic_center"/>
    </p>
    <ul>
     <li>
      <strong>
       主页
      </strong>
      : https://bair.berkeley.edu/blog/2023/04/03/koala/
     </li>
     <li>
      <strong>
       GitHub
      </strong>
      : https://github.com/young-geng/EasyLM
     </li>
     <li>
      <strong>
       Demo
      </strong>
      : https://chat.lmsys.org/?model=koala-13b
     </li>
    </ul>
    <p>
     Koala 模型是为学术研究而创建的对话模型，在基于对话的两种类型（Distillation Data/Open-source Data）监督微调数据集上进行了训练。该模型建立在 LLaMA 之上，并且评估表现通常优于 Alpaca ，并且在超过一半的情况下与 ChatGPT 接近。
    </p>
    <p>
     Koala 主要利用从网络上抓取的数据进行训练，大部分是对话数据，包括来自 ChatGPT 和其他公共数据集的数据。 构建 Koala 的 LLaMA 模型接受了数万亿 token 的训练，使其始终成为强大的科研模型。Koala 的训练代码、模型权重以及权重增量都在 Meta AI 的许可限制下公开可用 。100 名不同人士使用 Amazon Mechanical Turk 对该模型进行了对话微调和评估。
    </p>
    <p>
     用于训练 Koala 的数据集是高质量小数据集的集合，包括来自 SharedGPT 的 ChatGPT 蒸馏数据，去重和去除非英语数据后包含约 30,000 个示例。 实际训练中使用了更多的数据集，例如 Human GPT Comparison Corpus 和其他开源数据集，例如 30K Open Instruction Generalist standard Stanford 数据集，20K OpenAI webGPT 和 93K OpenAI summarization。 这些是公开可用的各种数据集，都在训练期间使用过。
    </p>
    <p>
     Koala 的优势不在于数据量，而在于数据质量。他们精选了问答、人类反馈和与现有大型语言模型对话的组合来创建用于训练 Koala 的数据集。 人类评估在提高 Koala 表现方面起着至关重要的作用。
    </p>
    <h3>
     <a id="_62">
     </a>
     全开源模型
    </h3>
    <h4>
     <a id="4_Dolly_20_64">
     </a>
     4. Dolly 2.0
    </h4>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/083a33784cb7c2f7fab37cda09ea0970.png#pic_center"/>
    </p>
    <ul>
     <li>
      <strong>
       博客主页
      </strong>
      : https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm
     </li>
     <li>
      <strong>
       GitHub
      </strong>
      : https://github.com/databrickslabs/dolly/
     </li>
     <li>
      <strong>
       Huggingface 主页
      </strong>
      : https://huggingface.co/databricks/dolly-v2-12b
     </li>
    </ul>
    <p>
     Dolly 2.0 是 Databricks 最近发布的模型，这是 Dolly 模型的第二个版本。 Databricks 开发 Dolly 2.0 的目标是制作一个既可用于商业又可用于研究的模型。他们所做的主要改动之一是将基础模型由 LLaMa 换成 Pythia，然后对其微调以获得出色的效果。Databricks 意识到他们之前使用的基于 ChatGPT 或 GPT-3 生成的数据集不适合商业用途，因此他们创建了一个包含 15,000 个指令任务的新数据集，并由公司 5,000 名员工标记了数据。
    </p>
    <p>
     Databricks 让员工标注数据包括七项具体任务：
    </p>
    <ul>
     <li>
      开放式问答，涉及提出可能有或可能没有正确答案的问题，需要了解世界。
     </li>
     <li>
      封闭式问答，可以使用参考文本中的信息回答问题。
     </li>
     <li>
      从维基百科中提取信息，注释者在其中复制段落并提取事实信息。
     </li>
     <li>
      通过将段落提炼成简短的摘要来总结来自维基百科的信息。
     </li>
     <li>
      头脑风暴，要求开放式构思和可能选项列表。
     </li>
     <li>
      分类，注释者在其中对类成员资格或文本属性做出判断。
     </li>
     <li>
      创意写作涉及写诗或情书等任务。
     </li>
    </ul>
    <h4>
     <a id="5_OpenAssistant_85">
     </a>
     5. OpenAssistant
    </h4>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/b0f74c2d478d95ba048f1ce0653792c2.png#pic_center"/>
    </p>
    <ul>
     <li>
      <strong>
       主页
      </strong>
      : https://open-assistant.io/
     </li>
     <li>
      <strong>
       GitHub
      </strong>
      : https://github.com/LAION-AI/Open-Assistant
     </li>
     <li>
      <strong>
       Demo
      </strong>
      : https://open-assistant.io/chat
     </li>
    </ul>
    <p>
     Open Assistant 是由 Yannic Kilcher，一位备受欢迎的 YouTube博主，以及来自 LAION AI 和开源社区的一些开发者发起的项目。 该项目旨在构建一个完全开源的 ChatGPT 风格的项目。允许用户在线使用该模型或根据特定需求对其进行微调。
    </p>
    <p>
     Open Assistant 的用户界面跟 ChatGPT 非常类似，都是对话式交互。用户可以单击进入不同的聊天并开始与模型对话。到目前为止，oasst-sft-6-llama-30b 模式是列表中唯一可选的模型，它在 Open Assistant 数据集上进行了监督微调，并可通过多个预设参数进行调整，例如
     <code>
      top-k
     </code>
     ，
     <code>
      top-p
     </code>
     ，
     <code>
      temperature
     </code>
     。 Open Assistant会根据社区反馈更改这些设置以获得更好的响应。
    </p>
    <p>
     <img alt="img" src="https://i-blog.csdnimg.cn/blog_migrate/264b544279286d831f5246e062b75973.png#pic_center"/>
    </p>
    <p>
     Open Assistant 最吸引人也是最独特的部分是其基于 Web 的仪表板，它允许用户完成任务并帮助训练 AI 模型。 用户可以从各种类型的任务中进行选择，例如对提示进行分类或对模型回复进行排名。完成任务会获得积分，用户可以在仪表板上跟踪他们的进度和级别。甚至会显示排名前 5 的贡献者。这是模型创建者需要考虑的关键事项，因为模型访问的数据越多（越开放），其性能就越好。一套友好的用户界面是大家积极使用并为项目做出贡献的好方法。
    </p>
    <p>
     <img alt="img" src="https://i-blog.csdnimg.cn/blog_migrate/bdcd916910761223f679740ec5994374.png#pic_center"/>
    </p>
    <p>
     如果您想基于 Open Assistant 开发应用，可以查看 Open Assistant 的 GitHub 代码库。该项目发布了许多不同的模型，还发布了完整的数据集。
    </p>
    <hr/>
    <p>
     以上是本文全部内容。
    </p>
    <p>
     希望您能从本文中有所收获，感谢您的阅读！
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="6874747073:3a2f2f626c6f672e6373646e2e6e65742f6a61726f6479762f:61727469636c652f64657461696c732f313330383132303935" class_="artid" style="display:none">
 </p>
</div>


