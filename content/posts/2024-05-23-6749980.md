---
arturl_encode: "687474:70733a2f2f626c6f672e6373646e2e6e65742f666f726d6973:732f61727469636c652f64657461696c732f36373439393830"
layout: post
title: "通信工具的音视频的网络传输实现"
date: 2024-05-23 16:14:01 +0800
description: "当下比较流行的即时通信工具，比如MSN，QQ等都实现了视音频的功能，通过视频，音频，我们可以更好的和"
keywords: "视频怎么在通信中传输"
categories: ['未分类']
tags: ['网络', '工具', '图形', 'Null', 'Graph', 'Filter']
artid: "6749980"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=6749980
  alt: "通信工具的音视频的网络传输实现"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=6749980
featuredImagePreview: https://bing.ee123.net/img/rand?artid=6749980
---

# 通信工具的音视频的网络传输实现

当下比较流行的即时通信工具，比如MSN
，

QQ

等都实现了视音频的功能，通过视频，音频，我们可以更好的和朋友通过网络进行沟通，本文通过

DirectShow

技术模拟

QQ

实现了视频和音频的采集，传输，基本实现了

QQ

的视音频聊天的功能。

网络音视频系统主要功能就在于视音频的采集，网络传输两个方面，通过Video Capture
系列

API

函数，你就可以轻松的搞定视频捕捉，但是对于视频的网络传输，则要费一番功夫了。
对于视音频数据的传输，只简单地使用数据报套接字传输音视频数据是不可行的，还必须在UDP
层上采用

RTP

（实时传输协议）和

RTCP

（实时传输控制协议）来改善服务质量。
实时传输协议提供具有实时特征的、端到端的数据传输服务。我们在音视频数据前插入包含有载荷标识、序号、时间戳和同步源标识符的
RTP

包头，然后利用数据报套接字在

IP

网络上传输

RTP

包，以此改善连续重放效果和音视频同步。实时传输控制协议

RTCP

用于

RTP

的控制，它最基本的功能是利用发送者报告和接收者报告来推断网络的服务质量，若拥塞状况严重，则改用低速率编码标准或降低数据传输比特率，以减少网络负荷，提供较好的

Q.S

保证。

Directshow
对于音视频的采集提供了很好的接口，利用

ICaptureGraphBuilder2

接口可以很轻松的建立起视频捕捉的

graph

图，通过枚举音频设备

Filter

，也可以很轻松的实现音频的捕捉
，有点麻烦的是音视频数据的传输，我们可以自己封装
RTP

和

RTCP

的协议，来自己实现一个

filter

，用来发送和接收音视频数据，当然了

Directshow

也提供了一组支持使用

RTP

协议的网络传输多媒体流的

Filters

。你也完全可以用

Directshow

提供的

RTP

系列的

filter

实现数据的传输。

下面分析一下这些RTP Filters
。

新定义的Filter
包括

RTP Source Filter

，

RTP Render Filter

，

RTP Demux Filter

，

RTP Receive Playload Handler (RPH) filter

，

RTP Send Payload (SPH) filter

，使用这

5

个

filter

构建一个通过

RTP

协议传输音视频数据的

Graph

是没有问题的。

RTP Source filter
被用来从一个单独的

RTP
会话中接收RTP
和

RTCP

包。这个

filter

提供一个指定发送给其它主机

RTCP

接收器报告和指定网络地址和端口接口来接收

RTP

会话的接口。

RTP Rend filter
是用来将数据发到网络上的一个

filter

，这个

filter

也提供了和

RTP source Filter
类似的接口。

RTP Demux filter
用来多路分离来自

RTP Source filter

的

RTP
包，这个filter
有一个或者多个输出的

pin

。这个

Filter

提供了如何控制多路分离和如何分配到特定输出

pin

的接口。

RTP RPH Filter 是用来网络过来的RTP
包还原成原来的数据格式，主要支持

H.261

，

H.263

，

Indeo

，

G.711

，

G.723

和

G.729

和常见的多种音视频负载类型。

RTP SPH filter
则和

RPH filter

的功能相对，它的任务是将音视频 压缩

filter

输出的
数据分解为RTP
包，它提供的接口有指定最大生成包大小和

pt

值。

下面我们看看如何用这些filter
来搭建我们采集和传输的

graph

图。

图1
和图

2

展示了

DirectShow RTP

中定义的

filters

如何运用。图

1

是一个采集本地多媒体数据并使用

RTP

协议通过网络发送的

filter graph

。它包含一个输出原始视频帧的视频采集

filter

，紧跟一个压缩帧的编码

filter

。一旦压缩，这些帧就会被发送到

RTP SPH filter

，分片打包，生成

RTP

包，对应的发送到

RTP Render filter

，通过网络传输这些包。图

2

展现了一个

filter graph

，用来接收包含视频流

RTP

包，播放视频。这个

graph

由一个用来接收包的

RTP Source filter

，一个根据源和负载类型进行分类的

RTP Demux filter

，一个把

RTP

包转为压缩视频帧的

RTP RPH filter

组成。这些

filter

随后的是用来解压帧的解码

filter

，一个显示未压缩帧的渲染

filter

。

有了RTP filter
的帮助我们就可以完成类似

qq

的功能了，可以实现在网络上进行视频和音频的交互了，下面我给出在网络上两个客户端

A

和

B

进行音频和视频交互的

Graph

图。这里我对图

1

和图

2

中的

RTP filter

进行了自己封装，将编解码

filter

直接封装到了

RTP Source filter

和

RTP Render filter

中，这样

Graph

图就显得很简洁，

RTP Source filter

只是用来接收网络过来的音视频数据，然后将数据传递给客户程序，

RTP Render filter

则是将采集到的音视频数据发送到网络上的另一个客户端，编解码则的工作则封装到这两个

filter

之中。

如果你也想自己封装自己的Source
和

Render filter

，首先你要选择自己的编解码，视频编解码是选择

H261

，

H263

，还是

MEPG4

，音频是选择

G729

还是

G711

，要首先确定好。选好编解码，封装的工作就简单了。

不多说了，下面看看我给出的代码吧。

static const GUID CLSID\_FG729Render = { 0x3556f7d8, 0x5b5, 0x4015, { 0xb9, 0x40, 0x65, 0xb8, 0x8, 0x94, 0xc8, 0xf9 } }; //音频发送

static const GUID CLSID\_FG729Source = { 0x290bf11a, 0x93b4, 0x4662, { 0xb1, 0xa3, 0xa, 0x53, 0x51, 0xeb, 0xe5, 0x8e } };//音频接收

static const GUID CLSID\_FH263Source = { 0xa0431ccf, 0x75db, 0x463e, { 0xb1, 0xcd, 0xe, 0x9d, 0xb6, 0x67, 0xba, 0x72 } };//视频接收

static const GUID CLSID\_FH263Render = { 0x787969cf, 0xc1b6, 0x41c5, { 0xba, 0xa8, 0x4e, 0xff, 0xa3, 0xdb, 0xe4, 0x1f } };//视频发送

//发送和接收音视频数据的filter

CComPtr< IBaseFilter > m\_pAudioRtpRender ;

CComPtr< IBaseFilter > m\_pAudioRtpSource ;

CComPtr< IBaseFilter > m\_pVideoRtpRender ;

CComPtr< IBaseFilter > m\_pVideoRtpSource ;

char szClientA[100];

int iVideoPort = 9937;

int iAudioPort = 9938;

//构建视频的graph图,并发送数据

CComPtr< IGraphBuilder > m\_pVideoGraphBuilder; //视频图形管理器

CComPtr< ICaptureGraphBuilder2 > m\_pVideoCapGraphBuilder;

CComPtr< IBaseFilter > m\_pFilterVideoCap;

CComPtr< IVideoWindow > m\_pVideoWindow;

CComPtr< IMediaControl > m\_pVideoMediaCtrl ;

CComPtr< IBaseFilter > m\_pVideoRenderFilter;

HRESULT CMyDialog::VideoGraphInitAndSend(){

HRESULT hr;

hr =m\_pVideoGraphBuilder.CoCreateInstance( CLSID\_FilterGraph );

if(FAILED(hr))

return hr;

hr =m\_pVideoCapGraphBuilder.CoCreateInstance( CLSID\_CaptureGraphBuilder2);

if(FAILED (hr))

return hr;

m\_pVideoCapGraphBuilder->SetFiltergraph(m\_pVideoGraphBuilder);

m\_pVideoGraphBuilder->QueryInterface(IID\_IMediaControl,(void\*\*)&m\_pVideoMediaCtrl);

m\_pVideoGraphBuilder->QueryInterface(IID\_IVideoWindow,(void\*\*)&m\_pVideoWindow);

FindDeviceFilter(&m\_pFilterVideoCap,CLSID\_VideoInputDeviceCategory);

if(m\_pFilterVideoCap)

m\_pVideoGraphBuilder->AddFilter( m\_pFilterVideoCap,T2W("VideoCap") ) ;

//创建预览的filter

hr = m\_pRenderFilterVideo.CoCreateInstance(CLSID\_VideoRenderer);

if(FAILED(hr))

return hr;

m\_pVideoGraphBuilder->AddFilter( m\_pRenderFilterVideo, L"VideoRenderFilter" );

Connect(m\_pFilterVideoCap ,m\_pRenderFilterVideo);

//设置预览的窗口

CRect rc ;

GetClientRect(m\_hOwnerWnd, &rc );

int iWidth = rc.right - rc.left ;

int iHeight = rc.bottom - rc.top ;

int iLeft, iTop;

if((iHeight\*1.0)/(iWidth\*1.0) >= 0.75){

//按宽度算

int tmpiHeight = iWidth\*3/4;

iTop = (iHeight - tmpiHeight)/2;

int tmpiHeight = iWidth\*3/4;

iTop = (iHeight - tmpiHeight)/2;

iHeight = tmpiHeight;

iLeft = 0;

}

else

{//按高度算

int tmpiWidth = iHeight\*4/3;

iLeft = (iWidth - tmpiWidth)/2;

iWidth = tmpiWidth;

iTop = 0;

}

m\_pVideoWindow->put\_Owner( (OAHWND) m\_hRenderWnd ) ;

m\_pVideoWindow->put\_Visible( OATRUE );

m\_pVideoWindow->put\_WindowStyle( WS\_CHILD | WS\_CLIPSIBLINGS ) ;

m\_pVideoMediaCtrl->Run();

return S\_OK;

}

//

HRESULT FindDeviceFilter(IBaseFilter \*\* ppSrcFilter,GUID deviceGUID){

HRESULT hr;

IBaseFilter \* pSrc = NULL;

CComPtr <IMoniker> pMoniker =NULL;

ULONG cFetched;

if (!ppSrcFilter)

return E\_POINTER;

// Create the system device enumerator

CComPtr <ICreateDevEnum> pDevEnum =NULL;

hr = CoCreateInstance (CLSID\_SystemDeviceEnum, NULL, CLSCTX\_INPROC,IID\_ICreateDevEnum, (void \*\*) &pDevEnum);

if (FAILED(hr))

return hr;

// Create an enumerator for the video capture devices

CComPtr <IEnumMoniker> pClassEnum = NULL;

hr = pDevEnum->CreateClassEnumerator (deviceGUID, &pClassEnum, 0);

if (FAILED(hr))

return hr;

if (pClassEnum == NULL)

return E\_FAIL;

if (S\_OK == (pClassEnum->Next (1, &pMoniker, &cFetched)))

{

hr = pMoniker->BindToObject(0,0,IID\_IBaseFilter, (void\*\*)&pSrc);

if (FAILED(hr))

return hr;

}

else

return E\_FAIL;

\*ppSrcFilter = pSrc;

return S\_OK;

}

//构建音频Graph图，并发送

CComPtr< IGraphBuilder > m\_pAudioGraphBuilder; //音频图形管理器

CComPtr< ICaptureGraphBuilder2 > m\_pCapAudioGraphBuilder;

CComPtr< IBaseFilter > m\_pFilterAudioCap;

CComPtr< IMediaControl > m\_pAudioMediaCtrl ;

HRESULT AudioGraphInit()

{

HRESULT hr;

hr =m\_pAudioGraphBuilder.CoCreateInstance( CLSID\_FilterGraph );

if(FAILED(hr))

return hr;

hr =m\_pCapAudioGraphBuilder.CoCreateInstance( CLSID\_CaptureGraphBuilder2);

if(FAILED (hr))

return hr;

m\_pAudioGraphBuilder->SetFiltergraph(m\_pCapAudioGraphBuilder);

m\_pAudioGraphBuilder->QueryInterface(IID\_IMediaControl, (void \*\*)&m\_pAudioMediaCtrl);

FindDeviceFilter(&m\_pFilterVideoCap,CLSID\_AudioInputDeviceCategory);

if(m\_pFilterAudioCap)

m\_pAudioGraphBuilder->AddFilter( m\_pFilterAudioCap,T2W("AudioCap") ) ;

//发送到网络

hr =::CoCreateInstance(CLSID\_FG729Render,NULL,CLSCTX\_INPROC,

IID\_IBaseFilter,(void\*\*)&m\_pFilterRtpSendAudio)

if(FAILED(hr))

return hr;

m\_pAudioGraphBuilder->AddFilter(m\_pAudioRtpRender, L"FilterRtpSendAudio");

Connect(m\_pFilterAudioCap,m\_pAudioRtpRender);

CComPtr< IRtpOption > pOption ;

m\_pAudioRtpRender->QueryInterface(IID\_IJRTPOption,(void\*\*)&pOption);

hr =pOption->Connect(szClientA,iAudioPort,1024);

if(FAILED(hr))

return hr;

m\_pAudioMediaCtrl->Run();

return S\_OK;}

//音频的接收

CComPtr< IGraphBuilder > m\_pAudioGraphBuilder; //音频图形管理器

CComPtr< ICaptureGraphBuilder2 > m\_pCapAudioGraphBuilder;

CComPtr< IBaseFilter > m\_pFilterAudioCap;

CComPtr< IMediaControl > m\_pAudioMediaCtrl ;

CComPtr<IBaseFilter> m\_pAudioRender;

HRESULT AudioRecive()

{

HRESULT hr;

hr =m\_pAudioGraphBuilder.CoCreateInstance( CLSID\_FilterGraph );

if(FAILED(hr))

return hr;

m\_pAudioGraphBuilder->QueryInterface(IID\_IMediaControl, (void \*\*)&m\_pAudioMediaCtrl);

hr = m\_pAudioRtpSource->CoCreateInstance(CLSID\_FG729Source) ;

if(FAILED(hr))

return hr;

m\_pAudioGraphBuilder->AddFilter(m\_pAudioRtpSource,L"AudioRtp");

//创建声卡Renderfilter

FindDeviceFilter(&m\_pAudioRender,CLSID\_AudioRendererCategory);

m\_pAudioGraphBuilder->AddFilter(m\_pAudioRender,L"AudioRender");

CComPtr< IRtpOption > pRtpOption ;

m\_pAudioRtpSource->QueryInterface(IID\_IJRTPOption,(void\*\*)&pRtpOption);

hr= pRtpOption->Connect(szClientA,iAudioPort+2,1024);

if(FAILED (hr))

return hr;

Connect(m\_pAudioRtpSource,m\_pAudioRender);

m\_pAudioMediaCtrl->Run();

return S\_OK;

}