---
layout: post
title: "python做的网站有哪些,用python编写的网站"
date: 2025-01-06 17:40:33 +0800
description: "可依据不同的主题存储到Excel不同的Sheet ，采用User Agent伪装为浏览器进行爬取，并"
keywords: "python开发的网站"
categories: ['未分类']
tags: ['Python']
artid: "138390401"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=138390401
  alt: "python做的网站有哪些,用python编写的网站"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=138390401
featuredImagePreview: https://bing.ee123.net/img/rand?artid=138390401
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     python做的网站有哪些,用python编写的网站
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     本篇文章给大家谈谈python做的网站有哪些，以及用python编写的网站，希望对各位有所帮助，不要忘了收藏本站喔。
    </p>
    <p>
    </p>
    <p class="img-center">
     <img alt="" height="500" src="https://i-blog.csdnimg.cn/blog_migrate/6a570251a113ed49ecf30ef81ae923de.png" width="779"/>
    </p>
    <div id="article_content">
    </div>
    <div id="content_views">
     <p>
      刚从github上搜来19个常用的Python爬虫，技多不压身，觉得好用就收藏。
     </p>
     <h4>
      <a id="1_4">
      </a>
      1.微信公众号爬虫
     </h4>
     <p>
      GitHub：https://github.com/Chyroc/WechatSogou
     </p>
     <p>
      基于搜狗微信搜索的微信公众号爬虫接口，可以扩展成基于搜狗搜索的爬虫，返回结果是列表，每一项均是公众号具体信息字典
      <a href="http://yc.gptgaixie.com/article/151.html" rel="nofollow" title="python弧形7段数码管绘制">
       python弧形7段数码管绘制
      </a>
      。
     </p>
     <h4>
      <a id="2_14">
      </a>
      2.豆瓣读书爬虫
     </h4>
     <p>
      GitHub：https://github.com/lanbing510/DouBanSpider
     </p>
     <p>
      可以爬下豆瓣读书标签下的所有图书，按评分排名依次存储，存储到Excel中，可方便大家筛选搜罗，比如筛选评价人数&gt;1000的高分书籍；可依据不同的主题存储到Excel不同的Sheet ，采用User Agent伪装为浏览器进行爬取，并加入随机延时来更好的模仿浏览器行为，避免爬虫被封。
     </p>
     <h4>
      <a id="3_24">
      </a>
      3.知乎爬虫
     </h4>
     <p>
      GitHub：https://github.com/LiuRoy/zhihu_spider
     </p>
     <p>
      此项目的功能是爬取知乎用户信息以及人际拓扑关系，爬虫框架使用scrapy，数据存储使用mongo
     </p>
     <h4>
      <a id="4Bilibili_34">
      </a>
      4.Bilibili用户爬虫
     </h4>
     <p>
      GitHub：https://github.com/airingursb/bilibili-user
     </p>
     <p>
      总数据数：20119918，抓取字段：用户id，昵称，性别，头像，等级，经验值，粉丝数，生日，地址，注册时间，签名，等级与经验值等。抓取之后生成B站用户数据报告。
     </p>
     <h4>
      <a id="5_43">
      </a>
      5.新浪微博爬虫
     </h4>
     <p>
      GitHub：https://github.com/LiuXingMing/SinaSpider
     </p>
     <p>
      主要爬取新浪微博用户的个人信息、微博信息、粉丝和关注。代码获取新浪微博Cookie进行登录，可通过多账号登录来防止新浪的反扒。主要使用 scrapy 爬虫框架。
     </p>
     <h4>
      <a id="6_51">
      </a>
      6.小说下载分布式爬虫
     </h4>
     <p>
      GitHub：https://github.com/gnemoug/distribute_crawler
     </p>
     <p>
      使用scrapy,Redis, MongoDB,graphite实现的一个分布式网络爬虫,底层存储MongoDB集群,分布式使用Redis实现,爬虫状态显示使用graphite实现，主要针对一个小说站点。
     </p>
     <h4>
      <a id="7__60">
      </a>
      7. 中国知网爬虫
     </h4>
     <p>
      GitHub：https://github.com/yanzhou/CnkiSpider
     </p>
     <p>
      设置检索条件后，执行src/CnkiSpider.py抓取数据，抓取数据存储在/data目录下，每个数据文件的第一行为字段名称。
     </p>
     <h4>
      <a id="8_68">
      </a>
      8.链家网爬虫
     </h4>
     <p>
      GitHub：https://github.com/lanbing510/LianJiaSpider
     </p>
     <p>
      爬取北京地区链家历年二手房成交记录。涵盖链家爬虫一文的全部代码，包括链家模拟登录代码。
     </p>
     <h4>
      <a id="9_78">
      </a>
      9.京东爬虫
     </h4>
     <p>
      GitHub：https://github.com/taizilongxu/scrapy_jingdong
     </p>
     <p>
      基于scrapy的京东网站爬虫，保存格式为csv。
     </p>
     <h4>
      <a id="10QQ__88">
      </a>
      10.QQ 群爬虫
     </h4>
     <p>
      GitHub：https://github.com/caspartse/QQ-Groups-Spider
     </p>
     <p>
      批量抓取 QQ 群信息，包括群名称、群号、群人数、群主、群简介等内容，最终生成 XLS(X) / CSV 结果文件。
     </p>
     <h4>
      <a id="11_98">
      </a>
      11.乌云爬虫
     </h4>
     <p>
      GitHub：https://github.com/hanc00l/wooyun_public
     </p>
     <p>
      乌云公开漏洞、知识库爬虫和搜索。全部公开漏洞的列表和每个漏洞的文本内容存在MongoDB中，大概约2G内容；如果整站爬全部文本和图片作为离线查询，大概需要10G空间、2小时（10M电信带宽）；爬取全部知识库，总共约500M空间。漏洞搜索使用了Flask作为web server，bootstrap作为前端。
     </p>
     <h4>
      <a id="12hao123_108">
      </a>
      12.hao123网站爬虫
     </h4>
     <p>
      GitHub：https://github.com/buckyroberts/Spider
     </p>
     <p>
      以hao123为入口页面，滚动爬取外链，收集网址，并记录网址上的内链和外链数目，记录title等信息，windows7 32位上测试，目前每24个小时，可收集数据为10万左右。
     </p>
     <h4>
      <a id="13_118">
      </a>
      13.机票爬虫（去哪儿和携程网）
     </h4>
     <p>
      GitHub：https://github.com/fankcoder/findtrip
     </p>
     <p>
      Findtrip是一个基于Scrapy的机票爬虫，目前整合了国内两大机票网站（去哪儿 + 携程）。
     </p>
     <h4>
      <a id="14requestsMySQLdbtorndb_128">
      </a>
      14.基于requests、MySQLdb、torndb的网易客户端内容爬虫
     </h4>
     <p>
      GitHub：https://github.com/leyle/163spider
     </p>
     <h4>
      <a id="15_136">
      </a>
      15.豆瓣电影、书籍、小组、相册、东西等爬虫集
     </h4>
     <p>
      GitHub：https://github.com/fanpei91/doubanspiders
     </p>
     <h4>
      <a id="16QQ_144">
      </a>
      16.QQ空间爬虫
     </h4>
     <p>
      GitHub：https://github.com/LiuXingMing/QQSpider
     </p>
     <p>
      包括日志、说说、个人信息等，一天可抓取 400 万条数据。
     </p>
     <h4>
      <a id="17mp3redis_154">
      </a>
      17.百度mp3全站爬虫，使用redis支持断点续传。
     </h4>
     <p>
      GitHub：https://github.com/Shu-Ji/baidu-music-spider
     </p>
     <h4>
      <a id="18_162">
      </a>
      18.淘宝和天猫的爬虫
     </h4>
     <p>
      GitHub：https://github.com/pakoo/tbcrawler
     </p>
     <p>
      可以根据搜索关键词,物品id来抓去页面的信息，数据存储在mongodb。
     </p>
     <h4>
      <a id="19_172">
      </a>
      19.一个股票数据（沪深）爬虫和选股策略测试框架
     </h4>
     <p>
      GitHub：https://github.com/benitoro/stockholm
     </p>
     <p>
      根据选定的日期范围抓取所有沪深两市股票的行情数据。支持使用表达式定义选股策略。支持多线程处理。保存数据到JSON文件、CSV文件。
     </p>
     <p>
      <strong>
       我这里准备了详细的Python资料，除了为你提供一条清晰的学习路径，我甄选了最实用的学习资源以及庞大的实例库。短时间的学习，你就能够很好地掌握爬虫这个技能，获取你想得到的数据。
      </strong>
     </p>
     <h3>
      <a id="01_0_183">
      </a>
      01 专为0基础设置，小白也能轻松学会
     </h3>
     <p>
      我们把Python的所有知识点，都穿插在了漫画里面。
     </p>
     <p>
      在Python小课中，你可以通过漫画的方式学到知识点，难懂的专业知识瞬间变得有趣易懂。
     </p>
     <p>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/4e856e9f47976d31a671bc5f7a35c200.png#pic_center">
       <br/>
       <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/480bcfae132644265b9565e889866edd.png#pic_center">
        <br/>
        你就像漫画的主人公一样，穿越在剧情中，通关过坎，不知不觉完成知识的学习。
       </img>
      </img>
     </p>
     <h3>
      <a id="02__193">
      </a>
      02 无需自己下载安装包，提供详细安装教程
     </h3>
     <p>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/b043f72739c67369d451f5b3cf66197b.png#pic_center"/>
     </p>
     <h3>
      <a id="03__196">
      </a>
      03 规划详细学习路线，提供学习视频
     </h3>
     <p>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/90f13d9620e2e39166108001155efcb6.png">
       <br/>
       <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/62e4d5ed4cadebec089e4ac15f09a0cb.png"/>
      </img>
     </p>
     <h3>
      <a id="04__200">
      </a>
      04 提供实战资料，更好巩固知识
     </h3>
     <p>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/77d6aae94afbbb9e0a243b7ca451ca94.png"/>
     </p>
     <h3>
      <a id="05__203">
      </a>
      05 提供面试资料以及副业资料，便于更好就业
     </h3>
     <p>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/768de4c7e9d316e4d369dac5089d63ab.png"/>
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/bfba9315a3595177f9e07ce275e8831c.png"/>
      <br/>
      <strong>
       这份完整版的Python全套学习资料已经上传CSDN，朋友们如果需要也可以扫描下方csdn官方二维码或者点击主页和文章下方的微信卡片获取领取方式，【保证100%免费】
      </strong>
      <br/>
      <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/8175218fdf632831c918ffabc486657f.png"/>
     </p>
    </div>
    <div id="treeSkill">
    </div>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f323430315f38343636373734332f:61727469636c652f64657461696c732f313338333930343031" class_="artid" style="display:none">
 </p>
</div>
