---
layout: post
title: "国内外开源大模型-LLM整理"
date: 2025-09-04T22:09:17+0800
description: "国内外开源大语言模型（LLM）的发展非常迅速，目前已经形成了一个百花齐放、各具特色的生态系统。下面我将从国外和国内两个维度，为您梳理一些具有代表性的开源大模型。"
keywords: "国内外开源大模型 LLM整理"
categories: ['未分类']
tags: ['开源', '大语言模型', '大模型', 'Llm']
artid: "151195128"
arturl: "https://blog.csdn.net/boonya/article/details/151195128"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=151195128
    alt: "国内外开源大模型-LLM整理"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=151195128
featuredImagePreview: https://bing.ee123.net/img/rand?artid=151195128
cover: https://bing.ee123.net/img/rand?artid=151195128
image: https://bing.ee123.net/img/rand?artid=151195128
img: https://bing.ee123.net/img/rand?artid=151195128
---



# 国内外开源大模型 LLM整理

![](https://i-operation.csdnimg.cn/images/cf31225e169b4512917b2e77694eb0a2.png)国内外开源大模型LLM全景解析



![](https://i-blog.csdnimg.cn/direct/b4aef2b95bc9413791a679ec01e1cbf5.png)

国内外开源大语言模型（LLM）的发展非常迅速，目前已经形成了一个百花齐放、各具特色的生态系统。下面我将从**国外**和**国内**两个维度，为您梳理一些具有代表性的开源大模型。

#### 国外知名开源大模型

国外的开源生态启动较早，由Meta、Google等科技巨头引领，社区非常活跃。

##### 1. Llama 系列 (Meta)

毫无疑问，Llama系列是开源大模型的“基石”和最重要的推动者。

* **Llama / Llama 1**： Meta在2023年2月发布的第一个版本，首次让学术界和社区能够申请访问强大但非完全开放的模型。
* **Llama 2** (2023年7月)： 重大升级并**真正开源**（采用自定义的宽松许可证，允许商用）。提供了7B、13B、70B三个规模版本，以及对应的**Llama 2-Chat**对话微调模型。它的发布极大地降低了行业使用强大LLM的门槛。
* **Llama 3** (2024年4月)： 最新一代，性能大幅提升。率先发布了8B和70B两个版本，在多项基准测试中超越了同规模的其他模型。支持更长的上下文（8K），并大幅改进了代码生成和推理能力。后续发布了更强的**405B**（400B+）超大规模模型。

##### 2. Mistral 系列 (Mistral AI)

这家法国初创公司以“小而精”的模型策略闻名，模型效率极高。

* **Mistral 7B**： 证明了7B参数规模的模型经过精心设计可以达到更大型号的性能。
* **Mixtral 8x7B**： 首个开源的**混合专家模型（MoE）**。虽然总参数量很大，但激活的参数只有12.9B，因此推理速度快、成本低，性能却堪比甚至超越Llama 2 70B。
* **Mistral 8x22B**： Mixtral的更大升级版，拥有141B总参数和39B激活参数，性能更强。
* **Codestral**： 其最新发布的专注于代码生成的模型，支持80多种编程语言，性能强劲。

##### 3. Google 系列

* **Gemma** (2024年2月)： Google基于其Gemini技术推出的轻量级开源模型家族，提供2B和7B两个版本。同样采用宽松许可证，适合商业化和学术研究。

##### 4. 其他重要模型

* **Falcon** (Technology Innovation Institute, 阿联酋)： 曾是其发布时最强大的开源模型，有7B、40B和180B版本。
* **MPT** (MosaicML, 现为Databricks)： 系列模型，以其在长上下文方面的优化而知名。
* **OLMo** (Allen Institute for AI)： 强调真正的开放，不仅开源模型权重，还开源了完整的训练代码、数据和工具链。

---

#### 国内知名开源大模型

国内厂商在开源方面也非常积极，推出了许多优秀且更擅长中文任务的开源模型。

##### 1. 深度求索 (DeepSeek)

* **DeepSeek-V2** (2024年5月)： 近期最受关注的国产开源模型。采用创新的**MoE架构**（236B总参数，21B激活参数），性能极其强大，在中文和英文基准测试中都达到了顶级水平。同时，其推理成本声称比Llama 3-70B低99%，极具竞争力。
* **DeepSeek-Coder**： 专注于代码生成的模型系列，有多个版本，在代码能力上表现优异，是很多开发者的首选代码模型之一。

##### 2. 智谱AI (Zhipu AI)

* **ChatGLM3-6B**： 第三代对话模型，基于自研的GLM架构。6B的参数量使得其在消费级显卡上即可高效微调和部署，在中英文对话上表现均衡，是国内最受欢迎的开源对话模型之一。

##### 3. 阿里云 (Alibaba)

* **Qwen (通义千问)**： 阿里开源了多个规模的模型，包括**Qwen1.5**系列的0.5B、1.8B、4B、7B、14B、72B等版本。模型在中英文、代码、数学等多方面表现全面，且开源协议非常宽松，支持免费商用。
* **Qwen2**（2024年6月）：最新一代，发布了0.5B、1.5B、7B、14B、72B等多个尺寸版本，在多项基准上超越了同规模的Llama 3模型，支持多语言，性能非常强劲。

##### 4. 百川智能 (Baichuan)

* **Baichuan 2**： 开源了7B和13B版本，在中文法律、医疗、数学等垂直领域表现突出。
* **Baichuan 3**： 最新一代，但目前开源的为**7B版本**。

##### 5. 零一万物 ([01.AI](https://01.ai/ "01.AI"))

* **Yi (意)**： 发布了包括6B、9B、34B等不同规模的模型。以其**超长的上下文支持**（可高达200K tokens）而闻名，在处理长文档方面优势明显。

##### 6. 上海人工智能实验室 (Shanghai AI Lab)

* **InternLM (书生)**： 推出了7B和20B版本的模型，强调综合性能和在学术研究中的应用。

---

#### 如何选择？一个简单的总结对比

| 模型系列 | 主要特点/优势 | 代表型号 | 适合场景 |
| --- | --- | --- | --- |
| **Llama 3** | 综合性能顶级，生态最完善，工具链支持最好 | **Llama 3-8B/70B** | 通用聊天、推理、编程，追求最佳性能和生态 |
| **Mistral/Mixtral** | 效率极高，MoE架构，速度快成本低 | **Mixtral 8x7B** | 需要高性能但希望控制推理成本的商用场景 |
| **DeepSeek** | 国产最强MoE，中英双优，成本效益极高 | **DeepSeek-V2** | 需要强大中文能力且注重成本的企业应用和开发者 |
| **Qwen (通义)** | 型号齐全，中英均衡，开源协议友好 | **Qwen2-7B/72B** | 需要免费商用的全面、均衡的模型 |
| **ChatGLM** | 参数小易部署，对话优化好 | **ChatGLM3-6B** | 入门级尝试、轻量级部署和微调 |
| **Yi (意)** | **超长上下文**处理 | **Yi-34B** | 需要总结长文档、代码库分析等任务 |

#### 获取与使用

这些模型大多可以在以下平台找到和下载：

* **Hugging Face** (`huggingface.co`): 最大的模型社区，几乎所有开源模型都会首发于此。
* **ModelScope** (`modelscope.cn`): 阿里云推出的中文模型社区，是国内模型的重要分发平台。
* **GitHub**: 各个项目的代码、教程和许可证信息。

**重要提示**：

* **注意许可证**： 虽然都叫“开源”，但不同模型的许可证（License）不同。例如，Llama系列使用的是自定义的Meta许可证，允许商用但有一定用户规模限制（现已取消），而Gemma、Qwen等则更为宽松。使用前务必阅读并遵守其许可证条款。
* **硬件要求**： 大模型对GPU内存要求很高。例如，运行7B模型通常需要14GB+的GPU内存（INT4量化后可降低），70B模型则需要140GB+的GPU内存或通过多卡推理。

开源大模型：[开源大模型（LLM） - Awesome软件 - OSCHINA - 中文开源技术交流社区](https://www.oschina.net/project/awesome?columnId=51 "开源大模型（LLM） - Awesome软件 - OSCHINA - 中文开源技术交流社区")



