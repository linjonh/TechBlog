---
layout: post
title: "深度学习自动驾驶BEV专业名词解释汇总"
date: 2025-08-26T14:20:27+0800
description: "本文摘要：本文系统梳理了深度学习和计算机视觉中的核心概念与技术。重点解析了Focal Loss、主动学习等算法原理，对比了BEV与PV视角特性，阐述了浅层/深层特征差异。详细介绍了Head模块设计、Bottleneck结构、LSS算法等技术细节，并对比了BN与LN的适用场景。同时涵盖了UNet、DiT、Embedding等模型架构，以及BMM、WarmUp等关键操作策略。内容涵盖目标检测、自动驾驶、语义分割等多个应用领域的技术要点，为相关研究和工程实践提供全面的概念参考。"
keywords: "深度学习&amp;自动驾驶&amp;BEV【专业名词解释汇总】"
categories: ['未分类']
tags: ['人工智能']
artid: "150854670"
arturl: "https://blog.csdn.net/weixin_45564943/article/details/150854670"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=150854670
    alt: "深度学习自动驾驶BEV专业名词解释汇总"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=150854670
featuredImagePreview: https://bing.ee123.net/img/rand?artid=150854670
cover: https://bing.ee123.net/img/rand?artid=150854670
image: https://bing.ee123.net/img/rand?artid=150854670
img: https://bing.ee123.net/img/rand?artid=150854670
---



# 深度学习&自动驾驶&BEV【专业名词解释汇总】



#### 专业名词汇总

##### `Focal Loss`

是一种用于解决**类别不平衡问题**的损失函数，广泛应用于目标检测和语义分割等任务。它通过引入一个可调参数 γ，降低易分类样本的权重，同时增加难分类样本的权重，从而提高模型对少数类别的分类能力

##### **主动学习（Active Learning）**

是机器学习中的一种策略，核心思想是让模型**主动选择最有价值的数据样本**进行标注和训练，从而在减少标注成本的同时提升模型性能。

核心概念：

1. **动态调整数据集**

   * 传统训练：固定使用所有标注数据。
   * 主动学习：模型在训练过程中**逐步选择对自身最有帮助的未标注数据**，交由人工标注后加入训练集。
2. **选择标准（查询策略）** 通过某种策略筛选“有价值”的数据，常见方法包括：

   * **不确定性采样（Uncertainty Sampling）**：选择模型预测最不确定的样本（如置信度最低的样本）。
   * **多样性采样（Diversity Sampling）**：选择能覆盖数据分布多样性的样本。
   * **代表性采样（Representativeness Sampling）**：选择能代表整体数据分布的样本。

##### 简化loss --> 单一onehot，赢者通吃

1. **单一`onehot`**

   * 标准的分类任务中，标签（label）通常用**`onehot`编码**表示（如 `[0, 0, 1, 0]`）。
   * "单一onehot" 强调只保留**概率最大的类别（即赢家）**，其他类别直接置零，不保留任何概率分布信息。
   * 例如：模型输出 `[0.2, 0.6, 0.1, 0.1]` → 经过argmax硬化为 `[0, 1, 0, 0]`。
2. **赢者通吃（Winner-Takes-All）**

   * 在计算损失时，**只考虑预测概率最大的类别**，忽略其他类别的误差。
   * 常见于使用交叉熵损失（Cross-Entropy Loss）时：

     + 模型对正确类别的预测概率越接近1，损失越小；其他类别的错误不影响损失值。
3. **简化loss**

   * 直接使用硬标签（hard label）而非软标签（soft label），不涉及概率分布的复杂计算（如KL散度）。

##### `pred_traj`

* **全称**：`predicted trajectory`（预测轨迹）

* **含义**：模型对**时序路径或空间轨迹的预测结果**，通常是一个多维向量或序列。
* 常见场景：

  + 自动驾驶（预测车辆未来行驶路线）
  + 行人轨迹预测（如监控视频中的移动路径）
  + 时间序列预测（如股票价格走势）

##### `pred_prob`

* **全称**：`predicted probability`（预测概率）
* **含义**：模型对**分类任务中每个类别的预测概率**，通常是经过 `softmax` 或 `sigmoid` 归一化的概率值。
* 常见场景：

  + 图像分类（如猫狗分类的输出概率）
  + 语义分割（每个像素点属于不同类别的概率）
  + 二分类任务（如欺诈检测的正例概率）

##### `DPO`是什么？

**DPO** 通常指 **Direct Preference Optimization（直接偏好优化）**，是一种用于优化模型输出的强化学习方法。**作用**：通过人类或自动标注的**偏好数据**（如选择A结果优于B），直接微调模型输出，使其更符合人类期望。**对比传统方法**：不同于RLHF（基于人类反馈的强化学习）需要先训练奖励模型再优化策略，DPO**直接优化策略网络**，简化了训练流程。

##### 梯度

梯度是损失函数对参数的偏导数向量，用于指导模型参数的更新方向和步幅。

三个常见问题：

1. 为什么推理时要禁用梯度？

   * 节省显存和计算时间（梯度计算约占总训练的30%开销）。
2. 梯度下降与反向传播的关系？

   * 反向传播是计算梯度的算法，梯度下降是利用梯度更新参数的方法。
3. 哪些操作会打断梯度传递？

   * 张量的 `detach()`、`numpy()` 转换或 `@torch.no_grad()` 上下文。

`detach`：

* **中断梯度传递**： 用于中断梯度传递，从计算图中分离出一个**不携带梯度信息的新张量**，但保留原始张量的数值内容。

* **不复制数据**： 与原张量**共享**同一块内存（**修改一个会影响另一个**）。

`numpy`：

* **张量转NumPy数组**： 将PyTorch张量转换为NumPy数组格式，**同时隐式执行`detach()`**（即丢失梯度信息）。
* **内存共享**： `CPU`张量与`NumPy`数组共享内存；`GPU`张量需先`.cpu()`。

| 操作 | 保持梯度 | 内存共享 | 适用设备 | 典型用途 |
| --- | --- | --- | --- | --- |
| `.detach()` | ❌ | ✔️ | CPU/GPU | 阻止梯度传递，保留PyTorch操作 |
| `.numpy()` | ❌ | ✔️(CPU) | CPU（GPU需转换） | 与NumPy生态交互 |
| `.cpu()` | ✔️ | ❌ | GPU→CPU | 跨设备转移（保持梯度） |

##### 优化器Optimizer

**Optimizer** 的意思是**优化器**。在机器学习和深度学习中，优化器是一种算法，用于调整模型的参数（如权重和偏置），以最小化损失函数（loss function），从而提升模型的性能。

###### 优化器的作用

1. **参数更新**：优化器通过计算损失函数对参数的梯度，指导参数如何更新，以使损失函数值更小。
2. **加速训练**：优化器通过调整学习速率（learning rate）和优化策略，可以加速模型的收敛过程。
3. **避免问题**：优化器可以帮助避免一些训练中的问题，如梯度消失、梯度爆炸等。

###### 常见的优化器

1. **SGD（随机梯度下降）**：最基础的优化器，通过随机采样小批量数据来更新参数。
2. **Adam**：结合了动量（momentum）和自适应学习速率的优化器，广泛应用于深度学习。
3. **RMSprop**：自适应学习速率的优化器，常用于训练深度神经网络。
4. **Adagrad**：根据参数的历史梯度信息自适应调整学习速率。
5. **AdamW**：Adam的改进版，解决了权重衰减（weight decay）的不一致性问题。

###### 优化器的配置

在使用优化器时，通常需要设置一些超参数，如：

* **学习速率（learning rate）**：控制每一步参数更新的步幅。
* **动量（momentum）**：加速优化过程，减少震荡。
* **权重衰减（weight decay）**：防止过拟合。

##### `Focal Loss`

是一种用于解决**类别不平衡问题**的损失函数，广泛应用于目标检测和语义分割等任务。它通过引入一个可调参数 γ，降低易分类样本的权重，同时增加难分类样本的权重，从而提高模型对少数类别的分类能力

##### **主动学习（Active Learning）**

是机器学习中的一种策略，核心思想是让模型**主动选择最有价值的数据样本**进行标注和训练，从而在减少标注成本的同时提升模型性能。

核心概念：

1. **动态调整数据集**

   * 传统训练：固定使用所有标注数据。
   * 主动学习：模型在训练过程中**逐步选择对自身最有帮助的未标注数据**，交由人工标注后加入训练集。
2. **选择标准（查询策略）** 通过某种策略筛选“有价值”的数据，常见方法包括：

   * **不确定性采样（Uncertainty Sampling）**：选择模型预测最不确定的样本（如置信度最低的样本）。
   * **多样性采样（Diversity Sampling）**：选择能覆盖数据分布多样性的样本。
   * **代表性采样（Representativeness Sampling）**：选择能代表整体数据分布的样本。

##### `BEV`和`PV`视角对比

一、核心区别

| 维度 | `BEV（Bird's Eye View）` | `PV（Perspective View）` |
| --- | --- | --- |
| **视角特点** | 从正上方俯视的场景投影，类似地图 | 类似人类驾驶的摄像头视角，近大远小 |
| **坐标系统** | **世界坐标系**（X-Y平面，Z轴忽略或压缩） | **图像坐标系**（像素坐标，含透视畸变） |
| **深度信息** | 隐含或显式编码深度（通过`Lidar`/深度估计） | 需通过立体视觉或单目深度估计恢复 |
| **适用传感器** | 多摄像头融合、`Lidar`点云 | 单目/多目摄像头 |

###### **直观对比示意图**：

```

 BEV视角：            PV视角：
   ↑ Y               前方
   |                ↗
  汽车              /  \
   |              /      \
   +-----→ X    车头视角（近处路宽，远处收窄）
```

二、`BEV`的核心优势与应用

###### **1. 为什么用`BEV`？**

* **消除透视畸变**：世界坐标系下距离和尺寸恒定，便于路径规划。
* **多传感器融合**：天然适配`Lidar`点云和环视摄像头数据。
* **全局决策支持**：直观体现周围车辆/行人的空间关系。

###### **2. 典型应用场景**

* **高精地图构建**：将动态物体与静态环境分离后生成地图。
* **多目标跟踪**：在`BEV`空间计算车辆间欧氏距离（比像素距离更合理）。
* **端到端规划**：直接输出世界坐标系下的轨迹（如特斯拉`Occupancy Networks`）。

##### 浅层特征、深层特征的感受野、分辨率对比

感受野： 指网络中的**某个特征点**（`feature map`上的一个像素）**对应原始图像的区域大小**。换言之，它表示“神经网络的一个神经元能看到输入图像的多少信息”。**作用**：决定了特征提取的上下文范围，较大的感受野能捕捉更全局的信息

浅层特征：靠近输入的前几层（如第`1-3`个卷积层）。特点如下：

* **高分辨率**：空间尺寸接近输入图像，保留细节（如边缘、纹理）。
* **小感受野**：仅捕捉局部模式（如线条、颜色变化）。
* **几何敏感**：对旋转、平移等变化敏感。

* **应用**：边缘检测、图像增强。

深层特征：网络的深层（如最后几个卷积层）。特点如下：

* **低分辨率**：经过多次下采样，空间尺寸小（如`14x14`）。
* **大感受野**：覆盖整个物体甚至全图，理解高级语义（如“狗头”“车轮”）。
* **语义抽象**：对局部形变、遮挡更鲁棒。**语义信息丰富**。

* **应用**：物体分类、目标检测。

可视化对比：

```

 输入图像 (224x224)
   │
   ├─ 浅层特征 (Conv1)  
   │   分辨率: 224x224 | 感受野: 3x3 | 检测到: 边缘、纹理
   │
   ├─ 中层特征 (Conv3)  
   │   分辨率: 56x56   | 感受野: 24x24 | 检测到: 简单形状
   │
   └─ 深层特征 (Conv5)  
        分辨率: 14x14   | 感受野: 196x196 | 检测到: 完整物体
```

通俗比喻：**就像用手电筒照一堵墙，光源离墙越远，光圈能覆盖的范围越大，但亮度也会降低**

##### Head头是一个什么概念？

**Head（头部）**：是网络结构中负责**任务特定输出**的最后一层或几层组件。

作用：类似于“**决策部门**”——将主干网络提取的通用特征转化为针对具体任务的预测结果。

主干网络（如`ResNet`、`Vit`、`Transformer`）负责提取输入数据的**低级/高级特征**，而Head将这些特征映射到**任务目标空间**（如分类概率、检测框坐标等）。

```

 示例：图像分类任务中的Head
 features = backbone(image)  # 主干提取特征（例如2048维向量）
 logits = head(features)     # Head输出各类别得分（如1000维向量）
```

与`Backbone`关系：

* **Backbone**：通常是预训练好的通用特征提取器（如`CNN`、`ViT`）。
* **Head**：根据任务需求定制的小型网络，通常需要从头训练。（可以替换预训练模型的Head以适应新任务）

###### **设计考量：**

###### 1. **输入-输出匹配**

* **维度对齐**：Head输入需匹配Backbone输出的特征维度（如形状、通道数）

```

 # 错误示例：特征图通道不匹配导致报错
 head = nn.Linear(512, 10)  # 输入需512维
 backbone_output = torch.randn(64, 1024)  # 实际1024维 → 报错!
```

###### 2. **复杂度平衡**

* 轻量化原则：Head参数量通常远小于Backbone，避免过拟合

  ```

   # 合理设计：用1x1卷积减少通道数
   class EfficientHead(nn.Module):
       def __init__(self, in_channels, out_channels):
           super().__init__()
           self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)
  ```

1. **多任务Head设计**

* 共享特征：多个Head可共用同一Backbone

  ```

   # 同时进行分类和回归
   multi_head = nn.ModuleDict({
       "cls": ClassificationHead(256, 10),
       "reg": RegressionHead(256, 2)
   })
  ```

###### 特征冻结策略：

* 两阶段训练：

  1. 冻结Backbone，仅训练Head（快速适配）
  2. 解冻Backbone，进行端到端微调

###### 问题与解决方案：

1. 梯度不稳定：

   * 在`Head`前添加`BatchNorm`层或梯度裁剪
2. 输出尺寸错误：

   * 使用`nn.AdaptiveAvgPool2d`自动调整特征图尺寸
3. 模型过于复杂：

   * 采用Bottleneck结构减少Head参数量

##### **什么是`Bottleneck`结构？**

**Bottleneck（瓶颈层）** ：是一种通过**压缩与还原特征维度**来提升计算效率的网络设计模块。它的核心思想是“先降维再升维”，在减少计算量的同时保持模型表达能力~

###### 1. **设计动机**

* **降低计算成本**： 通过减少中间特征通道数（如从256维→64维），大幅减少卷积操作的参数量和计算量。
* **保留有效信息**： 在降维后通过非线性层（如`ReLU`）和升维操作恢复原始维度，避免信息丢失。

###### 2. **典型应用场景**

* `ResNet`系列中的残差块（如`ResNet50/101`）
* 轻量化模型设计（如`MobileNetV2`的逆残差块）
* 特征嵌入压缩（如`Autoencoder`的中间层）

##### 什么是`LSS`？

**`LSS`（Lift, Splat, Shoot）** 是一种将**`2D`图像特征转换到`3D`空间**并生成鸟瞰图（`BEV`, `Bird's-Eye-View`）表达的算法框架。其核心思想是通过几何投影与特征融合实现多视角统一建模，广泛应用于自动驾驶的感知任务中。

###### 三步核心操作：

* **Lift（提取）**： 在`2D`图像上预测每个像素的**深度分布**，将图像特征从平面“抬升”到`3D`空间。

* **Splat（展开）**：

通过**视锥（frustum）投影**，将3D特征点云“泼洒”到BEV网格中，形成稀疏特征图。

* **Shoot（聚合）**：

使用**体素池化（Voxel Pooling）**等操作聚合BEV特征，输出结构化鸟瞰图。

###### 解决关键问题：

* **视角统一**：将多摄像头`2D`观测统一到车辆中心的`3D`坐标系
* **遮挡推理**：通过深度预测隐式建模遮挡关系
* **多传感器融合**：`BEV`空间更易融合激光雷达、毫米波雷达数据

##### UNet网络是什么？

一种专为**语义分割**任务设计的编码器-解码器（Encoder-Decoder）架构网络，其核心特点是**对称的U型结构**和**跳跃连接（Skip Connection）**，能够同时捕获局部细节和全局上下文信息。

**特点：**

* **编码器（下采样）**：通过卷积和池化逐步提取高层特征，缩小空间尺寸。
* **解码器（上采样）**：通过转置卷积或插值恢复空间分辨率，逐步精细分割结果。
* **跳跃连接**：将编码器的浅层特征与解码器的深层特征拼接，补充位置细节。

**优势：**

| **特性** | **作用** |
| --- | --- |
| **跳跃连接** | 解决深层网络位置信息丢失问题，提升小目标分割精度 |
| **端到端训练** | 输入原始图像直接输出像素级分类结果 |
| **少量数据适应** | 通过数据增强和特征复用，在医学影像等小数据集上表现优异 |
| **对称结构** | 编码器和解码器的对称设计有利于梯度传播 |

**应用场景：**

* 医学图像分割
* 自动驾驶
* 遥感图像处理

##### `BMM`是什么操作？

**`BMM`（Batch Matrix Multiplication，批量矩阵乘法）** 是一种高效处理**三维张量矩阵乘法**的操作，其核心特点是在保持批量维度不变的情况下，对矩阵切片执行并行乘法运算。

**与普通矩阵乘法的区别**

| **操作** | **功能** | **输入维度** |
| --- | --- | --- |
| `torch.mm()` | 单组矩阵乘法 | `2D`张量 (M×K) @ (K×N) |
| `torch.bmm()` | 批量并行矩阵乘法 | `3D`张量 (B×M×K) @ (B×K×N) |

##### `DiT`是什么结构？

**`DiT`（Diffusion Transformer）** 是一种基于**扩散模型（Diffusion Model）和 Transformer** 相结合的混合网络结构，主要用于生成高质量的数据（如图像、点云或驾驶场景预测）。它将 Transformer 的全局建模能力与扩散模型的渐进式生成特性结合，适用于需要高精度输出的任务。

##### `WarmUp`是一个什么策略？

**WarmUp（预热策略）** 是一种**逐步增加学习率（Learning Rate）或梯度更新强度**的优化技术，常用于训练初期稳定模型参数、避免震荡。

**1. 核心思想**

* **渐进式调整**：训练初期从小学习率开始，逐步增大至预设值（或降低优化器动量），让模型“温和”适应数据分布。
* 解决问题

  + 避免初始随机参数下过大的梯度更新导致数值不稳定。
  + 防止Transformer等模型早期过拟合小批量数据。

**2. 常见 `WarmUp` 类型**

* 学习率`WarmUp`
* 优化器参数`WarmUp`

##### 什么是`Embedding`模型？

**`Embedding` 模型**是一个函数，其任务是学习如何将某个空间（通常是**高维稀疏空间**）中的数据点，转换（嵌入）到另一个**低维稠密向量空间**，同时保留数据点间的重要关系和特征。

**关键特性：**

1. 低维：输出的向量**维度远低于原始的表示方式**（如One-hot编码）。
2. 连续：向量空间是**连续**的，意味着微小的变化也有意义，非常适合神经网络处理。
3. 稠密：向量中的每个元素都包含信息（与之相对的是One-hot编码，绝大部分元素是0）。
4. 从数据中学习而来：Embedding向量不是随机赋值或人为设定的，而是模型在完成特定任务（如预测下一个词）的过程中，通过大量数据自动学习到的表示。它捕获了数据背后的隐藏规律和知识。

**关键作用：**

1. 解决“维度灾难”和稀疏性问题：**提高计算效率 & 浓缩信息**

1. 捕获语义和关系（最神奇的作用）：**捕捉单词之间的语义信息**

1. 作为下游任务的强大特征输入：**下游任务无需从零学习特征**

1. 实现跨模态学习：**实现图像 & 文本 之间的融合**

##### **SD Road Points**是什么？

在自动驾驶和高精地图领域，**SD Road Points（Standard Definition Road Points，标准道路点集）** 是一种用于描述道路几何形状和拓扑关系的**基础数据表达形式**，通常以离散的路径点集合存储道路中心线或车道线信息。

**1. 定义**

* 基本组成：由一系列有序的经纬度坐标点（或局部坐标系下的 `(x, y, z)` 点）构成，每个点可能附带的属性包括：

  + 曲率（`curvature`）
  + 航向角（`heading`）
  + 坡度（`slope`）
  + 车道线类型（`lane_type`）
* **数据层级**：通常作为高精地图（`HD Map`）的轻量化补充，适用于对精度要求较低但需快速响应的场景。

**2.应用**

* 自动驾驶路径规划
* 车道级定位匹配

##### **Batch Normalization(`BN`)** 和 **Layer Normalization(`LN`)** 对比

###### **1. 核心区别对比**

| **特性** | **Batch Normalization (`BN`)** | **Layer Normalization (`LN`)** |
| --- | --- | --- |
| **归一化维度** | 沿`batch`维度（对同一特征的所有样本归一化） | 沿`特征`维度（对单个样本的所有特征归一化） |
| **输入形状示例** | `(batch_size, seq_len, hidden_dim)` → 对`hidden_dim`按`batch`统计 | 同一输入 → 对`seq_len + hidden_dim`按样本统计 |
| **是否依赖batch大小** | 是（**小batch时性能下降**） | 否（适合任意batch大小） |
| **训练/推理差异** | 需维护移动平均的均值/方差，推理时固定 | 训练和推理行为一致 |
| **适用场景** | CV（图像数据）、固定长度输入 | `NLP`（变长序列）、`RNN`/`Transformer` |

---

###### **2. 效果比较**

* 效果优劣：

  + **`BN`**：在**图像数据（`CV`）**和大batch场景下更有效，能加速收敛并提升模型精度。
  + **`LN`**：在**序列数据（`NLP`）**和小batch场景下更稳定，尤其是对变长输入（如文本）鲁棒性更强。
* 典型案例：

  + **Transformer模型几乎全部使用`LN`，而`ResNet`等CNN模型普遍使用`BN`**。

###### 3.**`NLP`领域为何多用`LN`？**

`LN`在`NLP`中占主导地位的原因：

1. **序列长度可变性**：文本的句子长度不一，`BN`的batch统计会引入噪声。
2. **batch独立性**：`NLP`的batch内样本语义关联弱，`BN`的跨样本统计无意义。
3. **训练稳定性**：`LN`对小batch和在线学习更友好（如BERT训练常用batch_size=32）。

| **场景** | **推荐方法** | **理由** |
| --- | --- | --- |
| 图像分类（`ResNet`） | `BatchNorm` | 受益于跨样本的全局统计 |
| 文本处理（Transformer） | `LayerNorm` | 适应变长序列，避免batch依赖 |
| 小batch训练 | `LayerNorm` | 不依赖batch统计量 |
| 生成对抗网络（GAN） | 可尝试`BN`或`LN` | 生成器和判别器可能需不同策略 |

---

上一次分割线~~

##### 什么是Down CNN 和 Up CNN？

**Down-sampling CNN**（下采样卷积神经网络）是一种通过 **逐步降低空间分辨率同时增加通道数（如图像尺寸）** 来提取层次化特征的网络结构。它是许多编码器-解码器架构（如U-Net、Hourglass）中的核心组成部分，主要用于**压缩输入数据的空间维度并捕获更高级别的语义信息**。

**Up CNN**（上采样卷积网络），通过**逐步恢复特征图的空间分辨率**（如 `16x16` → `256x256`），同时减少通道数，将高层语义特征与低层细节特征融合，**生成高分辨率的输出**（如分割掩膜）。

##### 什么是**Up Interpolate**？

**Up Interpolate（上采样插值）** 是深度学习中的一种操作，主要用于 **提升特征图的空间分辨率（放大尺寸）**，同时尽可能保留或恢复原始数据的细节信息。

##### 卷积核 和 步长 对结果影响对比

###### **1. 卷积核大小（kernel_size）**

###### **(1) 核心影响**

* 感受野：

  + `kernel_size` 越大（如5×5），单次卷积覆盖的输入区域越大，**捕获的特征更全局化**。
  + `kernel_size` 越小（如1×1），则更聚焦**局部细节**。
* 计算量：

  + 大卷积核参数量显著增加（如5×5核的参数量是3×3核的2.78倍）。

###### **(2) 典型选择**

* **小核（3×3）**：VGG、ResNet等主流架构的标配，平衡感受野与计算效率。
* **大核（7×7）**：早期网络（如AlexNet第一层）或需要全局信息的任务。
* **1×1核**：用于通道数调整（如Inception模块）或非线性增强。

###### **2. 步长（stride）**

###### **(1) 核心影响**

* 下采样能力：

  + `stride=1`：保留输入尺寸，用于精细特征提取。
  + `stride≥2`：**降低分辨率**（如减半），减少计算量并扩大感受野。
* 信息损失：

  + 大步长（如`stride=2`）可能丢失细粒度特征，需配合跳跃连接（如U-Net）补偿。

###### **(2) 典型应用**

* **分类网络**：浅层用`stride=2`逐步压缩空间维度（如ResNet）。
* **密集预测任务**（分割、检测）：深层可能恢复分辨率（转置卷积+`stride=2`）。

**3. 两者对比总结**

| **特性** | **卷积核大小（kernel_size）** | **步长（stride）** |
| --- | --- | --- |
| **主要作用** | 控制特征提取的局部/全局性 | 控制空间分辨率的下采样速度 |
| **参数量影响** | 直接影响（大核→参数量激增） | 无直接影响（但可通过降维间接减少） |
| **输出尺寸影响** | 间接影响（公式中与stride协同作用） | 直接影响（stride↑ → 输出尺寸↓） |
| **典型值** | 3×3（主流）、1×1（通道操作） | 1（保留尺寸）、2（减半） |
| **极端情况风险** | 过大核导致过平滑，过小核忽略上下文 | 过大步长导致信息丢失 |



