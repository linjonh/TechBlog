---
layout: post
title: "第15章ConvNeXt图像分类实战遥感场景分类包含本地网页部署迁移学习"
date: 2025-03-16 20:00:25 +0800
description: "它通过借鉴Transformer的设计思想，对传统CNN进行了改进，使其在图像分类等任务中表现优异，甚至超越了Vision Transformers（ViT）ConvNeXt 实现的model部分代码如下面所示，这里如果采用官方预训练权重的话，会自动导入官方提供的最新版本（ImageNet）的权重。：使用更大的卷积核（如7x7）来扩大感受野，类似于Transformer中自注意力机制捕捉全局信息的能力。：借鉴MobileNetV2的倒置瓶颈设计，先扩展通道数再进行深度卷积，最后压缩通道数，提升计算效率。"
keywords: "第15章：ConvNeXt图像分类实战：遥感场景分类【包含本地网页部署、迁移学习】"
categories: ['计算机视觉实战']
tags: ['迁移学习', '机器学习', '分类', '人工智能']
artid: "146300194"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146300194
    alt: "第15章ConvNeXt图像分类实战遥感场景分类包含本地网页部署迁移学习"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146300194
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146300194
cover: https://bing.ee123.net/img/rand?artid=146300194
image: https://bing.ee123.net/img/rand?artid=146300194
img: https://bing.ee123.net/img/rand?artid=146300194
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     第15章：ConvNeXt图像分类实战：遥感场景分类【包含本地网页部署、迁移学习】
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <hr id="hr-toc" name="tableOfContents"/>
    <p>
    </p>
    <h2 name="1.%C2%A0ConvNeXt%20%E6%A8%A1%E5%9E%8B" style="background-color:transparent">
     1. ConvNeXt 模型
    </h2>
    <p>
     ConvNeXt是一种基于卷积神经网络（CNN）的现代架构，由Facebook AI Research (FAIR) 团队在2022年提出。它通过借鉴Transformer的设计思想，对传统CNN进行了改进，使其在图像分类等任务中表现优异，甚至超越了Vision Transformers（ViT）
    </p>
    <p class="img-center">
     <img alt="" height="601" src="https://i-blog.csdnimg.cn/direct/bad600fdd2b14f1a8dfcefda3e259daa.png" width="1041"/>
    </p>
    <p>
     详细介绍：
    </p>
    <p>
     <a href="https://blog.csdn.net/qq_44886601/article/details/138574202" title="基于ConvNeXt网络的图像识别-CSDN博客">
      基于ConvNeXt网络的图像识别-CSDN博客
     </a>
    </p>
    <p>
     核心思想
    </p>
    <p>
     ConvNeXt的核心思想是将Transformer的成功设计理念（如ViT）引入CNN，同时保留卷积的固有优势。通过一系列现代化改进，ConvNeXt在保持高效性的同时，提升了性能。
    </p>
    <p>
     主要改进
    </p>
    <ol>
     <li>
      <p>
       <strong>
        大卷积核
       </strong>
       ：使用更大的卷积核（如7x7）来扩大感受野，类似于Transformer中自注意力机制捕捉全局信息的能力。
      </p>
     </li>
     <li>
      <p>
       <strong>
        分层设计
       </strong>
       ：采用类似ResNet的分层结构，逐步降低分辨率并增加通道数，以提取多尺度特征。
      </p>
     </li>
     <li>
      <p>
       <strong>
        倒置瓶颈结构
       </strong>
       ：借鉴MobileNetV2的倒置瓶颈设计，先扩展通道数再进行深度卷积，最后压缩通道数，提升计算效率。
      </p>
     </li>
     <li>
      <p>
       <strong>
        Layer Normalization
       </strong>
       ：用Layer Normalization替换Batch Normalization，更适合小批量训练，并提升模型稳定性。
      </p>
     </li>
     <li>
      <p>
       <strong>
        GELU激活函数
       </strong>
       ：使用GELU激活函数替代ReLU，因其在Transformer中的表现更佳。
      </p>
     </li>
     <li>
      <p>
       <strong>
        减少激活和归一化层
       </strong>
       ：减少不必要的激活和归一化层，简化网络结构，提升性能。
      </p>
     </li>
     <li>
      <p>
       <strong>
        Stochastic Depth
       </strong>
       ：引入随机深度（Stochastic Depth），在训练时随机丢弃部分层，增强模型泛化能力。
      </p>
     </li>
    </ol>
    <h4 id="" name="">
    </h4>
    <h2 id="2.%20%E9%81%A5%E6%84%9F%E5%9C%BA%E6%99%AF%E5%BB%BA%E7%AD%91%E8%AF%86%E5%88%AB" name="2.%20%E9%81%A5%E6%84%9F%E5%9C%BA%E6%99%AF%E5%BB%BA%E7%AD%91%E8%AF%86%E5%88%AB" style="background-color:transparent">
     2. 遥感场景建筑识别
    </h2>
    <p>
     ConvNeXt 实现的model部分代码如下面所示，这里如果采用官方预训练权重的话，会自动导入官方提供的最新版本（ImageNet）的权重
    </p>
    <p>
     <img alt="" height="286" src="https://i-blog.csdnimg.cn/direct/1dc7880bc36244dd91a5209306baee10.png" width="994"/>
    </p>
    <p>
    </p>
    <h3 id="2.1%20%E6%95%B0%E6%8D%AE%E9%9B%86" name="2.1%20%E6%95%B0%E6%8D%AE%E9%9B%86">
     2.1 数据集
    </h3>
    <p>
     数据集文件如下：
    </p>
    <p class="img-center">
     <img alt="" height="299" src="https://i-blog.csdnimg.cn/direct/e5098f1f6cee455293e082315f13a399.png" width="596"/>
    </p>
    <p>
     具体图像示例：
    </p>
    <p>
     <img alt="" height="426" src="https://i-blog.csdnimg.cn/direct/b3b487334b8b4ce79ec39b241b4b8edd.png" width="696"/>
    </p>
    <p>
     标签如下：
    </p>
    <pre><code class="hljs">{
    "0": "airport",
    "1": "bridge",
    "2": "church",
    "3": "forest",
    "4": "lake",
    "5": "river",
    "6": "skyscraper",
    "7": "stadium",
    "8": "statue",
    "9": "tower",
    "10": "urbanPark"
}</code></pre>
    <p>
     其中，训练集的总数为820，验证集的总数为345
    </p>
    <p>
     <img alt="" height="748" src="https://i-blog.csdnimg.cn/direct/53acb5f04e744df0a3ff8e517f64755d.png" width="968"/>
    </p>
    <p>
    </p>
    <h3 id="2.2%20%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0" name="2.2%20%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0">
     2.2 训练参数
    </h3>
    <p>
     训练的参数如下：
    </p>
    <pre><code class="hljs">    parser.add_argument("--model", default='tiny', type=str,help='tiny,small,base,large')
    parser.add_argument("--pretrained", default=True, type=bool)       # 采用官方权重
    parser.add_argument("--freeze_layers", default=True, type=bool)    # 冻结权重

    parser.add_argument("--batch-size", default=8, type=int)
    parser.add_argument("--epochs", default=30, type=int)

    parser.add_argument("--optim", default='AdamW', type=str,help='SGD,Adam,AdamW')         # 优化器选择

    parser.add_argument('--lr', default=0.01, type=float)
    parser.add_argument('--lrf',default=0.01,type=float)                  # 最终学习率 = lr * lrf

    parser.add_argument('--save_ret', default='runs', type=str)             # 保存结果
    parser.add_argument('--data_train',default='./data/train',type=str)           # 训练集路径
    parser.add_argument('--data_val',default='./data/val',type=str)               # 验证集路径</code></pre>
    <blockquote>
     <p>
      <strong>
       需要注意的是网络分类的个数不需要指定，摆放好数据集后，代码会根据数据集自动生成！
      </strong>
     </p>
    </blockquote>
    <blockquote>
     <p>
      <strong>
       更换数据集的话，将data-train和data-val路径更改即可，一键运行！
      </strong>
     </p>
    </blockquote>
    <blockquote>
     <p>
      <strong>
       trian脚本会在训练同时自动验证，生成训练和验证的曲线图和指标
      </strong>
     </p>
    </blockquote>
    <p>
    </p>
    <p>
     <strong>
      网络模型信息如下：
     </strong>
    </p>
    <pre><code class="hljs"> "train parameters": {
        "model version": "tiny",
        "pretrained": true,
        "freeze_layers": true,
        "batch_size": 8,
        "epochs": 30,
        "optim": "AdamW",
        "lr": 0.01,
        "lrf": 0.01,
        "save_folder": "runs"
    },
    "dataset": {
        "trainset number": 820,
        "valset number": 345,
        "number classes": 11
    },
    "model": {
        "total parameters": 27818891.0,
        "train parameters": 9995,
        "flops": 4463390208.0
    },</code></pre>
    <p>
    </p>
    <h3 id="3.3%20%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C" name="3.3%20%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C">
     2.3 训练结果
    </h3>
    <p>
     所有的结果都保存在
     <strong>
      save_ret
     </strong>
     目录下，这里是
     <strong>
      runs
     </strong>
     ：
    </p>
    <p>
     weights 下有最好和最后的权重，
     <strong>
      在训练完成后控制台会打印最好的epoch
     </strong>
    </p>
    <p>
     <img alt="" height="320" src="https://i-blog.csdnimg.cn/direct/d733e33596ba4a19852853485fa65bde.png" width="703"/>
    </p>
    <p>
    </p>
    <p>
     这里只展示部分结果：
     <strong>
      可以看到网络没有完全收敛，增大epoch会得到更好的效果
     </strong>
    </p>
    <p>
     <img alt="" height="760" src="https://i-blog.csdnimg.cn/direct/71eae0d543b4477e8562c76496d7717f.png" width="1155"/>
    </p>
    <p>
     <img alt="" height="744" src="https://i-blog.csdnimg.cn/direct/641db0fbc2004b5591f49c7a2da8384a.png" width="1006"/>
    </p>
    <p>
    </p>
    <p>
     最后一轮结果：
    </p>
    <pre><code class="hljs">    "epoch:29": {
        "train info": {
            "accuracy": 0.9987804877926978,
            "airport": {
                "Precision": 1.0,
                "Recall": 1.0,
                "Specificity": 1.0,
                "F1 score": 1.0
            },
            "bridge": {
                "Precision": 1.0,
                "Recall": 1.0,
                "Specificity": 1.0,
                "F1 score": 1.0
            },
            "church": {
                "Precision": 1.0,
                "Recall": 1.0,
                "Specificity": 1.0,
                "F1 score": 1.0
            },
            "forest": {
                "Precision": 1.0,
                "Recall": 0.987,
                "Specificity": 1.0,
                "F1 score": 0.9935
            },
            "lake": {
                "Precision": 1.0,
                "Recall": 1.0,
                "Specificity": 1.0,
                "F1 score": 1.0
            },
            "river": {
                "Precision": 1.0,
                "Recall": 1.0,
                "Specificity": 1.0,
                "F1 score": 1.0
            },
            "skyscraper": {
                "Precision": 1.0,
                "Recall": 1.0,
                "Specificity": 1.0,
                "F1 score": 1.0
            },
            "stadium": {
                "Precision": 1.0,
                "Recall": 1.0,
                "Specificity": 1.0,
                "F1 score": 1.0
            },
            "statue": {
                "Precision": 1.0,
                "Recall": 1.0,
                "Specificity": 1.0,
                "F1 score": 1.0
            },
            "tower": {
                "Precision": 1.0,
                "Recall": 1.0,
                "Specificity": 1.0,
                "F1 score": 1.0
            },
            "urbanPark": {
                "Precision": 0.9872,
                "Recall": 1.0,
                "Specificity": 0.9987,
                "F1 score": 0.9936
            },
            "mean precision": 0.9988363636363636,
            "mean recall": 0.9988181818181818,
            "mean specificity": 0.9998818181818181,
            "mean f1 score": 0.9988272727272729
        },
        "valid info": {
            "accuracy": 0.8463768115696703,
            "airport": {
                "Precision": 0.9231,
                "Recall": 0.8571,
                "Specificity": 0.997,
                "F1 score": 0.8889
            },
            "bridge": {
                "Precision": 0.9032,
                "Recall": 0.8485,
                "Specificity": 0.9904,
                "F1 score": 0.875
            },
            "church": {
                "Precision": 0.7647,
                "Recall": 0.8125,
                "Specificity": 0.9878,
                "F1 score": 0.7879
            },
            "forest": {
                "Precision": 0.9259,
                "Recall": 0.7576,
                "Specificity": 0.9936,
                "F1 score": 0.8333
            },
            "lake": {
                "Precision": 0.9091,
                "Recall": 0.7692,
                "Specificity": 0.997,
                "F1 score": 0.8333
            },
            "river": {
                "Precision": 0.7872,
                "Recall": 0.9024,
                "Specificity": 0.9671,
                "F1 score": 0.8409
            },
            "skyscraper": {
                "Precision": 0.875,
                "Recall": 0.7,
                "Specificity": 0.997,
                "F1 score": 0.7778
            },
            "stadium": {
                "Precision": 0.8943,
                "Recall": 0.9649,
                "Specificity": 0.9437,
                "F1 score": 0.9283
            },
            "statue": {
                "Precision": 0.8095,
                "Recall": 0.6296,
                "Specificity": 0.9874,
                "F1 score": 0.7083
            },
            "tower": {
                "Precision": 0.7143,
                "Recall": 0.4167,
                "Specificity": 0.994,
                "F1 score": 0.5263
            },
            "urbanPark": {
                "Precision": 0.7,
                "Recall": 0.875,
                "Specificity": 0.9617,
                "F1 score": 0.7778
            },
            "mean precision": 0.8369363636363637,
            "mean recall": 0.7757727272727273,
            "mean specificity": 0.9833363636363637,
            "mean f1 score": 0.7979818181818181
        }
    }</code></pre>
    <p>
    </p>
    <p>
     训练集和测试集的混淆矩阵：
    </p>
    <p class="img-center">
     <img alt="" height="830" src="https://i-blog.csdnimg.cn/direct/792035d8ff414cea818f009b8a3ea77a.png" width="977"/>
    </p>
    <p class="img-center">
     <img alt="" height="837" src="https://i-blog.csdnimg.cn/direct/c699b603418144629dd724fc4c47b47f.png" width="1001"/>
    </p>
    <p>
    </p>
    <p>
     ROC曲线和auc值：
    </p>
    <p>
     <img alt="" height="837" src="https://i-blog.csdnimg.cn/direct/30933361653d41d3bc3f9dbadf102005.png" width="1309"/>
    </p>
    <p>
    </p>
    <h3 id="2.4%20%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BD%91%E9%A1%B5%E6%8E%A8%E7%90%86" name="2.4%20%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BD%91%E9%A1%B5%E6%8E%A8%E7%90%86">
     <strong>
      2.4 本地部署推理
     </strong>
    </h3>
    <p>
     推理是指没有标签，只有图片数据的情况下对数据的预测，这里使用了网页推理
    </p>
    <p>
     值得注意的是，如果训练了自己的数据集，需要对infer脚本进行更改，如下：
    </p>
    <pre><code class="hljs"># 参数
MODEL = 'tiny'
LABELS = r'D:\project\ConvNeXt全家桶\runs\class_indices.json'
PTH = r'D:\project\ConvNeXt全家桶\runs\weights\best.pth'
IMAGE_PATH = r'D:\project\ConvNeXt全家桶\data\train\airport\0.jpg'</code></pre>
    <p>
     运行：
    </p>
    <pre><code class="hljs">streamlit run D:\project\ConvNeXt全家桶\infer.py</code></pre>
    <p class="img-center">
     <img alt="" height="875" src="https://i-blog.csdnimg.cn/direct/a851d9545406459d8f3bbab2000f3d4e.png" width="965"/>
    </p>
    <p>
    </p>
    <h2 id="3.%20%E4%B8%8B%E8%BD%BD" name="3.%20%E4%B8%8B%E8%BD%BD" style="background-color:transparent">
     3. 下载
    </h2>
    <p>
     关于本项目代码和数据集、训练结果的下载：
    </p>
    <p>
     <a href="https://download.csdn.net/download/qq_44886601/90488567" title="基于ConVNeXt神经网络模型实现的迁移学习、图像识别项目：遥感场景分类网页推理资源-CSDN文库">
      基于ConVNeXt神经网络模型实现的迁移学习、图像识别项目：遥感场景分类网页推理资源-CSDN文库
     </a>
    </p>
    <p>
     <img alt="" height="309" src="https://i-blog.csdnimg.cn/direct/b9e21b43a6a64a9ab7b25c7f2a2b5b59.png" width="613"/>
    </p>
    <p>
     关于Ai 深度学习图像识别、医学图像分割改进系列：
     <a href="https://blog.csdn.net/qq_44886601/category_12858320.html" title="AI 改进系列_听风吹等浪起的博客-CSDN博客">
      AI 改进系列_听风吹等浪起的博客-CSDN博客
     </a>
    </p>
    <p>
     神经网络改进完整实战项目：
     <a href="https://blog.csdn.net/qq_44886601/category_12803200.html" title="改进系列_听风吹等浪起的博客-CSDN博客">
      改进系列_听风吹等浪起的博客-CSDN博客
     </a>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34343838363630312f:61727469636c652f64657461696c732f313436333030313934" class_="artid" style="display:none">
 </p>
</div>


