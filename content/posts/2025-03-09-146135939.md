---
layout: post
title: "复现-MODEST-机器人抓取透明物体-单目-ICRA-2025"
date: 2025-03-09 18:47:31 +0800
description: "MODEST 单目透明物体抓取算法，来自ICRA 2025，本文分享它的复现过程。输入单个视角的RGB图像，模型需要同时处理深度和分割任务，输出透明物体的分割结果和场景深度预测。将算法迁移到真实机器人平台，开展了透明物体抓取实验。实验平台主要由UR机械臂和深度相机组成。在借助MODEST方法对透明物体进行分割和深度预测，生成点云数据作为输入，进而采用GraspNet生成抓取位姿。"
keywords: "复现 MODEST 机器人抓取透明物体 单目 ICRA 2025"
categories: ['机器人']
tags: ['透明物体', '深度预测', '机器人', '抓取', '分割']
artid: "146135939"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146135939
    alt: "复现-MODEST-机器人抓取透明物体-单目-ICRA-2025"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146135939
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146135939
cover: https://bing.ee123.net/img/rand?artid=146135939
image: https://bing.ee123.net/img/rand?artid=146135939
img: https://bing.ee123.net/img/rand?artid=146135939
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     复现 MODEST 机器人抓取透明物体 单目 ICRA 2025
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     MODEST 单目透明物体抓取算法，来自ICRA 2025，本文分享它的复现过程。
    </p>
    <p>
     输入单个视角的RGB图像，模型需要同时处理深度和分割任务，输出透明物体的分割结果和场景深度预测。
    </p>
    <p>
     论文地址：
     <a class="link-info" href="https://arxiv.org/pdf/2502.14616" rel="nofollow" title="Monocular Depth Estimation and Segmentation for Transparent Object with Iterative Semantic and Geometric Fusion">
      Monocular Depth Estimation and Segmentation for Transparent Object with Iterative Semantic and Geometric Fusion
     </a>
    </p>
    <p>
     代码地址：
     <a class="link-info" href="https://github.com/D-Robotics-AI-Lab/MODEST" title="https://github.com/D-Robotics-AI-Lab/MODEST">
      https://github.com/D-Robotics-AI-Lab/MODEST
     </a>
    </p>
    <p>
     <img alt="" height="127" src="https://i-blog.csdnimg.cn/direct/bae14d6fd6664520b2991f988d0742de.png" width="853"/>
    </p>
    <p>
     将算法迁移到真实机器人平台，开展了透明物体抓取实验。实验平台主要由UR机械臂和深度相机组成。
    </p>
    <p>
     在借助MODEST方法对透明物体进行分割和深度预测，生成点云数据作为输入，进而采用GraspNet生成抓取位姿。
    </p>
    <p>
     <img alt="" height="352" src="https://i-blog.csdnimg.cn/direct/a0986c0800b047689a7684dcf9e14e5d.png" width="641"/>
    </p>
    <p>
    </p>
    <h3>
     1、创建Conda环境
    </h3>
    <p>
     使用conda创建一个虚拟环境，名字为modest，指定使用python3.8
    </p>
    <p>
     然后进入modest环境
    </p>
    <pre><code class="language-bash">conda create -n modest python=3.8
conda activate modest</code></pre>
    <p>
    </p>
    <h3>
     2、安装torch和CUDA
    </h3>
    <p>
     需要安装torch==1.10.1+cu111，执行下面命令：
    </p>
    <pre><code class="language-bash">pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/cu111/torch_stable.html</code></pre>
    <p>
     然后安装其他依赖
    </p>
    <pre><code class="language-bash">sudo apt-get install openexr libopenexr-dev</code></pre>
    <p>
    </p>
    <h3>
     3、安装依赖库requirements.txt
    </h3>
    <p>
     下载MODEST代码到本地，然后解压
    </p>
    <p>
     打开requirements.txt，注释torch==1.10.1+cu111、torchvision==0.11.2+cu111，因为上面安装了
    </p>
    <p>
     <img alt="" height="291" src="https://i-blog.csdnimg.cn/direct/a8bb2810490d492e914dd075625ee987.png" width="412">
     </img>
    </p>
    <p>
     然后执行命令，安装依赖库
    </p>
    <pre><code class="language-bash">pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple</code></pre>
    <p>
    </p>
    <h3>
     4、准备数据集ClearPose
    </h3>
    <p>
     ClearPose 数据集是使用 RealSense L515 摄像头在室内环境中捕获的，捕获了 63 个透明物体。
    </p>
    <p>
     它包含 RGB、原始深度、地面真实深度、地面真实表面法线图像以及所有物体实例6D位姿。
    </p>
    <p>
     代码地址：
     <a class="link-info" href="https://github.com/opipari/ClearPose" title="https://github.com/opipari/ClearPose">
      https://github.com/opipari/ClearPose
     </a>
    </p>
    <p>
     下载地址：
     <a class="link-info" href="https://www.dropbox.com/scl/fo/dzc777gazch9309g4lebn/AHUr5d8z5NLuw8Sc_stV3Nk?rlkey=i0kpvh3792kvrumpsh9c51qim&amp;e=1&amp;dl=0" rel="nofollow" title="点击下载clearpose">
      点击下载clearpose
     </a>
    </p>
    <p>
     <img alt="" height="745" src="https://i-blog.csdnimg.cn/direct/623fe0000db24554902549418aae6600.png" width="1075"/>
    </p>
    <p style="text-align:start">
     <span style="color:#1f2328">
      <span style="background-color:#ffffff">
       ClearPose 被分成 9 个集合，其中 Set1 只包含化学透明物体，Set2-7 只包含家居物品，Set8-9 还包含其他对抗因素。
      </span>
     </span>
    </p>
    <p style="text-align:start">
     文件夹结构如下：
    </p>
    <blockquote>
     <pre>&lt;dataset_path&gt;
|-- set1
    |-- scene1
        |-- metadata.mat            # 
        |-- 000000-color.png        # RGB image
        |-- 000000-depth.png        # Raw depth image
        |-- 000000-depth_true.png   # Ground truth depth image
        |-- 000000-label.png        #
        |-- 000000-normal_true.png  #
        ...
|-- model
    |-- &lt;object1&gt;
        |-- &lt;object1&gt;.obj
    |-- &lt;object2&gt;
        |-- &lt;object2&gt;.obj
        ...
</pre>
    </blockquote>
    <p>
     示例数据：
    </p>
    <p>
     <img alt="" height="554" src="https://i-blog.csdnimg.cn/direct/99576c73b62f491f8a4c0232cf2b2301.png" width="897"/>
    </p>
    <p>
    </p>
    <h3>
     5、下载
     <strong>
      模型权重
     </strong>
    </h3>
    <p>
     Syn-TODD 数据集上预先训练的模型权重：
     <a class="link-info" href="https://drive.google.com/file/d/1haxiir4PdBNE9Zr1AA4D9bVJ4KCzqa8v/view" rel="nofollow" title="https://drive.google.com/file/d/1haxiir4PdBNE9Zr1AA4D9bVJ4KCzqa8v/view">
      https://drive.google.com/file/d/1haxiir4PdBNE9Zr1AA4D9bVJ4KCzqa8v/view
     </a>
    </p>
    <p>
     真实世界数据集 ClearPose 的模型权重：
     <a class="link-info" href="https://drive.google.com/file/d/1798AE_u6KrMV6mpUGBxz_jaLrg_21A39/view" rel="nofollow" title="https://drive.google.com/file/d/1798AE_u6KrMV6mpUGBxz_jaLrg_21A39/view">
      https://drive.google.com/file/d/1798AE_u6KrMV6mpUGBxz_jaLrg_21A39/view
     </a>
    </p>
    <p>
     然后创建文件夹ckpt，放到里面：
    </p>
    <p>
     <img alt="" height="152" src="https://i-blog.csdnimg.cn/direct/2fda87f5a22a41f79345444dd8cb01e8.png" width="613"/>
    </p>
    <p>
    </p>
    <h3>
     6、进行推理
    </h3>
    <p>
     首先配置文件：config/config.json，指定预训练权重ISGNet_clearpose.p
    </p>
    <p>
     <img alt="" height="351" src="https://i-blog.csdnimg.cn/direct/2b9610fe7a6b42fc998d7e84ce9d833d.png" width="441"/>
    </p>
    <p>
     使用CPU运行，"device":"cpu"；如果使用GPU，"device":"cuda"
    </p>
    <p>
     <img alt="" height="274" src="https://i-blog.csdnimg.cn/direct/2b3889d4be9b452d8bac540acc559689.png" width="421">
     </img>
    </p>
    <p>
     然后在推理代码inference.py中，需要修改图片路径，比如：
    </p>
    <p>
     image_path = "./datasets/clearpose_downsample_100/set1/scene1/000000-color.png"
    </p>
    <p>
     推理代码如下
    </p>
    <pre><code class="language-python">import json
from models.Trainer import Trainer
from utils.visualize import *


image_path = "./datasets/clearpose_downsample_100/set1/scene1/000000-color.png"

################ load the config file ##################
with open('config/config.json', 'r') as f:
    config = json.load(f)

############### load the trainer ###############
trainer = Trainer(config)

############### start inference ##############
trainer.inference(image_path)</code></pre>
    <p>
     执行代码：
    </p>
    <p>
     <img alt="" height="284" src="https://i-blog.csdnimg.cn/direct/a28d0895afb54868a04886fb062a28f0.png" width="1042"/>
    </p>
    <p>
     运行结果，在results目录保存了
    </p>
    <p>
     <img alt="" height="263" src="https://i-blog.csdnimg.cn/direct/e42cbdc5d3a942da9fe13aa4e7acd0a8.png" width="579"/>
    </p>
    <p>
     原图是这样的
    </p>
    <p>
     <img alt="" height="480" src="https://i-blog.csdnimg.cn/direct/b6ad1e52e3134aed8e06e67335150bd6.png" width="640"/>
    </p>
    <p>
     模型预测的深度图：
    </p>
    <p>
     <img alt="" height="491" src="https://i-blog.csdnimg.cn/direct/f1adb796ae4d4ce69b97a188452ef922.png" width="491"/>
    </p>
    <p>
     模型预测的分割效果：
    </p>
    <p>
     <img alt="" height="481" src="https://i-blog.csdnimg.cn/direct/b6367ac57f5e48b3b7eabed233358c56.png" width="481"/>
    </p>
    <p>
     MODEST对透明物体进行分割和深度预测，生成点云数据作为输入，进而采用GraspNet生成抓取位姿。
    </p>
    <p>
    </p>
    <p>
     分享完成～
    </p>
    <p>
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34313230343436342f:61727469636c652f64657461696c732f313436313335393339" class_="artid" style="display:none">
 </p>
</div>


