---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f33333933343432372f:61727469636c652f64657461696c732f313235353039343639"
layout: post
title: "云原生题目整理待更新"
date: 2022-06-28 20:43:29 +08:00
description: "云原生技能树知识点整理_云原生考试题目"
keywords: "云原生考试题目"
categories: ['技能树', '云计算', 'Docker']
tags: ['开发语言', '云原生', 'Java']
artid: "125509469"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=125509469
    alt: "云原生题目整理待更新"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=125509469
featuredImagePreview: https://bing.ee123.net/img/rand?artid=125509469
---

# 云原生题目整理（待更新）

## 云原生题目整理（待更新）

**Note**
：根据
[CSDN云原生技能树](https://edu.csdn.net/skill/cloud_native/cloud_native-f22bbbe40efb4940914c5ba59021998d?category=851)
整理的题目。

#### 文章目录

* [云原生题目整理（待更新）](#_0)
* + [一、容器（docker）](#docker_5)
  + [二、容器编排（k8s）](#k8s_14)
  + - [1）学习环境 K8s 容器编排](#1_K8s__15)
    - [2）生产环境 K8s 容器编排](#2_K8s__48)
  + [三、k8s包管理（helm）](#k8shelm_63)
  + [四、服务网格（istio）](#istio_76)
  + [五、持续集成和部署（Jenkins）](#Jenkins_121)
  + [六、基础架构自动编排（Terraform）](#Terraform_137)
  + [七、云原生环境小结](#_152)

### 一、容器（docker）

* [docker image pull操作](https://edu.csdn.net/skill/practice/cloud_native-b7a0d39bc3694e03b5729a4e0d7862c4/19182)
* [docker image inspect查看镜像配置信息](https://edu.csdn.net/skill/practice/cloud_native-b7a0d39bc3694e03b5729a4e0d7862c4/19218)
* [docker image镜像操作命令](https://edu.csdn.net/skill/practice/cloud_native-b7a0d39bc3694e03b5729a4e0d7862c4/19199)
* [docker container run命令](https://edu.csdn.net/skill/practice/cloud_native-432fe9c58fe44f17bc31a17eb2808180/19193)
* [docker container run进入shell环境](https://edu.csdn.net/skill/practice/cloud_native-432fe9c58fe44f17bc31a17eb2808180/19196)
* [docker containerkill容器](https://edu.csdn.net/skill/practice/cloud_native-432fe9c58fe44f17bc31a17eb2808180/19179)
* [Dockerfile的使用（docker build）](https://edu.csdn.net/skill/practice/cloud_native-69e029b68b034927b5fa2153b893fa72/19197)
* [docker build构建容器并发布](https://edu.csdn.net/skill/practice/cloud_native-69e029b68b034927b5fa2153b893fa72/19180)

### 二、容器编排（k8s）

#### 1）学习环境 K8s 容器编排

* [kubectl命令](https://edu.csdn.net/skill/practice/cloud_native-f22bbbe40efb4940914c5ba59021998d/19224)
  ，可参考
  [kubectl ：命令技巧大全](https://blog.csdn.net/fly910905/article/details/97232498)
* [minikube和kind概述](https://edu.csdn.net/skill/practice/cloud_native-506bd8a7aa254e03b6394e15f139d9c6/19209)
  ，
  [minikube和kind创建K8s集群](https://bbs.csdn.net/topics/605532376)
  ，可参考
  [k8s官方文档](https://kubernetes.io/zh-cn/docs/tasks/tools/)
* [minikube 命令体系](https://edu.csdn.net/skill/practice/cloud_native-506bd8a7aa254e03b6394e15f139d9c6/19204)
  ，
  [minikube 启动k8s集群(配置kubectl)](https://edu.csdn.net/skill/practice/cloud_native-506bd8a7aa254e03b6394e15f139d9c6/19195)
  ，可参考
  [minikube快速搭建k8s](https://blog.csdn.net/u014636124/article/details/105145674)
* [kubernetes 的管理工具: kind](https://edu.csdn.net/skill/practice/cloud_native-7788644c8b714ed9a0e04caa25934ce2/19202)
  ，可参考
  [kind - Quick Start](https://kind.sigs.k8s.io/docs/user/quick-start/)
* [kind 创建的 k8s 集群信息(master,node)](https://edu.csdn.net/skill/practice/cloud_native-7788644c8b714ed9a0e04caa25934ce2/19225)
  ，可参考
  [K8s架构|全面整理K8s的架构介绍](https://blog.csdn.net/qq_37419449/article/details/122157277)
  ，
  [Kubernetes(K8S)架构1(Master,Node和Pod)](https://blog.csdn.net/qq_21047625/article/details/90180406)
* [kubectl查看和切换context (kubectl config view)](https://edu.csdn.net/skill/practice/cloud_native-96843019dff240fab2a76b6d53be1775/19214)
* [使用 kubectl 部署](https://edu.csdn.net/skill/practice/cloud_native-82e0635057c847f99823da536e9eba68/19206)
  ，可参考
  [K8s部署超详细](https://blog.csdn.net/qq_46126559/article/details/108277786)
* [使用 kubectl 查看 ReplicaSet 和 Pods](https://edu.csdn.net/skill/practice/cloud_native-82e0635057c847f99823da536e9eba68/19211)
* [使用 kubectl 启动服务(service)](https://edu.csdn.net/skill/practice/cloud_native-82e0635057c847f99823da536e9eba68/19203)

**Note**
：

* `kubectl`
  是用来与 Kubernetes 集群通讯的命令行工具。通过
  `Kubectl`
  可以在
  `Kubernetes`
  集群上完成如下操作：
  + 部署和管理应用
  + 查看资源信息
  + 删除和更新组件
* 学习阶段，在个人主机上安装和配置
  `kubernetes`
  有两个可选的套装：
  `kind`
  或者
  `minikube`
  的
  `kubernetes`
  管理工具，这两者不会安装
  `kubectl`
  ，因此
  `kubectl`
  是需要独立安装的。
    
  `minikube`
  和
  `kind`
  会自动安装
  `kubelet`
  ，但是
  `kubeadm`
  不会自动安装
  `kubelet`
* K8s中主机（物理机/云主机/虚拟机）主要分为两种
  `Master`
  和
  `Node`
  + `Node`
    是运行具体容器的主机,负责提供后具体的服务,并且本身具有自我修复能力 –
    **Data Plane 数据平面**
  + `Master`
    负责管理Node, 控制Node 具体运行什么容器, 同时还承担外部数据访问的角色--
    **Control Plane 控制层面**
* `Mater`
  由四个逻辑组件组成, 他们分别由四个独立的守护线程,
  `API Server`
  ,
  `Scheduler`
  和
  `Controller`
  是K8s自己做的,
  `etcd`
  则是使用 Core OS的成果。
  + `etcd`
    : 用户保存应用程序
    **配置信息的守护进程**
    ,是一个
    **k-v存储系统**
    ,存储内容为用用户发出的API请求中容器的具体要求, 是一个强一致性的。
  + `API Server`
    : 是
    **K8s开放给用户的唯一入口**
    , 接受用户的指令。同时对指令进行规范检查, 如果合乎规范的话将其放入
    `etcd`
    中。
  + `Scheduler`
    : 是作为调度器，负责的内容是
    **寻找要部署的容器的最佳Node**
    . 主从模式, 只能有一个正在执行的服务。
  + `Controller`
    : 是作为控制器,
    **K8s提供的API是声明式API**
    。要运行一个redis容器, 只需要声明要运行一个redis容器即可, 具体的镜像来源以及挂掉后重启等等都有控制器完成。
    **控制器负责用户指令的具体运行以及保证资源运行**
    一直符合用户的需求, 作为
    `Master`
    的大脑， 也只能有一个正在执行的服务。
* `Node`
  节点是作为K8s中的
  **工作负载节点**
  ,
  `Node`
  节点接收
  `Master`
  节点分配的一些任务，Node的关键组件：
  + `kubelet`
    : 负责
    **对pod(POD是一组 )对应容器的创建**
    ，启停等一系列的任务,
    `kubelet`
    时刻watch着
    `Mater`
    中的API Server中的资源变动, 当有和自己相关的任务的时候就会调用Docker执行具体的任务。
  + `kube-proxy`
    : 用于实现 K8S Service(需要提供的服务) 的通信和负载均衡
  + `Docker Engine`
    : docker引擎, 负责Node于和容器有关的操作,
    **K8s原生支持Docker作为容器引擎**
    , 如果要使用其他容器引擎则需要使用对应接口集成。
  + `Pod`
    : K8s不是直接运行的容器,而是操作Pod,
    **把Pod作为原子单元管理**
    ,一个Pod里面可能会运行多个容器,
    **Pod里面运行的多个容器被捆绑在一起被统一调度不可分割**
    ，一个Pod的所有容器只能同时运行在一个
    `Node`
    上。
* **ReplicaSet 通常包含多个Pods，Pod是一个或多个容器的组合**
  ，这些容器共享存储、网络和命名空间，以及如何运行的规范。
* 通过 deployment 可以部署一个 ReplicaSet，deployement 可以通过 service 暴露给集群外。

#### 2）生产环境 K8s 容器编排

* [k8s 三件套：kubelet, kubectl, kubeadm](https://edu.csdn.net/skill/practice/cloud_native-3a407b55039e4e29b802e5047caf881b/19221)
  ，可参考
  [深入剖析Kubernetes](https://book.douban.com/subject/35424872/)
* [k8s 基础组件介绍](https://edu.csdn.net/skill/practice/cloud_native-956e6d175eb343468b21131c54afb4c6/19207)
  ，可参考
  [K8s架构|全面整理K8s的架构介绍](https://blog.csdn.net/qq_37419449/article/details/122157277)
* [k8s 设计理念](https://edu.csdn.net/skill/practice/cloud_native-3d43dbd9c50e407a806cb4f7703c4160/19183)
  ，参考
  [Kubernetes 核心理解之声明式API和编程范式](https://blog.csdn.net/KevinBetterQ/article/details/104012293)

**Note**
：

* `kubelet`
  ：
  `kubelet`
  是
  **计算节点**
  上最核心的组件（对Borg项目中的
  `Borglet`
  进行改进），
  **主要负责同容器运行时**
  （比如Docker项目）打交道；而这个交互所依赖的，是一个称作
  **CRI**
  （Container Runtime Interface）的远程调用接口，这个接口定义了
  **容器运行时的各项核心操作**
  ；
  `kubelet`
  还通过
  **gRPC协议**
  同一个叫作
  **Device Plugin**
  的插件进行交互。
    
  `kubelet`
  的另一个重要功能，则是调用
  **网络插件**
  和
  **存储插件**
  为容器配置网络和持久化存储。
    
  在理解了容器技术之后，你可能已经萌生出了这样一个想法，
  **为什么不用容器部署K8s**
  呢？但这样做会带来一个很麻烦的问题，即
  **如何容器化
  `kubelet`**
  ; 到目前为止，在容器里运行
  `kubelet`
  ，依然没有很好的解决办法，所以不推荐使用容器去部署
  `Kubernetes`
  项目。
    
  因此，下面提到的
  `kubeadm`
  选择了一种妥协方案：把
  `kubelet`
  直接运行在宿主机上，然后
  **使用容器部署其他的K8s组件**
  。
* `kubeadm`
  ：
  `kubeadm`
  可以实现一键部署。主要包括
  `kubeadm init`
  和
  `kubeadm join`
  指令
    
  `kubeadm`
  首先要做的，是一系列的检查工作，以
  **确定这台机器可以用来部署K8s**
  ；
    
  在通过了
  `Preflight Checks`
  之后，
  `kubeadm`
  要做的，是
  **生成K8s对外提供服务所需的各种证书和对应的目录**
  ；证书生成后，
  `kubeadm`
  会为其他组件
  **生成访问kube-apiserver所需的配置文件**
  ；接下来，
  `kubeadm`
  会
  **为Master组件生成Pod配置文件**
  ；然后，
  `kubeadm`
  就会为集群生成一个bootstrap token，接着
  `kubeadm`
  会将
  `ca.crt`
  等Master节点的重要信息，通过
  `ConfigMap`
  的方式保存在
  `Etcd`
  当中，供后续部署
  `Node`
  节点使用。
    
  `kubeadm init`
  生成bootstrap token之后，你就可以在任意一台安装了
  `kubelet`
  和
  `kubeadm`
  的机器上执行
  `kubeadm join`
  了。
* `kubectl`
  ：kubectl是kubenetes
  **命令行工具**
  ，通过
  `kubectl`
  可以部署和管理应用，实现
  **k8s集群通讯**
  ，查看各种资源，创建，删除和更新组件。

### 三、k8s包管理（helm）

* [kubernetes-helm](https://edu.csdn.net/skill/practice/cloud_native-d803deb6ed5043f2925cb47b555ea9bc/19192)
  ，参考
  [kubernetes之helm简介、安装、配置、使用指南](https://blog.csdn.net/bbwangj/article/details/81087911)
* [helm三大概念（Chart、Repository、Release）](https://edu.csdn.net/skill/practice/cloud_native-ef938d686b4045f2a2da9e6b57500851/19184)
* [helm安装mysql到k8s](https://edu.csdn.net/skill/practice/cloud_native-e25cf855bd204baa82d43aeda5509431/19213)
* [使用 helm 部署 Python 应用](https://edu.csdn.net/skill/practice/cloud_native-89d35bea670a42a3aa7c135154ba16f1/19189)

**Note**
：

* 相较于centos 上的
  `yum`
  ，ubuntu 上的
  `apt-get`
  ，Windows 上的
  `choco`
  包管理软件，k8s 上也可以通过
  `helm`
  （k8s 的包管理软件），给 k8s 平台安装各种组件包或者服务包。
* `helm`
  通过三大概念来管理 k8s 上的包:
  + **Chart**
    ：Chart 代表着 helm 包。它包含在
    **K8s 集群内部运行应用程序**
    ，工具或服务所需的所有
    **资源定义**
    。
  + **Repository**
    ：是 chart 的存储库。例如：https://charts.bitnami.com/bitnami
  + **Release**
    ：Release 是运行在 K8s 集群中的 chart 的实例。
    **一个 chart 通常可以在同一个集群中安装多次**
    。每一次安装都会创建一个新的 release。以 MySQL chart为例，如果你想在你的集群中运行两个数据库，你可以安装该chart两次。每一个数据库都会拥有它自己的 release 和 release name。
* `kubectl`
  命令可以部署应用，
  `helm`
  也可以部署应用，而且
  `helm`
  部署的应用也可以通过
  `kubectl`
  管理。

### 四、服务网格（istio）

* [服务网格(ServiceMesh)](https://edu.csdn.net/skill/practice/cloud_native-9c2a74f5d85842ae895102786131545a/19200)
  ，参考
  [微服务和服务网格有什么区别，istio告诉你](https://blog.csdn.net/fly910905/article/details/107715285)
* [使用istioctl安装istio](https://edu.csdn.net/skill/practice/cloud_native-dcdf8cea6d814fc89adf10ce7e516a08/19223)
  ，
  [使用 helm 安装istio（比istioctl方便）](https://edu.csdn.net/skill/practice/cloud_native-dcdf8cea6d814fc89adf10ce7e516a08/19201)
  ，参考
  [istio官网](https://istio.io/latest/zh/docs/tasks/traffic-management/request-routing/)
  ，
  [istio简介和基础组件原理（服务网格Service Mesh）](https://blog.csdn.net/luanpeng825485697/article/details/84560659)
* [istio流量管理（服务通信，路由配置）](https://edu.csdn.net/skill/practice/cloud_native-80dec61abcca4348a6fdc9b9b727b486/19219)
* [istio安全管理（认证授权）](https://edu.csdn.net/skill/practice/cloud_native-029c7b191f8347d69d807d04fd315ced/19186)
* [istio可观察性（可视化，指标度量）](https://edu.csdn.net/skill/practice/cloud_native-7303d1d645de4693b303d04c962e1167/19188)

**Note**
：

* 客户端请求网页常常会经过代理，代理请求后面的服务，后台服务返回给代理，代理再返回给客户端。这是一个典型的代理服务的情景。大概是这样：
    
  `Client <-> Proxy <-> Server`
    
  现代后端开发，将服务拆分成多个微服务是常见的做法。
    
  `Client <-> Interface <-> [ProxyA->ServerA] <-> [ProxyB->ServerB]`
    
  `Client <-> Interface <-> [ProxyB->ServerB] <-> [ProxyA->ServerA]`
* **微服务之间的互相访问**
  ，公共的代理部分可以做很多
  **公共的控制逻辑**
  。这部分的的代码标准化，下层到云原生的基础设施里，就形成了服务网格（ServiceMesh）。
  **服务网格通常管理微服务**
  之间这三个方面的功能：
  + **流量管理**
    (Traffic management)：
    **动态服务发现**
    、路由、
    **流量灰度**
    和流量分离等。
  + **安全**
    (Security)：加密传输、基于
    **正式验证的授权**
    、基于访问控制和网络分区的授权等。
  + **可观察性**
    (Observability): 例如链路跟踪、日志等。
* 服务网格和 k8s 之间是什么关系呢？一图胜千言，在k8s的基础上，为每个pod增加一个proxy（或者叫边车，sidecar)，有两个变化：
    
  ![](https://i-blog.csdnimg.cn/blog_migrate/ad56150c41c9f5f01687c1e2c2e70287.png)
    
  1）原来k8s的node里的pod通过node的
  `kube-proxy`
  和
  **API Server 通信**
  ；
  **在ServiceMesh下，每个pod直接通过装在pod上的proxy和API Server通信**
  。
    
  2）原来k8s的node里的pod通过node的
  `kube-proxy`
  **桥接通信**
  ；在
  `ServiceMesh`
  下，每个
  `pod`
  之间直接
  **通过装在 pod上的proxy直接通信**
  。
* 在k8s原生组件的基础上，给每个pod安装服务网格的proxy，
  **对这些proxy的编排调度，构成里服务网格层**
  。服务网格的特点是，
  **将微服务管理功能内置到基础架构层**
  ，无需在应用层写相关代码。
* `istio`
  是
  **服务网格基础设施的一种实现**
  ，支持在多个不同的云原生基础设施上工作。
* 下面是一组
  **istio 流量管理**
  的实战文档：
  + [配置请求路由(request-routing)](https://istio.io/latest/zh/docs/tasks/traffic-management/request-routing/)
    ： 如何将请求动态路由到微服务的多个版本。
  + [故障注入(fault-injection)](https://istio.io/latest/zh/docs/tasks/traffic-management/fault-injection/)
    ：此任务说明如何注入故障并测试应用程序的弹性。
  + [流量转移(traffic-shifting)](https://istio.io/latest/zh/docs/tasks/traffic-management/traffic-shifting/)
    ： 展示如何将流量从旧版本迁移到新版本的服务。
  + [TCP 流量转移(tcp-traffic-shifting)](https://istio.io/latest/zh/docs/tasks/traffic-management/tcp-traffic-shifting/)
    ： 展示如何将一个服务的 TCP 流量从旧版本迁移到新版本。
  + [设置请求超时(request-timeouts)](https://istio.io/latest/zh/docs/tasks/traffic-management/request-timeouts/)
    ：本任务用于示范如何使用 Istio 在 Envoy 中设置请求超时。
  + [熔断(circuit-breaking)](https://istio.io/latest/zh/docs/tasks/traffic-management/circuit-breaking/)
    ：本任务展示如何为连接、请求以及异常检测配置熔断。
  + [镜像(mirroring)](https://istio.io/latest/zh/docs/tasks/traffic-management/mirroring/)
    ：此任务演示了 Istio 的流量镜像/影子功能。
  + [地域负载均衡(locality-load-balancing)](https://istio.io/latest/zh/docs/tasks/traffic-management/locality-load-balancing/)
    ：本系列任务演示如何在 Istio 中配置地域负载均衡。
  + [Ingress](https://istio.io/latest/zh/docs/tasks/traffic-management/ingress/)
    ：控制 Istio 服务网格的入口流量。
  + [Egress](https://istio.io/latest/zh/docs/tasks/traffic-management/egress/)
    ：控制 Istio 服务网格的出口流量。
* **istio安全控制**
  ：
  + **认证**
    ：管控网格服务间的双向 TLS 和终端用户的身份认证。
  + **证书管理**
    ：管理 Istio 的证书。
  + **授权**
    ：展示如何控制到 Istio 服务的访问。
* **istio 可观察性的操作任务**
  ：
  + [指标度量(metrics)](https://istio.io/latest/zh/docs/tasks/observability/metrics/)
    ：演示 Istio 网格指标度量的配置、收集和处理。
  + [日志(logs)](https://istio.io/latest/zh/docs/tasks/observability/logs/)
    ：演示 Istio 网格日志的配置、收集和处理。
  + [分布式追踪(distributed-tracing)](https://istio.io/latest/zh/docs/tasks/observability/distributed-tracing/)
    ：该任务展示了如何为启用了 Istio 支持的应用进行追踪。
  + [网络可视化(kiali)](https://istio.io/latest/zh/docs/tasks/observability/kiali/)
    ：此任务向您展示如何在 Istio 网格中可视化服务。
  + [gateways](https://istio.io/latest/zh/docs/tasks/observability/gateways/)
    ：此任务向您展示如何配置从外部访问 Istio gateways。

### 五、持续集成和部署（Jenkins）

* [helm 安装 Jenkins 到k8s集群，配置CI/CD](https://edu.csdn.net/skill/practice/cloud_native-a91605664c3f4cb69475c789c616e4a3/19212)
  ，参考
  [基于K8s和docker的Jenkins 可伸缩持续集成系统](https://blog.csdn.net/Daniel_greenspan/article/details/53338619)
  ，
  [Jenkins 部署 Maven 项目、Jenkins 部署 Vue 项目](https://blog.csdn.net/achi010/article/details/93708768)
  ，
  [Jenkins入门](https://blog.csdn.net/miss1181248983/article/details/82840006)
* [CI/CD动作](https://edu.csdn.net/skill/practice/cloud_native-8cb2691d48544d4c81422d89485e48d1/19208)

**Note**
：

* `Jenkins`
  是一个可伸缩的，持续集成，持续部署的
  **软件自动化工具**
  ，
  `jenkins`
  可以
  **部署在 k8s 内，也可以部署在k8s外**
  ；在k8s 内部署
  `jenkins`
  ，使得其自动获得了
  **高可用**
  。
* 登陆
  `jenkins`
  后 ，可以配置一系列
  `CI/CD`
  动作：
  + **CI**
      
    1）拉取代码
      
    2）
    **构建/测试/打包**
      
    3）
    **构建容器镜像**
  + **CD**
      
    1）推送容器镜像到
    **镜像中心**
      
    2）执行
    **k8s命令，拉取镜像**
      
    3）执行k8s命令，部署
      
    4）执行k8s命令，滚动更新

### 六、基础架构自动编排（Terraform）

* [Terraform概述](https://edu.csdn.net/skill/practice/cloud_native-851004ce780348c1a175c7530a00f0d8/19181)
  ，参考
  [Terraform 简介](https://blog.csdn.net/u012562943/article/details/110479507)
* [Terraform 配置和构建基础设施](https://edu.csdn.net/skill/practice/cloud_native-b6368923f8b04480a8345495b9da4a7c/19216)

**Note**
：

* `Terraform`
  是一种安全有效地构建、更改和版本控制的
  **基础设施管理工具**
  (基础架构自动化的编排工具)，它的目标是
  `Write, Plan, and create Infrastructure as Code`
  ,
  **基础架构即代码**
  ，允许我们以代码的方式构建、更改和管理基础设施。
  `Terraform`
  并不局限于任何特定的云服务提供商，它可以与多个云提供商和环境协同工作，虽然 Azure,AWS 分明有针对自己云平台的资源管理、设置的解决方案。
* `Terraform`
  能够让您在云上轻松
  **使用 简单模板语言 来定义、预览和部署云基础结构**
  。您可以使用
  `Terraform`
  来
  **创建、修改、删除ECS、VPC、RDS、SLB等多种资源**
  。
    
  可以从两个方面来简化理解:
    
  1）
  `Terraform`
  采用声明式方式配置基础架构设置
    
  2）
  `Terraform`
  提供了对规范的基础架构配置的命令行操作
* `Terraform`
  **对基础架构的管理**
  3个步骤:
    
  1）
  **Write**
  : 编写基础架构的配置
    
  2）
  **Plan**
  : 对配置进行校验
    
  3）
  **Apply**
  : 将配置在多云上实施、生效
* 使用
  `Terraform`
  可以让基础设施的构建
  **使用上声明式配置**
  ，具有标准化、统一配置、减少错误、跨平台的好处。

### 七、云原生环境小结

* [云原生的分层](https://edu.csdn.net/skill/practice/cloud_native-11a547517d4f412e9639ca61dcd6eaf7/19194)
* [云原生的命令](https://edu.csdn.net/skill/practice/cloud_native-34b5d17c4bb347ee896a35b06d18f7b4/19215)
* [云原生下的编程](https://edu.csdn.net/skill/practice/cloud_native-869b95155c8f4c5a9d969f364d8f75b0/19220)

**Note**
：

* 云原生下的编程，核心是将应用程序打包成容器镜像
* 云原生下的编程，容器镜像可以被部署到 k8s 的node里的pod上运行
* 云原生下的编程，天生上是分布式的程序
* 云原生下的编程，传统分
  **布式服务架构的很多开发工作都已经被下层到k8s或者服务网格基础设施层**
  。
* 云原生下的编程，有大量的对 yaml 做声明式配置的工作
* 云原生下的编程，CI/CD是常见的做法，并且具有高可用