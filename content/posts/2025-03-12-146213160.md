---
layout: post
title: "数据采集技术之python网络爬虫中国天气网的爬取"
date: 2025-03-12 19:53:16 +0800
description: "通过这段代码，可以学习如何从网页中提取结构化数据，并将其用于进一步的分析或存储。"
keywords: "python爬虫爬取天气数据csdn"
categories: ['Python']
tags: ['爬虫', 'Python', 'Pycharm']
artid: "146213160"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146213160
    alt: "数据采集技术之python网络爬虫中国天气网的爬取"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146213160
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146213160
cover: https://bing.ee123.net/img/rand?artid=146213160
image: https://bing.ee123.net/img/rand?artid=146213160
img: https://bing.ee123.net/img/rand?artid=146213160
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     数据采集技术之python网络爬虫（中国天气网的爬取）
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     一、爬取中国天气网所有地区当天的天气数据（PyCharm）：
    </h2>
    <p>
     <img alt="" height="563" src="https://i-blog.csdnimg.cn/direct/c8c4cba60f3c452fb8fbac289336eddf.png" width="1278"/>
    </p>
    <p>
     网址：
     <a href="https://www.weather.com.cn/" rel="nofollow" title="https://www.weather.com.cn/">
      https://www.weather.com.cn/
     </a>
    </p>
    <p>
     下面爬取数据：
    </p>
    <p>
     <img alt="" height="498" src="https://i-blog.csdnimg.cn/direct/e6f00a624e7e462684c3f71875357f86.png" width="1652"/>
    </p>
    <p>
     <img alt="" height="854" src="https://i-blog.csdnimg.cn/direct/ce698035688145cdbb91d6121a6b8e76.png" width="1308"/>
    </p>
    <p>
     因为现在已经到了夜间，所以白天的数据已经不见了，但原理是一样的。
    </p>
    <h2>
     二、代码以及详情解释：
    </h2>
    <p>
     具体的代码的url以及headers是要从检查里面找的：
    </p>
    <p>
     <img alt="" height="1033" src="https://i-blog.csdnimg.cn/direct/a765e79ca94f4592b07ed67b9add9ee1.png" width="1868"/>
    </p>
    <p>
     <img alt="" height="821" src="https://i-blog.csdnimg.cn/direct/8ade7dc7ba314dd3b133d4c5be186cf8.png" width="816">
     </img>
    </p>
    <p>
     以及这些元素代码的寻找：
    </p>
    <p>
     这个代码是一个用于从中国天气网（
     <code>
      weather.com.cn
     </code>
     ）抓取天气信息的Python脚本。它使用了
     <code>
      requests
     </code>
     库发送HTTP请求，并使用
     <code>
      BeautifulSoup
     </code>
     库解析HTML内容。以下是代码的主要功能和相关知识点的罗列：
    </p>
    <hr/>
    <h4>
     <strong>
      代码功能概述
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        遍历多个地区
       </strong>
       ：代码通过遍历一个地区列表（
       <code>
        area
       </code>
       ），构造不同的URL来获取不同地区的天气信息。
      </p>
     </li>
     <li>
      <p>
       <strong>
        发送HTTP请求
       </strong>
       ：使用
       <code>
        requests.get()
       </code>
       发送HTTP请求，获取网页的HTML内容。
      </p>
     </li>
     <li>
      <p>
       <strong>
        解析HTML
       </strong>
       ：使用
       <code>
        BeautifulSoup
       </code>
       解析HTML内容，提取所需的天气信息。
      </p>
     </li>
     <li>
      <p>
       <strong>
        提取天气信息
       </strong>
       ：从HTML中提取城市名称、上午天气、上午风力风向、上午最高温度、晚上天气、晚上风力风向、晚上最低温度等信息。
      </p>
     </li>
     <li>
      <p>
       <strong>
        去重处理
       </strong>
       ：使用集合
       <code>
        processed_cities
       </code>
       来避免重复处理同一个城市的天气信息。
      </p>
     </li>
     <li>
      <p>
       <strong>
        打印结果
       </strong>
       ：将提取的天气信息格式化输出到控制台。
      </p>
     </li>
    </ol>
    <hr/>
    <h4>
     <strong>
      涉及的知识点
     </strong>
    </h4>
    <h5>
     <strong>
      1. Python基础
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        列表与循环
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         使用列表
         <code>
          area
         </code>
         存储地区代码。
        </p>
       </li>
       <li>
        <p>
         使用
         <code>
          for
         </code>
         循环遍历列表中的每个地区。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        字符串格式化
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         使用
         <code>
          f-string
         </code>
         （如
         <code>
          f"https://www.weather.com.cn/textFC/{page}.shtml"
         </code>
         ）动态构造URL。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        集合（Set）
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         使用集合
         <code>
          processed_cities
         </code>
         来存储已经处理过的城市名称，确保每个城市只被处理一次。
        </p>
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <strong>
      2. HTTP请求
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        <code>
         requests
        </code>
        库
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         使用
         <code>
          requests.get()
         </code>
         发送HTTP GET请求，获取网页内容。
        </p>
       </li>
       <li>
        <p>
         设置请求头
         <code>
          headers
         </code>
         ，模拟浏览器访问，避免被网站反爬虫机制拦截。
        </p>
       </li>
       <li>
        <p>
         使用
         <code>
          res.encoding = 'utf-8'
         </code>
         设置响应内容的编码为UTF-8，确保中文内容正确显示。
        </p>
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <strong>
      3. HTML解析
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        <code>
         BeautifulSoup
        </code>
        库
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         使用
         <code>
          BeautifulSoup(res.text, 'lxml')
         </code>
         解析HTML内容，
         <code>
          lxml
         </code>
         是解析器。
        </p>
       </li>
       <li>
        <p>
         使用
         <code>
          soup.select()
         </code>
         方法通过CSS选择器查找HTML元素。
        </p>
       </li>
       <li>
        <p>
         使用
         <code>
          find()
         </code>
         和
         <code>
          find_all()
         </code>
         方法查找特定的HTML标签和属性。
        </p>
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <strong>
      4. HTML结构与CSS选择器
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        HTML表格结构
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         网页中的天气信息以表格形式展示，代码通过查找
         <code>
          &lt;div class="conMidtab2"&gt;
         </code>
         和
         <code>
          &lt;tr&gt;
         </code>
         、
         <code>
          &lt;td&gt;
         </code>
         标签来提取数据。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        CSS选择器
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         使用
         <code>
          div.conMidtab2
         </code>
         选择所有
         <code>
          class
         </code>
         为
         <code>
          conMidtab2
         </code>
         的
         <code>
          &lt;div&gt;
         </code>
         元素。
        </p>
       </li>
       <li>
        <p>
         使用
         <code>
          tr
         </code>
         选择表格行，
         <code>
          td
         </code>
         选择表格单元格。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        HTML属性
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         通过
         <code>
          width
         </code>
         属性（如
         <code>
          width='83'
         </code>
         ）定位特定的表格单元格。
        </p>
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <strong>
      5. 数据提取与处理
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        提取文本内容
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         使用
         <code>
          .string
         </code>
         提取HTML标签内的文本内容（如
         <code>
          tr.find('td', width='83').a.string
         </code>
         ）。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        条件判断
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         使用
         <code>
          if
         </code>
         语句检查是否存在某个HTML元素或属性，避免因元素不存在而报错。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        数据格式化与输出
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         使用
         <code>
          print()
         </code>
         函数将提取的天气信息格式化输出。
        </p>
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <strong>
      6. 去重与集合
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        集合（Set）
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         使用集合
         <code>
          processed_cities
         </code>
         存储已经处理过的城市名称，利用集合的唯一性特性避免重复处理。
        </p>
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <strong>
      7. 异常处理（未显式实现）
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       代码中没有显式的异常处理（如
       <code>
        try-except
       </code>
       ），但在实际应用中，建议添加异常处理机制，以应对网络请求失败或HTML解析错误等情况。
      </p>
     </li>
    </ul>
    <hr/>
    <h4>
     <strong>
      代码执行流程
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        遍历地区列表
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         对每个地区代码（如
         <code>
          hb
         </code>
         、
         <code>
          db
         </code>
         等），构造对应的URL。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        发送HTTP请求
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         使用
         <code>
          requests.get()
         </code>
         获取网页内容。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        解析HTML
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         使用
         <code>
          BeautifulSoup
         </code>
         解析HTML，查找包含天气信息的表格。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        提取天气信息
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         遍历表格行，提取城市名称、天气、风力风向、温度等信息。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        去重处理
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         使用集合
         <code>
          processed_cities
         </code>
         避免重复处理同一城市。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        输出结果
       </strong>
       ：
      </p>
      <ul>
       <li>
        <p>
         将提取的天气信息格式化输出到控制台。
        </p>
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <strong>
      总结
     </strong>
    </h4>
    <p>
     这段代码展示了如何使用Python进行网页抓取和HTML解析，涉及的知识点包括：
    </p>
    <ul>
     <li>
      <p>
       Python基础（列表、循环、字符串格式化、集合）
      </p>
     </li>
     <li>
      <p>
       HTTP请求（
       <code>
        requests
       </code>
       库）
      </p>
     </li>
     <li>
      <p>
       HTML解析（
       <code>
        BeautifulSoup
       </code>
       库）
      </p>
     </li>
     <li>
      <p>
       HTML结构与CSS选择器
      </p>
     </li>
     <li>
      <p>
       数据提取与处理
      </p>
     </li>
     <li>
      <p>
       去重与集合
      </p>
     </li>
    </ul>
    <p>
     通过这段代码，可以学习如何从网页中提取结构化数据，并将其用于进一步的分析或存储。
    </p>
    <pre><code class="language-python">import requests
from bs4 import BeautifulSoup

# 定义地区列表
area = ["hb", "db", "hd", "hz", "hn", "xb", "xn", "gat"]

for page in area:
    # 构造 URL
    url = f"https://www.weather.com.cn/textFC/{page}.shtml"
    headers = {
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36 Edg/134.0.0.0"
    }

    # 发送 HTTP 请求获取网页内容
    res = requests.get(url=url, headers=headers)
    res.encoding = 'utf-8'  # 设置编码为 UTF-8

    # 使用 BeautifulSoup 解析网页内容
    soup = BeautifulSoup(res.text, 'lxml')

    # 用于存储已经处理过的城市名称
    processed_cities = set()

    # 遍历所有 class 为 conMidtab2 的 div 元素
    for div in soup.select('div.conMidtab2'):
        # 遍历 div 中的所有 tr 元素（表格行）
        for tr in div.select('tr'):
            # 检查当前行是否包含宽度为 83 的 td 元素，该元素可能包含城市信息
            if tr.find('td', width='83'):
                # 检查宽度为 83 的 td 元素中是否有 a 标签，a 标签内通常是城市名
                if tr.find('td', width='83').a:
                    # 提取城市名
                    city = tr.find('td', width='83').a.string

                    # 如果城市已经处理过，则跳过
                    if city in processed_cities:
                        continue
                    # 否则，将城市添加到已处理集合中
                    processed_cities.add(city)

                    # 打印城市名
                    print(f"城市：{city}")

                    # 提取上午天气信息
                    morning_weather_td = tr.find('td', width='89')
                    if morning_weather_td:
                        morning_weather = morning_weather_td.string
                        print(f"上午天气：{morning_weather}")

                    # 提取上午风力风向信息
                    morning_wind_td = tr.find('td', width='162')
                    if morning_wind_td:
                        spans = morning_wind_td.find_all('span')
                        if len(spans) &gt;= 2:
                            morning_wind_1 = spans[0].string
                            morning_wind_2 = spans[1].string
                            print(f"上午风力风向：{morning_wind_1} {morning_wind_2}")

                    # 提取上午最高温度
                    morning_max_temp_td = tr.find('td', width='92')
                    if morning_max_temp_td:
                        morning_max_temp = morning_max_temp_td.string
                        print(f"上午最高温度：{morning_max_temp}")

                    # 提取晚上天气信息
                    night_weather_td = tr.find('td', width='98')
                    if night_weather_td:
                        night_weather = night_weather_td.string
                        print(f"晚上天气：{night_weather}")

                    # 提取晚上风力风向信息
                    night_wind_td = tr.find('td', width='177')
                    if night_wind_td:
                        spans = night_wind_td.find_all('span')
                        if len(spans) &gt;= 2:
                            night_wind_1 = spans[0].string
                            night_wind_2 = spans[1].string
                            print(f"晚上风力风向：{night_wind_1} {night_wind_2}")

                    # 提取晚上最低温度
                    night_min_temp_td = tr.find('td', width='86')
                    if night_min_temp_td:
                        night_min_temp = night_min_temp_td.string
                        print(f"晚上最低温度：{night_min_temp}")

                    # 打印分隔线，用于区分不同城市的天气信息
                    print('-----------------')
            else:
                # 如果当前行不包含宽度为 83 的 td 元素，跳过该行
                continue</code></pre>
    <h2>
     三、代码运行结果展示：
    </h2>
    <p>
     <img alt="" height="764" src="https://i-blog.csdnimg.cn/direct/dd970b51a5784eb29ef9a5ea84b53c06.png" width="884"/>
    </p>
    <p>
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f323330315f38303934353131332f:61727469636c652f64657461696c732f313436323133313630" class_="artid" style="display:none">
 </p>
</div>


