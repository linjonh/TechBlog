---
layout: post
title: "本地部署LLaMA-Factory"
date: 2025-03-14 19:28:57 +0800
description: "LLaMA-Factory是一个专注于大模型训练、微调、推理和部署的开源平台。这个平台的设计目标是简化大模型的训练流程，增强模型微调能力，优化推理和部署体验，以及促进社区协作。LLaMA-Factory支持多种模型类型，包括LLaMA、LLaVA、Mistral、Mixtral-MoE、Qwen、Yi、Gemma、Baichuan、ChatGLM、Phi等，并提供了多种训练算法、运算精度、优化算法、加速算子和推理引擎。"
keywords: "llama-factory下载"
categories: ['大模型微调']
tags: ['人工智能', 'Llama']
artid: "146263620"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146263620
    alt: "本地部署LLaMA-Factory"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146263620
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146263620
cover: https://bing.ee123.net/img/rand?artid=146263620
image: https://bing.ee123.net/img/rand?artid=146263620
img: https://bing.ee123.net/img/rand?artid=146263620
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     本地部署LLaMA-Factory
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     1. 介绍
    </h2>
    <p>
     LLaMA-Factory是一个专注于大模型训练、微调、推理和部署的开源平台。这个平台的设计目标是简化大模型的训练流程，增强模型微调能力，优化推理和部署体验，以及促进社区协作。LLaMA-Factory支持多种模型类型，包括LLaMA、LLaVA、Mistral、Mixtral-MoE、Qwen、Yi、Gemma、Baichuan、ChatGLM、Phi等，并提供了多种训练算法、运算精度、优化算法、加速算子和推理引擎。
    </p>
    <p>
     LLaMA-Factory的特点包括：
    </p>
    <ul>
     <li>
      无需编写代码即可在本地完成上百种预训练模型的微调。
     </li>
     <li>
      提供了多个高层次抽象的调用接口和网页版工作台，方便用户使用。
     </li>
     <li>
      支持多种微调方法，如LoRA、QLoRA等，允许用户根据特定任务需求对模型进行精细调整。
     </li>
     <li>
      提供便捷的推理接口和部署工具，支持多种硬件环境和云服务平台。
     </li>
    </ul>
    <p>
     此外，LLaMA-Factory还提供了一个全面的教程，涵盖了从环境搭建到模型训练评估的全过程。这个教程旨在帮助开发者迅速浏览和实践项目涉及到的常见功能，包括原始模型直接推理、自定义数据集构建、基于LoRA的sft指令微调、动态合并LoRA的推理、批量预测和训练效果评估、LoRA模型合并导出、一站式webui board的使用、API Server的启动与调用，以及大模型主流评测benchmark。
    </p>
    <h2>
     2. 部署LLaMA-Factory
    </h2>
    <h3>
     2.1 检验硬件环境是否支持
    </h3>
    <p>
     在命令行窗口中输入如下命令，查看自己电脑的显卡配置信息。
    </p>
    <pre><code class="hljs">nvidia-smi</code></pre>
    <p>
     <img alt="" height="655" src="https://i-blog.csdnimg.cn/direct/972626ed3df247e49e66c6de966129cc.png" width="1106"/>
    </p>
    <h3>
     2.2 下载LLaMA-Factory
    </h3>
    <p>
     首先在本地需要部署的地方建好目录，用于将LLaMA-Factory下载到这个目录当中。然后使用如下的命令将LLaMA-Factory从仓库克隆到本地。
    </p>
    <pre><code class="hljs">//github上克隆
git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git

//gitee上克隆，如果本地在github上克隆遇到错误时，就切换到这个
git clone https://gitee.com/qzl9999/LLaMA-Factory.git</code></pre>
    <p>
     执行完命令之后，可以看见本地的文件夹就有了 LLaMA-Factory文件夹。
    </p>
    <p>
     <img alt="" height="210" src="https://i-blog.csdnimg.cn/direct/6231e075fd0549cd9aeef168e5e1d0d2.png" width="1133"/>
    </p>
    <p>
     <img alt="" height="116" src="https://i-blog.csdnimg.cn/direct/ba444b71f9db4c2eb6aa12d48ec50461.png" width="784"/>
    </p>
    <h3>
     2.3 创建LLaMA-Factory需要的虚拟环境
    </h3>
    <p>
     输入如下的命令创建环境，-n是需要创建的虚拟环境的名称，python后面是指定的python版本，建议使用3.10版本。
    </p>
    <pre><code class="hljs">conda create -n llama_factory python=3.10</code></pre>
    <p>
     在创建过程中，如果遇到如下图所示的情况后，输入y即可。
    </p>
    <p>
     <img alt="" height="49" src="https://i-blog.csdnimg.cn/direct/9d099058eece4210a14805b8b0e3d2bc.png" width="212"/>
    </p>
    <p>
     看到如下图所示的输出后，则说明已经创建成功。
    </p>
    <p>
     <img alt="" height="307" src="https://i-blog.csdnimg.cn/direct/fac7ea31441343a2b0cb74776413c522.png" width="627"/>
    </p>
    <p>
     接下来就可以使用如下的命令使用环境。使用成功后会看到前面出现虚拟环境的名字。
    </p>
    <pre><code class="hljs">conda activate llama_factory</code></pre>
    <p>
     <img alt="" height="155" src="https://i-blog.csdnimg.cn/direct/9748ab697d8449e7b0e0c74e1326742f.png" width="859"/>
    </p>
    <p>
     2.4 安装需要的依赖
    </p>
    <p>
     使用命令切换到该目录下之后，然后安装相关的依赖。
    </p>
    <pre><code class="hljs">cd LLaMA-Factory
pip install -e ".[torch,metrics]"</code></pre>
    <p>
     到这里说明已经依赖已经安装成功。
    </p>
    <p>
     <img alt="" height="309" src="https://i-blog.csdnimg.cn/direct/fcb517a662e1430092c2fc7d840d6a5c.png" width="1097"/>
    </p>
    <p>
     安装成功后使用如下命令查看是否安装成功，如果看到对应的版本信息则说明安装成功。
    </p>
    <pre><code class="hljs">llamafactory-cli version</code></pre>
    <p>
     <img alt="" height="291" src="https://i-blog.csdnimg.cn/direct/db99070382044ce1b66a4e5576879a18.png" width="1429"/>
    </p>
    <h3>
     2.4 校验CUDA和Pytorch环境是否符合要求
    </h3>
    <p>
     在命令行中输入python进入Python操作界面，然后以此输入如下命令进行查看，如果识别到了可用的GPU就可以进行后续操作，如果识别不到，还需要继续处理环境问题，才能进行后续操作，否则可能会报错。查询结束之后，输入exit()，即可退出Python运行环境。
    </p>
    <pre><code class="hljs">import torch
torch.cuda.current_device()
torch.cuda.get_device_name(0)
torch.__version__</code></pre>
    <p>
     <img alt="" height="251" src="https://i-blog.csdnimg.cn/direct/0008355848f64789be2e289214eebb3a.png" width="932"/>
    </p>
    <h3>
     2.5 打开可视化微调界面。
    </h3>
    <p>
     输入下面的命令，然后就可以启动LLaMA-Factory，进入可视化界面。
    </p>
    <pre><code class="hljs">llamafactory-cli webui</code></pre>
    <p>
     <img alt="" height="1234" src="https://i-blog.csdnimg.cn/direct/13f6637936c14486bf45416ec44dbbf9.png" width="2432"/>
    </p>
    <h2>
     3. 下载模型
    </h2>
    <p>
     我了解的有两个常用的下载模型的网站。
     <br/>
     <a href="https://hf-mirror.com/models" rel="nofollow" title="Models - Hugging Face">
      Models - Hugging Face
     </a>
     ，这个网站下载模型需要注册登录，我试了好几次没有注册成功，如果可以注册成功，可以选择这个。
    </p>
    <p>
     <img alt="" height="1225" src="https://i-blog.csdnimg.cn/direct/d0c5bc8cf3234db8bb6cf0add3b4f9c1.png" width="1998"/>
    </p>
    <p>
     <a href="https://modelscope.cn/models" rel="nofollow" title="模型库首页 · 魔搭社区">
      模型库首页 · 魔搭社区
     </a>
     ，这个网站注册登陆后，也可以下载模型，而且速度还不慢。
    </p>
    <p>
     <img alt="" height="1213" src="https://i-blog.csdnimg.cn/direct/48d9cc0e5193493c998a14cca93af7fd.png" width="2221"/>
    </p>
    <p>
     这里的模型选择需要考虑自己的显卡，为了能成功运行，我选择的是Qwen2.5-3B-Instruct这个3B的模型。
    </p>
    <p>
     <img alt="" height="1141" src="https://i-blog.csdnimg.cn/direct/ff52f223a04d4f3d8a91087f1999ae33.png" width="2196"/>
    </p>
    <p>
     点击模型文件后下载模型，然后复制下面的git命令，在命令行进行下载。
    </p>
    <p>
     <img alt="" height="953" src="https://i-blog.csdnimg.cn/direct/6a091559daf7438994df040cdfbbe914.png" width="2358"/>
    </p>
    <p>
     <img alt="" height="1186" src="https://i-blog.csdnimg.cn/direct/3dd44bd975344926954863b5f7f91a4e.png" width="2281"/>
    </p>
    <p>
     注意下载的模型还是要在原来的这个目录下。执行命令后就可以进行下载，耐心等待下载完成即可。
    </p>
    <p>
     <img alt="" height="62" src="https://i-blog.csdnimg.cn/direct/ef2ed3352bc345e0a6bd1a30e15f64e2.png" width="1448"/>
    </p>
    <p>
     出现如下界面，就说明已经下载完成了。
    </p>
    <p>
     <img alt="" height="280" src="https://i-blog.csdnimg.cn/direct/2ea86cf0642b45ee8ab024d032b623b7.png" width="1102"/>
    </p>
    <h2>
     4. 训练模型
    </h2>
    <p>
     在可视化界面训练模型之前，还需要进行一些配置。
    </p>
    <h3>
     4.1 模型和数据集配置
    </h3>
    <p>
     首先选择zh，将语言切换到中文，这样后续操作也方便。
    </p>
    <p>
     <img alt="" height="346" src="https://i-blog.csdnimg.cn/direct/73e0cb516bf247b488aeb44311c701bd.png" width="369"/>
    </p>
    <p>
     然后模型名称就是刚才下载的模型的名称，由于模型是安装在LLaMA-Factory目录之下，所以模型路径直接使用文件夹的名字即可。
    </p>
    <p>
     <img alt="" height="395" src="https://i-blog.csdnimg.cn/direct/9eb7702fb2e74a06b62dc448b8d594f5.png" width="807"/>
    </p>
    <p>
     设置好如下图所示：
    </p>
    <p>
     <img alt="" height="436" src="https://i-blog.csdnimg.cn/direct/4018edd2625c4257aa60458fe516a054.png" width="2405"/>
    </p>
    <h3>
     4.2 设置训练参数
    </h3>
    <p>
     首先选择一个数据集，随便选择一个即可，然后设置学习率和训练轮数，可以按照图里的进行设置。至于其他的参数和设置，我还没有了解清楚，后续了解清楚了再写文章进行介绍。
    </p>
    <p>
     <img alt="" height="1117" src="https://i-blog.csdnimg.cn/direct/deec98c7447343168bccc95b37fd2452.png" width="2359"/>
    </p>
    <h3>
     4.3 开始训练
    </h3>
    <p>
     设置好参数后，点击预览命令，就会以命令行的方式显示刚才的各种配置。关于这个命令还需要好好注意，后面如果不用可视化界面的话，都需要依靠命令行进行操作。然后点击开始按钮，就开始训练了。
    </p>
    <p>
     <img alt="" height="1212" src="https://i-blog.csdnimg.cn/direct/e39401038aa84b6199cc136b54baacb5.png" width="2361"/>
    </p>
    <p>
     点击开始训练后，稍等片刻，就可以看见对应的进度、图像和日志。
    </p>
    <p>
     <img alt="" height="1182" src="https://i-blog.csdnimg.cn/direct/9c4b405b94054fe8884b0dabb2378c7b.png" width="2462"/>
    </p>
    <p>
     到这里，LLaMA-Factory工具就算是在本地成功部署了。后续的内容还需要继续学习更新。
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34363033303739342f:61727469636c652f64657461696c732f313436323633363230" class_="artid" style="display:none">
 </p>
</div>


