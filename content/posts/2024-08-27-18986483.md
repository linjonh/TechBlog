---
arturl_encode: "687474:70733a2f2f626c6f672e6373646e2e6e65742f68746a783939:2f61727469636c652f64657461696c732f3138393836343833"
layout: post
title: "音视频打包传送"
date: 2024-08-27 10:45:32 +0800
description: "1 请教大伙   我只做过 MPEG4视频流的RTP打包传输 接收  现在加入了音频采集 所以要发送"
keywords: "视频流是音频和视频封装后传输还是分开传输"
categories: ['未分类']
tags: ['无标签']
artid: "18986483"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=18986483
  alt: "音视频打包传送"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=18986483
featuredImagePreview: https://bing.ee123.net/img/rand?artid=18986483
---

# 音视频打包传送

1 请教大伙
  
我只做过 MPEG4视频流的RTP打包传输 接收
  
现在加入了音频采集 所以要发送 音视频流
  
我想请问大伙 在发送时 一般的做法是 音视频流分开发送
  
还是 发送音视频的合成流？
  
答案：

直播考虑实时性的话，就可能要考虑丢视频包、保音频包；分开传输比较好

点播不考虑实时性、要求同步的话，可以进行缓冲；合并传输比较好

现在的话 对合成流打包 就不需要有什么讲究了吧
  
在接收端 解RTP包 在接 分解 filter 再 分别解压音视频流

1 一个音视频同步算法。

情况是这样的，我们同步网络把音频/视频分开传送到接收端，现在的问题关键问题的如果对这股流进行同步播放。
  
我现在的算法是这样的:
  
在发送方:
  
对于相同时刻的音频/视频帧，打上相同的时间戳(系统时间)
  
接收方:
  
保存两个队列，audio/video分别用来存放还未播放的音频和视频
  
1。当每接收到音频帧的时候，遍历此时的video队列，将此音频帧的时间戳跟每个视频帧的时间戳进行比较:
  
1)如果音频帧的时间在这个视频帧的前面，帧播放该音频
  
2)如果音频跟视频的时间戳相差在某个可以接受的误差内，则同时播放该音频/视频(并将视频帧从video队列中删除)
  
3)如果视频时间在前，则播放视频帧(并将视频帧从video队列中删除)
  
如果video队列中的最后一帧的时间都在这个audio帧之前，在此时会把整个video队列中的帧播放完，此时video队列将为空，那么将这个音频放入audio队列。
  
2.对接收到视频帧的时候，也做类似的处理。
  
现在我们在局域网内测试，没有任何的问题。
  
但是我自己发现这个算法还是有些问题:
  
1)音频和视频发送帧的频率不一样，假如audio的频率是video的3倍，那么播放时，会是3个3个音频帧地播放
  
2)如果网络比较差的话，只有一个通道是好的时，将不能正常播放。我现在采取的方法是设定一个时间，如果没有接收到帧的话，就认为该通道是断开的，然后就只管自己播放。这样可以解决一些问题，但是在这不判断这个流是断开的过程中，另外一个流的播放是停止的，这是个大问题。我看网络播放方面的软件都没有这个问题，它们的音频给视频似乎是各自独立的，除了在同步的时候。