---
layout: post
title: "Scaling-Laws-for-Neural-Language-Models"
date: 2025-03-07 10:36:01 +0800
description: "调查大模型与模型结构，模型大小，算力，数据之间的关系。这种关系可以被更严格地定义成 Scaling Law，这是一个可以描述 LLM 的测试损失随某个量（如训练计算量）的增长而降低的公式。Scaling Law 可帮助我们预测当投入更多资源进行更大规模训练时的效果，这能给我们提供继续投资 scaling 的必要信心。如何合理的分配资源来达到更好的训练效果。问题：模型的形状（即层的数量和大小）重要吗？使模型更大是否有助于其表现更好？训练这些更大的模型需要多少数据匹配？"
keywords: "Scaling Laws for Neural Language Models"
categories: ['Llm']
tags: ['语言模型', '深度学习', '人工智能']
artid: "146048637"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146048637
    alt: "Scaling-Laws-for-Neural-Language-Models"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146048637
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146048637
cover: https://bing.ee123.net/img/rand?artid=146048637
image: https://bing.ee123.net/img/rand?artid=146048637
img: https://bing.ee123.net/img/rand?artid=146048637
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Scaling Laws for Neural Language Models
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="./../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="./../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-tomorrow-night-eighties" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="Scaling_Laws_for_Neural_Language_Models_0">
     </a>
     Scaling Laws for Neural Language Models
    </h3>
    <h4>
     <a id="_2">
     </a>
     摘要：
    </h4>
    <p>
     调查大模型与模型结构，模型大小，算力，数据之间的关系。这种关系可以被更严格地定义成 Scaling Law，这是一个可以描述 LLM 的测试损失随某个量（如训练计算量）的增长而降低的公式。Scaling Law 可帮助我们预测当投入更多资源进行更大规模训练时的效果，这能给我们提供继续投资 scaling 的必要信心。如何合理的分配资源来达到更好的训练效果。
    </p>
    <p>
     问题：
     <br/>
     模型的形状（即层的数量和大小）重要吗？
     <br/>
     使模型更大是否有助于其表现更好？
     <br/>
     训练这些更大的模型需要多少数据匹配？
     <br/>
     可以提前预测loss early stop吗？
    </p>
    <p>
     结论：
    </p>
    <ul>
     <li>
      模型性能主要与模型参数量N，数据集大小D，算力C相关，与模型参数（例如深度or宽度）无关。
     </li>
     <li>
      当不受另外两个参数限制时，模型性能与N，D，C成幂律的关系。单独改变一个参数，性能变化是平缓的。
     </li>
     <li>
      性能变化是可预测的，只要同时放大N与D的规模，如果N与D保持不变，另外一个增加，则会进入收益递减的状态。性能损失可预见的取决于该比例：
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         N 
          
         
           0.74 
          
         
        
          / 
         
        
          D 
         
        
       
         N^{0.74}/D
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 1.0641em; vertical-align: -0.25em;">
          </span>
          <span class="mord">
           <span class="mord mathnormal" style="margin-right: 0.109em;">
            N
           </span>
           <span class="msupsub">
            <span class="vlist-t">
             <span class="vlist-r">
              <span class="vlist" style="height: 0.8141em;">
               <span class="" style="top: -3.063em; margin-right: 0.05em;">
                <span class="pstrut" style="height: 2.7em;">
                </span>
                <span class="sizing reset-size6 size3 mtight">
                 <span class="mord mtight">
                  <span class="mord mtight">
                   0.74
                  </span>
                 </span>
                </span>
               </span>
              </span>
             </span>
            </span>
           </span>
          </span>
          <span class="mord">
           /
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0278em;">
           D
          </span>
         </span>
        </span>
       </span>
      </span>
      ， 如果增加模型大小8倍，需要同时增加数据大小5倍来避免惩罚（避免过拟合）。
     </li>
     <li>
      训练曲线遵循可预测的幂律，其参数大致与模型大小无关，通过外推早期预测曲线，后期loss是大致可预测的。
     </li>
     <li>
      sample-efficient ：大模型比小模型更加sample-efficient，使用更少的train step和数据可以达到相关的效果。
     </li>
    </ul>
    <p>
     也就是说模型的测试损失和模型参数量之间存在可测量的关系。其中一个量的变化将导致另一个量发生相对的、无关尺度的变化。换句话说，我们可基于这种关系了解到：增加模型参数量（假设已满足其他条件，比如训练数据充足）将导致测试损失降低某个可预测的程度。
    </p>
    <ul>
     <li>
      当拥有更多计算资源时，应该如何分配：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b0541573f49e402babe0733e740f368e.png"/>
     </li>
    </ul>
    <h3>
     <a id="Test_loss_25">
     </a>
     Test loss预测
    </h3>
    <p>
     在其他条件固定且充足的条件下，test loss是可预测的：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/ee7ed7b7fead457195d3d90167494a53.png"/>
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/5494d120e194468aa764b8a23ecc3317.png">
      <br/>
      LLM 的性能（就其在 WebText2 上的测试损失而言）会随着参数、数据和计算量的增加而稳步提高。这些趋势在计算量方面跨越了八个数量级，在模型大小方面跨越了六个数量级，在数据集大小方面跨越了两个数量级(横坐标)。上图提供了确切的幂律关系和拟合每个幂律关系的方程。
     </img>
    </p>
    <p>
     随着我们扩大参数
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        N 
        
       
      
        N
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 0.6833em;">
         </span>
         <span class="mord mathnormal" style="margin-right: 0.109em;">
          N
         </span>
        </span>
       </span>
      </span>
     </span>
     ,
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        D 
        
       
      
        D
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 0.6833em;">
         </span>
         <span class="mord mathnormal" style="margin-right: 0.0278em;">
          D
         </span>
        </span>
       </span>
      </span>
     </span>
     ,
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        C 
         
         
         
           m 
          
         
           i 
          
         
           n 
          
         
        
       
      
        C_{min}
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 0.8333em; vertical-align: -0.15em;">
         </span>
         <span class="mord">
          <span class="mord mathnormal" style="margin-right: 0.0715em;">
           C
          </span>
          <span class="msupsub">
           <span class="vlist-t vlist-t2">
            <span class="vlist-r">
             <span class="vlist" style="height: 0.3117em;">
              <span class="" style="top: -2.55em; margin-left: -0.0715em; margin-right: 0.05em;">
               <span class="pstrut" style="height: 2.7em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mtight">
                 <span class="mord mathnormal mtight">
                  min
                 </span>
                </span>
               </span>
              </span>
             </span>
             <span class="vlist-s">
              ​
             </span>
            </span>
            <span class="vlist-r">
             <span class="vlist" style="height: 0.15em;">
              <span class="">
              </span>
             </span>
            </span>
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
     </span>
     ，模型性能改变的程度成
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        α 
         
        
          N 
         
        
       
      
        \alpha_{N}
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 0.5806em; vertical-align: -0.15em;">
         </span>
         <span class="mord">
          <span class="mord mathnormal" style="margin-right: 0.0037em;">
           α
          </span>
          <span class="msupsub">
           <span class="vlist-t vlist-t2">
            <span class="vlist-r">
             <span class="vlist" style="height: 0.3283em;">
              <span class="" style="top: -2.55em; margin-left: -0.0037em; margin-right: 0.05em;">
               <span class="pstrut" style="height: 2.7em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mtight">
                 <span class="mord mathnormal mtight" style="margin-right: 0.109em;">
                  N
                 </span>
                </span>
               </span>
              </span>
             </span>
             <span class="vlist-s">
              ​
             </span>
            </span>
            <span class="vlist-r">
             <span class="vlist" style="height: 0.15em;">
              <span class="">
              </span>
             </span>
            </span>
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
     </span>
     ，
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        α 
         
        
          D 
         
        
       
      
        \alpha_{D}
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 0.5806em; vertical-align: -0.15em;">
         </span>
         <span class="mord">
          <span class="mord mathnormal" style="margin-right: 0.0037em;">
           α
          </span>
          <span class="msupsub">
           <span class="vlist-t vlist-t2">
            <span class="vlist-r">
             <span class="vlist" style="height: 0.3283em;">
              <span class="" style="top: -2.55em; margin-left: -0.0037em; margin-right: 0.05em;">
               <span class="pstrut" style="height: 2.7em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mtight">
                 <span class="mord mathnormal mtight" style="margin-right: 0.0278em;">
                  D
                 </span>
                </span>
               </span>
              </span>
             </span>
             <span class="vlist-s">
              ​
             </span>
            </span>
            <span class="vlist-r">
             <span class="vlist" style="height: 0.15em;">
              <span class="">
              </span>
             </span>
            </span>
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
     </span>
     ,
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        α 
         
         
         
           C 
          
         
           m 
          
         
           i 
          
         
           n 
          
         
        
       
      
        \alpha_{Cmin}
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 0.5806em; vertical-align: -0.15em;">
         </span>
         <span class="mord">
          <span class="mord mathnormal" style="margin-right: 0.0037em;">
           α
          </span>
          <span class="msupsub">
           <span class="vlist-t vlist-t2">
            <span class="vlist-r">
             <span class="vlist" style="height: 0.3283em;">
              <span class="" style="top: -2.55em; margin-left: -0.0037em; margin-right: 0.05em;">
               <span class="pstrut" style="height: 2.7em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mtight">
                 <span class="mord mathnormal mtight" style="margin-right: 0.0715em;">
                  C
                 </span>
                 <span class="mord mathnormal mtight">
                  min
                 </span>
                </span>
               </span>
              </span>
             </span>
             <span class="vlist-s">
              ​
             </span>
            </span>
            <span class="vlist-r">
             <span class="vlist" style="height: 0.15em;">
              <span class="">
              </span>
             </span>
            </span>
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
     </span>
     幂律变化。例如，将N增大2倍，那么loss缩小
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        2 
         
         
         
           − 
          
          
          
            α 
           
          
            N 
           
          
         
        
       
      
        2^{-\alpha_N}
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 0.7713em;">
         </span>
         <span class="mord">
          <span class="mord">
           2
          </span>
          <span class="msupsub">
           <span class="vlist-t">
            <span class="vlist-r">
             <span class="vlist" style="height: 0.7713em;">
              <span class="" style="top: -3.063em; margin-right: 0.05em;">
               <span class="pstrut" style="height: 2.7em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mtight">
                 <span class="mord mtight">
                  −
                 </span>
                 <span class="mord mtight">
                  <span class="mord mathnormal mtight" style="margin-right: 0.0037em;">
                   α
                  </span>
                  <span class="msupsub">
                   <span class="vlist-t vlist-t2">
                    <span class="vlist-r">
                     <span class="vlist" style="height: 0.3448em;">
                      <span class="" style="top: -2.3567em; margin-left: -0.0037em; margin-right: 0.0714em;">
                       <span class="pstrut" style="height: 2.5em;">
                       </span>
                       <span class="sizing reset-size3 size1 mtight">
                        <span class="mord mathnormal mtight" style="margin-right: 0.109em;">
                         N
                        </span>
                       </span>
                      </span>
                     </span>
                     <span class="vlist-s">
                      ​
                     </span>
                    </span>
                    <span class="vlist-r">
                     <span class="vlist" style="height: 0.1433em;">
                      <span class="">
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                 </span>
                </span>
               </span>
              </span>
             </span>
            </span>
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
     </span>
     =0.95倍。而模型的性能与model shape，tansformer超参数是弱相关的。
    </p>
    <h4>
     <a id="sample_efficent_33">
     </a>
     更大的模型具有更高的sample efficent
    </h4>
    <p>
     较大的 LLM 往往具有更高的样本效率，达到相同的测试效果相比小模型需要更少的数据。因此，对 LLM 进行预训练以使其收敛（可以说）不是最优的。相反，我们可以在较少的数据上训练更大的模型，在收敛之前停止训练过程。这种方法在训练计算使用量方面是最优的，但它没有考虑到推理成本。实际上通常会在更多数据上训练较小的模型，因为较小的模型推理成本较低。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/cfcd34861c204aada66aae353b82fb0b.png">
      <br/>
      将等式1.1和1.2结合，可以得到单个等式（N与D，N与S）来预测loss走势，指导过拟合的程度（loss曲线平缓了就可以early stop 见图4）：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/9278fc9fb4f440c9bd382db4f15cf4a2.png"/>
     </img>
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/af6cb0fbaeb845cb8530e7c002b7ffa2.png"/>
    </p>
    <p>
     S：number of train steps：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/74de507e0d83449ea524519b3fdc93bb.png">
      <br/>
      当使用固定的 compute budget
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         C 
        
       
      
        C
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.6833em;">
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0715em;">
           C
          </span>
         </span>
        </span>
       </span>
      </span>
      , 可以预测最优的
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         N 
        
       
      
        N
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.6833em;">
          </span>
          <span class="mord mathnormal" style="margin-right: 0.109em;">
           N
          </span>
         </span>
        </span>
       </span>
      </span>
      ,
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         B 
        
       
      
        B
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.6833em;">
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0502em;">
           B
          </span>
         </span>
        </span>
       </span>
      </span>
      ,
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         S 
        
       
      
        S
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.6833em;">
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0576em;">
           S
          </span>
         </span>
        </span>
       </span>
      </span>
      ,
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         D 
        
       
      
        D
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.6833em;">
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0278em;">
           D
          </span>
         </span>
        </span>
       </span>
      </span>
      :
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/a8a8ecbc674b4e8d8205b485dd9fb4cb.png">
       <br/>
       可以得到：
       <br/>
       <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/61f481843ce9435eb5431b2d5d09e990.png"/>
       <br/>
       所以当计算资源增加，应该主要增加模型参数
       <span class="katex--inline">
        <span class="katex">
         <span class="katex-mathml">
          N 
        
       
      
        N
         </span>
         <span class="katex-html">
          <span class="base">
           <span class="strut" style="height: 0.6833em;">
           </span>
           <span class="mord mathnormal" style="margin-right: 0.109em;">
            N
           </span>
          </span>
         </span>
        </span>
       </span>
       ,而不是训练时间和数据集。也说明了当模型变大时，会变得更加sample efficient。最优的实验结果依赖于总共的计算（等式1.3）
      </img>
     </img>
    </p>
    <h4>
     <a id="_52">
     </a>
     性能与模型参数之间的关系：
    </h4>
    <ol>
     <li>
      性能与模型shape 参数有较微弱的关系：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/723bd417a4c34323b7931cea85532182.png"/>
     </li>
     <li>
      性能与模型参数之间的关系：
     </li>
    </ol>
    <ul>
     <li>
      包含embedding参数：相同的参数下，效果与层数相关性巨大。
     </li>
     <li>
      不包含embedding参数：相同的参数下，效果呈相同的趋势（与模型shape相关参数关系微弱）。
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/64be268084404f29b8de8669f14f9677.png"/>
     </li>
    </ul>
    <ol start="3">
     <li>
      与LSTM比较：
     </li>
    </ol>
    <ul>
     <li>
      比较LSTM和Transformer的性能与non-embedding参数计数N的关系。LSTM使用相同的数据集和上下文长度进行训练。从这些图中我们可以看出，LSTM在上下文早期出现的令牌中的性能与Transformer一样好，但无法与后期的Transformer性能相匹配。性能和上下文位置之间的幂律关系：其中较大模型的幂函数越来越大，表明快速识别模式的能力得到了提高。
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/17798cc8b3974ff591cc09fbcf48577b.png"/>
     </li>
    </ul>
    <ol start="4">
     <li>
      训练时总共的non-embedding参数为：
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         C 
         
        
          = 
         
        
          6 
         
        
          N 
         
        
          B 
         
        
          S 
         
        
       
         C=6NBS
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.6833em;">
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0715em;">
           C
          </span>
          <span class="mspace" style="margin-right: 0.2778em;">
          </span>
          <span class="mrel">
           =
          </span>
          <span class="mspace" style="margin-right: 0.2778em;">
          </span>
         </span>
         <span class="base">
          <span class="strut" style="height: 0.6833em;">
          </span>
          <span class="mord">
           6
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0576em;">
           NBS
          </span>
         </span>
        </span>
       </span>
      </span>
      , 6是前向和反向传播的加和统计。所以对于给定C值，我们可以扫描不同的N值来找到最佳的性能。
     </li>
    </ol>
    <h4>
     <a id="Charting_the_Infinite_Data_Limit_and_Overfitting_63">
     </a>
     Charting the Infinite Data Limit and Overfitting
    </h4>
    <ul>
     <li>
      我们将实证证明，经过最佳训练的测试损耗符合方程式（1.5）定律。这为我们提供了指导，告诉我们需要多少数据来训练越来越大的模型，同时控制过度拟合。
      <br/>
      -
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/f6e71fb2077c49d5b1a839e315fbd08f.png"/>
      - 该公式的3个原则
     </li>
    </ul>
    <ol>
     <li>
      词汇量或标记化的变化预计将按总体因素重新调整损失。L（N，D）（以及所有损失模型）的参数化必须自然地允许这种重新缩放。
     </li>
     <li>
      固定D，放大N到无穷，整体loss接近
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         O 
         
        
          ( 
         
        
          D 
         
        
          ) 
         
        
       
         O(D)
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 1em; vertical-align: -0.25em;">
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0278em;">
           O
          </span>
          <span class="mopen">
           (
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0278em;">
           D
          </span>
          <span class="mclose">
           )
          </span>
         </span>
        </span>
       </span>
      </span>
      。同理，固定N，放大D到无穷，整体loss接近
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         O 
         
        
          ( 
         
        
          N 
         
        
          ) 
         
        
       
         O(N)
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 1em; vertical-align: -0.25em;">
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0278em;">
           O
          </span>
          <span class="mopen">
           (
          </span>
          <span class="mord mathnormal" style="margin-right: 0.109em;">
           N
          </span>
          <span class="mclose">
           )
          </span>
         </span>
        </span>
       </span>
      </span>
      。
     </li>
    </ol>
    <h4>
     <a id="Results_for_LNS_min_and_Performance_with_Model_Size_and_Compute_69">
     </a>
     Results for
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        L 
        
       
         ( 
        
       
         N 
        
       
         , 
        
        
        
          S 
         
         
         
           m 
          
         
           i 
          
         
           n 
          
         
        
       
         ) 
        
       
      
        L(N,S_{min})
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 1em; vertical-align: -0.25em;">
         </span>
         <span class="mord mathnormal">
          L
         </span>
         <span class="mopen">
          (
         </span>
         <span class="mord mathnormal" style="margin-right: 0.109em;">
          N
         </span>
         <span class="mpunct">
          ,
         </span>
         <span class="mspace" style="margin-right: 0.1667em;">
         </span>
         <span class="mord">
          <span class="mord mathnormal" style="margin-right: 0.0576em;">
           S
          </span>
          <span class="msupsub">
           <span class="vlist-t vlist-t2">
            <span class="vlist-r">
             <span class="vlist" style="height: 0.3117em;">
              <span class="" style="top: -2.55em; margin-left: -0.0576em; margin-right: 0.05em;">
               <span class="pstrut" style="height: 2.7em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mtight">
                 <span class="mord mathnormal mtight">
                  min
                 </span>
                </span>
               </span>
              </span>
             </span>
             <span class="vlist-s">
              ​
             </span>
            </span>
            <span class="vlist-r">
             <span class="vlist" style="height: 0.15em;">
              <span class="">
              </span>
             </span>
            </span>
           </span>
          </span>
         </span>
         <span class="mclose">
          )
         </span>
        </span>
       </span>
      </span>
     </span>
     and Performance with Model Size and Compute
    </h4>
    <p>
     不同预算值都有最佳的模型大小；
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/8949a145f08a4020a5600e8984410f3f.png"/>
    </p>
    <h4>
     <a id="_73">
     </a>
     实际意义
    </h4>
    <p>
     大规模预训练非常好，但这一事实却带来了一些困境。为了得到最好的模型，需要大量数据进行大规模模型训练。然而，这些训练成本很高，这意味着它们也会带来很大的风险。如果我们花费了 1000 万美元，结果训练了一个不符合我们期望的模型，这可如何是好？考虑到预训练的费用，我们无法执行任何特定于模型的调整，我们必须确保我们训练的模型表现良好。我们需要制定一个策略来调整这些模型并预测它们的性能，同时无需花费太多钱。
    </p>
    <p>
     参考：
    </p>
    <ul>
     <li>
      2020- Scaling Laws for Neural Language Models
     </li>
     <li>
      万字长文解读Scaling Law的一切，洞见LLM的未来： https://baijiahao.baidu.com/s?id=1822931723327422180&amp;wfr=spider&amp;for=pc
     </li>
    </ul>
   </div>
   <link href="./../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="./../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f79696e797531393935303831312f:61727469636c652f64657461696c732f313436303438363337" class_="artid" style="display:none">
 </p>
</div>


