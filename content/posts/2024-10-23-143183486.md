---
arturl_encode: "6874747073:3a2f2f626c6f672e6373646e2e6e65742f457665726c795f2f:61727469636c652f64657461696c732f313433313833343836"
layout: post
title: "2024-年最值得尝试的-8-个-AI-开源大模型"
date: 2024-10-23 14:31:52 +08:00
description: "本文只提及了 8 个值得尝试的开源 LLM，如果想要学习和尝试更多的 LLM，可以去 Hugging"
keywords: "开源ai模型"
categories: ['未分类']
tags:  [
    "算法",
    "机器学习",
    "开源",
    "人工智能",
    "产品经理",
    "Chatgpt",
    "1024程序员节"
  ]
artid: "143183486"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=143183486
  alt: "2024-年最值得尝试的-8-个-AI-开源大模型"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=143183486
featuredImagePreview: https://bing.ee123.net/img/rand?artid=143183486
---

# 2024 年最值得尝试的 8 个 AI 开源大模型

![](https://img-blog.csdnimg.cn/img_convert/5ba28041b899d0832083f061c501d939.png)

本文正文字数约 3000 字，阅读时间 8 分钟。

如果要将 LLM 按照是否开源来划分的话，那么，OpenAI 的 ChatGPT，Google 的 Gemini 这一类就属于闭源模型，也可以说是专有的 LLM，用户并不能深入到模型层面去使用，而是只能在基于模型的聊天应用层使用。

当然，尽管这些 LLM 提供了开放 API 给开发者，但是也只能够在一定的范围内进行调用和调试，并不能拥有对背后的模型的完全控制权。

而像 Llama 这样的模型就是属于开源模型，用户可以在自己的设备上部署、开发，甚至是微调。

相对于闭源模型，开源模型从成本、风险把控、定制化等多个方面，都有一定的优势。

所以，如果想要定制化属于自己的 LLM 或者只是尝试着在自己电脑上进行简易的部署和开发，开源 LLM 一定是第一选择。

本文将为你介绍 2024 年最值得尝试的 8 个开源 LLM。

### 开源 LLM 的好处

如上文所说，开源 LLM 的好处显而易见，接下来我将从以下方面来细化讲解这些好处。

#### 数据安全性和隐私保护

当然，并不是说使用开源 LLM 就不存在数据泄露的问题。

只是说，使用开源 LLM 的话，数据的管控都是由使用者完全控制。而如果使用闭源的 LLM，那么，这些风险其实是不可控的，而且，目前已经有多起有关于大公司使用个人或隐私数据来进行训练的争议了。

#### 成本以及对供应商的依赖性

一般来说，闭源的 LLM 在使用其 API 的时候，都是需要购买或者按量计费的，比如 Kimi、ChatGPT，不同厂商的价格会有所区别。

而开源 LLM 通常都可以直接免费下载和使用。

> 当然，在前期如果不考虑自己的硬件成本的情况下，开源 LLM 肯定是优于闭源的。如果涉及到在自己电脑或者服务器上进行微调或者推理的话，那可能就需要在硬件层面投入一定的成本了。

#### 代码透明性和模型定制化

由于开源 LLM 的源代码是公开透明的，所以可以直接查看它的工作原理，包括其架构、训练数据以及训练和推理机制，这种透明性也是定制化的基础。

#### 活跃的社区和共建

大型开源项目的最大优势就是活跃的社区以及有大量优秀的开发者来参与共建。

这样的社区可以促进 LLM 的创新，改进模型，减少偏见，提高模型的准确性和整体性能。

> 比如 Llama 3，目前在 GitHub 上已经有 25.7k Star 了，链接：https://github.com/meta-Llama/Llama3

接下来，我将依次介绍 8 个最值得尝试的开源 LLM。

### Llama 3.1

> https://Llama.meta.com/

Llama 3.1 于 2024 年 7 月 23 日发布，包含 8B、70B，以及首次推出的 405B 参数模型。

这些模型被设计用于处理多种自然语言处理任务，覆盖的语言包括英语、西班牙语、葡萄牙语、德语、泰语、法语、意大利语和印地语等。

Llama 3.1 模型支持大幅增加的上下文长度（128k），显著增强了模型处理和理解长篇文本的能力，在复杂推理任务中表现得更为出色，并在较长的对话中保持上下文的一致性。

特别是 405B 参数的模型在生成合成数据方面具有强大的能力，这些数据可以用于训练其他模型。

此外，该模型在知识蒸馏方面也具有优势，可以将其知识转移到更小、更高效的模型中。

> 详细了解 Llama 3.1 大模型，可以参考我之前的文章：
> [揭秘 Llama 3.1 405B：能与 GPT-4o 相媲美的开源 AI 模型](http://mp.weixin.qq.com/s?__biz=MzIwNDIwMTIxNQ==&mid=2653452048&idx=1&sn=9dad3c2689ec89dc170eeb1c2b7a65cb&chksm=8d1f1a80ba68939674c65654468c57452228d8bdb535fe89a1ba08a4b9397fcea237f2d0ebb2&scene=21#wechat_redirect)

### BLOOM

> https://huggingface.co/bigscience/bloom

![](https://img-blog.csdnimg.cn/img_convert/723c72c003ef02e680e7787471680a4f.png)

BLOOM 是一个自回归的 LLM，通过海量的文本数据和工业级的计算资源进行训练，能够在提示语的基础上生成连续的文本。

BLOOM 能够生成 46 种语言和 13 种编程语言的连贯文本，几乎与人类书写的文本难以区分。

此外，BLOOM 还可以在没有明确训练的情况下，将任务转化为文本生成任务，执行各种文本处理任务。

### MPT-7B

> https://huggingface.co/mosaicml/mpt-7b

MPT-7B 是一个仅解码的 Transformer 模型，由 MosaicML 从零开始预训练，处理了 1 万亿个英语文本和代码 tokens。

它属于 MPT (MosaicPretrainedTransformer) 模型家族，这些模型使用了一种经过修改的 Transformer 架构，专为高效训练和推理进行了优化。

MPT-7B 的架构改进包括性能优化的层实现，并通过用线性偏差注意力（ALiBi）替代位置嵌入，消除了上下文长度的限制。

这些改进使 MPT 模型能够以高吞吐量和稳定的收敛性进行训练，并能有效地与 HuggingFace 管道和 NVIDIA 的 FasterTransformer 集成进行推理。

模型的有以下特点：

* •
  **商业许可**
  ：与 Llama 不同，MPT-7B 允许商业用途。
* •
  **庞大的数据训练**
  ：模型训练数据量达到 1 万亿 tokens。
* •
  **处理超长输入**
  ：得益于 ALiBi，MPT-7B 可以处理极长的输入。
* •
  **快速训练与推理**
  ：通过 FlashAttention 和 FasterTransformer 提供快速的训练和推理能力。
* •
  **高效的开源训练代码**
  ：MPT-7B 提供了高效的开源训练代码，位于 llm-foundry 仓库中，链接为：https://github.com/mosaicml/llm-foundry

### Falcon 40B

> Falcon 40B: https://huggingface.co/tiiuae/falcon-40b

Falcon-40B 是一个由 TII（Technology Innovation Institute）构建的因果解码模型，拥有 40B 参数，训练数据包含 1,0000 亿个精炼网页和精选语料库的 tokens。

它在 Apache 2.0 许可下发布，允许商业用途，无需支付版税或面临限制。

Falcon-40B 在开放领域表现卓越，被认为是目前最好的开源模型。相比其他开源模型，如 Llama、StableLM、RedPajama 和 MPT，Falcon-40B 具有明显的优势。

这得益于其架构的优化，尤其是在推理方面，使用了 FlashAttention 和多查询（Multiquery）机制。

此模型是一个预训练的原始模型，适合大多数应用场景下的进一步微调。如果需要适合接收通用指令的聊天格式版本，可以参考 Falcon-40B-Instruct（https://huggingface.co/tiiuae/falcon-40b-instruct）。

### FLUX.1

> https://huggingface.co/black-forest-labs/FLUX.1-dev， Flux.1 系列模型包含 FLUX.1 [pro], FLUX.1 [dev] 和 FLUX.1 [schnell]，可以在 HuggingFace 上找到。

FLUX.1 是刚发布不久的文生图模型，甚至有人说它的性能超过了 Midjourney。

#### FLUX.1 [pro]

这是 FLUX.1 系列中的顶级版本，提供最先进的图像生成性能，具有卓越的提示语响应、视觉质量、图像细节和输出多样性。

用户可以通过 API 访问 FLUX.1 [pro]，该模型也可以通过 Replicate 和 fal.ai 使用。此外，FLUX.1 [pro] 还能够为企业提供定制解决方案。

#### FLUX.1 [dev]

这是一个开源权重模型，专为非商业应用设计。

FLUX.1 [dev] 是从 FLUX.1 [pro] 直接蒸馏而来，具备类似的质量和提示语响应能力，同时效率更高。

FLUX.1 [dev] 的权重可以在 HuggingFace 上找到，也可以在 Replicate 或 fal.ai 上直接试用。

#### FLUX.1 [schnell]

这是 FLUX.1 系列中最快的模型，专为本地开发和个人使用而设计。

FLUX.1 [schnell] 在 Apache 2.0 许可下开放，权重可在 HuggingFace 获取，推理代码可以在 GitHub 和 HuggingFace 的 Diffusers 中找到。此外，该模型与 ComfyUI 实现了集成。

### Phi-2

> https://huggingface.co/microsoft/phi-2

Phi-2 是一个拥有 2.7B 参数的 Transformer 模型，其训练数据与 Phi-1.5 相同，但增加了新的数据源，包括各种 NLP 合成文本和经过筛选的网站内容（确保安全性和教育价值）。

在评估常识、语言理解和逻辑推理的基准测试中，Phi-2 在 13B 参数以下的模型中表现最好。

与某些其他模型不同，Phi-2 并未通过人类反馈的强化学习进行微调。

此开源模型的开发目的是为研究社区提供一个不受限制的小型模型，用来探索关键的安全相关的问题，比如减少有害内容、理解社会偏见、增强模型可控性等。

### Gemma-7B

> https://huggingface.co/google/gemma-7b

Gemma 是 Google 推出的一系列轻量级、先进的开源模型家族，这些模型基于与 Gemini 模型相同的技术开发。

Gemma 是文本到文本的、仅解码的大型语言模型，主要提供英语版本，并开放了模型权重，包含预训练的变体和指令微调的变体。

Gemma 模型非常适合用于各种文本生成任务，例如问答、摘要生成和推理。

Gemma 模型的规模相对来说不算大，可以部署在资源有限的环境中，例如个人电脑或个人云基础设施上。

### Whisper large-v3

> https://huggingface.co/openai/whisper-large-v3

Whisper-large-v3 是一个用于自动语音识别 (ASR) 和语音翻译的预训练模型，由 OpenAI 开发。

这个模型基于 Transformer 架构的编码器-解码器设计，能够处理多种语言，且无需进行微调即可执行任务。

Whisper-large-v3 的目标是通过大规模弱监督学习，实现对语音数据的稳健识别。

这个模型的强大之处在于其零样本场景下的泛化能力，使得它在无需特定数据集微调的情况下，能够处理来自不同领域的任务。

### 选择适合自己的 LLM

开源 LLM 的发展速度非常快，目前在 HuggingFace 上，一共有八十多万的开源 LLM。

所以，如何选择适合自己的 LLM 就显得尤为重要了。可以从以下几点来考虑：

* • 你需要用 LLM 做什么？
* • 你需要的准确性如何？
* • 你愿意在硬件设施上投入多少资金？
* • 预训练模型是否就能够满足需求？

### 总结

本文只提及了 8 个值得尝试的开源 LLM，如果想要学习和尝试更多的 LLM，可以去 HuggingFace 上查看，这里集结了大量的优秀模型。

初期不建议投入大量资金到硬件设施上，个人学习的话，完全可以从小型的模型开始（比如 Llama 3.1 的 8B 模型、Phi-2 的 2.7B 模型），熟悉之后再选择更大的模型。

## 如何学习AI大模型 ？

#### “最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。

这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。

我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。

我意识到有很多经验和知识值得分享给大家，故此将并将重要的AI大模型资料包括
**AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。【保证100%免费】🆓**

## CSDN粉丝独家福利

这份完整版的 AI 大模型学习资料已经上传CSDN，朋友们如果需要可以点击下方CSDN官方认证链接免费领取
**【保证100%免费】**

读者福利：
[👉👉CSDN大礼包：《最新AI大模型学习资源包》免费分享 👈👈](https://mp.weixin.qq.com/s/6Gojoxcdpe4s8EDPev2r0A)

（👆👆👆安全链接，放心点击）

对于0基础小白入门：

> 如果你是零基础小白，想快速入门大模型是可以考虑的。
>
> 一方面是学习时间相对较短，学习内容更全面更集中。
>   
> 二方面是可以根据这些资料规划好学习计划和方向。

#### 👉1.大模型入门学习思维导图👈

要学习一门新的技术，作为新手一定要先学习成长路线图，方向不对，努力白费。

对于从来没有接触过AI大模型的同学，我们帮你准备了详细的学习成长路线图&学习规划。可以说是最科学最系统的学习路线，大家跟着这个大的方向学习准没问题。
**（全套教程文末领取哈）**
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/1a01ecf96fb142ae925bedad049ca7ba.png#pic_center)

#### 👉2.AGI大模型配套视频👈

很多朋友都不喜欢晦涩的文字，我也为大家准备了视频教程，每个章节都是当前板块的精华浓缩。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/50ece67c703340608cbfaf2daeea1358.png#pic_center)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/bd4618f1675b4870a7299d0212047e25.png)

#### 👉3.大模型实际应用报告合集👈

这套包含640份报告的合集，涵盖了AI大模型的理论研究、技术实现、行业应用等多个方面。无论您是科研人员、工程师，还是对AI大模型感兴趣的爱好者，这套报告合集都将为您提供宝贵的信息和启示。
**（全套教程文末领取哈）**

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/dc21268d8e9c4bda953ab1687bbca43d.png#pic_center)

#### 👉4.大模型落地应用案例PPT👈

光学理论是没用的，要学会跟着一起做，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。
**（全套教程文末领取哈）**

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a7511f74c1e14c4dbd1c846267399c2b.png#pic_center)

#### 👉5.大模型经典学习电子书👈

随着人工智能技术的飞速发展，AI大模型已经成为了当今科技领域的一大热点。这些大型预训练模型，如GPT-3、BERT、XLNet等，以其强大的语言理解和生成能力，正在改变我们对人工智能的认识。 那以下这些PDF籍就是非常不错的学习资源。
**（全套教程文末领取哈）**
  
![img](https://img-blog.csdnimg.cn/direct/f3f83643ea7e4954ad51c4b3099dddc6.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/348db3f6b65a4a8f8b94c3a6ab560457.jpeg)

#### 👉6.大模型面试题&答案👈

截至目前大模型已经超过200个，在大模型纵横的时代，不仅大模型技术越来越卷，就连大模型相关的岗位和面试也开始越来越卷了。为了让大家更容易上车大模型算法赛道，我总结了大模型常考的面试题。
**（全套教程文末领取哈）**

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/77792b8008fb4d849647c0db9adb148a.png)
  
**👉学会后的收获：👈**
  
•
**基于大模型全栈工程实现**
（前端、后端、产品经理、设计、数据分析等），通过这门课可获得不同能力；

•
**能够利用大模型解决相关实际项目需求**
： 大数据时代，越来越多的企业和机构需要处理海量数据，利用大模型技术可以更好地处理这些数据，提高数据分析和决策的准确性。因此，掌握大模型应用开发技能，可以让程序员更好地应对实际项目需求；

•
**基于大模型和企业数据AI应用开发，实现大模型理论、掌握GPU算力、硬件、LangChain开发框架和项目实战技能**
， 学会Fine-tuning垂直训练大模型（数据准备、数据蒸馏、大模型部署）一站式掌握；

•
**能够完成时下热门大模型垂直领域模型训练能力，提高程序员的编码能力**
： 大模型应用开发需要掌握机器学习算法、深度学习

## CSDN粉丝独家福利

这份完整版的 AI 大模型学习资料已经上传CSDN，朋友们如果需要可以点击下方CSDN官方认证链接免费领取
**【保证100%免费】**

读者福利：
[👉👉CSDN大礼包：《最新AI大模型学习资源包》免费分享 👈👈](https://mp.weixin.qq.com/s/6Gojoxcdpe4s8EDPev2r0A)

（👆👆👆安全链接，放心点击）


---

**最后，感谢每一个认真阅读我文章的人，礼尚往来总是要有的，下面资料虽然不是什么很值钱的东西，如果你用得到的话可以直接拿走：**
  
![](https://i-blog.csdnimg.cn/direct/a58039c129d341b59091bb2fd48b8b26.png)