---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f36353633393030392f:61727469636c652f64657461696c732f313436303638323833"
layout: post
title: "å¤§è¯­è¨€æ¨¡å‹ä»ç†è®ºåˆ°å®è·µç¬¬äºŒç‰ˆ-å­¦ä¹ ç¬”è®°ä¸€transformerç†è®ºä¸å®è·µ"
date: 2025-03-06 18:36:27 +0800
description: "æœºå™¨ç¿»è¯‘çš„ç›®æ ‡æ˜¯ä»æºè¯­è¨€ï¼ˆSource Languageï¼‰è½¬æ¢åˆ°ç›®æ ‡è¯­è¨€ï¼ˆTarget Languageï¼‰ã€‚Transformerç»“æ„å®Œå…¨é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å®Œæˆå¯¹æºè¯­è¨€åºåˆ—å’Œç›®æ ‡è¯­è¨€åºåˆ—å…¨å±€ä¾èµ–çš„å»ºæ¨¡ã€‚æ³¨æ„åŠ›å±‚ï¼šä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-Head Attentionï¼‰æœºåˆ¶æ•´åˆä¸Šä¸‹æ–‡è¯­ä¹‰ã€‚å¤šå¤´æ³¨æ„åŠ›å¹¶è¡Œè¿è¡Œå¤šä¸ªç‹¬ç«‹æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¿›è€Œä»å¤šç»´åº¦æ•æ‰è¾“å…¥åºåˆ—ä¿¡æ¯ã€‚å®ƒä½¿å¾—åºåˆ—ä¸­ä»»æ„ä¸¤ä¸ªå•è¯ä¹‹é—´çš„ä¾èµ–å…³ç³»å¯ä»¥ç›´æ¥è¢«å»ºæ¨¡è€Œä¸åŸºäºä¼ ç»Ÿçš„å¾ªç¯ç»“æ„ï¼Œä»è€Œæ›´å¥½åœ°è§£å†³æ–‡æœ¬çš„é•¿ç¨‹ä¾èµ–é—®é¢˜ã€‚"
keywords: "å¤§è¯­è¨€æ¨¡å‹ä»ç†è®ºåˆ°å®è·µï¼ˆç¬¬äºŒç‰ˆï¼‰-å­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰transformerç†è®ºä¸å®è·µ"
categories: ['æœªåˆ†ç±»']
tags: ['è¯­è¨€æ¨¡å‹', 'è‡ªç„¶è¯­è¨€å¤„ç†', 'ç¬”è®°', 'æ·±åº¦å­¦ä¹ ', 'Transformer', 'Pytorch', 'Python']
artid: "146068283"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146068283
    alt: "å¤§è¯­è¨€æ¨¡å‹ä»ç†è®ºåˆ°å®è·µç¬¬äºŒç‰ˆ-å­¦ä¹ ç¬”è®°ä¸€transformerç†è®ºä¸å®è·µ"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146068283
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146068283
cover: https://bing.ee123.net/img/rand?artid=146068283
image: https://bing.ee123.net/img/rand?artid=146068283
img: https://bing.ee123.net/img/rand?artid=146068283
---

# å¤§è¯­è¨€æ¨¡å‹ä»ç†è®ºåˆ°å®è·µï¼ˆç¬¬äºŒç‰ˆï¼‰-å­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰transformerç†è®ºä¸å®è·µ

## Transformer ç»“æ„

æœºå™¨ç¿»è¯‘çš„ç›®æ ‡æ˜¯ä»æºè¯­è¨€ï¼ˆSource Languageï¼‰è½¬æ¢åˆ°ç›®æ ‡è¯­è¨€ï¼ˆTarget Languageï¼‰ã€‚Transformerç»“æ„å®Œå…¨é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å®Œæˆå¯¹æºè¯­è¨€åºåˆ—å’Œç›®æ ‡è¯­è¨€åºåˆ—å…¨å±€ä¾èµ–çš„å»ºæ¨¡ã€‚
![](https://i-blog.csdnimg.cn/direct/7f4a9769ac234b3f8ea4b58be393a485.png)

æ³¨æ„åŠ›å±‚ï¼šä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-Head Attentionï¼‰æœºåˆ¶æ•´åˆä¸Šä¸‹æ–‡è¯­ä¹‰ã€‚å¤šå¤´æ³¨æ„åŠ›å¹¶è¡Œè¿è¡Œå¤šä¸ªç‹¬ç«‹æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¿›è€Œä»å¤šç»´åº¦æ•æ‰è¾“å…¥åºåˆ—ä¿¡æ¯ã€‚å®ƒä½¿å¾—åºåˆ—ä¸­ä»»æ„ä¸¤ä¸ªå•è¯ä¹‹é—´çš„ä¾èµ–å…³ç³»å¯ä»¥ç›´æ¥è¢«å»ºæ¨¡è€Œä¸åŸºäºä¼ ç»Ÿçš„å¾ªç¯ç»“æ„ï¼Œä»è€Œæ›´å¥½åœ°è§£å†³æ–‡æœ¬çš„é•¿ç¨‹ä¾èµ–é—®é¢˜ã€‚
  
â€¢ ä½ç½®æ„ŸçŸ¥å‰é¦ˆç½‘ç»œå±‚ï¼ˆPosition-wise Feed-Forward Networkï¼‰ï¼šé€šè¿‡å…¨è¿æ¥å±‚å¯¹è¾“å…¥æ–‡æœ¬åºåˆ—
  
ä¸­çš„æ¯ä¸ªå•è¯è¡¨ç¤ºè¿›è¡Œæ›´å¤æ‚çš„å˜æ¢ã€‚
  
â€¢ æ®‹å·®è¿æ¥ï¼šå¯¹åº”å›¾ä¸­çš„ Add éƒ¨åˆ†ã€‚å®ƒæ˜¯ä¸€æ¡åˆ†åˆ«ä½œç”¨åœ¨ä¸Šè¿°ä¸¤ä¸ªå­å±‚ä¸­çš„ç›´è¿é€šè·¯ï¼Œè¢«ç”¨äº
  
è¿æ¥ä¸¤ä¸ªå­å±‚çš„è¾“å…¥ä¸è¾“å‡ºï¼Œä½¿ä¿¡æ¯æµåŠ¨æ›´é«˜æ•ˆï¼Œ
**æœ‰åˆ©äºæ¨¡å‹çš„ä¼˜åŒ–**
ã€‚
  
â€¢ å±‚å½’ä¸€åŒ–ï¼šå¯¹åº”å›¾ä¸­çš„ Norm éƒ¨åˆ†ã€‚å®ƒä½œç”¨äºä¸Šè¿°ä¸¤ä¸ªå­å±‚çš„è¾“å‡ºè¡¨ç¤ºåºåˆ—ï¼Œå¯¹è¡¨ç¤ºåºåˆ—è¿›
  
è¡Œå±‚å½’ä¸€åŒ–æ“ä½œï¼ŒåŒæ ·èµ·åˆ°
**ç¨³å®šä¼˜åŒ–**
çš„ä½œç”¨ã€‚

![](https://i-blog.csdnimg.cn/direct/a9b2819987bf450e94767f80a48d8890.png)

æ¥ä¸‹æ¥ä»‹ç»å„å±‚çš„å®ç°æ–¹æ³•ï¼š

## åµŒå…¥è¡¨ç¤ºå±‚

å¯¹äºè¾“å…¥æ–‡æœ¬åºåˆ—ï¼Œå…ˆé€šè¿‡è¾“å…¥åµŒå…¥å±‚ï¼ˆInput Embeddingï¼‰å°†æ¯ä¸ªå•è¯è½¬æ¢ä¸ºå…¶ç›¸å¯¹åº”çš„å‘
  
é‡è¡¨ç¤ºã€‚åœ¨é€å…¥ç¼–ç å™¨ç«¯å»ºæ¨¡å…¶ä¸Šä¸‹æ–‡è¯­ä¹‰ä¹‹å‰ï¼Œä¸€ä¸ªéå¸¸é‡è¦çš„æ“ä½œæ˜¯åœ¨è¯åµŒå…¥ä¸­åŠ å…¥ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰è¿™ä¸€ç‰¹å¾ã€‚
**å…·ä½“æ¥è¯´ï¼Œåºåˆ—ä¸­æ¯ä¸€ä¸ªå•è¯æ‰€åœ¨çš„ä½ç½®éƒ½å¯¹åº”ä¸€ä¸ªå‘é‡ã€‚è¿™ä¸€å‘é‡ä¼šä¸å•è¯è¡¨ç¤ºå¯¹åº”ç›¸åŠ å¹¶é€å…¥åç»­æ¨¡å—ä¸­åšè¿›ä¸€æ­¥å¤„ç†ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨åœ°å­¦ä¹ åˆ°å¦‚ä½•åˆ©ç”¨è¿™éƒ¨åˆ†ä½ç½®ä¿¡æ¯ã€‚**
ä¸ºäº†å¾—åˆ°ä¸åŒä½ç½®æ‰€å¯¹åº”çš„ç¼–ç ï¼ŒTransformer ç»“æ„ä½¿ç”¨ä¸åŒé¢‘ç‡çš„æ­£ä½™å¼¦å‡½æ•°ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

![](https://i-blog.csdnimg.cn/direct/fc7998dac79c42cc83a77ed8f90c5ebf.png)

å…¶ä¸­ï¼Œpos è¡¨ç¤ºå•è¯æ‰€åœ¨çš„ä½ç½®ï¼Œ2i å’Œ 2i +1 è¡¨ç¤ºä½ç½®ç¼–ç å‘é‡ä¸­çš„å¯¹åº”ç»´åº¦ï¼Œd åˆ™å¯¹åº”ä½ç½®ç¼–ç 
  
çš„æ€»ç»´åº¦ã€‚é€šè¿‡ä¸Šé¢è¿™ç§æ–¹å¼è®¡ç®—ä½ç½®ç¼–ç æœ‰ä»¥ä¸‹ä¸¤ä¸ªå¥½å¤„ï¼šç¬¬ä¸€ï¼Œæ­£ä½™å¼¦å‡½æ•°çš„èŒƒå›´æ˜¯ [âˆ’1, +1]ï¼Œå¯¼å‡ºçš„ä½ç½®ç¼–ç ä¸åŸè¯åµŒå…¥ç›¸åŠ ä¸ä¼šä½¿å¾—ç»“æœåç¦»è¿‡è¿œè€Œç ´ååŸæœ‰å•è¯çš„è¯­ä¹‰ä¿¡æ¯ï¼›

ç¬¬äºŒï¼Œä¾æ®ä¸‰è§’å‡½æ•°çš„åŸºæœ¬æ€§è´¨ï¼Œå¯ä»¥å¾—çŸ¥ç¬¬ pos + k ä¸ªä½ç½®ç¼–ç æ˜¯ç¬¬ pos ä¸ªä½ç½®ç¼–ç çš„çº¿æ€§ç»„åˆï¼Œè¿™å°±æ„å‘³ç€ä½ç½®ç¼–ç ä¸­è•´å«ç€å•è¯ä¹‹é—´çš„è·ç¦»ä¿¡æ¯ã€‚è§£é‡Šï¼š

![](https://i-blog.csdnimg.cn/direct/b79432a767d444e699bc42f481e4914c.png)

```

#embed.py
import torch
import torch.nn as nn
import math


class Embedder(nn.Module):
    def __init__(self, vocab_size, d_model):
        super().__init__()
        self.d_model = d_model
        self.embed = nn.Embedding(vocab_size, d_model)

    def forward(self, x):
        return self.embed(x)


'''1.1.1 åµŒå…¥è¡¨ç¤ºå±‚'''


class PositionalEncoder(nn.Module):
    def __init__(self, d_model, max_seq_len=80, dropout=0.1):
        super().__init__()
        self.d_model = d_model
        self.dropout = nn.Dropout(dropout)
        # æ ¹æ®poså’Œiåˆ›å»ºä¸€ä¸ªå¸¸é‡PEçŸ©é˜µ
        pe = torch.zeros(max_seq_len, d_model)
        for pos in range(max_seq_len):
            for i in range(0, d_model, 2):
                pe[pos, i] = math.sin(pos / (10000 ** (i / d_model)))
                if i + 1 < d_model:
                    pe[pos, i + 1] = math.cos(pos / (10000 ** (i / d_model)))

        pe = pe.unsqueeze(0)
        '''
        åœ¨ PyTorch ä¸­ï¼Œç¼“å†²åŒºï¼ˆregister_bufferï¼‰å’Œå‚æ•°ï¼ˆregister_parameterï¼‰çš„åŒºåˆ«åœ¨äºï¼š
        å‚æ•°ï¼ˆæ¯”å¦‚æƒé‡ weightï¼‰æ˜¯éœ€è¦è®­ç»ƒçš„ï¼Œä¼šå‚ä¸æ¢¯åº¦è®¡ç®—ï¼Œé»˜è®¤ requires_grad=Trueã€‚
        ç¼“å†²åŒºï¼ˆæ¯”å¦‚ peï¼‰æ˜¯å›ºå®šçš„è¾…åŠ©å¼ é‡ï¼Œé»˜è®¤ requires_grad=Falseï¼Œä¸ä¼šå‚ä¸æ¢¯åº¦æ›´æ–°ã€‚
        '''
        self.register_buffer('pe', pe)

    def forward(self, x):
        # è®©è¯åµŒå…¥çš„æ•°å€¼æ¯”ä½ç½®ç¼–ç ï¼ˆèŒƒå›´åœ¨ [-1, 1]ï¼‰æ›´å¤§ä¸€äº›ã€‚è¿™æ ·åŠ æ³•åï¼Œè¯åµŒå…¥çš„è¯­ä¹‰ä¿¡æ¯ä¸ä¼šè¢«ä½ç½®ç¼–ç â€œæ·¹æ²¡â€ã€‚
        # è¿™æ˜¯ Transformer è®ºæ–‡é‡Œçš„ä¸€ä¸ªå°æŠ€å·§ã€‚
        x = x * math.sqrt(self.d_model)
        # å¢åŠ ä½ç½®å¸¸é‡åˆ°å•è¯åµŒå…¥è¡¨ç¤ºä¸­
        seq_len = x.size(1)
        x = x + self.pe[:, :seq_len, :]
        '''
        è®¾ç½® requires_grad=False è¡¨ç¤ºè¿™ä¸ªå¼ é‡ï¼ˆä½ç½®ç¼–ç  peï¼‰æ˜¯å›ºå®šçš„ï¼Œä¸å‚ä¸æ¢¯åº¦æ›´æ–°ã€‚
        ä¸ºä»€ä¹ˆè¿™ä¹ˆåšï¼Ÿ
        å› ä¸ºä½ç½®ç¼–ç æ˜¯é¢„å…ˆç®—å¥½çš„å¸¸é‡ï¼Œä¸æ˜¯æ¨¡å‹è¦å­¦ä¹ çš„å‚æ•°ã€‚Transformer åªå­¦ä¹ è¯åµŒå…¥å’Œåç»­çš„æƒé‡ï¼Œä½ç½®ç¼–ç åªæ˜¯â€œé™„åŠ ä¿¡æ¯â€ï¼Œä¸éœ€è¦è®­ç»ƒã€‚
        '''
        return self.dropout(x)
```

## æ³¨æ„åŠ›å±‚

![](https://i-blog.csdnimg.cn/direct/7f86a7cb761d408e97441b0fdbb0857f.png)

![](https://i-blog.csdnimg.cn/direct/87a91e24bbd44a058c851e981f97df72.png)

è§£é‡Šï¼š

![](https://i-blog.csdnimg.cn/direct/7cb3fff06f9f48ad98256d72860cd1aa.png)

![](https://i-blog.csdnimg.cn/direct/a141155daf07460ebb1761b4019a4fa0.png)

å…³äºqkvçš„ç»´åº¦ï¼š

![](https://i-blog.csdnimg.cn/direct/112f01e0332541dd9c4a826b3040cf9c.png)

## å‰é¦ˆå±‚

![](https://i-blog.csdnimg.cn/direct/ce2b5c4881104ffea2f2ffc0efecd999.png)

```
#Sublayer.py
import torch
import torch.nn as nn
import torch.nn.functional as F
import math


'''1.1.2 æ³¨æ„åŠ›å±‚'''
class MultiHeadAttention(nn.Module):
    def __init__(self, heads, d_model, dropout=0.1):
        super().__init__()

        self.d_model = d_model
        self.d_k = d_model // heads
        self.h = heads

        self.q_linear = nn.Linear(d_model, d_model)
        self.k_linear = nn.Linear(d_model, d_model)
        self.v_linear = nn.Linear(d_model, d_model)

        self.dropout = nn.Dropout(dropout)
        self.out = nn.Linear(d_model, d_model)

    def attention(self, q, k, v, d_k, mask=None, dropout=None):
        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)
        #q:(batch_size, num_heads, seq_len, d_k)
        #k:(batch_size, num_heads, d_k, seq_len)

        # æ©ç›–é‚£äº›ä¸ºäº†è¡¥å…¨é•¿åº¦è€Œå¢åŠ çš„å•å…ƒï¼Œä½¿å…¶é€šè¿‡Softmaxè®¡ç®—åä¸º0
        if mask is not None:
            mask = mask.unsqueeze(1)
            scores = scores.masked_fill(mask == 0, -1e9)

        scores = F.softmax(scores, dim=-1)

        if dropout is not None:
            scores = dropout(scores)
        '''
        ä¸ºä»€ä¹ˆå¯¹ scores è¿›è¡Œ Dropoutï¼Ÿ
        ä»¥ä¸‹æ˜¯å‡ ä¸ªä¸»è¦åŸå› ï¼š

        1. é˜²æ­¢è¿‡æ‹Ÿåˆscores æ˜¯æ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å¿ƒï¼Œå®ƒå†³å®šäº†æ¨¡å‹å¯¹è¾“å…¥åºåˆ—ä¸­ä¸åŒä½ç½®çš„å…³æ³¨ç¨‹åº¦ã€‚å¦‚æœæŸäº›ä½ç½®çš„æ³¨æ„åŠ›æƒé‡è¿‡é«˜
        ï¼ˆä¾‹å¦‚ï¼Œæ¨¡å‹è¿‡äºåå¥½æŸäº›ç‰¹å®šè¯ï¼‰ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¿‡æ‹Ÿåˆã€‚é€šè¿‡å¯¹ scores æ–½åŠ  dropoutï¼Œ
        éšæœºåœ°å°†éƒ¨åˆ†æ³¨æ„åŠ›æƒé‡ç½®ä¸º 0ï¼Œå¯ä»¥è¿«ä½¿æ¨¡å‹å­¦ä¹ æ›´é²æ£’çš„è¡¨ç¤ºï¼Œé¿å…è¿‡åº¦ä¾èµ–æŸäº›è¾“å…¥ç‰¹å¾æˆ–ä½ç½®ã€‚
        
        Transformer æ¨¡å‹åœ¨å¤šä¸ªåœ°æ–¹ä½¿ç”¨äº† dropoutï¼Œä¾‹å¦‚ï¼š
        è¯åµŒå…¥å±‚ä¹‹åã€‚
        Feed-Forward ç½‘ç»œä¸­ã€‚
        æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–ä¹‹åã€‚
        
        å¤„ç†å™ªå£°å’Œä¸ç¡®å®šæ€§
        åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ï¼Œè¾“å…¥åºåˆ—å¯èƒ½åŒ…å«å™ªå£°ï¼ˆä¾‹å¦‚ä¸ç›¸å…³çš„è¯æˆ–å†—ä½™ä¿¡æ¯ï¼‰ã€‚é€šè¿‡åœ¨ scores ä¸Šæ–½åŠ  dropoutï¼Œæ¨¡å‹å¯ä»¥æ¨¡æ‹Ÿè¿™ç§ä¸ç¡®å®šæ€§ï¼Œ
        å­¦ä¹ å¯¹è¾“å…¥çš„è½»å¾®æ‰°åŠ¨æ›´å…·é²æ£’æ€§ã€‚
        
        '''
        output = torch.matmul(scores, v)
        return output

    def forward(self, q, k, v, mask=None):
        bs = q.size(0)

        # åˆ©ç”¨çº¿æ€§è®¡ç®—åˆ’åˆ†æˆhä¸ªå¤´
        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)
        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)
        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)

        # çŸ©é˜µè½¬ç½® (batch_size, num_heads, seq_len, d_k)
        k = k.transpose(1, 2)
        q = q.transpose(1, 2)
        v = v.transpose(1, 2)

        # è®¡ç®—attention
        scores = self.attention(q, k, v, self.d_k, mask, self.dropout)

        # è¿æ¥å¤šä¸ªå¤´å¹¶è¾“å…¥æœ€åçš„çº¿æ€§å±‚
        '''
        ç»´åº¦å˜åŒ–ï¼š
        åŸå§‹å½¢çŠ¶ï¼š(batch_size, num_heads, seq_len, d_k)
        äº¤æ¢åå½¢çŠ¶ï¼š(batch_size, seq_len, num_heads, d_k)
        
        .contiguous()
        ä½œç”¨ï¼šç¡®ä¿å¼ é‡åœ¨å†…å­˜ä¸­æ˜¯è¿ç»­çš„ã€‚
        åç»­çš„ view æ“ä½œè¦æ±‚å¼ é‡æ˜¯è¿ç»­çš„ï¼ˆcontiguousï¼‰ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚
        '''
        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)

        output = self.out(concat)

        return output#(batch_size, seq_len, d_model)


'''1.1.3 å‰é¦ˆå±‚'''
class FeedForward(nn.Module):
    def __init__(self, d_model, d_ff=2048, dropout=0.1):
        super().__init__()

        # d_ff é»˜è®¤è®¾ä¸º 2048
        self.linear_1 = nn.Linear(d_model, d_ff)
        self.dropout = nn.Dropout(dropout)
        self.linear_2 = nn.Linear(d_ff, d_model)

    def forward(self, x):
        x = self.dropout(F.relu(self.linear_1(x)))
        x = self.linear_2(x)
        return x


'''1.1.4 æ®‹å·®è¿æ¥ä¸å±‚å½’ä¸€åŒ–'''
class Norm(nn.Module):
    def __init__(self, d_model, eps=1e-6):
        super().__init__()

        self.size = d_model

        # å±‚å½’ä¸€åŒ–åŒ…å«ä¸¤ä¸ªå¯å­¦ä¹ å‚æ•°
        self.alpha = nn.Parameter(torch.ones(self.size))
        self.bias = nn.Parameter(torch.zeros(self.size))

        self.eps = eps  # é¿å…é™¤é›¶

    def forward(self, x):
        mean = x.mean(dim=-1, keepdim=True)#(batch_size, seq_len)
        std = x.std(dim=-1, keepdim=True)#(batch_size, seq_len)
        norm = self.alpha * (x - mean) / (std + self.eps) + self.bias
        return norm
```

## æ®‹å·®è¿æ¥ä¸å±‚å½’ä¸€åŒ–

![](https://i-blog.csdnimg.cn/direct/f83678ed813c426bac6cfd181b4ec250.png)

å…¶ä¸­ Âµ å’Œ Ïƒ åˆ†åˆ«è¡¨ç¤ºå‡å€¼å’Œæ–¹å·®ï¼Œç”¨äºå°†æ•°æ®å¹³ç§»ç¼©æ”¾åˆ°å‡å€¼ä¸º 0ã€æ–¹å·®ä¸º 1 çš„æ ‡å‡†åˆ†å¸ƒï¼ŒÎ± å’Œ
  
b æ˜¯å¯å­¦ä¹ çš„å‚æ•°ã€‚å±‚å½’ä¸€åŒ–æŠ€æœ¯å¯ä»¥æœ‰æ•ˆåœ°ç¼“è§£ä¼˜åŒ–è¿‡ç¨‹ä¸­æ½œåœ¨çš„ä¸ç¨³å®šã€æ”¶æ•›é€Ÿåº¦æ…¢ç­‰é—®é¢˜ã€‚

![](https://i-blog.csdnimg.cn/direct/943fa94dec3d42c99ec9d4e71ddbb7d9.png)

## ç¼–ç å™¨å’Œè§£ç å™¨ç»“æ„

![](https://i-blog.csdnimg.cn/direct/7d2bbd3116994fe8953549db4ef49bd7.png)

```
#layers
import torch
import torch.nn as nn
from Sublayer import FeedForward, MultiHeadAttention, Norm

'''1.1.5 ç¼–ç å™¨å’Œè§£ç å™¨ç»“æ„'''


class EncoderLayer(nn.Module):
    def __init__(self, d_model, heads, dropout=0.1):
        super().__init__()
        self.norm_1 = Norm(d_model)
        self.norm_2 = Norm(d_model)
        self.attn = MultiHeadAttention(heads, d_model, dropout=dropout)
        self.ff = FeedForward(d_model, dropout=dropout)
        self.dropout_1 = nn.Dropout(dropout)
        self.dropout_2 = nn.Dropout(dropout)

    def forward(self, x, mask):
        attn_output = self.attn(x, x, x, mask)
        attn_output = self.dropout_1(attn_output)
        '''åœ¨å­æ¨¡å—è¾“å‡ºä¸Šåº”ç”¨ dropoutï¼ˆå¦‚ self.dropout_1(attn_output)ï¼‰ï¼Œ
        å¯ä»¥éšæœºä¸¢å¼ƒå­æ¨¡å—è¾“å‡ºçš„ä¸€éƒ¨åˆ†ï¼Œè¿«ä½¿æ¨¡å‹æ›´å¥½åœ°åˆ©ç”¨è¾“å…¥ğ‘¥å’Œå­æ¨¡å—è¾“å‡ºçš„ç»„åˆï¼Œ
        ä»è€Œå¢å¼ºé²æ£’æ€§ã€‚'''
        x = x + attn_output
        x = self.norm_1(x)
        
        ff_output = self.ff(x)
        ff_output = self.dropout_2(ff_output)
        x = x + ff_output
        x = self.norm_2(x)
        
        return x


class DecoderLayer(nn.Module):
    def __init__(self, d_model, heads, dropout=0.1):
        super().__init__()
        self.norm_1 = Norm(d_model)
        self.norm_2 = Norm(d_model)
        self.norm_3 = Norm(d_model)

        self.dropout_1 = nn.Dropout(dropout)
        self.dropout_2 = nn.Dropout(dropout)
        self.dropout_3 = nn.Dropout(dropout)

        self.attn_1 = MultiHeadAttention(heads, d_model, dropout=dropout)
        self.attn_2 = MultiHeadAttention(heads, d_model, dropout=dropout)
        self.ff = FeedForward(d_model, dropout=dropout)

    def forward(self, x, e_outputs, src_mask, trg_mask):
        attn_output_1 = self.attn_1(x, x, x, trg_mask)
        attn_output_1 = self.dropout_1(attn_output_1)
        x = x + attn_output_1
        x = self.norm_1(x)
        
        attn_output_2 = self.attn_2(x, e_outputs, e_outputs, src_mask)
        attn_output_2 = self.dropout_2(attn_output_2)
        x = x + attn_output_2
        x = self.norm_2(x)

        ff_output = self.ff(x)
        ff_output = self.dropout_3(ff_output)
        x = x + ff_output
        x = self.norm_3(x)

        return x
```

> é…å¥—çš„ä»£ç  å†™çš„çœŸçš„å¾ˆè§„æ•´ å‰å®³ï¼

æœ€åçš„transformerï¼š

```
'''
models.py
æºåºåˆ—åµŒå…¥+ä½ç½®ç¼–ç +encoder*N+å¯¹æœ€åçš„è¾“å‡ºå½’ä¸€åŒ–
ç›®æ ‡åµŒå…¥+ä½ç½®ç¼–ç +decoder*N+å¯¹æœ€åçš„è¾“å‡ºå½’ä¸€åŒ–

'''
import torch
import torch.nn as nn
from layers import EncoderLayer, DecoderLayer
from embed import Embedder, PositionalEncoder
from Sublayer import Norm
import copy


def get_clones(module, N):
    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])


'''1.1.5 ç¼–ç å™¨å’Œè§£ç å™¨ç»“æ„'''


class Encoder(nn.Module):
    def __init__(self, vocab_size, d_model, N, heads, dropout):
        super().__init__()
        self.N = N
        self.embed = Embedder(vocab_size, d_model)
        self.pe = PositionalEncoder(d_model, dropout=dropout)
        self.layers = get_clones(EncoderLayer(d_model, heads, dropout), N)
        self.norm = Norm(d_model)

    def forward(self, src, mask):
        x = self.embed(src)
        x = self.pe(x)
        for i in range(self.N):
            x = self.layers[i](x, mask)
        return self.norm(x)


class Decoder(nn.Module):
    def __init__(self, vocab_size, d_model, N, heads, dropout):
        super().__init__()
        self.N = N
        self.embed = Embedder(vocab_size, d_model)
        self.pe = PositionalEncoder(d_model, dropout=dropout)
        self.layers = get_clones(DecoderLayer(d_model, heads, dropout), N)
        self.norm = Norm(d_model)

    def forward(self, trg, e_outputs, src_mask, trg_mask):
        x = self.embed(trg)
        x = self.pe(x)
        for i in range(self.N):
            x = self.layers[i](x, e_outputs, src_mask, trg_mask)
        return self.norm(x)


class Transformer(nn.Module):
    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, dropout):
        super().__init__()
        self.encoder = Encoder(src_vocab, d_model, N, heads, dropout)
        self.decoder = Decoder(trg_vocab, d_model, N, heads, dropout)
        self.out = nn.Linear(d_model, trg_vocab)

    def forward(self, src, trg, src_mask, trg_mask):
        e_outputs = self.encoder(src, src_mask)
        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)
        output = self.out(d_output)
        return output

```

å¯¹æœ€åçš„è¾“å‡ºå½’ä¸€åŒ–çš„è§£é‡Šï¼š

![](https://i-blog.csdnimg.cn/direct/2c8b7dcdf5384708852f0ea95a7d88c0.png)

![](https://i-blog.csdnimg.cn/direct/2c500584dfc24c1586a3b2e1b3001cee.png)

![](https://i-blog.csdnimg.cn/direct/45ffe76aabf5404097d0ab38acbad095.png)

![](https://i-blog.csdnimg.cn/direct/cef97838c9c14d748b3bcba6aa73d1fc.png)

## è®­ç»ƒå’Œæµ‹è¯•

```
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.autograd import Variable
from models import Transformer
from batch import create_masks
from process import *
import numpy as np
import time

# æ•°æ®
src_file = 'data/english.txt'
trg_file = 'data/french.txt'
src_lang = 'en_core_web_sm'
trg_lang = 'fr_core_news_sm'
max_strlen = 80
batchsize = 1500
src_data, trg_data = read_data(src_file, trg_file)
EN_TEXT, FR_TEXT = create_fields(src_lang, trg_lang)
train_iter, src_pad, trg_pad = create_dataset(src_data, trg_data, EN_TEXT, FR_TEXT, max_strlen, batchsize)

'''1.1.5 ç¼–ç å™¨å’Œè§£ç å™¨ç»“æ„'''
# æ¨¡å‹å‚æ•°å®šä¹‰
d_model = 512
heads = 8
N = 6
dropout = 0.1
src_vocab = len(EN_TEXT.vocab)
trg_vocab = len(FR_TEXT.vocab)
model = Transformer(src_vocab, trg_vocab, d_model, N, heads, dropout)

for p in model.parameters():
    if p.dim() > 1:
        nn.init.xavier_uniform_(p)

optim = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)

# æ¨¡å‹è®­ç»ƒ
def train_model(epochs, print_every=100):
    model.train()

    start = time.time()
    temp = start

    total_loss = 0

    for epoch in range(epochs):
        for i, batch in enumerate(train_iter):
            src = batch.src.transpose(0, 1)
            trg = batch.trg.transpose(0, 1)
            # å°†æˆ‘ä»¬è¾“å…¥çš„è‹±è¯­å¥å­ä¸­çš„æ‰€æœ‰å•è¯ç¿»è¯‘æˆæ³•è¯­
            # é™¤äº†æœ€åä¸€ä¸ªå•è¯ï¼Œå› ä¸ºå®ƒä¸ºç»“æŸç¬¦ï¼Œä¸éœ€è¦è¿›è¡Œä¸‹ä¸€ä¸ªå•è¯çš„é¢„æµ‹

            trg_input = trg[:, :-1]

            # è¯•å›¾é¢„æµ‹å•è¯
            targets = trg[:, 1:].contiguous().view(-1)

            # ä½¿ç”¨æ©ç ä»£ç åˆ›å»ºå‡½æ•°æ¥åˆ¶ä½œæ©ç 
            src_mask, trg_mask = create_masks(src, trg_input, src_pad, trg_pad)

            preds = model(src, trg_input, src_mask, trg_mask)

            optim.zero_grad()

            loss = F.cross_entropy(preds.view(-1, preds.size(-1)), 
                                   targets, ignore_index=trg_pad)
            loss.backward()
            optim.step()

            total_loss += loss.item()
            if (i + 1) % print_every == 0:
                loss_avg = total_loss / print_every
                print("time = %dm, epoch %d, iter = %d, loss = %.3f, %ds per %d iters" % 
                      ((time.time() - start) // 60, epoch + 1, i + 1, loss_avg, 
                       time.time() - temp, print_every))
                total_loss = 0
                temp = time.time()

# æ¨¡å‹æµ‹è¯•
def translate(src, max_len=80, custom_string=False):
    model.eval()
    if custom_string == True:
        src = tokenize_en(src, EN_TEXT)
        src = torch.LongTensor(src)
    print(src)
    src_mask = (src != src_pad).unsqueeze(-2)
    e_outputs = model.encoder(src.unsqueeze(0), src_mask)

    outputs = torch.zeros(max_len).type_as(src.data)
    outputs[0] = torch.LongTensor([FR_TEXT.vocab.stoi['<sos>']])

    for i in range(1, max_len):
        trg_mask = np.triu(np.ones((1, i, i)).astype('uint8'))
        trg_mask = Variable(torch.from_numpy(trg_mask) == 0)

        out = model.out(model.decoder(outputs[:i].unsqueeze(0), 
                                      e_outputs, src_mask, trg_mask))
        out = F.softmax(out, dim=-1)
        val, ix = out[:, -1].data.topk(1)

        outputs[i] = ix[0][0]
        if ix[0][0] == FR_TEXT.vocab.stoi['<eos>']:
            break
    return ' '.join(
        [FR_TEXT.vocab.itos[ix] for ix in outputs[:i]]
    )

if __name__ == "__main__":
    train_model(2)

    words = 'Let me see.'
    print(translate(words, custom_string=True))
```

æºç åœ°å€(å¯è¿è¡Œ):
[intro-llm-code/chs/ch2-foundations/Transformer/main.py at main Â· intro-llm/intro-llm-code](https://github.com/intro-llm/intro-llm-code/blob/main/chs/ch2-foundations/Transformer/main.py "intro-llm-code/chs/ch2-foundations/Transformer/main.py at main Â· intro-llm/intro-llm-code")