---
arturl_encode: "687474:70733a2f2f626c6f672e6373646e2e6e65742f57697334652f:61727469636c652f64657461696c732f313436313339363837"
layout: post
title: "基于PyTorch的深度学习5如何构建神经网络"
date: 2025-03-10 08:06:27 +0800
description: "如果是测试或验证阶段，需要使模型处于验证阶段，即调用model.eval()，调用model.eval()会把所有的training属性设置为False。PyTorch提供了自动反向传播的功能，使用nn工具箱，无须我们自己编写反向传播，直接让损失函数(loss)调用backward()即可，非常方便和高效！在nn工具箱中，可以直接引用的网络很多，有全连接层、卷积层、循环层、正则化层、激活层等等。——————————————————前向传播和反向传播。—————————————————训练模型。"
keywords: "基于PyTorch的深度学习5——如何构建神经网络"
categories: ['未分类']
tags: ['神经网络', '深度学习', 'Pytorch']
artid: "146139687"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146139687
    alt: "基于PyTorch的深度学习5如何构建神经网络"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146139687
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146139687
cover: https://bing.ee123.net/img/rand?artid=146139687
image: https://bing.ee123.net/img/rand?artid=146139687
img: https://bing.ee123.net/img/rand?artid=146139687
---

# 基于PyTorch的深度学习5——如何构建神经网络

搭建神经网络虽然步骤较多，但关键就是选择网络层，构建网络，然后选择损失和优化器。

在nn工具箱中，可以直接引用的网络很多，有全连接层、卷积层、循环层、正则化层、激活层等等。假设这些层都定义好了，接下来应该如何组织或构建这些层呢？

在 PyTorch 中，
`torch.nn.Sequential()`
是一种按顺序组合网络层的容器，但默认情况下层名称是自动生成的数字（如
`0`
,
`1`
,
`2`
）。为了让层名称更具可读性，可以通过以下方法为每层定义自定义名称：

---

#### **方法1：使用 `add_module()` 添加层**

```
import torch.nn as nn

model = nn.Sequential()
model.add_module("layer1", nn.Linear(784, 256))
model.add_module("relu1", nn.ReLU())
model.add_module("layer2", nn.Linear(256, 10))
```

**特点**
：

* 逐层添加，显式指定名称。
* 适合需要动态构建网络的场景。

---

#### **方法2：使用字典形式（推荐）**

通过定义有序字典（
`OrderedDict`
）直接指定层名称和顺序：

```
from collections import OrderedDict
import torch.nn as nn

model = nn.Sequential(OrderedDict([
    ("linear1", nn.Linear(784, 256)),
    ("relu1", nn.ReLU()),
    ("linear2", nn.Linear(256, 10)),
]))

Sequential(
  (linear1): Linear(in_features=784, out_features=256, bias=True)
  (relu1): ReLU()
  (linear2): Linear(in_features=256, out_features=10, bias=True)
)
```

——————————————————前向传播和反向传播

定义好每层后，最后还需要通过前向传播的方式把这些串起来。这就是涉及如何定义forward函数的问题。forward函数的任务需要把输入层、网络层、输出层链接起来，实现信息的前向传导。该函数的参数一般为输入数据，返回值为输出数据。在forward函数中，有些层来自nn.Module，也可以使用nn.functional定义。来自nn.Module的需要实例化，而使用nn.functional定义的可以直接使用。

PyTorch提供了自动反向传播的功能，使用nn工具箱，无须我们自己编写反向传播，直接让损失函数(loss)调用backward()即可，非常方便和高效！在反向传播过程中，优化器是一个重要角色。优化方法有很多

—————————————————训练模型

层、模型、损失函数和优化器等都定义或创建好，接下来就是训练模型。训练模型时需要注意使模型处于训练模式，即调用model.train()。调用model.train()会把所有的module设置为训练模式。如果是测试或验证阶段，需要使模型处于验证阶段，即调用model.eval()，调用model.eval()会把所有的training属性设置为False。缺省情况下梯度是累加的，需要手工把梯度初始化或清零，调用optimizer.zero\_grad()即可。训练过程中，正向传播生成网络的输出，计算输出和实际值之间的损失值。调用loss.backward()自动生成梯度，然后使用optimizer.step()执行优化器，把梯度传播回每个网络。如果希望用GPU训练，需要把模型、训练数据、测试数据发送到GPU上，即调用.to(device)。