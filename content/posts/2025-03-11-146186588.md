---
layout: post
title: "深度学习读写文件"
date: 2025-03-11 19:16:43 +0800
description: "到目前为止，我们讨论了如何处理数据，以及如何构建、训练和测试深度学习模型。然而，有时我们希望保存训练的模型，以备将来在各种环境中使用（比如在部署中进行预测）。此外，当运行一个耗时较长的训练过程时，最佳的做法是定期保存中间结果，以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。因此，现在是时候了。"
keywords: "【深度学习】读写文件"
categories: ['深度学习']
tags: ['深度学习', '人工智能']
artid: "146186588"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146186588
    alt: "深度学习读写文件"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146186588
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146186588
cover: https://bing.ee123.net/img/rand?artid=146186588
image: https://bing.ee123.net/img/rand?artid=146186588
img: https://bing.ee123.net/img/rand?artid=146186588
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     【深度学习】读写文件
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="./../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="./../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h2>
     <a id="_0">
     </a>
     读写文件
    </h2>
    <p>
     到目前为止，我们讨论了如何处理数据，以及如何构建、训练和测试深度学习模型。
     <br/>
     然而，有时我们希望保存训练的模型，以备将来在各种环境中使用（比如在部署中进行预测）。
     <br/>
     此外，当运行一个耗时较长的训练过程时，最佳的做法是定期保存中间结果，以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。
    </p>
    <p>
     因此，现在是时候
     <strong>
      学习如何加载和存储权重向量和整个模型
     </strong>
     了。
    </p>
    <h3>
     <a id="_8">
     </a>
     (
     <strong>
      加载和保存张量
     </strong>
     )
    </h3>
    <p>
     对于单个张量，我们可以直接调用
     <code>
      load
     </code>
     和
     <code>
      save
     </code>
     函数分别读写它们。
     <br/>
     这两个函数都要求我们提供一个名称，
     <code>
      save
     </code>
     要求将要保存的变量作为输入。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F

<span class="token comment"># 创建一个包含从 0 到 3 的整数的一维张量</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token comment"># 将张量 x 保存到名为 'x-file' 的文件中</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token string">'x-file'</span><span class="token punctuation">)</span>
</code></pre>
    <blockquote>
     <p>
      通常
      <code>
       x-file
      </code>
      的文件格式一般是
      <code>
       .pt
      </code>
      或者
      <code>
       .pth
      </code>
      ，用于保存
      <code>
       PyTorch
      </code>
      模型的状态字典（state_dict）或者整个模型对象。
     </p>
    </blockquote>
    <p>
     我们现在可以将存储在文件中的数据读回内存。
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 从名为 'x-file' 的文件中加载之前保存的张量，并将其赋值给变量 x2</span>
x2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'x-file'</span><span class="token punctuation">)</span>
<span class="token comment"># 打印加载得到的张量 x2</span>
x2
</code></pre>
    <pre><code>tensor([0, 1, 2, 3])
</code></pre>
    <p>
     我们可以[
     <strong>
      存储一个张量列表，然后把它们读回内存。
     </strong>
     ]
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 创建一个包含 4 个零的一维张量</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token comment"># 将张量 x 和 y 组成一个列表，并保存到名为 'x-files' 的文件中</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'x-files'</span><span class="token punctuation">)</span>
<span class="token comment"># 从 'x-files' 文件中加载保存的张量，并将它们分别赋值给 x2 和 y2</span>
x2<span class="token punctuation">,</span> y2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'x-files'</span><span class="token punctuation">)</span>
<span class="token comment"># 打印加载得到的张量元组 (x2, y2)</span>
<span class="token punctuation">(</span>x2<span class="token punctuation">,</span> y2<span class="token punctuation">)</span>
</code></pre>
    <pre><code>(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))
</code></pre>
    <p>
     我们甚至可以(
     <strong>
      写入或读取从字符串映射到张量的字典
     </strong>
     )。当我们要读取或写入模型中的所有权重时，这很方便。
    </p>
    <pre><code class="prism language-python">mydict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'x'</span><span class="token punctuation">:</span> x<span class="token punctuation">,</span> <span class="token string">'y'</span><span class="token punctuation">:</span> y<span class="token punctuation">}</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>mydict<span class="token punctuation">,</span> <span class="token string">'mydict'</span><span class="token punctuation">)</span>
mydict2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'mydict'</span><span class="token punctuation">)</span>
mydict2
</code></pre>
    <pre><code>{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}
</code></pre>
    <h3>
     <a id="_64">
     </a>
     [
     <strong>
      加载和保存模型参数
     </strong>
     ]
    </h3>
    <p>
     保存单个权重向量（或其他张量）确实有用，但是如果我们想保存整个模型，并在以后加载它们，单独保存每个向量则会变得很麻烦。
     <br/>
     毕竟，我们可能有数百个参数散布在各处。因此，
     <strong>
      深度学习框架提供了内置函数来保存和加载整个网络
     </strong>
     。需要注意的一个重要细节是，
     <strong>
      这将保存模型的参数而不是保存整个模型
     </strong>
     。
     <br/>
     例如，如果我们有一个3层多层感知机，我们需要单独指定架构。因为模型本身可以包含任意代码，所以模型本身难以序列化。因此，为了恢复模型，我们需要用代码生成架构，然后从磁盘加载参数。
     <br/>
     让我们从熟悉的多层感知机开始尝试一下。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    定义一个多层感知机（MLP）模型，继承自 nn.Module。

    该模型包含一个隐藏层和一个输出层。
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        初始化 MLP 模型的各层。
        """</span>
        <span class="token comment"># 调用父类 nn.Module 的构造函数</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 定义隐藏层，输入维度为 20，输出维度为 256</span>
        self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>
        <span class="token comment"># 定义输出层，输入维度为 256，输出维度为 10</span>
        self<span class="token punctuation">.</span>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        定义模型的前向传播过程。

        参数:
        x (torch.Tensor): 输入张量。

        返回:
        torch.Tensor: 模型的输出张量。
        """</span>
        <span class="token comment"># 对隐藏层的输出应用 ReLU 激活函数</span>
        hidden_output <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># 通过输出层得到最终输出</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>output<span class="token punctuation">(</span>hidden_output<span class="token punctuation">)</span>

<span class="token comment"># 创建 MLP 模型的实例</span>
net <span class="token operator">=</span> MLP<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 生成一个形状为 (2, 20) 的随机输入张量</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 将输入张量传入模型进行前向传播，得到输出</span>
Y <span class="token operator">=</span> net<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
</code></pre>
    <p>
     接下来，我们[
     <strong>
      将模型的参数存储在一个叫做“mlp.params”的文件中。
     </strong>
     ]
    </p>
    <pre><code class="prism language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'mlp.params'</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     为了恢复模型，我们[
     <strong>
      实例化了原始多层感知机模型的一个备份。
     </strong>
     ]
     <br/>
     这里我们不需要随机初始化模型参数，而是(
     <strong>
      直接读取文件中存储的参数。
     </strong>
     )
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 创建一个新的 MLP 模型实例，用于加载预训练的参数</span>
clone <span class="token operator">=</span> MLP<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 从 'mlp.params' 文件中加载保存的模型参数状态字典，并将其加载到 clone 模型中</span>
clone<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'mlp.params'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 将模型设置为评估模式，这会影响一些特定层（如 Dropout、BatchNorm）的行为，确保在推理时使用正确的参数</span>
clone<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <blockquote>
     <p>
      <code>
       load_state_dict
      </code>
      方法可以将一个保存好的状态字典加载到当前的模型实例中，从而实现模型参数的恢复或迁移。状态字典是一个 Python 字典对象，它包含了模型中所有可学习参数（如权重和偏置）的张量。
     </p>
    </blockquote>
    <pre><code>clone = MLP()
clone.load_state_dict(torch.load('mlp.params'))
clone.eval()
</code></pre>
    <p>
     由于两个实例具有相同的模型参数，在输入相同的
     <code>
      X
     </code>
     时，两个实例的计算结果应该相同。让我们来验证一下。
    </p>
    <pre><code class="prism language-python">Y_clone <span class="token operator">=</span> clone<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
Y_clone <span class="token operator">==</span> Y
</code></pre>
    <pre><code>tensor([[True, True, True, True, True, True, True, True, True, True],
        [True, True, True, True, True, True, True, True, True, True]])
</code></pre>
   </div>
   <link href="./../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="./../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f53616b7572615f64696e672f:61727469636c652f64657461696c732f313436313836353838" class_="artid" style="display:none">
 </p>
</div>


