---
arturl_encode: "6874:7470733a2f2f626c6f672e6373646e2e6e65742f776e677561:2f61727469636c652f64657461696c732f3534393439343937"
layout: post
title: "应用系统运维建设必备的几个方面"
date: 2024-12-11 13:35:11 +08:00
description: "从知乎上看到有一篇针对应用运维建设讲解的几个必备的方面，个人觉得对运维的整体建设写的不错，特转载到此"
keywords: "应用运维体系有哪些方面"
categories: ['运维学习']
tags: ['运维技能', '运维体系建设', '自动运维']
artid: "54949497"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=54949497
    alt: "应用系统运维建设必备的几个方面"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=54949497
featuredImagePreview: https://bing.ee123.net/img/rand?artid=54949497
---

# 应用系统运维建设必备的几个方面

从知乎上看到有一篇针对应用运维建设讲解的几个必备的方面，个人觉得对运维的整体建设写的不错，特转载到此收藏参考。方便自己以后从下面几个方面参考建设运维体系。

结合现在云计算和


DevOps

的发展趋势，我觉得一个成熟的自动化运维平台应该包括以下的特性：

  

**一、支持混合云的


CMDB**

  



现在越来越多的服务器都转到了云上，而主流的公有云、私有云平台都拥有比较完备的资源管理的


API

，这些


API

也就是构建一个自动化


CMDB

的基础。

  



新一代的自动化运维平台应该是可以基于这些


API

来自动维护和管理相关的服务器、存储、网络、负载均衡的资源的。

  



通过


API

对资源的操作都应该被作为操作日志记录下来，以备作为后续操作审计的基础数据。

  

  
CMDB


这个东西听上去是老生常谈，但这个确实是所有运维工具的基础设施。

  



而基于开源工具做运维平台最大的麻烦，就是如何在各个工具之间把


CMDB

统一起来。

  

CMDB


不统一起来，就意味着一旦要增加一台服务器，可能要在各个运维工具里面都要同步一下，这个还是非常折腾滴。。。

  

  

**二、比较完备的监控


+

应用性能分析（


APM

）**

  



能支持对平台的可用性、服务器的性能、各种服务（


web

服务、应用服务、数据库服务）的性能进行监控。做的好一些应该能进行更深入、或者关联性的性能分析。

  

  


现在市面上一般都会将资源性能监控和应用性能监控（


APM

）混合着讲，这里面的产品确实也有很多都是重叠的，两方面都会涉及到。

  

  


开源的性能监控系统主流有的


Zabbix

、


Nagios

，国产的开源监控平台有小米


OpenFalcon

，但这些基本都只是做基本的资源监控（服务器，磁盘、网络等）和简单的服务软件的性能监控（中间件，数据库等）。

  

  


而市面上的


APM

系统更主打的功能是应用性能分析，比如能精确定位到某个应用的


URL

的访问速度快慢，某些


SQL

执行速度的快慢，这些对于开发人员和运维人员快速定位问题还是很有帮助的。

  

APM


这方面的商业工具，国外比较主流的有


New Reclic

、


Dynatrace

，国内的也就是透视宝、


Oneapm

、听云等，他们也提供了


API

进行集成。

  

APM


这方面的开源工具有


pinpoint

（一个韩国团队开源的），


zipkin

（


twitter

开源），


cat

（大众点评开源）。

  

  

**三、有一个还不错


UI

的批量运维工具**

  



在业务发展比较快的情况下，从几台服务器，到几十台服务器，再到几百台服务器，批量运维的需求很自然就产生了，老板也希望越少的人干越多的活。

  

  


现在也有不少开源的批量运维工具，也都比较成熟了，比如


puppet

、


chef

、


ansible

、


saltstack

。

  

puppet


和


chef

都是


ruby

做的，实话实说，


ruby

的熟手市面上很少，比


python

不是难招一点。

  

  


我个人比较推荐使用


ansible

或者


saltstack

，这两个系统都是


python

写的，代码质量和社区活跃度都挺不错的。

  

ansible


有官方的


web ui

——


Tower

，但实话实说不好用，所以我们也在重新做一套自己用起来更顺手的


WEBUI

。

  

  
  
**四、日志集中分析工具**

  



线上系统最常规的问题定位方式，就是日志分析了。

  



随着服务器的增多，日志的分析定位也成为一个难点和痛点（想象一下，系统出故障之后，要去几十甚至数百个节点去上去查日志，是有多折腾）。

  

  


国内有一家叫日志易的公司，是专门做日志分析方面的运维工具的。

  



另外还有一家


log insight

，也是做这个领域，但产品好像还处于


beta

阶段。

  

  


日志分析这个领域现在是一个热点，现在的开源方案也比较多了，比如著名的


ELKStack

，还有


Flume+Kafka+Storm

的体系。

  



上面这两个方案相对重一些，部署比较复杂，网上介绍的文章也不少。

  

  


比较轻量级的开源日志集中采集方案有


python

做的


Sentry

，他是通过改造各种语言的日志采集框架来实现日志的集中采集，各种主流的开发语言的日志框架都支持得很完整了，比如


java

的


log4j

和


logpack

。

  

Sentry


的官网在此：

[Sentry - Track exceptions with modern error logging for JavaScript,Python, Ruby, Java, and Node.js](https://link.zhihu.com/?target=https%3A//getsentry.com/welcome/)
  

  
**五、持续集成和发布工具**

  



这方面其实比较难有统一的需求，很多公司集成发布的做法都差异挺大的。

  



持续集成方面，一般用


jekins

的比较多，这方面网上介绍的文章也很多。

  

  


而如何把打好的包发布至各台服务器，则可以通过批量运维工具或者脚本来完成了。

  



版本发布的过程涉及到很多细节，包括了版本文件的上传、分发、版本管理、回滚等各种操作。

  



对于一般不太复杂的项目，我比较推荐的做法是把打包好的文件上传到


svn

上，然后通过脚本在各台服务器上进行发布操作就行了，这样其实是利用了


SVN

来完成文件的上传、分发、版本管理、回滚等各种操作。

  

  
**六、安全漏洞扫描工具**

  



现在一个稍微有点知名度的系统，都会遭受各种各样的安全攻击的折磨。

  



一般的公司不太可能请得起专职的安全工程师，所以运维工程师最好能自己借助一些安全扫描工具来发现自己系统的漏洞。

  



安全工具方面我了解不多，不太熟这个领域的开源工具。

  



之前乌云网推出过一个


SaaS

化的漏扫平台——唐朝巡航，有对外提供漏洞扫描的


API

，不过最近乌云网一直在升级，所以也就暂时无法调用了。

  

  


个人觉得，如果上述功能都有了，基本上大部分中小规模企业的日常运维工作的高频操作都覆盖到了。

  



如果是比较大的互联网企业，或者还有一些特殊的业务需求，那就具体问题具体分析了。

﻿﻿