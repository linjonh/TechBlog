---
arturl_encode: "6874747073:3a2f2f626c6f672e6373646e2e6e65742f776861746461792f:61727469636c652f64657461696c732f313036393432303233"
layout: post
title: "fofa-搜索结果提取技术分析"
date: 2025-01-19 09:00:00 +08:00
description: "本文探讨了Fofa搜索引擎的高级语法及如何利用BeautifulSoup解析网页，深入讲解了api使"
keywords: "fofa搜索base64"
categories: ['未分类']
tags: ['无标签']
artid: "106942023"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=106942023
  alt: "fofa-搜索结果提取技术分析"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=106942023
featuredImagePreview: https://bing.ee123.net/img/rand?artid=106942023
---

# fofa 搜索结果提取技术分析

> 脚本语言：python2.7

### 白嫖与付费

付费肯定有更好的服务，但是就是喜欢薅羊毛的快乐。能付费尽量付费吧，如果你付费了这个脚本使用起来更安逸。

### 非api原因

根据网站vip功能介绍，可以看到“注册用户”和“普通会员”使用api都是亏本买卖，如果想用api就开svip才最安逸

[![](https://i-blog.csdnimg.cn/blog_migrate/c8aa20c5469a213090bb0542e90e483d.png)](https://image.3001.net/images/20200528/1590631866_5ecf1dba2c6c5.png)

### Fofa与BeautifulSoup

**Fofa**
**的搜索语法**

返回头              header=”200″

国家                   country=”CN”

页面内容         body=”phpweb”

网页头              title=”公司”

端口                   port=”443″

网站年份         after=”2020-01-01″

**BeautifulSoup**
**库**

注：一般搭建好网站不会轻易更改网页标签类型，所以使用标签提取比正则匹配能让脚本“活得更久”

定位网页标签

```
         soup.find(name="input", attrs={"id": "total_entries"})
```

```
         soup.find_all(name="div", attrs={"class": "list_mod"})
```

获取标签值

```
         yourdiv.attrs['value']
```

获取ul内的li值

[![](https://i-blog.csdnimg.cn/blog_migrate/dbbf1e62622f7842e5ef2665f1a4f54e.png)](https://image.3001.net/images/20200528/1590631894_5ecf1dd6d7460.png)

### 执行搜索操作

打开fofa官网
<https://fofa.so/>
，搜索热门关键字，可以看到url请求为

<https://fofa.so/result?qbase64=>
xxx

[![](https://i-blog.csdnimg.cn/blog_migrate/23bbf278c1a90a610049211b6a1a79f2.png)](https://image.3001.net/images/20200528/1590632134_5ecf1ec6e4db4.png)

其中qbase64的值就是搜索字符串“base64编码+url编码”的结果，这里需要注意中文问题，需要将中文先gbk解码，再用base64库编码（我本机是gbk编码，所以输入的中文也是gbk编码，如果你的机器是utf-8编码就改为utf-8，没测）

```
code = key.decode()
 code = urllib.quote(base64.b64encode(code))
```

这里遇到个问题一直没整明白，上面那种方式可以成功，但是下面这种使用方式却失败了，如果有人知道原因请留言或私信给我。

```
code = urllib.quote(base64.b64encode(key.decode('gbk')))
```

代码

[![](https://i-blog.csdnimg.cn/blog_migrate/cc3a9f01b2704a683dea89e3c81877c0.png)](https://image.3001.net/images/20200528/1590632164_5ecf1ee4090fd.png)

### 获取页面搜索结果

使用浏览器自带调试功能查看html框架，可以看到我们搜索结果都在“<div>”标签下，每一个“<divclass=”list_mod”>”标签是一条信息

[![](https://i-blog.csdnimg.cn/blog_migrate/c205ad184400359796d30113a776bd0c.png)](https://image.3001.net/images/20200528/1590632182_5ecf1ef683149.png)
一个list_mod标签包含一个目标的全部信息

[![](https://i-blog.csdnimg.cn/blog_migrate/c04095f767d60fe7ced33f0923130667.png)](https://image.3001.net/images/20200528/1590632195_5ecf1f0301b6f.png)
代码，其中divs就是全部目标列表

[![](https://i-blog.csdnimg.cn/blog_migrate/304345a24893b483c1b2c3733f5fa609.png)](https://image.3001.net/images/20200528/1590632205_5ecf1f0dd5fc4.png)

### 定位单条目标信息

选取单个目标的标签点开分析，可以看到标签有list_mod_t和list_mod_c两个子标签

[![](https://i-blog.csdnimg.cn/blog_migrate/3f5e48ff66b041638a2d4fbe43f5915c.png)](https://image.3001.net/images/20200528/1590632221_5ecf1f1d08fa0.png)
而元素a就是可以直接跳转的链接，从这里提取到目标的url或者IP

![](https://i-blog.csdnimg.cn/blog_migrate/12580be6383dcb778bde1fb7ca6adfca.png)
![](https://i-blog.csdnimg.cn/blog_migrate/5242994a1885928ab96d13e212251260.png)
而目标下面的介绍其实是一个ul列表，这部分信息也比较重要，所以我也提取了

![](https://i-blog.csdnimg.cn/blog_migrate/db0c9d36cb7bcce9243449a92fd73878.png)
![](https://i-blog.csdnimg.cn/blog_migrate/b40aff926c2ba06de4f30998fa447d28.png)

代码

![](https://i-blog.csdnimg.cn/blog_migrate/064329e3de325d1befb5e69047f46d8d.png)
其中列表信息没做详细分类提取，也没有把他写入到文件，内存里长这样

![](https://i-blog.csdnimg.cn/blog_migrate/cdbd8267b9e115302f48cb5ca06f766e.png)

### 关于URL存活状态

在单个目标的右边有他的响应码，我是根据这个来确定的存活，当然你也可以自己请求一下提取的URL来判断存活，如果只需要200的网站就在查询时使用header=”200″；代码中获取的是右侧整个字符串，大家根据需要自行修改代码就行

![](https://i-blog.csdnimg.cn/blog_migrate/405ed342facd31a9797ea413495634ec.png)
代码
![](https://i-blog.csdnimg.cn/blog_migrate/c969d44d228e335e9b75e10b4a05e4f7.png)

### 翻页问题

我们知道目标总数除以10后加1就是页数，所以要提取目标总数，依旧是根据网页标签定位提取数据

![](https://i-blog.csdnimg.cn/blog_migrate/e65732df5bca37507b6a0a772060fafe.png)
代码如下

![](https://i-blog.csdnimg.cn/blog_migrate/8b0394e4dfd5f29e1fa024c8576edf02.png)

知道总页数怎么翻页呢？

通过api规则知道请求中的page参数决定当前页面（或者看网页【下一页】的链接），测试中发现有请求频率限制，做下防封延时就行

![](https://i-blog.csdnimg.cn/blog_migrate/860bc2175ed78f678c1814ea65d44d92.png)
![](https://i-blog.csdnimg.cn/blog_migrate/5d40e874078ded1268d49087bf68de44.png)
代码如下

![](https://i-blog.csdnimg.cn/blog_migrate/0ae814f2d072f5d8f6ead4747d2c2032.png)

### 网站cookie

Fofa现在登陆需要进行验证了，无法直接用户名密码登陆，所以我使用的cookie验证身份。

![](https://i-blog.csdnimg.cn/blog_migrate/7c7b296ee0029f395175b47046ca0755.png)

### 自定义数据输出

在按页获取函数中修改数据处理方式，解除注册会员限制

![](https://i-blog.csdnimg.cn/blog_migrate/49275c0b0b3b2a7d713044b5253212af.png)
脚本中是将链接追加到指定txt文件中，其它信息只是获取了，并没有输出

![](https://i-blog.csdnimg.cn/blog_migrate/6fa1aeb1b5006e041f5ddd2d0c8c1713.png)

### 脚本使用

使用命令参数输入关键字和cookie，会输出总数，提示每页有多少条存活，其他信息输出自行修改脚本

**注意titile**
**、app**
**等使用方法，如果网页搜索栏是这样的**

app=”BEA-WebLogic-Server”

**那么命令行这样输入**

“app=\”BEA-WebLogic-Server\”"

![](https://i-blog.csdnimg.cn/blog_migrate/5fa74277bf501bd32c6121d37fe7999b.png)
输出总数和网页搜索总数一致（没有带国家参数）

![](https://i-blog.csdnimg.cn/blog_migrate/38e0a7c13399250c62d8b34022224a16.png)
Hreffile.txt内容

![](https://i-blog.csdnimg.cn/blog_migrate/9adc2e660d486de07fd79b2b8b34f317.png)