---
layout: post
title: "图像识别技术与应用-YOLO"
date: 2025-03-12 16:32:00 +0800
description: "它通过对训练集中标注的目标框尺寸等信息进行聚类分析，自动确定合适的先验框尺寸，使得先验框能更好地匹配不同数据集中目标的实际形状和大小分布情况，进而提升目标检测的精度，让网络在预测时更容易收敛到合适的边界框。YOLO-V1它是经典的one-stage方法，You Only Look Once，名字就已经说明了一切！DarkNet，实际输入为416*416，没有FC层，5次降采样（13*13），1*1卷积节省了很多参数。最后一层时感受野太大了，小目标可能丢失了，需融合之前的特征。比YOLO-V1更快，更强，"
keywords: "图像识别技术与应用-YOLO"
categories: ['未分类']
tags: ['Yolo']
artid: "146207519"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146207519
    alt: "图像识别技术与应用-YOLO"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146207519
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146207519
cover: https://bing.ee123.net/img/rand?artid=146207519
image: https://bing.ee123.net/img/rand?artid=146207519
img: https://bing.ee123.net/img/rand?artid=146207519
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     图像识别技术与应用-YOLO
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     <strong>
      1 YOLO-V1
     </strong>
    </p>
    <p>
     YOLO-V1它是经典的one-stage方法，You Only Look Once，名字就已经说明了一切！把检测问题转化成回归问题，一个CNN就搞定了！也可以对视频进行实时检测，应用领域非常广！
    </p>
    <p>
     YOLO-V1诞生与2015年
    </p>
    <p>
     <img src="https://i-blog.csdnimg.cn/direct/276d913c8ca3415e9ab3cf2929a4bdac.png"/>
    </p>
    <p>
     <strong>
      优点
     </strong>
    </p>
    <p>
     1)快速，简单
    </p>
    <p>
     <strong>
      缺点
     </strong>
    </p>
    <p>
     1)每个Cell只预测一个类别，如果重叠无法解决
    </p>
    <p style="margin-left:0in; text-align:left">
     2)小物体检测效果一般，长宽比可选的但单一
    </p>
    <p style="margin-left:0in; text-align:left">
     <strong>
      核心思想:
     </strong>
     把目标检测任务当作一个回归问题处理
    </p>
    <p style="margin-left:0in; text-align:left">
     <img src="https://i-blog.csdnimg.cn/direct/4283620b19d04412b527f52debf07811.png"/>
    </p>
    <p style="margin-left:0in; text-align:left">
     <strong>
      网络架构
     </strong>
    </p>
    <p style="margin-left:0in; text-align:left">
     <img src="https://i-blog.csdnimg.cn/direct/2a33e2b08b3841beba63b9e3a9ca6323.png"/>
    </p>
    <p style="margin-left:0in; text-align:left">
     <strong>
      损失函数
     </strong>
    </p>
    <p style="margin-left:0in; text-align:left">
     <img src="https://i-blog.csdnimg.cn/direct/78a6a39724924a0caa02c023f0b75bb8.png"/>
    </p>
    <p style="margin-left:0in; text-align:left">
     <strong>
      2 YOLO-V2
     </strong>
    </p>
    <p style="margin-left:0in; text-align:left">
     <strong>
      优点:
     </strong>
     比YOLO-V1更快，更强，更大的分辨率
    </p>
    <p style="margin-left:0in; text-align:left">
     <img src="https://i-blog.csdnimg.cn/direct/44cc41ed14504b6da6a43fef78bd9b95.png"/>
    </p>
    <p style="margin-left:0in; text-align:left">
     <strong>
      YOLO-V2-Batch Normalization
     </strong>
    </p>
    <p style="margin-left:0in; text-align:left">
     V2版本舍弃Dropout，卷积后全部加入Batch Normalization
    </p>
    <p style="margin-left:0in; text-align:left">
     网络的每一层的输入都做了归一化，收敛相对更容易
    </p>
    <p style="margin-left:0in; text-align:left">
     经过Batch Normalization处理后的网络会提升2%的mAP
    </p>
    <p style="margin-left:0in; text-align:left">
     从现在的角度来看，Batch Normalization已经成网络必备处理
    </p>
    <p style="margin-left:0in; text-align:left">
     <strong>
      网络结构
     </strong>
    </p>
    <p style="margin-left:0in; text-align:left">
     DarkNet，实际输入为416*416，没有FC层，5次降采样（13*13），1*1卷积节省了很多参数
    </p>
    <p style="margin-left:0in; text-align:left">
     <img src="https://i-blog.csdnimg.cn/direct/a6968a03faf747288654d20939fdc2dd.png"/>
    </p>
    <p style="margin-left:0in; text-align:left">
     <strong>
      YOLO-V2-聚类提取先验框
     </strong>
    </p>
    <p style="margin-left:0in; text-align:left">
     <strong>
      特点:
     </strong>
     它通过对训练集中标注的目标框尺寸等信息进行聚类分析，自动确定合适的先验框尺寸，使得先验框能更好地匹配不同数据集中目标的实际形状和大小分布情况，进而提升目标检测的精度，让网络在预测时更容易收敛到合适的边界框
    </p>
    <p style="margin-left:0in; text-align:left">
     <img src="https://i-blog.csdnimg.cn/direct/b0e678c9905f437fbe4d6d11c51a0a3d.png">
      <img src="https://i-blog.csdnimg.cn/direct/616bd1c560fc44528405b152a019632a.png"/>
     </img>
    </p>
    <p style="margin-left:0in; text-align:left">
     <strong>
      YOLO-V2-Anchor Box
     </strong>
    </p>
    <p style="margin-left:0in; text-align:left">
     1)通过引入anchor boxes，使得预测的box数量更多（13*13*n）
    </p>
    <p style="margin-left:0in; text-align:left">
     2)跟faster-rcnn系列不同的是先验框并不是直接按照长宽固定比给定
    </p>
    <p style="margin-left:0in; text-align:left">
     <img src="https://i-blog.csdnimg.cn/direct/bde09f541a524fc48193646fff3c84ff.png"/>
    </p>
    <p style="margin-left:0in; text-align:left">
     <strong>
      感受野
     </strong>
    </p>
    <p style="margin-left:0in; text-align:left">
     <strong>
      简介：概述来说就是特征图上的点能看到原始图像多大区域。
     </strong>
    </p>
    <p style="margin-left:0in; text-align:left">
     <img src="https://i-blog.csdnimg.cn/direct/572073ee04a8421c973d65c015b9bdce.png"/>
    </p>
    <p style="margin-left:0in; text-align:left">
     <strong>
      YOLO-V2-Fine-Grained Features
     </strong>
    </p>
    <p style="margin-left:0in; text-align:left">
     如果最后一层时感受野太大了，小目标可能丢失了，需融合之前的特征。
    </p>
    <p style="margin-left:0in; text-align:left">
     <img src="https://i-blog.csdnimg.cn/direct/70e4ce7d6c4f47c6b09f8292d9773383.png"/>
    </p>
    <p style="margin-left:0in; text-align:left">
    </p>
    <p style="margin-left:0in; text-align:left">
    </p>
    <p style="margin-left:0in; text-align:left">
    </p>
    <p style="margin-left:0in; text-align:left">
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f323430315f38323432353638362f:61727469636c652f64657461696c732f313436323037353139" class_="artid" style="display:none">
 </p>
</div>


