---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f35323634393935322f:61727469636c652f64657461696c732f313436313636313638"
layout: post
title: "J6æ‰“å¡pytorchå®ç°ResNeXt-50å®ç°çŒ´ç—˜æ£€æµ‹"
date: 2025-03-10 23:02:40 +0800
description: "åœ¨è¿™æ¬¡æ·±åº¦å­¦ä¹ è®­ç»ƒè¥çš„å­¦ä¹ ä¸­ï¼Œæˆ‘é€šè¿‡å®ç°ResNeXt-50æ¨¡å‹çš„æ„å»ºã€è®­ç»ƒå’Œè¯„ä¼°ï¼Œæ·±å…¥ç†è§£äº†æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ„å»ºæµç¨‹å’Œä¼˜åŒ–æ–¹æ³•ã€‚"
keywords: "J6æ‰“å¡â€”â€”pytorchå®ç°ResNeXt-50å®ç°çŒ´ç—˜æ£€æµ‹"
categories: ['æœªåˆ†ç±»']
tags: ['äººå·¥æ™ºèƒ½', 'Pytorch', 'Python']
artid: "146166168"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146166168
    alt: "J6æ‰“å¡pytorchå®ç°ResNeXt-50å®ç°çŒ´ç—˜æ£€æµ‹"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146166168
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146166168
cover: https://bing.ee123.net/img/rand?artid=146166168
image: https://bing.ee123.net/img/rand?artid=146166168
img: https://bing.ee123.net/img/rand?artid=146166168
---

# J6æ‰“å¡â€”â€”pytorchå®ç°ResNeXt-50å®ç°çŒ´ç—˜æ£€æµ‹

* **ğŸ¨**
  **æœ¬æ–‡ä¸º**
  [ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥](https://mp.weixin.qq.com/s/Z9yL_wt7L8aPOr9Lqb1K3w "ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥")
  **ä¸­çš„å­¦ä¹ è®°å½•åšå®¢**

* **ğŸ–**
  **åŸä½œè€…ï¼š**
  [KåŒå­¦å•Š](https://mtyjkh.blog.csdn.net/ "KåŒå­¦å•Š")

## 1.æ£€æŸ¥GPU

```
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision
from torchvision import transforms, datasets

import os,PIL,pathlib

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

device
```

![](https://i-blog.csdnimg.cn/direct/55137779ebae4495a7b25dc1995440f7.png)
â€‹â€‹â€‹â€‹â€‹â€‹

## **2.æŸ¥çœ‹æ•°æ®**

```
import os,PIL,random,pathlib

data_dir = 'data/45-data/'
data_dir = pathlib.Path(data_dir)

data_paths = list(data_dir.glob('*'))
classeNames = [str(path).split("\\")[2] for path in data_paths]
classeNames
```

## â€‹â€‹â€‹

## 3.åˆ’åˆ†æ•°æ®é›†

```
total_datadir = 'data/45-data'

train_transforms = transforms.Compose([
    transforms.Resize([224, 224]),  # å°†è¾“å…¥å›¾ç‰‡resizeæˆç»Ÿä¸€å°ºå¯¸
    transforms.ToTensor(),          # å°†PIL Imageæˆ–numpy.ndarrayè½¬æ¢ä¸ºtensorï¼Œå¹¶å½’ä¸€åŒ–åˆ°[0,1]ä¹‹é—´
    transforms.Normalize(           # æ ‡å‡†åŒ–å¤„ç†-->è½¬æ¢ä¸ºæ ‡å‡†æ­£å¤ªåˆ†å¸ƒï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰ï¼Œä½¿æ¨¡å‹æ›´å®¹æ˜“æ”¶æ•›
        mean=[0.485, 0.456, 0.406], 
        std=[0.229, 0.224, 0.225])  # å…¶ä¸­ mean=[0.485,0.456,0.406]ä¸std=[0.229,0.224,0.225] ä»æ•°æ®é›†ä¸­éšæœºæŠ½æ ·è®¡ç®—å¾—åˆ°çš„ã€‚
])

total_data = datasets.ImageFolder(total_datadir,transform=train_transforms)
total_data

train_size = int(0.8 * len(total_data))
test_size  = len(total_data) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(total_data, [train_size, test_size])
train_dataset, test_dataset

train_size,test_size

batch_size = 32

train_dl = torch.utils.data.DataLoader(train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True,
                                           num_workers=1)
test_dl = torch.utils.data.DataLoader(test_dataset,
                                          batch_size=batch_size,
                                          shuffle=True,
                                          num_workers=1)

for X, y in test_dl:
    print("Shape of X [N, C, H, W]: ", X.shape)
    print("Shape of y: ", y.shape, y.dtype)
    break
```

## â€‹â€‹â€‹ â€‹â€‹â€‹â€‹â€‹â€‹

â€‹
![](https://i-blog.csdnimg.cn/direct/08220b17d41046819bb4cb21be30b073.png)
â€‹â€‹â€‹
![](https://i-blog.csdnimg.cn/direct/8a94a568335c417c909bb69f3034e5f7.png)
â€‹â€‹

## 4.åˆ›å»ºæ¨¡å‹

```
import torch
import torch.nn as nn
import torch.nn.functional as F

class GroupedConvolutionBlock(nn.Module):
    def __init__(self, in_channels, out_channels, strides, groups):
        super(GroupedConvolutionBlock, self).__init__()
        self.groups = groups
        self.g_channels = out_channels // groups
        self.conv_layers = nn.ModuleList([
            nn.Conv2d(self.g_channels, self.g_channels, kernel_size=3, stride=strides, padding=1, bias=False)
            for _ in range(groups)
        ])
        self.bn = nn.BatchNorm2d(out_channels, eps=1.001e-5)
        self.relu = nn.ReLU()

    def forward(self, x):
        group_list = []
        # åˆ†ç»„è¿›è¡Œå·ç§¯
        for c in range(self.groups):
            # åˆ†ç»„å–å‡ºæ•°æ®
            x_group = x[:, c * self.g_channels:(c + 1) * self.g_channels, :, :]
            # åˆ†ç»„è¿›è¡Œå·ç§¯
            x_group = self.conv_layers[c](x_group)
            # å­˜å…¥list
            group_list.append(x_group)
        # åˆå¹¶listä¸­çš„æ•°æ®
        group_merge = torch.cat(group_list, dim=1)
        x = self.bn(group_merge)
        x = self.relu(x)
        return x

class Block(nn.Module):
    def __init__(self, in_channels, filters, strides=1, groups=32, conv_shortcut=True):
        super(Block, self).__init__()
        self.conv_shortcut = conv_shortcut

        if conv_shortcut:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, filters * 2, kernel_size=1, stride=strides, bias=False),
                nn.BatchNorm2d(filters * 2, eps=1.001e-5)
            )
        else:
            self.shortcut = nn.Identity()

        self.conv1 = nn.Conv2d(in_channels, filters, kernel_size=1, stride=1, bias=False)
        self.bn1 = nn.BatchNorm2d(filters, eps=1.001e-5)
        self.relu1 = nn.ReLU()

        self.grouped_conv = GroupedConvolutionBlock(filters, filters, strides, groups)

        self.conv2 = nn.Conv2d(filters, filters * 2, kernel_size=1, stride=1, bias=False)
        self.bn2 = nn.BatchNorm2d(filters * 2, eps=1.001e-5)
        self.relu2 = nn.ReLU()

    def forward(self, x):
        shortcut = self.shortcut(x)

        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu1(x)

        x = self.grouped_conv(x)

        x = self.conv2(x)
        x = self.bn2(x)

        x = x + shortcut
        x = self.relu2(x)
        return x

class Stack(nn.Module):
    def __init__(self, in_channels, filters, blocks, strides, groups=32):
        super(Stack, self).__init__()
        self.blocks = nn.ModuleList()
        self.blocks.append(Block(in_channels, filters, strides, groups, conv_shortcut=True))
        for _ in range(1, blocks):
            self.blocks.append(Block(filters * 2, filters, strides=1, groups=groups, conv_shortcut=False))

    def forward(self, x):
        for block in self.blocks:
            x = block(x)
        return x

class ResNext50(nn.Module):
    def __init__(self, input_shape, num_classes):
        super(ResNext50, self).__init__()
        self.conv1 = nn.Conv2d(input_shape[0], 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64, eps=1.001e-5)
        self.relu1 = nn.ReLU()
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        self.stack1 = Stack(64, 128, 2, 1)
        self.stack2 = Stack(256, 256, 3, 2)
        self.stack3 = Stack(512, 512, 5, 2)
        self.stack4 = Stack(1024, 1024, 2, 2)

        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(2048, num_classes)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu1(x)
        x = self.maxpool(x)

        x = self.stack1(x)
        x = self.stack2(x)
        x = self.stack3(x)
        x = self.stack4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return x

from torchsummary import summary

model=ResNext50(input_shape=(224,224,3),num_classes=1000)

model = ResNext50(input_shape=(3, 224, 224), num_classes=1000)

# å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# æ‰“å°æ¨¡å‹æ‘˜è¦
summary(model, input_size=(3, 224, 224))

```

## 

## â€‹â€‹

## 5.ç¼–è¯‘åŠè®­ç»ƒæ¨¡å‹

```
loss_fn    = nn.CrossEntropyLoss() # åˆ›å»ºæŸå¤±å‡½æ•°
learn_rate = 1e-4 # å­¦ä¹ ç‡
opt        = torch.optim.SGD(model.parameters(),lr=learn_rate)

# è®­ç»ƒå¾ªç¯
def train(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset)  # è®­ç»ƒé›†çš„å¤§å°ï¼Œä¸€å…±60000å¼ å›¾ç‰‡
    num_batches = len(dataloader)   # æ‰¹æ¬¡æ•°ç›®ï¼Œ1875ï¼ˆ60000/32ï¼‰

    train_loss, train_acc = 0, 0  # åˆå§‹åŒ–è®­ç»ƒæŸå¤±å’Œæ­£ç¡®ç‡
    
    for X, y in dataloader:  # è·å–å›¾ç‰‡åŠå…¶æ ‡ç­¾
        X, y = X.to(device), y.to(device)
        
        # è®¡ç®—é¢„æµ‹è¯¯å·®
        pred = model(X)          # ç½‘ç»œè¾“å‡º
        loss = loss_fn(pred, y)  # è®¡ç®—ç½‘ç»œè¾“å‡ºå’ŒçœŸå®å€¼ä¹‹é—´çš„å·®è·ï¼Œtargetsä¸ºçœŸå®å€¼ï¼Œè®¡ç®—äºŒè€…å·®å€¼å³ä¸ºæŸå¤±
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()  # gradå±æ€§å½’é›¶
        loss.backward()        # åå‘ä¼ æ’­
        optimizer.step()       # æ¯ä¸€æ­¥è‡ªåŠ¨æ›´æ–°
        
        # è®°å½•accä¸loss
        train_acc  += (pred.argmax(1) == y).type(torch.float).sum().item()
        train_loss += loss.item()
            
    train_acc  /= size
    train_loss /= num_batches

    return train_acc, train_loss

def test (dataloader, model, loss_fn):
    size        = len(dataloader.dataset)  # æµ‹è¯•é›†çš„å¤§å°ï¼Œä¸€å…±10000å¼ å›¾ç‰‡
    num_batches = len(dataloader)          # æ‰¹æ¬¡æ•°ç›®ï¼Œ313ï¼ˆ10000/32=312.5ï¼Œå‘ä¸Šå–æ•´ï¼‰
    test_loss, test_acc = 0, 0
    
    # å½“ä¸è¿›è¡Œè®­ç»ƒæ—¶ï¼Œåœæ­¢æ¢¯åº¦æ›´æ–°ï¼ŒèŠ‚çœè®¡ç®—å†…å­˜æ¶ˆè€—
    with torch.no_grad():
        for imgs, target in dataloader:
            imgs, target = imgs.to(device), target.to(device)
            
            # è®¡ç®—loss
            target_pred = model(imgs)
            loss        = loss_fn(target_pred, target)
            
            test_loss += loss.item()
            test_acc  += (target_pred.argmax(1) == target).type(torch.float).sum().item()

    test_acc  /= size
    test_loss /= num_batches

    return test_acc, test_loss

epochs     = 20
train_loss = []
train_acc  = []
test_loss  = []
test_acc   = []

for epoch in range(epochs):
    model.train()
    epoch_train_acc, epoch_train_loss = train(train_dl, model, loss_fn, opt)
    
    model.eval()
    epoch_test_acc, epoch_test_loss = test(test_dl, model, loss_fn)
    
    train_acc.append(epoch_train_acc)
    train_loss.append(epoch_train_loss)
    test_acc.append(epoch_test_acc)
    test_loss.append(epoch_test_loss)
    
    template = ('Epoch:{:2d}, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%ï¼ŒTest_loss:{:.3f}')
    print(template.format(epoch+1, epoch_train_acc*100, epoch_train_loss, epoch_test_acc*100, epoch_test_loss))
print('Done')
```

## â€‹ â€‹â€‹

## 6.ç»“æœå¯è§†åŒ–

```
import matplotlib.pyplot as plt
#éšè—è­¦å‘Š
import warnings
warnings.filterwarnings("ignore")               #å¿½ç•¥è­¦å‘Šä¿¡æ¯
plt.rcParams['font.sans-serif']    = ['SimHei'] # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False      # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
plt.rcParams['figure.dpi']         = 100        #åˆ†è¾¨ç‡

from datetime import datetime
current_time = datetime.now() # è·å–å½“å‰æ—¶é—´

epochs_range = range(epochs)

plt.figure(figsize=(12, 3))
plt.subplot(1, 2, 1)

plt.plot(epochs_range, train_acc, label='Training Accuracy')
plt.plot(epochs_range, test_acc, label='Test Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')
plt.xlabel(current_time) # æ‰“å¡è¯·å¸¦ä¸Šæ—¶é—´æˆ³ï¼Œå¦åˆ™ä»£ç æˆªå›¾æ— æ•ˆ

plt.subplot(1, 2, 2)
plt.plot(epochs_range, train_loss, label='Training Loss')
plt.plot(epochs_range, test_loss, label='Test Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
```

## â€‹â€‹â€‹

## â€‹â€‹â€‹â€‹â€‹7.é¢„æµ‹å›¾ç‰‡

```
from PIL import Image 

classes = list(total_data.class_to_idx)

def predict_one_image(image_path, model, transform, classes):
    
    test_img = Image.open(image_path).convert('RGB')
    # plt.imshow(test_img)  # å±•ç¤ºé¢„æµ‹çš„å›¾ç‰‡

    test_img = transform(test_img)
    img = test_img.to(device).unsqueeze(0)
    
    model.eval()
    output = model(img)

    _,pred = torch.max(output,1)
    pred_class = classes[pred]
    print(f'é¢„æµ‹ç»“æœæ˜¯ï¼š{pred_class}')

# é¢„æµ‹è®­ç»ƒé›†ä¸­çš„æŸå¼ ç…§ç‰‡
predict_one_image(image_path='data/45-data/Others/NM01_01_05.jpg', 
                  model=model, 
                  transform=train_transforms, 
                  classes=classes)
```

## â€‹â€‹â€‹â€‹

## æ€»ç»“ï¼š

åœ¨è¿™æ¬¡æ·±åº¦å­¦ä¹ è®­ç»ƒè¥çš„å­¦ä¹ ä¸­ï¼Œæˆ‘é€šè¿‡å®ç°ResNeXt-50æ¨¡å‹çš„æ„å»ºã€è®­ç»ƒå’Œè¯„ä¼°ï¼Œæ·±å…¥ç†è§£äº†æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ„å»ºæµç¨‹å’Œä¼˜åŒ–æ–¹æ³•ã€‚ä»¥ä¸‹æ˜¯æˆ‘çš„å­¦ä¹ æ€»ç»“ï¼š

### 1. **GPUæ£€æŸ¥ä¸æ•°æ®å‡†å¤‡**

* **GPUæ£€æŸ¥**
  ï¼šé€šè¿‡
  `torch.cuda.is_available()`
  æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿåœ¨GPUä¸Šè¿è¡Œä»¥åŠ é€Ÿè®­ç»ƒã€‚
* **æ•°æ®å‡†å¤‡**
  ï¼šä½¿ç”¨
  `torchvision.datasets.ImageFolder`
  åŠ è½½æ•°æ®é›†ï¼Œå¹¶é€šè¿‡
  `transforms`
  å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬è°ƒæ•´å¤§å°ã€è½¬æ¢ä¸ºå¼ é‡å’Œæ ‡å‡†åŒ–å¤„ç†ã€‚

### 2. **æ¨¡å‹æ„å»º**

* **åˆ†ç»„å·ç§¯å—**
  ï¼šå®ç°äº†åˆ†ç»„å·ç§¯å—
  `GroupedConvolutionBlock`
  ï¼Œé€šè¿‡å°†è¾“å…¥ç‰¹å¾å›¾åˆ†ç»„å¹¶åˆ†åˆ«è¿›è¡Œå·ç§¯æ“ä½œï¼Œæœ€ååˆå¹¶ç»“æœã€‚è¿™ç§æ–¹å¼å¢åŠ äº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚
* **æ®‹å·®å•å…ƒ**
  ï¼šå®šä¹‰äº†æ®‹å·®å•å…ƒ
  `Block`
  ï¼ŒåŒ…å«1x1å·ç§¯ã€åˆ†ç»„å·ç§¯å’Œ1x1å·ç§¯ï¼Œå¹¶é€šè¿‡æ®‹å·®è¿æ¥å°†è¾“å…¥ä¸è¾“å‡ºç›¸åŠ ï¼Œé¿å…äº†æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚
* **å †å æ®‹å·®å•å…ƒ**
  ï¼šé€šè¿‡
  `Stack`
  ç±»å †å å¤šä¸ªæ®‹å·®å•å…ƒï¼Œæ„å»ºäº†ResNeXt-50æ¨¡å‹çš„æ ¸å¿ƒéƒ¨åˆ†ã€‚
* **ResNeXt-50æ¨¡å‹**
  ï¼šæ•´åˆäº†å·ç§¯å±‚ã€æ‰¹å½’ä¸€åŒ–å±‚ã€æ¿€æ´»å‡½æ•°å’Œæ®‹å·®å•å…ƒï¼Œæ„å»ºäº†å®Œæ•´çš„ResNeXt-50æ¨¡å‹ã€‚

### **3.Â æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°**

* **æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨**
  ï¼šä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°
  `nn.CrossEntropyLoss()`
  å’Œéšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨
  `torch.optim.SGD`
  ã€‚
* **è®­ç»ƒå¾ªç¯**
  ï¼šå®ç°äº†è®­ç»ƒå’Œæµ‹è¯•å¾ªç¯ï¼Œè®°å½•äº†æ¯ä¸ªepochçš„è®­ç»ƒå’Œæµ‹è¯•å‡†ç¡®ç‡åŠæŸå¤±ã€‚
* **ç»“æœå¯è§†åŒ–**
  ï¼šé€šè¿‡Matplotlibç»˜åˆ¶äº†è®­ç»ƒå’Œæµ‹è¯•çš„å‡†ç¡®ç‡åŠæŸå¤±æ›²çº¿ï¼Œç›´è§‚åœ°å±•ç¤ºäº†æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚

### 4. **æ¨¡å‹é¢„æµ‹**

* **å•å¼ å›¾ç‰‡é¢„æµ‹**
  ï¼šå®ç°äº†å•å¼ å›¾ç‰‡çš„é¢„æµ‹åŠŸèƒ½ï¼Œé€šè¿‡åŠ è½½å›¾ç‰‡å¹¶è¿›è¡Œé¢„å¤„ç†ï¼Œä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹å¹¶è¾“å‡ºç»“æœã€‚

### 5. **å­¦ä¹ æ”¶è·**

* **æ·±å…¥ç†è§£ResNeXt**
  ï¼šé€šè¿‡å®ç°ResNeXt-50æ¨¡å‹ï¼Œæ·±å…¥ç†è§£äº†åˆ†ç»„å·ç§¯å’ŒåŸºæ•°ï¼ˆcardinalityï¼‰çš„æ¦‚å¿µï¼Œä»¥åŠå®ƒä»¬åœ¨æå‡æ¨¡å‹è¡¨è¾¾èƒ½åŠ›ä¸­çš„ä½œç”¨ã€‚
* **PyTorchå®è·µ**
  ï¼šé€šè¿‡å®é™…ä»£ç ç¼–å†™ï¼Œç†Ÿæ‚‰äº†PyTorchçš„åŸºæœ¬æ“ä½œï¼ŒåŒ…æ‹¬æ¨¡å‹å®šä¹‰ã€æ•°æ®åŠ è½½ã€è®­ç»ƒå¾ªç¯å’Œç»“æœå¯è§†åŒ–ã€‚
* **é—®é¢˜è§£å†³èƒ½åŠ›**
  ï¼šåœ¨å®ç°è¿‡ç¨‹ä¸­é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œå¦‚GPUæ£€æŸ¥ã€æ•°æ®é¢„å¤„ç†å’Œæ¨¡å‹è°ƒè¯•ï¼Œé€šè¿‡æŸ¥é˜…æ–‡æ¡£å’Œè°ƒè¯•ä»£ç ï¼Œæå‡äº†é—®é¢˜è§£å†³èƒ½åŠ›ã€‚

### 6. **æ”¹è¿›æ–¹å‘**

* **æ¨¡å‹ä¼˜åŒ–**
  ï¼šå¯ä»¥å°è¯•è°ƒæ•´å­¦ä¹ ç‡ã€æ‰¹é‡å¤§å°ç­‰è¶…å‚æ•°ï¼Œæˆ–è€…ä½¿ç”¨æ›´å¤æ‚çš„ä¼˜åŒ–å™¨ï¼ˆå¦‚Adamï¼‰æ¥è¿›ä¸€æ­¥æå‡æ¨¡å‹æ€§èƒ½ã€‚
* **æ•°æ®å¢å¼º**
  ï¼šåœ¨æ•°æ®é¢„å¤„ç†é˜¶æ®µå¼•å…¥æ›´å¤šçš„æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œå¦‚éšæœºè£å‰ªã€æ—‹è½¬ç­‰ï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
* **æ¨¡å‹æ‰©å±•**
  ï¼šå¯ä»¥å°è¯•å®ç°å…¶ä»–ResNeXtå˜ä½“ï¼ˆå¦‚ResNeXt-101ï¼‰æˆ–å…¶ä»–å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚EfficientNetï¼‰ã€‚

## å¯¹æ¯”ï¼š

1. ResNeXt-50
  
æ ¸å¿ƒæ€æƒ³ï¼š
  
ResNeXt æ˜¯ ResNet çš„æ‰©å±•ç‰ˆæœ¬ï¼Œå¼•å…¥äº†åˆ†ç»„å·ç§¯ï¼ˆGrouped Convolutionï¼‰å’ŒåŸºæ•°ï¼ˆCardinalityï¼‰çš„æ¦‚å¿µã€‚
  
åŸºæ•°è¡¨ç¤ºåˆ†ç»„å·ç§¯çš„åˆ†æ”¯æ•°é‡ï¼Œé€šè¿‡å¢åŠ åŸºæ•°ï¼ˆå¦‚32ç»„ï¼‰æ¥æå‡æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒè®¡ç®—å¤æ‚åº¦ã€‚
  
ç»“æ„ç‰¹ç‚¹ï¼š
  
ä½¿ç”¨åˆ†ç»„å·ç§¯ä»£æ›¿ä¼ ç»Ÿçš„å·ç§¯æ“ä½œï¼Œå°†è¾“å…¥ç‰¹å¾å›¾åˆ†ä¸ºå¤šä¸ªç»„ï¼Œæ¯ç»„ç‹¬ç«‹è¿›è¡Œå·ç§¯ï¼Œæœ€ååˆå¹¶ç»“æœã€‚
  
æ®‹å·®è¿æ¥ä»ç„¶ä¿ç•™ï¼Œé¿å…äº†æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚

2. ResNet-50 V2
  
æ ¸å¿ƒæ€æƒ³ï¼š
  
ResNet-50 V2 æ˜¯ ResNet-50 çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œä¸»è¦ä¼˜åŒ–äº†æ®‹å·®å—çš„ç»“æ„ã€‚
  
åœ¨æ®‹å·®å—ä¸­ï¼Œå°†æ‰¹å½’ä¸€åŒ–ï¼ˆBatch Normalizationï¼‰å’Œæ¿€æ´»å‡½æ•°ï¼ˆReLUï¼‰çš„é¡ºåºè°ƒæ•´ä¸ºâ€œé¢„æ¿€æ´»â€ï¼ˆå³å…ˆè¿›è¡Œæ‰¹å½’ä¸€åŒ–å’Œæ¿€æ´»ï¼Œå†è¿›è¡Œå·ç§¯ï¼‰ã€‚
  
ç»“æ„ç‰¹ç‚¹ï¼š
  
ä½¿ç”¨â€œé¢„æ¿€æ´»â€æ®‹å·®å—ï¼Œä½¿å¾—æ¢¯åº¦æµåŠ¨æ›´åŠ é¡ºç•…ã€‚
  
ä¿ç•™äº† ResNet çš„åŸºæœ¬ç»“æ„ï¼ŒåŒ…æ‹¬æ®‹å·®è¿æ¥å’Œç“¶é¢ˆè®¾è®¡ï¼ˆ1x1-3x3-1x1å·ç§¯ï¼‰ã€‚
  
3. DenseNet
  
æ ¸å¿ƒæ€æƒ³ï¼š
  
DenseNet æå‡ºäº†å¯†é›†è¿æ¥ï¼ˆDense Connectionï¼‰\*\*çš„æ¦‚å¿µï¼Œå³æ¯ä¸€å±‚çš„è¾“å…¥æ¥è‡ªå‰é¢æ‰€æœ‰å±‚çš„è¾“å‡ºã€‚
  
é€šè¿‡å¯†é›†è¿æ¥ï¼Œå¢å¼ºäº†ç‰¹å¾å¤ç”¨ï¼Œå‡å°‘äº†å‚æ•°æ•°é‡ã€‚
  
ç»“æ„ç‰¹ç‚¹ï¼š
  
æ¯ä¸€å±‚çš„è¾“å‡ºä¼šä¸åç»­æ‰€æœ‰å±‚çš„è¾“å…¥è¿›è¡Œæ‹¼æ¥ï¼ˆconcatenationï¼‰ã€‚
  
ä½¿ç”¨è¿‡æ¸¡å±‚ï¼ˆTransition Layerï¼‰\*\*æ¥æ§åˆ¶ç‰¹å¾å›¾çš„å¤§å°å’Œé€šé“æ•°ã€‚