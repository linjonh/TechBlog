---
layout: post
title: "大数据hadoop课程笔记"
date: 2025-03-11 20:10:51 +0800
description: "柯洁Alpha Go是人工智能领域的里程碑。深度学习大模型deepseek chatgpt和之间有着非常紧密的关系。可以说，大数据是大模型发展的基石，而大模型是大数据价值挖掘的重要工具。"
keywords: "大数据hadoop课程笔记"
categories: ['未分类']
tags: ['笔记', '大数据', 'Hadoop']
artid: "146142258"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146142258
    alt: "大数据hadoop课程笔记"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146142258
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146142258
cover: https://bing.ee123.net/img/rand?artid=146142258
image: https://bing.ee123.net/img/rand?artid=146142258
img: https://bing.ee123.net/img/rand?artid=146142258
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     大数据hadoop课程笔记
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     1.课程导入
    </h2>
    <p>
     柯洁
    </p>
    <p>
     Alpha Go是人工智能领域的里程碑。
    </p>
    <p>
     深度学习
    </p>
    <p>
     <img alt="" height="724" src="https://i-blog.csdnimg.cn/direct/c6fe77218588452f9a10cd0c70af176b.png" width="1578"/>
    </p>
    <p>
     大模型deepseek chatgpt
    </p>
    <p>
     <strong>
      大模型
     </strong>
     和
     <strong>
      大数据
     </strong>
     之间有着非常紧密的关系。可以说，大数据是大模型发展的基石，而大模型是大数据价值挖掘的重要工具。
    </p>
    <p>
     <a href="https://youtu.be/nN-VacxHUH8?si=fj7LtkckVXm7soWR" rel="nofollow" title="https://youtu.be/nN-VacxHUH8?si=fj7LtkckVXm7soWR">
      https://youtu.be/nN-VacxHUH8?si=fj7LtkckVXm7soWR
     </a>
    </p>
    <p>
     <a href="https://www.bilibili.com/video/BV1UzNieDEFx/?spm_id_from=333.337.search-card.all.click" rel="nofollow" title="DeepSeek刚火就要垮掉了吗？史上最通俗的AI科普！15分钟搞懂国产Ai是如何实现弯道超車的！_哔哩哔哩_bilibili">
      DeepSeek刚火就要垮掉了吗？史上最通俗的AI科普！15分钟搞懂国产Ai是如何实现弯道超車的！_哔哩哔哩_bilibili
     </a>
    </p>
    <p>
     <img alt="" height="1047" src="https://i-blog.csdnimg.cn/direct/209e2884ac884a998f553286bfe73d3a.png" width="1694"/>
    </p>
    <p>
    </p>
    <h4>
     1.1.1大数据产生背景
    </h4>
    <ul>
     <li>
      <p>
       <strong>
        TB（太字节）
       </strong>
       ：常见于企业级数据存储，如数据库、数据仓库等。
      </p>
      <ul>
       <li>
        <p>
         示例：1 TB 可以存储大约 25 万张高清图片或 300 小时的视频。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        PB（拍字节）
       </strong>
       ：常见于大型互联网公司、科学研究机构或政府机构的数据中心。
      </p>
      <ul>
       <li>
        <p>
         示例：1 PB 可以存储大约 2 亿张高清图片或 3000 小时的 4K 视频。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        EB（艾字节）
       </strong>
       ：全球互联网流量、大型云服务提供商的数据规模。
      </p>
      <ul>
       <li>
        <p>
         示例：1 EB 可以存储大约 2000 亿张高清图片或 300 万小时的 4K 视频。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        ZB（泽字节）
       </strong>
       ：全球数据总量的规模（例如，2020 年全球数据总量约为 64 ZB）。
      </p>
     </li>
     <li>
      <p>
       <strong>
        YB（尧字节）
       </strong>
       ：未来的数据规模，目前尚未达到。
      </p>
     </li>
    </ul>
    <p>
     1.1.2
    </p>
    <p>
     大数据的定义
    </p>
    <p>
     volume:体积（大量化）：存储量大，增量大（TB,PB,EB）
    </p>
    <p>
     Variety:种类多。来源多，格式多。
    </p>
    <ul>
     <li>
      结构化数据
     </li>
     <li>
      非结构化数据
     </li>
     <li>
      半结构化数据
     </li>
    </ul>
    <p>
     Velocity:快速化
    </p>
    <p>
     value:价值密度低
    </p>
    <p>
    </p>
    <p>
     2003年，Google公司发表论文The Google File System,介绍GFS分布式文件系统，主要讲解海量数据胡可靠存储方法
    </p>
    <p>
     2004年，Google公司发表论文 MapReduce:Simplified Data Processing on Large Clusters,介绍并行计算模式MapReduce,海量数据的高效计算方法。
    </p>
    <p>
     2006年，Google发表国Bigtable:A distributed Storage System for Structured Data,介绍Google的大表Bigtable的设计。Bigtable是Google公司的分布式数据存储系统，是用来处理海量数据的一种非关系型数据库。
    </p>
    <p>
     GFS思想：
    </p>
    <p>
     数据节点：数据块
    </p>
    <p>
     管理节点：数据元文件（文件名，文件块，文件块所在数据节点）
    </p>
    <p>
     数据块保持：可靠性和可用性
    </p>
    <p>
    </p>
    <h2>
     2.hadoop实验环境搭建
    </h2>
    <h3 id="1%E5%8A%A0%E8%BD%BD%E9%95%9C%E5%83%8F">
     1.加载镜像
    </h3>
    <p>
     实验使用的Docker镜像保存在
     <code>
      /cg/images/hadoop_node.tar.gz
     </code>
     文件中，执行如下命令加载该镜像:
    </p>
    <pre><code>docker load &lt; /cg/images/hadoop_node.tar.gz</code></pre>
    <p>
     用来将一个 Docker 镜像从
     <code>
      .tar.gz
     </code>
     压缩包加载到本地的 Docker 环境中的。
    </p>
    <p>
     <img alt="" height="1216" src="https://i-blog.csdnimg.cn/direct/15b3bce32c5a40db90153c950a38be59.png" width="1800"/>
    </p>
    <p>
    </p>
    <h3 id="2%E5%90%AF%E5%8A%A8%E5%AE%9E%E9%AA%8C%E5%AE%B9%E5%99%A8">
     2.启动实验容器
    </h3>
    <p>
     执行如下4条命令，启动4个名称分别为master、slave1、slave2、slave3的docker容器用于实验：
    </p>
    <pre><code>docker run --name master --privileged --ulimit nofile=65535:65535 --hostname master --ip 172.17.0.2 --add-host=slave1:172.17.0.3  --add-host=slave2:172.17.0.4 --add-host=slave3:172.17.0.5 -itd -v /cgsrc:/cgsrc:ro -v /headless/course/:/course hadoop_node /service_start.sh

docker run --name slave1 --privileged --ulimit nofile=65535:65535 --hostname slave1 --ip 172.17.0.3 --add-host=master:172.17.0.2  --add-host=slave2:172.17.0.4 --add-host=slave3:172.17.0.5  -itd -v /cgsrc:/cgsrc:ro hadoop_node /service_start.sh

docker run --name slave2 --privileged --ulimit nofile=65535:65535 --hostname slave2 --ip 172.17.0.4 --add-host=master:172.17.0.2 --add-host=slave1:172.17.0.3  --add-host=slave3:172.17.0.5 -itd -v /cgsrc:/cgsrc:ro hadoop_node /service_start.sh

docker run --name slave3 --privileged --ulimit nofile=65535:65535 --hostname slave3 --ip 172.17.0.5 --add-host=master:172.17.0.2 --add-host=slave1:172.17.0.3  --add-host=slave2:172.17.0.4 -itd -v /cgsrc:/cgsrc:ro hadoop_node /service_start.sh</code></pre>
    <p>
     更新一下
    </p>
    <pre><code class="language-bash">docker run --name master --privileged --ulimit nofile=65535:65535 --hostname master --ip 172.18.0.2 --add-host=slave1:172.18.0.3 --add-host=slave2:172.18.0.4 --add-host=slave3:172.18.0.5 -itd -v /cgsrc:/cgsrc:ro -v /headless/course/:/course hadoop_node /service_start.sh 

docker run --name slave1 --privileged --ulimit nofile=65535:65535 --hostname slave1 --ip 172.18.0.3 --add-host=master:172.18.0.2 --add-host=slave2:172.18.0.4 --add-host=slave3:172.18.0.5 -itd -v /cgsrc:/cgsrc:ro hadoop_node /service_start.sh 

docker run --name slave2 --privileged --ulimit nofile=65535:65535 --hostname slave2 --ip 172.18.0.4 --add-host=master:172.18.0.2 --add-host=slave1:172.18.0.3 --add-host=slave3:172.18.0.5 -itd -v /cgsrc:/cgsrc:ro hadoop_node /service_start.sh 

docker run --name slave3 --privileged --ulimit nofile=65535:65535 --hostname slave3 --ip 172.18.0.5 --add-host=master:172.18.0.2 --add-host=slave1:172.18.0.3 --add-host=slave2:172.18.0.4 -itd -v /cgsrc:/cgsrc:ro hadoop_node /service_start.sh</code></pre>
    <p>
    </p>
    <p>
     这些
     <code>
      docker run
     </code>
     命令用于启动多个 Docker 容器，配置它们的主机名、IP 地址、主机映射、文件挂载等，并运行一个启动脚本
     <code>
      /service_start.sh
     </code>
     。这些容器似乎用于搭建一个 Hadoop 集群，其中包含一个
     <code>
      master
     </code>
     节点和三个
     <code>
      slave
     </code>
     节点。
    </p>
    <p>
     删除节点的命令为：
    </p>
    <pre><code class="language-bash">docker rm -f master slave1 slave2 slave3</code></pre>
    <h4>
     2.1.master节点
    </h4>
    <pre><code class="language-bash">docker run --name master --privileged --ulimit nofile=65535:65535 --hostname master --ip 172.17.0.2 --add-host=slave1:172.17.0.3  --add-host=slave2:172.17.0.4 --add-host=slave3:172.17.0.5 -itd -v /cgsrc:/cgsrc:ro -v /headless/course/:/course hadoop_node /service_start.sh</code></pre>
    <p>
     <img alt="" height="226" src="https://i-blog.csdnimg.cn/direct/af440f3ba9cc45389e31e6e9832b04c7.png" width="1512"/>
    </p>
    <ul>
     <li>
      <p>
       <code>
        --name master
       </code>
       ：将容器命名为
       <code>
        master
       </code>
       。
      </p>
     </li>
     <li>
      <p>
       <code>
        --privileged
       </code>
       ：赋予容器特权模式，允许它访问主机上的所有设备。
      </p>
     </li>
     <li>
      <p>
       <code>
        --ulimit nofile=65535:65535
       </code>
       ：设置文件描述符的软限制和硬限制为 65535。
      </p>
     </li>
     <li>
      <p>
       <code>
        --hostname master
       </code>
       ：设置容器的主机名为
       <code>
        master
       </code>
       。
      </p>
     </li>
     <li>
      <p>
       <code>
        --ip 172.17.0.2
       </code>
       ：为容器分配静态 IP 地址
       <code>
        172.17.0.2
       </code>
       。
      </p>
     </li>
     <li>
      <p>
       <code>
        --add-host=slave1:172.17.0.3
       </code>
       ：在容器的
       <code>
        /etc/hosts
       </code>
       文件中添加一条记录，将
       <code>
        slave1
       </code>
       映射到
       <code>
        172.17.0.3
       </code>
       。
      </p>
     </li>
     <li>
      <p>
       <code>
        --add-host=slave2:172.17.0.4
       </code>
       ：将
       <code>
        slave2
       </code>
       映射到
       <code>
        172.17.0.4
       </code>
       。
      </p>
     </li>
     <li>
      <p>
       <code>
        --add-host=slave3:172.17.0.5
       </code>
       ：将
       <code>
        slave3
       </code>
       映射到
       <code>
        172.17.0.5
       </code>
       。
      </p>
     </li>
     <li>
      <p>
       <code>
        -itd
       </code>
       ：以交互模式运行容器，并分配一个伪终端，同时在后台运行（
       <code>
        -d
       </code>
       ）。
      </p>
     </li>
     <li>
      <p>
       <code>
        -v /cgsrc:/cgsrc:ro
       </code>
       ：将主机上的
       <code>
        /cgsrc
       </code>
       目录挂载到容器的
       <code>
        /cgsrc
       </code>
       目录，并以只读模式（
       <code>
        ro
       </code>
       ）挂载。
      </p>
     </li>
     <li>
      <p>
       <code>
        -v /headless/course/:/course
       </code>
       ：将主机上的
       <code>
        /headless/course/
       </code>
       目录挂载到容器的
       <code>
        /course
       </code>
       目录。
      </p>
     </li>
     <li>
      <p>
       <code>
        hadoop_node
       </code>
       ：使用的 Docker 镜像名称。
      </p>
     </li>
     <li>
      <p>
       <code>
        /service_start.sh
       </code>
       ：容器启动后执行的脚
      </p>
     </li>
    </ul>
    <h4>
     2.2
     <code>
      slave1
     </code>
     节点
    </h4>
    <p>
     <img alt="" height="164" src="https://i-blog.csdnimg.cn/direct/decfe231925d41718f79a75cf6560ea8.png" width="1474"/>
    </p>
    <ul>
     <li>
      <p>
       <code>
        --name slave1
       </code>
       ：将容器命名为
       <code>
        slave1
       </code>
       。
      </p>
     </li>
     <li>
      <p>
       <code>
        --hostname slave1
       </code>
       ：设置容器的主机名为
       <code>
        slave1
       </code>
       。
      </p>
     </li>
     <li>
      <p>
       <code>
        --ip 172.17.0.3
       </code>
       ：为容器分配静态 IP 地址
       <code>
        172.17.0.3
       </code>
       。
      </p>
     </li>
     <li>
      <p>
       <code>
        --add-host=master:172.17.0.2
       </code>
       ：在容器的
       <code>
        /etc/hosts
       </code>
       文件中添加一条记录，将
       <code>
        master
       </code>
       映射到
       <code>
        172.17.0.2
       </code>
       。
      </p>
     </li>
     <li>
      <p>
       其他参数与
       <code>
        master
       </code>
       节点类似。
      </p>
     </li>
    </ul>
    <h4>
     2.3
     <code>
      slave2
     </code>
     节点
    </h4>
    <p>
     <img alt="" height="697" src="https://i-blog.csdnimg.cn/direct/124f155d86b64fbaa294659c2a2e726e.png" width="1503"/>
    </p>
    <h4>
     2.4.
     <code>
      slave3
     </code>
     节点
    </h4>
    <p>
     <img alt="" height="696" src="https://i-blog.csdnimg.cn/direct/849d62d7405c4499ad6d9c4ca11f0bac.png" width="1577"/>
    </p>
    <h4>
     2.5 查看
     <code>
      docker ps
     </code>
    </h4>
    <p>
     <code>
      docker ps
     </code>
     是一个 Docker 命令，用于列出当前正在运行的容器。它会显示容器的基本信息，例如容器 ID、镜像名称、启动命令、创建时间、状态、端口映射等。
    </p>
    <p>
     执行
    </p>
    <pre><code class="language-bash">docker ps</code></pre>
    <p>
     <img alt="" height="529" src="https://i-blog.csdnimg.cn/direct/63a5107a09b345a4988289a2545e899d.png" width="1599"/>
    </p>
    <p>
     解释：
    </p>
    <p>
     <img alt="" height="565" src="https://i-blog.csdnimg.cn/direct/12c5f21545d145eab437d596477ae8b2.png" width="823"/>
    </p>
    <p>
     <img alt="" height="784" src="https://i-blog.csdnimg.cn/direct/9a2b7a1140b54025945e2f6f7bb4e982.png" width="1549"/>
    </p>
    <p>
     <img alt="" height="382" src="https://i-blog.csdnimg.cn/direct/c2a2b73a98c0400484b9f0ec3f6a6f69.png" width="1513"/>
    </p>
    <h4>
     2.6 在终端使用如下命令进入容器中：
    </h4>
    <p>
     比如进入master容器可以使用命令:
    </p>
    <pre><code class="language-bash">docker exec -it --privileged master /bin/bash</code></pre>
    <p>
     <img alt="" height="151" src="https://i-blog.csdnimg.cn/direct/f3924d00c73c4ef2b5682132af2dac6e.png" width="1406"/>
    </p>
    <p>
    </p>
    <h3>
     3.java环境安装
    </h3>
    <p>
     在容器master中使用如下命令从资源文件夹
     <code>
      /cgsrc
     </code>
     中将JDK安装包复制到
     <code>
      /usr/local/java
     </code>
     目录下：
    </p>
    <pre><code class="language-bash">mkdir /usr/local/java
cp /cgsrc/jdk-8u171-linux-x64.tar.gz /usr/local/java/</code></pre>
    <p>
     我们接下来切换到
     <code>
      /usr/local/java
     </code>
     目录下，将安装包解压，并删除用过的tar文件。
    </p>
    <pre><code class="language-bash">cd /usr/local/java/
tar -zxvf jdk-8u171-linux-x64.tar.gz
rm -f jdk-8u171-linux-x64.tar.gz</code></pre>
    <p>
     此时
     <code>
      /usr/local/java
     </code>
     目录下仅有一个
     <code>
      jdk1.8.0_171
     </code>
     目录，这就是Java主目录。
    </p>
    <p>
     <img alt="" height="365" src="https://i-blog.csdnimg.cn/direct/3dc01c051a604a79aaf10c7304938328.png" width="1558"/>
    </p>
    <p>
     接下来需要配置
     <code>
      JAVA_HOME
     </code>
     环境变量，为了方便起见，这里直接在
     <code>
      ~/.bachrc
     </code>
     这个文件中进行设置，采用这种配置方式时，只对当前登录的单个用户生效，当该用户登录以及每次打开新的Shell时，它的环境变量文件
     <code>
      .bashrc
     </code>
     会被读取。输入下面命令打开当前登录用户的环境变量配置文件
     <code>
      .bashrc
     </code>
     ：
    </p>
    <pre><code class="language-bash">vim ~/.bashrc</code></pre>
    <p>
     在文件最后面添加如下3行（
     <strong>
      注意等号前后不能有空格
     </strong>
     ），然后保存退出vim：
    </p>
    <pre><code class="language-bash">export JAVA_HOME=/usr/local/java/jdk1.8.0_171
export CLASSPATH=.:${JAVA_HOME}/jre/lib/rt.jar:${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar
export PATH=$PATH:${JAVA_HOME}/bin</code></pre>
    <p>
     <img alt="" height="935" src="https://i-blog.csdnimg.cn/direct/7f8e4522a658418689c18a947bd563cc.png" width="1547"/>
    </p>
    <p>
     接下来让环境变量生效，执行如下代码：
    </p>
    <pre><code class="language-bash">source ~/.bashrc</code></pre>
    <pre><code class="language-bash">scp -r root@master:/usr/local/java root@slave1:/usr/local/java</code></pre>
    <h3>
     4.ssh无密码登陆
    </h3>
    <p>
     需要让master节点可以SSH⽆密码登录到各个slave节点上。
    </p>
    <p>
     ⾸先，⽣成master节点的公钥，如果之前已经⽣成过公钥，必须删除原来的公钥，重新⽣成⼀次。具体命令如下：
    </p>
    <pre><code class="language-bash">cd ~/.ssh            #如果没有该目录，先执行一次 ssh localhost，密码默认为83953588abc
rm -f ./id_rsa*        #删除之前生成的公钥
ssh-keygen -t rsa    #执行该命令后，遇到提示信息，均按Enter即可</code></pre>
    <p>
     下面这个命令是用于将一个公钥文件（
     <code>
      id_rsa.pub
     </code>
     ）的内容追加到另一个文件（
     <code>
      authorized_keys
     </code>
     ）中。具体来说，它的作用是将 SSH 公钥添加到授权密钥文件中，从而允许使用对应的私钥进行无密码登录。
    </p>
    <p>
     为了让master节点能⽆密码SSH登录到本机，需要在master节点上执⾏如下命令：
    </p>
    <pre><code class="language-bash">cat ./id_rsa.pub &gt;&gt; ./authorized_keys</code></pre>
    <p>
    </p>
    <h4>
     5.配置集群环境
    </h4>
    <pre><code class="language-bash">vim workers</code></pre>
    <p>
     <img alt="" height="599" src="https://i-blog.csdnimg.cn/direct/8fb22ca1e7af4aa99b69f58c9537e8f0.png" width="1622"/>
    </p>
    <p>
     <img alt="" height="1060" src="https://i-blog.csdnimg.cn/direct/901b2b8a72324a86bd8082d81bbe5803.png" width="1629"/>
    </p>
    <p>
    </p>
    <p>
    </p>
    <h3>
     7.测试：
    </h3>
    <p>
     随便在那个文件夹中，进行如下操作
    </p>
    <p>
     <img alt="" height="239" src="https://i-blog.csdnimg.cn/direct/a1222c7042984c1fa5bd0930286f5298.png" width="1137"/>
    </p>
    <p>
     /input的路径在这个文件夹的完整路径是：
     <code>
      hdfs://&lt;namenode-host&gt;:&lt;port&gt;/input
     </code>
     。
    </p>
    <ul>
     <li>
      <p>
       <code>
        &lt;namenode-host&gt;
       </code>
       是 NameNode 的主机名或 IP 地址。
      </p>
     </li>
     <li>
      <p>
       <code>
        &lt;port&gt;
       </code>
       是 HDFS 的端口号（默认是 9820）。
      </p>
     </li>
    </ul>
    <p>
     <img alt="" height="467" src="https://i-blog.csdnimg.cn/direct/f4c2048e223146c8aca7e32ef06af68f.png" width="1486"/>
    </p>
    <pre><code class="language-bash">cd share/hadoop/mapreduce/</code></pre>
    <pre><code class="language-bash">hadoop jar hadoop-mapreduce-examples-3.4.0.jar wordcount /input/data.txt /output</code></pre>
    <p>
     <img alt="" height="558" src="https://i-blog.csdnimg.cn/direct/496a0080d0bd4612bbe9a1819352c2eb.png" width="1596"/>
    </p>
    <p>
     <img alt="" height="934" src="https://i-blog.csdnimg.cn/direct/e8f64b6b77b044afae7227273ae9151b.png" width="1511"/>
    </p>
    <pre><code class="language-bash">hdfs dfs -cat /output/part-r-00000</code></pre>
    <p>
     问题：
    </p>
    <p>
     <img alt="" height="1088" src="https://i-blog.csdnimg.cn/direct/a378bf7953694e9e9e40022e0158a316.png" width="1680"/>
    </p>
    <p>
    </p>
    <p>
     更改mapred-site.xml文件
    </p>
    <pre><code class="language-bash">&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;


&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
		&lt;value&gt;yarn&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
		&lt;value&gt;master:10020&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
		&lt;value&gt;master:19888&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
	  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;
	  &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
	  &lt;name&gt;mapreduce.map.env&lt;/name&gt;
	  &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
	  &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;
	  &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
    <p>
     在原本的文档上增加了这些
    </p>
    <pre><code class="language-bash">&lt;property&gt;
  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;
  &lt;value&gt;HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.map.env&lt;/name&gt;
  &lt;value&gt;HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;
  &lt;value&gt;HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}&lt;/value&gt;
&lt;/property&gt;</code></pre>
    <p>
     <img alt="" height="663" src="https://i-blog.csdnimg.cn/direct/08c7bd53f67b472eb036bd0f8977efea.png" width="1655"/>
    </p>
    <pre><code class="language-bash">export JAVA_HOME=/usr/local/java/jdk1.8.0_171
export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop


export HADOOP_CLASSPATH=/usr/local/hadoop/share/hadoop/mapreduce/*:/usr/local/hadoop/share/hadoop/mapreduce/lib/*:${HADOOP_CLASSPATH}
</code></pre>
    <h2>
     第三周
    </h2>
    <p>
     1.
    </p>
    <pre><code class="language-bash">scp -r root@master:/usr/local/java root@slave1:/usr/local/java</code></pre>
    <p>
     scp克隆
    </p>
    <p>
     root@master:/usr/local/java：原本要被复制的文件
    </p>
    <p>
     root@slave1:/usr/local/java：粘贴的地方
    </p>
    <p>
    </p>
    <p>
     2.ssh无密码登录
    </p>
    <p>
     <img alt="" height="152" src="https://i-blog.csdnimg.cn/direct/b7d896b8d13b4aca9e05e565f519c55a.png" width="562"/>
    </p>
    <p>
     生成密钥对
    </p>
    <pre><code class="language-bash">ssh-keygen -t rsa </code></pre>
    <p>
     cat拼接，./id_rsa.pub  添加到./authorized_keys里面
    </p>
    <pre><code class="language-bash">cat ./id_rsa.pub &gt;&gt; ./authorized_keys</code></pre>
    <p>
     ssh文件下
    </p>
    <p>
     <img alt="" height="353" src="https://i-blog.csdnimg.cn/direct/99b8a0626af94604a966c5c4882bd360.png" width="565"/>
    </p>
    <table border="1" cellpadding="1" cellspacing="1">
     <tbody>
      <tr>
       <td>
        known_hosts
       </td>
       <td>
        记录ssh访问过计算机的公钥
       </td>
      </tr>
      <tr>
       <td>
        id_rsa
       </td>
       <td>
        生成的私钥
       </td>
      </tr>
      <tr>
       <td>
        id_rsa.pub
       </td>
       <td>
        生成的公钥
       </td>
      </tr>
      <tr>
       <td>
        authorized_keys
       </td>
       <td>
        存放授权过的无密码登录服务器公钥
       </td>
      </tr>
     </tbody>
    </table>
    <p>
    </p>
    <p>
    </p>
    <h3>
     hadoop安装
    </h3>
    <pre><code>cp /cgsrc/hadoop-3.4.0.tar.gz /usr/local/</code></pre>
    <p>
    </p>
    <p>
     1.bin: 存放操作命令，具体包含如下图(hdfs,mapred,yarn)
    </p>
    <p>
     2.etc:所有配置文件
    </p>
    <p>
     3.include:头文件
    </p>
    <p>
     4.lib：本地库（native库）压缩的动态链接库
    </p>
    <p>
     5.libexec：拓展库
    </p>
    <p>
     6.sbin:集群相关的命令
    </p>
    <p>
     7.share：学习的资料，文档
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c:6f672e6373646e2e6e65742f68656c6c6f6c69616e6875612f:61727469636c652f64657461696c732f313436313432323538" class_="artid" style="display:none">
 </p>
</div>


