---
layout: post
title: "Python-爬虫爬虫-网页抓取数据-工具curl"
date: 2025-03-12 14:29:44 +0800
description: "User-Agent : 有些服务器或 Proxy 会通过该值来判断是否是浏览器发出的请求Content-Type : 在使用 REST 接口时，服务器会检查该值，用来确定 HTTP Body 中的内容该怎样解析。application/xml ： 在 XML RPC，如 RESTful/SOAP 调用时使用application/json ： 在 JSON RPC 调用时使用application/x-www-form-urlencoded ： 浏览器提交 Web 表单时使用。"
keywords: "Python - 爬虫；爬虫-网页抓取数据-工具curl"
categories: ['Python']
tags: ['爬虫', 'Python', 'Curl']
artid: "145475985"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145475985
    alt: "Python-爬虫爬虫-网页抓取数据-工具curl"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145475985
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145475985
cover: https://bing.ee123.net/img/rand?artid=145475985
image: https://bing.ee123.net/img/rand?artid=145475985
img: https://bing.ee123.net/img/rand?artid=145475985
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Python - 爬虫；爬虫-网页抓取数据-工具curl
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     一、爬虫
    </h2>
    <p>
     关于爬虫的合法性
    </p>
    <h4>
     通用爬虫限制：
     <a href="https://zhida.zhihu.com/search?content_id=4285169&amp;content_type=Article&amp;match_order=1&amp;q=Robots%E5%8D%8F%E8%AE%AE&amp;zhida_source=entity" rel="nofollow" title="Robots协议">
      Robots协议
     </a>
     【约定协议robots.txt】
    </h4>
    <ul>
     <li>
      robots协议：协议指明通用爬虫可以爬取网页的权限
     </li>
     <li>
      robots协议是一种约定，一般是大型公司的程序或者搜索引擎等遵守
     </li>
    </ul>
    <p>
     几乎每一个网站都有一个名为
     <span style="color:#fe2c24">
      <strong>
       robots.txt
      </strong>
     </span>
     的文档，当然也有部分网站没有设定 robots.txt。对于没有设定 robots.txt 的网站可以通过网络爬虫获取没有口令加密的数据，也就是该网站所有页面数据都可以爬取。如果网站有 robots.txt 文档，就要判断是否有禁止访客获取的数据。
    </p>
    <h4>
     注意事项！！！
    </h4>
    <ul>
     <li>
      进行爬虫时，需要遵守目标网站的robots.txt文件的规定，避免过度爬取或违反网站的使用条款。
     </li>
     <li>
      爬虫行为可能会给目标网站带来额外的负担，因此在进行大规模爬虫操作时，需要谨慎处理。
     </li>
     <li>
      如果涉及金融、医疗、法律等存在风险的领域，请在操作前咨询专业人士，并注意遵守相关法律法规。
     </li>
    </ul>
    <p>
     网络爬虫（又被称为网页蜘蛛，网络机器人）就是模拟浏览器发送网络请求，接收请求响应，一种按照一定的规则，自动地抓取互联网信息的程序。
    </p>
    <p>
     爬虫是一个自动化程序，它能够自动地从互联网上抓取数据。使用Python编写爬虫程序时，通常会用到以下库：
    </p>
    <p>
     requests：用于发送HTTP请求，获取网页内容。
    </p>
    <p>
     BeautifulSoup 或 lxml：用于解析HTML或XML文档，提取所需数据。
    </p>
    <p>
     Scrapy：一个强大的爬虫框架，适合构建大型爬虫项目。
    </p>
    <h4>
     HTTP &amp; HTTPS
    </h4>
    <ul>
     <li>
      HTTP：超文本传输协议：Hyper Text Transfer Protocal
     </li>
     <li>
      HTTPS： Secure Hypertext Transfer Protocol 安全的超文本传输协议
     </li>
    </ul>
    <h4>
     1、headers的属性介绍
    </h4>
    <blockquote>
     User-Agent : 有些服务器或 Proxy 会通过该值来判断是否是浏览器发出的请求
     <br/>
     Content-Type : 在使用 REST 接口时，服务器会检查该值，用来确定 HTTP Body 中的内容该怎样解析。
     <br/>
     application/xml ： 在 XML RPC，如 RESTful/SOAP 调用时使用
     <br/>
     application/json ： 在 JSON RPC 调用时使用
     <br/>
     application/x-www-form-urlencoded ： 浏览器提交 Web 表单时使用
     <br/>
     在使用服务器提供的 RESTful 或 SOAP 服务时， Content-Type 设置错误会导致服务器拒绝服务
    </blockquote>
    <p>
     注意：使用正则匹配替换^(.*):(.*)$ --&gt; "\1":"\2",
    </p>
    <ul>
     <li>
      <strong>
       随机添加/修改User-Agent
      </strong>
     </li>
    </ul>
    <blockquote>
     可以通过调用Request.add_header() 添加/修改一个特定的header 也可以通过调用Request.get_header()来查看已有的header。
    </blockquote>
    <pre><code class="language-python">ua = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'
# 添加自定义的头信息
req = urllib.request.Request('http://httpbin.org/user-agent')
req.add_header('User-Agent', ua)
# 接受一个urllib.request.Request对象
r = urllib.request.urlopen(req)
resp = json.loads(r.read())
# 打印httpbin网站返回信息里的user-agent
print('网站返回的user-agent：', resp["user-agent"]) # 网站返回的user-agent： Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3
</code></pre>
    <h4>
     2、Referer (页面跳转处)
    </h4>
    <p>
     Referer：表明产生请求的网页来自于哪个URL，用户是从该 Referer页面访问到当前请求的页面。这个属性可以用来跟踪Web请求来自哪个页面，是从什么网站来的等。
    </p>
    <p>
     有时候遇到下载某网站图片，需要对应的referer，否则无法下载图片，那是因为人家做了防盗链，原理就是根据referer去判断是否是本网站的地址，如果不是，则拒绝，如果是，就可以下载；
    </p>
    <h4>
     3、Accept-Encoding（文件编解码格式）
    </h4>
    <p>
     <strong>
      Accept-Encoding：
     </strong>
     指出浏览器可以接受的编码方式。编码方式不同于文件格式，它是为了压缩文件并加速文件传递速度。浏览器在接收到Web响应之后先解码，然后再检查文件格式，许多情形下这可以减少大量的下载时间。
    </p>
    <p>
     <strong>
      举例：Accept-Encoding:gzip;q=1.0, identity; q=0.5, ;q=0
     </strong>
    </p>
    <p>
     如果有多个Encoding同时匹配, 按照q值顺序排列，本例中按顺序支持 gzip, identity压缩编码，支持gzip的浏览器会返回经过gzip编码的HTML页面。 如果请求消息中没有设置这个域服务器假定客户端对各种内容编码都可以接受。
    </p>
    <h4>
     4、Accept-Language（语言种类）
    </h4>
    <p>
     Accept-Langeuage：指出浏览器可以接受的语言种类，如en或en-us指英语，zh或者zh-cn指中文，当服务器能够提供一种以上的语言版本时要用到。
    </p>
    <h4>
     5.、Accept-Charset（字符编码）
    </h4>
    <p>
     Accept-Charset：指出浏览器可以接受的字符编码。
    </p>
    <p>
     <strong>
      举例：Accept-Charset:iso-8859-1,gb2312,utf-8
     </strong>
    </p>
    <ul>
     <li>
      ISO8859-1：通常叫做Latin-1。Latin-1包括了书写所有西方欧洲语言不可缺少的附加字符，英文浏览器的默认值是ISO-8859-1.
     </li>
     <li>
      gb2312：标准简体中文字符集;
     </li>
     <li>
      utf-8：UNICODE 的一种变长字符编码，可以解决多种语言文本显示问题，从而实现应用国际化和本地化。
      <br/>
      如果在请求消息中没有设置这个域，缺省是任何字符集都可以接受。
     </li>
    </ul>
    <h4>
     6.、Cookie （Cookie）
    </h4>
    <p>
     Cookie：浏览器用这个属性向服务器发送Cookie。Cookie是在浏览器中寄存的小型数据体，它可以记载和服务器相关的用户信息，也可以用来实现会话功能，以后会详细讲。
    </p>
    <h4>
     7.、Content-Type (POST数据类型)
    </h4>
    <p>
     Content-Type：POST请求里用来表示的内容类型。
    </p>
    <p>
     <strong>
      举例：Content-Type = Text/XML; charset=gb2312：
     </strong>
    </p>
    <p>
     指明该请求的消息体中包含的是纯文本的XML类型的数据，字符编码采用“gb2312”。
    </p>
    <h4>
     8、服务端HTTP响应
    </h4>
    <p>
     HTTP响应也由四个部分组成，分别是： 状态行、消息报头、空行、响应正文
    </p>
    <p>
     <img alt="" height="545" src="https://i-blog.csdnimg.cn/direct/ebff377a0d7f40e0bc174e722430ce25.png" width="1017"/>
    </p>
    <p>
    </p>
    <h3>
     常用的响应报头(了解)
    </h3>
    <p>
     理论上所有的响应头信息都应该是回应请求头的。但是服务端为了效率，安全，还有其他方面的考虑，会添加相对应的响应头信息，从上图可以看到：
    </p>
    <h4>
     <strong>
      1、Cache-Control：must-revalidate, no-cache, private
     </strong>
    </h4>
    <p>
     这个值告诉客户端，服务端不希望客户端缓存资源，在下次请求资源时，必须要从新请求服务器，不能从缓存副本中获取资源。
    </p>
    <ul>
     <li>
      Cache-Control是响应头中很重要的信息，当客户端请求头中包含Cache-Control:max-age=0请求，明确表示不会缓存服务器资源时,Cache-Control作为作为回应信息，通常会返回no-cache，意思就是说，"那就不缓存呗"。
     </li>
     <li>
      当客户端在请求头中没有包含Cache-Control时，服务端往往会定,不同的资源不同的缓存策略，比如说oschina在缓存图片资源的策略就是Cache-Control：max-age=86400,这个意思是，从当前时间开始，在86400秒的时间内，客户端可以直接从缓存副本中读取资源，而不需要向服务器请求。
     </li>
    </ul>
    <h4>
     2、Connection：keep-alive
    </h4>
    <p>
     这个字段作为回应客户端的Connection：keep-alive，告诉客户端服务器的tcp连接也是一个长连接，客户端可以继续使用这个tcp连接发送http请求。
    </p>
    <h4>
     3、Content-Encoding:gzip
    </h4>
    <p>
     告诉客户端，服务端发送的资源是采用gzip编码的，客户端看到这个信息后，应该采用gzip对资源进行解码。
    </p>
    <h4>
     4、Content-Type：text/html;charset=UTF-8
    </h4>
    <p>
     告诉客户端，资源文件的类型，还有字符编码，客户端通过utf-8对资源进行解码，然后对资源进行html解析。通常我们会看到有些网站是乱码的，往往就是服务器端没有返回正确的编码。
    </p>
    <h4>
     5、Date：Sun, 1 Jan 2000 01:00:00 GMT
    </h4>
    <p>
     这个是服务端发送资源时的服务器时间，GMT是格林尼治所在地的标准时间。http协议中发送的时间都是GMT的，这主要是解决在互联网上，不同时区在相互请求资源的时候，时间混乱问题。
    </p>
    <h4>
     6、Expires:Sun, 1 Jan 2000 01:00:00 GMT
    </h4>
    <p>
     这个响应头也是跟缓存有关的，告诉客户端在这个时间前，可以直接访问缓存副本，很显然这个值会存在问题，因为客户端和服务器的时间不一定会都是相同的，如果时间不同就会导致问题。所以这个响应头是没有Cache-Control：max-age=*这个响应头准确的，因为max-age=date中的date是个相对时间，不仅更好理解，也更准确。
    </p>
    <h4>
     7、Pragma:no-cache
    </h4>
    <p>
     这个含义与Cache-Control等同。
    </p>
    <h4>
     8、Server：Tengine/1.4.6
    </h4>
    <p>
     这个是服务器和相对应的版本，只是告诉客户端服务器的信息。
    </p>
    <h4>
     9、Transfer-Encoding：chunked
    </h4>
    <p>
     这个响应头告诉客户端，服务器发送的资源的方式是分块发送的。一般分块发送的资源都是服务器动态生成的，在发送时还不知道发送资源的大小，所以采用分块发送，每一块都是独立的，独立的块都能标示自己的长度，最后一块是0长度的，当客户端读到这个0长度的块时，就可以确定资源已经传输完了。
    </p>
    <h4>
     10、Vary: Accept-Encoding
    </h4>
    <p>
     告诉缓存服务器，缓存压缩文件和非压缩文件两个版本，现在这个字段用处并不大，因为现在的浏览器都是支持压缩的。
    </p>
    <p>
     响应状态码
    </p>
    <p>
     响应状态代码有三位数字组成，第一个数字定义了响应的类别，且有五种可能取值。
    </p>
    <p>
     <strong>
      常见状态码：
     </strong>
    </p>
    <ul>
     <li>
      100~199：表示服务器成功接收部分请求，要求客户端继续提交其余请求才能完成整个处理过程。
     </li>
     <li>
      200~299：表示服务器成功接收请求并已完成整个处理过程。常用200（OK 请求成功）。
     </li>
     <li>
      300~399：为完成请求，客户需进一步细化请求。例如：请求的资源已经移动一个新地址、常用302（所请求的页面已经临时转移至新的url）、307和304（使用缓存资源）。
     </li>
     <li>
      400~499：客户端的请求有错误，常用404（服务器无法找到被请求的页面）、403（服务器拒绝访问，权限不够）。
     </li>
     <li>
      500~599：服务器端出现错误，常用500（请求未完成。服务器遇到不可预知的情况）。
     </li>
    </ul>
    <h3>
     Cookie 和 Session：
    </h3>
    <p>
     服务器和客户端的交互仅限于请求/响应过程，结束之后便断开，在下一次请求时，服务器会认为新的客户端。
    </p>
    <p>
     为了维护他们之间的链接，让服务器知道这是前一个用户发送的请求，必须在一个地方保存客户端的信息。
    </p>
    <p>
     Cookie：通过在 客户端 记录的信息确定用户的身份。
    </p>
    <p>
     Session：通过在 服务器端 记录的信息确定用户的身份。
    </p>
    <h2>
     二、curl
    </h2>
    <p>
     <strong>
      curl是一个在命令行下工作的文件传输工具，常用于网络爬虫
     </strong>
     ‌。以下是关于curl爬虫的一些详细信息和使用方法：
    </p>
    <h4>
     curl简介
    </h4>
    <ul>
     <li>
      <span style="color:#fe2c24">
       <strong>
        curl
       </strong>
      </span>
      <span style="color:#0d0016">
       <strong>
        全称
       </strong>
      </span>
      <span style="color:#fe2c24">
       <strong>
        Command Line URL viewer
       </strong>
      </span>
      ，是一个在命令行下工作的文件传输工具。它支持文件的上传和下载，可以发送各种http请求给网站，然后抓取网站上内容。
     </li>
     <li>
      curl支持多种协议，包括HTTP、HTTPS、FTP、TELNET等。
     </li>
     <li>
      curl支持代理、用户认证、FTP上传、HTTP POST请求、SSL连接、cookies、文件传输、Metalink等功能。
     </li>
    </ul>
    <h4>
     curl在爬虫中的应用
    </h4>
    <ul>
     <li>
      curl可以用于获取网页的源代码。例如，通过命令行窗口使用curl访问新浪财经（curl http://finance.sina.com.cn/），可以获取新浪财经首页的网页源代码。
     </li>
     <li>
      curl支持多种参数来定制请求。例如，使用-o参数可以将网页源代码下载并保存到文件中。
     </li>
     <li>
      curl还支持自动跳转（-L参数）、显示http response的头信息（-i参数）、只显示http response的头信息（-I参数）等功能。
     </li>
    </ul>
    <h4>
     curl的高级用法
    </h4>
    <ul>
     <li>
      curl可以用于发送POST请求。例如，使用-X POST --data "data=xxx" www.cnblogs.com/form.cgi可以发送包含数据的POST请求。
     </li>
     <li>
      curl还可以用于处理cookies、设置请求头、处理HTTP认证等高级功能。
     </li>
    </ul>
    <h4>
     curl在PHP中的应用
    </h4>
    <ul>
     <li>
      在PHP中，curl库是自带的，无需额外安装。但为了避免使用时出现错误，建议检查cURL版本是否已经安装和集成。
     </li>
     <li>
      使用PHP的curl库，可以方便地进行Web数据的抓取、FTP上传文件、HTTP POST和PUT数据等操作。
     </li>
     <li>
      在PHP中，通过curl_setopt()函数可以设置各种请求选项，如URL、是否返回响应内容、请求头等。
     </li>
     <li>
      使用curl_exec()方法可以执行HTTP请求，获取响应内容。最后，使用curl_close()函数关闭cURL会话。
     </li>
    </ul>
    <h3>
     （一）Windows安装curl
    </h3>
    <p>
     在Windows系统中，通常有两种方式可以安装和使用
     <code>
      curl
     </code>
     命令：
    </p>
    <h4>
     方法1：使用Chocolatey
    </h4>
    <p>
     <a href="https://chocolatey.org/" rel="nofollow" title="Chocolatey">
      Chocolatey
     </a>
     是一个Windows下的包管理器，类似于Linux中的apt或yum。通过Chocolatey安装
     <code>
      curl
     </code>
     非常简单。
    </p>
    <ol>
     <li>
      <p>
       <strong>
        安装Chocolatey
       </strong>
       （如果你还没有安装的话）：
      </p>
      <p>
       打开命令提示符（cmd）并执行以下命令：
      </p>
      <pre><code class="language-bash">@"%SystemRoot%\System32\WindowsPowerShell\v1.0\powershell.exe" -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command "iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))" &amp;&amp; SET "PATH=%PATH%;%ALLUSERSPROFILE%\chocolatey\bin"</code></pre>
     </li>
     <li>
      <p>
       <strong>
        安装curl
       </strong>
       ：在命令提示符（cmd）中，执行以下命令：
      </p>
      <pre><code class="language-python">choco install curl</code></pre>
      <p>
      </p>
     </li>
    </ol>
    <h4>
     方法2：手动下载并安装
    </h4>
    <p>
     如果你不想使用Chocolatey，你也可以手动下载
     <code>
      curl
     </code>
     的可执行文件。
    </p>
    <ol>
     <li>
      <p>
       <strong>
        下载curl
       </strong>
       ：访问
       <a href="https://curl.se/download.html" rel="nofollow" title="curl官方网站">
        curl官方网站
       </a>
       或
       <a href="https://github.com/curl/curl-for-win" title="GitHub的curl项目页面">
        GitHub的curl项目页面
       </a>
       ，下载适合你的Windows版本的
       <code>
        curl
       </code>
       。
      </p>
     </li>
     <li>
      <p>
       <strong>
        解压和放置到系统路径
       </strong>
       ：
      </p>
      <p>
       下载后，通常你会得到一个压缩文件（如
       <code>
        .zip
       </code>
       ）。解压这个文件，并将解压后的文件夹路径添加到系统的环境变量
       <code>
        PATH
       </code>
       中。
      </p>
      <ul>
       <li>
        <p>
         右键点击“此电脑”或“我的电脑”，选择“属性”。
        </p>
       </li>
       <li>
        <p>
         点击“高级系统设置”。
        </p>
       </li>
       <li>
        <p>
         在“系统属性”窗口中，点击“环境变量”。
        </p>
       </li>
       <li>
        <p>
         在“系统变量”区域找到
         <code>
          Path
         </code>
         变量，选择它然后点击“编辑”。
        </p>
       </li>
       <li>
        <p>
         点击“新建”，然后添加你的
         <code>
          curl
         </code>
         解压目录的路径（例如
         <code>
          C:\Program Files\curl
         </code>
         ）。
        </p>
       </li>
       <li>
        <p>
         点击“确定”保存更改。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        验证安装
       </strong>
       ：
      </p>
      <p>
       打开一个新的命令提示符窗口，输入
       <code>
        curl --version
       </code>
       来检查是否正确安装了curl。如果显示版本信息，那么安装成功。
      </p>
      <pre><code class="language-python">curl --version</code></pre>
     </li>
    </ol>
    <p>
     如果在Windows中遇到如下错误
    </p>
    <pre><code class="language-python">curl --version curl : 未能解析此远程名称: '--version' 所在位置 行:1 字符: 1
curl --version
  + CategoryInfo          : InvalidOperation: (System.Net.HttpWebRequest:HttpWebRequest) [Invok
 e-WebRequest]，WebException
  + FullyQualifiedErrorId : WebCmdletWebResponseException,Microsoft.PowerShell.Commands.InvokeW
 ebRequestCommand</code></pre>
    <p>
     是因为你在 PowerShell 中使用了 curl 命令，并且 PowerShell 将 curl 解释为 Invoke-WebRequest 而不是调用实际的 curl 工具。
    </p>
    <p>
     以下是解决方案：
    </p>
    <p>
     如果你想使用 Windows 自带的类似 curl 的功能，你可以使用 Invoke-WebRequest -Uri &lt;url&gt; 或者简写为 iwr -Uri &lt;url&gt;。
    </p>
    <p>
     如果你确实想使用 GNU 或 Linux 版本的 curl 工具，请确保它已正确安装并且在系统的 PATH 环境变量中。然后尝试再次运行 curl --version。
    </p>
    <p>
     如果你需要检查是否安装了 curl 及其版本信息，在 PowerShell 中可以尝试以下命令来避免混淆：
    </p>
    <pre><code class="language-python"># 使用 cmd.exe 来运行 curl 命令
cmd /c "curl --version"</code></pre>
    <h4>
     方法3：使用Git Bash（如果你安装了Git）
    </h4>
    <p>
     如果你已经安装了Git for Windows，Git Bash自带了
     <code>
      curl
     </code>
     。你可以通过Git Bash来使用
     <code>
      curl
     </code>
     ，而不需要单独安装。
    </p>
    <ol>
     <li>
      <p>
       打开Git Bash。
      </p>
     </li>
     <li>
      <p>
       输入
       <code>
        curl --version
       </code>
       来检查是否已经包含在Git Bash中。
      </p>
     </li>
    </ol>
    <h3>
     （二）网站字段详解
    </h3>
    <p>
     <strong>
      一、查看网页源码
     </strong>
    </p>
    <p>
     直接在curl命令后加上网址，就可以看到网页源码。我们以网址www.sina.com为例（选择该网址，主要因为它的网页代码较短）：
    </p>
    <pre><code>$ curl https://www.baidu.com</code></pre>
    <pre><code class="language-bash">StatusCode        : 200
StatusDescription : OK
Content           : &lt;html&gt;
                    &lt;head&gt;
                        &lt;script&gt;
                                location.replace(location.href.replace("https://","http://"));
                        &lt;/script&gt;
                    &lt;/head&gt;
                    &lt;body&gt;
                        &lt;noscript&gt;&lt;meta http-equiv="refresh" content="0;url=http://www.b
                    aidu.com/"&gt;&lt;/...
RawContent        : HTTP/1.1 200 OK
                    Connection: keep-alive
                    Content-Security-Policy: frame-ancestors 'self' https://chat.baid
                    u.com http://mirror-chat.baidu.com https://fj-chat.baidu.com http
                    s://hba-chat.baidu.com https:...
Forms             : {}
Headers           : {[Connection, keep-alive], [Content-Security-Policy, frame-ancest
                    ors 'self' https://chat.baidu.com http://mirror-chat.baidu.com ht
                    tps://fj-chat.baidu.com https://hba-chat.baidu.com https://hbe-ch
                    at.baidu.com https://njjs-chat.baidu.com https://nj-chat.baidu.co
                    m https://hna-chat.baidu.com https://hnb-chat.baidu.com http://de
                    bug.baidu-int.com;], [Accept-Ranges, bytes], [Content-Length, 227
                    ]...}
Images            : {}
InputFields       : {}
Links             : {}
ParsedHtml        : mshtml.HTMLDocumentClass
RawContentLength  : 227</code></pre>
    <p>
     如果要把这个网页保存下来，可以使用`-o`参数，这就相当于使用wget命令了。
    </p>
    <pre><code class="language-bash">$ curl -o [文件名] www.baidu.com</code></pre>
    <p>
     <strong>
      二、自动跳转：
     </strong>
     `-L`参数
    </p>
    <p>
     有的网址是自动跳转的。使用`-L`参数，curl就会跳转到新的网址。
    </p>
    <pre><code class="language-bash">$ curl -L www.baidu.com</code></pre>
    <pre><code class="language-bash">StatusCode        : 200
StatusDescription : OK
Content           : &lt;html&gt;
                    &lt;head&gt;
                        &lt;script&gt;
                                location.replace(location.href.replace("https://","http://"));
                        &lt;/script&gt;
                    &lt;/head&gt;
                    &lt;body&gt;
                        &lt;noscript&gt;&lt;meta http-equiv="refresh" content="0;url=http://www.b
                    aidu.com/"&gt;&lt;/...
RawContent        : HTTP/1.1 200 OK
                    Connection: keep-alive
                    Content-Security-Policy: frame-ancestors 'self' https://chat.baid
                    u.com http://mirror-chat.baidu.com https://fj-chat.baidu.com http
                    s://hba-chat.baidu.com https:...
Forms             : {}
Headers           : {[Connection, keep-alive], [Content-Security-Policy, frame-ancest
                    ors 'self' https://chat.baidu.com http://mirror-chat.baidu.com ht
                    tps://fj-chat.baidu.com https://hba-chat.baidu.com https://hbe-ch
                    at.baidu.com https://njjs-chat.baidu.com https://nj-chat.baidu.co
                    m https://hna-chat.baidu.com https://hnb-chat.baidu.com http://de
                    bug.baidu-int.com;], [Accept-Ranges, bytes], [Content-Length, 227
                    ]...}
Images            : {}
InputFields       : {}
Links             : {}
ParsedHtml        : mshtml.HTMLDocumentClass
RawContentLength  : 227</code></pre>
    <p>
     键入上面的命令，结果就自动跳转为www.baidu.com。
    </p>
    <p>
     <strong>
      三、显示头信息：
     </strong>
     `-i`参数
    </p>
    <p>
     `-i`参数可以显示http response的头信息，连同网页代码一起。
    </p>
    <pre><code class="language-bash">curl -i https://www.baidu.com</code></pre>
    <pre><code class="language-bash">HTTP/1.1 200 OK
Accept-Ranges: bytes
Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform
Connection: keep-alive
Content-Length: 2443
Content-Type: text/html
Date: Thu, 06 Feb 2025 13:45:16 GMT
Etag: "588603eb-98b"
Last-Modified: Mon, 23 Jan 2017 13:23:55 GMT
Pragma: no-cache
Server: bfe/1.0.8.18
Set-Cookie: BDORZ=27315; max-age=86400; domain=.baidu.com; path=/

&lt;!DOCTYPE html&gt;
&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hidden name=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class="bg s_ipt_wr"&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus=autofocus&gt;&lt;/span&gt;&lt;span class="bg s_btn_wr"&gt;&lt;input type=submit id=su value=百 度一下 class="bg s_btn" autofocus&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;新闻&lt;/a&gt; &lt;a href=https://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;地图&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;视频&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;贴吧&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;登录&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write('&lt;a href="http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u='+ encodeURIComponent(window.location.href+ (window.location.search === "" ? "?" : "&amp;")+ "bdorz_come=1")+ '" name="tj_login" class="lb"&gt;登录&lt;/a&gt;');
                &lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style="display: block;"&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;关于百度&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;使用百度前必读&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;意见反馈&lt;/a&gt;&amp;nbsp;京ICP证030173号&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;</code></pre>
    <p>
     `-I`参数则是只显示http response的头信息。
    </p>
    <p>
     <strong>
      四、显示通信过程：
     </strong>
     `-v`参数
    </p>
    <p>
     `-v`参数可以显示一次http通信的整个过程，包括端口连接和http request头信息。
    </p>
    <pre><code class="language-bash">curl -v www.baidu.com</code></pre>
    <pre><code class="language-bash">详细信息: GET with 0-byte payload
详细信息: received 511136-byte response of content type text/html; charset=utf-8


StatusCode        : 200
StatusDescription : OK
Content           : &lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Cont
                    ent-Type" content="text/html;charset=utf-8"&gt;&lt;meta http-equiv="X-U
                    A-Compatible" content="IE=edge,chrome=1"&gt;&lt;meta content="always" n
                    ame="...
RawContent        : HTTP/1.1 200 OK
                    Bdpagetype: 1
                    Bdqid: 0xa93c6a67005e92e9
                    Connection: keep-alive
                    Content-Length: 511136
                    Content-Type: text/html; charset=utf-8
                    Date: Thu, 06 Feb 2025 13:48:53 GMT
                    P3P: CP=" OTI DS...
Forms             : {form}
Headers           : {[Bdpagetype, 1], [Bdqid, 0xa93c6a67005e92e9], [Connection, keep-
                    alive], [Content-Length, 511136]...}
Images            : {@{innerHTML=; innerText=; outerHTML=&lt;img class="s-top-tab-image"
                     src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAE4AAAAqCAMAA
                    AAqEZ1jAAAAAXNSR0IArs4c6QAAAAlwSFlzAAAhOAAAITgBRZYxYAAAAKJQTFRFAA
                    AAenb/RpP/k2j/XXf7cXX6P5z7i2n8W3j7ZHP7jmn9VID7Qpf8jWn8Xnr6iWr8YHb
                    7i2n8RJb9dWz8WXr8mWj9RpP8W3n8bW/8l2j+QJz9Q5f9ToT8fWv9ZW/8lWj9VID8
                    YnX7Pp79QZr9pWb+RJT8m2f9k2j9SYz8jWn9hmr8UIT8fmv8VX78Xnn7d2z8ZHT7W
                    Hr7bm77Xnb7Z3D7YHH7RJOQRAAAACJ0Uk5TABAgICAwQEBAWF5gZXBwgICbn5+fo7
                    +/vsLP39/f3urv73XwOA8AAAKfSURBVHja7dbJcuIwFIXhIzCxMTMNcdwMDoMZY4N
                    xeP9X66srEckYQlPVvcvPBhZ8dVSIAvz03xNV/Luq4Xq9Hgo8nfDqjXq97hS1yXZN
                    hXg2Z3o+f1KnLqx62y17Pp5smp+158EUaW6I52rkxLF3eoNpt1Ne+bR+Fd8U5Oc8P
                    x6P5M0Evgq11ytpy0jgbk6e5cSxd2pb7yKOikpTouWyhbsNMsnpefZpOzsCI7c8br
                    kM74/LqFSC7HkwVTu9lsB14ZJy745LlDdV5+3iQTXC7s9z3pNEggOh9s3woOFqJT2
                    BmzUSLnMQEEeeh2+rkraiOrjZeL+XXEBwyp71Ybg+hWL+iltGt8ftKQI9QMzSlDxz
                    9VofssIMdxitdJEvbo3jxqAGKXtt6N4OkpvgkmiFa50Ch1UU8zab/Ya4Br/IUnnew
                    HCHg+FEh7/ExUIXdq+KG4N7z3hfzXDkaa5FmGpdMENrYWWjaoDrJtJLu4ajFFfbUd
                    uryN1ue4brb2KpjSvgvETe53R24U6Ggz+RYJnsCTMujmMJ9qELErkv9y7cyXAGtNC
                    oI2Dqx9ymAl1bcYMLJ2NO5fZ2dmHLxiBGrJlxEAl7M1HkTFUzseeiWHOxYK+CrwLl
                    tRX3qTk7/4PbTXDdaBHLxytMdcllaaA56U1RSEyU56M0jotfYBLvynM091ni0GGtP
                    O73nLkR7AaK6yqOKnG1g+wXrnqZz9nrw87bszdjjn/dDGffbgdX9YmT4HykaoLTp/
                    UABGfyypx7a1yFNb0wpl7BddW8geSO5JU5TE63xhmOPb2uok8reN1Nrn4qjQNBlmf
                    dvkB5beaoMgdP4LpFgbNuX3svtSwABoZ7WPOKa0Inxgl7DurMdfFXVV7savjK8WQ1
                    /cz5+Q9e7A/jUZeiPQO0fwAAAABJRU5ErkJggg=="&gt;; outerText=; tagName=I
                    MG; class=s-top-tab-image; src=data:image/png;base64,iVBORw0KGgoA
                    AAANSUhEUgAAAE4AAAAqCAMAAAAqEZ1jAAAAAXNSR0IArs4c6QAAAAlwSFlzAAAhO
                    AAAITgBRZYxYAAAAKJQTFRFAAAAenb/RpP/k2j/XXf7cXX6P5z7i2n8W3j7ZHP7jm
                    n9VID7Qpf8jWn8Xnr6iWr8YHb7i2n8RJb9dWz8WXr8mWj9RpP8W3n8bW/8l2j+QJz
                    9Q5f9ToT8fWv9ZW/8lWj9VID8YnX7Pp79QZr9pWb+RJT8m2f9k2j9SYz8jWn9hmr8
                    UIT8fmv8VX78Xnn7d2z8ZHT7WHr7bm77Xnb7Z3D7YHH7RJOQRAAAACJ0Uk5TABAgI
                    CAwQEBAWF5gZXBwgICbn5+fo7+/vsLP39/f3urv73XwOA8AAAKfSURBVHja7dbJcu
                    IwFIXhIzCxMTMNcdwMDoMZY4NxeP9X66srEckYQlPVvcvPBhZ8dVSIAvz03xNV/Lu
                    q4Xq9Hgo8nfDqjXq97hS1yXZNhXg2Z3o+f1KnLqx62y17Pp5smp+158EUaW6I52rk
                    xLF3eoNpt1Ne+bR+Fd8U5Oc8Px6P5M0Evgq11ytpy0jgbk6e5cSxd2pb7yKOikpTo
                    uWyhbsNMsnpefZpOzsCI7c8brkM74/LqFSC7HkwVTu9lsB14ZJy745LlDdV5+3iQT
                    XC7s9z3pNEggOh9s3woOFqJT2BmzUSLnMQEEeeh2+rkraiOrjZeL+XXEBwyp71Ybg
                    +hWL+iltGt8ftKQI9QMzSlDxz9VofssIMdxitdJEvbo3jxqAGKXtt6N4OkpvgkmiF
                    a50Ch1UU8zab/Ya4Br/IUnnewHCHg+FEh7/ExUIXdq+KG4N7z3hfzXDkaa5FmGpdM
                    ENrYWWjaoDrJtJLu4ajFFfbUduryN1ue4brb2KpjSvgvETe53R24U6Ggz+RYJnsCT
                    MujmMJ9qELErkv9y7cyXAGtNCoI2Dqx9ymAl1bcYMLJ2NO5fZ2dmHLxiBGrJlxEAl
                    7M1HkTFUzseeiWHOxYK+CrwLltRX3qTk7/4PbTXDdaBHLxytMdcllaaA56U1RSEyU
                    56M0jotfYBLvynM091ni0GGtPO73nLkR7AaK6yqOKnG1g+wXrnqZz9nrw87bszdjj
                    n/dDGffbgdX9YmT4HykaoLTp/UABGfyypx7a1yFNb0wpl7BddW8geSO5JU5TE63xh
                    mOPb2uok8reN1Nrn4qjQNBlmfdvkB5beaoMgdP4LpFgbNuX3svtSwABoZ7WPOKa0I
                    nxgl7DurMdfFXVV7savjK8WQ1/cz5+Q9e7A/jUZeiPQO0fwAAAABJRU5ErkJggg==
                    }, @{innerHTML=; innerText=; outerHTML=&lt;img src="https://pss.bdst
                    atic.com/static/superman/img/topnav/newfanyi-da0cea8f7e.png"&gt;; ou
                    terText=; tagName=IMG; src=https://pss.bdstatic.com/static/superm
                    an/img/topnav/newfanyi-da0cea8f7e.png}, @{innerHTML=; innerText=;
                     outerHTML=&lt;img src="https://pss.bdstatic.com/static/superman/img
                    /topnav/newxueshuicon-a5314d5c83.png"&gt;; outerText=; tagName=IMG;
                    src=https://pss.bdstatic.com/static/superman/img/topnav/newxueshu
                    icon-a5314d5c83.png}, @{innerHTML=; innerText=; outerHTML=&lt;img sr
                    c="https://pss.bdstatic.com/static/superman/img/topnav/newbaike-8
                    89054f349.png"&gt;; outerText=; tagName=IMG; src=https://pss.bdstati
                    c.com/static/superman/img/topnav/newbaike-889054f349.png}...}
InputFields       : {@{innerHTML=; innerText=; outerHTML=&lt;input name="ie" type="hidde
                    n" value="utf-8"&gt;; outerText=; tagName=INPUT; name=ie; type=hidde
                    n; value=utf-8}, @{innerHTML=; innerText=; outerHTML=&lt;input name=
                    "f" type="hidden" value="8"&gt;; outerText=; tagName=INPUT; name=f;
                    type=hidden; value=8}, @{innerHTML=; innerText=; outerHTML=&lt;input
                     name="rsv_bp" type="hidden" value="1"&gt;; outerText=; tagName=INPU
                    T; name=rsv_bp; type=hidden; value=1}, @{innerHTML=; innerText=;
                    outerHTML=&lt;input name="rsv_idx" type="hidden" value="1"&gt;; outerTe
                    xt=; tagName=INPUT; name=rsv_idx; type=hidden; value=1}...}
Links             : {@{innerHTML=百度首页; innerText=百度首页; outerHTML=&lt;a class="to
                    index" href="/"&gt;百度首页&lt;/a&gt;; outerText=百度首页; tagName=A; clas
                    s=toindex; href=/}, @{innerHTML=设置&lt;i class="c-icon c-icon-trian
                    gle-down"&gt;&lt;/i&gt;; innerText=设置; outerHTML=&lt;a name="tj_settingicon
                    " class="pf" href="javascript:;"&gt;设置&lt;i class="c-icon c-icon-tria
                    ngle-down"&gt;&lt;/i&gt;&lt;/a&gt;; outerText=设置; tagName=A; name=tj_settingic
                    on; class=pf; href=javascript:;}, @{innerHTML=登录; innerText=登
                    录; outerHTML=&lt;a name="tj_login" class="lb" onclick="return false
                    ;" href="https://passport.baidu.com/v2/?login&amp;amp;tpl=mn&amp;amp;u=ht
                    tp%3A%2F%2Fwww.baidu.com%2F&amp;amp;sms=5"&gt;登录&lt;/a&gt;; outerText=登录;
                    tagName=A; name=tj_login; class=lb; onclick=return false;; href=h
                    ttps://passport.baidu.com/v2/?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2
                    Fwww.baidu.com%2F&amp;amp;sms=5}, @{innerHTML=

                                            新闻

                                    ; innerText= 新闻 ; outerHTML=&lt;a class="mnav c-fo
                    nt-normal c-color-t" href="http://news.baidu.com" target="_blank"
                    &gt;

                                            新闻

                                    &lt;/a&gt;; outerText= 新闻 ; tagName=A; class=mnav c-f
                    ont-normal c-color-t; href=http://news.baidu.com; target=_blank}.
                    ..}
ParsedHtml        : mshtml.HTMLDocumentClass
RawContentLength  : 511136</code></pre>
    <p>
     如果你觉得上面的信息还不够，那么下面的命令可以查看更详细的通信过程。
    </p>
    <pre><code>$ curl --trace output.txt www.baidu.com</code></pre>
    <p>
     或者
    </p>
    <pre><code>$ curl --trace-ascii output.txt www.baidu.com</code></pre>
    <p>
     运行后，请打开output.txt文件查看。
    </p>
    <p>
     <strong>
      五、发送表单信息
     </strong>
    </p>
    <p>
     发送表单信息有GET和POST两种方法。GET方法相对简单，只要把数据附在网址后面就行。
    </p>
    <blockquote>
     <p>
      $ curl example.com?data=xxx
     </p>
    </blockquote>
    <p>
     POST方法必须把数据和网址分开，curl就要用到--data参数。
    </p>
    <blockquote>
     <p>
      $ curl -X POST --data "data=xxx" example.com
     </p>
    </blockquote>
    <p>
     如果你的数据没有经过表单编码，还可以让curl为你编码，参数是`--data-urlencode`。
    </p>
    <blockquote>
     <p>
      $ curl -X POST--data-urlencode "date=April 1" example.com/form.cgi
     </p>
    </blockquote>
    <p>
     <strong>
      六、HTTP动词
     </strong>
    </p>
    <p>
     curl默认的HTTP动词是GET，使用`-X`参数可以支持其他动词。
    </p>
    <blockquote>
     <p>
      $ curl -X POST www.example.com
     </p>
    </blockquote>
    <blockquote>
     <p>
      $ curl -X DELETE www.example.com
     </p>
    </blockquote>
    <p>
     <strong>
      七、文件上传
     </strong>
    </p>
    <p>
     假定文件上传的表单是下面这样：
    </p>
    <blockquote>
     <p>
      &lt;form method="POST" enctype='multipart/form-data' action="upload.cgi"&gt;
      <br/>
      &lt;input type=file name=upload&gt;
      <br/>
      &lt;input type=submit name=press value="OK"&gt;
      <br/>
      &lt;/form&gt;
     </p>
    </blockquote>
    <p>
     你可以用curl这样上传文件：
    </p>
    <blockquote>
     <p>
      $ curl --form upload=@localfilename --form press=OK [URL]
     </p>
    </blockquote>
    <p>
     <strong>
      八、Referer字段
     </strong>
    </p>
    <p>
     有时你需要在http request头信息中，提供一个referer字段，表示你是从哪里跳转过来的。
    </p>
    <blockquote>
     <p>
      $ curl --referer http://www.example.com http://www.example.com
     </p>
    </blockquote>
    <p>
     <strong>
      九、User Agent字段
     </strong>
    </p>
    <p>
     这个字段是用来表示客户端的设备信息。服务器有时会根据这个字段，针对不同设备，返回不同格式的网页，比如手机版和桌面版。
    </p>
    <p>
     curl可以这样模拟：
    </p>
    <blockquote>
     <p>
      $ curl --user-agent "[User Agent]" [URL]
     </p>
    </blockquote>
    <p>
     <strong>
      十、cookie
     </strong>
    </p>
    <p>
     使用`--cookie`参数，可以让curl发送cookie。
    </p>
    <blockquote>
     <p>
      $ curl --cookie "name=xxx" www.example.com
     </p>
    </blockquote>
    <p>
     至于具体的cookie的值，可以从http response头信息的`Set-Cookie`字段中得到。
    </p>
    <p>
     `-c cookie-file`可以保存服务器返回的cookie到文件，`-b cookie-file`可以使用这个文件作为cookie信息，进行后续的请求。
    </p>
    <blockquote>
     <p>
      $ curl -c cookies http://example.com
      <br/>
      $ curl -b cookies http://example.com
     </p>
    </blockquote>
    <p>
     <strong>
      十一、增加头信息
     </strong>
    </p>
    <p>
     有时需要在http request之中，自行增加一个头信息。`--header`参数就可以起到这个作用。
    </p>
    <blockquote>
     <p>
      $ curl --header "Content-Type:application/json" http://example.com
     </p>
    </blockquote>
    <p>
     <strong>
      十二、HTTP认证
     </strong>
    </p>
    <p>
     有些网域需要HTTP认证，这时curl需要用到`--user`参数。
    </p>
    <blockquote>
     <p>
      $ curl --user name:password example.com
     </p>
    </blockquote>
    <h3>
     （三）curl命令行参数
    </h3>
    <h4>
     参考链接
    </h4>
    <ul>
     <li>
      <a href="https://catonmat.net/cookbooks/curl" rel="nofollow" title="Curl Cookbook">
       Curl Cookbook
      </a>
     </li>
    </ul>
    <p>
     不带有任何参数时，curl 就是发出 GET 请求。
    </p>
    <pre><code class="language-python">curl http://www.baidu.com</code></pre>
    <p>
     上面命令向
     <code>
      www.baidu.com
     </code>
     发出 GET 请求，服务器返回的内容会在命令行输出。
    </p>
    <h4>
     <strong>
      -A
     </strong>
    </h4>
    <p>
     <code>
      -A
     </code>
     参数指定客户端的用户代理标头，即
     <code>
      User-Agent
     </code>
     。curl 的默认用户代理字符串是
     <code>
      curl/[version]
     </code>
     。
    </p>
    <pre><code class="language-python">$ curl -A 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36' https://www.baidu.com</code></pre>
    <p>
     上面命令将
     <code>
      User-Agent
     </code>
     改成 Chrome 浏览器。
    </p>
    <pre><code class="language-python">$ curl -A '' https://www.baidu.com</code></pre>
    <p>
     上面命令会移除
     <code>
      User-Agent
     </code>
     标头。
    </p>
    <p>
     也可以通过
     <code>
      -H
     </code>
     参数直接指定标头，更改
     <code>
      User-Agent
     </code>
     。
    </p>
    <pre><code class="language-python">​$ curl -H 'User-Agent: php/1.0' https://www.baidu.com</code></pre>
    <h4>
     <strong>
      -b
     </strong>
    </h4>
    <p>
     <code>
      -b
     </code>
     参数用来向服务器发送 Cookie。
    </p>
    <pre><code class="language-python">​$ curl -b 'data=admin' https://www.baidu.com</code></pre>
    <p>
     上面命令会生成一个标头
     <code>
      Cookie: data=admin
     </code>
     ，向服务器发送一个名为data、值为admin的 Cookie。
    </p>
    <pre><code class="language-python">$ curl -b 'data1=admin;data2=admin2' https://www.baidu.com
</code></pre>
    <p>
     上面命令发送两个 Cookie。
    </p>
    <pre><code class="language-python">$ curl -b cookies.txt https://www.baidu.com
</code></pre>
    <p>
     上面命令读取本地文件
     <code>
      cookies.txt
     </code>
     ，里面是服务器设置的 Cookie（参见
     <code>
      -c
     </code>
     参数），将其发送到服务器。
    </p>
    <h4>
     <strong>
      -c
     </strong>
    </h4>
    <p>
     <code>
      -c
     </code>
     参数将服务器设置的 Cookie 写入一个文件。
    </p>
    <pre><code class="language-python">$ curl -c cookies.txt https://www.baidu.com
</code></pre>
    <p>
     上面命令将服务器的 HTTP 回应所设置 Cookie 写入文本文件
     <code>
      cookies.txt
     </code>
     。
    </p>
    <h4>
     <strong>
      -d
     </strong>
    </h4>
    <p>
     <code>
      -d
     </code>
     参数用于发送 POST 请求的数据体。
    </p>
    <pre><code class="language-python">$ curl -d 'login=admin＆password=admin123' -X POST https://www.baidu.com/login
# 或者
$ curl -d 'login=admin' -d 'password=admin123' -X POST https://www.baidu.com/login</code></pre>
    <p>
     使用
     <code>
      -d
     </code>
     参数以后，HTTP 请求会自动加上标头
     <code>
      Content-Type : application/x-www-form-urlencoded
     </code>
     。并且会自动将请求转为 POST 方法，因此可以省略
     <code>
      -X POST
     </code>
     。
    </p>
    <p>
     <code>
      -d
     </code>
     参数可以读取本地文本文件的数据，向服务器发送。
    </p>
    <pre><code class="language-python">$ curl -d '@data.txt' https://www.baidu.com/login
</code></pre>
    <p>
     上面命令读取
     <code>
      data.txt
     </code>
     文件的内容，作为数据体向服务器发送。
    </p>
    <pre><code># $ cmd /c "curl -d test=123 http://httpbin.org/post"
$ curl -d test=123 http://httpbin.org/post
{
  "args": {},
  "data": "",
  "files": {},
  "form": {
    "test": "123"
  },
  "headers": {
    "Accept": "*/*",
    "Content-Length": "8",
    "Content-Type": "application/x-www-form-urlencoded",
    "Host": "httpbin.org",
    "User-Agent": "curl/8.9.1",
    "X-Amzn-Trace-Id": "Root=1-67a56bb0-6dd0b5a5665ff1d168572cf2"
  },
  "json": null,
  "origin": "58.241.18.10",
  "url": "http://httpbin.org/post"
}</code></pre>
    <h4>
     <strong>
      --data-urlencode
     </strong>
    </h4>
    <p>
     <code>
      --data-urlencode
     </code>
     参数等同于
     <code>
      -d
     </code>
     ，发送 POST 请求的数据体，区别在于会自动将发送的数据进行 URL 编码。
    </p>
    <pre><code class="language-python">$ curl --data-urlencode 'comment=hello world' https://www.baidu.com/login
</code></pre>
    <p>
     上面代码中，发送的数据
     <code>
      hello world
     </code>
     之间有一个空格，需要进行 URL 编码。
    </p>
    <h4>
     <strong>
      -e
     </strong>
    </h4>
    <p>
     <code>
      -e
     </code>
     参数用来设置 HTTP 的标头
     <code>
      Referer
     </code>
     ，表示请求的来源。
     <code>
     </code>
    </p>
    <pre><code class="language-python">curl -e 'https://www.baidu.com?q=example' https://www.example.com</code></pre>
    <p>
     上面命令将
     <code>
      Referer
     </code>
     标头设为
     <code>
      https://www.baidu.com?q=example
     </code>
     。
    </p>
    <p>
     <code>
      -H
     </code>
     参数可以通过直接添加标头
     <code>
      Referer
     </code>
     ，达到同样效果
    </p>
    <pre><code class="language-python">​curl -H 'Referer: https://www.baidu.com?q=example' https://www.example.com</code></pre>
    <h4>
     <strong>
      -F
     </strong>
    </h4>
    <p>
     <code>
      -F
     </code>
     参数用来向服务器上传二进制文件。
     <code>
     </code>
    </p>
    <pre><code class="language-python">$ curl -F 'file=@photo.png' https://www.baidu.com/profile</code></pre>
    <p>
     上面命令会给 HTTP 请求加上标头
     <code>
      Content-Type: multipart/form-data
     </code>
     ，然后将文件
     <code>
      photo.png
     </code>
     作为
     <code>
      file
     </code>
     字段上传。
    </p>
    <p>
     <code>
      -F
     </code>
     参数可以指定 MIME 类型。
     <code>
     </code>
    </p>
    <pre><code class="language-python">$ curl -F 'file=@photo.png;type=image/png' https://www.baidu.com/profile</code></pre>
    <p>
     上面命令指定 MIME 类型为
     <code>
      image/png
     </code>
     ，否则 curl 会把 MIME 类型设为
     <code>
      application/octet-stream
     </code>
     。
    </p>
    <p>
     <code>
      -F
     </code>
     参数也可以指定文件名
    </p>
    <pre><code class="language-python">$ curl -F 'file=@photo.png;filename=me.png' https://www.baidu.com/profile</code></pre>
    <p>
     上面命令中，原始文件名为
     <code>
      photo.png
     </code>
     ，但是服务器接收到的文件名为
     <code>
      me.png
     </code>
     。
    </p>
    <h4>
     <strong>
      -G
     </strong>
    </h4>
    <p>
     <code>
      -G
     </code>
     参数用来构造 URL 的查询字符串。
    </p>
    <pre><code class="language-python">$ curl -G -d 'q=kitties' -d 'count=20' https://www.baidu.com/search
</code></pre>
    <p>
     上面命令会发出一个 GET 请求，实际请求的 URL 为
     <a href="https://www.baidu.com" rel="nofollow" title="百度一下，你就知道">
      百度一下，你就知道
     </a>
     <code>
      /search?q=kitties&amp;count=20
     </code>
     。如果省略
     <code>
      --G
     </code>
     ，会发出一个 POST 请求。
    </p>
    <p>
     如果数据需要 URL 编码，可以结合
     <code>
      --data--urlencode
     </code>
     参数。
    </p>
    <pre><code class="language-python">$ curl -G --data-urlencode 'comment=hello world' https://www.example.com
</code></pre>
    <h4>
     <strong>
      -H
     </strong>
    </h4>
    <p>
     <code>
      -H
     </code>
     参数添加 HTTP 请求的标头。
    </p>
    <pre><code class="language-python">$ curl -H 'Accept-Language: en-US' https://www.baidu.com
</code></pre>
    <p>
     上面命令添加 HTTP 标头
     <code>
      Accept-Language: en-US
     </code>
     。
    </p>
    <pre><code class="language-python">$ curl -H 'Accept-Language: en-US' -H 'Secret-Message: xyzzy' https://www.baidu.com
</code></pre>
    <p>
     上面命令添加两个 HTTP 标头。
    </p>
    <pre><code class="language-python">$ curl -d '{"login": "emma", "pass": "123"}' -H 'Content-Type: application/json' https://www.baidu.com/login
</code></pre>
    <p>
     上面命令添加 HTTP 请求的标头是
     <code>
      Content-Type: application/json
     </code>
     ，然后用
     <code>
      -d
     </code>
     参数发送 JSON 数据。
    </p>
    <h4>
     <strong>
      -i
     </strong>
    </h4>
    <p>
     <code>
      -i
     </code>
     参数打印出服务器回应的 HTTP 标头。
    </p>
    <pre><code class="language-python">$ curl -i https://www.baidu.com
</code></pre>
    <p>
     上面命令收到服务器回应后，先输出服务器回应的标头，然后空一行，再输出网页的源码。
    </p>
    <h4>
     <strong>
      -I
     </strong>
    </h4>
    <p>
     <code>
      -I
     </code>
     参数向服务器发出 HEAD 请求，然会将服务器返回的 HTTP 标头打印出来。
    </p>
    <pre><code class="language-python">$ curl -I https://www.baidu.com
</code></pre>
    <p>
     上面命令输出服务器对 HEAD 请求的回应。
    </p>
    <p>
     <code>
      --head
     </code>
     参数等同于
     <code>
      -I
     </code>
     。
    </p>
    <pre><code class="language-python">$ curl --head https://www.baidu.com
</code></pre>
    <h4>
     <strong>
      -k
     </strong>
    </h4>
    <p>
     <code>
      -k
     </code>
     参数指定跳过 SSL 检测。
    </p>
    <pre><code class="language-python">$ curl -k https://www.baidu.com
</code></pre>
    <p>
     上面命令不会检查服务器的 SSL 证书是否正确。
    </p>
    <h4>
     <strong>
      -L
     </strong>
    </h4>
    <p>
     <code>
      -L
     </code>
     参数会让 HTTP 请求跟随服务器的重定向。curl 默认不跟随重定向。
    </p>
    <pre><code class="language-python">$ curl -L -d 'tweet=hi' https://api.twitter.com/tweet
</code></pre>
    <h4>
     <strong>
      --limit-rate
     </strong>
    </h4>
    <p>
     <code>
      --limit-rate
     </code>
     用来限制 HTTP 请求和回应的带宽，模拟慢网速的环境。
    </p>
    <pre><code class="language-python">$ curl --limit-rate 200k https://www.baidu.com
</code></pre>
    <p>
     上面命令将带宽限制在每秒 200K 字节。
    </p>
    <h4>
     <strong>
      -o
     </strong>
    </h4>
    <p>
     <code>
      -o
     </code>
     参数将服务器的回应保存成文件，等同于
     <code>
      wget
     </code>
     命令。
    </p>
    <pre><code class="language-python">$ curl -o example.html https://www.example.com
</code></pre>
    <p>
     上面命令将
     <code>
      www.example.com
     </code>
     保存成
     <code>
      example.html
     </code>
     。
    </p>
    <h4>
     <strong>
      -O
     </strong>
    </h4>
    <p>
     <code>
      -O
     </code>
     参数将服务器回应保存成文件，并将 URL 的最后部分当作文件名。
    </p>
    <pre><code class="language-python">$ curl -O https://www.example.com/foo/bar.html
</code></pre>
    <p>
     上面命令将服务器回应保存成文件，文件名为
     <code>
      bar.html
     </code>
     。
    </p>
    <h4>
     <strong>
      -s
     </strong>
    </h4>
    <p>
     <code>
      -s
     </code>
     参数将不输出错误和进度信息。
    </p>
    <pre><code class="language-python">$ curl -s https://www.example.com
</code></pre>
    <p>
     上面命令一旦发生错误，不会显示错误信息。不发生错误的话，会正常显示运行结果。
    </p>
    <p>
     如果想让 curl 不产生任何输出，可以使用下面的命令。
    </p>
    <pre><code class="language-python">$ curl -s -o /dev/null https://google.com
</code></pre>
    <h4>
     <strong>
      -S
     </strong>
    </h4>
    <p>
     <code>
      -S
     </code>
     参数指定只输出错误信息，通常与
     <code>
      -s
     </code>
     一起使用。
    </p>
    <pre><code class="language-python">$ curl -s -o /dev/null https://www.baidu.com
</code></pre>
    <p>
     上面命令没有任何输出，除非发生错误。
    </p>
    <h4>
     <strong>
      -u
     </strong>
    </h4>
    <p>
     <code>
      -u
     </code>
     参数用来设置服务器认证的用户名和密码。
    </p>
    <pre><code class="language-python">$ curl -u 'admin:admin12345' https://google.com/login
</code></pre>
    <p>
     上面命令设置用户名为
     <code>
      admin
     </code>
     ，密码为admin
     <code>
      12345
     </code>
     ，然后将其转为 HTTP 标头
     <code>
      Authorization: Basic Ym9iOjEyMzQ1
     </code>
     。
    </p>
    <p>
     curl 能够识别 URL 里面的用户名和密码。
    </p>
    <pre><code class="language-python">$ curl https://admin:admin12345@google.com/login
</code></pre>
    <p>
     上面命令能够识别 URL 里面的用户名和密码，将其转为上个例子里面的 HTTP 标头。
    </p>
    <pre><code class="language-python">$ curl -u 'admin' https://google.com/login
</code></pre>
    <p>
     上面命令只设置了用户名，执行后，curl 会提示用户输入密码。
    </p>
    <h4>
     <strong>
      -v
     </strong>
    </h4>
    <p>
     <code>
      -v
     </code>
     参数输出通信的整个过程，用于调试。
    </p>
    <pre><code class="language-python">​$ curl -v https://www.example.com</code></pre>
    <p>
     <code>
      --trace
     </code>
     参数也可以用于调试，还会输出原始的二进制数据
    </p>
    <pre><code class="language-python">$ curl --trace - https://www.example.com
</code></pre>
    <h4>
     <strong>
      -x
     </strong>
    </h4>
    <p>
     <code>
      -x
     </code>
     参数指定 HTTP 请求的代理。
     <code>
     </code>
    </p>
    <pre><code class="language-python">$ curl -x socks5://james:cats@myproxy.com:8080 https://www.example.com</code></pre>
    <p>
     上面命令指定 HTTP 请求通过
     <code>
      myproxy.com:8080
     </code>
     的 socks5 代理发出。
    </p>
    <p>
     如果没有指定代理协议，默认为 HTTP。
     <code>
     </code>
    </p>
    <pre><code class="language-python">$ curl -x james:cats@myproxy.com:8080 https://www.example.com</code></pre>
    <p>
     上面命令中，请求的代理使用 HTTP 协议。
    </p>
    <h4>
     <strong>
      -X
     </strong>
    </h4>
    <p>
     <code>
      -X
     </code>
     参数指定 HTTP 请求的方法。
    </p>
    <pre><code class="language-python">$ curl -X POST https://www.example.com
</code></pre>
    <p>
     上面命令对
     <code>
      https://www.example.com
     </code>
     发出 POST 请求
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f67:2e6373646e2e6e65742f4d696e67676551696e676368756e2f:61727469636c652f64657461696c732f313435343735393835" class_="artid" style="display:none">
 </p>
</div>


