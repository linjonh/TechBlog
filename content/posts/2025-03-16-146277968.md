---
layout: post
title: "k8s中的微服务"
date: 2025-03-16 11:45:58 +08:00
description: "用控制器来完成集群的工作负载，那么应用如何暴漏出去？需要通过微服务暴漏出去后才能被访问Service是一组提供相同服务的Pod对外开放的接口。借助Service，应用可以实现服务发现和负载均衡。service默认只支持4层负载均衡能力，没有7层功能。（可以通过Ingress实现）"
keywords: "k8s中的微服务"
categories: ['未分类']
tags: ['微服务', '容器', 'Kubernetes']
artid: "146277968"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146277968
    alt: "k8s中的微服务"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146277968
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146277968
cover: https://bing.ee123.net/img/rand?artid=146277968
image: https://bing.ee123.net/img/rand?artid=146277968
img: https://bing.ee123.net/img/rand?artid=146277968
---

# k8s中的微服务
## 一 什么是微服务
用控制器来完成集群的工作负载，那么应用如何暴漏出去？需要通过微服务暴漏出去后才能被访问
\* Service是一组提供相同服务的Pod对外开放的接口。
\* 借助Service，应用可以实现服务发现和负载均衡。
\* service默认只支持4层负载均衡能力，没有7层功能。（可以通过Ingress实现）
## 二 微服务的类型
微服务类型| 作用描述
---|---
ClusterIP| 默认值，k8s系统给service自动分配的虚拟IP，只能在集群内部访问
NodePort| 将Service通过指定的Node上的端口暴露给外部，访问任意一个NodeIP:nodePort都将路由到ClusterIP
LoadBalancer| 在NodePort的基础上,借助cloud provider创建一个外部的负载均衡器，并将请求转发到
NodeIP:NodePort，此模式只能在云服务器上使用
ExternalName| 将服务通过 DNS CNAME 记录方式转发到指定的域名（通过 spec.externlName 设定
示例：
#生成控制器文件并建立控制器
![](https://i-blog.csdnimg.cn/direct/ec6e891cca7343cabbd125fd9b206fea.png)
#生成微服务yaml追加到已有yaml中
> [root@master ~]# cat timinglee.yaml
> apiVersion: apps/v1
> kind: Deployment
> metadata:
> creationTimestamp: null
> labels:
> app: timinglee
> name: timinglee
> spec:
> replicas: 2
> selector:
> matchLabels:
> app: timinglee
> template:
> metadata:
> creationTimestamp: null
> labels:
> app: timinglee
> spec:
> containers:
> \- image: reg.timinglee.org/library/myapp:v1
> name: myapp
> \---
> apiVersion: v1
> kind: Service
> metadata:
> creationTimestamp: null
> labels:
> app: timinglee
> name: timinglee
> spec:
> ports:
> \- port: 80
> protocol: TCP
> targetPort: 80
> selector:
![](https://i-blog.csdnimg.cn/direct/a58a8185e7164bd7acc7d2981f30102a.png)
微服务默认使用iptables调度
![](https://i-blog.csdnimg.cn/direct/e2be3cf85f7b4f0e9aa14b044fe8f747.png)
## 三 ipvs模式
\* Service 是由 kube-proxy 组件，加上 iptables 来共同实现的
\* kube-proxy 通过 iptables 处理 Service 的过程，需要在宿主机上设置相当多的 iptables 规则，如果宿主机有大量的Pod，不断刷新iptables规则，会消耗大量的CPU资源
\* IPVS模式的service，可以使K8s集群支持更多量级的Pod
### 3.1 ipvs模式配置方式
1 在所有节点中安装ipvsadm
![](https://i-blog.csdnimg.cn/direct/23c3ca017d5b4c41b43a40de1d85c4c8.png)
2 修改master节点的代理配置
![](https://i-blog.csdnimg.cn/direct/50e36def2eed47bd971fc942d8838562.png)
![](https://i-blog.csdnimg.cn/direct/1297d2ed24a74859822c977d5215645d.png)
3 重启pod，在pod运行时配置文件中采用默认配置，当改变配置文件后已经运行的pod状态不会变化，所以要重启pod
![](https://i-blog.csdnimg.cn/direct/ae0dce19158849e58ffd9330da843209.png)
切换ipvs模式后，kube-proxy会在宿主机上添加一个虚拟网卡：kube-ipvs0，并分配所有service IP
![](https://i-blog.csdnimg.cn/direct/2747c7f6161146cda108e74b9bd5c066.png)
## 四 微服务类型详解
### 4.1 clusterip
特点：
clusterip模式只能在集群内访问，并对集群内的pod提供健康检测和自动发现功能
示例：
![](https://i-blog.csdnimg.cn/direct/74275fce578846b9841b1cadb8c23b39.png)
![](https://i-blog.csdnimg.cn/direct/177c6f0783cc411f973ba94712362179.png)
![](https://i-blog.csdnimg.cn/direct/8521eacdfd2e4be69ca84b6a9912d0b8.png)
### 4.2 ClusterIP中的特殊模式headless
headless（无头服务）
对于无头 `Services` 并不会分配 Cluster IP，kube-proxy不会处理它们，
而且平台也不会为它们进行负载均衡和路由，集群访问通过dns解析直接指向到业务pod上的IP，所有的调度有dns单独完成
示例：
![](https://i-blog.csdnimg.cn/direct/8652ecc5a1154a818d33887c7fbb0f1d.png)
![](https://i-blog.csdnimg.cn/direct/e3059fe15aa74a9292183862cf1e467e.png)
无ip
![](https://i-blog.csdnimg.cn/direct/925e02bde3114efc963415a1d7d62410.png)
#开启一个busyboxplus的pod测试
![](https://i-blog.csdnimg.cn/direct/c5f7082e816c4ca8b9d6e3ad04ad716c.png)
IP 都是后端ip直接暴露不走ipvs
### 4.3 nodeport
通过ipvs暴漏端口从而使外部主机通过master节点的对外ip:来访问pod业务
其访问过程为：
![](https://i-blog.csdnimg.cn/direct/4ce1c1d380af48f0ac61e9df42d4c669.png)
示例：
![](https://i-blog.csdnimg.cn/direct/d5ccd05cde79459980d561c48daa34b6.png)
![](https://i-blog.csdnimg.cn/direct/a59e5ab28fec4f4dabdffc188e080c3a.png)
nodeport在集群节点上绑定端口，一个端口对应一个服务
nodeport默认端口是30000-32767，超出会报错
直接指定端口：
![](https://i-blog.csdnimg.cn/direct/0a0cb8c980c24223b7d4ecdf87616ff7.png)![](https://i-blog.csdnimg.cn/direct/44f04705b6de45789883d91cda9b4ca1.png)
如果需要使用这个范围以外的端口就需要特殊设定
> vim /etc/kubernetes/manifests/kube-apiserver.yaml
>
> \--service-node-port-range=30000-40000
添加“--service-node-port-range=“ 参数，端口范围可以自定义
修改后api-server会自动重启，等apiserver正常启动后才能操作集群
集群重启自动完成在修改完参数后全程不需要人为干预
### 4.4 loadbalancer
云平台会为我们分配vip并实现访问，如果是裸金属主机那么需要metallb来实现ip的分配
![](https://i-blog.csdnimg.cn/direct/14deccaf83d6476885573a77a908c723.png)
![](https://i-blog.csdnimg.cn/direct/8aee002e79234156a439380058dcce58.png)
默认无法分配外部访问IP
![](https://i-blog.csdnimg.cn/direct/281b86d56b684154b1e67c3cff68adf4.png)
LoadBalancer模式适用云平台，裸金属环境需要安装metallb提供支持
### 4.5 metalLB
![](https://i-blog.csdnimg.cn/direct/8fd623eca7ea445bbd26fdfdaf4dc538.png)
metalLB功能为LoadBalancer分配vip
部署方式
> 1.设置ipvs模式
> [root@k8s-master ~]# kubectl edit cm -n kube-system kube-proxy
> apiVersion: kubeproxy.config.k8s.io/v1alpha1
> kind: KubeProxyConfiguration
> mode: "ipvs"
> ipvs:
> strictARP: true
>
>
> [root@k8s-master ~]# kubectl -n kube-system get pods | awk '/kube-proxy/{system("kubectl -n kube-system delete pods "$1)}'
2.下载部署文件
> wget
> https://raw.githubusercontent.com/metallb/metallb/v0.13.12/config/manifests/metallb-
> native.yaml
3.修改文件中镜像地址,与harbor仓库路径保持一致
4.上传镜像到harbor
![](https://i-blog.csdnimg.cn/direct/413c67a55b3743f58ff1949691d3f22c.png)
![](https://i-blog.csdnimg.cn/direct/da65bcd69e374b44b28fcd5b2c660c91.png)
部署服务
![](https://i-blog.csdnimg.cn/direct/75fd139030844165ad66d1ac83fd7893.png)
配置分配地址段
![](https://i-blog.csdnimg.cn/direct/5bc4af29918048049a07f91af1782bc4.png)
![](https://i-blog.csdnimg.cn/direct/263b17ab91834a078b14216d417efb4a.png)
#通过分配地址从集群外访问服务
![](https://i-blog.csdnimg.cn/direct/f35b0ab0ce624da58a654e38d95b39e2.png)
### 4.6 externalname
\* 开启services后，不会被分配IP，而是用dns解析CNAME固定域名来解决ip变化问题
\* 一般应用于外部业务和pod沟通或外部业务迁移到pod内时
\* 在应用向集群迁移过程中，externalname在过度阶段就可以起作用了。
\* 集群外的资源迁移到集群时，在迁移的过程中ip可能会变化，但是域名+dns解析能完美解决此问题
示例：
![](https://i-blog.csdnimg.cn/direct/a0f0e8805c824844b6f99b145fea0939.png)
![](https://i-blog.csdnimg.cn/direct/80ecf6cde94140fbb1023058c93401ad.png)
## 五 Ingress-nginx
### 5.1 ingress-nginx功能
![](https://i-blog.csdnimg.cn/direct/b605caea470440a88e581d4c2da7fed6.png)
\* 一种全局的、为了代理不同后端 Service 而设置的负载均衡服务,支持7层
\* Ingress由两部分组成：Ingress controller和Ingress服务
\* Ingress Controller 会根据你定义的 Ingress 对象，提供对应的代理能力。
\* 业界常用的各种反向代理项目，比如 Nginx、HAProxy、Envoy、Traefik 等，都已经为Kubernetes 专门维护了对应的 Ingress Controller。
### 5.2 部署ingress
#### 5.2.1 下载部署文件
上传ingress所需镜像到harbor
![](https://i-blog.csdnimg.cn/direct/7a5fe9fb06554eadac2bc33df7b184a1.png)
![](https://i-blog.csdnimg.cn/direct/913c31c372d04421b1077dec4263a16f.png)
#### 5.2.2 安装ingress
![](https://i-blog.csdnimg.cn/direct/755d08dc09d040d1bad1dd84374656ab.png)
![](https://i-blog.csdnimg.cn/direct/74eebf16faa94e74a75c597ff40aaa7a.png)
在ingress-nginx-controller中看到的对外IP就是ingress最终对外开放的ip
#### 5.2.3 测试ingress
#生成yaml文件
![](https://i-blog.csdnimg.cn/direct/db67e3fe480643eba317bf5524c6a7b6.png)
> [root@master ingress]# cat ingress1.yml
> apiVersion: networking.k8s.io/v1
> kind: Ingress
> metadata:
> name: myappv1
> spec:
> ingressClassName: nginx
> rules:
> \- http:
> paths:
> \- backend:
> service:
> name: myappv1
> port:
> number: 80
> path: /
> pathType: Prefix
> #Exact（精确匹配），ImplementationSpecific（特定实现），Prefix（前缀匹配），Regular
> expression（正则表达式匹配）
#修改微服务为loadbalancer
kubectl -n ingress-nginx edit svc ingress-nginx-controller
![](https://i-blog.csdnimg.cn/direct/039d72bd4fa04fc683eebd0b8956e722.png)
![](https://i-blog.csdnimg.cn/direct/d3e734d3b5eb4bf680632aaf833bea87.png)
#建立ingress控制器
![](https://i-blog.csdnimg.cn/direct/e82350d4b61045e6a2247e7c30e1129a.png)
![](https://i-blog.csdnimg.cn/direct/a9e6f319f6d64120a43ad78803e53e90.png)
### 5.3 ingress 的高级用法
#### 5.3.1 基于路径的访问
建立用于测试的控制器myapp
![](https://i-blog.csdnimg.cn/direct/5c5e1a6dfbf74cb08107d3c9e9bf4975.png)
建立ingress的yaml
![](https://i-blog.csdnimg.cn/direct/b5986e31ed3f44febb333707d75f9fe3.png)
#测试：
![](https://i-blog.csdnimg.cn/direct/7ee6810ae7254cedbea91ece74461d50.png)
#### 5.3.3 建立tls加密
#建立证书
![](https://i-blog.csdnimg.cn/direct/22ae9433c9c547a491c7025295b7f6e6.png)
#建立加密资源类型secret
![](https://i-blog.csdnimg.cn/direct/f49a1f36dc904131b77cff7327a21ed7.png)
#建立ingress3基于tls认证的yml文件
![](https://i-blog.csdnimg.cn/direct/51315e22064f4f47b391e52e19f529c0.png)
#测试
![](https://i-blog.csdnimg.cn/direct/fe98d20da82d4f8b9cd28d3174a5daa8.png)
#### 5.3.4 建立auth认证
#建立认证文件
![](https://i-blog.csdnimg.cn/direct/6855dccc7b1c4de9a6ca24fc0f960d1d.png)
#建立认证类型资源
![](https://i-blog.csdnimg.cn/direct/20539d1d3666404aa4148fa0805a9da7.png)
#建立ingress4基于用户认证的yaml文件
![](https://i-blog.csdnimg.cn/direct/fba6cca08fb54b02a0ee72caac0cd62b.png)
![](https://i-blog.csdnimg.cn/direct/418eb812d7f647748deef008dfa33001.png)
#测试：
![](https://i-blog.csdnimg.cn/direct/b2f9bec1d8814d4688748faf0367d404.png)
#### 5.3.5 rewrite重定向
#指定默认访问的文件到hostname.html上
![](https://i-blog.csdnimg.cn/direct/d8a39e5b2d3b46e0ae814407be456126.png)
#测试：
![](https://i-blog.csdnimg.cn/direct/3d09da3b7f9d4a5ea2c06d14f25a98a9.png)
#解决重定向路径问题
> apiVersion: networking.k8s.io/v1
> name: myapp
> annotations:
> nginx.ingress.kubernetes.io/rewrite-target: /$2
> nginx.ingress.kubernetes.io/use-regex: "true"
> spec:
> ingressClassName: nginx
> rules:
> \- host: www.timinglee.org
> \- http:
> paths:
> \- backend:
> service:
> name: myappv1
> port:
> number: 80
> path: /
> pathType: Prefix
> \- backend:
> service:
> name: myappv1
> port:
> number: 80
> path: /lee(/|$)(.\*)
> pathType: ImplementationSpecific
#测试
![](https://i-blog.csdnimg.cn/direct/39836139be1a4ee78ebe1114358ff95d.png)
## 六 Canary金丝雀发布
### 6.1 么是金丝雀发布
金丝雀发布（Canary Release）也称为灰度发布，是一种软件发布策略。
主要目的是在将新版本的软件全面推广到生产环境之前，先在一小部分用户或服务器上进行测试和验证，以降低因新版本引入重大问题而对整个系统造成的影响。
是一种Pod的发布方式。金丝雀发布采取先添加、再删除的方式，保证Pod的总量不低于期望值。并且在更新部分Pod后，暂停更新，当确认新Pod版本运行正常后再进行其他版本的Pod的更新。
### 6.2 Canary发布方式
![](https://i-blog.csdnimg.cn/direct/739c528c30f44b4f9f7daf4a3ed597b1.png)
其中header和weiht中的最多
#### 6.2.1 基于header（http包头）灰度
示例：
#建立版本1的ingress
![](https://i-blog.csdnimg.cn/direct/9a806fdffd28411fb28cc7622cfb15fd.png)
#建立基于header的ingress
![](https://i-blog.csdnimg.cn/direct/5609b514f7914f5da3e80fca8cb09b35.png)
![](https://i-blog.csdnimg.cn/direct/9a8bbc6a60944f71b6afd0fd20e7564f.png)
#测试：
![](https://i-blog.csdnimg.cn/direct/41a2c6c8e85c43d09f209fd31df33498.png)
#### 6.2.2 基于权重的灰度发布
#基于权重的灰度发布
![](https://i-blog.csdnimg.cn/direct/ec6730f0b19d48839e37f25a82981cb2.png)
测试：
![](https://i-blog.csdnimg.cn/direct/2f2c5a49da27474ab40bcc6ed0cd22f2.png)