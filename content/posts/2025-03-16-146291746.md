---
layout: post
title: "python爬虫Scrapy5之增量式"
date: 2025-03-16 10:42:13 +0800
description: "scrapyd是一个用于部署和运行scrapy爬虫的程序，它由 scrapy 官方提供的。它允许你通过JSON API来部署爬虫项目和控制爬虫运行。所谓json api本质就是post请求的webapi选择一台主机当做服务器，安装并启动 scrapyd 服务。再这之后，scrapyd 会以守护进程的方式存在系统中，监听爬虫地运行与请求，然后启动进程来执行爬虫程序。"
keywords: "python爬虫Scrapy(5)之增量式"
categories: ['Python']
tags: ['爬虫', 'Scrapy', 'Python']
artid: "146291746"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146291746
    alt: "python爬虫Scrapy5之增量式"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146291746
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146291746
cover: https://bing.ee123.net/img/rand?artid=146291746
image: https://bing.ee123.net/img/rand?artid=146291746
img: https://bing.ee123.net/img/rand?artid=146291746
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     python爬虫Scrapy(5)之增量式
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-tomorrow-night" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h4>
     <a id="_0">
     </a>
     增量式
    </h4>
    <ul>
     <li>
      <p>
       爬虫应用场景分类
      </p>
      <ul>
       <li>
        通用爬虫
       </li>
       <li>
        聚焦爬虫
       </li>
       <li>
        功能爬虫
       </li>
       <li>
        分布式爬虫
       </li>
       <li>
        增量式：
        <ul>
         <li>
          用来监测网站数据更新的情况（爬取网站最新更新出来的数据）。
         </li>
         <li>
          只是一种程序设计的思路，使用什么技术都是可以实现的。
         </li>
         <li>
          核心：
          <ul>
           <li>
            去重。
            <ul>
             <li>
              使用一个记录表来实现数据的去重：
              <ul>
               <li>
                记录表：存储爬取过的数据的记录
               </li>
               <li>
                如何构建和设计一个记录表：
                <ul>
                 <li>
                  记录表需要具备的特性：
                  <ul>
                   <li>
                    去重
                   </li>
                   <li>
                    需要持久保存的
                   </li>
                  </ul>
                 </li>
                 <li>
                  方案1：使用Python的set集合充当记录表？
                  <ul>
                   <li>
                    不可以的！因为set集合无法实现持久化存储
                   </li>
                  </ul>
                 </li>
                 <li>
                  方案2：使用redis的set集合充当记录表？
                  <ul>
                   <li>
                    可以的，因为redis的set既可以实现去重又可以进行数据的持久化存储。
                   </li>
                  </ul>
                 </li>
                </ul>
               </li>
              </ul>
             </li>
            </ul>
           </li>
          </ul>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li>
      <p>
       基于两个场景实现增量式爬虫：
      </p>
      <ul>
       <li>
        场景1：如果爬取的数据都是存储在当前网页中，没有深度的数据爬取的必要。
       </li>
       <li>
        场景2：爬取的数据存在于当前页和详情页中，具备深度爬取的必要。
       </li>
      </ul>
     </li>
     <li>
      <p>
       场景1的实现：
      </p>
      <ul>
       <li>
        <p>
         数据指纹：
        </p>
        <ul>
         <li>
          <p>
           数据的唯一标识。记录表中可以不直接存储数据本身，直接存储数据指纹更好一些。
          </p>
         </li>
         <li>
          <pre><code>#爬虫文件
import scrapy
import redis
from ..items import Zlsdemo1ProItem
class DuanziSpider(scrapy.Spider):
    name = 'duanzi'
    # allowed_domains = ['www.xxxx.com']
    start_urls = ['https://ishuo.cn/']
    #Redis的链接对象
    conn = redis.Redis(host='127.0.0.1',port=6379)

    def parse(self, response):
        li_list = response.xpath('//*[@id="list"]/ul/li')
        for li in li_list:
            content = li.xpath('./div[1]/text()').extract_first()
            title = li.xpath('./div[2]/a/text()').extract_first()
            all_data = title+content
            #生成该数据的数据指纹
            import hashlib  # 导入一个生成数据指纹的模块
            m = hashlib.md5()
            m.update(all_data.encode('utf-8'))
            data_id = m.hexdigest()

            ex = self.conn.sadd('data_id',data_id)
            if ex == 1:#sadd执行成功（数据指纹在set集合中不存在）
                print('有最新数据的更新，正在爬取中......')
                item = Zlsdemo1ProItem()
                item['title'] = title
                item['content'] = content
                yield item
            else:#sadd没有执行成功（数据指纹在set集合中存储）
                print('暂无最新数据更新，请等待......')
</code></pre>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li>
      <p>
       场景2的实现：
      </p>
      <ul>
       <li>
        <p>
         使用详情页的url充当数据指纹即可。
        </p>
       </li>
       <li>
        <pre><code class="prism language-python"><span class="token keyword">import</span> scrapy
<span class="token keyword">import</span> redis
<span class="token keyword">from</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>items <span class="token keyword">import</span> Zlsdemo2ProItem
<span class="token keyword">class</span> <span class="token class-name">JianliSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'jianli'</span>
    <span class="token comment"># allowed_domains = ['www.xxx.com']</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://sc.chinaz.com/jianli/free.html'</span><span class="token punctuation">]</span>
    conn <span class="token operator">=</span> redis<span class="token punctuation">.</span>Redis<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">'127.0.0.1'</span><span class="token punctuation">,</span>port<span class="token operator">=</span><span class="token number">6379</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        div_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@id="container"]/div'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> div <span class="token keyword">in</span> div_list<span class="token punctuation">:</span>
            title <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./p/a/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment">#充当数据指纹</span>
            detail_url <span class="token operator">=</span> <span class="token string">'https:'</span><span class="token operator">+</span>div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./p/a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            ex <span class="token operator">=</span> self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>sadd<span class="token punctuation">(</span><span class="token string">'data_id'</span><span class="token punctuation">,</span>detail_url<span class="token punctuation">)</span>
            item <span class="token operator">=</span> Zlsdemo2ProItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> title
            <span class="token keyword">if</span> ex <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'有最新数据的更新，正在采集......'</span><span class="token punctuation">)</span>
                <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>detail_url<span class="token punctuation">,</span>callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse_detail<span class="token punctuation">,</span>meta<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'item'</span><span class="token punctuation">:</span>item<span class="token punctuation">}</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'暂无数据更新！'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse_detail</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item <span class="token operator">=</span> response<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span>
        download_url <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@id="down"]/div[2]/ul/li[1]/a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">'download_url'</span><span class="token punctuation">]</span> <span class="token operator">=</span> download_url

        <span class="token keyword">yield</span> item
</code></pre>
       </li>
      </ul>
     </li>
    </ul>
    <h4>
     <a id="scrapy_106">
     </a>
     scrapy项目部署
    </h4>
    <h5>
     <a id="scrapyd_108">
     </a>
     scrapyd部署工具介绍
    </h5>
    <ul>
     <li>
      scrapyd是一个用于部署和运行scrapy爬虫的程序，它由 scrapy 官方提供的。它允许你通过JSON API来
      <strong>
       部署爬虫项目和控制爬虫运行
      </strong>
      。
     </li>
    </ul>
    <blockquote>
     <p>
      所谓json api本质就是post请求的webapi
     </p>
    </blockquote>
    <ul>
     <li>
      选择一台主机当做服务器，安装并启动 scrapyd 服务。再这之后，scrapyd 会以守护进程的方式存在系统中，监听爬虫地运行与请求，然后启动进程来执行爬虫程序。
     </li>
    </ul>
    <h5>
     <a id="_116">
     </a>
     环境安装
    </h5>
    <ul>
     <li>
      scrapyd服务:
     </li>
    </ul>
    <p>
     ​
     <code>
      pip install scrapyd
     </code>
    </p>
    <ul>
     <li>
      scrapyd客户端:
     </li>
    </ul>
    <p>
     ​
     <code>
      pip install scrapyd-client
     </code>
    </p>
    <p>
     ​ 一定要安装较新的版本10以上的版本，如果是现在安装的一般都是新版本
    </p>
    <h5>
     <a id="scrapyd_128">
     </a>
     启动scrapyd服务
    </h5>
    <ul>
     <li>
      <p>
       打开终端
       <strong>
        在scrapy项目路径下
       </strong>
       启动scrapyd的命令：
       <code>
        scrapyd
       </code>
      </p>
     </li>
     <li>
      <p>
       scrapyd 也提供了 web 的接口。方便我们查看和管理爬虫程序。默认情况下 scrapyd 监听 6800 端口，运行 scrapyd 后。在本机上使用浏览器访问
       <code>
        http://localhost:6800/
       </code>
       地址即可查看到当前可以运行的项目。
      </p>
     </li>
     <li>
      <p>
       点击job可以查看任务监控界面
      </p>
     </li>
    </ul>
    <h5>
     <a id="scrapy_142">
     </a>
     scrapy项目部署
    </h5>
    <h6>
     <a id="_144">
     </a>
     配置需要部署的项目
    </h6>
    <ul>
     <li>
      编辑需要部署的项目的scrapy.cfg文件(需要将哪一个爬虫部署到scrapyd中，就配置该项目的该文件)
     </li>
    </ul>
    <pre><code>[deploy:部署名(部署名可以自行定义)] 
url = http://localhost:6800/ 
project = 项目名(创建爬虫项目时使用的名称)

username = bobo # 如果不需要用户名可以不写
password = 123456 # 如果不需要密码可以不写
</code></pre>
    <h6>
     <a id="scrapyd_159">
     </a>
     部署项目到scrapyd
    </h6>
    <ul>
     <li>
      <p>
       同样在
       <strong>
        scrapy项目路径下
       </strong>
       执行如下指令：
      </p>
      <pre><code>scrapyd-deploy 部署名(配置文件中设置的名称) -p 项目名称
</code></pre>
     </li>
     <li>
      <p>
       部署成功之后就可以看到部署的项目
      </p>
     </li>
     <li>
      <p>
       使用以下命令检查部署爬虫结果：
      </p>
      <ul>
       <li>
        <pre><code class="prism language-text">scrapyd-deploy -L 部署名
</code></pre>
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <a id="scrapy_177">
     </a>
     管理scrapy项目
    </h5>
    <h6>
     <a id="_179">
     </a>
     指令管理
    </h6>
    <ul>
     <li>
      <p>
       安装curl命令行工具
      </p>
      <ul>
       <li>
        window需要安装
       </li>
       <li>
        linux和mac无需单独安装
       </li>
      </ul>
     </li>
     <li>
      <p>
       window安装步骤：
      </p>
      <ul>
       <li>
        <p>
         下载curl文件：https://curl.se/download.html，打开网页后向下拖动，找到window系统对应版本下载
        </p>
       </li>
       <li>
        <p>
         下载后，放置到一个无中文的文件夹下直接解压缩，解压后将bin文件夹配置环境变量！
        </p>
       </li>
       <li>
        <p>
         参考网页：https://www.cnblogs.com/lisa2016/p/12193494.html
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       启动项目：
      </p>
      <pre><code>curl http://localhost:6800/schedule.json -d project=项目名 -d spider=爬虫名
</code></pre>
      <ul>
       <li>
        <p>
         返回结果：注意期中的jobid，在关闭项目时候会用到
        </p>
        <ul>
         <li>
          <pre><code>{"status": "ok", "jobid": "94bd8ce041fd11e6af1a000c2969bafd", "node_name": "james-virtual-machine"}
</code></pre>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li>
      <p>
       关闭项目：
      </p>
      <ul>
       <li>
        <pre><code>curl http://localhost:6800/cancel.json -d project=项目名 -d job=项目的jobid
</code></pre>
       </li>
      </ul>
     </li>
     <li>
      <p>
       删除爬虫项目：
      </p>
      <ul>
       <li>
        <pre><code>curl http://localhost:6800/delproject.json -d project=爬虫项目名称
</code></pre>
       </li>
      </ul>
     </li>
    </ul>
    <h6>
     <a id="requestsscrapy_219">
     </a>
     requests模块控制scrapy项目
    </h6>
    <pre><code class="prism language-python"><span class="token keyword">import</span> requests

<span class="token comment"># 启动爬虫</span>
url <span class="token operator">=</span> <span class="token string">'http://localhost:6800/schedule.json'</span>
data <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
	<span class="token string">'project'</span><span class="token punctuation">:</span> 项目名<span class="token punctuation">,</span>
	<span class="token string">'spider'</span><span class="token punctuation">:</span> 爬虫名<span class="token punctuation">,</span>
<span class="token punctuation">}</span>
resp <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>url<span class="token punctuation">,</span> data<span class="token operator">=</span>data<span class="token punctuation">)</span>

<span class="token comment"># 停止爬虫</span>
url <span class="token operator">=</span> <span class="token string">'http://localhost:6800/cancel.json'</span>
data <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
	<span class="token string">'project'</span><span class="token punctuation">:</span> 项目名<span class="token punctuation">,</span>
	<span class="token string">'job'</span><span class="token punctuation">:</span> 启动爬虫时返回的jobid<span class="token punctuation">,</span>
<span class="token punctuation">}</span>
resp <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>url<span class="token punctuation">,</span> data<span class="token operator">=</span>data<span class="token punctuation">)</span>

</code></pre>
    <h4>
     <a id="_244">
     </a>
     生产者消费者模式
    </h4>
    <h5>
     <a id="_246">
     </a>
     认识生产者和消费者模式
    </h5>
    <p>
     生产者和消费者是异步爬虫中很常见的一个问题。产生数据的模块，我们称之为生产者，而处理数据的模块，就称为消费者。
    </p>
    <p>
     例如：
    </p>
    <p>
     ​ 图片数据爬取中，解析出图片链接的操作就是在生产数据
    </p>
    <p>
     ​ 对图片链接发起请求下载图片的操作就是在消费数据
    </p>
    <h5>
     <a id="_256">
     </a>
     为什么要使用生产者和消费者模式
    </h5>
    <blockquote>
     <p>
      ​ 在异步世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这个问题于是引入了生产者和消费者模式。
     </p>
    </blockquote>
    <pre><code class="prism language-python"><span class="token keyword">import</span> requests
<span class="token keyword">import</span> threading
<span class="token keyword">from</span> lxml <span class="token keyword">import</span> etree
<span class="token keyword">from</span> queue <span class="token keyword">import</span> Queue
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> urlretrieve
<span class="token keyword">from</span> time <span class="token keyword">import</span> sleep
headers <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">"User-Agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36"</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span>

<span class="token comment">#生产数据：解析提取图片地址</span>
<span class="token keyword">class</span> <span class="token class-name">Producer</span><span class="token punctuation">(</span>threading<span class="token punctuation">.</span>Thread<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#生产者线程</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>page_queue<span class="token punctuation">,</span>img_queue<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>page_queue <span class="token operator">=</span> page_queue
        self<span class="token punctuation">.</span>img_queue <span class="token operator">=</span> img_queue
    <span class="token keyword">def</span> <span class="token function">run</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>page_queue<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Producer任务结束'</span><span class="token punctuation">)</span>
                <span class="token keyword">break</span>
            <span class="token comment">#从page_queue中取出一个页码链接</span>
            url <span class="token operator">=</span> self<span class="token punctuation">.</span>page_queue<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment">#从当前的页码对应的页面中解析出更多的图片地址</span>
            self<span class="token punctuation">.</span>parse_detail<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">parse_detail</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>
        response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span>headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>
        response<span class="token punctuation">.</span>encoding <span class="token operator">=</span> <span class="token string">'gbk'</span>
        page_text <span class="token operator">=</span> response<span class="token punctuation">.</span>text
        tree <span class="token operator">=</span> etree<span class="token punctuation">.</span>HTML<span class="token punctuation">(</span>page_text<span class="token punctuation">)</span>
        li_list <span class="token operator">=</span> tree<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@id="main"]/div[3]/ul/li'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> li <span class="token keyword">in</span> li_list<span class="token punctuation">:</span>
            img_src <span class="token operator">=</span> <span class="token string">'https://pic.netbian.com'</span><span class="token operator">+</span>li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./a/img/@src'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            img_title <span class="token operator">=</span> li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./a/b/text()'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">'.jpg'</span>
            dic <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
                <span class="token string">'title'</span><span class="token punctuation">:</span>img_title<span class="token punctuation">,</span>
                <span class="token string">'src'</span><span class="token punctuation">:</span>img_src
            <span class="token punctuation">}</span>
            self<span class="token punctuation">.</span>img_queue<span class="token punctuation">.</span>put<span class="token punctuation">(</span>dic<span class="token punctuation">)</span>

<span class="token comment">#消费数据：对图片地址进行数据请求</span>
<span class="token keyword">class</span> <span class="token class-name">Consumer</span><span class="token punctuation">(</span>threading<span class="token punctuation">.</span>Thread<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#消费者线程</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>page_queue<span class="token punctuation">,</span>img_queue<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>page_queue <span class="token operator">=</span> page_queue
        self<span class="token punctuation">.</span>img_queue <span class="token operator">=</span> img_queue
    <span class="token keyword">def</span> <span class="token function">run</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>img_queue<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">and</span> self<span class="token punctuation">.</span>page_queue<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Consumer任务结束'</span><span class="token punctuation">)</span>
                <span class="token keyword">break</span>
            dic <span class="token operator">=</span> self<span class="token punctuation">.</span>img_queue<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
            title <span class="token operator">=</span> dic<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span>
            src <span class="token operator">=</span> dic<span class="token punctuation">[</span><span class="token string">'src'</span><span class="token punctuation">]</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>src<span class="token punctuation">)</span>
            urlretrieve<span class="token punctuation">(</span>src<span class="token punctuation">,</span><span class="token string">'imgs/'</span><span class="token operator">+</span>title<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>title<span class="token punctuation">,</span><span class="token string">'下载完毕！'</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#该队列中存储即将要要去的页面页码链接</span>
    page_queue <span class="token operator">=</span> Queue<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>
    <span class="token comment">#该队列存储生产者生产出来的图片地址</span>
    img_queue <span class="token operator">=</span> Queue<span class="token punctuation">(</span><span class="token number">60</span><span class="token punctuation">)</span>

    <span class="token comment">#该循环可以将2，3，4这三个页码链接放入page_queue中</span>
    <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        url <span class="token operator">=</span> <span class="token string">'https://pic.netbian.com/4kmeinv/index_%d.html'</span><span class="token operator">%</span>x
        page_queue<span class="token punctuation">.</span>put<span class="token punctuation">(</span>url<span class="token punctuation">)</span>

    <span class="token comment">#生产者</span>
    <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        t <span class="token operator">=</span> Producer<span class="token punctuation">(</span>page_queue<span class="token punctuation">,</span>img_queue<span class="token punctuation">)</span>
        t<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">#消费者</span>
    <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        t <span class="token operator">=</span> Consumer<span class="token punctuation">(</span>page_queue<span class="token punctuation">,</span>img_queue<span class="token punctuation">)</span>
        t<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>

main<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f37303136313135382f:61727469636c652f64657461696c732f313436323931373436" class_="artid" style="display:none">
 </p>
</div>


