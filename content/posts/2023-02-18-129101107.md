---
layout: post
title: 三维重建开源项目大汇总
date: 2023-02-18 15:58:39 +0800
categories: ['Slam']
tags: ['计算机视觉', '开源', '人工智能']
image:
    path: https://img-blog.csdnimg.cn/img_convert/39b0e06f03c2763df40d89eb365d9938.png?x-oss-process=image/resize,m_fixed,h_150
    alt: 三维重建开源项目大汇总
artid: 129101107
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=129101107
featuredImagePreview: https://bing.ee123.net/img/rand?artid=129101107
---
<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     三维重建开源项目大汇总
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     <strong>
      1. Meshroom
     </strong>
    </h2>
    <p>
     Meshroom是一款基于AliceVision摄影测量计算机视觉框架的免费开源三维重建软件。
    </p>
    <p>
     <img alt="" height="355" src="https://i-blog.csdnimg.cn/direct/fc93ea779f4d4d9fa9c7672b7a416676.png" width="772"/>
    </p>
    <p>
     <a href="https://github.com/alicevision/meshroom" title="GitHub - alicevision/Meshroom: 3D Reconstruction Software">
      GitHub - alicevision/Meshroom: 3D Reconstruction Software
     </a>
    </p>
    <h2>
     <strong>
      2. OpenMVG
     </strong>
    </h2>
    <p>
     OpenMVG库根据三维计算机视觉和结构的运动。OpenMVG提供了一个端到端的3D重建，它由图像框架组成，包含库、二进制文件和管道。
    </p>
    <ul>
     <li>
      <p>
       这些库提供了简单的功能，如：图像处理，功能描述和匹配，功能跟踪，相机模型，多视图几何，旋转估计…
      </p>
     </li>
     <li>
      <p>
       该二进制文件解决了管道可能需要的单元任务：场景初始化、特征检测与匹配和运动重建的结构，并将重建的场景导出到其他多视点立体视觉框架中，以计算密集的点云或纹理网格。
      </p>
     </li>
     <li>
      <p>
       这些管道通过链接各种二进制文件来计算图像匹配关系
      </p>
     </li>
    </ul>
    <p>
     OpenMVG是用C++开发的，可以在Android、iOS、Linux、macOS和Windows上运行。
    </p>
    <p>
     <a href="https://github.com/openMVG/openMVG" title="GitHub - openMVG/openMVG: open Multiple View Geometry library. Basis for 3D computer vision and Structure from Motion.">
      GitHub - openMVG/openMVG: open Multiple View Geometry library. Basis for 3D computer vision and Structure from Motion.
     </a>
    </p>
    <h2>
     <strong>
      3.
     </strong>
     <strong>
      Awesome_3dreconstruction_list
     </strong>
    </h2>
    <p>
     与图像3D重建相关的论文和资源精选清单
    </p>
    <p>
     <a href="https://github.com/openMVG/awesome_3DReconstruction_list" title="GitHub - openMVG/awesome_3DReconstruction_list: A curated list of papers &amp; resources linked to 3D reconstruction from images.">
      GitHub - openMVG/awesome_3DReconstruction_list: A curated list of papers &amp; resources linked to 3D reconstruction from images.
     </a>
    </p>
    <h2>
     <strong>
      4. Awesome Point Cloud Analysis
     </strong>
    </h2>
    <p>
     关于点云分析(处理)的论文和数据集列表
    </p>
    <p>
     <a href="https://github.com/Yochengliu/awesome-point-cloud-analysis" title="GitHub - Yochengliu/awesome-point-cloud-analysis: A list of papers and datasets about point cloud analysis (processing)">
      GitHub - Yochengliu/awesome-point-cloud-analysis: A list of papers and datasets about point cloud analysis (processing)
     </a>
    </p>
    <h2>
     <strong>
      5.
     </strong>
     OpenSfM
    </h2>
    <p>
     OpenSfM是一个用Python编写的运动库的结构。该库作为一个处理管道，用于从多个图像重建相机姿态和3D场景。它由运动结构的基本模块（特征检测/匹配，最小解算）组成，重点是构建一个健壮的、可伸缩的重建管道。它还集成了外部传感器（如GPS、加速计）测量，以实现地理定位和鲁棒性。提供了一个JavaScript查看器来预览模型和调试管道。
    </p>
    <p>
     <img alt="" height="500" src="https://i-blog.csdnimg.cn/direct/3c405b2315084a89b7f48d2c701f526d.png" width="799"/>
    </p>
    <p>
     <a href="https://github.com/mapillary/OpenSfM" title="GitHub - mapillary/OpenSfM: Open source Structure-from-Motion pipeline">
      GitHub - mapillary/OpenSfM: Open source Structure-from-Motion pipeline
     </a>
    </p>
    <h2>
     <strong>
      6. Alicevision
     </strong>
    </h2>
    <p class="img-center">
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/8797045d3822e40d4be17d365f8c5787.png"/>
    </p>
    <p>
     AliceVision是摄影测量计算机视觉框架，可提供3D重建和相机跟踪算法。AliceVision旨在通过可测试，分析和重用的最新计算机视觉算法提供强大的软件基础。该项目是学术界和工业界合作的结果，旨在为尖端算法提供鲁棒性和生产使用所需的质量。
    </p>
    <p>
     <a href="https://github.com/alicevision/AliceVision" title="GitHub - alicevision/AliceVision: Photogrammetric Computer Vision Framework">
      GitHub - alicevision/AliceVision: Photogrammetric Computer Vision Framework
     </a>
    </p>
    <h2>
     <strong>
      7.
     </strong>
     OpenMVS
     <strong>
     </strong>
    </h2>
    <p>
     OpenMVS是面向计算机视觉的库，尤其是针对多视图立体重建社区的。尽管有针对运动结构管道（例如OpenMVG）的成熟而完整的开源项目，这些管道可以从输入的图像集中恢复相机的姿势和稀疏的3D点云，但没有一个解决摄影测量链的最后一部分-流。OpenMVS旨在通过提供一套完整的算法来恢复要重建场景的整个表面来填补这一空白。输入是一组摄影机姿势加上稀疏的点云，输出是带纹理的网格。该项目涉及的主要主题是：
    </p>
    <ul>
     <li>
      <p>
       密集的点云重构，以获得尽可能完整，准确的点云
      </p>
     </li>
     <li>
      <p>
       网格重建，用于估计最能解释输入点云的网格表面
      </p>
     </li>
     <li>
      <p>
       网格细化可恢复所有精细细节
      </p>
     </li>
     <li>
      <p>
       网格纹理，用于计算清晰准确的纹理以对网格着色
      </p>
     </li>
    </ul>
    <p>
     <a href="https://github.com/cdcseacave/openMVS" title="GitHub - cdcseacave/openMVS: open Multi-View Stereo reconstruction library">
      GitHub - cdcseacave/openMVS: open Multi-View Stereo reconstruction library
     </a>
    </p>
    <h2>
     <strong>
      8. Bundler_sfm
     </strong>
    </h2>
    <p>
     Bundler和CMVS-PMVS是进行多视图三维重建的一套非常有用的工具包。Bundler利用一系列无序图片生成场景的稀疏点云，并且估计每一幅图片的相机参数（内参和外参）。CMVS-PMVS可以利用已知图片以及图片对应相机参数（使用Bundler求得）来进行稠密的三维重建（dense reconstruction）。
    </p>
    <p>
     <a href="https://github.com/snavely/bundler_sfm" title="GitHub - snavely/bundler_sfm: Bundler Structure from Motion Toolkit">
      GitHub - snavely/bundler_sfm: Bundler Structure from Motion Toolkit
     </a>
    </p>
    <h2>
     <strong>
      9. Bundlefusion
     </strong>
    </h2>
    <p class="img-center">
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/39818b89968272b62c5b0fd23ce1cf32.jpeg"/>
    </p>
    <p>
     使用在线表面重新整合进行实时全局一致的三维重建
    </p>
    <p>
     <a href="https://github.com/niessner/BundleFusion" title="GitHub - niessner/BundleFusion: [Siggraph 2017] BundleFusion: Real-time Globally Consistent 3D Reconstruction using Online Surface Re-integration">
      GitHub - niessner/BundleFusion: [Siggraph 2017] BundleFusion: Real-time Globally Consistent 3D Reconstruction using Online Surface Re-integration
     </a>
    </p>
    <h2>
     <strong>
      10. Scannet
     </strong>
    </h2>
    <p>
     ScanNet是一个RGB-D视频数据集，包含超过1500次扫描中的250万次视图，使用3D摄像机姿态、表面重建和实例级语义分段进行注释。
    </p>
    <p>
     <a href="https://github.com/ScanNet/ScanNet" title="GitHub - ScanNet/ScanNet">
      GitHub - ScanNet/ScanNet
     </a>
    </p>
    <h2>
     <strong>
      11. Softras
     </strong>
    </h2>
    <p>
     SoftRas是一个真正的可微分渲染框架，把渲染作为一个可微分的聚合过程，融合所有网格三角形的概率贡献相对于渲染像素。
    </p>
    <p>
     <a href="https://github.com/ShichenLiu/SoftRas" title='GitHub - ShichenLiu/SoftRas: Project page of paper "Soft Rasterizer: A Differentiable Renderer for Image-based 3D Reasoning"'>
      GitHub - ShichenLiu/SoftRas: Project page of paper "Soft Rasterizer: A Differentiable Renderer for Image-based 3D Reasoning"
     </a>
    </p>
    <h2>
     <strong>
      12. Pifu
     </strong>
    </h2>
    <p>
     PIFu这篇工作是由 USC lihao 团队完成，被ICCV 2019接收为Oral。该论文提出了一种Pixel-aligned Implicit Function(PIFu)的隐式表达，该表达将2D图像中的像素和该像素对应的人体的3D信息进行关联。使用PIFu，该文提出了一种端到端的基于深度学习的方法（之后称作PIFu），输入是人体单张2D图片和
     <strong>
      对应的人体Mask图片
     </strong>
     ，输出人体的三维模型和三维模型对应的纹理信息（即三维模型中每个顶点的RGB信息）。另外PIFu可以扩展到任意个视角的情况，但是在这种情况下，需要知道所使用视角对应的相机内外参。
    </p>
    <p class="img-center">
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/03fc4c0ad15b47e8473aa4ac7e6b01d9.png"/>
    </p>
    <p>
     <a href="https://github.com/shunsukesaito/PIFu" title='GitHub - shunsukesaito/PIFu: This repository contains the code for the paper "PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization"'>
      GitHub - shunsukesaito/PIFu: This repository contains the code for the paper "PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization"
     </a>
    </p>
    <h2>
     <strong>
      13. Matterport
     </strong>
    </h2>
    <p>
     用于RGB-D机器学习任务的非常棒的数据集。
    </p>
    <p>
     <a href="https://github.com/niessner/Matterport" title="GitHub - niessner/Matterport: Matterport3D is a pretty awesome dataset for RGB-D machine learning tasks :)">
      GitHub - niessner/Matterport: Matterport3D is a pretty awesome dataset for RGB-D machine learning tasks :)
     </a>
    </p>
    <h2>
     <strong>
      14. Kimera
     </strong>
    </h2>
    <p>
     Kimera是一个用于实时度量-语义同步定位和映射的C++库，它使用摄像机图像和惯性数据来构建环境的语义注释3D网格。Kimera是模块化的，支持ros，在CPU上运行。
    </p>
    <p>
     <a href="https://github.com/MIT-SPARK/Kimera" title="GitHub - MIT-SPARK/Kimera: Index repo for Kimera code">
      GitHub - MIT-SPARK/Kimera: Index repo for Kimera code
     </a>
    </p>
    <h2>
     <strong>
      15.
     </strong>
     <strong>
      Mvs Texturing
     </strong>
    </h2>
    <p>
     项目可以根据图像对3D重建进行纹理处理。该项目专注于使用运动和多视图立体技术的结构生成的3D重建。
    </p>
    <p>
     <a href="https://github.com/nmoehrle/mvs-texturing" title="GitHub - nmoehrle/mvs-texturing: Algorithm to texture 3D reconstructions from multi-view stereo images">
      GitHub - nmoehrle/mvs-texturing: Algorithm to texture 3D reconstructions from multi-view stereo images
     </a>
    </p>
    <h2>
     <strong>
      16. Livescan3d
     </strong>
    </h2>
    <p>
     LiveScan3D是一个实时三维重建系统，使用多个Kinect v2深度传感器同时进行三维重建。产生的3D重建形式是有色点云的形式，所有Kinect的点都放置在同一坐标系中。该系统的可能使用场景包括：
    </p>
    <ul>
     <li>
      <p>
       同时从多个视点捕获对象的3D结构
      </p>
     </li>
     <li>
      <p>
       捕获场景的“全景” 3D结构（通过使用多个传感器来扩展一个传感器的视场）
      </p>
     </li>
     <li>
      <p>
       将重建的点云流式传输到远程位置
      </p>
     </li>
     <li>
      <p>
       通过让多个传感器捕获同一场景来提高单个传感器捕获的点云的密度
      </p>
     </li>
    </ul>
    <p>
     <a href="https://github.com/MarekKowalski/LiveScan3D" title="GitHub - MarekKowalski/LiveScan3D: LiveScan3D is a system designed for real time 3D reconstruction using multiple Azure Kinect or Kinect v2 depth sensors simultaneously at real time speed.">
      GitHub - MarekKowalski/LiveScan3D: LiveScan3D is a system designed for real time 3D reconstruction using multiple Azure Kinect or Kinect v2 depth sensors simultaneously at real time speed.
     </a>
    </p>
    <h2>
     <strong>
      17. Voxelhashing
     </strong>
    </h2>
    <p>
     Voxel Hashing的特点
    </p>
    <p>
     能够有效的压缩T-SDF的体积，在无需分层空间的数据结构的同时，保证表面的分辨率通过插入和更新操作，能够有效的把新的T-SDF数据融合到哈希表中，同时最小化哈希冲突在清理无效的体素块时，不需要重组数据结构，避免了巨大的开销在主机和GPU之间构建了轻量级的双向流，支持无边界重建通过标准光线投射和多边形操作，从数据结构中提取出等值面，以进行渲染和相机位姿估计
    </p>
    <p>
     <a href="https://github.com/niessner/VoxelHashing" title="GitHub - niessner/VoxelHashing: [Siggraph Asia 2013] Large-Scale, Real-Time 3D Reconstruction">
      GitHub - niessner/VoxelHashing: [Siggraph Asia 2013] Large-Scale, Real-Time 3D Reconstruction
     </a>
    </p>
    <h2>
     <strong>
      18. Layoutnet
     </strong>
    </h2>
    <p>
     从单个RGB图像重建三维房间布局
    </p>
    <p>
     创新点：
    </p>
    <ul>
     <li>
      提出了根据 RGB 图像推断出布局的算法与LayoutNet网络，它适用于曼哈顿布局的透视图和全景图。基于消失点对齐全景图像之后，利用深度网络直接预测边界与角落和边界。通过预测的角落与边界图，利用几何约束生成3维布局。
     </li>
     <li>
      通过添加目标函数以直接回归 3D布局参数，从而更好地预测用于最终解决布局预测问题的边界和角落图。
     </li>
     <li>
      扩展了斯坦福「2D-3D」数据集的注释，提供了可用于后续工作的房间布局注释。
     </li>
    </ul>
    <p class="img-center">
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/800dde15874c18235b2de6b04b46d01a.png"/>
    </p>
    <p>
     <a href="https://github.com/zouchuhang/LayoutNet" title='GitHub - zouchuhang/LayoutNet: Torch implementation of our CVPR 18 paper: "LayoutNet: Reconstructing the 3D Room Layout from a Single RGB Image"'>
      GitHub - zouchuhang/LayoutNet: Torch implementation of our CVPR 18 paper: "LayoutNet: Reconstructing the 3D Room Layout from a Single RGB Image"
     </a>
    </p>
    <h2>
     <strong>
      19.
     </strong>
     <strong>
      Tsdf Fusion Python
     </strong>
    </h2>
    <p>
     这是一个轻量级的python脚本，可将多个颜色和深度图像融合到TSDF体积中，然后可以将其用于创建高质量的3D表面网格和点云。在Ubuntu 16.04上测试效果如下图：
    </p>
    <p class="img-center">
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/d6ba3014d6ce9b380abe23209e8fef9e.png"/>
    </p>
    <p>
     <a href="https://github.com/andyzeng/tsdf-fusion-python" title="GitHub - andyzeng/tsdf-fusion-python: Python code to fuse multiple RGB-D images into a TSDF voxel volume.">
      GitHub - andyzeng/tsdf-fusion-python: Python code to fuse multiple RGB-D images into a TSDF voxel volume.
     </a>
    </p>
    <h2>
     <strong>
      20. Intrinsic3d
     </strong>
    </h2>
    <p>
     通过外观和几何优化以及空间变化的照明实现高质量3D重构
    </p>
    <p class="img-center">
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/317ca9f96b8ec52ae7414b707814a3ee.png"/>
    </p>
    <p>
     <a href="https://github.com/NVlabs/intrinsic3d" title="GitHub - NVlabs/intrinsic3d: Intrinsic3D - High-Quality 3D Reconstruction by Joint Appearance and Geometry Optimization with Spatially-Varying Lighting (ICCV 2017)">
      GitHub - NVlabs/intrinsic3d: Intrinsic3D - High-Quality 3D Reconstruction by Joint Appearance and Geometry Optimization with Spatially-Varying Lighting (ICCV 2017)
     </a>
    </p>
    <h2>
     <strong>
      21. Kimera Semantics
     </strong>
    </h2>
    <p>
     从2D数据进行实时3D语义重构
    </p>
    <p class="img-center">
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/a07aca2de7144b227de066f739e39e05.png"/>
    </p>
    <p>
     <a href="https://github.com/MIT-SPARK/Kimera-Semantics" title="GitHub - MIT-SPARK/Kimera-Semantics: Real-Time 3D Semantic Reconstruction from 2D data">
      GitHub - MIT-SPARK/Kimera-Semantics: Real-Time 3D Semantic Reconstruction from 2D data
     </a>
    </p>
    <h2>
     <strong>
      22. Awesome Holistic 3d
     </strong>
    </h2>
    <p>
     3D重建的论文和资源清单：
    </p>
    <p>
     <a href="https://github.com/holistic-3d/awesome-holistic-3d" title="GitHub - holistic-3d/awesome-holistic-3d: A list of papers and resources (data,code,etc) for holistic 3D reconstruction in computer vision">
      GitHub - holistic-3d/awesome-holistic-3d: A list of papers and resources (data,code,etc) for holistic 3D reconstruction in computer vision
     </a>
    </p>
    <h2>
     <strong>
      23. 3dreconstruction
     </strong>
    </h2>
    <p>
     使用Python3进行SFM的3D重建
    </p>
    <p>
     <a href="https://github.com/alyssaq/3Dreconstruction" title="GitHub - alyssaq/3Dreconstruction: 3D reconstruction, sfm with Python3">
      GitHub - alyssaq/3Dreconstruction: 3D reconstruction, sfm with Python3
     </a>
    </p>
    <h2>
     <strong>
      24. Structured3d
     </strong>
    </h2>
    <p>
     用于结构化3D建模的大型照片级数据集
    </p>
    <p class="img-center">
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/dd38e22909948151c0ab4c0db908f3fe.png"/>
    </p>
    <p>
     <a href="https://github.com/bertjiazheng/Structured3D" title="GitHub - bertjiazheng/Structured3D: [ECCV'20] Structured3D: A Large Photo-realistic Dataset for Structured 3D Modeling">
      GitHub - bertjiazheng/Structured3D: [ECCV'20] Structured3D: A Large Photo-realistic Dataset for Structured 3D Modeling
     </a>
    </p>
    <h2>
     <strong>
      25. Synthesize3dviadepthorsil
     </strong>
    </h2>
    <p>
     通过对多视图深度图或轮廓建模来生成和重建3D形状
    </p>
    <p class="img-center">
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/307073b3e3c5b6a415e21c48a3e6b4c3.png"/>
    </p>
    <p>
     <a href="https://github.com/Amir-Arsalan/Synthesize3DviaDepthOrSil" title="GitHub - Amir-Arsalan/Synthesize3DviaDepthOrSil: [CVPR 2017] Generation and reconstruction of 3D shapes via modeling multi-view depth maps or silhouettes">
      GitHub - Amir-Arsalan/Synthesize3DviaDepthOrSil: [CVPR 2017] Generation and reconstruction of 3D shapes via modeling multi-view depth maps or silhouettes
     </a>
    </p>
    <h2>
     <strong>
      26. Msn Point Cloud Completion
     </strong>
    </h2>
    <p class="img-center">
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/137d43e3cef186c374961dcf8815f4fd.jpeg"/>
    </p>
    <p>
     <a href="https://github.com/Colin97/MSN-Point-Cloud-Completion" title="GitHub - Colin97/MSN-Point-Cloud-Completion: Morphing and Sampling Network for Dense Point Cloud Completion (AAAI2020)">
      GitHub - Colin97/MSN-Point-Cloud-Completion: Morphing and Sampling Network for Dense Point Cloud Completion (AAAI2020)
     </a>
    </p>
    <h2>
     <strong>
      27. Cnncomplete
     </strong>
    </h2>
    <p>
     用于训练体积深层神经网络以完成部分扫描的3D形状的代码
    </p>
    <p class="img-center">
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/0417dcb42213dfcc669a2b6ba7e2196b.png"/>
    </p>
    <p>
     <a href="https://github.com/angeladai/cnncomplete" title="GitHub - angeladai/cnncomplete: [CVPR'17] Shape Completion using 3D-Encoder-Predictor CNNs and Shape Synthesis">
      GitHub - angeladai/cnncomplete: [CVPR'17] Shape Completion using 3D-Encoder-Predictor CNNs and Shape Synthesis
     </a>
    </p>
    <h2>
     <strong>
      28. Reconstructiondataset
     </strong>
    </h2>
    <p>
     用于进行三维重建的一组图像
    </p>
    <p>
     <a href="https://github.com/rperrot/ReconstructionDataSet" title="GitHub - rperrot/ReconstructionDataSet: Set of images for doing 3d reconstruction">
      GitHub - rperrot/ReconstructionDataSet: Set of images for doing 3d reconstruction
     </a>
    </p>
    <h2>
     <strong>
      29. 3d Recgan Extended
     </strong>
    </h2>
    <p>
     从单个深度视图进行密集的3D对象重建
    </p>
    <p>
     <a href="https://github.com/Yang7879/3D-RecGAN-extended" title="GitHub - Yang7879/3D-RecGAN-extended: 🔥3D-RecGAN++ in Tensorflow (TPAMI 2018)">
      GitHub - Yang7879/3D-RecGAN-extended: 🔥3D-RecGAN++ in Tensorflow (TPAMI 2018)
     </a>
    </p>
    <h2>
     参考文献
    </h2>
    <p>
     <a href="https://zhuanlan.zhihu.com/p/617362102" rel="nofollow" title="一篇文章教你学会使用三维重建知名开源系统 - 知乎">
      一篇文章教你学会使用三维重建知名开源系统 - 知乎
     </a>
    </p>
    <p>
     <a href="https://zhuanlan.zhihu.com/p/148509062?utm_source=wechat_session" rel="nofollow" title="论文解读 | PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization - 知乎">
      论文解读 | PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization - 知乎
     </a>
    </p>
    <p>
     <a href="https://blog.csdn.net/heiyaheiya/article/details/90754689" title="Layout网络阅读笔记_神经网络layout-CSDN博客">
      Layout网络阅读笔记_神经网络layout-CSDN博客
     </a>
    </p>
   </div>
  </div>
 </article>
</div>


