---
layout: post
title: "ModelScope概述与实战"
date: 2025-09-06T23:56:35+0800
description: "概述：Web、模型下载及使用、MS Hub、MS-SWIFT、MS-EvalScope、MS-Agent、数据集"
keywords: "ModelScope概述与实战"
categories: ['Llm']
tags: ['语言模型']
artid: "150858341"
arturl: "https://blog.csdn.net/lonelymanontheway/article/details/150858341"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=150858341
    alt: "ModelScope概述与实战"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=150858341
featuredImagePreview: https://bing.ee123.net/img/rand?artid=150858341
cover: https://bing.ee123.net/img/rand?artid=150858341
image: https://bing.ee123.net/img/rand?artid=150858341
img: https://bing.ee123.net/img/rand?artid=150858341
---



# ModelScope概述与实战


[#王者杯·14天创作挑战营·第5期#](https://activity.csdn.net/writing?id=10949)

## 概述

ModelScope，简称MS，魔搭社区，由阿里巴巴达摩院推出的一个多任务、多模态的预训练模型开放平台，提供模型下载与运行、数据集管理、在线推理体验、开发者社区交流等一站式服务，支持多种主流框架（如PyTorch、Transformers）。整体上它的定位类似于HuggingFace(HF)，但在多模态支持、国产模型整合和本地化适配方面做得更加贴近国内开发者的使用需求。

### Web

https://modelscope.cn/home，很奇怪为啥不能注册：  
 ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/2a1b80f30dc048aabb0653c28be69352.png)

### 模型下载及使用

下载模型的两种方式：

```bash
# 命令行
modelscope download --model="Qwen/Qwen2.5-0.5B-Instruct" --local_dir ./model-dir
# Python SDK，支持更多个性化配置，如只下载特定文件、跳过某些组件等
from modelscope.hub.snapshot_download import snapshot_download
model_dir = snapshot_download('Qwen/Qwen2.5-0.5B-Instruct', local_dir = './model-dir')

```

实例：

```py
from modelscope import AutoModelForCausalLM, AutoTokenizer

model_name = "输入本地文件夹路径"
# 从预训练模型加载因果语言模型和分词器
# 模型会根据可用硬件自动选择精度（torch_dtype="auto"）并进行设备分配（device_map="auto"）
model = AutoModelForCausalLM.from_pretrained(
	model_name,
	torch_dtype="auto",
	device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# 构建对话历史，包含系统角色和用户角色的消息
messages = [
	{"role": "system", "content": "你是一个有用的助手"}, # 系统消息设定助手的行为模式
	{"role": "user", "content": "请简单介绍一下大语言模型"}
]

# 将对话历史转换为模型可接受的文本格式
text = tokenizer.apply_chat_template(
	messages,
	tokenize=False, # 表示不直接分词，而是保留文本形式
	add_generation_prompt=True # 添加模型特定的生成提示标记
)
# 使用分词器将文本转换为模型所需的张量格式，并移至与模型相同的设备
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

# 模型生成回答
generated_ids = model.generate(
	**model_inputs,
	max_new_tokens=512
)
# 从生成的token ID序列中提取出模型生成的部分（去掉输入部分）
generated_ids = [
	output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]
# 将生成的token ID序列解码为文本，并跳过特殊标记（如填充标记、结束标记等）
response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)

```

### MS Hub

即ModelScope的模型库，共享机器学习模型、demo演示、数据集和数据指标的地方。

模型公开属性：

* 公开模型：社区所有人可见、可下载；
* 非公开模型：私有模型，仅组织成员或模型所有者可见、可下载；
* 申请制模型：任意用户均可在按照要求发起申请、并经模型所有者审批同意后可见、可下载。

### MS-SWIFT

Scalable lightWeight Infrastructure for Fine-Tuning，魔搭社区推出的一套完整的轻量级量化、训练、推理、评估、部署工具。支持200+LLM、15+多模态大模型、10+轻量化Tuners，支持消费级显卡玩转LLM和AIGC。

特性：

* 具备SOTA特性的Efficient Tuners：可结合LLM在商业级显卡上实现轻量级训练和推理。
* 使用MS Hub的Trainer：基于Transformers Trainer提供，支持LLM训练，且能将训练后的模型上传到MS Hub中。
* 可运行的模型Examples：针对热门大模型提供训练脚本和推理脚本，同时针对热门开源数据集提供预处理逻辑，可直接运行使用。
* 支持界面化训练和推理：基于Gradio Web界面，简化大模型全链路流程。

安装

```bash
pip install ms-swift
# 或pip install git+https://github.com/modelscope/ms-swift.git，或
git clone https://github.com/modelscope/ms-swift.git
cd ms-swift
pip install -e .

```

微调数据集示例：

```json
{"messages": [{"role": "user", "content": "浙江的省会在哪？"}, {"role": "assistant", "content": "<think>\nxxx\n</think>\n\n浙江的省会在杭州。"}]}

```

GRPO训练数据集示例：

* LLM类型：

```json
{"messages": [{"role": "user", "content": "What is your name?"}]}

```

* MLLM类型：

```json
{"messages": [{"role": "user", "content": "<image><image>What is the difference between the two images?"}], "images": ["/xxx/y.jpg", "/xxx/z.png"]}

```

Lora微调

1. 训练显存要求为22GB。
2. 可指定`--dataset AI-ModelScope/alpaca-gpt4-data-zh`来跑通实验。
3. 训练命令：

```bash
CUDA_VISIBLE_DEVICES=0 \
swift sft \
--model Qwen/Qwen3-8B \
--train_type lora \
--dataset '<dataset-path>' \
--torch_dtype bfloat16 \
--num_train_epochs 1 \
--per_device_train_batch_size 1 \
--per_device_eval_batch_size 1 \
--learning_rate 1e-4 \
--lora_rank 8 \
--lora_alpha 32 \
--target_modules all-linear \
--gradient_accumulation_steps 4 \
--eval_steps 50 \
--save_steps 50 \
--save_total_limit 2 \
--logging_steps 5 \
--max_length 2048 \
--output_dir output \
--warmup_ratio 0.05 \
--dataloader_num_workers 4 \
--packing true \
--user_liger_kernel true

```

GRPO训练  
 硬件要求为`70G*8`，训练命令：

```bash
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \
NPROC_PER_NODE=8 \
swift rlhf \
--rlhf_type grpo \
--model Qwen/Qwen3-8B \
--train_type full \
--dataset AI-MO/NuminaMath-TIR \
--torch_dtype bfloat16 \
--num_train_epochs 1 \
--per_device_train_batch_size 2 \
--per_device_eval_batch_size 2 \
--learning_rate 1e-6 \
--save_total_limit 2 \
--logging_steps 5 \
--output_dir output \
--gradient_accumulation_steps 1 \
--warmup_ratio 0.05 \
--dataloader_num_workers 4 \
--max_completion_length 4096 \
--vllm_max_model_len 8192 \
--reward_funcs accuracy \
--num_generations 16 \
--use_vllm true \
--vllm_gpu_memory_utilization 0.4 \
--sleep_level 1 \
--offload_model true \
--offload_optimizer true \
--gc_collect_after_offload true \
--deepspeed zero3 \
--num_infer_workers 8 \
--tensor_parallel_size 1 \
--temperature 1.0 \
--top_p 0.85 \
--report_to wandb \
--log_completions true \
--overlong_filter true

```

Megatron并行训练  
 引入Megatron的并行技术来加速大模型的训练，包括数据并行、张量并行、流水线并行、序列并行，上下文并行，专家并行。支持Qwen3等模型的预训练和微调。

训练命令：

```bash
NNODES=$WORLD_SIZE \
NODE_RANK=$RANK \
megatron sft \
--load Qwen3-30B-A3B-Base-mcore \
--dataset 'liucong/Chinese-DeepSeek-R1-Distill-data-110k-SFT' \
--tensor_model_parallel_size 2 \
--expert_model_parallel_size 8 \
--moe_grouped_gemm true \
--moe_shared_expert_overlap true \
--moe_aux_loss_coeff 0.01 \
--micro_batch_size 1 \
--global_batch_size 16 \
--packing true \
--recompute_granularity full \
--recompute_method uniform \
--recompute_num_layers 1 \
--train_iters 2000 \
--eval_iters 50 \
--finetune true \
--cross_entropy_loss_fusion true \
--lr 1e-5 \
--lr_warmup_iters 100 \
--min_lr 1e-6 \
--save megatron_output/Qwen3-30B-A3B-Base \
--eval_interval 200 \
--save_interval 200 \
--max_length 8192 \
--num_workers 8 \
--dataset_num_proc 8 \
--no_save_optim true \
--no_save_rng true \
--sequence_parallel true \
--use_flash_attn true

```

### MS-EvalScope

[开源](https://github.com/modelscope/evalscope)模型评估框架，旨在为LLM和多模态模型提供统一、系统化的性能评估方案。具备高度的自动化和可扩展性，适用于研究机构、工业界以及模型开发者在模型验证与性能对比场景中的广泛需求。

特点

* 丰富的评测基准覆盖：内置多种权威评测数据集，涵盖中英文通用知识问答、数学推理、常识判断、代码生成等多个方向，支持多维度评估。
* 多样的评估模式支持：提供单模型评估模式（Single）、基于基线的两两对比模式（Pairwise-Baseline）、全模型两两对比模式（Pairwise-All），满足不同使用场景。
* 统一的模型接入接口：对不同类型的模型提供统一调用方式，兼容HF、本地部署模型及API远程调用，降低模型集成复杂度。
* 评估流程高度自动化：实现评测任务全自动执行，包括客观题自动打分、复杂问题使用评审模型辅助判定结果等，支持批量评估与日志记录。
* 完善的可视化工具：支持生成详细评估报告和图表，展示模型在不同任务维度下的表现，便于横向对比和性能分析。
* 多后端与评测能力扩展：可集成多个评测后端，支持从单模态到多模态、从语言建模到RAG端到端评测的全链路能力。
* 支持部署性能测试：提供服务端推理性能测试工具，涵盖吞吐量、响应时延等关键指标，帮助评估模型部署实用性。

### MS-Agent

[GitHub](https://github.com/modelscope/ms-agent)，[文档](https://modelscope-agent.readthedocs.io/zh-cn/latest/)，[论文](https://arxiv.org/abs/2309.00986)，[ModelScopeGPT体验地址](https://modelscope.cn/studios/iic/ModelScopeGPT)，已停止维护，生成有问题。

MS-Agent是魔搭社区打造的开源多模态多智能体系统。

特点：

* 可定制且功能全面的框架，提供可定制化的引擎、数据集收集、工具检索与注册、存储处理、定制模型训练和应用开发等功能，可快速应用于实际场景。
* 以开源LLM为核心组件，支持各种文本或多模态大模型。
* 支持多样化且全面的API开发。

架构  
 ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/29a687e292ae451f89d353a03271ac56.png)

`AgentExecutor`对象包含以下组件：

* `LLM`：负责处理输入并决定调用哪些工具；
* `tool_list`：由代理可使用的工具组成的列表；
* `PromptGenerator`：将`prompt_template`、`user_input`、`history`、`tool_list`…整合为高效的提示；
* `OutputParser`：用于解析LLM响应，确定要调用的工具及其相应参数。

安装

```bash
git clone https://github.com/modelscope/ms-agent.git
cd modelscope-agent && pip install -r requirements.txt

```

或：`pip install modelscope_agent`

文本转语音工具：

```py
from modelscope_agent.tools import ModelscopePipelineTool
from modelscope.utils.constant import Tasks
from modelscope_agent.output_wrapper import AudioWrapper

class TextToSpeechTool(ModelscopePipelineTool):
    default_model = 'damo/speech_sambert-hifigan_tts_zh-cn_16k'
    description = '文本转语音服务，将文字转换为自然而逼真的语音，可配置男声/女声'
    name = 'modelscope_speech-generation'
    parameters: list = [{
        'name': 'input',
        'description': '要转成语音的文本',
        'required': True
    }, {
        'name': 'gender',
        'description': '用户身份',
        'required': True
    }]
    task = Tasks.text_to_speech
    def _remote_parse_input(self, *args, **kwargs):
        if 'gender' not in kwargs:
            kwargs['gender'] = 'man'
        voice = 'zhibei_emo' if kwargs['gender'] == 'man' else 'zhiyan_emo'
        kwargs['parameters'] = voice
        kwargs.pop('gender')
        return kwargs
    def _parse_output(self, origin_result, remote=True):
        audio = origin_result['output_wav']
        return {'result': AudioWrapper(audio)}

```

文本地址解析工具

```py
from modelscope_agent.tools import ModelscopePipelineTool
from modelscope.utils.constant import Tasks

class TextAddressTool(ModelscopePipelineTool):
    default_model = 'damo/mgeo_geographic_elements_tagging_chinese_base'
    description = '地址解析服务，针对中文地址信息，识别出里面的元素，包括省、市、区、镇、社区、道路、路号、POI、楼栋号、户室号等'
    name = 'modelscope_text-address'
    parameters: list = [{
        'name': 'input',
        'description': '用户输入的地址信息',
        'required': True
    }]
    task = Tasks.token_classification
    def _parse_output(self, origin_result, *args, **kwargs):
        final_result = {}
        for e in origin_result['output']:
            final_result[e['type']] = e['span']
        return final_result

```

集成LangChain：

```py
from modelscope_agent.tools import LangchainTool
from langchain_community.tools import ShellTool, ReadFileTool

# 包装一下
shell_tool = LangchainTool(ShellTool())
print(shell_tool(commands=["echo 'Hello World!'", "ls"]))

```

### 数据集

[MSAgent-Bench](https://modelscope.cn/datasets/iic/MSAgent-Bench)：综合性工具数据集，包含59.8万个对话，涵盖模型API、通用API、面向API的QA对、API无关指令。  
 ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/49894391f924442686468453c49f94a1.png)

评估包含下面四个维度：

* 插件调用的准确率：识别`api_name`是否正确；
* 插件url的准确率：URL地址是否正确；
* 插件传入参数的准确率：parameters对应参数是否正确；
* 插件整体的准确率：生成的Function Calling是否完全正确，整个JSON可以被加载的格式。

[MSAgent-MultiRole](https://modelscope.cn/datasets/iic/MSAgent-MultiRole)：在MSAgent-Bench基础上，增加多角色扮演数据集，提升开源LLM作为中枢来做多角色扮演实现多角色聊天的能力。

下载方式：

* 页面下载
* SDK

```py
import ast
from modelscope.msdatasets import MsDataset

ds = MsDataset.load('damo/MSAgent-Bench', split='train') # or split='validation'
one_ds = next(iter(ds))
print(one_ds)
# to parse conversations value
conv = one_ds['conversations']
conv = ast.literal_eval(conv)
print(conv[0]['from'])
print(conv[0]['value'])

```

## 参考

* [MSAgent-Bench](https://modelscope.cn/datasets/iic/MSAgent-Bench)



