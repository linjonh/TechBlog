---
arturl_encode: "68747470733a2f2f626c6f67:2e6373646e2e6e65742f79616e67323333303634383036342f:61727469636c652f64657461696c732f313436313635383936"
layout: post
title: "小白学Agent技术5Agent框架"
date: 2025-03-10 23:52:19 +08:00
description: "LangGraph：一个基于图的多智能体系统开发平台，可以创建复杂的智能体交互。Autogen：一个自动代码生成平台，通过自动代码生成简化了多智能体系统的开发过程。Crewai：一个云平台，提供可扩展和安全的解决方案，适用于复杂的多智能体系统开发。"
keywords: "小白学Agent技术[5](Agent框架)"
categories: ['Agent']
tags: ['Ai', 'Agent']
artid: "146165896"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146165896
    alt: "小白学Agent技术5Agent框架"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146165896
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146165896
cover: https://bing.ee123.net/img/rand?artid=146165896
image: https://bing.ee123.net/img/rand?artid=146165896
img: https://bing.ee123.net/img/rand?artid=146165896
---

# 小白学Agent技术[5](Agent框架)

## Agent框架

* [Agent课程地址](https://www.bilibili.com/video/BV1BvRNYdEnh/?p=2&share_source=copy_web&vd_source=90f0e584e7a9f2145777788170d3b45e)

> * 提醒：Agent如果有文件系统访问权限，要在docker容器中运行保证安全性。

### Single Agent框架

* Single Agent框架优点：

1. 简单性：设计、实现和管理相对简单，因为不需要考虑多个智能体之间的交互和协调问题。
2. 专业性：可以针对特定任务进行优化，专注于执行单一任务，效率较高。
3. 易于开发：由于系统组件较少，开发和部署速度更快。
4. 成本效益：相比多智能体系统，单智能体系统通常需要较少的计算资源。

* Single Agent框架缺点：

5. 灵活性有限：对于需要多个智能体协作才能完成的复杂任务，单智能体系统可能无法提供最佳解决方案。
6. 扩展性差：增加新功能或适应新环境可能需要重构整个系统。一旦面临极其错综复杂、计算量密集的任务，Single-Agent会遭遇算力瓶颈，无法高效完成处理，性能将大打折扣。
7. 鲁棒性低：系统对故障的容忍度较低，单点故障可能导致整个系统失效。

#### BabyAGI

* [github项目](https://github.com/yoheinakajima/babyagi)
* [文档](https://yoheinakajima.com/birth-of-babyagi)
* babyAGI决策流程：
  1. 根据需求分解任务；
  2. 对任务排列优先级；
  3. 执行任务并整合结果；
* 作为早期agent的实践，babyagi框架简单实用，里面的任务优先级排序模块是一个比较独特的feature，后续的agent里大多看不到这个feature。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b3c68da531ff44b499b6423c3622af3f.png)

#### AutoGPT

* [github项目](https://github.com/Significant-Gravitas/AutoGPT)
* [文档](https://docs.agpt.co/)
* AutoGPT定位类似个人助理助用户完成指定的任务，如调研某个课题。AutoGPT比较强调对外部工具的便用，如搜索引擎、页面浏览等。同样，作为早期agent，autoGPT麻雀虽小五脏俱全，虽然也有很多缺点，比如无法控制选代次数、工具有限。但是后续的模仿者非常多，基于此演变出了非常多的框架

#### HuggingGPT

* [论文](https://arxiv.org/pdf/2303.17580)
* [github项目](https://github.com/microsof/JARVIS)
* 由浙大&微软联合发布的一个大模型协作系统。研究者提出用ChatGPT作为任务规划器，连接HuggingFace社区中的各种Al模型，完成多模态复杂任务。整个过程只需要做的是：用自然语言将你的需求输出。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/026ba2e5efce47048c557765e1ad15a0.png)

#### HuggingGPT工作原理说明

1. 任务规划：使用ChatGPT分析用户请求，将其分解为多个子任务，并规划任务顺序和依赖关系。
2. 模型选择：根据HuggingFace中可用的功能描述选择模型。
3. 任务执行：使用所选的AI模型执行每个子任务。
4. 响应生成：根据AI模型执行结果进行总结和输出。

---

* HuggingGPT的工作原理可以概括为以下几点：
* 语言作为接口：HuggingGPT将语言作为连接LLM和AI模型的通用接口，通过将模型描述结合到提示中。使LLM能够管理AI模型，如计划、调度和合作。
* 任务规划：LLM首先解析用户请求，将其分解为一系列结构化任务，并确定这些任务的依赖关系和执行顺序。
* 模型选择：LLM根据HuggingFace中的模型描述，将解析后的任务分配给专家模型。
* 任务执行：每个专家模型在推理端点上执行所分配的子任务，并将执行信息和推理结果记录到LLM。
* 响应生成：最后，LLM总结执行过程日志和推理结果，并将摘要返回给用户。
* HuggingGPT的亮点：HuggingGPT与AutoGPT的不同之处在于，它可以调用HuggingFace上不同的模型来完成更复杂的任务，从而提高了每个任务的精确度和准确率。然而，总体成本并没有降低太多。

#### GPT-Engineer

* github项目
* [文档](https://gptengmeer.readhedocs.o/en/larest/quckstart.html)
* 基于langchaln开发，单一的工程师agent，解决编码场景的问题，目的是创建一个完整的代码仓库，在需要时要求用户额外输入补充信息。
* 亮点：code-copilot的自动化升级版。

#### AppAgent

* [github项目](https://github.com/X-PLUG/MobileAgent)
* [论文](https://arxiv.org/pdf/2312.13771)
* 基于ground-dino以及gptview模型做多模态处理的Agent。
* 亮点：基于视觉/多模态appagent，os级别的agent，可以完成系统级别的操作，直接操控多个app。
* 缺点：由于需要系统级权限、只支持安卓系统。

#### OS-Copilot

* [github项目](https://lgithub.com/Os-Copilot/Os-Copllot)
* [论文](https://arxiv.org/pdf/2402.07456)
* [文档](https://os-copilot.github.jo/)
* OS级别的Agent，FRIDAY能够从图片、视频或者文本中学习，并且能够执行一系列的计算机任务，比辑在Excel中绘图，或者创建一个网站。
* 最重要的是，FRIDAY能够通过做任务来学习新的技能，就像人类一样，通过不断的尝试和练习变得更程长。
* 亮点：自我学习改进，学习如何更有效地使用软件应用、执行特定任务的最佳实践等。

### Multi-Agent框架

* [论文Large Language Model based Multi-Agents:A Survey of Progress and Challenges](https://arxiv.org/pdf/2402.01680)
* [Exploring Collaboration Mechanisms for LLMAgents:A Social Psychology View](https://arxiv.org/pdf/2310.02124)
* [LONGAGENT:Scaling Language Models to 128k Context through Multi-Agent Collaboration](https:/larxivorg/pdf/2402.11550)
* 将多个Agent，按照一定的工作流进行编排，每个Agent负责不同的任务，即组成了多智能体架构（Multi-Agent）。这非常类似于我们实际中的工作流程或组织
* 结构：拥有不同能力的人，负责不同的任务，每个工序执行的结果给到下一个工序，最终得到最后的任务成果。

---

* multiagent的例子，它允许不同角色的Agent完成任务，其中某个Agent撞长检索数据，余下的Agent则擅长数据分析或数据可视化。
* 设计一个智慧城市的数据分析工作流，由于数据来源比较复杂，并且要同时考虑模型的经济和分析地高效，可以设计三个不同的Agent：
  1. Agent-1代理负责数据收集，从各种数据源（如气象部门、交通部门、环保部门的数据共享接口），收集原始数据，并进行去重、缺失值填补、格式转换等数据预处理工作。为了经济，使用GPT-3.5模型。
  2. Agent-2拿到Agent-1的结果，然后进行数据加载和深度数据分析，使用本地微调过的Mistral7B模型。
  3. Agent-3则负责最终的数据可视化，将上一步的数据分析结果展示为可视化图表，并提供用户界面，可以选择允许用户与可视化结果进行交互，如筛选、放大、导出等。

---

* 优点：
  1. 协作性：智能体之间可以相互通信和协作，共同完成复杂任务。
  2. 灵活性和适应性：能够适应多变的环境和任务需求，智能体可以自主调整行为和策略。
  3. 可扩展性：通过增加更多的智能体来扩展系统的功能和处理能力。
  4. 鲁棒性和容错性：系统中的智能体可以互为备份，提高了系统的可靠性和容错性。
  5. 分布式处理：可以分散处理任务，提高效率和吞吐量。
  6. 专业化：每个智能体可以拥有特定领域的专业知识，提高问题解决能力。
* 缺点：
  1. 复杂性高：需要设计和实现智能体之间的通信、协调和协作机制，增加了系统的复杂性。
  2. 开发难度大：相比单智能体系统，多智能体系统需要更多的开发工作和专业知识。
  3. 成本较高：可能需要更多的计算资源和开发投入，简单的问题singleAgent也能解决

---

* **单智能体=大语言模型（LLM）+观察（obs）+思考（thought）+行动（act）+记忆（mem）**
* **多智能体=智能体+环境+SOP+评审+通信+成本**

#### 斯坦福虚拟小镇

* [github项目](https://github.com/joonspk-research/generative_agents)
* [论文](https://arxiv.org/pdf/2304.03442)
* 斯坦福虚拟小镇（Smallille）是一个由斯坦福大学和谷歌的研究人员创建的虚拟社区项目，旨在模拟人类行为。
* 项目通过使用大型语言模型（LLM），特别是ChatGPTAPI，来实现25个AI智能体的自然语言交互和社会行为模拟。这些AI智能体在虚拟小镇中生活，他们有工作，会八卦，能组织社交活动，结交新朋友，甚至举办派对，每个"小镇居民“都有独特的个性和背景故事。Smallvile虚拟小镇包含了多种公共场景，如咖啡馆、酒吧、公园、学校、宿舍、房屋和商店，智能体可以在这些场景中自由活动，进入或离开场所，甚至与其他智能体打招呼和互动。这些智能体的行为模仿了人类的日常活动，例如果看到早餐着火了，会走过去关掉炉子；如果看到浴室有人，会在外面等待；如果遇到一个想交谈的个体丁会停下来聊天。虚拟小镇作为早期的multi-agent项目，很多设计也影响到了其他multi-agent框架，里面的反思和记忆检素feature，模拟人类的思考方式
* 代理（Agents）感知他们的环境，当前代理所有的感知（完整的经历记录）都被保存在一个名为”记忆流”（memory stream）中。基于代理的感知，系统检索相关的记忆，然后便用这些检索到的行为来决定下一个行为。这些检索到的记忆也被用来形成长期计划，并创造出更高级的反思，这些都被输入到记忆流中以供未来使用。

#### TaskWeaver

* [github项目](https://github.com/microsott/Taskweaver)
* [文档](https://microsoft.github.io/TaskWeaver/docs/overview/)
* TaskWeaver：面向数据分析任务，通过编码片段解释用户请求，并以函数的形式有效协调各种插件来执行数据分析任务。
* TaskWeaver不仅仅是一个工具，更量一个复杂的离统，能够解释命令，将它们转换为代码，并精确地执行在势。
* TaskWeaver的工作流程涉及几个关键组件和过程。它由三个关键组件组成：规划器（Planner）、代码生成器（CG）和代码执行器（CE）。
* 代码生成器和代码执行器由代码解释器（CI）组成。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/0e454c5e21e944efbcb4bab205c1227d.png)

#### MetaGPT

* [MetaGPT github项目](https://github.com/geekan/MetaGPT)
* [MetaGPT文档](https://docs.deepwisdom.ai/main/zh/guide/get_started/introduction.html)
* MetaGPT是国内开源的一个Multi-Agent框架，目前整体社区活跃度较高和也不断有新feature出来，中文文档支持的很好。
* MetaGPT输入一句话的老板需求，输出用户故事/竞品分析/需求/数据结构/APIs/文件等。
* MetaGPT以软件公司方式组成，内部包括产品经理/架构师/项目经理/工程师，它提供了一个软件公司的全过程与精心调配的SOP。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3fd693d34d7249899cd09ca8a96b15c1.png)
* Pole特从Environment中_observeMessage。如果有一个Role_watch的特定Action引起的Message，那么这是一个有效的观察，触发Role的后续思考和操作。在_think中，Role将选择其能力范围内的一个Action并将其设置为要做的事情。在_act中，Role执行要做的事情，即运行Action并获取输出。将输出封装在Message中，最终publish_message到Environment，完成了一个完整的智能体运行。

#### 微软UFO

* [微软UFO github项目](https://github.com/microsoft/UFO)
* UFO是面向Windows系统的Agent，结合自然语言和视觉操作WindowsGUI。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a4b0bc190e0546419709a86fd4e50b76.png)
* UFO（UI-Focused Agent）的工作原理基于先进的视觉语言模型技术，特别是GPT-Vision。以及一个独特的双代理框架，使其能够理解和执行Windows操作系统中的图形用户界面（GUI）任务。
    
  以下是UFO工作原理的详细解释：

1. 双代理框架双代理架构：UFO由两个主要代理组成，AppAgent和ActAgent，分别负责应用程序的选择与切换，以及在这些应用程序内执行具体动作。
   * 应用程序选择代理（AppAgent）：负责决定为了完成用户请求需要启动或切换到哪个应用程序。它通过分析用户的自然语言指令和当前桌面的屏幕截图来做出选择。一旦确定了最适合的应用程序，AppAgent会制定一个全局计划来指导任务的执行。
   * 动作选择代理（ActAgent）：一旦选择应用程序，ActAgent就会在该应用程序中执行具体的操作，如点击按钮、输入文本等。ActAgent利用应用程序的屏幕截图和控件信息来决定下一步最合适的操作，并通过控制交互模块将这些操作转化为对应用程序控件的实际动作。
2. 控制交互模块UFO的控制交互模块是将代理识别的动作转换为应用程序中实际执行的关键组成部分。这个模块使UFO能够直接与应用程序的GUI元素进行交互，执行如点击、拖动、文本输入等操作，而无需人工干预。
3. 多模态输入处理UFO能够处理多种类型的输入，包括文本（用户的自然语言指令）和图像（应用程序的屏幕截图）。这便UFO能够理解当前GUI的状态、可用控件和它们的属性，从而做出准确的操作决策。
4. 用户请求解析当接收到用户的自然语言指令时，UFO首先解析这些指令，以确定用户的意图和所需完成的任务。然后，它将这个任务分解成一系列子任务或操作步骤，这些步骤被AppAgent和ActAgent按顺序执行。
5. 应用程序间的无缝切换如果完成用户请求需要多个应用程序的操作，UFO能够在这些应用程序之间无缝切换。它通过AppAgent来决定何时以及如何切换应用程序，并通过ActAgent在每个应用程序中执行具体的操作。
6. 自然语言命令到GUI操作的映射UFO的核心功能之一是将用户的自然语言命令映射到具体的GUI操作上。这一过程涉及到理解命令的意图，识别相关的GUI元素。以及生成和执行操作这些元素的动作。通过这种方式，UFO可以自动完成从文档编辑和信息提取到电子邮件撰写和发送等一系列复杂的任务，大大提高用户在Windows操作系统中工作的效率和便捷性。
     
   ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/2a8874dd8a634932a089c5fa8536a7eb.png)

#### AgentScope

* [AgentScope github项目](https://github.com/modelscope/agentscope)
* [AgentScope 论文](https://arxiv.org/pdf/2402.14034)
* [AgentScope agent平台](https://agentscope.io/)
* 阿里开源的Multi-agent框架，亮点是支持分布式框架，并且做了工程链路上的优化及监控。
    
  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6da8600948374490ba6855ad001a100a.png)

#### 现状

* Multi-Agent并不是Agent框架的终态，Multi-Agent框架是当前有限的LLM能力背景下的产物，更多还是为了解决当前LLM的能力缺陷，通过LLM多次迭代、弥补一些显而易见的错误，不同框架间仍然存在着极高的学习和开发成本。
* 随着LLM能力的提升，未来的Agent框架肯定会朝着更加的简单、易用的方向发展
* 游戏场景（npc对话、游戏素材生产）、内容生产、私域助理、OS级别智能体、部分工作的提效
* 在利用LLM多智体解决各种任务方面取得了有希望的结果，如软件开发、多机器人系统、社会模拟、策略模拟和游戏模拟。
* 由于该领域跨学科研究的性质，它吸引了各种各样的研究人员，从A专家扩展到社会科学、心理学和政策研究专家。研究论文的数量正在迅速增加。

## 常见Agent项目比较

|  | LangGraph | Autogen | Crewai |
| --- | --- | --- | --- |
| 开发难度 | 中 | 低 | 高 |
| 拓展性 | 高 | 中 | 高 |
| 集成能力 | 中断 | 高 | 低 |

### 概述

* LangGraph：一个基于图的多智能体系统开发平台，可以创建复杂的智能体交互。
* Autogen：一个自动代码生成平台，通过自动代码生成简化了多智能体系统的开发过程。
* Crewai：一个云平台，提供可扩展和安全的解决方案，适用于复杂的多智能体系统开发。

### 技术规格和能力

* 架构：LangGraph采用图架构，Autogen便用自动代码生成方法，而Crewai便用云基础设施。
* 可扩展性：三者都能扩展，但复杂度不同。
* 集成能力：Autogen的集成能力较强，更易于集成多个系统和服务。

### 实际应用案例

* LangGraph：一家物流公司利用LangGraph优化了供应链管理，减少了25%的交货时间。
    
  0 Autogen：一家金融机构利用Autogen开发了一个用于投资组合优化的多智能体系统，提高了投资回报率。
* Crewai：一个研究团队利用Crewai的云基础设施部署了一个气候模型，提高了预测准确性和决策质量。

### 开发体验比较

* LangGraph：开发过程较为复杂，需要理解图系统的知识。
* Autogen：自动代码生成使得开发过程更简单，易于开发者便用。
* Crewai：云基础设施对不熟悉云计算的开发者来说可能有一定难度

### ChatChain模式

* 本质上，通过相互聊天能完善用户需求，能详细生成推理步骤，能提升模型规划能力，正确拆解任务。
* crewa和AutoGen等项目采用ChatChain模式的原因在于，这种模式特别适合于构建能够协同工作的多代理系统，通过代理间的对话和协作来解决问题。

以下是ChatChain模式的相关信息：

* 代理协作：ChatChain模式允许创建多个代理，这些代理可以相互对话，共同完成任务。这种模式非常适合需要多个步骤或多个参与者协同工作的场景。
* 任务分解与分配：在ChatChain中，复杂的任务可以被分解成多个子任务，并由不同的代理负责处理。这种任务分解和分配的方式提高了处理复杂问题的效率。
* 灵活性与可扩展性：ChatChain模式支持多种会话模式，如双代理聊天、顺序聊天、群聊等，使得系统可以根据不同的需求灵活调整代理间的交互方式。