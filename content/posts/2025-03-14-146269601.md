---
arturl_encode: "68747470733a2f2f626c6f:672e6373646e2e6e65742f323330315f37363937393838362f:61727469636c652f64657461696c732f313436323639363031"
layout: post
title: "实验5-逻辑回归"
date: 2025-03-14 23:49:20 +08:00
description: "1、参照“2.1梯度下降法实现线性逻辑回归.ipynb”和“2.2 sklearn实现线性逻辑回归.ipynb”，在Jupyter Notebook中新建Python运行环境，以单元格为单位运行代码，在实验报告中解释每行代码的含义，分析运行结果，把运行结果截图保存到实验报告中，并比较两种实现方式的优劣。使用matplotlib绘制散点图，类别0的数据点用天蓝色（“skyblue”）的圆圈（“o”）标记，类别1的数据点用红色（“red”）的叉号（“x”）标记。方法返回了 0.95 的准确率。"
keywords: "实验5 逻辑回归"
categories: ['人工智能']
tags: ['逻辑回归', '算法', '机器学习']
artid: "146269601"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146269601
    alt: "实验5-逻辑回归"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146269601
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146269601
cover: https://bing.ee123.net/img/rand?artid=146269601
image: https://bing.ee123.net/img/rand?artid=146269601
img: https://bing.ee123.net/img/rand?artid=146269601
---

# 实验5 逻辑回归

## 实验5 逻辑回归

【实验目的】掌握逻辑回归算法
  
【实验内容】处理样本，使用逻辑回归算法进行参数估计，并画出分类边界
  
【实验要求】写明实验步骤，必要时补充截图
  
1、参照“2.1梯度下降法实现线性逻辑回归.ipynb”和“2.2 sklearn实现线性逻辑回归.ipynb”，在Jupyter Notebook中新建Python运行环境，以单元格为单位运行代码，在实验报告中解释每行代码的含义，分析运行结果，把运行结果截图保存到实验报告中，并比较两种实现方式的优劣。

2.1梯度下降法实现线性逻辑回归.ipynb：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/63a3600e9e51470ca40c8ca8ce37f00e.png)

导入matplotlib的pyplot模块，并简称为plt，用于数据可视化。
  
x_data现在包含了数据集中的特征，是除了最后一列之外的所有数据。
  
y_data现在包含了数据集中的特征，选择了数据数组 data 的所有行和最后一列。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5fc7abe760a24bb4b7bf784d457ea75d.png)

定义了一个名为 plot_logi 的函数，该函数将数据集根据标签（0或1）分割成两组，并分别使用散点图绘制这两组数据。
  
类别0的数据以天蓝色圆点表示，类别1的数据以红色叉号表示。
  
通过 plt.show() 展示包含图例的图形。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e0a8cd9573d847d089e5ebe12f3a88a4.png)

从数据集 data 中提取特征（x_data）和标签（y_data）。
  
在特征矩阵 x_data 的最左侧添加了一列全为1的数据，这个新列是通过 np.ones 函数生成的，其长度与 x_data 的行数相同，
  
使用 np.concatenate 函数沿着列方向（axis=1）将其与 x_data 拼接起来，形成新的特征矩阵 X_data。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3280f46d4304423d88b68686fdc5848e.png)

sigmoid函数：将任意实数值映射到(0,1)区间内；
  
损失函数 (cost_):计算逻辑回归模型的损失（成本）；
  
梯度上升算法 (gradAscent):通过迭代更新参数向量ws（即θ的转置），以最小化损失函数。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/dfbf7eb969d74c3bb0962c5507eceea7.png)

计算决策边界：对于每个 x1 值，我们计算对应的 x2 值，使得 x1
*theta1 + x2*
theta2 + theta0 = 0，即 x2 = -(x1*theta1 + theta0) / theta2
  
可视化决策边界
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/1426be3f2fee4a9e8aadf77bdc8bcdef.png)

绘制损失曲线

运行结果：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3ff91aa237db4a188002b6cb7cca5262.png)

ws是一个包含权重系数的数组，这些权重决定了输入特征对预测结果的贡献程度。

2.2 sklearn实现线性逻辑回归.ipynb
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b12980fe7f7d46c2881342aa823a9d6b.png)

定义一个plot_logi函数，用于绘制逻辑回归的数据点
  
使用matplotlib绘制散点图，类别0的数据点用天蓝色（“skyblue”）的圆圈（“o”）标记，类别1的数据点用红色（“red”）的叉号（“x”）标记
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/70da714a9a504919bf012fc335a97f7b.png)

使用x_data（特征）和y_data（标签）来训练逻辑回归模型
  
# fit方法会找到最佳的权重和偏置，以便将特征映射到标签上
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/db50fbd26c084a28977df3f3b783a0f7.png)

计算决策边界：逻辑回归的决策边界通常是一个直线（在二维特征空间中），其方程可以表示为 theta0 + theta1
*x1 + theta2*
x2 = 0
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/ede3976f596e490bbe3a798b7f9292f9.png)

score方法返回准确率

运行结果：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/fad75255ad3a458ab15f11fc6b455fe4.png)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/ab89704ad85949578be9c72eba04057c.png)

方法返回了 0.95 的准确率。这意味着在提供的测试数据集上，模型正确预测了 95% 的样本。

两种实现方式的优劣：
  
sklearn实现：
  
sklearn中的逻辑回归模型通常利用高度优化的算法进行训练，这些算法在收敛速度和模型准确性方面通常优于简单的梯度下降法，sklearn实现的逻辑回归模型往往能更快地达到更优的准确率。
  
sklearn实现的逻辑回归模型通常不需要手动设置学习率等超参数，因为sklearn中的优化算法会自动调整这些参数，这意味着可能无法完全控制模型的训练过程，从而在某些情况下可能影响模型的可解释性。

梯度下降法实现：
  
梯度下降法也能实现逻辑回归，但其收敛速度和准确性可能受到学习率、迭代次数等超参数的影响。若超参数设置不当，可能导致模型训练不充分或陷入局部最优解。
  
梯度下降法实现的逻辑回归模型提供了明确的权重系数，这些系数可以直接用于解释特征对预测结果的影响，通过调整学习率、迭代次数等超参数，可以更灵活地控制模型的训练过程。

2、读取ex2data1.txt中的数据，建立样本集，使用逻辑回归算法得到参数估计值。并在坐标图中画出分界图。
  
提示：参考“成绩分类版本1.ipynb”
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/cf140696efdb44bfb5a72160c8873fec.png)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/cceee102cad249d59f04821886d259af.png)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/59a2c90a6506493593442c1eccfeebdb.png)

结合自己的知识背景及兴趣，选做以下题目：
  

选做第3题：
  
3、读取“简单分类数据.txt”中的数据，建立样本集，使用逻辑回归算法得到参数值，并在坐标图中画出分界线

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/8879d16ea15d4dd8b8971546e52dca26.png)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/50c01f5917134c52885ec9630bafc31b.png)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/fa41f30c84be4373afc60349c54f8cc6.png)