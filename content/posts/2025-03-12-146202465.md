---
layout: post
title: "反无人机目标检测DRBD-YOLOv8"
date: 2025-03-12 13:14:52 +0800
description: "摘要：由于对无人飞行器（UAV）相关的安全和隐私问题的日益关注，反无人机检测系统的兴趣不断增加。在边缘计算设备资源有限的情况下，实现高精度的实时检测是反无人机检测面临的一个重大挑战。现有的基于深度学习的反无人机检测模型往往无法在精度、处理速度、模型大小和计算效率之间取得平衡。为了解决这些局限性，本文提出了一种轻量级且高效的反无人机检测模型DRBD-YOLOv8。"
keywords: "【反无人机目标检测】DRBD-YOLOv8"
categories: ['目标检测']
tags: ['目标检测', '无人机', 'Yolo']
artid: "146202465"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146202465
    alt: "反无人机目标检测DRBD-YOLOv8"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146202465
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146202465
cover: https://bing.ee123.net/img/rand?artid=146202465
image: https://bing.ee123.net/img/rand?artid=146202465
img: https://bing.ee123.net/img/rand?artid=146202465
---

# 【反无人机目标检测】DRBD-YOLOv8

DRBD-YOLOv8：A Lightweight and Efficient Anti-UAV Detection Model  
DRBD-YOLOv8：一种轻量高效的无人机检测模型

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/58b55e6dffa44ef29362b86577f0e2bd.png)

## 0.论文摘要

摘要：由于对无人飞行器（UAV）相关的安全和隐私问题的日益关注，反无人机检测系统的兴趣不断增加。在边缘计算设备资源有限的情况下，实现高精度的实时检测是反无人机检测面临的一个重大挑战。现有的基于深度学习的反无人机检测模型往往无法在精度、处理速度、模型大小和计算效率之间取得平衡。为了解决这些局限性，本文提出了一种轻量级且高效的反无人机检测模型DRBD-
YOLOv8。该模型集成了多项创新，包括应用重参数化跨阶段高效分层注意力网络（RCELAN）和双向特征金字塔网络（BiFPN），以在保持轻量级设计的同时增强特征处理能力。此外，还建立了一种新的损失函数DN-
ShapeIoU，以提高检测精度，并引入了深度可分离卷积以降低计算复杂度。实验结果表明，所提出的模型在mAP50、mAP95、精度和FPS方面均优于YOLOv8n，同时减少了GFLOPs和参数数量。DRBD-
YOLOv8模型的尺寸仅为3.25
M，几乎是YOLOv8n模型的一半。其小尺寸、快速和高精度的特点相结合，提供了一种轻量级、高精度的设备，非常适合在边缘计算设备上进行实时反无人机检测。

关键词：反无人机检测；轻量级；YOLOv8n；BiFPN；损失函数；边缘计算设备

## 1.引言

随着电气和通信技术的进步，无人机得到了显著发展，并在许多不同领域得到了广泛应用[1–4]。尽管无人机带来了诸多益处，但也伴随着高风险，尤其是在安全和隐私方面。在军事基地、核电站、机场和政府建筑等关键区域，无人机的恶意使用可能导致严重后果[5]。涉及未经批准的无人机飞行事件以及利用无人机进行的恐怖袭击也有所增加[6–8]。为了有效应对这些风险，并执行能够限制无人机生产和使用的政策和法规[9,10]，采用先进的技术手段来防御无人机威胁至关重要。

实时探测与识别是反无人机技术的关键环节，也是实施有效对抗措施的基础。当前主流的无人机探测技术主要依赖于多种传感器，包括红外、雷达、光电、声学和射频传感器[11,12]。在低空无人机探测中，应用最广泛的方法是基于计算机视觉的目标检测。传统的计算机视觉检测技术通常采用滑动窗口法对图像中的潜在框进行统计，并提取重要特征信息，随后对无人机进行分类与识别[13,14]。然而，这些传统方法往往计算量大、耗时长，且在反无人机检测中表现出特征提取能力差、准确率低的问题。近年来，基于深度学习的计算机视觉技术发展迅速，涌现出许多高效的目标检测算法[15–19]。其中，YOLO系列算法尤为突出。YOLO系列算法在智能安防[20]、自动驾驶[21]和医学图像分析[22]等多个领域得到了广泛应用，同时也为无人机的实时探测与识别提供了新的机遇。

随着反无人机检测任务的日益复杂化，它们也面临着各种独特的问题。反无人机检测模型需要高精度和实时处理能力，以成功应对无人机威胁，而许多目标识别算法难以满足这一标准。此外，这些检测模型通常部署在户外边缘计算设备上，这些设备的硬件资源有限，因此部署大型模型并不现实。因此，无人机检测模型的轻量化设计至关重要。此外，对于像无人机这样的小型移动目标，运动模糊和遮挡是不可避免的，这会损害图像质量并降低检测精度。

为了应对这些挑战，大量研究致力于基于YOLO系列开发无人机检测算法。例如，Behera等人[23]进行了广泛的比较，最终采用YOLOv3进行无人机检测和分类，实现了74%的最佳检测准确率。Phung等人[24]将YOLOv4与CSRT跟踪算法结合，用于检测和跟踪无人机，获得了81%的检测准确率和约10
FPS的帧率。Singha等人[25]使用YOLOv4检测视频中的无人机，获得了74.36%的mAP。仅使用YOLO算法进行无人机检测的性能相对较低，主要原因是YOLO系列存在一些缺陷，例如对小目标不敏感、在边缘设备上处理速度较慢，尤其是无法在准确性和模型效率之间达到完美平衡。因此，研究人员对YOLO算法进行了多项改进，以提高其检测效果。为了进一步优化复杂环境中小型无人机的检测，Bo等人[26]提出了YOLOv7-GS模型，该模型引入了带有简单注意力机制的SPPCSPC-
SR模块，专注于小目标区域，减少信息丢失并最小化漏检。Tian等人[27]开发了MD-
YOLO算法，该算法集成了多尺度特征融合模块和自适应注意力模块，以提高对小目标的敏感性。Wu等人[28]在原始YOLOv8n中引入了小目标检测层，显著提高了模型捕捉小目标信息的能力。这三种技术提高了检测准确性，但代价是更高的计算和参数负载。例如，YOLOv7-GS的GFLOPS为15.5，超过了原始YOLOv7-tiny的13.2。此外，YOLOv7-GS的模型大小为23.2
MB，几乎是YOLOv7（12.3
MB）的两倍。为了优化YOLO在边缘计算设备上的性能，提出了各种轻量级改进。Liu等人[29]为YOLO骨干网络设计了一个高效的特征提取模块，在减少模型大小和计算成本的同时提取有意义的特征。Huang等人[30]通过集成Ghost卷积来减少模型参数，改进了YOLOv8，创建了一个仅4.23
MB的紧凑模型。为了捕捉更多特征并提高无人机识别准确性，该模型更新了三个有效的多尺度注意力模块。然而，这种方法导致了更长的处理时间和更高的计算开销。Zhou等人[31]通过引入VDTNet改进了YOLOv4，该网络使用模型压缩将其大小减少到3.9
MB。空间注意力模块通过显示更长的延迟和适中的速度来补偿准确性。Liu等人[32]对YOLOv4进行了改进，应用剪枝技术最小化参数数量，并通过小目标增强来抵消精度损失。然而，最终模型大小仍为15.1
MB，对于边缘设备来说仍然过大。

总的来说，目前大多数基于YOLO系列的反无人机检测方法在准确性、速度和计算效率之间难以达到最佳平衡。

为克服这些局限性，本研究提出了一种新的无人机检测模型DRBDYOLOv8。该模型基于YOLOv8进行了一系列改进，展示了快速的计算速度、高检测精度、低计算复杂度和最小的内存占用。本研究的主要贡献包括以下方面：

•
开发了一种高性能且轻量化的反无人机检测模型。该模型在骨干网络中集成了深度可分离卷积，以实现更轻量化的设计。为了重新配置颈部网络，提出了一种名为RCELAN的新型融合模块，该模块在轻量化、快速推理和高精度之间取得了平衡。此外，在颈部引入了BiFPN架构，以促进多尺度特征融合，提高了模型检测小目标的能力，同时显著降低了复杂性和参数数量。

• 创建了一个全面的无人机数据集，包含无人机在城市、山区、森林和高速公路等各种环境中的图像。该数据集反映了复杂的现实场景，并为训练检测模型提供了丰富的数据。

• 提出了一种新的损失函数DN-
ShapeIoU，该函数在损失计算中同时考虑了边界框的形状和尺度，并基于样本质量采用了动态非线性梯度策略。通过减少低质量图像的不利影响，DN-
ShapeIoU整体上提高了检测精度，并增强了边界框回归效果。

本文的其余部分组织如下：第2节回顾了基于深度学习的反无人机检测技术的相关研究。第3节详细介绍了DRBDYOLOv8反无人机检测模型。第4节展示了一系列对比实验，并对实验结果进行了深入分析。第5节总结了本研究，并对未来的工作进行了展望。

## 2.材料与方法

本文提出了一种高性能、轻量化的反无人机检测模型，称为DRBD-
YOLOv8。当前模型在边缘计算设备上的应用因其庞大的体积和较慢的速度而受到阻碍。该模型解决了这些限制。

与YOLOv8相比，DRBD-
YOLOv8模型有几项显著改进（图1）。首先，通过在骨干网络中用深度可分离卷积替代标准卷积，生成了一个更高效且紧凑的模型。其次，在颈部网络中引入了提出的RCELAN模块，取代了原有的C2f模块。该RCELAN模块通过整合特征图分割与梯度路径优化，提升了多级特征提取能力，同时减少了计算负载和参数数量。一个重要的改进是集成了RepConv
[33]，它利用结构重参数化技术来提高推理速度和操作效率。第三，考虑到无人机目标尺寸较小，采用了BiFPN架构，以增强多尺度信息的融合，并提升模型对小目标的识别能力。最后，为了解决低质量训练样本带来的负面影响，引入了DN-
ShapeIoU损失函数。该损失函数优先考虑边界框的形状和大小，并基于样本质量应用动态非线性梯度策略，以优化模型的边界框回归和检测精度。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6c8fb73c3060494bbdea0bc75c236993.png)  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/2254aa420f39446fa1574dc3bd72cda2.png)

图1. (a) YOLOv8和(b) DRBD-YOLOv8的结构。(b)中的Conv、C2f和SPPF模块的结构与(a)中的相同。图1. (a)
YOLOv8和(b) DRBD-YOLOv8的结构。(b)中的Conv、C2f和SPPF模块的结构与(a)中的相同。

### 2.1 深度可分离卷积

深度可分离卷积相较于标准卷积具有多个优势，其中最主要的是它能够在保持网络性能的同时显著减少模型参数和计算量。由于其效率的提升，深度可分离卷积已在多种轻量级网络架构中得到广泛应用[34,35]。在本研究中，YOLOv8n的主干网络被替换为深度可分离卷积，从而实现了更加简化和轻量化的模型设计。深度可分离卷积由两个部分组成：逐点卷积和逐通道卷积。前者在单个通道上提取空间特征，而逐点卷积则应用于逐通道卷积的输出，融合空间位置特征以增强特征表示的丰富性。深度可分离卷积的计算过程如图2所示。给定一个维度为
h 1 × w 1 × c 1 h_1 × w_1 × c_1 h1​×w1​×c1​的输入特征图，逐通道卷积使用 C 1 C_1 C1​组 k × k ×
1 k × k × 1 k×k×1的卷积核（在本例中 k = 3 k = 3 k=3）进行处理，生成每个通道的 C 1 C_1
C1​个特征图。随后，这些特征图通过逐点卷积进行处理，逐点卷积使用 C 2 C_2 C2​组 1 × 1 × c 1 1 × 1 × c_1
1×1×c1​的卷积核，最终生成维度为 h 2 × w 2 × c 2 h_2 × w_2 × c_2 h2​×w2​×c2​的输出特征图。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/26b2c83d5f284ce9b2b8b3e3a325ad53.png)

图2. 深度可分离卷积的计算过程。

假设 P 1 P_1 P1​和 F 1 F_1 F1​分别表示深度可分离卷积的参数数量和计算成本，可以得到以下公式：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/9fbd5ee7a4124db7b3cf50f199da9990.png)

对于相同的输入特征图，使用标准卷积获得维度为 h 2 × w 2 × c 2 h_2 × w_2 × c_2
h2​×w2​×c2​的输出特征图时，涉及的参数数量和计算成本分别用 P 2 P_2 P2​和 F 2 F_2 F2​表示。具体表达式如下：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/83ee59bdd209467788e453b552b8ebea.png)

其中  k = 3 k = 3 k=3。通过比较  P 1 P_1 P1​ 与  P 2 P_2 P2​ 以及  F 1 F_1 F1​ 与  F 2
F_2 F2​，可以推导出以下表达式：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/9cff005da91e400dbe41f212498bf894.png)

公式（5）和（6）表明，深度可分离卷积的计算成本和参数量显著减少，约为标准卷积的九分之一。这种大幅度的减少对于创建轻量级模型非常有利，尤其是在无人机检测系统中。

### 2.2 RCELAN模块

RCELAN模块的灵感来源于CSPNet [36] 和ELAN [37]
等前沿网络，它在推理速度、检测精度和轻量级架构之间实现了理想的平衡。为了调整通道，输入特征图首先经过一维卷积处理，如图3所示。随后，特征图被分为两部分：一部分保留为原始特征表示，另一部分则沿着主分支进行多次卷积操作。参数
e e e表示扩展比率，用于调整隐藏层中的通道数量，从而控制网络的容量和计算复杂度。通常， e e
e的值设置在0到1之间，较高的值会增加通道数量，能够捕获更丰富的特征，但也会增加计算成本。相反，较低的 e e
e值会降低复杂度，但可能限制模型学习特征的能力。参数 s s s作为缩放因子，用于调整中间层的通道维度，其值可以是任何正数。通过修改 s s
s，可以调整模型大小以满足不同网络的需求。在本研究中， e e e和 s s s均设置为0.5，其中c_表示中间通道维度，且 c _ = s × e × c
2 c\\_ = s × e × c_2 c_=s×e×c2​。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a364dc372b7446d2bf3c7e2d579fe7ab.png)

图3. RCELAN模块的架构。

RCELAN模块消除了瓶颈结构，与原始YOLOv8的C2f结构形成对比。为了提升特征提取和梯度传播，RCELAN模块将RepConv集成到主分支中，以弥补因移除瓶颈中的残差块而带来的性能损失。RepConv通过并行执行1×1和3×3卷积操作，增强了多尺度特征提取能力。主分支随后应用3×3卷积进行局部特征提取，接着通过额外的3×3卷积层捕获更复杂和更深层次的特征。最后，1×1卷积用于捕捉更广泛的语义信息。RCELAN模块将分割操作中未处理的特征与主分支生成的特征进行融合，实现了多层次特征融合。最终的1×1卷积调整输出通道，生成最终的特征图。

RepConv在训练时使用了多分支卷积层，如图4所示。该结构包括并行的3×3卷积层、1×1卷积层以及恒等分支。在推理过程中，通过重参数化技术提取并合并每个分支的参数，生成一组等效的权重和偏置，从而将多个层有效地压缩为一个。批量归一化（BN）的公式如下：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/05723c411ce94d32845870c208f01f75.png)  
图4. RepConv的架构：(a) 训练和(b) 推理  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/0094efa55d5a438eb9a2f9323b46801e.png)

其中， μ μ μ和 σ σ σ分别表示BN通道的均值和标准差； γ γ γ表示学习到的缩放因子； β β β表示学习到的偏置项； x b x_b
xb​表示BN层的输入； X b X_b Xb​表示经过BN后的输出； W B N W_{BN} WBN​表示等效权重； b B N b_{BN}
bBN​表示等效偏置。卷积层和归一化层的融合公式如下：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6d02677ee5c442319e359ac9249f5d76.png)  
其中， x c x_c xc​表示卷积输入； W c W_c Wc​和 b c b_c bc​分别表示卷积的权重和偏置； W C B W_{CB}
WCB​和 b C B b_{CB} bCB​表示融合后的权重和偏置； X c b X_{cb}
Xcb​表示融合后的输出。在推理过程中，由3×3和1×1卷积层以及恒等分支组成的三条分支被合并为仅包含3×3卷积的单一分支。最终输出 Y i Y_i
Yi​可以表示为：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4aab5cd3c0d844db920b916c8ee352f9.png)

最终输出 Y i Y_i Yi​可以表示为公式(13)-(15)，其中 W f u s e W_{fuse} Wfuse​和 b f u s e
b_{fuse} bfuse​表示最终卷积层的参数。 W I 0 × 0 W^{0×0}_I WI0×0​、 W f u s e 0 × 0
W^{0×0}_{fuse} Wfuse0×0​和 W f u s e 3 × 3 W^{3×3}_{fuse}
Wfuse3×3​分别表示从卷积层和BN层融合得到的权重，对应于恒等、1×1和3×3卷积层。同样， b I 0 × 0 b^{0×0}_I bI0×0​、
b f u s e 1 × 1 b^{1×1}_{fuse} bfuse1×1​和 b f u s e 3 × 3 b^{3×3}_{fuse}
bfuse3×3​表示从相同融合过程中得到的各分支的偏置。

重参数化技术显著降低了模型的复杂性和内存使用，使得设计更加紧凑和高效。此外，在推理过程中，层间转换和参数处理的减少提升了计算效率，从而加快了推理速度。重要的是，由于融合操作在数学上是等价的，模型的学习能力并未受到影响。

### 2.3. 融合小目标检测层的BiFPN

YOLOv3的特征提取层采用了FPN架构[38]，该架构通过建立自上而下的路径并结合横向连接来融合不同层的特征。这种架构提升了模型在不同尺度下捕捉丰富特征的能力。然而，由于其单向信息流，检测精度仍然受限，尤其是在处理复杂的多尺度目标特征时。PAN[39]通过引入自下而上的路径改进了FPN，增强了不同特征层级之间的信息流动。PAN将来自顶层的语义特征与底层的定位特征相结合，从而使预测特征图既包含精确的空间信息，也包含抽象的语义信息。图5a和5b分别展示了FPN和PAN的结构。图5c展示了YOLOv5和YOLOv8用于多层特征融合的PAFPN结构。通过移除对特征融合贡献较小的节点，PAFPN简化了设计，并融合了PAN和FPN的优点。这种简化促进了抽象语义细节与具体空间细节的传递与整合，最终提升了目标检测任务的性能。然而，在PAFPN中，不同尺度的特征信息通过拼接方式结合，而未区分这些特征的重要性差异。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/870615e842ae403db71c5956ca120b92.png)

图5. 特征提取网络设计：(a) FPN，(b) PAN，© PAFPN，(d) BiFPN

在本研究中，采用了BiFPN结构进行特征融合。如图5d所示，BiFPN通过在不同层次的融合过程中为每个输入分配权重，从而突出重要特征。移除低贡献节点并建立水平连接，改善了网络中多尺度数据的融合和流动。为了提高对小目标的检测性能，该方法策略性地将P2层的低层次特征融入高层次信息中。与标准流程不同，P2层的特征融合仍然是主要关注点，并且没有增加更多的检测头。增加更多的检测头会大大增加网络的计算负载，使得保持轻量级架构变得更加困难。

BiFPN架构通过充分整合P2层元素，使网络更能够识别和定位小目标。准确的无人机识别依赖于降低误报率和漏报率，这是因为这一改进增强了对多尺度目标的检测能力。

### 2.4 DN-ShapeIoU

边界框回归损失函数旨在衡量预测边界框与真实边界框之间的差异。通常，这些损失函数基于交并比（IoU），用于衡量预测边界框与实际边界框之间的重叠程度[40]。然而，在处理诸如无人机等小型移动目标时，由于边界框形状和尺度的不可预测性，锚框回归面临困难。此外，无人机数据集通常包含模糊、低分辨率和遮挡的样本，这些反映了现实世界中使无人机检测复杂化的条件。YOLOv8损失函数使用CIOU，但在处理这些问题时表现不佳。为了克服这一局限性，本研究提出了一种名为DN-
ShapeIoU的新型损失函数。

Shape-
IoU损失函数[40]全面考虑了边界框的形状和大小，以增强回归性能。它引入了一个形状加权因子，动态调整沿水平和垂直轴的损失贡献。为了进一步提高回归的准确性，该函数还包含了形状距离和角度损失因子。Shape-
IoU的数学表达式由以下方程给出：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/746690bba18341d989e3ad47c24f4e69.png)

其中，D 表示形状距离，Ω 指角度损失，B 表示预测边界框的面积， B g t B_{gt} Bgt​ 表示真实边界框的面积。

如图6所示， b g t b_{gt} bgt​是 B g t B_{gt} Bgt​的中心点，坐标为 ( x g t , y g t ) (x_{gt},
y_{gt}) (xgt​,ygt​)，而b是B的中心，坐标为 ( x c , y c ) (x_c, y_c) (xc​,yc​)。变量c指的是覆盖 B
B B和 B g t B_{gt} Bgt​的最小外接包围框的对角线距离。水平和垂直权重系数分别由 w w ww ww和 h h hh
hh表示。相关表达式在公式(20)-(23)中给出。数据集中目标对象的大小与尺度因子相关，尺度因子由符号scale表示。此外，w和h表示预测包围框B的宽度和高度，而
w g t w_{gt} wgt​和 h g t h_{gt} hgt​表示真实值包围框 B g t B_{gt} Bgt​的宽度和高度。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/db19c08299dd4a96aed6cbf2d88f46f8.png)  
尽管Shape-IoU
[40]提高了边界框回归的准确性，但它无法根据训练数据的各种质量区分梯度贡献。在训练过程中，低质量样本可能会产生误导性梯度，导致异常梯度增益，并破坏模型学习准确特征的能力。为了解决这一问题，本文提出了一种基于Shape-
IoU的增强损失函数，称为DN-
ShapeIoU，其灵感来源于[41]的工作。该函数通过减少低质量样本对模型训练的负面影响，从而提高了模型的泛化能力。所提出的DN-
ShapeIoU引入了一种自适应非线性聚焦机制，能够根据样本质量动态调整梯度增益，从而优化训练过程中的梯度流动。DN-
ShapeIoU的数学公式如公式(24)所示，其中 γ γ γ表示自适应梯度增益。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a97bd6a9cdcd48e9b3c46003347afb24.png)

γ的公式在式(25)中给出，其中α和ϵ表示超参数，τ表示异常程度，如式(26)所定义。在此上下文中， L s h a p e I o U ∗
L^*_{shapeIoU} LshapeIoU∗​指的是当前 L s h a p e I o U L_{shapeIoU}
LshapeIoU​的非梯度版本， A L s h a p e I o U A_{LshapeIoU} ALshapeIoU​是 L s h a p e I
o U L_{shapeIoU} LshapeIoU​的指数移动平均值，其动量因子为 m m m。 γ γ
γ的值在训练过程中根据锚框的质量动态调整。具体而言，对于异常程度较低的高质量锚框，该机制会为 γ γ
γ分配一个较小的值，以限制更新幅度，避免对这些定义良好的样本进行过度调整。为了防止危险梯度的传播，对于异常程度较高的低质量锚框，同样使用较低的梯度增益。这种自适应非线性机制根据异常程度而非IoU值分配梯度增益，从而在训练过程中实现更智能的梯度分布。

综上所述，DN-
ShapeIoU损失函数不仅解决了无人机数据集中边界框形状和尺度的变化问题，还引入了一种自适应非线性聚焦方法，根据样本的异常程度调整梯度增益。通过减少低质量无人机样本的干扰影响，该技术显著提高了模型的检测精度和整体鲁棒性。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/bf979f29cae14e5eb213b858b859035c.png)

图6. IoU示意图。

## 3.实验与分析

本节概述了我们的实验方法，首先介绍了实验设置，包括数据集、实验环境、参数设置和评估指标；然后进行了四项对比实验，以评估本文的创新点，分别是与深度可分离卷积、RCELAN、BiFPN结构和DN-
ShapeIoU的对比实验，并通过消融实验证明它们各自的贡献。此外，DRBD-
YOLOv8模型还在我们的无人机数据集上与其他主流YOLO系列算法进行了进一步比较，并在公开数据集上进行了定量比较，以验证模型的泛化能力和通用性。最后，通过可视化检测结果展示了所提出增强方法的有效性。

### 3.1 数据集

为无人机检测构建了一个全面的数据集。该数据集包含14,509张无人机图像，这些图像拍摄于各种环境，如城市地区、山区、森林、桥梁和沙漠。数据集被随机分为三部分：训练集、验证集和测试集，比例为6:2:2。数据集中包含15种不同类型的无人机，涵盖了单无人机和多无人机场景。这些图像来源于公开的VAU视频和图像，以及实验拍摄。图7展示了该数据集中的部分无人机图像，展示了其多样性和与现实世界条件的紧密契合。该数据集为训练和评估提供了丰富的学习资源。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/f595e2cf7b27458a847ca5ad8814f7ba.png)

图7. 数据集样本，展示了无人机在不同场景中的飞行：(a) 在草原上空，(b) 在高速公路上，© 在桥梁附近，(d) 在山脉中，(e) 在城市上空，(f)
穿过树林，(g) 在沙漠上空，(h) 在远处的云层中，无人机位于红色框内，以及(i) 包含多架无人机的场景。

### 3.2 参数设置

所有实验均使用i9-12900KF CPU（英特尔，中国上海）进行，主频为3.2 GHz，配备32 GB内存，以及单块NVIDIA GeForce RTX
3060 GPU（英伟达，中国上海），显存为12 GB。实验采用的软件为PyTorch 2.3.0框架，搭配torchvision
0.18.0，并使用Python 3.8.0和CUDA 12.1版本进行GPU加速。关键训练参数如表1所示。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/710b30ff5e124008ab9765eb81bfb59f.png)

为了全面评估所提出模型的性能，采用了多种评估指标：精确率（P）、平均精度均值（mAP）、GFLOPs、召回率（R）、参数量（Param）、模型大小和帧率（FPS）。平均精度（AP）通过计算P-
R曲线下的面积得出。指标mAP50表示在50%
IoU阈值下所有类别的平均AP，而mAP95遵循相同的定义，但在不同IoU阈值（最高至95%）下对AP值进行平均。AP和mAP的详细计算公式分别见公式（27）和（28），其中n表示类别数量。FPS反映了数据预处理（
T p r e T_{pre} Tpre​）、模型推理（ T i n f e r T_{infer} Tinfer​）和后处理（ T p o s t
T_{post} Tpost​）所花费的总时间，如公式（29）所示。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/ba1e1cdbee8a4b34a246fd17280f7274.png)

### 3.3 实验对比与分析

#### 3.3.1 不同卷积的对比影响

通过将多种常用的轻量级卷积纳入YOLOv8n模型，进行了对比研究，以验证深度可分离卷积的有效性。在这些实验中，YOLOv8n主干网络中的标准卷积（Conv）被替换为其他类型，如深度卷积（DWConv）、幽灵卷积（GhostConv）、逐点卷积（PWConv）、组卷积（GConv）以及深度可分离卷积（DSConv）。表2总结了这些实验的具体结果，并展示了每种卷积变体的贡献。需要注意的是，所有对比测试均在相同条件下进行，且本实验及后续所有实验的结果均基于测试集的评估。  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/0a8de33134544567aeef09858c7c8f51.png)

#### 3.3.2 RCELAN模块的对比实验

针对YOLOv5中的C3模块[42]、YOLOv7中的ELAN模块[43]、YOLOv8中的C2f模块[44]以及YOLOv9中的Rep-
NCSPELAN4模块[45]，我们进行了对比实验，以评估所提出的RCELAN模块的性能。在这些实验中，输入和输出特征图的维度设置为(1, 1, 128,
128)。从表3中可以看出，RCELAN模块在输入相同特征图的情况下，展示了最低的参数数量和计算成本，同时实现了最高的FPS（每秒帧数）值。综上所述，RCELAN模块在处理速度、检测精度和轻量化设计方面表现优异。  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5806534bf39448e2832b16be0b489a04.png)

在本研究中，开发了RCELAN模块以替代YOLOv8中的C2f模块，旨在提升特征图的理解与融合能力。由于YOLOv8包含多个C2f模块，因此通过四种不同的实验配置研究了在不同位置替换这些模块的效果：第一个实验未进行任何替换。第二个实验仅替换了YOLOv8n骨干网络中的C2f模块。第三个实验专注于替换YOLOv8n颈部网络中的C2f模块。第四个实验则将YOLOv8n中的所有C2f模块替换为RCELAN模块。

表4表明，将所有C2f模块替换为RCELAN模块后，GFLOPs和参数量显著减少。然而，与原始的YOLOv8n相比，这种完全替换导致mAP50、mAP95、P和R的值有所降低。在研究中，第三组表现最佳，其mAP50、mAP95和精度值均为最高，该组仅替换了颈部中的C2f模块。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/899dabc28944403683e52070a4e414c5.png)

与原始的YOLOv8n相比，第三组实验在参数上减少了13%，GFLOPs降低了约10%，同时在mAP50和mAP95上均表现出小幅提升。这表明在模型的颈部用RCELAN模块替换C2f模块，在检测性能和轻量化设计之间实现了平衡的权衡。

#### 3.3.3 BiFPN架构的对比效果

为评估BiFPN架构带来的改进信息融合能力，进行了一系列实验。BiFPN架构在颈部网络中整合了多尺度特征。这些实验将标准的YOLOv8n模型与采用BiFPN结构的对应模型进行了比较。结果突出了通过增强特征融合所获得的改进，并展示了BiFPN在提升模型检测性能方面的价值。

从表5中可以看出，BiFPN架构在降低复杂性和计算需求的同时，显著提升了模型颈部特征信息的融合能力。与YOLOv8n相比，采用BiFPN的模型在mAP50、mAP95、R和P指标上均有提升。这一改进主要源于BiFPN能够有效融合多尺度信息，特别是通过整合小目标层P2的特征数据。此外，使用BiFPN还使得GFLOPs减少了12.3%，参数量减少了33.9%，模型大小减少了32.3%，凸显了其在创建更轻量化模型方面的有效性，适合边缘设备部署。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/0160a8e81628470da748cc9e16e50f1b.png)

#### 3.3.4 不同损失函数的比较

为了评估不同损失函数对检测精度的影响，研究了五种边界框回归损失函数：GIoU [46]、Shape-IoU [40]、Inner-IoU [47]、WIoU
[41]以及新提出的DN-ShapeIoU。这些损失函数与YOLOv8n中使用的原始CIoU损失函数[44]进行了对比。

表6展示了使用不同边界框回归损失函数的YOLOv8n模型的性能指标。需要注意的是，这些损失函数对模型的GFLOPs和参数数量没有显著影响，因此这些指标未在表中列出。对于使用CIoU损失函数的原始YOLOv8n模型，mAP50、mAP95、召回率（R）和精度（P）分别为93.6%、54.1%、90.1%和93.3%。应用GIoU损失函数导致mAP50、mAP95和召回率略有下降。通过切换到Inner-
IoU和Shape-IoU损失函数，mAP50、mAP95和召回率有所提升，但精度分别下降了0.6%和1.1%。这种精度下降可能归因于Inner-
IoU增加了辅助边界框，以及Shape-IoU关注边界框的尺寸和形状，这些方法虽然增强了对小目标的检测能力，但可能降低了精度。WIoU
v3损失函数在所有四个指标上均有所提升，但使用DN-ShapeIoU的模型表现最佳。使用DN-
ShapeIoU时，mAP50、mAP95、召回率和精度分别提升至94.2%、55.1%、91.0%和94.0%。与原始YOLOv8n相比，这些提升分别为mAP50提高0.7%、mAP95提高1.0%、召回率提高0.9%、精度提高1.7%。DN-
ShapeIoU性能的提升可能归因于其对边界框尺度、形状以及样本质量的全面评估。通过使用这种技术，网络能够处理来自更复杂图像的信息，从而获得更好的检测结果。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/810dc7c511c94e7e93b59877ad4bef03.png)

### 3.4 消融实验

在受控条件下进行了多项消融实验，以验证增强措施的有效性。使用的评估指标包括mAP50、mAP95、R、P、GFLOPs、参数量、FPS和模型大小。这些指标全面评估了模型的性能。评估的增强措施包括：在骨干网络中集成深度可分离卷积（DS）、在颈部部分使用提出的RCELAN结构替代C2f模块（R）、在颈部应用BiFPN架构（B）、以及使用DN-
ShapeIoU进行边界框回归（DN）。表7总结了YOLOv8n及其改进版本的实验结果：YOLOv8n + DS、YOLOv8n + DS +
R、YOLOv8n + DS + R + B，以及YOLOv8n + DS + R + B + DN（提出的DRBD-YOLOv8）。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a0ec20575f484ee09936302d079ba135.png)

与基准模型YOLOv8n相比，将主干网络中的标准卷积替换为深度可分离卷积的模型（称为YOLOv8n +
DS）在mAP50上实现了1%的提升。此外，GFLOPs、参数量和模型大小分别减少了约11%，这表明深度可分离卷积在提高检测精度的同时，降低了模型的复杂性和计算需求。

在颈部网络中用RCELAN模块替换C2F模块（称为YOLOv8n + DS +
R）导致mAP50和mAP95略有下降，但这些变化是可接受的。GFLOPs和模型大小分别减少到6.4和4.58
M，使模型更加紧凑和轻量化。特别是召回率和精确度显著提高，从而降低了漏检率和误报率。FPS从340上升到357，展示了推理效率和速度的提升。

与YOLOv8n + DS +
R相比，mAP50和mAP95提升了约0.5%。BiFPN增强了不同层级之间的特征融合，提升了对小目标的检测性能。这一变化使模型尺寸缩小至更紧凑的3.25
MB，GFLOPs和参数量分别减少了11%和30.8%。这表明BiFPN架构显著降低了内存使用和计算成本，满足了资源受限的边缘设备的需求。

将DN-ShapeIoU作为损失函数（称为YOLOv8n + DS + R + B +
DN）的应用取得了最高性能，mAP50和mAP95分别达到95.1%和55.4%。这一改进的原因是DN-
ShapeIoU能够更有效地处理低质量样本，从而提高了训练精度。精度略有下降，而召回率则上升至92%。对于无人机检测来说，更高的召回率至关重要，因为它可以最大限度地减少漏检。

DRBD-
YOLOv8模型在mAP50、mAP95、召回率和FPS等指标上均超越了其他所有模型，同时具有最小的模型尺寸和最低的计算复杂度（图8-10）。总体而言，DRBD-
YOLOv8算法展现了卓越的性能。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/9c0d25c9086b4af1b3c9f5589e9439ab.png)  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b0c899807db24dec845dd8953f0df448.png)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/87aac6aa72124cdca632ca5e8adf53a3.png)

### 3.5. 不同目标检测模型的比较

所提出的DRBD-
YOLOv8模型与一系列目标检测模型进行了全面比较，以验证其效率和优越性。比较主要集中在几个关键评估指标上，包括mAP50、P、GFLOPs、FPS和模型大小。

表8显示，所提出的DRBD-YOLOv8模型的mAP50为95.1%，略低于YOLOv5s（96.2%）和YOLOv8s（96.4%）。然而，DRBD-
YOLOv8的模型大小仅为3.25
M，并且达到了最高的每秒357个任务的FPS。与YOLOv7-tiny、YOLOv8n、YOLOv9t和YOLOv10n相比，DRBD-
YOLOv8模型展示了更好的性能指标。尽管YOLOv5n的GFLOPs最低，但其mAP50、精度、FPS和模型大小均不如DRBD-
YOLOv8。具体而言，YOLOv5n的mAP50和精度分别比DRBD-YOLOv8低2.6%和3.2%。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/deb38ea498ce4beaa63544a02a556e7a.png)

为了更直观地比较DRBD-
YOLOv8的综合性能，将mAP50绘制在纵轴上，横轴则展示其他四个评估指标。图11a和11b分别展示了mAP50与GFLOPs以及mAP50与模型大小的散点图。在这些图中，越靠近左上角的点表示性能越好。图11c和11d分别展示了mAP50与FPS以及mAP50与精度的散点图，越靠近右下角的点表示性能越优。DRBD-
YOLOv8模型整体表现更佳，它在保持最低计算复杂度和最小模型大小的同时，提供了最高的检测精度和FPS。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/834a0d4ed60747e19ae7c833135c77be.png)  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/151580948d884c2f915db29543bd3d0d.png)

图11. 不同模型在不同指标上的比较：(a) GFLOPs与mAP50，(b) 模型大小与mAP50，© FPS与mAP50，(d) P与mAP5

### 3.6. 公开数据集上的实验结果

采用DUT反无人机数据集对DRBD-
YOLOv8模型进行重新训练、验证和测试，以评估其鲁棒性和泛化能力[49]。该数据集包含10,000张无人机图像，其中5200张用于训练，2600张用于验证，2200张用于测试。数据集涵盖了超过35种无人机模型，涉及多种场景、光照条件和天气情况，是评估无人机检测模型鲁棒性和性能的理想基准。对比实验结果表明，DRBD-
YOLOv8在帧率上比YOLOv8n高出24
FPS，mAP50提升了2.6%，mAP95提升了1.1%，召回率提升了0.8%，精确率提升了0.9%（见表9）。与YOLOv8n相比，DRBD-
YOLOv8在DUT反无人机数据集上的所有评估指标均表现出更优的性能。这些发现验证了DRBD-YOLOv8模型出色的泛化能力和鲁棒性。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/2939958c90cb4a3889f48a5b4158e2b6.png)

### 3.7 可视化实验

总体而言，DRBD-
YOLOv8成功解决了YOLOv8n引入的误检和漏检问题。由于跨层特征融合和多尺度特征提取的改进，该模型对远距离无人机的检测更加敏感。此外，为了提高所开发模型在复杂检测环境中的鲁棒性和性能，DN-
ShapeIoU损失函数根据样本质量调整了学习梯度。

通过对多种场景下的无人机图像进行分析，比较了DRBD-YOLOv8与YOLOv8n的检测性能。从图12中可以明显看出，DRBD-
YOLOv8在检测精度、小目标识别能力以及对干扰的鲁棒性方面均优于基线模型。图12放大了检测结果，以便提供更易读的展示。在图12a中，DRBD-
YOLOv8在同一图像上显示出比YOLOv8n更高的检测置信度。在图12b中，YOLOv8n将树叶错误分类为无人机，而DRBD-
YOLOv8则正确将其分类为无人机。对于非常小的目标，如图12c所示，YOLOv8n未能检测到仅占几个像素的远处无人机，而DRBD-
YOLOv8成功识别了它。此外，图12d展示了一种情况，即在高空飞行的无人机被树枝部分遮挡。由于复杂的背景，YOLOv8n难以辨别无人机，而DRBD-
YOLOv8则准确地检测到了它。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c32e6d3d33484d66958f68ede6fe6034.png)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/34c05cb3939142878aea99dff849d624.png)  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/30c6dd32bea84cf8854de34ea5a328cb.png)  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/160d0834722a4ce99f439da7b7417312.png)

图12. YOLOv8n（左图）和DRBD-YOLOv8（右图）的检测结果。(a) 在城市区域。(b) 中，绿色圆圈标记的椭圆为误检对象。(c,d)
中，深紫色圆圈标记的椭圆为漏检对象。

## 4.讨论

DRBD-
YOLOv8模型相较于YOLOv8n进行了多项显著改进。首先，在骨干网络中引入了深度可分离卷积，以在保持计算效率的同时提升检测性能。其次，通过使用RCELAN模块和BiFPN架构，改进了跨尺度信息提取与融合。这些改进增强了模型对小目标的敏感性，同时显著降低了计算负载和复杂度。最后，DN-
ShapeIoU损失函数通过根据样本质量动态调整梯度，实现了更好的边界框回归和整体检测精度。

DRBD-
YOLOv8相较于原始YOLOv8n展现出显著改进，mAP50提升了1.6%，mAP95提高了1.3%，召回率增加了1.9%，精确率提升了1.3%。此外，模型的GFLOPs和参数量分别减少了29.6%和47.8%，达到了3.25M的紧凑尺寸，几乎比原始模型缩小了一半。DRBD-
YOLOv8还实现了357
FPS的高帧率，满足了实时检测的需求。该模型在公开的DUT反无人机数据集上的稳健表现进一步证实了其泛化能力和可靠性。与其他领先检测模型的对比实验凸显了DRBD-
YOLOv8在轻量化设计、检测速度和准确性方面的优势，使其成为部署在车辆安全系统、移动设备和边缘计算设备中进行实时无人机检测和空域威胁监测的理想选择。

然而，DRBD-YOLOv8也存在一些局限性。尽管DRBD-
YOLOv8在检测速度上有所提升，但这种提升的程度仍然较小。为了进一步提高检测速度，未来的研究可能会集中在探索模型压缩策略上。此外，该模型并未考虑天气对检测性能的影响。需要集成先进的去雨和图像去雾算法，以提升模型在恶劣天气条件下的性能，从而增强其泛化能力。另外，未来的研究还将涉及将该模型部署在边缘计算设备上，进行真实无人机检测实验，并根据实验结果对模型进行微调。

## 5.结论

本研究提出了DRBD-
YOLOv8，这是一种优化的无人机检测模型，相较于YOLOv8n，它融合了多项显著改进。这些改进包括在骨干网络中引入深度可分离卷积，在颈部使用RCELAN融合模块和BiFPN结构，以及应用DN-
ShapeIoU损失函数。DRBD-YOLOv8专为高速计算、提高精度、降低计算需求和减少内存占用而设计，使其成为嵌入式边缘设备上实时检测的理想选择。



