---
layout: post
title: "从WorkTool看RPA技术演进移动端自动化的未来趋势"
date: 2025-03-12 11:03:17 +0800
description: "西安交大提出的两阶段框架，通过视觉解析UI并生成自然语言描述，由LLM拆解任务步骤，在147个真实任务中达到人类水平完成率。：支持鸿蒙/安卓双平台，通过视觉模型+ADB实现跨APP操作（如微信自动回复+小红书评论），任务成功率比单设备方案提升40%。：多Agent协作框架，订座任务中通过“视觉感知-Agent-执行器”链路实现端到端操作，意图理解准确率91%。：港大研发的纯视觉方案，无需后台数据支持，在AndroidWorld基准测试中超越Claude 3.5。"
keywords: "从WorkTool看RPA技术演进——移动端自动化的未来趋势"
categories: ['Rpa']
tags: ['运维', '自动化', 'Rpa']
artid: "146199445"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146199445
    alt: "从WorkTool看RPA技术演进移动端自动化的未来趋势"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146199445
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146199445
cover: https://bing.ee123.net/img/rand?artid=146199445
image: https://bing.ee123.net/img/rand?artid=146199445
img: https://bing.ee123.net/img/rand?artid=146199445
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     从WorkTool看RPA技术演进——移动端自动化的未来趋势
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h5>
     <a id="RPA_0">
     </a>
     <strong>
      一、RPA技术发展脉络：从脚本到多模态智能体
     </strong>
    </h5>
    <p>
     传统RPA技术以控件操作为核心，但移动端场景的复杂性和动态性催生了新一代技术范式：
    </p>
    <ol>
     <li>
      <p>
       <strong>
        控件依赖阶段
       </strong>
       （2010-2020）
       <br/>
       • 依赖Android无障碍服务（AccessibilityService）解析控件树，通过ID或坐标定位元素。
       <br/>
       •
       <strong>
        局限性
       </strong>
       ：应用界面改版易导致脚本失效，维护成本高。
      </p>
     </li>
     <li>
      <p>
       <strong>
        视觉增强阶段
       </strong>
       （2021-2024）
       <br/>
       • 引入计算机视觉（CV）技术，例如OpenCV模板匹配和OCR文字识别：
      </p>
      <pre><code class="prism language-python"><span class="token comment"># OpenCV按钮定位示例</span>
result <span class="token operator">=</span> cv2<span class="token punctuation">.</span>matchTemplate<span class="token punctuation">(</span>screen<span class="token punctuation">,</span> template<span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>TM_CCOEFF_NORMED<span class="token punctuation">)</span>
</code></pre>
      <p>
       •
       <strong>
        突破
       </strong>
       ：降低对控件ID的依赖，跨应用兼容性提升30%。
      </p>
     </li>
     <li>
      <p>
       <strong>
        大模型驱动阶段
       </strong>
       （2024至今）
       <br/>
       • 融合视觉大模型（VLMs）与LLM任务规划，实现端到端自动化。典型方案包括：
       <br/>
       ◦
       <strong>
        VisionTasker
       </strong>
       ：西安交大提出的两阶段框架，通过视觉解析UI并生成自然语言描述，由LLM拆解任务步骤，在147个真实任务中达到人类水平完成率。
       <br/>
       ◦
       <strong>
        Aria-UI
       </strong>
       ：港大研发的纯视觉方案，无需后台数据支持，在AndroidWorld基准测试中超越Claude 3.5。
       <br/>
       ◦
       <strong>
        AutoGLM
       </strong>
       ：智谱AI基于自进化强化学习框架，在Web和手机端任务成功率提升160-200%。
      </p>
     </li>
    </ol>
    <hr/>
    <h5>
     <a id="_22">
     </a>
     <strong>
      二、移动端自动化技术瓶颈与视觉大模型破局
     </strong>
    </h5>
    <h6>
     <a id="1__23">
     </a>
     <strong>
      1. 传统方案的核心痛点
     </strong>
    </h6>
    <p>
     •
     <strong>
      动态界面适配
     </strong>
     ：企业微信等应用频繁更新导致控件ID失效（如2024年11月版本升级导致30%脚本报错）。
     <br/>
     •
     <strong>
      跨语言/跨平台限制
     </strong>
     ：HTML源码解析无法处理混合开发框架（如Flutter）的应用。
    </p>
    <h6>
     <a id="2__27">
     </a>
     <strong>
      2. 视觉大模型的革新性突破
     </strong>
    </h6>
    <p>
     •
     <strong>
      视觉-语言联合表征
     </strong>
     <br/>
     •
     <strong>
      案例
     </strong>
     ：VisionTasker通过CLIP模型推断无标签按钮功能（如小红书“点赞”图标识别准确率达92%），并划分功能区块生成自然语言描述供LLM决策。
     <br/>
     •
     <strong>
      动态任务规划能力
     </strong>
     <br/>
     •
     <strong>
      AutoGLM
     </strong>
     采用自进化课程强化学习，模拟人类操作轨迹：
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 伪代码：动态调整任务难度</span>
<span class="token keyword">if</span> current_success_rate <span class="token operator">&gt;</span> <span class="token number">80</span><span class="token operator">%</span><span class="token punctuation">:</span>
    task_difficulty <span class="token operator">+=</span> <span class="token number">1</span>  <span class="token comment"># 提升任务复杂度</span>
</code></pre>
    <p>
     • 结果：在订外卖等复杂任务中，步骤拆解准确率比传统方法提升45%。
    </p>
    <hr/>
    <h5>
     <a id="Agent_41">
     </a>
     <strong>
      三、技术实现：从单模态到多Agent协同
     </strong>
    </h5>
    <h6>
     <a id="1__42">
     </a>
     <strong>
      1. 视觉大模型的核心架构
     </strong>
    </h6>
    <p>
     •
     <strong>
      VisionTasker的两阶段框架
     </strong>
     ：
    </p>
    <div class="mermaid">
     <svg class="mermaid-svg" height="62" id="mermaid-svg-M78arlgBqm4a8iD2" viewbox="0 0 881.734375 62" width="881.734375" xmlns="http://www.w3.org/2000/svg">
      <style>
       #mermaid-svg-M78arlgBqm4a8iD2 {font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:16px;fill:#333;}#mermaid-svg-M78arlgBqm4a8iD2 .error-icon{fill:#552222;}#mermaid-svg-M78arlgBqm4a8iD2 .error-text{fill:#552222;stroke:#552222;}#mermaid-svg-M78arlgBqm4a8iD2 .edge-thickness-normal{stroke-width:2px;}#mermaid-svg-M78arlgBqm4a8iD2 .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg-M78arlgBqm4a8iD2 .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg-M78arlgBqm4a8iD2 .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg-M78arlgBqm4a8iD2 .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg-M78arlgBqm4a8iD2 .marker{fill:#333333;stroke:#333333;}#mermaid-svg-M78arlgBqm4a8iD2 .marker.cross{stroke:#333333;}#mermaid-svg-M78arlgBqm4a8iD2 svg{font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg-M78arlgBqm4a8iD2 .label{font-family:"trebuchet ms",verdana,arial,sans-serif;color:#333;}#mermaid-svg-M78arlgBqm4a8iD2 .cluster-label text{fill:#333;}#mermaid-svg-M78arlgBqm4a8iD2 .cluster-label span{color:#333;}#mermaid-svg-M78arlgBqm4a8iD2 .label text,#mermaid-svg-M78arlgBqm4a8iD2 span{fill:#333;color:#333;}#mermaid-svg-M78arlgBqm4a8iD2 .node rect,#mermaid-svg-M78arlgBqm4a8iD2 .node circle,#mermaid-svg-M78arlgBqm4a8iD2 .node ellipse,#mermaid-svg-M78arlgBqm4a8iD2 .node polygon,#mermaid-svg-M78arlgBqm4a8iD2 .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-svg-M78arlgBqm4a8iD2 .node .label{text-align:center;}#mermaid-svg-M78arlgBqm4a8iD2 .node.clickable{cursor:pointer;}#mermaid-svg-M78arlgBqm4a8iD2 .arrowheadPath{fill:#333333;}#mermaid-svg-M78arlgBqm4a8iD2 .edgePath .path{stroke:#333333;stroke-width:2.0px;}#mermaid-svg-M78arlgBqm4a8iD2 .flowchart-link{stroke:#333333;fill:none;}#mermaid-svg-M78arlgBqm4a8iD2 .edgeLabel{background-color:#e8e8e8;text-align:center;}#mermaid-svg-M78arlgBqm4a8iD2 .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#mermaid-svg-M78arlgBqm4a8iD2 .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-svg-M78arlgBqm4a8iD2 .cluster text{fill:#333;}#mermaid-svg-M78arlgBqm4a8iD2 .cluster span{color:#333;}#mermaid-svg-M78arlgBqm4a8iD2 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg-M78arlgBqm4a8iD2 :root{--mermaid-font-family:"trebuchet ms",verdana,arial,sans-serif;}
      </style>
      <g>
       <g class="output">
        <g class="clusters">
        </g>
        <g class="edgePaths">
         <g class="edgePath LS-A LE-B" id="L-A-B" style="opacity: 1;">
          <path class="path" d="M106.828125,31L110.99479166666667,31C115.16145833333333,31,123.49479166666667,31,131.828125,31C140.16145833333334,31,148.49479166666666,31,152.66145833333334,31L156.828125,31" marker-end="url(#arrowhead122)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead122" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
         <g class="edgePath LS-B LE-C" id="L-B-C" style="opacity: 1;">
          <path class="path" d="M303.875,31L308.0416666666667,31C312.2083333333333,31,320.5416666666667,31,328.875,31C337.2083333333333,31,345.5416666666667,31,349.7083333333333,31L353.875,31" marker-end="url(#arrowhead123)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead123" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
         <g class="edgePath LS-C LE-D" id="L-C-D" style="opacity: 1;">
          <path class="path" d="M549.875,31L554.0416666666666,31C558.2083333333334,31,566.5416666666666,31,574.875,31C583.2083333333334,31,591.5416666666666,31,595.7083333333334,31L599.875,31" marker-end="url(#arrowhead124)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead124" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
         <g class="edgePath LS-D LE-E" id="L-D-E" style="opacity: 1;">
          <path class="path" d="M711.4296875,31L715.5963541666666,31C719.7630208333334,31,728.0963541666666,31,736.4296875,31C744.7630208333334,31,753.0963541666666,31,757.2630208333334,31L761.4296875,31" marker-end="url(#arrowhead125)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead125" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
        </g>
        <g class="edgeLabels">
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-A' L-LE-B" id="L-L-A-B">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-B' L-LE-C" id="L-L-B-C">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-C' L-LE-D" id="L-L-C-D">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-D' L-LE-E" id="L-L-D-E">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
        </g>
        <g class="nodes">
         <g class="node default" id="flowchart-A-72" style="opacity: 1;" transform="translate(57.4140625,31)">
          <rect class="label-container" height="46" rx="0" ry="0" width="98.828125" x="-49.4140625" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-39.4140625,-13)">
            <foreignobject height="26" width="78.828125">
             <div style="display: inline-block; white-space: nowrap;">
              视觉UI解析
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-B-73" style="opacity: 1;" transform="translate(230.3515625,31)">
          <rect class="label-container" height="46" rx="0" ry="0" width="147.046875" x="-73.5234375" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-63.5234375,-13)">
            <foreignobject height="26" width="127.046875">
             <div style="display: inline-block; white-space: nowrap;">
              CLIP推断元素功能
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-C-75" style="opacity: 1;" transform="translate(451.875,31)">
          <rect class="label-container" height="46" rx="0" ry="0" width="196" x="-98" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-88,-13)">
            <foreignobject height="26" width="176">
             <div style="display: inline-block; white-space: nowrap;">
              区块划分与自然语言描述
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-D-77" style="opacity: 1;" transform="translate(655.65234375,31)">
          <rect class="label-container" height="46" rx="0" ry="0" width="111.5546875" x="-55.77734375" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-45.77734375,-13)">
            <foreignobject height="26" width="91.5546875">
             <div style="display: inline-block; white-space: nowrap;">
              LLM任务规划
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-E-79" style="opacity: 1;" transform="translate(817.58203125,31)">
          <rect class="label-container" height="46" rx="0" ry="0" width="112.3046875" x="-56.15234375" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-46.15234375,-13)">
            <foreignobject height="26" width="92.3046875">
             <div style="display: inline-block; white-space: nowrap;">
              ADB执行操作
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
        </g>
       </g>
      </g>
     </svg>
    </div>
    <p>
     •
     <strong>
      性能数据
     </strong>
     ：单步动作预测准确率67%，跨语言任务泛化能力提升35%。
    </p>
    <h6>
     <a id="2__53">
     </a>
     <strong>
      2. 分布式自动化演进
     </strong>
    </h6>
    <p>
     •
     <strong>
      Mobile-Agent-v2
     </strong>
     ：支持鸿蒙/安卓双平台，通过视觉模型+ADB实现跨APP操作（如微信自动回复+小红书评论），任务成功率比单设备方案提升40%。
     <br/>
     •
     <strong>
      vivo PhoneGPT
     </strong>
     ：多Agent协作框架，订座任务中通过“视觉感知-Agent-执行器”链路实现端到端操作，意图理解准确率91%。
    </p>
    <hr/>
    <h5>
     <a id="_59">
     </a>
     <strong>
      四、伦理与监管：技术创新的边界
     </strong>
    </h5>
    <ol>
     <li>
      <p>
       <strong>
        数据安全风险
       </strong>
       <br/>
       • VisionTasker等方案明确禁止采集聊天记录，仅保留操作日志；
       <br/>
       • 《生成式人工智能服务管理办法》要求自动化工具需提供“人工接管”接口（如AutoGLM的任务中断功能）。
      </p>
     </li>
     <li>
      <p>
       <strong>
        频率控制策略
       </strong>
       <br/>
       • 企业微信场景建议：消息间隔≥10秒/条，单日上限1000条，避免触发反骚扰机制。
      </p>
     </li>
    </ol>
    <hr/>
    <h5>
     <a id="_69">
     </a>
     <strong>
      五、未来趋势与开发者建议
     </strong>
    </h5>
    <ol>
     <li>
      <p>
       <strong>
        技术融合方向
       </strong>
       <br/>
       •
       <strong>
        低代码化
       </strong>
       ：vivo PhoneGPT支持自然语言指令生成自动化流程（如“每周五订咖啡”）；
       <br/>
       •
       <strong>
        边缘计算优化
       </strong>
       ：Aria-UI的MoE架构将模型参数压缩至3.9B，内存占用降低60%。
      </p>
     </li>
     <li>
      <p>
       <strong>
        开发实践指南
       </strong>
       <br/>
       •
       <strong>
        设备选型
       </strong>
       ：优先小米/OPPO等对无障碍服务限制较少的机型；
       <br/>
       •
       <strong>
        抗风控设计
       </strong>
       ：随机化操作间隔（±20%）、修改设备指纹。
      </p>
     </li>
    </ol>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f753031323936303135352f:61727469636c652f64657461696c732f313436313939343435" class_="artid" style="display:none">
 </p>
</div>


