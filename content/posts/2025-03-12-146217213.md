---
layout: post
title: "神经网络的探秘从基础到实战"
date: 2025-03-12 22:54:02 +0800
description: "神经网络的探秘：从基础到实战"
keywords: "神经网络的探秘：从基础到实战"
categories: ['Ai']
tags: ['神经网络', '深度学习', '人工智能']
artid: "146217213"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146217213
    alt: "神经网络的探秘从基础到实战"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146217213
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146217213
cover: https://bing.ee123.net/img/rand?artid=146217213
image: https://bing.ee123.net/img/rand?artid=146217213
img: https://bing.ee123.net/img/rand?artid=146217213
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     神经网络的探秘：从基础到实战
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-dracula" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/e61ec21e850440d38944a8ff21810c27.webp#pic_center">
      <br/>
      <code>
       前些天发现了一个巨牛的人工智能学习网站，通俗易懂，风趣幽默，忍不住分享一下给大家。点击跳转到网站。
      </code>
      <a href="https://www.captainbed.cn/north" rel="nofollow">
       https://www.captainbed.cn/north
      </a>
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/58301668db8c4b56af1fccf0988639e5.gif#pic_center"/>
     </img>
    </p>
    <p>
    </p>
    <p>
    </p>
    <h3>
     <a id="_6">
     </a>
     一、神经网络简介
    </h3>
    <p>
     神经网络是一种模拟人脑神经元工作方式的机器学习模型。它由多个层次组成，每一层包含多个神经元，这些神经元通过权重和偏置连接在一起。神经网络通过前向传播和反向传播来学习和优化模型参数。
    </p>
    <h4>
     <a id="11__10">
     </a>
     1.1 神经网络的基本结构
    </h4>
    <p>
     神经网络通常由输入层、隐藏层和输出层组成。输入层接收原始数据，隐藏层进行特征提取和转换，输出层生成最终的预测结果。
    </p>
    <div class="mermaid">
     <svg class="mermaid-svg" height="350" id="mermaid-svg-WjMpcl4nebzQJ4Cl" viewbox="0 0 92.4000015258789 350" width="92.4000015258789" xmlns="http://www.w3.org/2000/svg">
      <style>
       #mermaid-svg-WjMpcl4nebzQJ4Cl {font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:16px;fill:#333;}#mermaid-svg-WjMpcl4nebzQJ4Cl .error-icon{fill:#552222;}#mermaid-svg-WjMpcl4nebzQJ4Cl .error-text{fill:#552222;stroke:#552222;}#mermaid-svg-WjMpcl4nebzQJ4Cl .edge-thickness-normal{stroke-width:2px;}#mermaid-svg-WjMpcl4nebzQJ4Cl .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg-WjMpcl4nebzQJ4Cl .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg-WjMpcl4nebzQJ4Cl .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg-WjMpcl4nebzQJ4Cl .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg-WjMpcl4nebzQJ4Cl .marker{fill:#333333;stroke:#333333;}#mermaid-svg-WjMpcl4nebzQJ4Cl .marker.cross{stroke:#333333;}#mermaid-svg-WjMpcl4nebzQJ4Cl svg{font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg-WjMpcl4nebzQJ4Cl .label{font-family:"trebuchet ms",verdana,arial,sans-serif;color:#333;}#mermaid-svg-WjMpcl4nebzQJ4Cl .cluster-label text{fill:#333;}#mermaid-svg-WjMpcl4nebzQJ4Cl .cluster-label span{color:#333;}#mermaid-svg-WjMpcl4nebzQJ4Cl .label text,#mermaid-svg-WjMpcl4nebzQJ4Cl span{fill:#333;color:#333;}#mermaid-svg-WjMpcl4nebzQJ4Cl .node rect,#mermaid-svg-WjMpcl4nebzQJ4Cl .node circle,#mermaid-svg-WjMpcl4nebzQJ4Cl .node ellipse,#mermaid-svg-WjMpcl4nebzQJ4Cl .node polygon,#mermaid-svg-WjMpcl4nebzQJ4Cl .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-svg-WjMpcl4nebzQJ4Cl .node .label{text-align:center;}#mermaid-svg-WjMpcl4nebzQJ4Cl .node.clickable{cursor:pointer;}#mermaid-svg-WjMpcl4nebzQJ4Cl .arrowheadPath{fill:#333333;}#mermaid-svg-WjMpcl4nebzQJ4Cl .edgePath .path{stroke:#333333;stroke-width:2.0px;}#mermaid-svg-WjMpcl4nebzQJ4Cl .flowchart-link{stroke:#333333;fill:none;}#mermaid-svg-WjMpcl4nebzQJ4Cl .edgeLabel{background-color:#e8e8e8;text-align:center;}#mermaid-svg-WjMpcl4nebzQJ4Cl .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#mermaid-svg-WjMpcl4nebzQJ4Cl .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-svg-WjMpcl4nebzQJ4Cl .cluster text{fill:#333;}#mermaid-svg-WjMpcl4nebzQJ4Cl .cluster span{color:#333;}#mermaid-svg-WjMpcl4nebzQJ4Cl div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg-WjMpcl4nebzQJ4Cl :root{--mermaid-font-family:"trebuchet ms",verdana,arial,sans-serif;}
      </style>
      <g>
       <g class="output">
        <g class="clusters">
        </g>
        <g class="edgePaths">
         <g class="edgePath LS-A LE-B" id="L-A-B" style="opacity: 1;">
          <path class="path" d="M46.20000076293945,54L46.20000076293945,58.166666666666664C46.20000076293945,62.333333333333336,46.20000076293945,70.66666666666667,46.20000076293945,79C46.20000076293945,87.33333333333333,46.20000076293945,95.66666666666667,46.20000076293945,99.83333333333333L46.20000076293945,104" marker-end="url(#arrowhead207)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead207" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
         <g class="edgePath LS-B LE-C" id="L-B-C" style="opacity: 1;">
          <path class="path" d="M46.20000076293945,150L46.20000076293945,154.16666666666666C46.20000076293945,158.33333333333334,46.20000076293945,166.66666666666666,46.20000076293945,175C46.20000076293945,183.33333333333334,46.20000076293945,191.66666666666666,46.20000076293945,195.83333333333334L46.20000076293945,200" marker-end="url(#arrowhead208)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead208" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
         <g class="edgePath LS-C LE-D" id="L-C-D" style="opacity: 1;">
          <path class="path" d="M46.20000076293945,246L46.20000076293945,250.16666666666666C46.20000076293945,254.33333333333334,46.20000076293945,262.6666666666667,46.20000076293945,271C46.20000076293945,279.3333333333333,46.20000076293945,287.6666666666667,46.20000076293945,291.8333333333333L46.20000076293945,296" marker-end="url(#arrowhead209)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead209" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
        </g>
        <g class="edgeLabels">
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-A' L-LE-B" id="L-L-A-B">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-B' L-LE-C" id="L-L-B-C">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-C' L-LE-D" id="L-L-C-D">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
        </g>
        <g class="nodes">
         <g class="node default" id="flowchart-A-126" style="opacity: 1;" transform="translate(46.20000076293945,31)">
          <rect class="label-container" height="46" rx="0" ry="0" width="68" x="-34" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-24,-13)">
            <foreignobject height="26" width="48">
             <div style="display: inline-block; white-space: nowrap;">
              输入层
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-B-127" style="opacity: 1;" transform="translate(46.20000076293945,127)">
          <rect class="label-container" height="46" rx="0" ry="0" width="76.4000015258789" x="-38.20000076293945" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-28.200000762939453,-13)">
            <foreignobject height="26" width="56.400001525878906">
             <div style="display: inline-block; white-space: nowrap;">
              隐藏层1
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-C-129" style="opacity: 1;" transform="translate(46.20000076293945,223)">
          <rect class="label-container" height="46" rx="0" ry="0" width="76.4000015258789" x="-38.20000076293945" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-28.200000762939453,-13)">
            <foreignobject height="26" width="56.400001525878906">
             <div style="display: inline-block; white-space: nowrap;">
              隐藏层2
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-D-131" style="opacity: 1;" transform="translate(46.20000076293945,319)">
          <rect class="label-container" height="46" rx="0" ry="0" width="68" x="-34" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-24,-13)">
            <foreignobject height="26" width="48">
             <div style="display: inline-block; white-space: nowrap;">
              输出层
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
        </g>
       </g>
      </g>
     </svg>
    </div>
    <h4>
     <a id="12__21">
     </a>
     1.2 神经元的工作原理
    </h4>
    <p>
     每个神经元接收来自前一层神经元的输入，通过加权求和并加上偏置，然后通过激活函数生成输出。
    </p>
    <p>
     <span class="katex--display">
      <span class="katex-display">
       <span class="katex">
        <span class="katex-mathml">
         z 
         
        
          = 
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
           n 
          
         
         
         
           w 
          
         
           i 
          
         
         
         
           x 
          
         
           i 
          
         
        
          + 
         
        
          b 
         
        
       
         z = \sum_{i=1}^{n} w_i x_i + b
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.4306em;">
          </span>
          <span class="mord mathnormal" style="margin-right: 0.044em;">
           z
          </span>
          <span class="mspace" style="margin-right: 0.2778em;">
          </span>
          <span class="mrel">
           =
          </span>
          <span class="mspace" style="margin-right: 0.2778em;">
          </span>
         </span>
         <span class="base">
          <span class="strut" style="height: 2.9291em; vertical-align: -1.2777em;">
          </span>
          <span class="mop op-limits">
           <span class="vlist-t vlist-t2">
            <span class="vlist-r">
             <span class="vlist" style="height: 1.6514em;">
              <span class="" style="top: -1.8723em; margin-left: 0em;">
               <span class="pstrut" style="height: 3.05em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mtight">
                 <span class="mord mathnormal mtight">
                  i
                 </span>
                 <span class="mrel mtight">
                  =
                 </span>
                 <span class="mord mtight">
                  1
                 </span>
                </span>
               </span>
              </span>
              <span class="" style="top: -3.05em;">
               <span class="pstrut" style="height: 3.05em;">
               </span>
               <span class="">
                <span class="mop op-symbol large-op">
                 ∑
                </span>
               </span>
              </span>
              <span class="" style="top: -4.3em; margin-left: 0em;">
               <span class="pstrut" style="height: 3.05em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mtight">
                 <span class="mord mathnormal mtight">
                  n
                 </span>
                </span>
               </span>
              </span>
             </span>
             <span class="vlist-s">
              ​
             </span>
            </span>
            <span class="vlist-r">
             <span class="vlist" style="height: 1.2777em;">
              <span class="">
              </span>
             </span>
            </span>
           </span>
          </span>
          <span class="mspace" style="margin-right: 0.1667em;">
          </span>
          <span class="mord">
           <span class="mord mathnormal" style="margin-right: 0.0269em;">
            w
           </span>
           <span class="msupsub">
            <span class="vlist-t vlist-t2">
             <span class="vlist-r">
              <span class="vlist" style="height: 0.3117em;">
               <span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;">
                <span class="pstrut" style="height: 2.7em;">
                </span>
                <span class="sizing reset-size6 size3 mtight">
                 <span class="mord mathnormal mtight">
                  i
                 </span>
                </span>
               </span>
              </span>
              <span class="vlist-s">
               ​
              </span>
             </span>
             <span class="vlist-r">
              <span class="vlist" style="height: 0.15em;">
               <span class="">
               </span>
              </span>
             </span>
            </span>
           </span>
          </span>
          <span class="mord">
           <span class="mord mathnormal">
            x
           </span>
           <span class="msupsub">
            <span class="vlist-t vlist-t2">
             <span class="vlist-r">
              <span class="vlist" style="height: 0.3117em;">
               <span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;">
                <span class="pstrut" style="height: 2.7em;">
                </span>
                <span class="sizing reset-size6 size3 mtight">
                 <span class="mord mathnormal mtight">
                  i
                 </span>
                </span>
               </span>
              </span>
              <span class="vlist-s">
               ​
              </span>
             </span>
             <span class="vlist-r">
              <span class="vlist" style="height: 0.15em;">
               <span class="">
               </span>
              </span>
             </span>
            </span>
           </span>
          </span>
          <span class="mspace" style="margin-right: 0.2222em;">
          </span>
          <span class="mbin">
           +
          </span>
          <span class="mspace" style="margin-right: 0.2222em;">
          </span>
         </span>
         <span class="base">
          <span class="strut" style="height: 0.6944em;">
          </span>
          <span class="mord mathnormal">
           b
          </span>
         </span>
        </span>
       </span>
      </span>
     </span>
    </p>
    <p>
     <span class="katex--display">
      <span class="katex-display">
       <span class="katex">
        <span class="katex-mathml">
         a 
         
        
          = 
         
        
          σ 
         
        
          ( 
         
        
          z 
         
        
          ) 
         
        
       
         a = \sigma(z)
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.4306em;">
          </span>
          <span class="mord mathnormal">
           a
          </span>
          <span class="mspace" style="margin-right: 0.2778em;">
          </span>
          <span class="mrel">
           =
          </span>
          <span class="mspace" style="margin-right: 0.2778em;">
          </span>
         </span>
         <span class="base">
          <span class="strut" style="height: 1em; vertical-align: -0.25em;">
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0359em;">
           σ
          </span>
          <span class="mopen">
           (
          </span>
          <span class="mord mathnormal" style="margin-right: 0.044em;">
           z
          </span>
          <span class="mclose">
           )
          </span>
         </span>
        </span>
       </span>
      </span>
     </span>
    </p>
    <p>
     其中，
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        w 
         
        
          i 
         
        
       
      
        w_i
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 0.5806em; vertical-align: -0.15em;">
         </span>
         <span class="mord">
          <span class="mord mathnormal" style="margin-right: 0.0269em;">
           w
          </span>
          <span class="msupsub">
           <span class="vlist-t vlist-t2">
            <span class="vlist-r">
             <span class="vlist" style="height: 0.3117em;">
              <span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;">
               <span class="pstrut" style="height: 2.7em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mathnormal mtight">
                 i
                </span>
               </span>
              </span>
             </span>
             <span class="vlist-s">
              ​
             </span>
            </span>
            <span class="vlist-r">
             <span class="vlist" style="height: 0.15em;">
              <span class="">
              </span>
             </span>
            </span>
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
     </span>
     是权重，
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        x 
         
        
          i 
         
        
       
      
        x_i
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 0.5806em; vertical-align: -0.15em;">
         </span>
         <span class="mord">
          <span class="mord mathnormal">
           x
          </span>
          <span class="msupsub">
           <span class="vlist-t vlist-t2">
            <span class="vlist-r">
             <span class="vlist" style="height: 0.3117em;">
              <span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;">
               <span class="pstrut" style="height: 2.7em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mathnormal mtight">
                 i
                </span>
               </span>
              </span>
             </span>
             <span class="vlist-s">
              ​
             </span>
            </span>
            <span class="vlist-r">
             <span class="vlist" style="height: 0.15em;">
              <span class="">
              </span>
             </span>
            </span>
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
     </span>
     是输入，
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        b 
        
       
      
        b
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 0.6944em;">
         </span>
         <span class="mord mathnormal">
          b
         </span>
        </span>
       </span>
      </span>
     </span>
     是偏置，
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        σ 
        
       
      
        \sigma
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 0.4306em;">
         </span>
         <span class="mord mathnormal" style="margin-right: 0.0359em;">
          σ
         </span>
        </span>
       </span>
      </span>
     </span>
     是激活函数。
    </p>
    <h3>
     <a id="_35">
     </a>
     二、神经网络的训练过程
    </h3>
    <p>
     神经网络的训练过程包括前向传播和反向传播两个阶段。
    </p>
    <h4>
     <a id="21__39">
     </a>
     2.1 前向传播
    </h4>
    <p>
     前向传播是指数据从输入层经过隐藏层到输出层的过程。每一层的神经元通过加权求和和激活函数生成输出。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">forward_propagation</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> weights<span class="token punctuation">,</span> biases<span class="token punctuation">)</span><span class="token punctuation">:</span>
    layer_input <span class="token operator">=</span> X
    <span class="token keyword">for</span> w<span class="token punctuation">,</span> b <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>weights<span class="token punctuation">,</span> biases<span class="token punctuation">)</span><span class="token punctuation">:</span>
        z <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>layer_input<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b
        layer_input <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
    <span class="token keyword">return</span> layer_input

<span class="token comment"># 示例数据</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
weights <span class="token operator">=</span> <span class="token punctuation">[</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
biases <span class="token operator">=</span> <span class="token punctuation">[</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

output <span class="token operator">=</span> forward_propagation<span class="token punctuation">(</span>X<span class="token punctuation">,</span> weights<span class="token punctuation">,</span> biases<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="22__65">
     </a>
     2.2 反向传播
    </h4>
    <p>
     反向传播是指通过计算损失函数的梯度来更新模型参数的过程。反向传播使用链式法则来计算每一层的梯度。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">sigmoid_derivative</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> x<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">backward_propagation</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> weights<span class="token punctuation">,</span> biases<span class="token punctuation">,</span> output<span class="token punctuation">)</span><span class="token punctuation">:</span>
    m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    dZ <span class="token operator">=</span> output <span class="token operator">-</span> y
    dW <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dZ<span class="token punctuation">)</span> <span class="token operator">/</span> m
    db <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dZ<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token operator">/</span> m
    <span class="token keyword">return</span> dW<span class="token punctuation">,</span> db

<span class="token comment"># 示例数据</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
dW<span class="token punctuation">,</span> db <span class="token operator">=</span> backward_propagation<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> weights<span class="token punctuation">,</span> biases<span class="token punctuation">,</span> output<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dW<span class="token punctuation">,</span> db<span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="23__86">
     </a>
     2.3 参数更新
    </h4>
    <p>
     通过梯度下降法更新模型参数：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">update_parameters</span><span class="token punctuation">(</span>weights<span class="token punctuation">,</span> biases<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>weights<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        weights<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> dW<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        biases<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> db<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    <span class="token keyword">return</span> weights<span class="token punctuation">,</span> biases

<span class="token comment"># 示例数据</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.1</span>
weights<span class="token punctuation">,</span> biases <span class="token operator">=</span> update_parameters<span class="token punctuation">(</span>weights<span class="token punctuation">,</span> biases<span class="token punctuation">,</span> dW<span class="token punctuation">,</span> db<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>weights<span class="token punctuation">,</span> biases<span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="_103">
     </a>
     三、神经网络的类型
    </h3>
    <h4>
     <a id="31_Fully_Connected_Neural_Network_FCNN_105">
     </a>
     3.1 全连接神经网络（Fully Connected Neural Network, FCNN）
    </h4>
    <p>
     全连接神经网络是最基本的神经网络类型，每一层的神经元与下一层的所有神经元相连。
    </p>
    <div class="mermaid">
     <svg class="mermaid-svg" height="350" id="mermaid-svg-GjQ7omF4L3ktwbYx" viewbox="0 0 92.4000015258789 350" width="92.4000015258789" xmlns="http://www.w3.org/2000/svg">
      <style>
       #mermaid-svg-GjQ7omF4L3ktwbYx {font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:16px;fill:#333;}#mermaid-svg-GjQ7omF4L3ktwbYx .error-icon{fill:#552222;}#mermaid-svg-GjQ7omF4L3ktwbYx .error-text{fill:#552222;stroke:#552222;}#mermaid-svg-GjQ7omF4L3ktwbYx .edge-thickness-normal{stroke-width:2px;}#mermaid-svg-GjQ7omF4L3ktwbYx .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg-GjQ7omF4L3ktwbYx .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg-GjQ7omF4L3ktwbYx .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg-GjQ7omF4L3ktwbYx .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg-GjQ7omF4L3ktwbYx .marker{fill:#333333;stroke:#333333;}#mermaid-svg-GjQ7omF4L3ktwbYx .marker.cross{stroke:#333333;}#mermaid-svg-GjQ7omF4L3ktwbYx svg{font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg-GjQ7omF4L3ktwbYx .label{font-family:"trebuchet ms",verdana,arial,sans-serif;color:#333;}#mermaid-svg-GjQ7omF4L3ktwbYx .cluster-label text{fill:#333;}#mermaid-svg-GjQ7omF4L3ktwbYx .cluster-label span{color:#333;}#mermaid-svg-GjQ7omF4L3ktwbYx .label text,#mermaid-svg-GjQ7omF4L3ktwbYx span{fill:#333;color:#333;}#mermaid-svg-GjQ7omF4L3ktwbYx .node rect,#mermaid-svg-GjQ7omF4L3ktwbYx .node circle,#mermaid-svg-GjQ7omF4L3ktwbYx .node ellipse,#mermaid-svg-GjQ7omF4L3ktwbYx .node polygon,#mermaid-svg-GjQ7omF4L3ktwbYx .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-svg-GjQ7omF4L3ktwbYx .node .label{text-align:center;}#mermaid-svg-GjQ7omF4L3ktwbYx .node.clickable{cursor:pointer;}#mermaid-svg-GjQ7omF4L3ktwbYx .arrowheadPath{fill:#333333;}#mermaid-svg-GjQ7omF4L3ktwbYx .edgePath .path{stroke:#333333;stroke-width:2.0px;}#mermaid-svg-GjQ7omF4L3ktwbYx .flowchart-link{stroke:#333333;fill:none;}#mermaid-svg-GjQ7omF4L3ktwbYx .edgeLabel{background-color:#e8e8e8;text-align:center;}#mermaid-svg-GjQ7omF4L3ktwbYx .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#mermaid-svg-GjQ7omF4L3ktwbYx .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-svg-GjQ7omF4L3ktwbYx .cluster text{fill:#333;}#mermaid-svg-GjQ7omF4L3ktwbYx .cluster span{color:#333;}#mermaid-svg-GjQ7omF4L3ktwbYx div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg-GjQ7omF4L3ktwbYx :root{--mermaid-font-family:"trebuchet ms",verdana,arial,sans-serif;}
      </style>
      <g>
       <g class="output">
        <g class="clusters">
        </g>
        <g class="edgePaths">
         <g class="edgePath LS-A LE-B" id="L-A-B" style="opacity: 1;">
          <path class="path" d="M46.20000076293945,54L46.20000076293945,58.166666666666664C46.20000076293945,62.333333333333336,46.20000076293945,70.66666666666667,46.20000076293945,79C46.20000076293945,87.33333333333333,46.20000076293945,95.66666666666667,46.20000076293945,99.83333333333333L46.20000076293945,104" marker-end="url(#arrowhead226)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead226" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
         <g class="edgePath LS-B LE-C" id="L-B-C" style="opacity: 1;">
          <path class="path" d="M46.20000076293945,150L46.20000076293945,154.16666666666666C46.20000076293945,158.33333333333334,46.20000076293945,166.66666666666666,46.20000076293945,175C46.20000076293945,183.33333333333334,46.20000076293945,191.66666666666666,46.20000076293945,195.83333333333334L46.20000076293945,200" marker-end="url(#arrowhead227)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead227" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
         <g class="edgePath LS-C LE-D" id="L-C-D" style="opacity: 1;">
          <path class="path" d="M46.20000076293945,246L46.20000076293945,250.16666666666666C46.20000076293945,254.33333333333334,46.20000076293945,262.6666666666667,46.20000076293945,271C46.20000076293945,279.3333333333333,46.20000076293945,287.6666666666667,46.20000076293945,291.8333333333333L46.20000076293945,296" marker-end="url(#arrowhead228)" style="fill:none">
          </path>
          <defs>
           <marker id="arrowhead228" markerheight="6" markerunits="strokeWidth" markerwidth="8" orient="auto" refx="9" refy="5" viewbox="0 0 10 10">
            <path class="arrowheadPath" d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;">
            </path>
           </marker>
          </defs>
         </g>
        </g>
        <g class="edgeLabels">
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-A' L-LE-B" id="L-L-A-B">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-B' L-LE-C" id="L-L-B-C">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
         <g class="edgeLabel" style="opacity: 1;" transform="">
          <g class="label" transform="translate(0,0)">
           <rect height="0" rx="0" ry="0" width="0">
           </rect>
           <foreignobject height="0" width="0">
            <div style="display: inline-block; white-space: nowrap;">
             <span class="edgeLabel L-LS-C' L-LE-D" id="L-L-C-D">
             </span>
            </div>
           </foreignobject>
          </g>
         </g>
        </g>
        <g class="nodes">
         <g class="node default" id="flowchart-A-138" style="opacity: 1;" transform="translate(46.20000076293945,31)">
          <rect class="label-container" height="46" rx="0" ry="0" width="68" x="-34" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-24,-13)">
            <foreignobject height="26" width="48">
             <div style="display: inline-block; white-space: nowrap;">
              输入层
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-B-139" style="opacity: 1;" transform="translate(46.20000076293945,127)">
          <rect class="label-container" height="46" rx="0" ry="0" width="76.4000015258789" x="-38.20000076293945" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-28.200000762939453,-13)">
            <foreignobject height="26" width="56.400001525878906">
             <div style="display: inline-block; white-space: nowrap;">
              隐藏层1
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-C-141" style="opacity: 1;" transform="translate(46.20000076293945,223)">
          <rect class="label-container" height="46" rx="0" ry="0" width="76.4000015258789" x="-38.20000076293945" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-28.200000762939453,-13)">
            <foreignobject height="26" width="56.400001525878906">
             <div style="display: inline-block; white-space: nowrap;">
              隐藏层2
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
         <g class="node default" id="flowchart-D-143" style="opacity: 1;" transform="translate(46.20000076293945,319)">
          <rect class="label-container" height="46" rx="0" ry="0" width="68" x="-34" y="-23">
          </rect>
          <g class="label" transform="translate(0,0)">
           <g transform="translate(-24,-13)">
            <foreignobject height="26" width="48">
             <div style="display: inline-block; white-space: nowrap;">
              输出层
             </div>
            </foreignobject>
           </g>
          </g>
         </g>
        </g>
       </g>
      </g>
     </svg>
    </div>
    <h4>
     <a id="32_Convolutional_Neural_Network_CNN_116">
     </a>
     3.2 卷积神经网络（Convolutional Neural Network, CNN）
    </h4>
    <p>
     卷积神经网络主要用于图像处理任务，通过卷积层提取图像特征。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> layers

model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="33_Recurrent_Neural_Network_RNN_137">
     </a>
     3.3 循环神经网络（Recurrent Neural Network, RNN）
    </h4>
    <p>
     循环神经网络主要用于序列数据处理任务，如时间序列预测和自然语言处理。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> layers

model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    layers<span class="token punctuation">.</span>SimpleRNN<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> return_sequences<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>SimpleRNN<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="_154">
     </a>
     四、神经网络的优化技巧
    </h3>
    <h4>
     <a id="41__156">
     </a>
     4.1 正则化
    </h4>
    <p>
     正则化用于防止模型过拟合，常用的正则化方法包括L1正则化和L2正则化。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> regularizers

model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> kernel_regularizer<span class="token operator">=</span>regularizers<span class="token punctuation">.</span>l2<span class="token punctuation">(</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="42_Dropout_169">
     </a>
     4.2 Dropout
    </h4>
    <p>
     Dropout是一种随机丢弃神经元的技术，用于防止模型过拟合。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> layers

model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="43__183">
     </a>
     4.3 批量归一化
    </h4>
    <p>
     批量归一化用于加速训练过程并提高模型性能。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> layers

model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="_197">
     </a>
     五、实战案例：手写数字识别
    </h3>
    <h4>
     <a id="51__199">
     </a>
     5.1 数据集介绍
    </h4>
    <p>
     使用MNIST数据集，包含60000张训练图像和10000张测试图像，每张图像大小为28x28像素。
    </p>
    <h4>
     <a id="52__203">
     </a>
     5.2 模型构建
    </h4>
    <pre><code class="prism language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> layers

model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>
              loss<span class="token operator">=</span><span class="token string">'sparse_categorical_crossentropy'</span><span class="token punctuation">,</span>
              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="53__220">
     </a>
     5.3 模型训练
    </h4>
    <pre><code class="prism language-python">mnist <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>mnist
<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_train<span class="token punctuation">,</span> x_test <span class="token operator">=</span> x_train <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> x_test <span class="token operator">/</span> <span class="token number">255.0</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="54__230">
     </a>
     5.4 模型评估
    </h4>
    <pre><code class="prism language-python">test_loss<span class="token punctuation">,</span> test_acc <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test accuracy: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>test_acc<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="_237">
     </a>
     六、总结
    </h3>
    <p>
     本文详细介绍了神经网络的基本结构、训练过程、常见类型和优化技巧，并通过一个实战案例展示了如何使用神经网络进行手写数字识别。希望本文能帮助读者深入理解神经网络的原理和应用，并在实际项目中灵活运用。
    </p>
    <hr/>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/7671a6feb95a4874812078b124560710.gif#pic_center"/>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f31363234323631332f:61727469636c652f64657461696c732f313436323137323133" class_="artid" style="display:none">
 </p>
</div>


