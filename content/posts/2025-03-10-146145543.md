---
layout: post
title: "å¤§è¯­è¨€æ¨¡å‹-å…¨æ–‡"
date: 2025-03-10 15:36:37 +0800
description: "æœ¬åšå®¢å†…å®¹æ˜¯ã€Šå¤§è¯­è¨€æ¨¡å‹ã€‹ä¸€ä¹¦çš„è¯»ä¹¦ç¬”è®°ï¼Œæœ¬æ–‡ä¸»è¦è®°å½•datawhaleçš„æ´»åŠ¨å­¦ä¹ ç¬”è®°ï¼Œæ˜¯ç³»åˆ—åšå®¢çš„æ±‡æ€»ã€‚"
keywords: "å¤§è¯­è¨€æ¨¡å‹-å…¨æ–‡"
categories: ['æœºå™¨å­¦ä¹ 2025', 'å¤§æ¨¡å‹Llm']
tags: ['è¯­è¨€æ¨¡å‹', 'è‡ªç„¶è¯­è¨€å¤„ç†', 'äººå·¥æ™ºèƒ½', 'Datawhale']
artid: "146145543"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146145543
    alt: "å¤§è¯­è¨€æ¨¡å‹-å…¨æ–‡"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146145543
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146145543
cover: https://bing.ee123.net/img/rand?artid=146145543
image: https://bing.ee123.net/img/rand?artid=146145543
img: https://bing.ee123.net/img/rand?artid=146145543
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     å¤§è¯­è¨€æ¨¡å‹-å…¨æ–‡
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="_0">
     </a>
     ç®€ä»‹
    </h3>
    <p>
     æœ¬åšå®¢å†…å®¹æ˜¯ã€Šå¤§è¯­è¨€æ¨¡å‹ã€‹ä¸€ä¹¦çš„è¯»ä¹¦ç¬”è®°ï¼Œè¯¥ä¹¦æ˜¯ä¸­å›½äººæ°‘å¤§å­¦é«˜ç“´äººå·¥æ™ºèƒ½å­¦é™¢èµµé‘«æ•™æˆå›¢é˜Ÿå‡ºå“ï¼Œè¦†ç›–å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒä¸ä½¿ç”¨çš„å…¨æµç¨‹ï¼Œä»é¢„è®­ç»ƒåˆ°å¾®è°ƒä¸å¯¹é½ï¼Œä»ä½¿ç”¨æŠ€æœ¯åˆ°è¯„æµ‹åº”ç”¨ï¼Œå¸®åŠ©å­¦å‘˜å…¨é¢æŒæ¡å¤§è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒæŠ€æœ¯ã€‚å¹¶ä¸”ï¼Œè¯¾ç¨‹å†…å®¹åŸºäºå¤§é‡çš„ä»£ç å®æˆ˜ä¸è®²è§£ï¼Œé€šè¿‡å®é™…é¡¹ç›®ä¸æ¡ˆä¾‹ï¼Œå­¦å‘˜èƒ½å°†ç†è®ºçŸ¥è¯†åº”ç”¨äºçœŸå®åœºæ™¯ï¼Œæå‡è§£å†³å®é™…é—®é¢˜çš„èƒ½åŠ›ã€‚
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/8462d74a8d764cc7a56c909eade4c15a.png"/>
    </p>
    <p>
     æœ¬æ–‡ä¸»è¦è®°å½•datawhaleçš„æ´»åŠ¨å­¦ä¹ ç¬”è®°ï¼Œ
     <a href="https://www.datawhale.cn/activity/150" rel="nofollow">
      å¯ç‚¹å‡»æ´»åŠ¨è¿æ¥
     </a>
    </p>
    <h3>
     <a id="11_5">
     </a>
     1.1è¯­è¨€æ¨¡å‹å‘å±•å†ç¨‹
    </h3>
    <h4>
     <a id="_6">
     </a>
     å¤§æ¨¡å‹çš„èƒ½åŠ›
    </h4>
    <blockquote>
     <p>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/5f036bbc0bc146cd84af5510a5cafd13.png"/>
     </p>
    </blockquote>
    <blockquote>
     <p>
      <strong>
       èŒƒå›´å¹¿æ³›çš„ä¸–ç•ŒçŸ¥è¯†
      </strong>
      ï¼š
      <br/>
      ä¾‹å¦‚ï¼Œäº†è§£å†å²äº‹ä»¶å¦‚2024å¹´å·´é»å¥¥è¿ä¼šçš„è¯¦ç»†æƒ…å†µï¼ŒåŒ…æ‹¬å‚èµ›å›½å®¶ã€ä¸»è¦æ¯”èµ›é¡¹ç›®å’Œè·å¥–è€…çš„ä¿¡æ¯ï¼›æˆ–è€…è§£é‡Šç§‘å­¦ç†è®ºï¼Œæ¯”å¦‚é‡å­è®¡ç®—çš„åŸºæœ¬åŸç†åŠå…¶å¯¹æœªæ¥è®¡ç®—æœºæŠ€æœ¯çš„å½±å“ã€‚
      <strong>
       è¿™é‡Œä¸ºçŸ¥é“è°æ˜¯è€å­ï¼Œä»¥åŠè€å­çš„æ€æƒ³ã€‚
      </strong>
      <br/>
      <strong>
       è¾ƒå¼ºçš„äººç±»æŒ‡ä»¤éµå¾ªèƒ½åŠ›
      </strong>
      ï¼š
      <br/>
      å¦‚æœç”¨æˆ·è¯¢é—®ï¼šâ€œè¯·å¸®æˆ‘æŸ¥æ‰¾ä¸€ä¸‹å¦‚ä½•åœ¨å®¶åˆ¶ä½œä¸€æ¯æ‹¿é“å’–å•¡çš„æ–¹æ³•â€ï¼Œç³»ç»Ÿåº”è¯¥èƒ½å¤Ÿæä¾›è¯¦ç»†çš„æ­¥éª¤æŒ‡å¯¼ï¼Œä»å‡†å¤‡æ‰€éœ€ææ–™åˆ°å…·ä½“çš„åˆ¶ä½œæµç¨‹ï¼Œç¡®ä¿ç”¨æˆ·å¯ä»¥è½»æ¾è·Ÿéšæ“ä½œã€‚
      <strong>
       è¿™é‡Œä¸ºç»™å‡ºæœ¬é¢˜çš„ç­”æ¡ˆB
      </strong>
      <br/>
      <strong>
       æ”¹è¿›çš„å¤æ‚ä»»åŠ¡æ¨ç†èƒ½åŠ›
      </strong>
      ï¼š
      <br/>
      æ¯”å¦‚åˆ†æå¤æ‚çš„ç»æµæ¨¡å‹ï¼Œé¢„æµ‹æŸä¸€æ”¿ç­–å˜åŠ¨å¯¹ä¸åŒè¡Œä¸šçš„å½±å“ã€‚è¿™æ¶‰åŠåˆ°ç†è§£å®è§‚ç»æµæŒ‡æ ‡ã€å¸‚åœºè¶‹åŠ¿ä»¥åŠå„è¡Œä¸šçš„ç›¸äº’å…³ç³»ï¼Œå¹¶åŸºäºè¿™äº›ä¿¡æ¯åšå‡ºåˆç†çš„æ¨æµ‹ã€‚
      <strong>
       è¿™é‡Œä¸ºåŸºäºè€è€…çš„è¯æ¨å‡ºè€è€…çš„æ€æƒ³ï¼Œå¹¶ç»™å‡ºä¸ä¹‹åŒ¹é…çš„æ”¿æ²»ç†å¿µæå‡ºè€…
      </strong>
      <br/>
      <strong>
       è¾ƒå¼ºçš„é€šç”¨ä»»åŠ¡è§£å†³èƒ½åŠ›
      </strong>
      ï¼šä¾‹å¦‚ï¼Œå¸®åŠ©ç”¨æˆ·è§„åˆ’ä¸€æ¬¡å›½é™…æ—…è¡Œï¼Œä¸ä»…åŒ…æ‹¬é¢„è®¢æœºç¥¨å’Œé…’åº—ï¼Œè¿˜éœ€è¦è€ƒè™‘ç­¾è¯ç”³è¯·ã€å½“åœ°äº¤é€šå®‰æ’ã€æ—…æ¸¸æ™¯ç‚¹æ¨èç­‰å¤šä¸ªæ–¹é¢çš„é—®é¢˜ï¼Œç¡®ä¿æ•´ä¸ªæ—…ç¨‹é¡ºåˆ©ã€‚
      <br/>
      <strong>
       è¾ƒå¥½çš„äººç±»å¯¹é½èƒ½åŠ›
      </strong>
      ï¼š åœ¨ä¸ç”¨æˆ·çš„å¯¹è¯ä¸­ï¼Œèƒ½å¤Ÿç†è§£å¹¶å›åº”ç”¨æˆ·çš„æƒ…æ„ŸçŠ¶æ€ã€‚å¦‚æœç”¨æˆ·è¡¨è¾¾å‡ºå¤±æœ›æˆ–å›°æƒ‘çš„æƒ…ç»ªï¼Œç³»ç»Ÿåº”èƒ½ä»¥åŒç†å¿ƒå›åº”ï¼Œå¹¶æä¾›é€‚å½“çš„æ”¯æŒæˆ–å»ºè®®ï¼Œæ¯”å¦‚å½“ç”¨æˆ·æåˆ°å› ä¸ºé”™è¿‡ä¸€åœºé‡è¦ä¼šè®®è€Œæ„Ÿåˆ°æ²®ä¸§æ—¶ï¼Œç³»ç»Ÿå¯ä»¥æä¾›ä¸€äº›æ—¶é—´ç®¡ç†æŠ€å·§æˆ–é¼“åŠ±çš„è¯è¯­ã€‚
      <br/>
      <strong>
       è¾ƒå¼ºçš„å¤šè½®å¯¹è¯äº¤äº’èƒ½åŠ›
      </strong>
      ï¼š
      <br/>
      æ”¯æŒæ·±å…¥ä¸”è¿è´¯çš„å¯¹è¯ã€‚ä¾‹å¦‚ï¼Œåœ¨è®¨è®ºä¸€ä¸ªé¡¹ç›®çš„è®¡åˆ’æ—¶ï¼Œç”¨æˆ·å¯ä»¥é€æ­¥æå‡ºä¸åŒçš„é—®é¢˜æˆ–è¦æ±‚æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œç³»ç»Ÿèƒ½å¤Ÿä¿æŒä¸Šä¸‹æ–‡çš„ç†è§£ï¼ŒæŒç»­ç»™å‡ºç›¸å…³çš„å›ç­”å’Œå»ºè®®ï¼Œè€Œä¸æ˜¯æ¯æ¬¡éƒ½éœ€è¦é‡æ–°è¾“å…¥èƒŒæ™¯ä¿¡æ¯ã€‚
      <strong>
       è¿™é‡Œæ²¡æœ‰ç»§ç»­é—®ï¼Œä¸€é—®ä¸€ä¸ªä¸å±å£°
      </strong>
     </p>
    </blockquote>
    <h4>
     <a id="_20">
     </a>
     å¤§è¯­è¨€æ¨¡å‹çš„ç™¾èŠ±é½æ”¾æ—¶ä»£
    </h4>
    <p>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/977f911920464b4480a83ef77c40c181.png">
      <br/>
      è®ºæ–‡åœ°å€:
      <br/>
      <a href="https://arxiv.org/abs/2303.18223" rel="nofollow">
       https://arxiv.org/abs/2303.18223
      </a>
      <br/>
      <a href="https://hub.baai.ac.cn/view/27667" rel="nofollow">
       https://hub.baai.ac.cn/view/27667
      </a>
     </img>
    </p>
    <h4>
     <a id="_27">
     </a>
     è¯­è¨€æ¨¡å‹å‘å±•å†ç¨‹
    </h4>
    <p>
     è¯­è¨€æ¨¡å‹é€šå¸¸æ˜¯æŒ‡èƒ½å¤Ÿå»ºæ¨¡è‡ªç„¶è¯­è¨€æ–‡æœ¬ç”Ÿæˆæ¦‚ç‡çš„æ¨¡å‹ã€‚
     <br/>
     ä»è¯­è¨€å»ºæ¨¡åˆ°ä»»åŠ¡æ±‚è§£ï¼Œè¿™æ˜¯ç§‘å­¦æ€ç»´çš„ä¸€æ¬¡é‡è¦è·ƒå‡ã€‚
     <br/>
     è¯­è¨€æ¨¡å‹çš„å‘å±•å†ç¨‹å¦‚ä¸‹ï¼š
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/d504b2c9da7240d6ad260b25c998dd61.png"/>
    </p>
    <h5>
     <a id="Statistical_Language_modelsSLM_32">
     </a>
     ç»Ÿè®¡è¯­è¨€æ¨¡å‹ï¼ˆStatistical Language models,SLMï¼‰
    </h5>
    <p>
     â¢ ä¸»è¦å»ºç«‹åœ¨ç»Ÿè®¡å­¦ä¹ ç†è®ºæ¡†æ¶ï¼Œé€šå¸¸ä½¿ç”¨é“¾å¼æ³•åˆ™å»ºæ¨¡å¥å­åºåˆ—
     <br/>
     â¢ ä¾‹å¦‚ï¼š
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/b6df20b8b2db4af39e5c8cd40779692e.png"/>
    </p>
    <h6>
     <a id="ngram__36">
     </a>
     n-gram è¯­è¨€æ¨¡å‹ï¼š
    </h6>
    <p>
     n-gram è¯­è¨€æ¨¡å‹ï¼šåŸºäºé©¬å°”ç§‘å¤«å‡è®¾ï¼Œå½“å‰è¯æ¦‚ç‡ä»…ä¸å‰ğ‘› âˆ’ 1ä¸ªè¯æœ‰å…³
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/90d6a97add194cb8acc4fd1806356998.png"/>
    </p>
    <p>
     â¢ å¦‚æœä½¿ç”¨äºŒå…ƒè¯­è¨€æ¨¡å‹ï¼Œåˆ™ä¸Šè¿°ç¤ºä¾‹æ¦‚ç‡è®¡ç®—å˜ä¸º
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/6e80f32f918145e5ae54aa4c99c84d82.png"/>
    </p>
    <blockquote>
     <p>
      è¿™é‡Œçš„p(I,am,fime)è¡¨ç¤ºè¿™ä¸ªå¥å­åœ¨è¯­æ–™åº“ä¸­å‡ºç°çš„æ¦‚ç‡ï¼Œæ¦‚ç‡è¶Šå¤§ï¼Œè¯´æ˜è¿™ä¸ªå¥å­çº¦åˆç†ã€‚p(fine|am)è¡¨ç¤ºè¯­æ–™åº“ä¸­ï¼Œamåé¢å‡ºç°fineçš„æ¦‚ç‡ï¼Œæ¦‚ç‡è¶Šå¤§ï¼Œè¯´ä¹ˆè¿™ä¸ªamåé¢è¶Šå¯èƒ½åŠ fineã€‚
     </p>
    </blockquote>
    <p>
     è¯­æ–™åº“çš„æ ·ä¾‹å¦‚ä¸‹ï¼š
     <br/>
     å‚è€ƒ:
     <a href="https://bcc.blcu.edu.cn/zh/search/0/%E6%88%91%E5%BE%88" rel="nofollow">
      https://bcc.blcu.edu.cn/zh/search/0/%E6%88%91%E5%BE%88
     </a>
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/14fede33a5af4942945d876ffc49cb26.png"/>
    </p>
    <h6>
     <a id="__49">
     </a>
     åŸºäºé¢‘ç‡çš„ä¼°è®¡æ–¹æ³• (æœ€å¤§ä¼¼ç„¶ä¼°è®¡)
    </h6>
    <p>
     â¢ å››å…ƒè¯­è¨€æ¨¡å‹ä¼°è®¡ç¤ºä¾‹
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/1da6e4ec8e17406dab9fe5db4ab6b04e.png">
      <br/>
      â¢ ä¸»è¦é—®é¢˜
      <br/>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/b506fa1104904dd3ae66c379dd7835bd.png"/>
     </img>
    </p>
    <p>
     â¢ è§£å†³åŠæ³•-åŠ ä¸€å¹³æ»‘ (åˆç§°ä¸º Laplace smoothing )
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/e95c797d66484f37bd09f0e4e0521967.png"/>
    </p>
    <p>
     â¢ å›é€€ (back-off)
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/1e9eeb991a2746659b41962b8244204f.png"/>
     <br/>
     â¢ æ’å€¼ (interpolation)
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/f675e6782592471a8c5392fb9da06c64.png"/>
    </p>
    <blockquote>
     <p>
      å¯ä»¥è¯æ˜ï¼Œä»ç„¶èƒ½å¤Ÿä¿è¯è¯­è¨€æ¨¡å‹çš„æ¦‚ç‡æ€§è´¨
      <br/>
      é€šå¸¸è¿™ç§æ–¹å¼å¯ä»¥ç»“åˆä¸åŒé˜¶æ•°ä¼°è®¡æ–¹æ³•çš„ä¼˜åŠ¿
      <br/>
      ä½†ä»ç„¶ä¸èƒ½ä»æ ¹æœ¬è§£å†³æ•°æ®ç¨€ç–æ€§é—®é¢˜
     </p>
    </blockquote>
    <h5>
     <a id="Neural_Language_ModelsNLM_68">
     </a>
     ç¥ç»è¯­è¨€æ¨¡å‹ï¼ˆNeural Language Models,NLMï¼‰
    </h5>
    <blockquote>
     <p>
      åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼ŒNLM æŒ‡ç¥ç»è¯­è¨€æ¨¡å‹ï¼ˆNeural Language Modelsï¼‰ã€‚å®ƒåˆ©ç”¨ç¥ç»ç½‘ç»œæ¥å­¦ä¹ å’Œè¡¨ç¤ºè¯­è¨€çš„æ¦‚ç‡åˆ†å¸ƒï¼Œèƒ½å¤Ÿæ›´åŠ ç²¾ç¡®åœ°ç†è§£ã€å¤„ç†å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€ã€‚é€šè¿‡æ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œçš„ç»“åˆï¼Œä»å¤§é‡çš„æ–‡æœ¬æ•°æ®ä¸­å­¦ä¹ è¯­è¨€çš„ç»Ÿè®¡è§„å¾‹å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæ•æ‰åˆ°è¯è¯­ä¹‹é—´çš„å…³è”å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œæé«˜å¯¹è‡ªç„¶è¯­è¨€çš„ç†è§£èƒ½åŠ›ã€‚
      <br/>
      è¿™ç§æ¨¡å‹é€šå¸¸é‡‡ç”¨å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ã€é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰å’Œå˜å‹å™¨ï¼ˆTransformerï¼‰ç­‰ç»“æ„ï¼Œä»¥å»ºæ¨¡æ–‡æœ¬åºåˆ—å¹¶é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯æˆ–å­—ç¬¦çš„æ¦‚ç‡åˆ†å¸ƒã€‚
      <br/>
      ç¥ç»è¯­è¨€æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„åº”ç”¨è¶Šæ¥è¶Šå¹¿æ³›ï¼Œæ¶µç›–äº†æœºå™¨ç¿»è¯‘ã€è¯­éŸ³è¯†åˆ«ã€æ–‡æœ¬ç”Ÿæˆç­‰å¤šä¸ªä»»åŠ¡ã€‚
     </p>
    </blockquote>
    <h6>
     <a id="MLPNNLP_74">
     </a>
     æ—©æœŸå·¥ä½œï¼ˆMLPæˆ–NNLPï¼‰åŸç†
    </h6>
    <p>
     æ—©æœŸå·¥ä½œMLPï¼ˆMultilayer Perceptron,MLPï¼Œå¤šå±‚æ„ŸçŸ¥æœºï¼‰ï¼š
     <br/>
     NNLMï¼ˆNeural Network Language Modelï¼Œç¥ç»ç½‘ç»œè¯­è¨€æ¨¡å‹ï¼‰ï¼Œå•è¯æ˜ å°„åˆ°è¯å‘é‡ï¼Œå†ç”±ç¥ç»ç½‘ç»œé¢„æµ‹å½“å‰æ—¶åˆ»è¯æ±‡ã€‚æ˜¯ä¸€ç§é€šè¿‡ç¥ç»ç½‘ç»œè¿›è¡Œè¯­è¨€å»ºæ¨¡çš„æŠ€æœ¯ï¼Œé€šå¸¸ç”¨äºé¢„æµ‹åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªè¯ã€‚
    </p>
    <p>
     NNLMçš„æ ¸å¿ƒæ€æƒ³æ˜¯ä½¿ç”¨è¯åµŒå…¥ï¼ˆword embeddingï¼‰å°†è¯è½¬æ¢ä¸ºä½ç»´å‘é‡ï¼Œå¹¶é€šè¿‡ç¥ç»ç½‘ç»œå­¦ä¹ è¯­è¨€ä¸­çš„è¯åºå…³ç³»ã€‚
     <br/>
     NNLMçš„åŸºæœ¬ç»“æ„åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š
    </p>
    <blockquote>
     <p>
      è¾“å…¥å±‚ï¼šè¾“å…¥ä¸€ä¸ªå›ºå®šé•¿åº¦çš„è¯çª—å£ï¼Œä¾‹å¦‚ n ä¸ªè¯çš„ä¸Šä¸‹æ–‡ï¼ˆå‰ n - 1 ä¸ªè¯ï¼‰ä½œä¸ºè¾“å…¥ã€‚
      <br/>
      åµŒå…¥å±‚ï¼šå°†æ¯ä¸ªè¾“å…¥è¯æ˜ å°„åˆ°ä¸€ä¸ªä½ç»´ç©ºé—´ï¼Œå¾—åˆ°è¯å‘é‡ã€‚è¿™ä¸€å±‚çš„æƒé‡çŸ©é˜µé€šå¸¸è¡¨ç¤ºä¸ºè¯åµŒå…¥çŸ©é˜µã€‚
      <br/>
      éšè—å±‚ï¼šä¸€ä¸ªæˆ–å¤šä¸ªéšè—å±‚å¯ä»¥æ•è·è¯ä¹‹é—´çš„å…³ç³»ï¼Œä¸€èˆ¬æ˜¯å…¨è¿æ¥å±‚ã€‚
      <br/>
      è¾“å‡ºå±‚ï¼šç”¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒï¼Œé€šå¸¸ä½¿ç”¨softmaxå‡½æ•°ã€‚
     </p>
    </blockquote>
    <p>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/7d6da8edfe8e4ef3ae218c6c8e9a6e21.png"/>
    </p>
    <blockquote>
     <p>
      A goal of statistical language modeling is to learn the joint probabilityfunction of sequences of words.
      <br/>
      ç»Ÿè®¡è¯­è¨€å»ºæ¨¡çš„ä¸€ä¸ªç›®æ ‡æ˜¯å­¦ä¹ å•è¯åºåˆ—çš„è”åˆæ¦‚ç‡å‡½æ•°ã€‚
      <br/>
      This is intrinsically difficult because ofthe curse of dimensionality:we propose to fight it with its own weapons.
      <br/>
      è¿™æœ¬è´¨ä¸Šæ˜¯å›°éš¾çš„ï¼Œå› ä¸ºç»´åº¦è¯…å’’ï¼šæˆ‘ä»¬å»ºè®®ç”¨è‡ªå·±çš„æ­¦å™¨æ¥å¯¹æŠ—å®ƒã€‚
      <br/>
      In the proposed approach one learns simultaneously(1)a distributed rep-resentation for each word (i.e.a similarity between words)along with(2)the probability function for word sequences,expressed with these repre-sentations.
      <br/>
      åœ¨æ‰€æå‡ºçš„æ–¹æ³•ä¸­ï¼Œäººä»¬åŒæ—¶å­¦ä¹ ï¼ˆ1ï¼‰æ¯ä¸ªå•è¯çš„åˆ†å¸ƒå¼è¡¨ç¤ºï¼ˆå³å•è¯ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼‰ä»¥åŠï¼ˆ2ï¼‰ç”¨è¿™äº›è¡¨ç¤ºè¡¨ç¤ºçš„å•è¯åºåˆ—çš„æ¦‚ç‡å‡½æ•°ã€‚
      <br/>
      Generalization is obtained because a sequence of words that has never been seen before gets high probability, if it is made of words that are similar to words forming an already seen sentence.
      <br/>
      ä¹‹æ‰€ä»¥è·å¾—æ³›åŒ–ï¼Œæ˜¯å› ä¸ºå¦‚æœä¸€ä¸ªä»¥å‰ä»æœªè§è¿‡çš„å•è¯åºåˆ—æ˜¯ç”±ä¸å·²ç»è§è¿‡çš„å¥å­ä¸­çš„å•è¯ç›¸ä¼¼çš„å•è¯ç»„æˆçš„ï¼Œé‚£ä¹ˆå®ƒçš„æ¦‚ç‡å¾ˆé«˜ã€‚
      <br/>
      We report onexperiments using neural networks for the probability function,showingon two text corpora that the proposed approach very significantly im-proves on a state-of-the-art trigram model.
      <br/>
      æˆ‘ä»¬æŠ¥å‘Šäº†ä¸€é¡¹ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œæ¦‚ç‡å‡½æ•°çš„å®éªŒï¼Œåœ¨ä¸¤ä¸ªæ–‡æœ¬è¯­æ–™åº“ä¸Šè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨æœ€å…ˆè¿›çš„ä¸‰å…ƒç»„æ¨¡å‹ä¸Šå¾—åˆ°äº†éå¸¸æ˜¾è‘—çš„æ”¹è¿›ã€‚
     </p>
    </blockquote>
    <p>
     è¯¥æ¨¡å‹ä¸»è¦ä»»åŠ¡æ˜¯
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/518e9d7c44074326a91c442a665d9cf9.png"/>
    </p>
    <p>
     è¯¥æ¨¡å‹çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹ï¼š
    </p>
    <blockquote>
     <p>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/7f4993aa571b43de8c13617889baa74e.png"/>
      <br/>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/5d008c3c877e4579ab5de121595ac845.png"/>
      <br/>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/36ae6632df25455096c8e013abebdf22.png"/>
     </p>
    </blockquote>
    <h6>
     <a id="MLPNNLP_109">
     </a>
     æ—©æœŸå·¥ä½œï¼ˆMLPæˆ–NNLPï¼‰ä»£ç å®ç°
    </h6>
    <p>
     å‚è€ƒï¼š
     <br/>
     <a href="https://blog.csdn.net/weixin_62472350/article/details/143448417">
      https://blog.csdn.net/weixin_62472350/article/details/143448417
     </a>
     <br/>
     <a href="https://www.bilibili.com/video/BV1AT4y1J7bv/" rel="nofollow">
      https://www.bilibili.com/video/BV1AT4y1J7bv/
     </a>
     <br/>
     <a href="https://wmathor.com/index.php/archives/1442/" rel="nofollow">
      NNLM çš„ PyTorch å®ç°
     </a>
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 1.å¯¼å…¥å¿…è¦çš„åº“</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optimizer
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> Data
 
<span class="token comment"># 2.æ•°æ®å‡†å¤‡</span>
sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"I like milk"</span><span class="token punctuation">,</span>
             <span class="token string">"I love hot-pot"</span><span class="token punctuation">,</span>
             <span class="token string">"I hate coffee"</span><span class="token punctuation">,</span>
             <span class="token string">"I want sing"</span><span class="token punctuation">,</span>
             <span class="token string">"I am sleep"</span><span class="token punctuation">,</span>
             <span class="token string">"I go home"</span><span class="token punctuation">,</span>
             <span class="token string">"Love you forever"</span><span class="token punctuation">]</span>
 
word_list <span class="token operator">=</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sentences<span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># è·å–ä¸ªå¥å­å•è¯</span>
word_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>word_list<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment"># è·å–å•è¯åˆ—è¡¨</span>
 
word_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>w<span class="token punctuation">:</span> i <span class="token keyword">for</span> i<span class="token punctuation">,</span> w <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>word_list<span class="token punctuation">)</span><span class="token punctuation">}</span>     <span class="token comment"># å•è¯-ä½ç½®ç´¢å¼•å­—å…¸</span>
number_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>i<span class="token punctuation">:</span> w <span class="token keyword">for</span> i<span class="token punctuation">,</span> w <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>word_list<span class="token punctuation">)</span><span class="token punctuation">}</span>   <span class="token comment"># ä½ç½®-å•è¯ç´¢å¼•å­—å…¸</span>
 
vocab_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>word_list<span class="token punctuation">)</span>         <span class="token comment"># è¯æ±‡è¡¨å¤§å°</span>
 
<span class="token comment"># 3.X-ç”Ÿæˆè¾“å…¥å’Œè¾“å‡ºæ•°æ®</span>
<span class="token keyword">def</span> <span class="token function">make_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    input_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    output_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
 
    <span class="token keyword">for</span> sen <span class="token keyword">in</span> sentences<span class="token punctuation">:</span>
        word <span class="token operator">=</span> sen<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
        input_temp <span class="token operator">=</span> <span class="token punctuation">[</span>word_dict<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token keyword">for</span> n <span class="token keyword">in</span> word<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
        output_temp <span class="token operator">=</span> word_dict<span class="token punctuation">[</span>word<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
 
        input_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>input_temp<span class="token punctuation">)</span>
        output_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>output_temp<span class="token punctuation">)</span>
 
    <span class="token keyword">return</span> input_data<span class="token punctuation">,</span> output_data
 
 
input_data<span class="token punctuation">,</span> output_data <span class="token operator">=</span> make_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
input_data<span class="token punctuation">,</span> output_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>input_data<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>output_data<span class="token punctuation">)</span>   <span class="token comment"># æ•°æ®è½¬æ¢ï¼šå°† input_data å’Œ output_data è½¬æ¢ä¸º LongTensorï¼Œä»¥ä¾¿ç”¨äºæ¨¡å‹è®­ç»ƒã€‚</span>
dataset <span class="token operator">=</span> Data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span>input_data<span class="token punctuation">,</span> output_data<span class="token punctuation">)</span>       <span class="token comment"># å»ºæ•°æ®é›†ï¼šData.TensorDataset å°†è¾“å…¥å’Œè¾“å‡ºé…å¯¹ä¸ºæ•°æ®é›†</span>
loader <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>                  <span class="token comment"># æ•°æ®åŠ è½½å™¨ï¼šDataLoaderï¼Œä½¿ç”¨æ‰¹é‡å¤§å°ä¸º 2ï¼Œéšæœºæ‰“ä¹±æ ·æœ¬</span>
 
 
<span class="token comment"># 4.åˆå§‹åŒ–å‚æ•°</span>
m <span class="token operator">=</span> <span class="token number">2</span>
n_step <span class="token operator">=</span> <span class="token number">2</span>
n_hidden <span class="token operator">=</span> <span class="token number">10</span>
 
 
<span class="token comment"># 5.æ¨¡å‹å®šä¹‰</span>
<span class="token keyword">class</span> <span class="token class-name">NNLM</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>NNLM<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>C <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> m<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>H <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_step <span class="token operator">*</span> m<span class="token punctuation">,</span> n_hidden<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>d <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>n_hidden<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_hidden<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_step <span class="token operator">*</span> m<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>vocab_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
 
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        X <span class="token operator">=</span> self<span class="token punctuation">.</span>C<span class="token punctuation">(</span>X<span class="token punctuation">)</span>               <span class="token comment"># X = [batch_size, n_step, m]</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> n_step <span class="token operator">*</span> m<span class="token punctuation">)</span>  <span class="token comment"># å±•å¹³ X = [batch_size, n_step * m]</span>
        hidden_output <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>self<span class="token punctuation">.</span>d <span class="token operator">+</span> self<span class="token punctuation">.</span>H<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>b <span class="token operator">+</span> self<span class="token punctuation">.</span>W<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>U<span class="token punctuation">(</span>hidden_output<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
 
<span class="token comment"># 6.å®šä¹‰è®­ç»ƒè¿‡ç¨‹</span>
model <span class="token operator">=</span> NNLM<span class="token punctuation">(</span><span class="token punctuation">)</span>
optim <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
<span class="token comment"># 7.æ¨¡å‹è®­ç»ƒ</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">5000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> batch_x<span class="token punctuation">,</span> batch_y <span class="token keyword">in</span> loader<span class="token punctuation">:</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>batch_x<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> batch_y<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
<span class="token comment"># 8.æ¨¡å‹æµ‹è¯•</span>
pred <span class="token operator">=</span> model<span class="token punctuation">(</span>input_data<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>number_dict<span class="token punctuation">[</span>idx<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> pred<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     <strong>
      ä»£ç è§£é‡Š
     </strong>
     <br/>
     <strong>
      1.æœ€å¼€å§‹å¯¼å…¥ä¸€äº›å¿…è¦çš„åº“
     </strong>
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 1.å¯¼å…¥å¿…è¦çš„åº“</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optimizer
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> Data
</code></pre>
    <p>
     <strong>
      2.é¦–å…ˆéœ€è¦å‡†å¤‡ä¸€äº›æ•°æ®ï¼Œç”¨äºæ¨¡å‹è®­ç»ƒå¹¶æµ‹è¯•
     </strong>
    </p>
    <pre><code class="prism language-python">word_list <span class="token operator">=</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sentences<span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     â‘ å¯¹äºæ–‡æœ¬æ•°æ®ï¼Œè‚¯å®šè¦è¿›è¡Œä¸€ä¸ªåˆ†è¯æ“ä½œï¼Œå…ˆä½¿ç”¨" ".join(sentences).split()æ¥åˆ‡åˆ†æ¯ä¸€ä¸ªå¥å­çš„æ¯ä¸ªå•è¯ï¼Œè¿™æ—¶å€™è·å¾—çš„word_liståˆ—è¡¨å°±æ˜¯ï¼š
    </p>
    <blockquote>
     <p>
      [â€˜Iâ€™, â€˜likeâ€™, â€˜milkâ€™, â€˜Iâ€™, â€˜loveâ€™, â€˜hot-potâ€™, â€˜Iâ€™, â€˜hateâ€™, â€˜coffeeâ€™, â€˜Iâ€™, â€˜wantâ€™, â€˜singâ€™, â€˜Iâ€™, â€˜amâ€™, â€˜sleepâ€™, â€˜Iâ€™, â€˜goâ€™, â€˜homeâ€™, â€˜Loveâ€™, â€˜youâ€™, â€˜foreverâ€™]
     </p>
    </blockquote>
    <p>
     â‘¡ä½†æ˜¯è¿™é‡Œå¾—åˆ°çš„å•è¯å¯èƒ½ä¼šæœ‰é‡å¤çš„æƒ…å†µï¼Œæˆ‘ä»¬éœ€è¦å¾—åˆ°ä¸é‡å¤çš„å•è¯åˆ—è¡¨ï¼Œä¸ºåé¢çš„åˆ›å»ºè¯å…¸æä¾›æ–¹ä¾¿ã€‚
    </p>
    <pre><code class="prism language-python">word_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>word_list<span class="token punctuation">)</span><span class="token punctuation">)</span>  
</code></pre>
    <p>
     set (word_list) ï¼šå°† word_list è½¬æ¢ä¸ºé›†åˆï¼ˆsetï¼‰ï¼Œè‡ªåŠ¨å»é™¤åˆ—è¡¨ä¸­çš„é‡å¤å…ƒç´ ã€‚
     <br/>
     list(set (word_list) )ï¼šå†å°†é›†åˆè½¬æ¢å›åˆ—è¡¨ï¼Œè¿™æ ·å¯ä»¥ä¿æŒåŸæ•°æ®ç±»å‹ä¸€è‡´ï¼ˆå³ word_list ä»ç„¶æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼‰ã€‚
    </p>
    <blockquote>
     <p>
      [â€˜milkâ€™, â€˜coffeeâ€™, â€˜singâ€™, â€˜hot-potâ€™, â€˜homeâ€™, â€˜youâ€™, â€˜amâ€™, â€˜Iâ€™, â€˜sleepâ€™, â€˜loveâ€™, â€˜wantâ€™, â€˜hateâ€™, â€˜goâ€™, â€˜foreverâ€™, â€˜likeâ€™, â€˜Loveâ€™]
     </p>
    </blockquote>
    <p>
     â‘¢ç„¶åå°±æ˜¯æ„é€ è¯å…¸ï¼šå•è¯åˆ°ä½ç½®çš„ç´¢å¼•å­—å…¸ã€ä½ç½®åˆ°å•è¯çš„ç´¢å¼•å­—å…¸ã€‚
    </p>
    <pre><code class="prism language-python">word_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>w<span class="token punctuation">:</span> i <span class="token keyword">for</span> i<span class="token punctuation">,</span> w <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>word_list<span class="token punctuation">)</span><span class="token punctuation">}</span>     <span class="token comment"># å•è¯-ä½ç½®ç´¢å¼•å­—å…¸</span>
number_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>i<span class="token punctuation">:</span> w <span class="token keyword">for</span> i<span class="token punctuation">,</span> w <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>word_list<span class="token punctuation">)</span><span class="token punctuation">}</span>   <span class="token comment"># ä½ç½®-å•è¯ç´¢å¼•å­—å…¸</span>
</code></pre>
    <blockquote>
     <p>
      word_dictï¼š {â€˜sleepâ€™: 0, â€˜goâ€™: 1, â€˜homeâ€™: 2, â€˜milkâ€™: 3, â€˜hateâ€™: 4, â€˜Loveâ€™: 5, â€˜loveâ€™: 6, â€˜amâ€™: 7, â€˜wantâ€™: 8, â€˜singâ€™: 9, â€˜foreverâ€™: 10, â€˜hot-potâ€™: 11, â€˜Iâ€™: 12, â€˜likeâ€™: 13, â€˜youâ€™: 14, â€˜coffeeâ€™: 15}
     </p>
    </blockquote>
    <blockquote>
     <p>
      number_dictï¼š{0: â€˜sleepâ€™, 1: â€˜goâ€™, 2: â€˜homeâ€™, 3: â€˜milkâ€™, 4: â€˜hateâ€™, 5: â€˜Loveâ€™, 6: â€˜loveâ€™, 7: â€˜amâ€™, 8: â€˜wantâ€™, 9: â€˜singâ€™, 10: â€˜foreverâ€™, 11: â€˜hot-potâ€™, 12: â€˜Iâ€™, 13: â€˜likeâ€™, 14: â€˜youâ€™, 15: â€˜coffeeâ€™}
     </p>
    </blockquote>
    <pre><code>    è¿™é‡Œä½¿ç”¨enumerateæ˜¯å› ä¸º enumerate å‡½æ•°å¯ä»¥æ–¹ä¾¿åœ°åŒæ—¶è·å–åˆ—è¡¨å…ƒç´ çš„ç´¢å¼•å’Œå¯¹åº”çš„å€¼ã€‚ä¹Ÿå°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„å­—å…¸ã€‚
</code></pre>
    <p>
     â‘£ç„¶åå°±æ˜¯è·å¾—è¯æ±‡è¡¨å¤§å°ï¼Œåœ¨æ¨¡å‹æ­å»ºä¸­éœ€è¦ç”¨åˆ°ã€‚
    </p>
    <p>
     <strong>
      3.æœ‰äº†åˆå§‹æ•°æ®ï¼Œæˆ‘ä»¬éœ€è¦æ„å»ºå‡ºæ•°æ®Xï¼Œä¹Ÿå°±æ˜¯è¾“å…¥æ•°æ®å’Œç›®æ ‡è¾“å‡ºæ•°æ®ã€‚
     </strong>
    </p>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">make_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    input_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    output_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
 
    <span class="token keyword">for</span> sen <span class="token keyword">in</span> sentences<span class="token punctuation">:</span>
        word <span class="token operator">=</span> sen<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
        input_temp <span class="token operator">=</span> <span class="token punctuation">[</span>word_dict<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token keyword">for</span> n <span class="token keyword">in</span> word<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
        output_temp <span class="token operator">=</span> word_dict<span class="token punctuation">[</span>word<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
 
        input_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>input_temp<span class="token punctuation">)</span>
        output_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>output_temp<span class="token punctuation">)</span>
 
    <span class="token keyword">return</span> input_data<span class="token punctuation">,</span> output_data
</code></pre>
    <p>
     â‘ å…ˆæ„å»ºç©ºçš„è¾“å…¥æ•°æ®input_dataå’Œè¾“å‡ºæ•°æ®output_dataã€‚
    </p>
    <p>
     â‘¡å°†æ¯ä¸ªå¥å­çš„å‰ n-1ä¸ªå•è¯çš„ä½ç½®æ·»åŠ åˆ°è¾“å…¥æ•°æ®input_dataä¸­ï¼Œç¬¬ n ä¸ªå•è¯çš„ä½ç½®æ·»åŠ åˆ°è¾“å…¥æ•°æ®output_dataä¸­ï¼Œå¾—åˆ°æ¯ä¸ªè¾“å…¥ x å’Œè¾“å‡º y åœ¨è¯æ±‡è¡¨ä¸­çš„é¡ºåºï¼š
    </p>
    <blockquote>
     <p>
      input_dataï¼š[[12, 13], [12, 6], [12, 4], [12, 8], [12, 7], [12, 1], [5, 14]]
     </p>
    </blockquote>
    <blockquote>
     <p>
      output_dataï¼š[3, 11, 15, 9, 0, 2, 10]
     </p>
    </blockquote>
    <p>
     è¿™æ˜¯ä¸ªäºŒç»´çš„çŸ©é˜µï¼Œè¡Œå…ƒç´ ä»£è¡¨ä¸€ä¸ªå¥å­ä¸­ç”¨äºè®­ç»ƒè¾“å…¥/æµ‹è¯•è¾“å‡ºçš„å•è¯åœ¨è¯æ±‡è¡¨ä¸­çš„ä½ç½®ç´¢å¼•ï¼›åˆ—å…ƒç´ æ˜¯ä¸åŒçš„å¥å­ã€‚
     <br/>
     æ¯ä¸ªå¥å­éƒ½æ˜¯3ä¸ªå•è¯ï¼Œå‰2ä¸ªä½œä¸ºå‰æ–‡ä¿¡æ¯ä½œä¸ºè¾“å…¥ï¼Œç¬¬3ä¸ªä½œä¸ºé¢„æµ‹è¾“å‡ºï¼Œæˆ‘ä»¬å‰é¢ç»™çš„ä¸€å…±æ˜¯7ä¸ªå¥å­ã€‚
    </p>
    <p>
     <strong>
      4.åˆå§‹åŒ–å‚æ•°
     </strong>
    </p>
    <p>
     è¿™é‡Œçš„mæŒ‡çš„æ˜¯ç»´åº¦ï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ªå•è¯è¦åµŒå…¥åˆ°å¤šå°‘ç»´åº¦ï¼Œç”±äºè¿™é‡Œçš„æ•°æ®é‡æ¯”è¾ƒå°ï¼Œæ¯ä¸ªå¥å­ä¹Ÿåªæœ‰3ä¸ªå•è¯ï¼Œæ‰€ä»¥è¿™ç»™å‡ºçš„ç»´åº¦é€‰ä¸ªå¾ˆä½çš„2ã€‚
    </p>
    <blockquote>
     <p>
      n_step=2ï¼ŒæŒ‡çš„æ˜¯ç”¨ä¸¤ä¸ªå•è¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªç›®æ ‡å•è¯ã€‚
      <br/>
      n_hidden=10ï¼ŒæŒ‡çš„æ˜¯éšè—å±‚çš„æ•°é‡ã€‚
     </p>
    </blockquote>
    <p>
     <strong>
      5.å‰é¢çš„æ•°æ®å·²ç»åˆæ­¥å®šä¹‰å¥½äº†ï¼Œè¿™é‡Œå°±è¦æ­å»ºNNLMæ¨¡å‹äº†ã€‚
     </strong>
    </p>
    <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">NNLM</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>NNLM<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>C <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> m<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>H <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_step <span class="token operator">*</span> m<span class="token punctuation">,</span> n_hidden<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>d <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>n_hidden<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_hidden<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_step <span class="token operator">*</span> m<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>vocab_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
 
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        X <span class="token operator">=</span> self<span class="token punctuation">.</span>C<span class="token punctuation">(</span>X<span class="token punctuation">)</span>               <span class="token comment"># X = [batch_size, n_step, m]</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> n_step <span class="token operator">*</span> m<span class="token punctuation">)</span>  <span class="token comment"># å±•å¹³ X = [batch_size, n_step * m]</span>
        hidden_output <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>self<span class="token punctuation">.</span>d <span class="token operator">+</span> self<span class="token punctuation">.</span>H<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>b <span class="token operator">+</span> self<span class="token punctuation">.</span>W<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>U<span class="token punctuation">(</span>hidden_output<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
</code></pre>
    <p>
     â‘ def _init_(self)ï¼šå®šä¹‰å„å±‚å’Œå‚æ•°ï¼š
    </p>
    <blockquote>
     <p>
      self.Cï¼šè¯åµŒå…¥å±‚ï¼Œå°†è¾“å…¥è¯è½¬æ¢ä¸ºè¯å‘é‡ã€‚
      <br/>
      vocab_size å®šä¹‰è¯æ±‡è¡¨çš„å¤§å°ï¼Œm æ˜¯è¯åµŒå…¥çš„ç»´åº¦ï¼Œè¡¨ç¤ºæ¯ä¸ªè¯å°†è¢«åµŒå…¥æˆ m ç»´çš„å‘é‡ã€‚
     </p>
    </blockquote>
    <blockquote>
     <p>
      self.Hï¼šçº¿æ€§å±‚ï¼Œå°†å±•å¹³åçš„è¾“å…¥æ˜ å°„åˆ°éšè—å±‚ã€‚
      <br/>
      n_step * m æ˜¯å±•å¹³åçš„è¾“å…¥å¤§å°ï¼Œn_hidden æ˜¯éšè—å±‚çš„ç»´åº¦ï¼Œç”¨æ¥æ§åˆ¶éšè—å±‚è¾“å‡ºçš„ç‰¹å¾æ•°é‡ã€‚
     </p>
    </blockquote>
    <blockquote>
     <p>
      self.dï¼šåç½®å‘é‡ï¼Œç”¨äºéšè—å±‚çš„è¾“å‡ºã€‚
      <br/>
      n_hidden æ˜¯åç½®é¡¹çš„ç»´åº¦ï¼Œä¸éšè—å±‚è¾“å‡ºåŒ¹é…ï¼Œç”¨äºæå‡éšè—å±‚çš„è¡¨è¾¾èƒ½åŠ›ã€‚
     </p>
    </blockquote>
    <blockquote>
     <p>
      self.Uï¼šçº¿æ€§å±‚ï¼Œå°†éšè—å±‚è¾“å‡ºæ˜ å°„åˆ°è¯æ±‡è¡¨ç©ºé—´ã€‚
      <br/>
      n_hidden æ˜¯éšè—å±‚è¾“å‡ºçš„å¤§å°ï¼Œvocab_size æ˜¯è¯æ±‡è¡¨å¤§å°ï¼Œç”¨äºå°†éšè—å±‚çš„ç‰¹å¾æ˜ å°„åˆ°æ¯ä¸ªè¯çš„é¢„æµ‹ç©ºé—´ã€‚
     </p>
    </blockquote>
    <blockquote>
     <p>
      self.Wï¼šçº¿æ€§å±‚ï¼Œä»è¾“å…¥ç›´æ¥æ˜ å°„åˆ°è¯æ±‡è¡¨ç©ºé—´ã€‚
      <br/>
      n_step * m æ˜¯å±•å¹³åçš„è¾“å…¥å¤§å°ï¼Œvocab_size æ˜¯è¯æ±‡è¡¨å¤§å°ï¼Œç”¨äºå°†è¾“å…¥ç›´æ¥æ˜ å°„åˆ°è¯æ±‡è¡¨çš„é¢„æµ‹ç©ºé—´ã€‚
     </p>
    </blockquote>
    <blockquote>
     <p>
      self.bï¼šåç½®å‘é‡ï¼Œç”¨äºæœ€ç»ˆè¾“å‡ºå±‚çš„åˆ†æ•°è°ƒæ•´ã€‚
      <br/>
      vocab_size æ˜¯è¯æ±‡è¡¨çš„å¤§å°ï¼Œç”¨ä½œæœ€ç»ˆè¾“å‡ºå±‚çš„åç½®ã€‚
     </p>
    </blockquote>
    <p>
     è¿™é‡Œåˆ†åˆ«ç”¨äº†Embeddingã€Linearå’ŒParameterï¼š
    </p>
    <blockquote>
     <p>
      Embeddingï¼šåµŒå…¥å±‚ï¼Œç”¨äºå°†ç¦»æ•£çš„è¯æ±‡ç´¢å¼•ï¼ˆå¦‚å•è¯çš„æ•´æ•°è¡¨ç¤ºï¼‰æ˜ å°„åˆ°è¿ç»­çš„ç¨ å¯†å‘é‡ç©ºé—´ã€‚
      <br/>
      Linearï¼šå…¨è¿æ¥å±‚ï¼ˆçº¿æ€§å±‚ï¼‰ï¼Œç”¨äºå°†è¾“å…¥çš„ç‰¹å¾é€šè¿‡çº¿æ€§å˜æ¢æ˜ å°„åˆ°è¾“å‡ºç©ºé—´ã€‚
      <br/>
      Parameterï¼šå¯å­¦ä¹ çš„å‚æ•°ã€‚
     </p>
    </blockquote>
    <p>
     â‘¡def forward(self,X)ï¼šå®šä¹‰ç¥ç»ç½‘ç»œåœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­çš„è®¡ç®—æ­¥éª¤
    </p>
    <pre><code class="prism language-python">X <span class="token operator">=</span> self<span class="token punctuation">.</span>C<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
</code></pre>
    <blockquote>
     <p>
      é¦–å…ˆé€šè¿‡åµŒå…¥å±‚å°†è¾“å…¥çš„è¯ç´¢å¼•ï¼ˆXï¼‰è½¬æ¢ä¸ºè¯å‘é‡è¡¨ç¤ºï¼Œè¿™ä¸ªæ—¶å€™å¾—åˆ°æ˜¯ä¸‰ç»´åº¦çš„ï¼š[batch_size, n_step, m]ã€‚
     </p>
    </blockquote>
    <pre><code class="prism language-python">X <span class="token operator">=</span> X<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> n_step <span class="token operator">*</span> m<span class="token punctuation">)</span>
</code></pre>
    <blockquote>
     <p>
      ç„¶åå°† X ä»ä¸‰ç»´å¼ é‡å±•å¹³ä¸ºäºŒç»´å¼ é‡ [batch_size, n_step * m]ï¼Œæ–¹ä¾¿è¾“å…¥åˆ°å…¨è¿æ¥å±‚ self.Hã€‚
     </p>
    </blockquote>
    <pre><code class="prism language-python">hidden_output <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>self<span class="token punctuation">.</span>d <span class="token operator">+</span> self<span class="token punctuation">.</span>H<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <blockquote>
     <p>
      æ¥ç€ï¼Œåˆ©ç”¨å…¬å¼
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         h 
         
        
          = 
         
        
          t 
         
        
          a 
         
        
          n 
         
        
          h 
         
        
          ( 
         
         
         
           W 
          
         
           h 
          
         
        
          X 
         
        
          + 
         
        
          d 
         
        
          ) 
         
        
       
         h=tanh(W_hX+d)
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.6944em;">
          </span>
          <span class="mord mathnormal">
           h
          </span>
          <span class="mspace" style="margin-right: 0.2778em;">
          </span>
          <span class="mrel">
           =
          </span>
          <span class="mspace" style="margin-right: 0.2778em;">
          </span>
         </span>
         <span class="base">
          <span class="strut" style="height: 1em; vertical-align: -0.25em;">
          </span>
          <span class="mord mathnormal">
           t
          </span>
          <span class="mord mathnormal">
           anh
          </span>
          <span class="mopen">
           (
          </span>
          <span class="mord">
           <span class="mord mathnormal" style="margin-right: 0.1389em;">
            W
           </span>
           <span class="msupsub">
            <span class="vlist-t vlist-t2">
             <span class="vlist-r">
              <span class="vlist" style="height: 0.3361em;">
               <span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;">
                <span class="pstrut" style="height: 2.7em;">
                </span>
                <span class="sizing reset-size6 size3 mtight">
                 <span class="mord mathnormal mtight">
                  h
                 </span>
                </span>
               </span>
              </span>
              <span class="vlist-s">
               â€‹
              </span>
             </span>
             <span class="vlist-r">
              <span class="vlist" style="height: 0.15em;">
               <span class="">
               </span>
              </span>
             </span>
            </span>
           </span>
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0785em;">
           X
          </span>
          <span class="mspace" style="margin-right: 0.2222em;">
          </span>
          <span class="mbin">
           +
          </span>
          <span class="mspace" style="margin-right: 0.2222em;">
          </span>
         </span>
         <span class="base">
          <span class="strut" style="height: 1em; vertical-align: -0.25em;">
          </span>
          <span class="mord mathnormal">
           d
          </span>
          <span class="mclose">
           )
          </span>
         </span>
        </span>
       </span>
      </span>
      è®¡ç®—å¾—åˆ°éšè—å±‚è¾“å‡ºã€‚
     </p>
    </blockquote>
    <pre><code class="prism language-python">output <span class="token operator">=</span> self<span class="token punctuation">.</span>b <span class="token operator">+</span> self<span class="token punctuation">.</span>W<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>U<span class="token punctuation">(</span>hidden_output<span class="token punctuation">)</span>
</code></pre>
    <blockquote>
     <p>
      æœ€åï¼Œåˆ©ç”¨å…¬å¼
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         o 
         
        
          u 
         
        
          t 
         
        
          p 
         
        
          u 
         
        
          t 
         
        
          = 
         
        
          b 
         
        
          + 
         
        
          W 
         
        
          X 
         
        
          + 
         
        
          U 
         
        
          h 
         
        
       
         output=b+WX+Uh
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.8095em; vertical-align: -0.1944em;">
          </span>
          <span class="mord mathnormal">
           o
          </span>
          <span class="mord mathnormal">
           u
          </span>
          <span class="mord mathnormal">
           tp
          </span>
          <span class="mord mathnormal">
           u
          </span>
          <span class="mord mathnormal">
           t
          </span>
          <span class="mspace" style="margin-right: 0.2778em;">
          </span>
          <span class="mrel">
           =
          </span>
          <span class="mspace" style="margin-right: 0.2778em;">
          </span>
         </span>
         <span class="base">
          <span class="strut" style="height: 0.7778em; vertical-align: -0.0833em;">
          </span>
          <span class="mord mathnormal">
           b
          </span>
          <span class="mspace" style="margin-right: 0.2222em;">
          </span>
          <span class="mbin">
           +
          </span>
          <span class="mspace" style="margin-right: 0.2222em;">
          </span>
         </span>
         <span class="base">
          <span class="strut" style="height: 0.7667em; vertical-align: -0.0833em;">
          </span>
          <span class="mord mathnormal" style="margin-right: 0.1389em;">
           W
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0785em;">
           X
          </span>
          <span class="mspace" style="margin-right: 0.2222em;">
          </span>
          <span class="mbin">
           +
          </span>
          <span class="mspace" style="margin-right: 0.2222em;">
          </span>
         </span>
         <span class="base">
          <span class="strut" style="height: 0.6944em;">
          </span>
          <span class="mord mathnormal" style="margin-right: 0.109em;">
           U
          </span>
          <span class="mord mathnormal">
           h
          </span>
         </span>
        </span>
       </span>
      </span>
      å¾—åˆ°æœ€ç»ˆçš„è¾“å‡ºã€‚
     </p>
    </blockquote>
    <p>
     <strong>
      6.å®šä¹‰è®­ç»ƒè¿‡ç¨‹
     </strong>
    </p>
    <p>
     è¿™é‡Œåˆå§‹åŒ–modelï¼Œå¹¶ä¸”è®¾ç½®ä¼˜åŒ–å™¨ä¸ºAdamï¼Œå¹¶ä¸”ä½¿ç”¨äº†äº¤å‰ç†µæŸå¤±ã€‚
    </p>
    <p>
     <strong>
      7.æ¨¡å‹è®­ç»ƒ
     </strong>
    </p>
    <pre><code class="prism language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">5000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> batch_x<span class="token punctuation">,</span> batch_y <span class="token keyword">in</span> loader<span class="token punctuation">:</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>batch_x<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> batch_y<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     è¿™é‡Œä»æ•°æ®åŠ è½½å™¨ä¸­åŠ è½½æ•°æ®ï¼Œå°†å½“å‰æ‰¹æ¬¡çš„è¾“å…¥æ•°æ®batch_xä¼ å…¥æ¨¡å‹ä¸­å¾—åˆ°é¢„æµ‹ç»“æœï¼ŒåŒæ—¶è®¡ç®—é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„æŸå¤±lossï¼Œæ¯1000ä¸ªepochæ‰“å°æŸå¤±ã€‚ç„¶åæ¢¯åº¦æ¸…é›¶ã€åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦ã€æ›´æ–°æ¨¡å‹å‚æ•°ã€‚
    </p>
    <p>
     <strong>
      8.æ¨¡å‹æµ‹è¯•
     </strong>
    </p>
    <pre><code class="prism language-python">pred <span class="token operator">=</span> model<span class="token punctuation">(</span>input_data<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
</code></pre>
    <blockquote>
     <p>
      model(input_data)ï¼šå°†è¾“å…¥æ•°æ®ä¼ é€’ç»™æ¨¡å‹ï¼Œè·å–æ¯ä¸ªç±»åˆ«çš„å¾—åˆ†ï¼ˆlogitsï¼‰ã€‚
      <br/>
      max(1, keepdim=True)[1]ï¼š
     </p>
     <blockquote>
      <p>
       max(1)ï¼šå¯¹æ¯ä¸ªæ ·æœ¬æ‰¾å‡ºæœ€å¤§å¾—åˆ†çš„ç±»åˆ«ç´¢å¼•ã€‚
       <br/>
       keepdim=Trueï¼šä¿æŒè¾“å‡ºç»´åº¦ä¸å˜ã€‚
       <br/>
       [1]ï¼šæå–æ¯ä¸ªæ ·æœ¬çš„æœ€å¤§å€¼ç´¢å¼•ï¼ˆé¢„æµ‹ç±»åˆ«ï¼‰ã€‚
      </p>
     </blockquote>
    </blockquote>
    <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>number_dict<span class="token punctuation">[</span>idx<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> pred<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <blockquote>
     <p>
      pred.squeeze()ï¼šç§»é™¤ç»´åº¦ä¸º 1 çš„ç»´åº¦ï¼Œå¾—åˆ°ä¸€ç»´å¼ é‡ã€‚
      <br/>
      [idx.item() for idx in pred.squeeze()]ï¼šå°†æ¯ä¸ªç´¢å¼•è½¬æ¢ä¸ºæ•´æ•°ã€‚
      <br/>
      number_dict[idx.item()]ï¼šé€šè¿‡ç´¢å¼•æŸ¥æ‰¾å¯è¯»æ ‡ç­¾ã€‚
      <br/>
      print([â€¦])ï¼šæ‰“å°å‡ºæ¨¡å‹é¢„æµ‹çš„ç±»åˆ«æ ‡ç­¾ã€‚
     </p>
    </blockquote>
    <blockquote>
     <p>
      è¾“å‡ºï¼š
      <br/>
      1000 0.05966342240571976
      <br/>
      1000 0.034198883920907974
      <br/>
      2000 0.005526650696992874
      <br/>
      2000 0.009151813574135303
      <br/>
      3000 0.0021409429609775543
      <br/>
      3000 0.0015856553800404072
      <br/>
      4000 0.0006656644982285798
      <br/>
      4000 0.0005017295479774475
      <br/>
      5000 0.00018937562708742917
      <br/>
      5000 0.00020660058362409472
      <br/>
      [â€˜milkâ€™, â€˜hot-potâ€™, â€˜coffeeâ€™, â€˜singâ€™, â€˜sleepâ€™, â€˜homeâ€™, â€˜foreverâ€™]
     </p>
    </blockquote>
    <h6>
     <a id="_418">
     </a>
     ç¥ç»ç½‘ç»œçš„è®¡ç®—è¿‡ç¨‹
    </h6>
    <p>
     BPç¥ç»ç½‘ç»œï¼šè¯¯å·®åå‘ä¼ æ’­ç®—æ³•å…¬å¼æ¨å¯¼
     <br/>
     å¼€ç«¯ï¼š BPç®—æ³•æå‡º
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/15dcb48d4b2e47408c4a28e8af629f4f.png"/>
    </p>
    <ol>
     <li>
      <p>
       BPç¥ç»ç½‘ç»œå‚æ•°ç¬¦å·åŠæ¿€æ´»å‡½æ•°è¯´æ˜
       <br/>
       <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/7f98c6ea29d54a509df443ff1457b7b0.png"/>
      </p>
     </li>
     <li>
      <p>
       ç½‘ç»œè¾“å‡ºè¯¯å·®ï¼ˆæŸå¤±å‡½æ•°ï¼‰å®šä¹‰
      </p>
     </li>
    </ol>
    <p>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/ab1a21ed994a4c0c9bbab27325f84545.png"/>
    </p>
    <ol start="3">
     <li>
      <p>
       éšè—å±‚ä¸è¾“å‡ºå±‚é—´çš„æƒé‡æ›´æ–°å…¬å¼æ¨å¯¼
       <br/>
       <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/be88cc604c8145d4afe3e77a623b423f.png"/>
      </p>
     </li>
     <li>
      <p>
       è¾“å…¥å±‚ä¸éšè—å±‚é—´çš„æƒé‡æ›´æ–°å…¬å¼æ¨å¯¼
      </p>
     </li>
    </ol>
    <p>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/4e2cfd49ae9e437b898adef7e4fca4d8.png"/>
    </p>
    <h6>
     <a id="RNNRecurrent_Neural_Network_447">
     </a>
     å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼ŒRecurrent Neural Networkï¼‰
    </h6>
    <p>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/4c3f0f089b6d4610ab483e174f925775.png"/>
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/54b81edb1c3747f294cc8903e56de02e.png"/>
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/0dbd72f84e7341f4b10dea5bd122ef5c.png"/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/a70d02887e164459aa9257c6aca7979d.png"/>
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/9304ab6c3a504ed08be2d61402b4dd80.png"/>
    </p>
    <p>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/0afbaffaea7044e38448c602bda01cf9.png"/>
    </p>
    <p>
     <a href="https://zhuanlan.zhihu.com/p/689910526" rel="nofollow">
      RNNå­˜åœ¨æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜
     </a>
    </p>
    <h6>
     <a id="Word2Vec_460">
     </a>
     ç®€åŒ–æ¨¡å‹ï¼šWord2Vec
    </h6>
    <p>
     å‚è€ƒï¼š
     <a href="https://blog.csdn.net/julac/article/details/127767053">
      ä¸€ç¯‡æ–‡ç« å…¥é—¨Word2Vec
     </a>
     <br/>
     <a href="https://www.cnblogs.com/stephen-goodboy/p/12574738.html" rel="nofollow">
      è¯å‘é‡æ¨¡å‹word2vectorè¯¦è§£
     </a>
     <br/>
     <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/c4d756efb63f467581190e1612945ef7.png"/>
    </p>
    <p>
     â¢ åŸºæœ¬åŠŸèƒ½
     <br/>
     âƒ ç»™å®šæ–‡æœ¬æ•°æ®ï¼Œå¯¹äºæ¯ä¸ªå•è¯å­¦ä¹ ä¸€ä¸ªä½ç»´è¡¨ç¤º
     <br/>
     â¢ åŸºäºåˆ†å¸ƒå¼è¯­ä¹‰çš„æ€æƒ³è¿›è¡Œè®¾è®¡
     <br/>
     âƒ è¯ä¹‰=èƒŒæ™¯å•è¯çš„è¯­ä¹‰
     <br/>
     â¢ ä¸è€ƒè™‘çª—å£å†…å•è¯çš„é¡ºåº
     <br/>
     âƒ åº”ç”¨äº†ç®€å•çš„average poolingçš„ç­–ç•¥
     <br/>
     â¢ å……åˆ†è€ƒè™‘å®è·µå’Œæ•ˆæœ
     <br/>
     âƒ æœ‰å¾ˆå¤šçš„ä¼˜åŒ–trickï¼Œé€Ÿåº¦å¿«ã€æ•ˆæœç¨³å®š
    </p>
    <h6>
     <a id="__Word2VecELMo_475">
     </a>
     è¯å‘é‡ - ä»Word2Vecåˆ°ELMo
    </h6>
    <p>
     å‚è€ƒï¼š
     <a href="https://blog.csdn.net/Jackie_vip/article/details/141600366">
      ã€å¤§æ¨¡å‹ç³»åˆ—ç¯‡ã€‘è¯å‘é‡ - ä»Word2Vecåˆ°ELMo
     </a>
    </p>
    <blockquote>
     <p>
      è¯å‘é‡ï¼ˆåˆå«è¯åµŒå…¥ï¼‰å·²ç»æˆä¸ºNLPé¢†åŸŸå„ç§ä»»åŠ¡çš„å¿…å¤‡ä¸€æ­¥ï¼Œè€Œä¸”éšç€BERTã€GPTç­‰é¢„è®­ç»ƒæ¨¡å‹çš„å‘å±•ï¼Œè¯å‘é‡æ¼”å˜ä¸ºçŸ¥è¯†è¡¨ç¤ºæ–¹æ³•ï¼Œä½†å…¶æœ¬è´¨æ€æƒ³ä¸å˜ã€‚ ç”Ÿæˆè¯å‘é‡çš„æ–¹æ³•æœ‰å¾ˆå¤šç§ï¼Œæœ¬æ–‡é‡ç‚¹å›é¡¾Word2Vecåˆ°ELMoã€‚
      <br/>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/c78b6c2b3a7c40f28fa8d7784fc80bd6.png"/>
     </p>
    </blockquote>
    <p>
     one-hot ç¼–ç 
    </p>
    <blockquote>
     <p>
      one-hot ç¼–ç ï¼Œé¦–å…ˆæ„é€ ä¸€ä¸ªå®¹é‡ä¸º N çš„è¯æ±‡è¡¨ï¼Œæ¯ä¸ªå•è¯å¯ä»¥ç”¨ä¸€ä¸ª N ç»´çš„è¯å‘é‡è¡¨ç¤ºï¼Œè¯å‘é‡ä¸­åªæœ‰å•è¯åœ¨è¯æ±‡è¡¨çš„ç´¢å¼•å¤„å–å€¼ä¸º 1ï¼Œå…¶ä½™ä¸º 0ã€‚
      <br/>
      one-hot ç¼–ç ä¸»è¦çš„ç¼ºç‚¹æ˜¯ï¼šå½“è¯æ±‡è¡¨çš„å®¹é‡å˜å¤§æ—¶ï¼Œè¯å‘é‡çš„ç‰¹å¾ç©ºé—´ä¼šå˜å¾—å¾ˆå¤§ï¼›å¦å¤– one-hot ç¼–ç ä¸èƒ½åŒºåˆ†å•è¯ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼ŒåŒæ—¶å…·æœ‰å¼ºç¨€ç–æ€§ã€‚
      <br/>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/b8c70ea88b624734b56c02172cfb9c3d.png"/>
     </p>
    </blockquote>
    <p>
     å…±ç°çŸ©é˜µï¼ˆCo-Occurrence Matrixï¼‰
    </p>
    <blockquote>
     <p>
      é€šè¿‡ç»Ÿè®¡ä¸€ä¸ªäº‹å…ˆæŒ‡å®šå¤§å°çš„çª—å£å†…çš„å•è¯å…±åŒå‡ºç°çš„æ¬¡æ•°ï¼Œæ­¤æ—¶å°†è¯åˆ’åˆ†ä¸ºä¸¤ç§ï¼Œä¸­å¿ƒè¯å’Œå…¶ä»–è¯ã€‚å‡è®¾ç°åœ¨è¯­æ–™åº“ä¸­åªæœ‰ä¸‰ä¸ªå¥å­ â€œI have a catâ€ã€â€œcat eat fishâ€ã€â€œI have a appleâ€ï¼Œåˆ™å¯ä»¥æ„é€ å‡ºå•è¯é—´çš„å…±ç°çŸ©é˜µ Aã€‚ä¾‹å¦‚ â€œIâ€ å’Œ â€œhaveâ€ åœ¨ä¸¤ä¸ªå¥å­ä¸­å…±åŒå‡ºç°è¿‡ï¼Œå› æ­¤åœ¨ Aä¸­çš„æƒé‡ä¸º 2ï¼›è€Œ â€œIâ€ å’Œ â€œcatâ€œ åªåœ¨ä¸€ä¸ªå¥å­ä¸­å…±ç°ï¼Œ A ä¸­æƒé‡ä¸º 1 ã€‚
      <br/>
      çŸ©é˜µ A çš„æ¯ä¸€è¡Œå°±ä»£è¡¨äº†ä¸€ä¸ªå•è¯çš„è¯å‘é‡ï¼Œä¸ one-hot ç¼–ç ç±»ä¼¼ï¼Œä½¿ç”¨å…±ç°çŸ©é˜µçš„è¯å‘é‡çš„ç»´åº¦ä¹Ÿéå¸¸å¤§ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨ SVD (å¥‡å¼‚å€¼åˆ†è§£) å¯¹ Aè¿›è¡Œåˆ†è§£ï¼Œä»è€Œå¾—åˆ°æ›´ä½ç»´åº¦çš„è¯å‘é‡ï¼Œä½†æ˜¯ SVD ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦è¾ƒé«˜ï¼Œå¯¹ nÃ—n çš„çŸ©é˜µè¿›è¡Œ SVD åˆ†è§£çš„å¤æ‚åº¦ä¸º
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         O 
         
        
          ( 
         
         
         
           n 
          
         
           3 
          
         
        
          ) 
         
        
       
         O(n^3)
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 1.0641em; vertical-align: -0.25em;">
          </span>
          <span class="mord mathnormal" style="margin-right: 0.0278em;">
           O
          </span>
          <span class="mopen">
           (
          </span>
          <span class="mord">
           <span class="mord mathnormal">
            n
           </span>
           <span class="msupsub">
            <span class="vlist-t">
             <span class="vlist-r">
              <span class="vlist" style="height: 0.8141em;">
               <span class="" style="top: -3.063em; margin-right: 0.05em;">
                <span class="pstrut" style="height: 2.7em;">
                </span>
                <span class="sizing reset-size6 size3 mtight">
                 <span class="mord mtight">
                  3
                 </span>
                </span>
               </span>
              </span>
             </span>
            </span>
           </span>
          </span>
          <span class="mclose">
           )
          </span>
         </span>
        </span>
       </span>
      </span>
      ã€‚
      <br/>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/db318d39bcd04143a7ea6dce12af8ba4.png"/>
     </p>
    </blockquote>
    <p>
     Word2Vec
    </p>
    <blockquote>
     <p>
      ã€ŠEfficient Estimation of Word Representation in Vector Spaceã€‹- Word2Vec(2013)
      <br/>
      Word2Vecè¯å‘é‡æ¨¡å‹ï¼Œå¯ä»¥ç”¨æ•°å€¼å‘é‡è¡¨ç¤ºå•è¯ï¼Œä¸”åœ¨å‘é‡ç©ºé—´ä¸­å¯ä»¥å¾ˆå¥½åœ°è¡¡é‡ä¸¤ä¸ªå•è¯çš„ç›¸ä¼¼æ€§ï¼Œå®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡è¯çš„ä¸Šä¸‹æ–‡å¾—åˆ°è¯çš„å‘é‡åŒ–è¡¨ç¤ºã€‚
      <br/>
      Word2Vecæ˜¯è½»é‡çº§çš„ç¥ç»ç½‘ç»œï¼Œå…¶æ¨¡å‹ä»…ä»…åŒ…æ‹¬è¾“å…¥å±‚ã€éšè—å±‚å’Œè¾“å‡ºå±‚ï¼Œæ¨¡å‹æ¡†æ¶æ ¹æ®è¾“å…¥è¾“å‡ºçš„ä¸åŒï¼Œä¸»è¦åŒ…æ‹¬CBOWå’ŒSkip-gramæ¨¡å‹ã€‚
      <br/>
      ä¸¤ç§æ¨¡å‹çš„åŒºåˆ«åœ¨äº CBOW ä½¿ç”¨ä¸Šä¸‹æ–‡è¯é¢„æµ‹ä¸­å¿ƒè¯ï¼Œè€Œ Skip-Gram ä½¿ç”¨ä¸­å¿ƒè¯é¢„æµ‹å…¶ä¸Šä¸‹æ–‡å•è¯ã€‚CBOWé€‚åˆäºæ•°æ®é›†è¾ƒå°çš„æƒ…å†µï¼Œè€ŒSkip-Gramåœ¨å¤§å‹è¯­æ–™ä¸­è¡¨ç°æ›´å¥½ã€‚
      <br/>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/1f82c8655eae480c8e9389d97d4f5b8e.png"/>
      <br/>
      Simple CBOW Model
      <br/>
      ä¸ºäº†æ›´å¥½çš„äº†è§£æ¨¡å‹æ·±å¤„çš„åŸç†ï¼Œæˆ‘ä»¬å…ˆä»Simple CBOW modelï¼ˆä»…è¾“å…¥ä¸€ä¸ªè¯ï¼Œè¾“å‡ºä¸€ä¸ªè¯ï¼‰æ¡†æ¶è¯´èµ·ã€‚
      <br/>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/d463068c413746f3a26dfa68ca56add8.png"/>
      <br/>
      input layerè¾“å…¥çš„Xæ˜¯å•è¯çš„one-hot representationï¼ˆè€ƒè™‘ä¸€ä¸ªè¯è¡¨Vï¼Œé‡Œé¢çš„æ¯ä¸€ä¸ªè¯
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         w 
          
         
           i 
          
         
        
       
         w_i
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.5806em; vertical-align: -0.15em;">
          </span>
          <span class="mord">
           <span class="mord mathnormal" style="margin-right: 0.0269em;">
            w
           </span>
           <span class="msupsub">
            <span class="vlist-t vlist-t2">
             <span class="vlist-r">
              <span class="vlist" style="height: 0.3117em;">
               <span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;">
                <span class="pstrut" style="height: 2.7em;">
                </span>
                <span class="sizing reset-size6 size3 mtight">
                 <span class="mord mathnormal mtight">
                  i
                 </span>
                </span>
               </span>
              </span>
              <span class="vlist-s">
               â€‹
              </span>
             </span>
             <span class="vlist-r">
              <span class="vlist" style="height: 0.15em;">
               <span class="">
               </span>
              </span>
             </span>
            </span>
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
      éƒ½æœ‰ä¸€ä¸ªç¼–å·
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         i 
         
        
          Ïµ 
         
        
          { 
         
        
          1 
         
        
          , 
         
        
          . 
         
        
          . 
         
        
          . 
         
        
          , 
         
        
          âˆ£ 
         
        
          V 
         
        
          âˆ£ 
         
        
          } 
         
        
       
         i\epsilon \{1,...,|V|\}
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 1em; vertical-align: -0.25em;">
          </span>
          <span class="mord mathnormal">
           i
          </span>
          <span class="mord mathnormal">
           Ïµ
          </span>
          <span class="mopen">
           {
           <!-- -->
          </span>
          <span class="mord">
           1
          </span>
          <span class="mpunct">
           ,
          </span>
          <span class="mspace" style="margin-right: 0.1667em;">
          </span>
          <span class="mord">
           ...
          </span>
          <span class="mpunct">
           ,
          </span>
          <span class="mspace" style="margin-right: 0.1667em;">
          </span>
          <span class="mord">
           âˆ£
          </span>
          <span class="mord mathnormal" style="margin-right: 0.2222em;">
           V
          </span>
          <span class="mord">
           âˆ£
          </span>
          <span class="mclose">
           }
          </span>
         </span>
        </span>
       </span>
      </span>
      ï¼Œé‚£ä¹ˆè¯
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         w 
          
         
           i 
          
         
        
       
         w_i
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.5806em; vertical-align: -0.15em;">
          </span>
          <span class="mord">
           <span class="mord mathnormal" style="margin-right: 0.0269em;">
            w
           </span>
           <span class="msupsub">
            <span class="vlist-t vlist-t2">
             <span class="vlist-r">
              <span class="vlist" style="height: 0.3117em;">
               <span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;">
                <span class="pstrut" style="height: 2.7em;">
                </span>
                <span class="sizing reset-size6 size3 mtight">
                 <span class="mord mathnormal mtight">
                  i
                 </span>
                </span>
               </span>
              </span>
              <span class="vlist-s">
               â€‹
              </span>
             </span>
             <span class="vlist-r">
              <span class="vlist" style="height: 0.15em;">
               <span class="">
               </span>
              </span>
             </span>
            </span>
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
      çš„one-hotè¡¨ç¤ºå°±æ˜¯ä¸€ä¸ªç»´åº¦ä¸º
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         âˆ£ 
         
        
          V 
         
        
          âˆ£ 
         
        
       
         |V|
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 1em; vertical-align: -0.25em;">
          </span>
          <span class="mord">
           âˆ£
          </span>
          <span class="mord mathnormal" style="margin-right: 0.2222em;">
           V
          </span>
          <span class="mord">
           âˆ£
          </span>
         </span>
        </span>
       </span>
      </span>
      çš„å‘é‡ï¼Œå…¶ä¸­ç¬¬iä¸ªå…ƒç´ å€¼éé›¶ï¼Œå…¶ä½™å…ƒç´ å…¨ä¸º0ï¼Œä¾‹å¦‚ï¼š
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         w 
          
         
           2 
          
         
        
          = 
         
        
          [ 
         
        
          0 
         
        
          , 
         
        
          1 
         
        
          , 
         
        
          0 
         
        
          , 
         
        
          . 
         
        
          . 
         
        
          . 
         
        
          , 
         
        
          0 
         
         
         
           ] 
          
         
           T 
          
         
        
       
         w_2=[0,1,0,...,0]^T
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.5806em; vertical-align: -0.15em;">
          </span>
          <span class="mord">
           <span class="mord mathnormal" style="margin-right: 0.0269em;">
            w
           </span>
           <span class="msupsub">
            <span class="vlist-t vlist-t2">
             <span class="vlist-r">
              <span class="vlist" style="height: 0.3011em;">
               <span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;">
                <span class="pstrut" style="height: 2.7em;">
                </span>
                <span class="sizing reset-size6 size3 mtight">
                 <span class="mord mtight">
                  2
                 </span>
                </span>
               </span>
              </span>
              <span class="vlist-s">
               â€‹
              </span>
             </span>
             <span class="vlist-r">
              <span class="vlist" style="height: 0.15em;">
               <span class="">
               </span>
              </span>
             </span>
            </span>
           </span>
          </span>
          <span class="mspace" style="margin-right: 0.2778em;">
          </span>
          <span class="mrel">
           =
          </span>
          <span class="mspace" style="margin-right: 0.2778em;">
          </span>
         </span>
         <span class="base">
          <span class="strut" style="height: 1.0913em; vertical-align: -0.25em;">
          </span>
          <span class="mopen">
           [
          </span>
          <span class="mord">
           0
          </span>
          <span class="mpunct">
           ,
          </span>
          <span class="mspace" style="margin-right: 0.1667em;">
          </span>
          <span class="mord">
           1
          </span>
          <span class="mpunct">
           ,
          </span>
          <span class="mspace" style="margin-right: 0.1667em;">
          </span>
          <span class="mord">
           0
          </span>
          <span class="mpunct">
           ,
          </span>
          <span class="mspace" style="margin-right: 0.1667em;">
          </span>
          <span class="mord">
           ...
          </span>
          <span class="mpunct">
           ,
          </span>
          <span class="mspace" style="margin-right: 0.1667em;">
          </span>
          <span class="mord">
           0
          </span>
          <span class="mclose">
           <span class="mclose">
            ]
           </span>
           <span class="msupsub">
            <span class="vlist-t">
             <span class="vlist-r">
              <span class="vlist" style="height: 0.8413em;">
               <span class="" style="top: -3.063em; margin-right: 0.05em;">
                <span class="pstrut" style="height: 2.7em;">
                </span>
                <span class="sizing reset-size6 size3 mtight">
                 <span class="mord mathnormal mtight" style="margin-right: 0.1389em;">
                  T
                 </span>
                </span>
               </span>
              </span>
             </span>
            </span>
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
      ï¼›
      <br/>
      è¾“å…¥å±‚åˆ°éšè—å±‚ä¹‹é—´æœ‰ä¸€ä¸ªæƒé‡çŸ©é˜µWï¼Œéšè—å±‚å¾—åˆ°çš„å€¼æ˜¯ç”±è¾“å…¥Xä¹˜ä¸Šæƒé‡çŸ©é˜µå¾—åˆ°çš„ï¼ˆç»†å¿ƒçš„äººä¼šå‘ç°ï¼Œ0-1å‘é‡ä¹˜ä¸Šä¸€ä¸ªçŸ©é˜µï¼Œå°±ç›¸å½“äºé€‰æ‹©äº†æƒé‡çŸ©é˜µçš„æŸä¸€è¡Œï¼Œå¦‚å›¾ï¼šè¾“å…¥çš„å‘é‡Xæ˜¯[0ï¼Œ0ï¼Œ1ï¼Œ0ï¼Œ0ï¼Œ0]ï¼ŒWçš„è½¬ç½®ä¹˜ä¸ŠXå°±ç›¸å½“äºä»çŸ©é˜µä¸­é€‰æ‹©ç¬¬3è¡Œ[2,1,3]ä½œä¸ºéšè—å±‚çš„å€¼ï¼‰;
      <br/>
      éšè—å±‚åˆ°è¾“å‡ºå±‚ä¹Ÿæœ‰ä¸€ä¸ªæƒé‡çŸ©é˜µWâ€™ï¼Œå› æ­¤ï¼Œè¾“å‡ºå±‚å‘é‡yçš„æ¯ä¸€ä¸ªå€¼ï¼Œå…¶å®å°±æ˜¯éšè—å±‚çš„å‘é‡ç‚¹ä¹˜æƒé‡å‘é‡Wâ€™çš„æ¯ä¸€åˆ—ï¼Œæ¯”å¦‚è¾“å‡ºå±‚çš„ç¬¬ä¸€ä¸ªæ•°7ï¼Œå°±æ˜¯å‘é‡[2,1,3]å’Œåˆ—å‘é‡[1,2,1]ç‚¹ä¹˜ä¹‹åçš„ç»“æœï¼›
      <br/>
      æœ€ç»ˆçš„è¾“å‡ºéœ€è¦ç»è¿‡softmaxå‡½æ•°ï¼Œå°†è¾“å‡ºå‘é‡ä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ å½’ä¸€åŒ–åˆ°0-1ä¹‹é—´çš„æ¦‚ç‡ï¼Œæ¦‚ç‡æœ€å¤§çš„ï¼Œå°±æ˜¯é¢„æµ‹çš„è¯ã€‚
      <br/>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/3659c3f4f1304c0cb0450b19a03772c6.png"/>
      <br/>
      è¾“å‡ºå±‚é€šè¿‡softmaxå½’ä¸€åŒ–ï¼Œuä»£è¡¨çš„æ˜¯è¾“å‡ºå±‚çš„åŸå§‹ç»“æœã€‚é€šè¿‡ä¸‹é¢å…¬å¼ï¼Œæˆ‘ä»¬çš„ç›®æ ‡å‡½æ•°å¯ä»¥è½¬åŒ–ä¸ºç°åœ¨è¿™ä¸ªå½¢å¼
      <br/>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/ab6c7e031a6a4a21843aacd65967b91b.png"/>
      <br/>
      CBOW Multi-Word Context Model
      <br/>
      äº†è§£äº†Simple CBOW modelä¹‹åï¼Œæ‰©å±•åˆ°CBOWå°±å¾ˆå®¹æ˜“äº†ï¼Œåªæ˜¯æŠŠå•ä¸ªè¾“å…¥æ¢æˆå¤šä¸ªè¾“å…¥ç½¢äº†ï¼ˆåˆ’çº¢çº¿éƒ¨åˆ†ï¼‰ã€‚
      <br/>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/2efb02b3ef84458888aee1410470b292.png"/>
      <br/>
      å¯¹æ¯”å¯ä»¥å‘ç°ï¼Œå’Œsimple CBOWä¸åŒä¹‹å¤„åœ¨äºï¼Œè¾“å…¥ç”±1ä¸ªè¯å˜æˆäº†Cä¸ªè¯ï¼Œæ¯ä¸ªè¾“å…¥X_{ik}åˆ°è¾¾éšè—å±‚éƒ½ä¼šç»è¿‡ç›¸åŒçš„æƒé‡çŸ©é˜µWï¼Œéšè—å±‚hçš„å€¼å˜æˆäº†å¤šä¸ªè¯ä¹˜ä¸Šæƒé‡çŸ©é˜µä¹‹ååŠ å’Œæ±‚å¹³å‡å€¼ã€‚
      <br/>
      Skip-gram
      <br/>
      æœ‰äº†CBOWçš„ä»‹ç»ï¼Œå¯¹äºSkip-gram model çš„ç†è§£åº”è¯¥ä¼šæ›´å¿«ä¸€äº›ã€‚
      <br/>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/01d5243d7fa4456689f8901190564e6e.png"/>
      <br/>
      å¦‚ä¸Šå›¾æ‰€ç¤ºï¼ŒSkip-gram modelæ˜¯é€šè¿‡è¾“å…¥ä¸€ä¸ªè¯å»é¢„æµ‹å¤šä¸ªè¯çš„æ¦‚ç‡ã€‚è¾“å…¥å±‚åˆ°éšè—å±‚çš„åŸç†å’Œsimple CBOWä¸€æ ·ï¼Œä¸åŒçš„æ˜¯éšè—å±‚åˆ°è¾“å‡ºå±‚ï¼ŒæŸå¤±å‡½æ•°å˜æˆäº†Cä¸ªè¯æŸå¤±å‡½æ•°çš„æ€»å’Œï¼Œæƒé‡çŸ©é˜µWâ€™è¿˜æ˜¯å…±äº«çš„ã€‚
     </p>
    </blockquote>
    <p>
     GloVe
    </p>
    <blockquote>
     <p>
      ã€ŠGloVe : Global Vectors forWord Representationã€‹å…¨å±€å‘é‡çš„è¯åµŒå…¥ï¼Œé€šå¸¸ç®€ç§°ä¸ºGloVeï¼Œæ˜¯ä¸€ç§ç”¨äºå°†è¯è¯­æ˜ å°„åˆ°è¿ç»­å‘é‡ç©ºé—´çš„è¯åµŒå…¥æ–¹æ³•ã€‚å®ƒæ—¨åœ¨æ•æ‰è¯è¯­ä¹‹é—´çš„è¯­ä¹‰å…³ç³»å’Œè¯­æ³•å…³ç³»ï¼Œä»¥ä¾¿åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­èƒ½å¤Ÿæ›´å¥½åœ°è¡¨ç¤ºè¯è¯­çš„è¯­ä¹‰ä¿¡æ¯ã€‚
      <br/>
      å¸¸è§çš„è¯åµŒå…¥ç®—æ³•æœ‰åŸºäºçŸ©é˜µåˆ†è§£çš„æ–¹æ³•å’ŒåŸºäºæµ…å±‚çª—å£çš„æ–¹æ³•ï¼ŒGlove ç»“åˆäº†è¿™ä¸¤ç±»æ–¹æ³•çš„ä¼˜ç‚¹ç”Ÿæˆè¯å‘é‡ã€‚åŸºäºçŸ©é˜µåˆ†è§£çš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨å…¨å±€ä¿¡æ¯ï¼Œä½†æ˜¯åœ¨å¤§æ•°æ®é›†ä¸Šé€Ÿåº¦æ…¢ï¼›è€ŒåŸºäºæµ…å±‚çª—å£çš„æ–¹æ³•å¯¹äºè¯æ±‡ç±»æ¯”ä»»åŠ¡æ•ˆæœè¾ƒå¥½ï¼Œè®­ç»ƒé€Ÿåº¦å¿«ï¼Œä½†æ˜¯ä¸èƒ½æœ‰æ•ˆåˆ©ç”¨å…¨å±€ä¿¡æ¯ã€‚
      <br/>
      è¯åµŒå…¥ç®—æ³• Gloveï¼Œç»“åˆä¸¤ç±»è¯åµŒå…¥ç®—æ³•çš„ä¼˜ç‚¹ã€‚
      <br/>
      ç¬¬ä¸€ç±»æ˜¯ Matrix Factorization (çŸ©é˜µåˆ†è§£) æ–¹æ³•ï¼Œä¾‹å¦‚ LSAï¼›
      <br/>
      ç¬¬äºŒç±»æ˜¯ Shallow Window-Based (åŸºäºæµ…å±‚çª—å£) æ–¹æ³•ï¼Œä¹Ÿç§°ä¸ºåŸºäºé¢„æµ‹çš„æ–¹æ³•ï¼Œä¾‹å¦‚ Word2Vecã€‚
      <br/>
      GloVeæ¨¡å‹å°† LSA å’Œ Word2Vec çš„ä¼˜ç‚¹ç»“åˆåœ¨ä¸€èµ·ï¼Œæ—¢åˆ©ç”¨äº†è¯­æ–™åº“çš„å…¨å±€ç»Ÿè®¡ä¿¡æ¯ï¼Œä¹Ÿåˆ©ç”¨äº†å±€éƒ¨çš„ä¸Šä¸‹æ–‡ç‰¹å¾ (æ»‘åŠ¨çª—å£)ã€‚Glove é¦–å…ˆéœ€è¦æ„é€ å•è¯å…±ç°çŸ©é˜µï¼Œå¹¶æå‡ºäº†å…±ç°æ¦‚ç‡çŸ©é˜µ (Co-occurrence Probabilities Matrix)çš„æ¦‚å¿µï¼Œå…±ç°æ¦‚ç‡çŸ©é˜µå¯ä»¥é€šè¿‡å•è¯å…±ç°çŸ©é˜µè®¡ç®—ã€‚
     </p>
    </blockquote>
    <p>
     ELMo
    </p>
    <blockquote>
     <p>
      ELMoæ¥è‡ªäºè®ºæ–‡ã€ŠDeep contextualized word representationsã€‹(2018)
      <br/>
      <img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://i-blog.csdnimg.cn/direct/1a865ea56d264f3b99b422375636cc6f.webp#pic_center"/>
      <br/>
      word2vecå’Œgloveè¿™ä¸¤ç§ç®—æ³•éƒ½æ˜¯é™æ€è¯å‘é‡ç®—æ³•ï¼Œå®ƒä»¬éƒ½å­˜åœ¨ä¸€ä¸ªé—®é¢˜ï¼Œè¯åœ¨ä¸åŒçš„è¯­å¢ƒä¸‹å…¶å®æœ‰ä¸åŒçš„å«ä¹‰ï¼Œè€Œè¿™ä¸¤ä¸ªæ¨¡å‹è¯åœ¨ä¸åŒè¯­å¢ƒä¸‹çš„å‘é‡è¡¨ç¤ºæ˜¯ç›¸åŒçš„ï¼›
      <br/>
      ELMoæ˜¯ä¸€ç§åŠ¨æ€è¯å‘é‡ç®—æ³•ï¼Œå°±æ˜¯é’ˆå¯¹è¿™ä¸€ç‚¹è¿›è¡Œäº†ä¼˜åŒ–ï¼Œæ¥è‡ªäºè¯­è¨€æ¨¡å‹çš„è¯å‘é‡è¡¨ç¤ºï¼Œä¹Ÿæ˜¯åˆ©ç”¨äº†æ·±åº¦ä¸Šä¸‹æ–‡å•è¯è¡¨å¾ï¼Œè¯¥æ¨¡å‹çš„ä¼˜åŠ¿ï¼š ï¼ˆ1ï¼‰èƒ½å¤Ÿå¤„ç†å•è¯ç”¨æ³•ä¸­çš„å¤æ‚ç‰¹æ€§ï¼ˆæ¯”å¦‚å¥æ³•å’Œè¯­ä¹‰ï¼‰ ï¼ˆ2ï¼‰è¿™äº›ç”¨æ³•åœ¨ä¸åŒçš„è¯­è¨€ä¸Šä¸‹æ–‡ä¸­å¦‚ä½•å˜åŒ–ï¼ˆæ¯”å¦‚ä¸ºè¯çš„å¤šä¹‰æ€§å»ºæ¨¡ï¼‰
      <br/>
      é’ˆå¯¹ç‚¹1ï¼Œä½œè€…æ˜¯é€šè¿‡å¤šå±‚çš„stack LSTMå»å­¦ä¹ è¯çš„å¤æ‚ç”¨æ³•ï¼Œè®ºæ–‡ä¸­çš„å®éªŒéªŒè¯äº†ä½œè€…çš„æƒ³æ³•ï¼Œä¸åŒå±‚çš„outputå¯ä»¥è·å¾—ä¸åŒå±‚æ¬¡çš„è¯æ³•ç‰¹å¾ã€‚å¯¹äºè¯ä¹‰æ¶ˆæ­§æœ‰éœ€æ±‚çš„ä»»åŠ¡ï¼Œç¬¬2å±‚ä¼šæœ‰è¾ƒå¤§çš„æƒé‡ï¼Œå¯¹äºè¯æ€§ã€å¥æ³•æœ‰éœ€æ±‚çš„ä»»åŠ¡ï¼Œå¯¹ç¬¬1å±‚ä¼šæœ‰æ¯”è¾ƒå¤§çš„æƒé‡ã€‚
      <br/>
      é’ˆå¯¹ç‚¹2ï¼Œä½œè€…é€šè¿‡pre-train+fine tuningçš„æ–¹å¼å®ç°ï¼Œå…ˆåœ¨å¤§è¯­æ–™åº“ä¸Šè¿›è¡Œpre-trainï¼Œå†åœ¨ä¸‹æ¸¸ä»»åŠ¡çš„è¯­æ–™åº“ä¸Šè¿›è¡Œfine tuningã€‚
      <br/>
      <strong>
       ELMoæ¨¡å‹æœ‰ä¸‰ä¸ªä¼˜ç‚¹ï¼š
      </strong>
      <br/>
      ELMoå…·æœ‰å¤„ç†ä¸€è¯å¤šä¹‰çš„èƒ½åŠ›ã€‚å› ä¸ºELMoä¸­æ¯ä¸ªå•è¯çš„åµŒå…¥å¹¶ä¸æ˜¯å›ºå®šçš„ï¼Œåœ¨å°†è¿™ä¸ªå•è¯çš„è¯åµŒå…¥è¾“å…¥åŒå‘LSTMä¹‹åï¼Œå®ƒçš„å€¼ä¼šéšç€ä¸Šä¸‹æ–‡å†…å®¹çš„ä¸åŒè€Œæ”¹å˜ï¼Œä»è€Œå­¦åˆ°äº†å’Œä¸Šä¸‹æ–‡ç›¸å…³çš„è¯åµŒå…¥ã€‚
      <br/>
      ELMoå…·æœ‰ä¸åŒå±‚æ¬¡çš„è¡¨å¾èƒ½åŠ›ã€‚æˆ‘ä»¬çŸ¥é“ï¼Œå¯¹äºä¸€ä¸ªå¤šå±‚çš„ç½‘ç»œæ¥è¯´ï¼Œä¸åŒçš„æ·±åº¦å…·æœ‰ä¸åŒçš„è¡¨å¾èƒ½åŠ›ï¼Œè¶Šæ¥è¿‘è¾“å…¥å±‚çš„ç½‘ç»œå±‚å­¦åˆ°çš„ç‰¹å¾è¶Šæ¥è¿‘è¾“å…¥çš„åŸå§‹ç‰¹å¾ï¼Œè€Œè¶Šæ¥è¿‘ç½‘ç»œè¾“å‡ºå±‚çš„ç½‘ç»œå±‚å­¦åˆ°çš„ç‰¹å¾åˆ™å…·æœ‰å¾ˆå¥½çš„è¯­ä¹‰è¡¨å¾èƒ½åŠ›ã€‚ELMoä½¿ç”¨äº†å¯¹å¤šå±‚LSTMçš„è¾“å‡ºè¿›è¡Œè‡ªé€‚åº”åŠ æƒçš„ç»“æ„ï¼ˆattentionï¼‰ï¼Œä½¿ç”¨å…¶å¯ä»¥æ ¹æ®ä¸‹æ¸¸ä»»åŠ¡è‡ªé€‚åº”è°ƒæ•´ELMoçš„è¾“å‡ºï¼Œè®©å…¶ä¸ä¸‹æ¸¸ä»»åŠ¡ç›¸é€‚åº”ã€‚
      <br/>
      ELMoå…·æœ‰éå¸¸å¼ºå¤§çš„çµæ´»æ€§ï¼šé™¤äº†ELMoæœ¬èº«çš„è¾“å…¥å¯ä»¥æ ¹æ®è°ƒæ•´å¤–ï¼ŒELMoè¿˜å¯ä»¥ä»¥å„ç§å½¢å¼å’Œä¸‹æ¸¸ä»»åŠ¡è¿›è¡Œç»“åˆã€‚é€šè¿‡ELMoå¾—åˆ°çš„ä»…æ˜¯å½“å‰æ—¶é—´ç‰‡çš„è¾“å…¥çš„ç¼–ç ç»“æœï¼Œå› æ­¤å¯ä»¥åŠ å…¥åˆ°è¾“å…¥å±‚ï¼Œéšå±‚ï¼Œè¾“å‡ºå±‚ä¸­ã€‚
      <br/>
      ELMoæ˜¯æœ€æ—©çš„ä¸€æ‰¹å°†æ·±åº¦å­¦ä¹ åº”ç”¨åˆ°è¯å‘é‡å­¦ä¹ çš„ä»»åŠ¡ä¸­ï¼Œå®ƒçš„æ€æƒ³å¯¹åç»­çš„BERTç­‰äº§ç”Ÿäº†å·¨å¤§çš„å½±å“ã€‚
     </p>
    </blockquote>
    <h4>
     <a id="_551">
     </a>
     å‚è€ƒï¼š
    </h4>
    <p>
     <a href="https://blog.csdn.net/weixin_62472350/article/details/143448417">
      NNLMâ€”â€”é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯
     </a>
     <br/>
     <a href="https://www.bilibili.com/video/BV1AT4y1J7bv/" rel="nofollow">
      Neural Network Language Model PyTorchå®ç°
     </a>
     <br/>
     <a href="https://wmathor.com/index.php/archives/1442/" rel="nofollow">
      NNLM çš„ PyTorch å®ç°
     </a>
    </p>
    <p>
     <a href="https://www.cnblogs.com/tsingke/p/14826896.html" rel="nofollow">
      BPç¥ç»ç½‘ç»œï¼šè¯¯å·®åå‘ä¼ æ’­ç®—æ³•å…¬å¼æ¨å¯¼å›¾è§£
     </a>
     <br/>
     <a href="https://zhuanlan.zhihu.com/p/689910526" rel="nofollow">
      RNNå­˜åœ¨æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜
     </a>
    </p>
    <p>
     å‚è€ƒï¼š
     <a href="https://blog.csdn.net/julac/article/details/127767053">
      ä¸€ç¯‡æ–‡ç« å…¥é—¨Word2Vec
     </a>
     <br/>
     <a href="https://www.cnblogs.com/stephen-goodboy/p/12574738.html" rel="nofollow">
      è¯å‘é‡æ¨¡å‹word2vectorè¯¦è§£
     </a>
    </p>
    <p>
     å‚è€ƒï¼š
     <a href="https://blog.csdn.net/Jackie_vip/article/details/141600366">
      ã€å¤§æ¨¡å‹ç³»åˆ—ç¯‡ã€‘è¯å‘é‡ - ä»Word2Vecåˆ°ELMo
     </a>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f33383133393235302f:61727469636c652f64657461696c732f313436313435353433" class_="artid" style="display:none">
 </p>
</div>


