---
layout: post
title: "DeepSeek-R1本地化部署Mac"
date: 2025-03-07 16:05:54 +0800
description: "DeepSeek-R1本地化部署（Mac）"
keywords: "DeepSeek-R1本地化部署（Mac）"
categories: ['技术实践']
tags: ['Macos', 'Deepseek', 'Ai']
artid: "146089304"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146089304
    alt: "DeepSeek-R1本地化部署Mac"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146089304
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146089304
cover: https://bing.ee123.net/img/rand?artid=146089304
image: https://bing.ee123.net/img/rand?artid=146089304
img: https://bing.ee123.net/img/rand?artid=146089304
---

# DeepSeek-R1本地化部署（Mac）

#### **一、下载 Ollama**

本地化部署需要用到 Ollama，它能支持很多大模型。官方网站：https://ollama.com/

![](https://i-blog.csdnimg.cn/direct/62f61b20ebc645ad89a3532fc46c7e2e.png)

点击 Download 即可，支持macOS,Linux 和 Windows；我下载的是 mac 版本，要求macOS 11 Big Sur or
later，Ollama是跳转到github去下载的，如果下载不了可能要借助科学上网。

下载的是个压缩包，直接双击就可以解压出Ollama.app，点击运行即可安装

![](https://i-blog.csdnimg.cn/direct/f21c218bfb2a4f7bab346290464f7a85.png)

安装成功之后，ollama会在后台运行，启动命令行，输入ollama

![](https://i-blog.csdnimg.cn/direct/bce7ff52453e413ca276ddaf42890ee7.png)

出现以上页面即表示安装成功

#### **二、下载DeepSeek-R1**

还是进入ollama.com的页面，点击Models

![](https://i-blog.csdnimg.cn/direct/f5de70fe6bea4076a82cabb70b74de98.png)

下载deepseek-r1，

![](https://i-blog.csdnimg.cn/direct/abd7e473c038444c91dd2f0a87dd5ee6.png)

deepseek-r1有很多个版本，1.5b，7b，8b，14b，32b，70b，671b，分别代表模型不同的参数数量。

  * B = Billion（十亿参数）：表示模型的参数量级，直接影响计算复杂度和显存占用。 
    * DeepSeek 1.5B：15亿参数（小型模型，适合轻量级任务）
    * DeepSeek 7B：70亿参数（主流规模，平衡性能与资源）
    * DeepSeek 70B：700亿参数（高性能需求场景）
    * DeepSeek 671B：6710亿参数（超大规模，对标PaLM/GPT-4）

每个版本对应所需的内存大小都不一样，如果你电脑运行内存为8G那可以下载1.5b，7b，8b的蒸馏后的模型；如果你电脑运行内存为16G那可以下载14b的蒸馏后的模型，我这里选择14b的模型。

使用ollama run deepseek-r1:14b 进行下载，在命令行里面输入：

    
    
    ollama run deepseek-r1:14b

![](https://i-blog.csdnimg.cn/direct/18fc272b66ac49b080ad0354c5ed2d70.png)

使用ollama list 查看是否成功下载了模型

![](https://i-blog.csdnimg.cn/direct/371362214b2e42a98de5d2f2a82dfd2c.png)

输入ollama run
deepseek-r1:14b运行模型，启动成功后，就可以输入我们想问的问题，模型首先会进行深度思考（也就是think标签包含的地方），思考结束后会反馈我们问题的结果。在>>>之后输入想要咨询的
问题，模型回答的速度取决电脑的性能。

![](https://i-blog.csdnimg.cn/direct/128983f54ecc487b9a1d8934639c57a2.png)

使用快捷键Ctrl + d 或者在>>>之后输入 /bye即可退出对话模式。

    
    
    ## 删除模型
    ollama rm deepseek-r1:14b
    ## 停止模型
    ollama stop deepseek-r1:14b

#### **三、web页面的访问**

我们通过ollama下载模型后，可以在命令行使用deepseek了，但是命令行的形式还是有些不友好，我们可以借助chatBox，或者Open-
WebUI，只要接入ollama的Api就可以使用了。

##### **1、Open-WebUI**

Open
WebUI是一个可扩展、功能丰富、用户友好的自托管AI平台，旨在完全离线运行。它支持各种LLM运行程序，如Ollama和OpenAI兼容的API，内置RAG推理引擎，使其成为一个强大的AI部署解决方案，本地需要安装Python3（版本3.11～3.13以下）。

安装 Open-WebUI需要使用pip进行安装，安装需要一定时间

    
    
    pip install open-webui
    ### 如网络太差，可以使用国内的镜像下载
    pip install open-webui -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com

如果 pip 版本较低，可以更新下

    
    
    python3 -m pip install --upgrade pip

使用如下命令启动open-webui服务，启动需要一定时间

    
    
    open-webui serve

后使用浏览器输入<http://127.0.0.1:8080/>登录服务，注意端口的占用冲突，页面如下：

![](https://i-blog.csdnimg.cn/direct/bbbc94cbb83041e795887905904191f7.png)

点击开始使用，第一次使用需要注册用户名、邮件以及密码，这都是存在本地的，可以放心填写。

![](https://i-blog.csdnimg.cn/direct/d29227cac5de4fe4ba625f65b33f87fe.png)

注册完毕后，如果本地已经运行了deepseek-r1，它可以自动识别本地已经安装的deepseek r1大模型，

![](https://i-blog.csdnimg.cn/direct/7091fc0b3bef410fa597b9a36630976d.png)

在对话框里面输入内容，即可与deepseek-r1展开对话

![](https://i-blog.csdnimg.cn/direct/7a5d60fa1b48477d8b14efc491afcdcc.png)

##### **2、ChatBox**

Chatbox AI 是一款 AI 客户端应用和智能助手，支持众多先进的 AI 模型和 API，可在
Windows、MacOS、Android、iOS、Linux 和网页版上使用。

![](https://i-blog.csdnimg.cn/direct/49b84f619ca4498bbb75e0ea31bb4a09.png)我这里下载的mac版本，成功安装启动后，点击左下角的**设置**

![](https://i-blog.csdnimg.cn/direct/4ded4864ce924e2faf9b0aba98f3adb6.png)

模型提供方选择Ollama API

![](https://i-blog.csdnimg.cn/direct/63cb7395b53245d0b8b12108e0803ef1.png)

模型选择本地部署好的deepseek-r1:14b，点击保存，即可以开始对话

![](https://i-blog.csdnimg.cn/direct/9962bd96fcdc41e5975cdc4b5ad5b666.png)

**最后：蒸馏模型不同规格的选择，需要结合自己电脑的配置来选择，不合适的模型会导致电脑过载，对话回答的速度和效果问题都会很差。我电脑内存16GB，以为14b能扛得住，结果安装之后，对话巨慢！后面安装了8b，运行起来速度就快多了，但是通过页面的返回速度会变慢。**



