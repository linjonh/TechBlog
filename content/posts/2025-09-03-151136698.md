---
layout: post
title: "Day20_机器学习逻辑回归-1原理"
date: 2025-09-03T19:50:10+0800
description: "逻辑回归是一种，要用于解决经典的问题其把。"
keywords: "Day20_【机器学习—逻辑回归 (1)—原理】"
categories: ['未分类']
tags: ['逻辑回归原理', '逻辑回归', '机器学习', '人工智能']
artid: "151136698"
arturl: "https://blog.csdn.net/l12345sy/article/details/151136698"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=151136698
    alt: "Day20_机器学习逻辑回归-1原理"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=151136698
featuredImagePreview: https://bing.ee123.net/img/rand?artid=151136698
cover: https://bing.ee123.net/img/rand?artid=151136698
image: https://bing.ee123.net/img/rand?artid=151136698
img: https://bing.ee123.net/img/rand?artid=151136698
---



# Day20_【机器学习—逻辑回归 (1)—原理】

## 一、逻辑回归原理

        逻辑回归是一种**分类模型** ，要用于解决经典**二分类**的问题

其把**线性回归的输出作为逻辑回归的输入**：

* 1.利用线性模型 f(x) = w^Tx + b 根据特征的重要性计算出一个值
* 2.再使用 sigmoid 函数将 f(x) 的输出值映射到[0,1]之间的值，也就是概率值
  + 1.设置阈值(eg：0.6)，输出概率值大于 0.6，则将未知样本输出为 1 类
  + 2.否则输出为 0 类

![](https://i-blog.csdnimg.cn/direct/022afb15cee34ac3bb910ca3a312643a.png)

## 二、signmoid函数（激活函数) (s型函数）

数学公式：

![](https://i-blog.csdnimg.cn/direct/c6924aa4a7c648e9874f2b75da635c0b.png)

图像：

![](https://i-blog.csdnimg.cn/direct/05be99d95aa64fcbb0ee01248ccf5841.png)

* x轴 特征值
* y轴 标签值
* 拐点(0,0.5)

作用：把数值映射到[0,1]

> * 用来控制逻辑输出的结果的范围是[0,1]，将值转换为[0,1]，
> * 也就是由**回归问题**转换到**分类问题**,增加了模型的**非线性因素**

## 三、逻辑回归的假设函数

                        ​​​​​​​        ​​​​​​​        ![](https://i-blog.csdnimg.cn/direct/42c48031da6e4038bc43d1b8ec647c48.png)

        ​​​​​​​        ​​​​​​​        ​​ ​ 还可以写成![](https://i-blog.csdnimg.cn/direct/bc77cc5863394daab3d71888071751b8.png)

## 四、逻辑回归的损失函数

        ​​​​​​​        ​​​​​​​    ![](https://i-blog.csdnimg.cn/direct/5eec788304ff413f86687ca161523f49.png)

## 五、逻辑回归的API

```

sklearn.linear_model.LogisticRegression(solver='liblinear', penalty=‘l2’, C = 1.0)
```

* 参数
  + solver 损失函数优化方法
    - 1 liblinear 对小数据集场景训练速度更快，sag 和 saga 对大数据集更快一些。
    - 2 正则化
      * 1 sag、saga 支持 L2 正则化或者没有正则化
      * 2 liblinear 和 saga 支持 L1 正则化
  + penalty：正则化的种类，l1 或者 l2
  + C：正则化力度
  + 损失函数 与 正则化 结合的作用：在拟合的同时 防止过拟合



