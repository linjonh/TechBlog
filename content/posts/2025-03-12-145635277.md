---
layout: post
title: "CleanGPT清晰简洁的GPT模型训练框架"
date: 2025-03-12 09:09:50 +0800
description: "CleanGPT：一个清晰简洁，具备扩展性和教育性的GPT模型工程模板"
keywords: "CleanGPT：清晰简洁的GPT模型训练框架"
categories: ['未分类']
tags: ['Gpt']
artid: "145635277"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145635277
    alt: "CleanGPT清晰简洁的GPT模型训练框架"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145635277
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145635277
cover: https://bing.ee123.net/img/rand?artid=145635277
image: https://bing.ee123.net/img/rand?artid=145635277
img: https://bing.ee123.net/img/rand?artid=145635277
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     CleanGPT：清晰简洁的GPT模型训练框架
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-github-gist" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <ul>
     <li>
      本文介绍我近期的开源项目
      <a href="https://github.com/wxc971231/CleanGPT">
       CleanGPT
      </a>
      ，这是一个基于PyTorch实现的GPT类模型训练框架。该项目试图保持清晰、简洁、扩展性和教育性，旨在为科研工作提供一个易于使用的工程模板，基于
      <a href="https://github.com/karpathy/nanoGPT">
       NanoGPT
      </a>
      扩展实现
     </li>
     <li>
      本文主要介绍该项目中使用的各种trick
     </li>
    </ul>
    <hr/>
    <p>
    </p>
    <p>
    </p>
    <h2>
     <a id="0__4">
     </a>
     0. 项目结构
    </h2>
    <ul>
     <li>
      本项目结构如下所示
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/aee45ddf64e0456192c799c9f8b666ff.png"/>
     </li>
     <li>
      项目主要文件存储于 data, train, eval 和 model 四个文件夹中，具体而言
      <ol>
       <li>
        <strong>
         data
        </strong>
        ：用于存储和数据相关的所有文件，其中
        <code>
         data/data.py
        </code>
        定义了
        <code>
         Dataset
        </code>
        ,
        <code>
         Dataloader
        </code>
        ,
        <code>
         DistributedSampler
        </code>
        等方法，用于在训练和评估过程中加载数据。每个数据集以独立文件夹形式存储和管理，其中提供了数据集和Tokenizer等相关组件的下载方法，目前提供了 shakespeare_char 和 tinystory 两个数据集
        <br/>
        <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/3d80fbf85d6a4fcb85038e57dee83d5b.png"/>
       </li>
       <li>
        <strong>
         model
        </strong>
        ：用于存储模型定义代码，目前在
        <code>
         model/NanoGPT.py
        </code>
        中实现了 NanoGPT 模型
       </li>
       <li>
        <strong>
         train
        </strong>
        ：用于存储训练相关的代码，其中
        <code>
         train/config.py
        </code>
        使用
        <code>
         argparse
        </code>
        整理了训练所需的所有参数并设置了缺省值和解释；
        <code>
         train/scheduler.py
        </code>
        实现了训练调度器，可用于动态调整 learning_rate, batch_size 和 weight_decay 系数等参数，并实现了早停方法；
        <code>
         train/train_ddp.py
        </code>
        是启动分布式数据并行训练的入口；
        <code>
         trainer.py
        </code>
        实现了完整的训练流程，包括 checkpoint &amp; snapshot 存储、wandb log 等功能
        <br/>
        <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b84012dbe92e41c1a3896e7afc2da4c9.png"/>
       </li>
       <li>
        <strong>
         eval
        </strong>
        ：用于存储模型评估相关的代码，目前在
        <code>
         eval/text_autoregress.py
        </code>
        中实现了简单的自回归生成方法
       </li>
      </ol>
     </li>
    </ul>
    <h2>
     <a id="1__14">
     </a>
     1. 特性
    </h2>
    <ul>
     <li>
      本项目具备以下特性，基本可以覆盖典型科研项目的需求
      <ol>
       <li>
        <strong>
         分布式训练
        </strong>
        ：支持基于 PyTorch DDP 的多卡训练框架（不支持其他训练方式，如 CPU 训练）
       </li>
       <li>
        <strong>
         自动混合精度
        </strong>
        ：支持基于
        <code>
         torch.cuda.amp
        </code>
        的混合精度训练（优先尝试 bf16，若不支持则使用 fp16）
       </li>
       <li>
        <strong>
         模型编译加速
        </strong>
        ：支持利用
        <code>
         torch.compile
        </code>
        对模型进行编译优化从而加速训练（要求 Pytorch 2.0 及以上版本）
       </li>
       <li>
        <strong>
         轻量数据加载
        </strong>
        ：利用
        <code>
         np.memmap
        </code>
        构造 Dataloader，不需要将全部数据加载到内存
       </li>
       <li>
        <strong>
         训练调度器
        </strong>
        ：提供了强大的训练调度器，支持 learning-rate, weight decay coefficient 和 training batch-size 的动态调度，使用早停机制避免过拟合
       </li>
       <li>
        <strong>
         断点续训
        </strong>
        ：支持从最新的 snapshot 无感恢复训练过程
       </li>
       <li>
        <strong>
         模型管理
        </strong>
        ：提供了实用的 checkpoint 保存管理机制，可根据设定自动保存最好（即验证损失最低）的n个模型权重，且可从指定 checkpoint 初始化进行微调
       </li>
       <li>
        <strong>
         Wandb Log
        </strong>
        ：支持在
        <a href="https://wandb.ai/site" rel="nofollow">
         Wandb
        </a>
        实时记录训练损失、验证损失、学习率、数据集访问比例等数据曲线
       </li>
       <li>
        <strong>
         Macro Batch
        </strong>
        ：由于 Lanuage Model 训练往往使用非常大的数集，整个训练过程可能只遍历数据集几次，甚至无法完整遍历一次，传统的 epoch 概念不再适用。本项目基于 macro-batch 概念进行训练，具体地，batch 是加载数据的最小单位，若干个 batch 组成一个 macro-batch，作为验证损失评估、snapshot &amp; checkpoint 保存的单位
       </li>
       <li>
        <strong>
         GPT2
        </strong>
        : 支持加载 HuggingFace GPT-2 checkpoints 作为初始模型进行微调
       </li>
      </ol>
     </li>
    </ul>
    <h2>
     <a id="2__27">
     </a>
     2. 实现细节
    </h2>
    <ul>
     <li>
      代码注释已经比较详细了，本节待续
     </li>
    </ul>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f:2f626c6f672e6373646e2e6e65742f7778633937313233312f:61727469636c652f64657461696c732f313435363335323737" class_="artid" style="display:none">
 </p>
</div>


