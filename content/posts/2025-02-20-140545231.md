---
layout: post
title: "揭秘开源大模型争议是真开源还是假开源"
date: 2025-02-20 14:38:16 +0800
description: "人工智能在近几年的飞速发展，不仅打破了很多传统技术和"
keywords: "盘古大模型开源了吗"
categories: ['语言模型']
tags: ['语言模型', '开源', '大模型', '人工智能', 'Ai']
artid: "140545231"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=140545231
    alt: "揭秘开源大模型争议是真开源还是假开源"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=140545231
featuredImagePreview: https://bing.ee123.net/img/rand?artid=140545231
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     揭秘开源大模型争议：是真开源还是假开源？
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="_2">
     </a>
     目录
    </h3>
    <ul>
     <li>
      <p>
       前言
      </p>
     </li>
     <li>
      <p>
       开源的定义
      </p>
     </li>
     <li>
      <p>
       什么是开源大模型？
      </p>
     </li>
     <li>
      <p>
       大模型时代首次出现闭源和开源“齐头并进”
      </p>
     </li>
     <li>
      <p>
       开源和闭源不是绝对对立的
      </p>
     </li>
     <li>
      <p>
       大模型到底开源什么？
      </p>
     </li>
     <li>
      <p>
       传统开源软件与开源大模型的差别
      </p>
     </li>
     <li>
      <p>
       开源软件让开源大模型“受益匪浅”
      </p>
     </li>
     <li>
      <p>
       不同大模型企业，开源、闭源策略不同
      </p>
     </li>
     <li>
      <p>
       开源与闭源之争下的大模型
      </p>
     </li>
     <li>
      <p>
       大模型：开源干不掉闭源
      </p>
     </li>
     <li>
      <p>
       开发者视角：大模型开源的必要性
      </p>
     </li>
     <li>
      <p>
       结束语
      </p>
     </li>
    </ul>
    <h3>
     <a id="_21">
     </a>
     前言
    </h3>
    <blockquote>
     <p>
      人工智能在近几年的飞速发展，不仅打破了很多传统技术和习惯，也让全球围绕大模型生态迎来了全新的赛道之争。尤其是从去年开始，全球互联网大厂掀起了“百模大战”，大家耳熟能详的互联网大厂如微软、谷歌、百度、阿里等接连下场，经过半年多的发力，这些科技巨头围绕着大模型生态而面临选择开源大模型还是闭源大模型。面对这个选择，在大模型生态圈掀起了一场引全球人瞩目的大模型开源之争，正所谓“内行看门道，外行看热闹”，普通开发者和用户中大部分人是赞成大模型开源的，但是作为大模型厂商更多的是关心如何确保良性的发展而是否选择开源自己的大模型。那么对于大模型是否开源这一个命题，开源大模型是真的开源么？本文就来简单聊聊，欢迎大家在评论区留言交流。
     </p>
    </blockquote>
    <h3>
     <a id="_26">
     </a>
     开源的定义
    </h3>
    <p>
     首先再来回顾一下什么是开源，开源其实是指软件或其他技术产品的源代码是开放的，可以被公众自由访问、使用、修改和分发，这种开放性的核心在于，任何人都可以查看、了解、修改并重新分发这些源代码，前提是遵循相关的开源许可协议。
    </p>
    <p>
     开源的核心理念就是鼓励协作、共享和持续改进，通过开放源代码，开发者可以共享他们的成果，同时也可以从社区中获得反馈和建议，从而不断改进和优化他们的产品，而且开源也促进了技术的快速传播和普及，使得更多的人能够受益于这些技术。关于开源许可协议，它是开源运动的重要组成部分，它们规定了源代码的使用、修改和分发规则。常见的开源许可协议包括GNU通用公共许可证（GPL）、BSD许可证、Apache许可证等，这些许可协议通常要求保留原始作者的版权信息，并允许用户以开源的方式分发修改后的代码。
    </p>
    <p>
     所以说开源是一种基于开放、共享和协作的软件开发模式，它鼓励人们共同参与到软件的开发和改进中来，推动技术的持续进步和普及。
    </p>
    <h3>
     <a id="_35">
     </a>
     什么是开源大模型？
    </h3>
    <p>
     上面关于开源的介绍之后，再来看开源大模型就容易理解了。开源起源于软件开发领域，全称就是“开放源代码”，但是在当前的“百模大战”中，出现了大模型的开源、闭源之争，就引出来了开源大模型。开源大模型，其实就是大模型厂商公开自己模型的源代码和训练数据，任何人都能查看、使用。
    </p>
    <p>
     但是，根据目前已有的开源大模型，都不是真正的开源大模型，有的可能只是开放了源代码，但没有公开训练数据，与真正的开源还是有很大的差距的。在继续下文之前，为了保证阅读体验流畅，我们暂且依习惯将这些开源大模型笼统地称作开源大模型；同时，为方便对比，下文中所有的“软件”特指传统意义上的软件，不包括大模型。
    </p>
    <h3>
     <a id="_42">
     </a>
     大模型时代首次出现闭源和开源“齐头并进”
    </h3>
    <p>
     为什么说大模型时代首次出现闭源和开源“齐头并进”，那是因为比如像MySQL、Linux、云架构等开源技术，在历史上都一定滞后于当时最先进的技术，但是大模型则是首次出现闭源和开源齐头并进的状态。
    </p>
    <p>
     出现上述情况的原因在于，关于开源技术，需要感兴趣的开发者能在一起能够有效地去协作，这需要一些基础条件加持，比如高速网络、开源平台等。因为在 Linux 刚开始发展的那个时代，这些条件都不健全（比如能访问到 Linux 代码的人很少、没有好的管理工具等），而且那时候的开源技术只属于少部分极客。但是在现在，网络、开源平台和各类管理工具都已经发展得很完备，所以当下的开源时代，更多人是可以参与建设的，甚至是普通人，也就是现在说的“人人都可参与开源”。
    </p>
    <h3>
     <a id="_49">
     </a>
     开源和闭源不是绝对对立的
    </h3>
    <p>
     作为普通开发者和创业者来讲，如果对开源不太熟悉，可能觉得开源就是免费，开源和闭源是二者不能共存的关系，也并不是现在有些声音说的：开源一定会赢、或者闭源一定赢的问题。个人觉得开源、闭源都是可以互相转化的，而且转化的维度很宽泛，二者结合很紧密，它们不是对立关系，更多的是相互依存的关系。
    </p>
    <p>
     下面我会详细提到不同大模型企业，开源、闭源策略不同。比如 OpenAI 最早也是做开源的，比如发了 whisper 这些开源的模型，只是后来他选择了把大模型闭源。又比如，Meta 也做了很多开源的工作，但其内部也有大模型是不开源的。
    </p>
    <p>
     就像上面所说的开源和闭源是相互依存的关系，开源大模型和闭源大模型也可以互相转化的，比如有一个开源模型，一家企业用自己的语料去微调它，在这个基础之上再做一些优化，最终形成的这个模型是闭源的，可能产生商业价值，而且这“最后一公里”（优化）是收费的，但它仍然算闭源。
    </p>
    <h3>
     <a id="_58">
     </a>
     大模型到底开源什么？
    </h3>
    <p>
     了解大模型的应该都知道，大模型是基于深度学习技术，通过海量数据进行训练而来的深度学习模型，大模型能够基于自然语言来实现文本的生成和理解，根据输入的数据得到输出，从而完成多类型的通用任务。在大模型的运转方面，主要就是训练和推理两个过程，训练过程就是大模型产生的过程，训练过程的基本原理是在深度学习框架上运行特定的模型架构，然后把训练数据集输入给架构，再通过复杂的计算和多次迭代，最后得到一套想要的权重，而这套权重就是训练后的结果，也叫预训练模型。预训练模型在经过部署之后，以及在得到深度学习框架的支持之下，根据给定的输入内容得到对应的输出结果，这一套流程就是推理过程。
    </p>
    <p>
     但是需要说的是，在大模型训练和推理过程中，往往所需要的算力和资源的差异很大。在训练过程中，需要很多次的迭代计算，且需要具备海量GPU算力做支持，这样才能在合理的时间范围内完成一次完整的训练过程。另外，在推理过程中，需要的算力资源却相对较小，因为推理的时候在消费型GPU以及普通的GPU上就可以完成一次一般类型的推理。
    </p>
    <p>
     根据目前情况来看，市面上绝大多数开源大模型开放出来的只是一套权重，也就是预训练模型，如果开发者想要复现该开源大模型的训练过程，需要通过优化数据集、方法等训练出一个更优质的模型，而且需要数据集、训练过程和源代码，但是是大部分开源大模型在开源的时候并未提供上面所需要的这些内容，就算开发者掌握算力也无法复现。拿市面上这些开源大模型类比传统软件，那么这些大模型更像是一个开放了的二进制包（如.exe文件），只是闭源、免费开放使用的，它其实是一个“免费软件” 而不是一个“开源软件”。
    </p>
    <p>
     其实大语言模型的所谓开源，实际上是有三个对象，源码只是其中之一，大家都知道人工智能三要素：算法、算力和数据，但是到了力大飞砖的大语言模型时代，这三要素就成了算法、高算力和大数据。所以说只有同时满足这三大要素，我们才有可能最终得到一款和ChatGPT类似效果拔群的模型。那么源码在哪呢？就在算法，算法的核心部分主要包括有模型结构和训练方法，这两部分都有对应的源码。一款人工智能产品，尤其是大型人工智能产品，还会有许多工程问题需要解决，除了核心还需要其它配套部件。拿到源码之后，真正的挑战才刚开始，接下来才是这个世界绝大多数人、研究机构和企业注定无法迈过的门槛：高算力和大数据。高算力已经说了很多了，门槛很高，但从全世界范围来说，总归有一些企业挤挤还是有的，但是大数据就未必了。因为数据非常重要，无论是人工智能时代，还是人工智障时代，扩大数据的规模、提高数据的质量，通常都能显著提高模型的最终表现，所以说技术领先优势可以追赶，数据领先优势则就未必了。
    </p>
    <p>
     那么，现在很多研究者在呼吁的开源，到底是要开源什么呢？开源模型，具体来说，是开源训练好的模型参数。模型参数拿到手，基本上就能完整复现能力了。当然，这还是对于大企业、大机构来说，运行大语言模型虽然消耗的算力远不如训练，但也不是单卡就能负担的。
    </p>
    <h3>
     <a id="_71">
     </a>
     传统开源软件与开源大模型的差别
    </h3>
    <p>
     上文也介绍到开源大模型的概念，其实大模型的开源和传统软件开源是完全不同的逻辑，开源软件因为代码完全公开，社区开发者可以参与迭代，不断提升软件能力。但开源模型像一个“黑箱”，不管是模型、算法还是数据，都无人知晓，只是最终产生一个模型开放给用户使用。开发者参与对大模型迭代帮助不大，开源大模型和开源软件是两回事，所以大部分人都是被传统的开源软件思维所误导，也正是这个原因才造成一部分人盲目的呼吁大模型厂商开源自己的大模型。
    </p>
    <p>
     其实，开源大模型和传统开源软件在多个方面存在显著的区别，以下是它们之间的主要区别：
    </p>
    <h5>
     <a id="1_78">
     </a>
     1、定义与特性
    </h5>
    <ul>
     <li>
      开源大模型：是指基于开源技术和大规模数据集构建的人工智能模型，它强调开放性和可扩展性，利用大量的开源工具和资源，比如开源的深度学习框架、数据集和算法等，开源大模型还需要借助云计算和大数据等技术进行大规模的模型训练和优化。
     </li>
     <li>
      传统开源软件：其源代码完全公开，允许用户自由使用、修改和分发，它的核心特点包括低成本、可协作性、透明度、灵活性和可持续性。
     </li>
    </ul>
    <h5>
     <a id="2_83">
     </a>
     2、应用领域
    </h5>
    <ul>
     <li>
      开源大模型：主要应用于人工智能领域，比如自然语言处理、图像识别、语音处理等，并取得了显著的成果。（如，GPT-3、BERT、ResNet等都是开源大模型的代表。）
     </li>
     <li>
      传统开源软件：应用于各种软件领域，包括操作系统、办公软件、开发工具等，为各种计算需求提供支持。
     </li>
    </ul>
    <h5>
     <a id="3_88">
     </a>
     3、社区与协作
    </h5>
    <ul>
     <li>
      开源大模型：其协同共建更多体现在社区繁荣，大家一起对模型进行优化、数据做丰富、工具做完善、应用做全面，开源社区可以汇聚广大科技企业、研究机构和开发者，共同推动模型技术和配套数据集、应用工具等的发展。
     </li>
     <li>
      传统开源软件：其社区通常关注软件的维护、更新和功能的迭代，通过全球开发者社区的共同努力，加速软件的迭代和改进。
     </li>
    </ul>
    <h5>
     <a id="4_93">
     </a>
     4、具体实例
    </h5>
    <ul>
     <li>
      开源大模型：GPT-3作为自然语言处理领域的代表，具有1750亿个参数，能够生成高质量的文本、回答问题、实现翻译等多种任务。
     </li>
     <li>
      传统开源软件：如Linux操作系统，作为全球最大的开源项目之一，其成功证明了开源模式在软件领域的强大影响力。
     </li>
    </ul>
    <p>
     所以说开源大模型和传统开源软件在定义、特性、应用领域、社区与协作以及具体实例等方面存在明显的区别。开源大模型更加注重在人工智能领域的开放性和协作性，而传统开源软件则更广泛地应用于各种软件领域，并通过所有开发者社区的共同努力推动软件技术的创新和发展。
    </p>
    <h3>
     <a id="_100">
     </a>
     开源软件让开源大模型“受益匪浅”
    </h3>
    <p>
     在数字化时代的浪潮中，开源软件以其独特的魅力，为开源大模型的发展注入了源源不断的活力，而且开源大模型作为人工智能领域的重要分支，正在以前所未有的速度向前发展，而这一切都离不开开源软件的影响，得益于开源软件的土壤。在上文中提到大模型的训练需要硬件、软件、数据三大要素的支撑，也就是GPU算力、深度学习框架和大规模数据集，但是当前主流的深度学习框架作为软件模块基本都是开源的，比如谷歌开源的Tensorflow、百度开源的PaddlePaddle等，而且这两个主流深度学习框架都采用了OSI认证的开源许可证，可谓是名副其实的开源。
    </p>
    <p>
     个人觉得，在基础软件平台较为统一且开源免费，这让大模型在有限开源的情况下依然可以被低成本、低门槛的开发和使用，另外一个原因就是得益于开源深度学习框架以及相关开源工具链的生态完整性，大模型创业才成为可能。
    </p>
    <p>
     其实深度学习框架的开源，会形成广泛的开发者协作贡献，从而形成良性且蓬勃的生态，这也让底层芯片厂商愿意提供强有力的支持，比如作为GPU芯片巨头的英伟达，就会不遗余力的支持 Tensorflow、PaddlePaddle 等主流开源深度学习框架，这也让开发者去开发大模型的门槛降低。那么从这个角度来看，谷歌、百度等厂商早期的对基础平台的开源和持续贡献，奠定了如今开源大模型的生长的基石。
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/baf1d2f961912a8e5a88086eec08fc71.png"/>
    </p>
    <h3>
     <a id="_111">
     </a>
     不同大模型企业，开源、闭源策略不同
    </h3>
    <p>
     根据目前全球大模型生态现状，结合市面上已有的大模型来看，可以看出来不同的大模型企业，开源、闭源的策略不尽相同。大致分为四种策略：
    </p>
    <p>
     第一，从开源走向闭源，最典型的代表为OpenAI。2018年其发布的GPT-1完全对外开源；2019年发布GPT-2，分四次开源完整代码；2020年发布GPT-3，通过论文公开了技术细节，同时用户可通过调用API的方式使用模型资源，属于部分开源；2022年11月推出GPT-3.5，官方没有发布论文披露细节，2023年3月开放API；同年3月的GPT-4，也仅处于开放API状态，技术细节不得而知。就在5月13日，OpenAI在万众期待中推出了名为GPT-4o的新一代旗舰AI模型，新的GPT-4o号称是OpenAI“有史以来最好的模型”。
    </p>
    <p>
     第二，坚持开源，最典型的代表是Meta。2023年3月，Meta发布开源大模型LLaMA，可免费用于研究，研究人员向Meta提出申请和审核后即可使用；2023年7月，Meta发布LLaMA 2，公开了技术论文和源代码，可免费用于研究和商业；2024年4月Meta开源了Llama 3。
    </p>
    <p>
     第三，坚持闭源，最典型的代表是华为。在发布盘古大模型3.0时，华为云公开表示，盘古大模型全栈技术均是由华为自主创新的，没有采用任何开源技术，盘古大模型在未来也不会开源。
    </p>
    <p>
     第四，从闭源走向开源、闭源并行，最典型代表为智谱。根据智谱AI的官网，GLM2不限实例+不限推理或微调工具包的私有化报价此前是一年30万。2023年7月，智谱AI和清华KEG发布公告，称为了更好地支持国产大模型开源生态，ChatGLM-6B和ChatGLM2-6B权重对学术研究完全开放，并且在完成企业登记获得授权后，允许免费商业使用，与此同时，ChatGLM2-12B、ChatGLM2-32B、ChatGLM2-66B、ChatGLM2-130B 等模型仍为闭源。
    </p>
    <p>
     所以说，大模型是否开源的策略，是根据大模型厂商自己的特色道路来决定的，而且这些策略会根据大模型厂商的自身调整而改变，不是一成不变的。
    </p>
    <h3>
     <a id="_126">
     </a>
     开源与闭源之争下的大模型
    </h3>
    <p>
     最近关于开源和闭源的选择是大模型领域的热点话题，比如OpenAI的GPT-4模型就是采用闭源模式，微软则开源了WizardLM-2。在国内，阿里的通义千问开源，而华为盘古大模型则坚定选择不开源。在模式之争的背后，个人觉得是关于如何平衡技术创新、商业利益、社区参与和市场竞争力的讨论。
    </p>
    <p>
     作为大模型市场上的一员，大模型厂商都会选择最适合自己的发展模式和路线，比如OpenAI、百度选择了闭源路线，而Meta、阿里云选择了开源的路线。但是，从目前的情况来看，闭源大模型在性能、效果等方面仍远远优于开源大模型，而且闭源大模型厂商在快速丰富自己的产品和服务形态，比如百度不仅拥有文心一言对话式AI应用，而且还推出了千帆大模型平台、ModelBuiler、Appbuilder、Agent Builder 等产品和服务，全面覆盖了个人用户、企业级客户、开发者等用户群，个人觉得这是非常不错的策略。另外，OpenAI也在通过GPTs等方式展开一些新的尝试，也是比较良性的模式。而且开源不仅是开放源代码这么简单，它还得满足一些条件，比如允许大家自由地用、改和分享这个软件，甚至基于它创造新的东西。但是，开源软件也不是啥都不管，它得在某种开源许可证下发布，比如我们常听到的GPL、Apache、BSD和MIT这些许可证。
    </p>
    <p>
     所以说来到大模型时代，开源变了么？大模型的技术浪潮，某种程度上也是由开源开启，谷歌开源了Transformer，才有了后来OpenAI引爆行业的ChatGPT。当OpenAI不再Open，谷歌也不再那么Open，大模型的开源大旗，反而被Meta以其Llama系列模型扛起，马斯克开源了Grok模型，位于法国巴黎的Mistral AI，成为另外两股最被关注的大模型开源力量。值得思考的是Llama2在刚刚发布后不久，就有人批评说Llama2并不符合开源促进会（OSI）设定的定义，Llama2的许可证包含了一定的限制，比如禁止使用Llama2去训练其它语言模型，如果该模型用于每月用户超过7亿的应用程序和服务，则需要获得Meta的特殊许可证。
    </p>
    <p>
     开源大模型并不等同于开源软件，它无法充分实现多元化的协作开发模式，所以大模型开源更关乎商业策略，而不是生成方式或技术水平。大模型开源的方式和传统软件开源的方式不太相同，单单从最具代表性的Llama系列模型和Mistral系列模型，它们的开源方式就不太相同，它们的区别主要在于Restrict License（限制许可）VS Apache。Llama的开源属于前者，从前面描述的Llama2的限制方式可以看出，这种开源方式是指在开放源代码的同时，对使用、修改和分发该模型的行为施加一定的限制。除了开源方式的不同，训练一个大模型通常需要大量的数据、计算资源和专业知识来进行训练和优化，这些资源往往只有大型科技公司或研究机构才能提供。所以大模型时代的开源主体，往往是大型科技公司，或者资源优势强的创业公司，而不是个体；这也造成了，开源虽然可能吸引更广泛的社区参与，但由于技术门槛和资源需求，实际贡献可能集中在有限的专家群体中；某些大公司的开源，还有着占据竞争生态位的考量，所以对于开源条款的设计，也会有更加复杂的考虑。
    </p>
    <p>
     个人觉得作为广大的技术开发者、使用者和创业者，我们更应该考去虑如何选择一个最合适自己实际需要的大模型平台，然后专注于应用开发，而不是去关注某一个大模型是否开源，所以说大模型开不开源不重要，也无需“道德绑架”式的要求所有大模型都开源，我们更应该关注哪个大模型更好用，更符合我们自身的实际需要。
    </p>
    <h3>
     <a id="_139">
     </a>
     大模型：开源干不掉闭源
    </h3>
    <p>
     随着一小部分大模型厂商宣布“部分”开源自己的大模型，导致开源大模型对闭源大模型的冲击变得非常猛烈。比如在去年3月的时候Meta发布了Llama（羊驼），很快成为AI社区内最强大的开源大模型，也是许多模型的基座模型，当时就有人戏称，当前的大模型集群，就是一堆各种花色的“羊驼”。其实各个互联网、科技公司都在竞相训练、推出自己的大模型，投入了大量的计算资源和成本，如果不能有效的完成商业化，那么这些大模型就很难回收成本，在后续的迭代、更新、升级都成问题，不仅研发企业会亏个底掉，更苦恼的大概就是“前功尽弃”的用户了。
    </p>
    <p>
     现在有个比较流行的说法有了自由开放强大的开源大模型，谁还愿意给闭源大模型送钱？答案还别说，还真的有送钱的主儿。虽然说开源是未来的方向，但闭源大模型依然有其存在意义和商业价值，按照目前的AI产业落地经验来看，用好大模型，还是得靠闭源。“到产业去，到产业去”，大模型的商业化终点是产业，见一斑可窥全豹，至少在短期内，大模型走向产业，落地还是要靠闭源的。还有就是大模型方面，闭源大模型的质量更高。比如Meta 将 Llama 2的结果，与闭源模型进行了比较，结果在 MMLU 和 GSM8K 上接近 GPT-3.5，但在编码基准上，还存在显著差距，不少数据在多样性和质量方面有所欠缺。
    </p>
    <p>
     虽然开源大模型的优化迭代速度很快，但开源的本质和“有性繁殖”很像，就是通过大量繁殖和变异，如同开篇那张“羊驼集群”一样，面对不确定的未来，借助进化的“优胜劣汰”，让最优质的后代持续涌现，所以说开源软件的分支多，对用户来说这个选择的成本是很高的，加上开发人员众多，版本控制是一个问题。
    </p>
    <p>
     还有在产业化方面，闭源大模型的长期服务能力更强、更可用。我觉得大模型落地，并不是接入API、塞进数据、调参优化就结束了，但是作为一种新兴技术，大模型与业务场景的融合，还有非常多挑战，比如大模型需要通过蒸馏压缩，减小模型规模，才能在端侧部署，很多企业根本没有这类专业人才。再比如数据隐私顾虑，大模型是不能直接为产业所用的，还要通过专有场景数据进行优化，而这些数据训练完的模型会被开源开放出去，让企业顾虑重重。另外，开源大模型需要平衡技术创新自由和版权收益之间的冲突，而使用闭源大模型就没有这方面的麻烦，数据和模型的所有权、使用权都很清晰，牢牢掌握在企业自己手里。
    </p>
    <p>
     目前开源大模型还无法达到实际的业务需求，而开源大模型使用者和ISV集成商，是需要获得商业回报的，如果开源大模型不可商用、效果不好、很难赚钱，那么即使免费，企业也会慎重考虑要不要投入人来开发，所以未来一段时间，闭源依然是大模型落地产业的热门选择。可能有人不理解了，开源免费商用，大家都能用上白菜价的大模型了，对开发者和企业用户多友好，怎么还说闭源好？但凡了解开源，都会支持开源，但凡支持开源，都会关注开源的商业化。开源以理想主义为源起，以商业化为蓬勃助力，是开放创新的典范，没有商业化，不可能有开源。所以，开源也好，闭源也好，谁能更早“可商用”，谁就更有未来，闭源大模型可能更占优势，毕竟有底气闭源的厂商都是有自己的优势所在的。
    </p>
    <h3>
     <a id="_152">
     </a>
     开发者视角：大模型开源的必要性
    </h3>
    <p>
     就像上面关于大模型开源、闭源之争所说的那样，我个人觉得大模型开源的必要性对于我们广大开发者和创业者来说不太重要，因为我们往往更在乎的是哪个大模型更好用，更符合我们自身的实际需要。但是真要我说几个大模型闭源的优点，那我从4个层面来简单分享一下。
    </p>
    <h5>
     <a id="1_157">
     </a>
     1、商业模式考虑
    </h5>
    <ul>
     <li>
      闭源模型在能力上会持续地领先，而不是一时地领先，而且闭源模型能更好地保护大模型厂商自身的商业利益和技术优势，为大模型的商业应用提供更好的保障。
     </li>
     <li>
      开源模型虽然能推动技术共享和协作，但开源本身并不是一种商业模式，而是一种软件的开发、发布和传播模式，而大模型厂商更看重的是通过闭源模型实现商业化和盈利。
     </li>
    </ul>
    <h5>
     <a id="2_162">
     </a>
     2、性能与安全性
    </h5>
    <ul>
     <li>
      闭源模型在性能上会优于开源模型，比如百度的大模型文心一言在处理文本的能力上已经达到很高的水平，日均处理Tokens文本达2490亿，显示出闭源模型在性能上的优势。
     </li>
     <li>
      开源模型在安全性上可能存在风险，比如开源模型可能接受到垃圾代码和低质数据，导致性能下降，而且开源模型还可能面临被恶意利用的风险，如插入后门触发机制的恶意行为。而百度的大模型通过闭源来保护模型的机密性和专利性，避免被竞争对手或恶意者利用。
     </li>
    </ul>
    <h5>
     <a id="3_167">
     </a>
     3、技术与质量控制
    </h5>
    <ul>
     <li>
      闭源模式可以确保大模型厂商对模型技术和质量的严格控制，比如百度可以自主决定模型的更新、优化和发布，从而确保模型的质量和稳定性。
     </li>
     <li>
      开源模式可能会导致技术路线的分散和混乱，使得模型的标准化和一致性难以保证。而选择闭源可以更好地掌控技术路线和模型质量。
     </li>
    </ul>
    <h5>
     <a id="4_172">
     </a>
     4、市场趋势与主流方向
    </h5>
    <ul>
     <li>
      其实“闭源大模型+公有云”已成为全球AI市场的主流趋势，这种趋势能够实现比开源大模型性能更好、成本更低的综合效果，并促进AI应用生态的繁荣。所以说选择闭源也是为了顺应这一市场趋势和主流方向。
     </li>
    </ul>
    <p>
     通过上面这四个方面的分析，想必大家都知道一些大模型厂商选择闭源大模型，主要是出于商业模式、性能与安全性、技术与质量控制以及市场趋势等多方面的考虑。闭源模式能够更好地保护大模型厂商的商业利益和技术优势，确保模型的性能和安全性，并顺应市场趋势和主流方向。
    </p>
    <h3>
     <a id="AI_179">
     </a>
     如何学习AI大模型？
    </h3>
    <p>
     我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。
    </p>
    <p>
     我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/26837cac94c3b677bad169b26a9e1e46.png"/>
    </p>
    <p>
     第一阶段： 从大模型系统设计入手，讲解大模型的主要方法；
    </p>
    <p>
     第二阶段： 在通过大模型提示词工程从Prompts角度入手更好发挥模型的作用；
    </p>
    <p>
     第三阶段： 大模型平台应用开发借助阿里云PAI平台构建电商领域虚拟试衣系统；
    </p>
    <p>
     第四阶段： 大模型知识库应用开发以LangChain框架为例，构建物流行业咨询智能问答系统；
    </p>
    <p>
     第五阶段： 大模型微调开发借助以大健康、新零售、新媒体领域构建适合当前领域大模型；
    </p>
    <p>
     第六阶段： 以SD多模态大模型为主，搭建了文生图小程序案例；
    </p>
    <p>
     第七阶段： 以大模型平台应用与开发为主，通过星火大模型，文心大模型等成熟大模型构建大模型行业应用。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/542f58910ba9a5939dc266222e08e2ce.jpeg#pic_center"/>
    </p>
    <p>
     👉学会后的收获：👈
     <br/>
     • 基于大模型全栈工程实现（前端、后端、产品经理、设计、数据分析等），通过这门课可获得不同能力；
    </p>
    <p>
     • 能够利用大模型解决相关实际项目需求： 大数据时代，越来越多的企业和机构需要处理海量数据，利用大模型技术可以更好地处理这些数据，提高数据分析和决策的准确性。因此，掌握大模型应用开发技能，可以让程序员更好地应对实际项目需求；
    </p>
    <p>
     • 基于大模型和企业数据AI应用开发，实现大模型理论、掌握GPU算力、硬件、LangChain开发框架和项目实战技能， 学会Fine-tuning垂直训练大模型（数据准备、数据蒸馏、大模型部署）一站式掌握；
    </p>
    <p>
     • 能够完成时下热门大模型垂直领域模型训练能力，提高程序员的编码能力： 大模型应用开发需要掌握机器学习算法、深度学习框架等技术，这些技术的掌握可以提高程序员的编码能力和分析能力，让程序员更加熟练地编写高质量的代码。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/c400d99382638099028a1e0493884952.jpeg#pic_center"/>
    </p>
    <blockquote>
     <p>
      <em>
       <strong>
        1.AI大模型学习路线图
        <br/>
        2.100套AI大模型商业化落地方案
        <br/>
        3.100集大模型视频教程
        <br/>
        4.200本大模型PDF书籍
        <br/>
        5.LLM面试题合集
        <br/>
        6.AI产品经理资源合集
       </strong>
      </em>
     </p>
    </blockquote>
    <p>
     👉获取方式：
     <br/>
     😝有需要的小伙伴，可以保存图片到wx扫描二v码免费领取【保证100%免费】🆓
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/3c3a284aea75af128b0d778ce659e582.jpeg#pic_center"/>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f323430315f38343439353837322f:61727469636c652f64657461696c732f313430353435323331" class_="artid" style="display:none">
 </p>
</div>


