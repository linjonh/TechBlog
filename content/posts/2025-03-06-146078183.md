---
layout: post
title: "漫话机器学习系列121.偏导数Partial-Derivative"
date: 2025-03-06 19:38:38 +0800
description: "在数学分析、机器学习、物理学和工程学中，我们经常会遇到多个变量的函数。这些函数的输出不仅取决于一个变量，而是由多个变量共同决定的。那么，当其中某一个变量发生变化时，函数的输出如何变化呢？这就涉及到了偏导数（Partial Derivative）的概念。"
keywords: "【漫话机器学习系列】121.偏导数（Partial Derivative）"
categories: ['漫话机器学习系列专辑']
tags: ['算法', '机器学习', '人工智能']
artid: "146078183"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146078183
    alt: "漫话机器学习系列121.偏导数Partial-Derivative"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146078183
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146078183
cover: https://bing.ee123.net/img/rand?artid=146078183
image: https://bing.ee123.net/img/rand?artid=146078183
img: https://bing.ee123.net/img/rand?artid=146078183
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     【漫话机器学习系列】121.偏导数（Partial Derivative）
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p style="text-align:center">
     <img alt="" src="https://i-blog.csdnimg.cn/direct/d6ecf007920a49b78b21f26636ca40c0.png"/>
    </p>
    <h2>
     <strong>
      偏导数（Partial Derivative）详解
     </strong>
    </h2>
    <h3>
     <strong>
      1. 引言
     </strong>
    </h3>
    <p>
     在数学分析、机器学习、物理学和工程学中，我们经常会遇到多个变量的函数。这些函数的输出不仅取决于一个变量，而是由多个变量共同决定的。那么，当其中
     <strong>
      某一个变量发生变化
     </strong>
     时，函数的输出如何变化呢？这就涉及到了
     <strong>
      偏导数（Partial Derivative）
     </strong>
     的概念。
    </p>
    <p>
     偏导数是多变量微积分的重要工具，它描述了一个多变量函数对其中某一个变量的变化率。在最优化问题、梯度计算、物理模拟等多个领域，偏导数都扮演着关键角色。
    </p>
    <p>
     本文将详细介绍：
    </p>
    <ul>
     <li>
      偏导数的定义
     </li>
     <li>
      计算方法
     </li>
     <li>
      几何意义
     </li>
     <li>
      在机器学习等领域的应用
     </li>
    </ul>
    <hr/>
    <h3>
     <strong>
      2. 偏导数的定义
     </strong>
    </h3>
    <p>
     设
     <img alt="f(x_1, x_2, ..., x_n)" class="mathcode" src="https://latex.csdn.net/eq?f%28x_1%2C%20x_2%2C%20...%2C%20x_n%29">
      是一个由多个变量
      <img alt="x_1, x_2, ..., x_n" class="mathcode" src="https://latex.csdn.net/eq?x_1%2C%20x_2%2C%20...%2C%20x_n">
       ​ 组成的函数，我们希望研究函数在某个变量 xix_ixi​ 上的变化趋势，而
       <strong>
        保持其他变量不变
       </strong>
       ，则偏导数的定义如下：
      </img>
     </img>
    </p>
    <p style="text-align:center">
     <img alt="\frac{\partial f}{\partial x_i} = \lim_{\Delta x_i \to 0} \frac{f(x_1, ..., x_i + \Delta x_i, ..., x_n) - f(x_1, ..., x_i, ..., x_n)}{\Delta x_i}" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20x_i%7D%20%3D%20%5Clim_%7B%5CDelta%20x_i%20%5Cto%200%7D%20%5Cfrac%7Bf%28x_1%2C%20...%2C%20x_i%20&amp;plus;%20%5CDelta%20x_i%2C%20...%2C%20x_n%29%20-%20f%28x_1%2C%20...%2C%20x_i%2C%20...%2C%20x_n%29%7D%7B%5CDelta%20x_i%7D"/>
    </p>
    <p>
     其中：
    </p>
    <ul>
     <li>
      <img alt="\frac{\partial}{\partial x_i}" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20x_i%7D">
       ​ 表示
       <strong>
        对
        <img alt="x_i" class="mathcode" src="https://latex.csdn.net/eq?x_i">
         进行偏导
        </img>
       </strong>
       ，即计算函数在该变量上的变化率。
      </img>
     </li>
     <li>
      其他变量
      <img alt="x_1, ..., x_{i-1}, x_{i+1}, ..., x_n" class="mathcode" src="https://latex.csdn.net/eq?x_1%2C%20...%2C%20x_%7Bi-1%7D%2C%20x_%7Bi&amp;plus;1%7D%2C%20...%2C%20x_n">
       ​
       <strong>
        保持不变
       </strong>
       。
      </img>
     </li>
     <li>
      这个极限表示当
      <img alt="x_i" class="mathcode" src="https://latex.csdn.net/eq?x_i">
       ​ 发生微小变化时，函数 f 的变化速率。
      </img>
     </li>
    </ul>
    <h4>
     <strong>
      2.1. 与普通导数的区别
     </strong>
    </h4>
    <p>
     普通导数（单变量函数的导数）是研究
     <strong>
      一个变量的函数
     </strong>
     y = f(x) 随着 x 变化的变化率：
    </p>
    <p style="text-align:center">
     <img alt="f'(x) = \lim_{\Delta x \to 0} \frac{f(x+\Delta x) - f(x)}{\Delta x}" class="mathcode" src="https://latex.csdn.net/eq?f%27%28x%29%20%3D%20%5Clim_%7B%5CDelta%20x%20%5Cto%200%7D%20%5Cfrac%7Bf%28x&amp;plus;%5CDelta%20x%29%20-%20f%28x%29%7D%7B%5CDelta%20x%7D"/>
    </p>
    <p>
     而
     <strong>
      偏导数
     </strong>
     适用于
     <strong>
      多个变量的函数
     </strong>
     ，它只关注
     <strong>
      某一个变量的变化率
     </strong>
     ，其他变量保持不变。
    </p>
    <hr/>
    <h3>
     <strong>
      3. 偏导数的计算方法
     </strong>
    </h3>
    <h4>
     <strong>
      3.1. 基本计算规则
     </strong>
    </h4>
    <p>
     计算偏导数时，我们假设所有变量
     <strong>
      除了要求偏导的变量外
     </strong>
     都是常数，然后按照普通导数的方法求导。
    </p>
    <h5>
     <strong>
      示例 1：二元函数
     </strong>
    </h5>
    <p>
     给定函数：
    </p>
    <p style="text-align:center">
     <img alt="f(x, y) = x^2 + 3xy + y^2" class="mathcode" src="https://latex.csdn.net/eq?f%28x%2C%20y%29%20%3D%20x%5E2%20&amp;plus;%203xy%20&amp;plus;%20y%5E2"/>
    </p>
    <p>
     求 fff 对 x 和 y 的偏导数。
    </p>
    <p>
     <strong>
      （1）对 x 求偏导
     </strong>
    </p>
    <p style="text-align:center">
     <img alt="\frac{\partial f}{\partial x} = \frac{\partial}{\partial x} (x^2 + 3xy + y^2)" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20x%7D%20%3D%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20x%7D%20%28x%5E2%20&amp;plus;%203xy%20&amp;plus;%20y%5E2%29"/>
    </p>
    <ul>
     <li>
      <img alt="x^2" class="mathcode" src="https://latex.csdn.net/eq?x%5E2"/>
      对 x 的导数是 2x。
     </li>
     <li>
      3xy 对 x 的导数是 3y（因为 y 被视为常数）。
     </li>
     <li>
      <img alt="y^2" class="mathcode" src="https://latex.csdn.net/eq?y%5E2"/>
      对 x 的导数是 0（因为它不含 x）。
     </li>
    </ul>
    <p>
     所以：
    </p>
    <p style="text-align:center">
     <img alt="\frac{\partial f}{\partial x} = 2x + 3y" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20x%7D%20%3D%202x%20&amp;plus;%203y"/>
    </p>
    <p>
     <strong>
      （2）对 y 求偏导
     </strong>
    </p>
    <p style="text-align:center">
     <img alt="\frac{\partial f}{\partial y} = \frac{\partial}{\partial y} (x^2 + 3xy + y^2)" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20y%7D%20%3D%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20y%7D%20%28x%5E2%20&amp;plus;%203xy%20&amp;plus;%20y%5E2%29"/>
    </p>
    <ul>
     <li>
      <img alt="x^2" class="mathcode" src="https://latex.csdn.net/eq?x%5E2"/>
      对 y 的导数是 0（因为它不含 y）。
     </li>
     <li>
      3xy 对 y 的导数是 3x（因为 x 被视为常数）。
     </li>
     <li>
      <img alt="y^2" class="mathcode" src="https://latex.csdn.net/eq?y%5E2"/>
      对 y 的导数是 2y。
     </li>
    </ul>
    <p>
     所以：
    </p>
    <p style="text-align:center">
     <img alt="\frac{\partial f}{\partial y} = 3x + 2y" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20y%7D%20%3D%203x%20&amp;plus;%202y"/>
    </p>
    <hr/>
    <h4>
     <strong>
      3.2. 高阶偏导数
     </strong>
    </h4>
    <p>
     偏导数可以继续求导，形成
     <strong>
      二阶偏导数
     </strong>
     ，甚至更高阶的偏导数。二阶偏导数有两种情况：
    </p>
    <ol>
     <li>
      <strong>
       同一个变量求两次导数
      </strong>
      （纯二阶偏导）：
      <img alt="\frac{\partial^2 f}{\partial x^2}" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%5E2%20f%7D%7B%5Cpartial%20x%5E2%7D"/>
     </li>
     <li>
      <strong>
       对不同变量求两次导数
      </strong>
      （混合二阶偏导）：
      <img alt="\frac{\partial^2 f}{\partial x \partial y}" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%5E2%20f%7D%7B%5Cpartial%20x%20%5Cpartial%20y%7D"/>
     </li>
    </ol>
    <h5>
     <strong>
      示例 2：求二阶偏导
     </strong>
    </h5>
    <p>
     继续对
     <strong>
      示例 1
     </strong>
     的
     <img alt="f(x, y) = x^2 + 3xy + y^2" class="mathcode" src="https://latex.csdn.net/eq?f%28x%2C%20y%29%20%3D%20x%5E2%20&amp;plus;%203xy%20&amp;plus;%20y%5E2"/>
     计算二阶偏导数：
    </p>
    <ul>
     <li>
      纯二阶偏导：
      <br/>
      <br/>
      <img alt="\frac{\partial^2 f}{\partial x^2} = \frac{\partial}{\partial x} (2x + 3y) = 2" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%5E2%20f%7D%7B%5Cpartial%20x%5E2%7D%20%3D%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20x%7D%20%282x%20&amp;plus;%203y%29%20%3D%202"/>
      <br/>
      <img alt="\frac{\partial^2 f}{\partial y^2} = \frac{\partial}{\partial y} (3x + 2y) = 2" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%5E2%20f%7D%7B%5Cpartial%20y%5E2%7D%20%3D%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20y%7D%20%283x%20&amp;plus;%202y%29%20%3D%202"/>
     </li>
     <li>
      混合二阶偏导：
      <br/>
      <br/>
      <img alt="\frac{\partial^2 f}{\partial x \partial y} = \frac{\partial}{\partial y}" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%5E2%20f%7D%7B%5Cpartial%20x%20%5Cpartial%20y%7D%20%3D%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20y%7D"/>
      <br/>
      <img alt="\frac{\partial^2 f}{\partial y \partial x} = \frac{\partial}{\partial x} (3x + 2y) = 3" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%5E2%20f%7D%7B%5Cpartial%20y%20%5Cpartial%20x%7D%20%3D%20%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20x%7D%20%283x%20&amp;plus;%202y%29%20%3D%203"/>
     </li>
    </ul>
    <hr/>
    <h3>
     <strong>
      4. 几何意义
     </strong>
    </h3>
    <p>
     偏导数的几何意义可以用
     <strong>
      曲面切线的斜率
     </strong>
     来理解：
    </p>
    <ul>
     <li>
      <strong>
       <img alt="\frac{\partial f}{\partial x}" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20x%7D"/>
      </strong>
      代表在
      <strong>
       固定 y 的情况下
      </strong>
      ，曲面沿
      <strong>
       x 轴方向
      </strong>
      的变化率。
     </li>
     <li>
      <strong>
       <img alt="\frac{\partial f}{\partial y}" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20y%7D"/>
      </strong>
      代表在
      <strong>
       固定 x 的情况下
      </strong>
      ，曲面沿
      <strong>
       y 轴方向
      </strong>
      的变化率。
     </li>
    </ul>
    <p>
     可以想象，一个多变量函数 f(x, y) 是一个三维曲面，而偏导数就是在某个方向上的斜率。
    </p>
    <hr/>
    <h3>
     <strong>
      5. 偏导数在机器学习中的应用
     </strong>
    </h3>
    <h4>
     <strong>
      5.1. 梯度下降（Gradient Descent）
     </strong>
    </h4>
    <p>
     在机器学习和深度学习中，偏导数用于计算
     <strong>
      损失函数的梯度
     </strong>
     ，指导模型参数的优化。梯度下降算法的核心思想是：
    </p>
    <p style="text-align:center">
     <img alt="\theta = \theta - \alpha \frac{\partial J}{\partial \theta}" class="mathcode" src="https://latex.csdn.net/eq?%5Ctheta%20%3D%20%5Ctheta%20-%20%5Calpha%20%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Ctheta%7D"/>
    </p>
    <p>
     其中：
    </p>
    <ul>
     <li>
      <img alt="\frac{\partial J}{\partial \theta}" class="mathcode" src="https://latex.csdn.net/eq?%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Ctheta%7D"/>
      是损失函数 J 对参数 θ 的偏导数。
     </li>
     <li>
      α 是学习率。
     </li>
    </ul>
    <h4>
     <strong>
      5.2. 计算神经网络的权重更新
     </strong>
    </h4>
    <p>
     神经网络中的
     <strong>
      反向传播（Backpropagation）
     </strong>
     算法依赖于偏导数来计算梯度，从而调整权重。
    </p>
    <hr/>
    <h3>
     <strong>
      6. 结论
     </strong>
    </h3>
    <p>
     偏导数是研究
     <strong>
      多变量函数的变化率
     </strong>
     的重要工具，它在数学、物理、工程和机器学习等领域都有广泛应用。通过计算偏导数，我们可以：
    </p>
    <ul>
     <li>
      了解函数在某个方向上的变化趋势。
     </li>
     <li>
      优化机器学习模型（如梯度下降）。
     </li>
     <li>
      分析三维曲面的形状和斜率。
     </li>
    </ul>
    <p>
     掌握偏导数是进一步学习多元微积分、优化方法和机器学习的基础！
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f:2f626c6f672e6373646e2e6e65742f49545f4f5241434c452f:61727469636c652f64657461696c732f313436303738313833" class_="artid" style="display:none">
 </p>
</div>


