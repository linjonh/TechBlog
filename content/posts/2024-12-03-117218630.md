---
arturl_encode: "68747470:733a2f2f626c6f672e6373646e2e6e65742f63706c7666782f:61727469636c652f64657461696c732f313137323138363330"
layout: post
title: "屏蔽爬虫收录的四种方法"
date: 2024-12-03 16:54:56 +08:00
description: "本文介绍了四种方法来阻止搜索引擎如百度、谷歌等爬虫抓取网站内容：1) 使用robots.txt文件；"
keywords: "禁止爬虫抓取"
categories: ['Seo']
tags: ['无标签']
artid: "117218630"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=117218630
    alt: "屏蔽爬虫收录的四种方法"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=117218630
featuredImagePreview: https://bing.ee123.net/img/rand?artid=117218630
---

# 屏蔽爬虫收录的四种方法

## 1、robots.txt屏蔽百度或某一爬虫抓取

打开robots.txt，在开头加入如下语句（以百度蜘蛛为例）：

```
User-agent: baiduspider
Disallow: /
```

代码分析，首先要知道该爬虫的名称，如百度爬虫是
**Baiduspider**
，Google爬虫是
**Googlebot**
，360搜索爬虫是
**360Spider**
，你可以通过
[各大搜索引擎蜘蛛爬虫UA汇总](http://www.webkaka.com/tutorial/zhanzhang/2017/061068/)
来获取爬虫的名称，例如，微软必应的蜘蛛UA是：

```
"Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)"
```

我们就可以知道它的爬虫名称为
**bingbot**
。

## 2、robots Meta标签屏蔽百度或某一爬虫抓取

如果是针对某一个页面屏蔽百度蜘蛛或某一爬虫抓取，那么可以通过Meta标签来实现。代码如下：

```
<head> … 
<meta name="robots" content="noindex,nofollow" /> 
</head>
```

这是屏蔽所有蜘蛛爬虫抓取该页面的写法，如果只屏蔽某个爬虫，可以把"robots"改为特定的爬虫名称，爬虫名称可以通过上面方法1中提及的办法获得。例如想只屏蔽微软必应的蜘蛛抓取该页，则可以写成：

```
<head> … 
<meta name="bingbot" content="noindex,nofollow" /> 
</head>
```

## 3、.htaccess屏蔽百度或某一爬虫抓取

一些可恶的爬虫并不遵循robots规则，那么我们还可以通过.htaccess来屏蔽它，代码如下（以百度蜘蛛为例）：

```
RewriteEngine on
RewriteCond %{HTTP_USER_AGENT} ^.*Baiduspider.* [NC]
RewriteRule .* - [F]
```

**如果是Apache服务器**
，可以修改配置文件 httpd.conf ，这样写( /var/www/html 是根目录)：

```
<Directory "/var/www/html">
...
SetEnvIfNoCase User-Agent ^.*Baiduspider.* bad_bot
Order Allow,Deny
Allow from all
Deny from env=bad_bot
...
</Directory>
```

**如果是Nginx服务器**
，可以修改配置文件( 默认是 nginx.conf )，这样写：

```
Server{
...
  location / {
    if ($http_user_agent !~ Baiduspider) {
      return 403;
    }
  }
...
}
```

## 4、通过IP屏蔽百度或某一爬虫抓取

```
我们还可以通过分析日志，获得爬虫的IP地址，然后从服务器防火墙屏蔽该IP，不过爬虫通常有很多IP，我们可以屏蔽爬虫的IP段。

不过此方法没有前面几个方法实用，较少人这样操作。
```

> ## 以上转载
>
> <http://www.webkaka.com/tutorial/zhanzhang/2017/061069/>

---

## 工具

### robots文件生成

<http://tool.chinaz.com/robots/>