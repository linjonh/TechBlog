---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f37333335393036382f:61727469636c652f64657461696c732f313436303630353038"
layout: post
title: "视频理解开山之作-双流网络"
date: 2025-03-06 10:31:10 +08:00
description: "最典型的例子是视频分类任务中的两个流，一个处理静态图像信息（通常是视频的每一帧），另一个处理动态信息（通常是光流，描述了视频帧之间的运动）。双流网络需要两个独立的网络处理不同的流，这意味着需要更多的计算资源，尤其是在处理长视频或高分辨率图像时。双流网络需要同时训练两个流，这可能会增加训练过程的复杂性，并且两个流之间的学习过程可能不完全同步，导致训练过程不稳定或收敛速度较慢。双流网络依赖于不同类型的数据（如图像和光流），如果数据不充分或质量不高，可能会导致信息缺失或冗余，影响最终的识别效果。"
keywords: "双流网络"
categories: ['基于Prompt视觉语言模型的长视频行文理解分析']
tags: ['音视频']
artid: "146060508"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146060508
    alt: "视频理解开山之作-双流网络"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146060508
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146060508
cover: https://bing.ee123.net/img/rand?artid=146060508
image: https://bing.ee123.net/img/rand?artid=146060508
img: https://bing.ee123.net/img/rand?artid=146060508
---

# 视频理解开山之作 “双流网络”

## 1 论文核心信息

### 1.1核心问题

* **任务**
  ：如何利用深度学习方法进行视频中的动作识别（Action Recognition）。
* **挑战**
  ：
  + 视频包含时空信息，既需要捕捉
    **静态外观特征（Spatial Information）**
    ，也需要建模
    **运动信息（Temporal Information）**
    。(空间以及时间)
  + 现有基于单帧输入的 CNN 模型在视频理解任务上的表现不如传统的手工特征（如 Dense Trajectories）。
* **解决方案**
  ：提出
  **双流卷积神经网络（Two-Stream ConvNets）**
  ，分别建模静态和运动信息。

### 1.2 论文主要贡献

* **提出 Two-Stream ConvNet 架构**
  ：由
  **空间流（Spatial Stream）**
  和
  **时间流（Temporal Stream）**
  组成：

  + 空间流（Spatial Stream）：基于单帧 RGB 图像进行分类。
  + 时间流（Temporal Stream）：基于**多帧密集光流（Dense Optical Flow）**进行分类。
  + 两个流的 softmax 预测结果融合，提高识别性能。
* **证明光流作为输入有助于学习时序信息**
  ：相比直接输入多帧 RGB 图像，
  **基于光流的方法效果更好**
  。
* **利用多任务学习（Multi-task Learning）**
  ：在多个数据集上进行联合训练，提高泛化能力。
* **在 UCF-101、HMDB-51 数据集上达到 SOTA**
  ：比之前 CNN 方法显著提升，并接近于基于手工特征的 SOTA 方法

## 2 深度技术细节

### 2.1 神经架构

![](https://i-blog.csdnimg.cn/direct/3f98f7c3140c48c49b34c915bcc03950.png)

**(1) 输入数据**

* **输入视频**
  （左侧）：视频序列被送入两个不同的 CNN 流。
* **空间流（Spatial Stream ConvNet）**
  （上方绿色框）：

  + 输入单帧 RGB 图像（single frame）。
  + 主要学习静态外观信息，如背景、物体形状等。
* **时间流（Temporal Stream ConvNet）**
  （下方紫色框）：

  + 输入多帧光流（multi-frame optical flow）。
  + 主要学习运动信息，如物体的移动方向、速度等。

**(2) CNN 结构**

两个流的 CNN 结构基本相同：

* **conv1**
  ：7×7 卷积核，stride=2，norm，pooling 2×2
* **conv2**
  ：5×5 卷积核，stride=2，pooling 2×2
* **conv3, conv4, conv5**
  ：3×3 卷积核，stride=1，pooling 2×2
* **全连接层（FC）**
  + **fc6**
    ：4096 维 + dropout（40%）
  + **fc7**
    ：2048 维 + dropout（40%）
  + **softmax 分类**

**(3) 结果融合**

* **两个 CNN 输出的 softmax 结果融合**
  （右侧红色框）。
* **融合方式**
  ：

  + **平均融合（Averaging）**
  + **SVM 训练（支持向量机）**

### 2.2 为什么使用光流？

![](https://i-blog.csdnimg.cn/direct/a2436b559a444ec98dcbaaa8a3e8dfc6.png)

* **光流（Optical Flow）**
  提供了显式的运动信息，使网络能够直接学习时序关系，而不需要 CNN 直接从 RGB 帧中推导运动。（de就是竖直和水平方向）
* 试验表明，使用多帧 RGB 作为输入时，CNN 无法有效建模运动信息，而光流可以显著提升性能。

### **2.3   训练策略**

* **空间流 CNN 预训练于 ImageNet**
  ，然后迁移到 UCF-101 和 HMDB-51 进行微调。
* **时间流 CNN 直接在视频数据集上训练**
  ，因没有类似 ImageNet 的大规模视频数据可供预训练。
* **采用多任务学习（Multi-task Learning）**
  ，在 UCF-101 和 HMDB-51 数据集上联合训练，以增强泛化能力。

## 3 优缺点分析(现在)

双流网络（Two-Stream Networks）是一种常见的深度学习架构，通常用于视频分析、动作识别等任务。它的基本思想是通过两个不同的网络流来处理不同类型的信息流。最典型的例子是视频分类任务中的两个流，一个处理静态图像信息（通常是视频的每一帧），另一个处理动态信息（通常是光流，描述了视频帧之间的运动）。下面是双流网络的优缺点分析：

### **优点** ：

1. **能够处理多模态信息**
   ：

   双流网络能够同时处理不同类型的输入信息，例如静态图像流和动态光流流。通过结合这两种信息，可以更全面地理解视频内容，尤其在动作识别中，静态图像能够捕捉物体的外观信息，而动态流可以捕捉物体的运动信息。
2. **增强表达能力**
   ：

   每个流都专注于不同的特征提取任务，从而有助于模型提取更多的信息并增强分类的准确性。例如，光流流能够捕捉时间上的运动变化，静态图像流则可以捕捉空间上的细节。
3. **提高鲁棒性**
   ：

   由于网络通过不同流处理不同类型的信息，能够在某种信息缺失的情况下，仍然保持较强的鲁棒性。例如，如果一个流受到噪声影响，另一个流仍然能提供有用的信息。

### **缺点：**

1. **计算开销大**
   ：

   * 双流网络需要两个独立的网络处理不同的流，这意味着需要更多的计算资源，尤其是在处理长视频或高分辨率图像时。两条流分别进行计算和特征提取，导致网络参数量和计算复杂度较高。
2. **训练难度高**
   ：

   * 双流网络需要同时训练两个流，这可能会增加训练过程的复杂性，并且两个流之间的学习过程可能不完全同步，导致训练过程不稳定或收敛速度较慢。
3. **难以共享信息**
   ：

   * 虽然两个流可以分别处理不同的信息，但它们并不总是能够很好地共享信息。这可能导致某些信息在流之间没有得到有效融合，降低模型的整体性能。
4. **对数据质量要求高**
   ：

   * 双流网络依赖于不同类型的数据（如图像和光流），如果数据不充分或质量不高，可能会导致信息缺失或冗余，影响最终的识别效果。