---
layout: post
title: "GPT-1-3速通版"
date: 2025-03-16 11:34:17 +0800
description: "用的 transformer 解码器结构（48 层 decoder），15 亿参数，模型输入是文本，输出也是文本。预训练模型能够实现 zero-shot，即无需微调直接能在各种领域使用。在众多 zero-shot 领域达到 SOTA，并且这种架构的精度天花板还远未触及，只要继续去提高参数量和数据量。"
keywords: "GPT 1-3（速通版）"
categories: ['大模型多模态Aigc']
tags: ['Aigc']
artid: "146292497"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146292497
    alt: "GPT-1-3速通版"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146292497
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146292497
cover: https://bing.ee123.net/img/rand?artid=146292497
image: https://bing.ee123.net/img/rand?artid=146292497
img: https://bing.ee123.net/img/rand?artid=146292497
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     GPT 1-3（速通版）
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     概述
    </h2>
    <p>
     发布时间线：
    </p>
    <ul>
     <li>
      <p>
       Transformer 2017 年 6 月
      </p>
     </li>
     <li>
      <p>
       GPT1：2018 年 6 月
      </p>
     </li>
     <li>
      <p>
       Bert: 2018 年 10 月
      </p>
     </li>
     <li>
      <p>
       GPT2：2019 年 2 月
      </p>
     </li>
     <li>
      <p>
       GPT3：2020 年 5 月
      </p>
     </li>
    </ul>
    <p>
     <img alt="" height="238" src="https://i-blog.csdnimg.cn/direct/b1e011724c8d4f10b707abd80dc5bcca.png" width="1229"/>
    </p>
    <p>
     bert 适合较小数据集、GPT 必须要超大规模数据集才能有效。
    </p>
    <p>
     GPT-4 未有论文。
    </p>
    <p>
    </p>
    <h2>
     GPT-1（2018 年 6 月）
    </h2>
    <ul>
     <li>
      <p>
       <strong>
        GPT1 参数量
       </strong>
       ：大概 1 亿参数
      </p>
      <ul>
       <li>
        <p>
         12 层 decoder（维度 768，12 个注意力头）
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        训练集
       </strong>
       ：7000 本书籍（8 亿个单词）
      </p>
     </li>
    </ul>
    <p>
     <img alt="" height="574" src="https://i-blog.csdnimg.cn/direct/f080fa3e40f445a594ee47919ce3ccb1.png" width="1306"/>
    </p>
    <h2>
    </h2>
    <h2>
     GPT-2（2019 年 2 月）
    </h2>
    <ul>
     <li>
      <p>
       <strong>
        名称
       </strong>
       ：《Language Models are Unsupervised Multitask Learners》【语言模型是无监督的多任务学习者】
      </p>
     </li>
     <li>
      <p>
       <strong>
        时间
       </strong>
       ：2019 年 2 月
      </p>
     </li>
     <li>
      <p>
       <strong>
        作者
       </strong>
       ：OpenAI 6 人（负责人是 ilya）
      </p>
     </li>
     <li>
      <p>
       <strong>
        代码
       </strong>
       ：https://github.com/openai/gpt-2（没有提供训练代码，也没有最大号预训练模型）
      </p>
     </li>
     <li>
      <p>
       <strong>
        一段话总结 GPT-2
       </strong>
       ：用的 transformer 解码器结构（48 层 decoder），15 亿参数，模型输入是文本，输出也是文本。训练数据源自 reddit 上被点赞的 4500 万个网站链接，各种筛选后获得 800 万文本，大概 40GB 文本数据量。预训练模型能够实现 zero-shot，即无需微调直接能在各种领域使用。在众多 zero-shot 领域达到 SOTA，并且这种架构的精度天花板还远未触及，只要继续去提高参数量和数据量。
      </p>
     </li>
    </ul>
    <p>
     <img alt="" height="917" src="https://i-blog.csdnimg.cn/direct/71a0d40a9ceb43f69d25c038fd304c71.png" width="1148">
      <img alt="" height="266" src="https://i-blog.csdnimg.cn/direct/b8941216662f4a1db8f59ab2509e0845.png" width="502"/>
     </img>
    </p>
    <h2>
    </h2>
    <h2>
     GPT-3（2020 年 5 月）
    </h2>
    <p>
     模型结构跟 GPT-2 几乎完全一致，调整的部分是：采用稀疏注意力（只有临近 token 进行注意力计算）。
    </p>
    <p>
     <strong>
      GPT-3 最大特点
     </strong>
     ：
    </p>
    <ol>
     <li>
      <p>
       显著提高了在零样本学习和少样本学习上的表现，它能够通过简单的提示（prompts）来执行各种任务，无需额外的训练。
      </p>
     </li>
    </ol>
    <p>
     <img alt="" height="621" src="https://i-blog.csdnimg.cn/direct/e89fbe13b2a743e5ac5ea18afc8627d9.png" width="1233"/>
    </p>
    <p>
     <img alt="" height="655" src="https://i-blog.csdnimg.cn/direct/0ca54f117cd847f2921436162e8a5fb5.png" width="1086"/>
    </p>
    <p>
     GPT-3 在几十种类型任务中的平均表现（其中很多领域，few shot 能力超过其他 SOTA 模型的微调）
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34323131383635372f:61727469636c652f64657461696c732f313436323932343937" class_="artid" style="display:none">
 </p>
</div>


