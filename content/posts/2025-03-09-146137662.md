---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f36353130343431392f:61727469636c652f64657461696c732f313436313337363632"
layout: post
title: "机器学习数学基础44.多元线性回归"
date: 2025-03-09 20:36:03 +08:00
description: "多元线性回归"
keywords: "机器学习数学基础：44.多元线性回归"
categories: ['未分类']
tags: ['线性回归', '机器学习', '人工智能']
artid: "146137662"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146137662
    alt: "机器学习数学基础44.多元线性回归"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146137662
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146137662
cover: https://bing.ee123.net/img/rand?artid=146137662
image: https://bing.ee123.net/img/rand?artid=146137662
img: https://bing.ee123.net/img/rand?artid=146137662
---

# 机器学习数学基础：44.多元线性回归

#### 一、文字内容详解

##### 1. 多重共线性的判断——皮尔逊相关系数

皮尔逊相关系数用于衡量自变量间的线性相关程度，取值范围为 ([-1, 1])：

* 绝对值越接近 (1)，变量间线性相关性越强；越接近 (0)，相关性越弱。
* 在多重共线性判断中，经验标准为：若自变量间的皮尔逊相关系数
  **＜ 0.7**
  ，说明变量间线性关联未达到“严重”水平，多重共线性问题可控。例如，分析“广告投入、产品价格”对销量的影响时，若二者相关系数为 (0.6)，则不构成严重共线性。

##### 2. 多重共线性的处理措施

* **删除次要变量**
  ：
    
  通过理论分析或统计检验（如变量显著性检验），识别对因变量影响较小（不显著）且与其他变量高度相关的自变量。例如，研究消费行为时，若“月收入”与“银行存款”高度相关，且“银行存款”对消费的解释不显著，可删除该变量，减少共线性干扰。
* **合并相关较高的变量**
  ：
    
  将高相关变量整合成新指标。常用方法包括：
  + **主成分分析**
    ：提取公共因子，用少数综合变量替代原始变量；
  + **构建综合指标**
    ：如将“运动量”“运动强度”合并为“运动总消耗”，既保留信息，又降低共线性。

#### 二、图示内容详解

* **变量关系**
  ：
  + **X1、X2、X3**
    ：代表自变量，彼此间通过曲线箭头连接，表明存在相关关系（即多重共线性）。
  + **Y**
    ：代表因变量，直线箭头表示自变量对因变量的影响路径，体现多元线性回归中“多个自变量共同解释因变量”的逻辑。
* **模型逻辑**
  ：
    
  图示直观呈现多元线性回归模型的结构，既展示自变量间的关联（潜在的多重共线性问题），也体现自变量对因变量的作用。这种关联可能干扰对因变量影响的准确估计，因此需通过判断（如皮尔逊相关系数）和处理（删除或合并变量）优化模型。

#### 三、通俗理解多重共线性

##### 1. 多重共线性是啥？

想象分析“每天学习时长、刷题量、复习次数”对考试成绩的影响。理论上，这三个因素独立影响成绩，但现实中，学习时间长可能刷题量多、复习次数也多——它们之间有关联，这就是
**多重共线性**
。多元回归假设自变量“各自独立”，但现实中它们常有关联，只要关联不大就没事，关联过强才出问题。

##### 2. 多重共线性的“破坏力”

比如研究“运动量、运动强度”对减肥的影响。正常逻辑：运动量越大、强度越高，减肥效果越好（对应回归系数应为正数）。但如果“运动量”和“运动强度”高度相关（如运动强度高时，运动量被迫减少），分析结果可能出现“运动强度”的系数是负数——违背常理，这就是多重共线性导致的“诡异结果”。

##### 3. VIF：判断共线性的“尺子”

* **VIF＜3**
  ：自变量间“关系很淡”，共线性问题几乎可忽略，像陌生人；
* **3≤VIF≤10**
  ：自变量间“有点交情”，存在弱共线性，像普通朋友；
* **VIF＞10**
  ：自变量间“关系过密”，共线性严重，像亲密伙伴，此时必须处理（如删除部分变量、合并变量等），否则分析结果不可信。