---
layout: post
title: "机器学习数学基础44.多元线性回归"
date: 2025-03-09 20:36:03 +0800
description: "多元线性回归"
keywords: "机器学习数学基础：44.多元线性回归"
categories: ['未分类']
tags: ['线性回归', '机器学习', '人工智能']
artid: "146137662"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146137662
    alt: "机器学习数学基础44.多元线性回归"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146137662
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146137662
cover: https://bing.ee123.net/img/rand?artid=146137662
image: https://bing.ee123.net/img/rand?artid=146137662
img: https://bing.ee123.net/img/rand?artid=146137662
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     机器学习数学基础：44.多元线性回归
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h4>
     <a id="_0">
     </a>
     一、文字内容详解
    </h4>
    <h5>
     <a id="1__1">
     </a>
     1. 多重共线性的判断——皮尔逊相关系数
    </h5>
    <p>
     皮尔逊相关系数用于衡量自变量间的线性相关程度，取值范围为 ([-1, 1])：
    </p>
    <ul>
     <li>
      绝对值越接近 (1)，变量间线性相关性越强；越接近 (0)，相关性越弱。
     </li>
     <li>
      在多重共线性判断中，经验标准为：若自变量间的皮尔逊相关系数
      <strong>
       ＜ 0.7
      </strong>
      ，说明变量间线性关联未达到“严重”水平，多重共线性问题可控。例如，分析“广告投入、产品价格”对销量的影响时，若二者相关系数为 (0.6)，则不构成严重共线性。
     </li>
    </ul>
    <h5>
     <a id="2__6">
     </a>
     2. 多重共线性的处理措施
    </h5>
    <ul>
     <li>
      <strong>
       删除次要变量
      </strong>
      ：
      <br/>
      通过理论分析或统计检验（如变量显著性检验），识别对因变量影响较小（不显著）且与其他变量高度相关的自变量。例如，研究消费行为时，若“月收入”与“银行存款”高度相关，且“银行存款”对消费的解释不显著，可删除该变量，减少共线性干扰。
     </li>
     <li>
      <strong>
       合并相关较高的变量
      </strong>
      ：
      <br/>
      将高相关变量整合成新指标。常用方法包括：
      <ul>
       <li>
        <strong>
         主成分分析
        </strong>
        ：提取公共因子，用少数综合变量替代原始变量；
       </li>
       <li>
        <strong>
         构建综合指标
        </strong>
        ：如将“运动量”“运动强度”合并为“运动总消耗”，既保留信息，又降低共线性。
       </li>
      </ul>
     </li>
    </ul>
    <h4>
     <a id="_14">
     </a>
     二、图示内容详解
    </h4>
    <ul>
     <li>
      <strong>
       变量关系
      </strong>
      ：
      <ul>
       <li>
        <strong>
         X1、X2、X3
        </strong>
        ：代表自变量，彼此间通过曲线箭头连接，表明存在相关关系（即多重共线性）。
       </li>
       <li>
        <strong>
         Y
        </strong>
        ：代表因变量，直线箭头表示自变量对因变量的影响路径，体现多元线性回归中“多个自变量共同解释因变量”的逻辑。
       </li>
      </ul>
     </li>
     <li>
      <strong>
       模型逻辑
      </strong>
      ：
      <br/>
      图示直观呈现多元线性回归模型的结构，既展示自变量间的关联（潜在的多重共线性问题），也体现自变量对因变量的作用。这种关联可能干扰对因变量影响的准确估计，因此需通过判断（如皮尔逊相关系数）和处理（删除或合并变量）优化模型。
     </li>
    </ul>
    <h4>
     <a id="_21">
     </a>
     三、通俗理解多重共线性
    </h4>
    <h5>
     <a id="1__22">
     </a>
     1. 多重共线性是啥？
    </h5>
    <p>
     想象分析“每天学习时长、刷题量、复习次数”对考试成绩的影响。理论上，这三个因素独立影响成绩，但现实中，学习时间长可能刷题量多、复习次数也多——它们之间有关联，这就是
     <strong>
      多重共线性
     </strong>
     。多元回归假设自变量“各自独立”，但现实中它们常有关联，只要关联不大就没事，关联过强才出问题。
    </p>
    <h5>
     <a id="2__25">
     </a>
     2. 多重共线性的“破坏力”
    </h5>
    <p>
     比如研究“运动量、运动强度”对减肥的影响。正常逻辑：运动量越大、强度越高，减肥效果越好（对应回归系数应为正数）。但如果“运动量”和“运动强度”高度相关（如运动强度高时，运动量被迫减少），分析结果可能出现“运动强度”的系数是负数——违背常理，这就是多重共线性导致的“诡异结果”。
    </p>
    <h5>
     <a id="3_VIF_28">
     </a>
     3. VIF：判断共线性的“尺子”
    </h5>
    <ul>
     <li>
      <strong>
       VIF＜3
      </strong>
      ：自变量间“关系很淡”，共线性问题几乎可忽略，像陌生人；
     </li>
     <li>
      <strong>
       3≤VIF≤10
      </strong>
      ：自变量间“有点交情”，存在弱共线性，像普通朋友；
     </li>
     <li>
      <strong>
       VIF＞10
      </strong>
      ：自变量间“关系过密”，共线性严重，像亲密伙伴，此时必须处理（如删除部分变量、合并变量等），否则分析结果不可信。
     </li>
    </ul>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f36353130343431392f:61727469636c652f64657461696c732f313436313337363632" class_="artid" style="display:none">
 </p>
</div>


