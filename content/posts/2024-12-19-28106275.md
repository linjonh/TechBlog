---
arturl_encode: "68747470733a2f:2f626c6f672e6373646e2e6e65742f69616d62657374303037:2f61727469636c652f64657461696c732f3238313036323735"
layout: post
title: "RTPRTCP音视频同步"
date: 2024-12-19 00:34:24 +0800
description: "2.1  RTCP控制参数由于音视频流作为不同的RTP会话传送，它们在RTP"
keywords: "frevideo"
categories: ['Linuxos']
tags: ['视频流', '视频', '多媒体', 'Rtp', 'Linux']
artid: "28106275"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=28106275
    alt: "RTPRTCP音视频同步"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=28106275
featuredImagePreview: https://bing.ee123.net/img/rand?artid=28106275
---

# RTP/RTCP音视频同步

Blog From
<http://blog.csdn.net/kof98765/article/details/17733701>

<http://hongdow.com/rtp%E3%80%81rtcp%E5%8F%8A%E5%AA%92%E4%BD%93%E6%B5%81%E5%90%8C%E6%AD%A5.html>

RTCP控制参数

由于音视频流作为不同的RTP会话传送，它们在RTP层无直接关联。尽管由一个数据源发出的不同的流具有不同的同步源标识(SSRC)，为能进行流同步，RTCP要求发送方给接收方传送一个唯一的标识数据源的规范名(canonical name)，应用层藉此关联音视频流，以便实现同步。
  
RTP/ RTCP中有时间戳（相对和绝对）和序列号等信息，可以利用它实现基于时间戳的多媒体流同步。使用相对时间戳和序列号实现流内同步；使用相对和绝对时间戳的对应关系实现流间同步。获得相对与绝对时间戳的算法如下：
  

```cpp
while ((pack = GetNextPacket()) != NULL)
         {
              if(srcdat->SR_HasInfo() && srcdat->SR_GetRTPTimestamp() != app->mvideortcprtp)  
                   {  
                            app->mvideortcprtp = srcdat->SR_GetRTPTimestamp();
                            app->mvideortcpntp = srcdat->SR_GetNTPTimestamp().GetMSW();
                            srcdat->FlushPackets();  
                   }
                   DeletePacket(pack);
}
 
```

音视频流间同步实现
  
发送端在发送音视频数据时，同时也会发送SR包，这样可以使接收方能够正确使音视频同步播放。具体实现方法是在接收方每次接收数据包后，再遍历一次数据源，获取所有源端的SS\_RTPTime与SS\_NTPTime这两则数据，通过获取音频端与视频端的数据，可以利用下面的公式进行计算。
  
表 2.1    变量描述表
  

```html
   类型                    RTP数据               NTP数据               RTP时戳频率
   音频                 Audio_SRRTPTime       Audio_SRNTPTime             Audio_Fre
   视频                 Video_SRRTPTime       Video_SRNTPTime             Video_Fre
```

从SR包中可以读出音频与视频的RTP与NTP数据，而需要计算的是时戳频率，利用下述公式：

```cpp
                      Audio_Fre=( AudioSRRTPtime2- AudioSRRTPtime1)/( AudioSRNTPtime2- AudioSRNTPtime1)     
                      Video_Fre=( VideoSRRTPtime2- VideoSRRTPtime1)/( VideoSRNTPtime2- Video SRNTPtime1)
```

然后计算视频RTP的时间，即：
  

```cpp
                      Video_RTPTime=Video_SRRTPTime + (Audio_SRNTP-Video_SRNTP)×Video_Fre
```

最后即可计算出Video\_TRUERTP时间，将其与从RTP包中读出的时间进行比较，就可以进行同步播放了。
  

```cpp
                      (Video_TRUERTP-Video_RTPTime)/Video_Fre=(Audio_TRUERTP-Audio_SRRTPTime)/Audio_Fre
```

下面采用临时缓冲区的方法来同步音视频。因为要保证音频优先正常传输，所以本系统以音频为主轴，视频为辅轴。

以最大延迟时间为缓冲区大小，存放M个音频帧数据。当接收端获得M个音频帧后开始播放音频，每次获得视频帧时，就计算出当前视频应当播放RTP时间与现有RTP时间进行比对，如若在120ms以内，迅速播放；延迟120ms以上，则扔掉，然后比对下一帧；还在120ms以内，放入视频缓冲区内进行储存，如果视频缓冲区的大小超过了最大临时缓冲区的数值，依旧开始播放。