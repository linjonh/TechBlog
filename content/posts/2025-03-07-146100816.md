---
layout: post
title: "Flink深入浅出之03状态窗口checkpoint两阶段提交"
date: 2025-03-07 18:15:42 +0800
description: "Flink 是一个默认就有状态的分析引擎，前面的WordCount 案例可以做到单词的数量的累加，其实是因为在内存中保证了每个单词的出现的次数，这些数据其实就是状态数据。但是如果一个 Task 在处理过程中挂掉了，那么它在内存中的状态都会丢失，所有的数据都需要重新计算。从容错和消息处理的语义（At -least-once 和 Exactly-once）上来说，Flink引入了State 和 CheckPoint。"
keywords: "Flink深入浅出之03：状态、窗口、checkpoint、两阶段提交"
categories: ['大数据技术学习']
tags: ['大数据', 'Flink']
artid: "146100816"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146100816
    alt: "Flink深入浅出之03状态窗口checkpoint两阶段提交"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146100816
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146100816
cover: https://bing.ee123.net/img/rand?artid=146100816
image: https://bing.ee123.net/img/rand?artid=146100816
img: https://bing.ee123.net/img/rand?artid=146100816
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Flink深入浅出之03：状态、窗口、checkpoint、两阶段提交
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h2>
     <a id="Flink_0">
     </a>
     Flink是一个有状态的流，👅一起深入了解这个有状态的流
    </h2>
    <h3>
     <a id="three__6">
     </a>
     3️⃣ 目标
    </h3>
    <ol>
     <li>
      掌握State知识
     </li>
     <li>
      掌握Flink三种State Backend
     </li>
     <li>
      掌握Flink checkpoint和savepoint原理
     </li>
     <li>
      了解Flink的重启策略
     </li>
     <li>
      checkpoint+two phase commit保证E-O语义
     </li>
    </ol>
    <h3>
     <a id="four__16">
     </a>
     4️⃣ 要点
    </h3>
    <h3>
     <a id="book_1_FlinkState_20">
     </a>
     📖 1. Flink的State
    </h3>
    <h5>
     <a id="11_state_22">
     </a>
     1.1 state概述
    </h5>
    <p>
     <strong>
      Apache Flink® — Stateful Computations over Data Streams
     </strong>
    </p>
    <pre><code>	Flink 是一个默认就有状态的分析引擎，前面的WordCount 案例可以做到单词的数量的累加，
	其实是因为在内存中保证了每个单词的出现的次数，这些数据其实就是状态数据。
	但是如果一个 Task 在处理过程中挂掉了，那么它在内存中的状态都会丢失，
	所有的数据都需要重新计算。
	从容错和消息处理的语义（At -least-once 和 Exactly-once）上来说，
	Flink引入了State 和 CheckPoint。
	
	State一般指一个具体的 Task/Operator 的状态，State数据默认保存在 Java 的堆内存中。
</code></pre>
    <ul>
     <li>
      <p>
       回顾单词计数的例子
      </p>
      <pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>demo1</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span>Tuple
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataStream<span class="token punctuation">,</span> StreamExecutionEnvironment<span class="token punctuation">,</span> WindowedStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>windowing<span class="token punctuation">.</span>time<span class="token punctuation">.</span></span>Time
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>windowing<span class="token punctuation">.</span>windows<span class="token punctuation">.</span></span>TimeWindow

<span class="token comment">/**
  * 使用滑动窗口
  * 每隔1秒钟统计最近2秒钟的每个单词出现的次数
  */</span>
<span class="token keyword">object</span> FlinkStream <span class="token punctuation">{<!-- --></span>

  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
      <span class="token comment">//构建流处理的环境</span>
      <span class="token keyword">val</span> env<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment

  <span class="token comment">//从socket获取数据</span>
<span class="token keyword">val</span> sourceStream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> env<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"node01"</span><span class="token punctuation">,</span><span class="token number">9999</span><span class="token punctuation">)</span>
 <span class="token comment">//导入隐式转换的包</span>
  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>_
 
 <span class="token comment">//对数据进行处理</span>
  <span class="token keyword">val</span> result<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sourceStream
                                <span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">//按照空格切分</span>
                                <span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">//每个单词计为1</span>
                                <span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>         <span class="token comment">//按照下标为0的单词进行分组</span>
                                <span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>          <span class="token comment">//按照下标为1累加相同单词出现的1</span>
        <span class="token comment">//对数据进行打印</span>
  result<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token comment">//开启任务</span>
   env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"FlinkStream"</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
</code></pre>
     </li>
     <li>
      <p>
       输入
      </p>
      <pre><code>  hadoop hadoop
  hadoop
  hive hadoop 
</code></pre>
     </li>
     <li>
      <p>
       输出
      </p>
      <pre><code>  8&gt; (hadoop,1)
  1&gt; (hive,1)
  8&gt; (hadoop,2)
  8&gt; (hadoop,3)
  8&gt; (hadoop,4)
</code></pre>
     </li>
    </ul>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/0c1b9b542ab5462ab4c48c53fabc6e30.png"/>
    </p>
    <h5>
     <a id="12_state_101">
     </a>
     1.2 state类型
    </h5>
    <ul>
     <li>
      Flink中有两种基本类型的State, ，他们两种都可以以两种形式存在：
      <ul>
       <li>
        原生状态(raw state)
        <ul>
         <li>
          由算子自己管理数据结构，当触发Checkpoint操作过程中，Flink并不知道状态数据内部的数据结构，只是将数据转换成bytes数据存储在Checkpoints中，当从Checkpoints恢复任务时，算子自己再反序列化出状态的数据结构。
         </li>
        </ul>
       </li>
       <li>
        托管状态(managed state)
        <ul>
         <li>
          由
          <strong>
           Flink Runtime
          </strong>
          控制和管理状态数据，并将状态数据转换成为内存的Hash tables或 RocksDB的对象存储，然后将这些数据通过内部的接口持久化到checkpoints中，任务异常时可以通过这些状态数据恢复任务。
         </li>
         <li>
          推荐使用ManagedState管理状态数据，ManagedState更好的支持状态数据的重平衡以及更加完善的内存管理
         </li>
        </ul>
       </li>
      </ul>
     </li>
    </ul>
    <table>
     <thead>
      <tr>
       <th>
       </th>
       <th>
        Managed State
       </th>
       <th>
        Raw State
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        状态管理方式
       </td>
       <td>
        Flink Runtime托管，自动存储、自动恢复、自动伸缩
       </td>
       <td>
        用户自己管理
       </td>
      </tr>
      <tr>
       <td>
        状态数据结构
       </td>
       <td>
        Flink提供的常用数据结构，如ListState、MapState等
       </td>
       <td>
        字节数组：byte[]
       </td>
      </tr>
      <tr>
       <td>
        使用场景
       </td>
       <td>
        绝大多数Flink算子
       </td>
       <td>
        用户自定义算子
       </td>
      </tr>
     </tbody>
    </table>
    <h6>
     <a id="121__Operator_State_118">
     </a>
     1.2.1 Operator State(算子状态)
    </h6>
    <ul>
     <li>
      operator state是task级别的state，说白了就是每个task对应一个state。
     </li>
     <li>
      Kafka Connector source中的每个分区（task）都需要记录消费的topic的partition和offset等信息。
     </li>
     <li>
      对于Operator State，我们还需进一步实现
      <code>
       CheckpointedFunction
      </code>
      接口。
     </li>
     <li>
      Operator State的实际应用场景不如Keyed State多，它经常被用在Source或Sink等算子上，用来保存流入数据的偏移量或对输出数据做缓存，以保证Flink应用的Exactly-Once语义。
     </li>
    </ul>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/4d8c796bff2f4f37a2d2561ff3b38310.png"/>
    </p>
    <h6>
     <a id="122_keyed_State_130">
     </a>
     1.2.2 keyed State(键控状态)
    </h6>
    <ul>
     <li>
      <p>
       <code>
        Keyed State：
       </code>
      </p>
      <ul>
       <li>
        顾名思义就是基于KeyedStream上的状态，这个状态是跟特定的Key 绑定的。KeyedStream流上的每一个Key，都对应一个State。Flink针对 Keyed State 提供了以下可以保存State的数据结构.
       </li>
      </ul>
     </li>
     <li>
      <p>
       <code>
        Keyed state托管状态有六种类型：
       </code>
      </p>
      <ul>
       <li>
        <p>
         1、
         <mark>
          ValueState
         </mark>
        </p>
        <pre><code> 保存一个可以更新和检索的值（如上所述，每个值都对应到当前的输入数据的key，因此算子接收到的每个key都可能对应一个值）。 这个值可以通过update(T) 进行更新，通过 T value() 进行检索	
</code></pre>
       </li>
       <li>
        <p>
         2、
         <mark>
          ListState
         </mark>
        </p>
        <pre><code>	保存一个元素的列表。可以往这个列表中追加数据，并在当前的列表上进行检索。可以通过 add(T) 或者 addAll(List&lt;T&gt;) 进行添加元素，通过 Iterable&lt;T&gt; get() 获得整个列表。还可以通过 update(List&lt;T&gt;) 覆盖当前的列表	。
</code></pre>
       </li>
       <li>
        <p>
         3、
         <mark>
          MapState
         </mark>
        </p>
        <pre><code>	维护了一个映射列表。 你可以添加键值对到状态中，也可以获得 反映当前所有映射的迭代器。使用 put(UK，UV) 或者 putAll(Map&lt;UK，UV&gt;) 添加映射。 使用 get(UK) 检索特定 key。 使用 entries()，keys() 和 values() 分别检索映射、 键和值的可迭代视图。
</code></pre>
       </li>
       <li>
        <p>
         4、ReducingState
        </p>
        <pre><code>	保存一个单值，表示添加到状态的所有值的聚合。接口与ListState类似，但使用add(T) 增加元素，会使用提供的 ReduceFunction 进行聚合。
</code></pre>
       </li>
       <li>
        <p>
         5、AggregatingState
        </p>
        <pre><code>	AggregatingState&lt;IN, OUT&gt;: 保留一个单值，表示添加到状态的所有值的聚合。和 ReducingState 相反的是, 聚合类型可能与添加到状态的元素的类型不同。 接口与 ListState类似，但使用 add(IN) 添加的元素会用指定的 AggregateFunction 进行聚合
</code></pre>
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        keyedState使用方法
       </strong>
      </p>
      <ul>
       <li>
        1、只能用于
        <code>
         RichFunction
        </code>
       </li>
       <li>
        2、将
        <code>
         State
        </code>
        声明为实例变量
       </li>
       <li>
        3、在
        <code>
         open()
        </code>
        方法中为State赋值
        <ul>
         <li>
          创建一个
          <code>
           StateDescriptor
          </code>
         </li>
         <li>
          利用
          <code>
           getRuntimeContext().getXXState(...)
          </code>
          构建不同的State
         </li>
        </ul>
       </li>
       <li>
        4、调用State的方法进行
        <code>
         读写
        </code>
        <ul>
         <li>
          例如 state.value()、state.update(…)等等
         </li>
        </ul>
       </li>
      </ul>
     </li>
    </ul>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/45e7bd0992e64ea6afae3b797ad5e5bc.png"/>
    </p>
    <h5>
     <a id="13_Keyed_State_183">
     </a>
     1.3 Keyed State案例演示
    </h5>
    <h6>
     <a id="131_ValueState_185">
     </a>
     1.3.1 ValueState
    </h6>
    <ul>
     <li>
      <p>
       作用
      </p>
      <ul>
       <li>
        保存一个可以更新和检索的值
       </li>
      </ul>
     </li>
     <li>
      <p>
       需求
      </p>
      <ul>
       <li>
        使用valueState实现平均值求取
       </li>
      </ul>
     </li>
     <li>
      <p>
       代码开发
      </p>
      <pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>keystate</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>RichFlatMapFunction
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>state<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>ValueState<span class="token punctuation">,</span> ValueStateDescriptor<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span></span>Configuration
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>StreamExecutionEnvironment
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Collector

<span class="token comment">/**
  * 使用valueState实现平均值求取
  */</span>
<span class="token keyword">object</span> ValueStateOperate <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>_

      env<span class="token punctuation">.</span>fromCollection<span class="token punctuation">(</span>List<span class="token punctuation">(</span>
        <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">3d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">5d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">7d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">4d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">2d</span><span class="token punctuation">)</span>
      <span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
        <span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span><span class="token keyword">new</span> CountAverageWithValue<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token keyword">class</span> CountAverageWithValue <span class="token keyword">extends</span> RichFlatMapFunction<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token punctuation">{<!-- --></span>
  <span class="token comment">//定义ValueState类型的变量</span>
  <span class="token keyword">private</span> <span class="token keyword">var</span> sum<span class="token operator">:</span> ValueState<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> _
    <span class="token keyword">override</span> <span class="token keyword">def</span> <span class="token keyword">open</span><span class="token punctuation">(</span>parameters<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
  <span class="token comment">//初始化获取历史状态的值</span>
  sum <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getState<span class="token punctuation">(</span>
    <span class="token keyword">new</span> ValueStateDescriptor<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"average"</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  <span class="token punctuation">)</span>
<span class="token punctuation">}</span>

<span class="token keyword">override</span> <span class="token keyword">def</span> flatMap<span class="token punctuation">(</span>input<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
  <span class="token comment">// access the state value</span>
  <span class="token keyword">val</span> tmpCurrentSum <span class="token operator">=</span> sum<span class="token punctuation">.</span>value
  <span class="token comment">// If it hasn't been used before, it will be null</span>
  <span class="token keyword">val</span> currentSum <span class="token operator">=</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>tmpCurrentSum <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
    tmpCurrentSum
  <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{<!-- --></span>
    <span class="token punctuation">(</span><span class="token number">0L</span><span class="token punctuation">,</span> <span class="token number">0d</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
  <span class="token comment">// update the count</span>
  <span class="token keyword">val</span> newSum <span class="token operator">=</span> <span class="token punctuation">(</span>currentSum<span class="token punctuation">.</span>_1 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> currentSum<span class="token punctuation">.</span>_2 <span class="token operator">+</span> input<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>

  <span class="token comment">// update the state</span>
  sum<span class="token punctuation">.</span>update<span class="token punctuation">(</span>newSum<span class="token punctuation">)</span>

  <span class="token comment">// if the count reaches 2, emit the average and clear the state</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>newSum<span class="token punctuation">.</span>_1 <span class="token operator">&gt;=</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
    out<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">(</span>input<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> newSum<span class="token punctuation">.</span>_2 <span class="token operator">/</span> newSum<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//将状态清除</span>
    <span class="token comment">//sum.clear()</span>
  		<span class="token punctuation">}</span>
	<span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
</code></pre>
     </li>
    </ul>
    <h6>
     <a id="132_ListState_265">
     </a>
     1.3.2 ListState
    </h6>
    <ul>
     <li>
      <p>
       作用
      </p>
      <ul>
       <li>
        用于保存每个key的历史数据数据成为一个列表
       </li>
      </ul>
     </li>
     <li>
      <p>
       需求
      </p>
      <ul>
       <li>
        使用ListState求取数据平均值
       </li>
      </ul>
     </li>
     <li>
      <p>
       代码开发
      </p>
      <pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>keystate</span>

  <span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>lang</span>
  <span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Collections

  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>RichFlatMapFunction
  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>state<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>ListState<span class="token punctuation">,</span> ListStateDescriptor<span class="token punctuation">}</span>
  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span></span>Configuration
  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>StreamExecutionEnvironment
  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Collector

  <span class="token comment">/**
    * 使用ListState实现平均值求取
    * ListState&lt;T&gt; ：这个状态为每一个 key 保存集合的值
    *      get() 获取状态值
    *      add() / addAll() 更新状态值，将数据放到状态中
    *      clear() 清除状态
    */</span>
  <span class="token keyword">object</span> ListStateOperate <span class="token punctuation">{<!-- --></span>

    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
      <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>_
      env<span class="token punctuation">.</span>fromCollection<span class="token punctuation">(</span>List<span class="token punctuation">(</span>
        <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">3d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">5d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">7d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">4d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">2d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">6d</span><span class="token punctuation">)</span>
      <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
        <span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span><span class="token keyword">new</span> CountAverageWithList<span class="token punctuation">)</span>
        <span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
      env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>



  <span class="token keyword">class</span> CountAverageWithList <span class="token keyword">extends</span> RichFlatMapFunction<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">{<!-- --></span>
    <span class="token comment">//定义我们历史所有的数据获取</span>
    <span class="token keyword">private</span> <span class="token keyword">var</span> elementsByKey<span class="token operator">:</span> ListState<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> _

    <span class="token keyword">override</span> <span class="token keyword">def</span> <span class="token keyword">open</span><span class="token punctuation">(</span>parameters<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
      <span class="token comment">//初始化获取历史状态的值，每个key对应的所有历史值，都存储在list集合里面了</span>
      <span class="token keyword">val</span> listState <span class="token operator">=</span> <span class="token keyword">new</span> ListStateDescriptor<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"listState"</span><span class="token punctuation">,</span>classOf<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
      elementsByKey <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getListState<span class="token punctuation">(</span>listState<span class="token punctuation">)</span>

    <span class="token punctuation">}</span>

    <span class="token keyword">override</span> <span class="token keyword">def</span> flatMap<span class="token punctuation">(</span>element<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
      <span class="token comment">//获取当前key的状态值</span>
     <span class="token keyword">val</span> currentState<span class="token operator">:</span> lang<span class="token punctuation">.</span>Iterable<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> elementsByKey<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>

      <span class="token comment">//如果初始状态为空，那么就进行初始化，构造一个空的集合出来，准备用于存储后续的数据</span>
      <span class="token keyword">if</span><span class="token punctuation">(</span>currentState <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        elementsByKey<span class="token punctuation">.</span>addAll<span class="token punctuation">(</span>Collections<span class="token punctuation">.</span>emptyList<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
      <span class="token comment">//添加元素</span>
      elementsByKey<span class="token punctuation">.</span>add<span class="token punctuation">(</span>element<span class="token punctuation">)</span>
      <span class="token keyword">import</span> <span class="token namespace">scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span></span>JavaConverters<span class="token punctuation">.</span>_
      <span class="token keyword">val</span> allElements<span class="token operator">:</span> Iterator<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> elementsByKey<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>iterator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>asScala
        
      <span class="token keyword">val</span> allElementList<span class="token operator">:</span> List<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> allElements<span class="token punctuation">.</span>toList
      <span class="token keyword">if</span><span class="token punctuation">(</span>allElementList<span class="token punctuation">.</span>size <span class="token operator">&gt;=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        <span class="token keyword">var</span> count <span class="token operator">=</span> <span class="token number">0L</span>
        <span class="token keyword">var</span> sum <span class="token operator">=</span> <span class="token number">0d</span>
        <span class="token keyword">for</span><span class="token punctuation">(</span>eachElement <span class="token keyword">&lt;-</span> allElementList<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
          count <span class="token operator">+=</span><span class="token number">1</span>
          sum <span class="token operator">+=</span> eachElement<span class="token punctuation">.</span>_2
        <span class="token punctuation">}</span>
        out<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">(</span>element<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>sum<span class="token operator">/</span>count<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
</code></pre>
     </li>
    </ul>
    <h6>
     <a id="133_MapState_357">
     </a>
     1.3.3 MapState
    </h6>
    <ul>
     <li>
      <p>
       作用
      </p>
      <ul>
       <li>
        用于将每个key对应的数据都保存成一个map集合
       </li>
      </ul>
     </li>
     <li>
      <p>
       需求
      </p>
      <ul>
       <li>
        使用MapState求取每个key对应的平均值
       </li>
      </ul>
     </li>
     <li>
      <p>
       代码开发
      </p>
      <pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>keystate</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>UUID

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>RichFlatMapFunction
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>state<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>MapState<span class="token punctuation">,</span> MapStateDescriptor<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span></span>Configuration
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>StreamExecutionEnvironment
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Collector
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>_

<span class="token comment">/**
  * 使用MapState求取每个key对应的平均值
  */</span>
<span class="token keyword">object</span> MapStateOperate <span class="token punctuation">{<!-- --></span>

  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>

    <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment

    env<span class="token punctuation">.</span>fromCollection<span class="token punctuation">(</span>List<span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">3d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">5d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">7d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">4d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">2d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">6d</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span><span class="token keyword">new</span> CountAverageMapState<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token keyword">class</span> CountAverageMapState <span class="token keyword">extends</span> RichFlatMapFunction<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">{<!-- --></span>
  <span class="token keyword">private</span> <span class="token keyword">var</span> mapState<span class="token operator">:</span>MapState<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">]</span> <span class="token operator">=</span> _

  <span class="token comment">//初始化获取mapState对象</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> <span class="token keyword">open</span><span class="token punctuation">(</span>parameters<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> mapStateOperate <span class="token operator">=</span> <span class="token keyword">new</span> MapStateDescriptor<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"mapStateOperate"</span><span class="token punctuation">,</span>classOf<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">,</span>classOf<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    mapState <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getMapState<span class="token punctuation">(</span>mapStateOperate<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> flatMap<span class="token punctuation">(</span>input<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">//将相同的key对应的数据放到一个map集合当中去，就是这种对应  key -&gt; Map((key1, value1),(key2, value2)) </span>
    <span class="token comment">//每次都构建一个map集合</span>
    mapState<span class="token punctuation">.</span>put<span class="token punctuation">(</span>UUID<span class="token punctuation">.</span>randomUUID<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toString<span class="token punctuation">,</span>input<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>
    <span class="token keyword">import</span> <span class="token namespace">scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span></span>JavaConverters<span class="token punctuation">.</span>_

    <span class="token comment">//获取map集合当中所有的value，我们每次将数据的value给放到map的value里面去</span>
    <span class="token keyword">val</span> listState<span class="token operator">:</span> List<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span> <span class="token operator">=</span> mapState<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>iterator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>asScala<span class="token punctuation">.</span>toList
    <span class="token keyword">if</span><span class="token punctuation">(</span>listState<span class="token punctuation">.</span>size <span class="token operator">&gt;=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
      <span class="token keyword">var</span> count <span class="token operator">=</span> <span class="token number">0L</span>
      <span class="token keyword">var</span> sum <span class="token operator">=</span> <span class="token number">0d</span>
      <span class="token keyword">for</span><span class="token punctuation">(</span>eachState <span class="token keyword">&lt;-</span> listState<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        count <span class="token operator">+=</span><span class="token number">1</span>
        sum <span class="token operator">+=</span> eachState
      <span class="token punctuation">}</span>
      out<span class="token punctuation">.</span>collect<span class="token punctuation">(</span>input<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>sum<span class="token operator">/</span>count<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
     </li>
    </ul>
    <h6>
     <a id="134_ReducingState_436">
     </a>
     1.3.4 ReducingState
    </h6>
    <ul>
     <li>
      <p>
       作用
      </p>
      <ul>
       <li>
        用于数据的聚合
       </li>
      </ul>
     </li>
     <li>
      <p>
       需求
      </p>
      <ul>
       <li>
        使用ReducingState求取每个key对应的平均值
       </li>
      </ul>
     </li>
     <li>
      <p>
       代码开发
      </p>
      <pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>keystate</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>ReduceFunction<span class="token punctuation">,</span> RichFlatMapFunction<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>state<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>ReducingState<span class="token punctuation">,</span> ReducingStateDescriptor<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span></span>Configuration
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>StreamExecutionEnvironment
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Collector

<span class="token comment">/**
  * ReducingState&lt;T&gt; ：这个状态为每一个 key 保存一个聚合之后的值
  * get() 获取状态值
  * add()  更新状态值，将数据放到状态中
  * clear() 清除状态
  */</span>

<span class="token keyword">object</span> ReduceingStateOperate <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>_
    env<span class="token punctuation">.</span>fromCollection<span class="token punctuation">(</span>List<span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">3d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">5d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">7d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">4d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">2d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">6d</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span><span class="token keyword">new</span> CountAverageReduceStage<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>

    env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
  <span class="token keyword">class</span> CountAverageReduceStage <span class="token keyword">extends</span> RichFlatMapFunction<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">{<!-- --></span>
      
       <span class="token comment">//定义ReducingState</span>
        <span class="token keyword">private</span> <span class="token keyword">var</span> reducingState<span class="token operator">:</span>ReducingState<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span> <span class="token operator">=</span> _

        <span class="token comment">//定义一个计数器</span>
        <span class="token keyword">var</span> counter<span class="token operator">=</span><span class="token number">0L</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> <span class="token keyword">open</span><span class="token punctuation">(</span>parameters<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>

  <span class="token keyword">val</span> reduceSum <span class="token operator">=</span> <span class="token keyword">new</span> ReducingStateDescriptor<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"reduceSum"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> ReduceFunction<span class="token punctuation">[</span> <span class="token builtin">Double</span><span class="token punctuation">]</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">override</span> <span class="token keyword">def</span> reduce<span class="token punctuation">(</span>value1<span class="token operator">:</span> <span class="token builtin">Double</span><span class="token punctuation">,</span> value2<span class="token operator">:</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Double</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
      value1<span class="token operator">+</span> value2
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

  <span class="token comment">//初始化获取reducingState对象</span>
  reducingState <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getReducingState<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">(</span>reduceSum<span class="token punctuation">)</span>

<span class="token punctuation">}</span>
<span class="token keyword">override</span> <span class="token keyword">def</span> flatMap<span class="token punctuation">(</span>input<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
  <span class="token comment">//计数器+1</span>
  counter<span class="token operator">+=</span><span class="token number">1</span>

  <span class="token comment">//添加数据到reducingState</span>
  reducingState<span class="token punctuation">.</span>add<span class="token punctuation">(</span>input<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>

  out<span class="token punctuation">.</span>collect<span class="token punctuation">(</span>input<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>reducingState<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>counter<span class="token punctuation">)</span>
	<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
     </li>
    </ul>
    <h6>
     <a id="135_AggregatingState_515">
     </a>
     1.3.5 AggregatingState
    </h6>
    <ul>
     <li>
      <p>
       作用
      </p>
      <ul>
       <li>
        将相同key的数据进行聚合
       </li>
      </ul>
     </li>
     <li>
      <p>
       需求
      </p>
      <ul>
       <li>
        将相同key的数据聚合成为一个字符串
       </li>
      </ul>
     </li>
     <li>
      <p>
       代码开发
      </p>
      <pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>keystate</span>

  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>AggregateFunction<span class="token punctuation">,</span> RichFlatMapFunction<span class="token punctuation">}</span>
  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>state<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>AggregatingState<span class="token punctuation">,</span> AggregatingStateDescriptor<span class="token punctuation">}</span>
  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span></span>Configuration
  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span>state<span class="token punctuation">.</span>memory<span class="token punctuation">.</span></span>MemoryStateBackend
  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>StreamExecutionEnvironment
  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Collector
  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>_
  <span class="token comment">/**
    * 将相同key的数据聚合成为一个字符串
    */</span>
  <span class="token keyword">object</span> AggregrageStateOperate <span class="token punctuation">{<!-- --></span>

    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>

        <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment

        env<span class="token punctuation">.</span>fromCollection<span class="token punctuation">(</span>List<span class="token punctuation">(</span>
          <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">3d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">5d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> <span class="token number">7d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token punctuation">(</span><span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">4d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token punctuation">(</span><span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">2d</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token punctuation">(</span><span class="token number">2L</span><span class="token punctuation">,</span> <span class="token number">6d</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
          <span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span><span class="token keyword">new</span> AggregrageState<span class="token punctuation">)</span>
          <span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>

        env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>

    <span class="token comment">/**
      *   (1L, 3d),
          (1L, 5d),
          (1L, 7d),   把相同key的value拼接字符串：Contains-3-5-7
      */</span>
    <span class="token keyword">class</span> AggregrageState <span class="token keyword">extends</span> RichFlatMapFunction<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">{<!-- --></span>

       <span class="token comment">//定义AggregatingState</span>
      <span class="token keyword">private</span> <span class="token keyword">var</span> aggregateTotal<span class="token operator">:</span>AggregatingState<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> _

      <span class="token keyword">override</span> <span class="token keyword">def</span> <span class="token keyword">open</span><span class="token punctuation">(</span>parameters<span class="token operator">:</span> Configuration<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">/**
          * name: String,
          * aggFunction: AggregateFunction[IN, ACC, OUT],
          * stateType: Class[ACC]
          */</span>
        <span class="token keyword">val</span> aggregateStateDescriptor <span class="token operator">=</span> <span class="token keyword">new</span> AggregatingStateDescriptor<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"aggregateState"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> AggregateFunction<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token punctuation">{<!-- --></span>
               <span class="token comment">//创建一个初始值</span>
              <span class="token keyword">override</span> <span class="token keyword">def</span> createAccumulator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
                <span class="token string">"Contains"</span>
              <span class="token punctuation">}</span>

              <span class="token comment">//对数据进行累加</span>
              <span class="token keyword">override</span> <span class="token keyword">def</span> add<span class="token punctuation">(</span>value<span class="token operator">:</span> <span class="token builtin">Double</span><span class="token punctuation">,</span> accumulator<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
                accumulator <span class="token operator">+</span> <span class="token string">"-"</span> <span class="token operator">+</span> value
          <span class="token punctuation">}</span>

             <span class="token comment">//获取累加的结果</span>
            <span class="token keyword">override</span> <span class="token keyword">def</span> getResult<span class="token punctuation">(</span>accumulator<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
                accumulator
            <span class="token punctuation">}</span>

            <span class="token comment">//数据合并的规则</span>
            <span class="token keyword">override</span> <span class="token keyword">def</span> merge<span class="token punctuation">(</span>a<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> b<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
                a <span class="token operator">+</span> <span class="token string">"-"</span> <span class="token operator">+</span> b
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token comment">//获取AggregatingState对象</span>
          aggregateTotal <span class="token operator">=</span> getRuntimeContext<span class="token punctuation">.</span>getAggregatingState<span class="token punctuation">(</span>aggregateStateDescriptor<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>

      <span class="token keyword">override</span> <span class="token keyword">def</span> flatMap<span class="token punctuation">(</span>input<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
          aggregateTotal<span class="token punctuation">.</span>add<span class="token punctuation">(</span>input<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>
          out<span class="token punctuation">.</span>collect<span class="token punctuation">(</span>input<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>aggregateTotal<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>

  <span class="token punctuation">}</span>

</code></pre>
     </li>
    </ul>
    <h5>
     <a id="14__Operator_State_614">
     </a>
     1.4 Operator State案例演示
    </h5>
    <ul>
     <li>
      需求
      <ul>
       <li>
        <p>
         实现每两条数据进行输出打印一次，不用区分数据的key
        </p>
       </li>
       <li>
        <p>
         这里使用ListState实现
        </p>
        <pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>operatorstate</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>functions<span class="token punctuation">.</span>sink<span class="token punctuation">.</span></span>SinkFunction
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataStream<span class="token punctuation">,</span> StreamExecutionEnvironment<span class="token punctuation">}</span>

<span class="token keyword">import</span> <span class="token namespace">scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>mutable<span class="token punctuation">.</span></span>ListBuffer

<span class="token comment">/**
  * 实现每两条数据进行输出打印一次，不用区分数据的key
  */</span>
<span class="token keyword">object</span> OperatorListState <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>_
    <span class="token keyword">val</span> sourceStream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> env<span class="token punctuation">.</span>fromCollection<span class="token punctuation">(</span>List<span class="token punctuation">(</span>
        <span class="token punctuation">(</span><span class="token string">"spark"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"hadoop"</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"hive"</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"flume"</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">)</span>

    sourceStream<span class="token punctuation">.</span>addSink<span class="token punctuation">(</span><span class="token keyword">new</span> OperateTaskState<span class="token punctuation">)</span><span class="token punctuation">.</span>setParallelism<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

    env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

<span class="token punctuation">}</span>

<span class="token keyword">class</span> OperateTaskState <span class="token keyword">extends</span> SinkFunction<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">{<!-- --></span>
  <span class="token comment">//定义一个list 用于我们每两条数据打印一下</span>
  <span class="token keyword">private</span> <span class="token keyword">var</span> listBuffer<span class="token operator">:</span>ListBuffer<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">new</span> ListBuffer<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> invoke<span class="token punctuation">(</span>value<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">,</span> context<span class="token operator">:</span> SinkFunction<span class="token punctuation">.</span>Context<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    listBuffer<span class="token punctuation">.</span>+<span class="token operator">=</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span>

    <span class="token keyword">if</span><span class="token punctuation">(</span>listBuffer<span class="token punctuation">.</span>size <span class="token operator">==</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
       println<span class="token punctuation">(</span>listBuffer<span class="token punctuation">)</span>

      <span class="token comment">//清空state状态</span>
      listBuffer<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>

<span class="token punctuation">}</span>



</code></pre>
       </li>
      </ul>
     </li>
    </ul>
    <h3>
     <a id="book_2_FlinkState_Backend_677">
     </a>
     📖 2. Flink的状态管理之State Backend
    </h3>
    <ul>
     <li>
      默认情况下，state会保存在taskmanager的内存中，checkpoint会存储在JobManager的内存中。state 的存储和checkpoint的位置取决于State Backend的配置。
     </li>
     <li>
      <mark>
       Flink一共提供了3种StateBackend
      </mark>
      <ul>
       <li>
        MemoryStateBackend
        <ul>
         <li>
          基于内存存储
         </li>
        </ul>
       </li>
       <li>
        FsStateBackend
        <ul>
         <li>
          基于文件系统存储
         </li>
        </ul>
       </li>
       <li>
        RocksDBStateBackend
        <ul>
         <li>
          基于数据库存储
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li>
      可以通过 ==StreamExecutionEnvironment.setStateBackend(…)==来设置state存储的位置
     </li>
    </ul>
    <h5>
     <a id="21_MemoryStateBackend_689">
     </a>
     2.1 MemoryStateBackend
    </h5>
    <pre><code>	将数据持久化状态存储到内存当中，state数据保存在java堆内存中，
	执行checkpoint的时候，会把state的快照数据保存到jobmanager的内存中。
	基于内存的state backend在生产环境下不建议使用。
</code></pre>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/27e4b9cc4ddc4517b0eb43b1ee5c883b.png"/>
    </p>
    <ul>
     <li>
      代码配置：
     </li>
    </ul>
    <pre><code class="prism language-scala">environment<span class="token punctuation">.</span>setStateBackend<span class="token punctuation">(</span><span class="token keyword">new</span> MemoryStateBackend<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <ul>
     <li>
      使用场景：
     </li>
    </ul>
    <pre><code>（1）本地调试
（2）flink任务状态数据量较小的场景
</code></pre>
    <h5>
     <a id="22__FsStateBackend_717">
     </a>
     2.2 FsStateBackend
    </h5>
    <pre><code>	state数据保存在taskmanager的内存中，
	执行checkpoint的时候，会把state的快照数据保存到配置的文件系统中。
	可以使用hdfs等分布式文件系统.
	
	FsStateBackend 适合场景：状态数据特别的多，还有长时间的window算子等，它很安全，因为基于hdfs，所以数据有备份很安全。
</code></pre>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/09e2a888ee9e496688f236c6fcd139d7.png"/>
    </p>
    <ul>
     <li>
      代码配置：
     </li>
    </ul>
    <pre><code class="prism language-scala">environment<span class="token punctuation">.</span>setStateBackend<span class="token punctuation">(</span><span class="token keyword">new</span> FsStateBackend<span class="token punctuation">(</span><span class="token string">"hdfs://node01:8020/flink/checkDir"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <ul>
     <li>
      适用场景：
     </li>
    </ul>
    <pre><code>（1）大状态、长窗口、大key/value状态的的任务
（2）全高可用配置
</code></pre>
    <h5>
     <a id="23__RocksDBStateBackend____743">
     </a>
     2.3 RocksDBStateBackend （生产中推荐）
    </h5>
    <pre><code>RocksDB介绍：
	RocksDB使用一套日志结构的数据库引擎，
	它是Flink中内置的第三方状态管理器,为了更好的性能，这套引擎是用C++编写的。 
	Key和value是任意大小的字节流。
	RocksDB跟上面的都略有不同，它会在本地文件系统中维护状态，state会直接写入本地rocksdb中。
	同时它需要配置一个远端的filesystem uri（一般是HDFS），在做checkpoint的时候，会把本地的数据直接复制到fileSystem中。
	fail over的时候从fileSystem中恢复到本地RocksDB克服了state受内存限制的缺点，同时又能够持久化到远端文件系统中，比较适合在生产中使用.
</code></pre>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b4675ce8b5ca485ca906877aadce5600.png"/>
    </p>
    <ul>
     <li>
      代码配置：导入jar包然后配置代码
     </li>
    </ul>
    <pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-statebackend-rocksdb_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.9.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre>
    <ul>
     <li>
      配置代码
     </li>
    </ul>
    <pre><code class="prism language-scala">environment<span class="token punctuation">.</span>setStateBackend<span class="token punctuation">(</span><span class="token keyword">new</span> RocksDBStateBackend<span class="token punctuation">(</span><span class="token string">"hdfs://node01:8020/flink/checkDir"</span><span class="token punctuation">,</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <ul>
     <li>
      使用场景
     </li>
    </ul>
    <pre><code>（1）大状态、长窗口、大key/value状态的的任务
（2）全高可用配置

    由于RocksDBStateBackend将工作状态存储在taskManger的本地文件系统，状态数量仅仅受限于本地磁盘容量限制，对比于FsStateBackend保存工作状态在内存中，RocksDBStateBackend能避免flink任务持续运行可能导致的状态数量暴增而内存不足的情况，因此适合在生产环境使用。

</code></pre>
    <h5>
     <a id="24__statebackend_788">
     </a>
     2.4 修改state-backend的两种方式
    </h5>
    <ul>
     <li>
      第一种：单任务调整
      <ul>
       <li>
        修改当前任务代码
       </li>
      </ul>
     </li>
    </ul>
    <pre><code class="prism language-scala">env<span class="token punctuation">.</span>setStateBackend<span class="token punctuation">(</span>
<span class="token keyword">new</span> FsStateBackend<span class="token punctuation">(</span><span class="token string">"hdfs://node01:8020/flink/checkDir"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
或者<span class="token keyword">new</span> MemoryStateBackend<span class="token punctuation">(</span><span class="token punctuation">)</span>
或者<span class="token keyword">new</span> RocksDBStateBackend<span class="token punctuation">(</span>filebackend<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>【需要添加第三方依赖】
</code></pre>
    <ul>
     <li>
      <p>
       第二种：全局调整
      </p>
      <ul>
       <li>
        修改flink-conf.yaml
       </li>
      </ul>
      <pre><code class="prism language-yaml"><span class="token key atrule">state.backend</span><span class="token punctuation">:</span> filesystem
<span class="token key atrule">state.checkpoints.dir</span><span class="token punctuation">:</span> hdfs<span class="token punctuation">:</span>//node01<span class="token punctuation">:</span>8020/flink/checkDir
</code></pre>
      <ul>
       <li>
        注意：state.backend的值可以是下面几种
       </li>
      </ul>
      <pre><code>(1) jobmanager    表示使用 MemoryStateBackend
(2) filesystem    表示使用 FsStateBackend
(3) rocksdb       表示使用 RocksDBStateBackend
</code></pre>
     </li>
    </ul>
    <h3>
     <a id="book_3_FlinkcheckPoint_818">
     </a>
     📖 3. Flink的checkPoint保存数据实现容错
    </h3>
    <h5>
     <a id="31_checkPoint_820">
     </a>
     3.1 checkPoint的基本概念
    </h5>
    <pre><code>为了保证state的容错性，Flink需要对state进行checkpoint。

	Checkpoint是Flink实现容错机制最核心的功能，它能够根据配置周期性地基于Stream中各个Operator/task的状态来生成快照，从而将这些状态数据定期持久化存储下来，当Flink程序一旦意外崩溃时，重新运行程序时可以有选择地从这些快照进行恢复，从而修正因为故障带来的程序数据异常。

</code></pre>
    <h5>
     <a id="32__checkPoint_831">
     </a>
     3.2 checkPoint的前提
    </h5>
    <ul>
     <li>
      Flink的checkpoint机制可以与(stream和state)的持久化存储交互的前提
      <ul>
       <li>
        <p>
         1、持久化的source，它需要支持在一定时间内重放事件。这种sources的典型例子是持久化的消息队列（比如Apache Kafka，RabbitMQ等）或文件系统（比如HDFS，S3，GFS等）
        </p>
       </li>
       <li>
        <p>
         2、用于state的持久化存储，例如分布式文件系统（比如HDFS，S3，GFS等）
        </p>
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <a id="33_Flinkcheckpoint_840">
     </a>
     3.3 Flink进行checkpoint步骤
    </h5>
    <ul>
     <li>
      （1）暂停新数据的输入
     </li>
     <li>
      （2）等待流中on-the-fly的数据被处理干净，此时得到flink graph的一个snapshot
     </li>
     <li>
      （3）将所有Task中的State拷贝到State Backend中，如HDFS。此动作由各个Task Manager完成
     </li>
     <li>
      （4）各个Task Manager将Task State的位置上报给Job Manager，完成checkpoint
     </li>
     <li>
      （5）恢复数据的输入
     </li>
    </ul>
    <blockquote>
     <p>
      如上所述，这里才需要“暂停输入 + 排干on-the-fly 数据”的操作，这样才能拿到同一时刻下所有subtask的state
     </p>
    </blockquote>
    <h5>
     <a id="34__checkPoint_853">
     </a>
     3.4 配置checkPoint
    </h5>
    <ul>
     <li>
      <p>
       默认checkpoint功能是disabled的，想要使用的时候需要先启用
      </p>
     </li>
     <li>
      <p>
       checkpoint开启之后，默认的checkPointMode是Exactly-once
      </p>
     </li>
     <li>
      <p>
       checkpoint的checkPointMode有两种
      </p>
      <ul>
       <li>
        Exactly-once: 数据处理且只被处理一次
       </li>
       <li>
        At-least-once：数据至少被处理一次
       </li>
      </ul>
     </li>
    </ul>
    <p>
     Exactly-once对于大多数应用来说是最合适的。At-least-once可能用在某些延迟超低的应用程序（始终延迟为几毫秒）
    </p>
    <pre><code class="prism language-scala"><span class="token comment">//默认checkpoint功能是disabled的，想要使用的时候需要先启用</span>
<span class="token comment">// 每隔1000 ms进行启动一个检查点【设置checkpoint的周期】</span>
environment<span class="token punctuation">.</span>enableCheckpointing<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 高级选项：</span>
<span class="token comment">// 设置模式为exactly-once （这是默认值）</span>
environment<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointingMode<span class="token punctuation">(</span>CheckpointingMode<span class="token punctuation">.</span>EXACTLY_ONCE<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 确保检查点之间有至少500 ms的间隔【checkpoint最小间隔】</span>
environment<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setMinPauseBetweenCheckpoints<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 检查点必须在一分钟内完成，或者被丢弃【checkpoint的超时时间】</span>
environment<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointTimeout<span class="token punctuation">(</span><span class="token number">60000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 同一时间只允许进行一个检查点</span>
environment<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setMaxConcurrentCheckpoints<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 表示一旦Flink处理程序被cancel后，会保留Checkpoint数据，以便根据实际需要恢复到指定的Checkpoint【详细解释见备注】</span>

<span class="token comment">/**
  * ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION:表示一旦Flink处理程序被cancel后，会保留Checkpoint数据，以便根据实际需要恢复到指定的Checkpoint
  * ExternalizedCheckpointCleanup.DELETE_ON_CANCELLATION: 表示一旦Flink处理程序被cancel后，会删除Checkpoint数据，只有job执行失败的时候才会保存checkpoint
  */</span>
environment<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>enableExternalizedCheckpoints<span class="token punctuation">(</span>ExternalizedCheckpointCleanup<span class="token punctuation">.</span>RETAIN_ON_CANCELLATION<span class="token punctuation">)</span><span class="token punctuation">;</span>

</code></pre>
    <h5>
     <a id="star35___890">
     </a>
     ⭐️3.5 重启策略概述
    </h5>
    <ul>
     <li>
      Flink支持不同的重启策略，以在故障发生时控制作业如何重启，集群在启动时会伴随一个默认的重启策略，在没有定义具体重启策略时会使用该默认策略。
     </li>
     <li>
      如果在工作提交时指定了一个重启策略，该策略会覆盖集群的默认策略，默认的重启策略可以通过 Flink 的配置文件 flink-conf.yaml 指定。配置参数 restart-strategy 定义了哪个策略被使用。
     </li>
     <li>
      常用的重启策略
      <ul>
       <li>
        （1）固定间隔 (Fixed delay)
       </li>
       <li>
        （2）失败率 (Failure rate)
       </li>
       <li>
        （3）无重启 (No restart)
       </li>
      </ul>
     </li>
     <li>
      如果没有启用 checkpointing，则使用无重启 (no restart) 策略。
     </li>
     <li>
      如果启用了 checkpointing，重启策略可以在
      <mark>
       flink-conf.yaml
      </mark>
      中配置，表示全局的配置。也可以在应用代码中动态指定，会覆盖全局配置
      <ul>
       <li>
        但没有配置重启策略，则使用固定间隔 (fixed-delay) 策略， 尝试重启次数默认值是：Integer.MAX_VALUE，。
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <a id="36___902">
     </a>
     3.6 重启策略配置实现
    </h5>
    <ul>
     <li>
      固定间隔 (Fixed delay)
     </li>
    </ul>
    <pre><code class="prism language-properties">第一种：全局配置 flink-conf.yaml
restart-strategy: fixed-delay
restart-strategy.fixed-delay.attempts: 3
restart-strategy.fixed-delay.delay: 10 s

第二种：应用代码设置
	//重启次数、重启时间间隔
environment.setRestartStrategy(RestartStrategies.fixedDelayRestart(3,10000))

</code></pre>
    <ul>
     <li>
      失败率 (Failure rate)
     </li>
    </ul>
    <pre><code class="prism language-properties">第一种：全局配置 flink-conf.yaml
//5分钟内若失败了3次则认为该job失败，重试间隔为10s
restart-strategy: failure-rate
restart-strategy.failure-rate.max-failures-per-interval: 3
restart-strategy.failure-rate.failure-rate-interval: 5 min
restart-strategy.failure-rate.delay: 10 s


第二种：应用代码设置
environment.setRestartStrategy(RestartStrategies.failureRateRestart(3, org.apache.flink.api.common.time.Time.seconds(100), org.apache.flink.api.common.time.Time.seconds(10)))

</code></pre>
    <ul>
     <li>
      无重启 (No restart)
     </li>
    </ul>
    <pre><code class="prism language-properties">第一种：全局配置 flink-conf.yaml
restart-strategy: none

第二种：应用代码设置
environment.setRestartStrategy(RestartStrategies.noRestart())

</code></pre>
    <h3>
     <a id="starbook_4__checkPointcheckPoint_947">
     </a>
     ⭐️📖 4. 从checkPoint恢复数据以及checkPoint保存多个历史版本
    </h3>
    <h5>
     <a id="41___949">
     </a>
     4.1 保存多个历史版本
    </h5>
    <ul>
     <li>
      <p>
       默认情况下，如果设置了Checkpoint选项，则Flink只保留最近成功生成的1个Checkpoint，而当Flink程序失败时，可以从最近的这个Checkpoint来进行恢复。
      </p>
     </li>
     <li>
      <p>
       如果我们希望保留多个Checkpoint，并能够根据实际需要
       <mark>
        选择其中一个进行恢复
       </mark>
       ，这样会更加灵活，比如，我们发现最近4个小时数据记录处理有问题，希望将整个状态还原到4小时之前
      </p>
     </li>
     <li>
      <p>
       Flink可以支持保留多个Checkpoint，需要在Flink的配置文件
       <mark>
        conf/flink-conf.yaml
       </mark>
       中，添加如下配置，指定最多需要保存Checkpoint的个数。
      </p>
     </li>
    </ul>
    <pre><code class="prism language-yaml"><span class="token key atrule">state.checkpoints.num-retained</span><span class="token punctuation">:</span> <span class="token number">20</span>
</code></pre>
    <ul>
     <li>
      这样设置以后就查看对应的Checkpoint在HDFS上存储的文件目录
     </li>
    </ul>
    <pre><code class="prism language-yaml">hdfs dfs <span class="token punctuation">-</span>ls hdfs<span class="token punctuation">:</span>//node01<span class="token punctuation">:</span>8020/flink/checkpoints
</code></pre>
    <ul>
     <li>
      如果希望回退到某个Checkpoint点，只需要指定对应的某个Checkpoint路径即可实现
     </li>
    </ul>
    <h5>
     <a id="42__968">
     </a>
     4.2 恢复历史某个版本数据
    </h5>
    <ul>
     <li>
      如果Flink程序异常失败，或者最近一段时间内数据处理错误，我们可以将程序从某一个Checkpoint点进行恢复
     </li>
    </ul>
    <pre><code class="prism language-scala">flink run <span class="token operator">-</span>m yarn<span class="token operator">-</span>cluster <span class="token operator">-</span>yn <span class="token number">2</span> <span class="token operator">-</span>yjm <span class="token number">1024</span> <span class="token operator">-</span>ytm <span class="token number">1024</span> <span class="token operator">-</span>s hdfs<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>node01<span class="token operator">:</span><span class="token number">8020</span><span class="token operator">/</span>fsStateBackend<span class="token operator">/</span><span class="token number">971</span>ae7ac4d5f20e704747ea7c549b356<span class="token operator">/</span>chk<span class="token operator">-</span><span class="token number">50</span><span class="token operator">/</span>_metadata <span class="token operator">-</span>c com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>checkpoint<span class="token punctuation">.</span>TestCheckPoint original<span class="token operator">-</span>flink_study<span class="token operator">-</span><span class="token number">1.0</span><span class="token operator">-</span>SNAPSHOT<span class="token punctuation">.</span>jar
</code></pre>
    <ul>
     <li>
      程序正常运行后，还会按照Checkpoint配置进行运行，继续生成Checkpoint数据
     </li>
    </ul>
    <h3>
     <a id="book_5_FlinksavePoint_980">
     </a>
     📖 5. Flink的savePoint保存数据
    </h3>
    <h5>
     <a id="51_savePoint_982">
     </a>
     5.1 savePoint的介绍
    </h5>
    <ul>
     <li>
      <p>
       savePoint是检查点一种特殊实现，底层其实也是使用Checkpoints的机制。
      </p>
     </li>
     <li>
      <p>
       savePoint是用户以手工命令的方式触发checkpoint，并将结果持久化到指定的存储目录中
      </p>
     </li>
     <li>
      <p>
       作用
      </p>
      <ul>
       <li>
        <mark>
         1、应用程序代码升级
        </mark>
        <ul>
         <li>
          通过触发保存点并从该保存点处运行新版本，下游的应用程序并不会察觉到不同
         </li>
        </ul>
       </li>
       <li>
        <mark>
         2、Flink版本更新
        </mark>
        <ul>
         <li>
          Flink 自身的更新也变得简单，因为可以针对正在运行的任务触发保存点，并从保存点处用新版本的 Flink 重启任务。
         </li>
        </ul>
       </li>
       <li>
        <mark>
         3、维护和迁移
        </mark>
        <ul>
         <li>
          使用保存点，可以轻松地“暂停和恢复”应用程序
         </li>
        </ul>
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <a id="52_savePoint_995">
     </a>
     5.2 savePoint的使用
    </h5>
    <ul>
     <li>
      1：在flink-conf.yaml中配置Savepoint存储位置
     </li>
    </ul>
    <p>
     不是必须设置，但是设置后，后面创建指定Job的Savepoint时，可以不用在手动执行命令时指定Savepoint的位置
    </p>
    <pre><code class="prism language-yaml"><span class="token key atrule">state.savepoints.dir</span><span class="token punctuation">:</span> hdfs<span class="token punctuation">:</span>//node01<span class="token punctuation">:</span>8020/flink/savepoints
</code></pre>
    <ul>
     <li>
      <p>
       2：触发一个savepoint
      </p>
      <ul>
       <li>
        <p>
         （1）手动触发savepoint
        </p>
        <pre><code class="prism language-shell">
<span class="token comment">#【针对on standAlone模式】</span>
bin/flink savepoint jobId <span class="token punctuation">[</span>targetDirectory<span class="token punctuation">]</span> 

<span class="token comment">#【针对on yarn模式需要指定-yid参数】</span>
bin/flink savepoint jobId <span class="token punctuation">[</span>targetDirectory<span class="token punctuation">]</span> <span class="token punctuation">[</span>-yid yarnAppId<span class="token punctuation">]</span>

<span class="token comment">#jobId 				需要触发savepoint的jobId编号</span>
<span class="token comment">#targetDirectory     指定savepoint存储数据目录</span>
<span class="token comment">#-yid                指定yarnAppId </span>

<span class="token comment">##例如：</span>
flink savepoint 8d1bb7f88a486815f9b9cf97c304885b  <span class="token parameter variable">-yid</span> application_1594807273214_0004
</code></pre>
       </li>
       <li>
        <p>
         （2）取消任务并手动触发savepoint
        </p>
        <pre><code class="prism language-shell"><span class="token comment">##【针对on standAlone模式】</span>
bin/flink cancel <span class="token parameter variable">-s</span> <span class="token punctuation">[</span>targetDirectory<span class="token punctuation">]</span> jobId 

<span class="token comment">##【针对on yarn模式需要指定-yid参数】</span>
bin/flink cancel <span class="token parameter variable">-s</span> <span class="token punctuation">[</span>targetDirectory<span class="token punctuation">]</span> jobId <span class="token punctuation">[</span>-yid yarnAppId<span class="token punctuation">]</span>

<span class="token comment">##例如：</span>
flink cancel 8d1bb7f88a486815f9b9cf97c304885b <span class="token parameter variable">-yid</span> application_1594807273214_0004
</code></pre>
       </li>
      </ul>
     </li>
     <li>
      <p>
       3：从指定的savepoint启动job
      </p>
      <pre><code class="prism language-shell">bin/flink run <span class="token parameter variable">-s</span> savepointPath <span class="token punctuation">[</span>runArgs<span class="token punctuation">]</span>

<span class="token comment">##例如：</span>
flink run <span class="token parameter variable">-m</span> yarn-cluster <span class="token parameter variable">-yn</span> <span class="token number">2</span> <span class="token parameter variable">-yjm</span> <span class="token number">1024</span> <span class="token parameter variable">-ytm</span> <span class="token number">1024</span> <span class="token parameter variable">-s</span> hdfs://node01:8020/flink/savepoints/savepoint-8d1bb7-c9187993ca94 <span class="token parameter variable">-c</span> com.kaikeba.checkpoint.TestCheckPoint original-flink_study-1.0-SNAPSHOT.jar

</code></pre>
     </li>
     <li>
      <p>
       4、清除savepoint数据
      </p>
      <pre><code class="prism language-shell">bin/flink savepoint <span class="token parameter variable">-d</span> savepointPath
</code></pre>
     </li>
    </ul>
    <h3>
     <a id="book_6__Flinkkafka_1062">
     </a>
     📖 6. Flink流式处理集成kafka
    </h3>
    <ul>
     <li>
      <p>
       对于实时处理当中，我们实际工作当中的数据源一般都是使用kafka，所以我们一起来看看如何通过Flink来集成kafka
      </p>
     </li>
     <li>
      <p>
       Flink提供了一个特有的kafka connector去读写kafka topic的数据。flink消费kafka数据，并不是完全通过跟踪kafka消费组的offset来实现去保证exactly-once的语义，而是flink内部去跟踪offset和做checkpoint去实现exactly-once的语义，而且对于kafka的partition，Flink会启动对应的并行度去处理kafka当中的每个分区的数据
      </p>
     </li>
     <li>
      <p>
       Flink整合kafka官网介绍
      </p>
      <ul>
       <li>
        https://ci.apache.org/projects/flink/flink-docs-release-1.9/dev/connectors/kafka.html
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <a id="61_pom_1071">
     </a>
     6.1 导入pom依赖
    </h5>
    <pre><code class="prism language-xml"><span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-connector-kafka --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-connector-kafka_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.9.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-statebackend-rocksdb_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.9.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.kafka<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>kafka-clients<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.slf4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>slf4j-api<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.7.25<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.slf4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>slf4j-log4j12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.7.25<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre>
    <h5>
     <a id="62_kafkaflinksource_1104">
     </a>
     6.2 将kafka作为flink的source来使用
    </h5>
    <ul>
     <li>
      实际工作当中一般都是将kafka作为flink的source来使用
     </li>
    </ul>
    <h6>
     <a id="621_kafkatopic_1108">
     </a>
     6.2.1 创建kafka的topic
    </h6>
    <ul>
     <li>
      安装好kafka集群，并启动kafka集群，然后在node01执行以下命令创建kafka的topic为test
     </li>
    </ul>
    <pre><code class="prism language-shell">kafka-topics.sh <span class="token parameter variable">--create</span> <span class="token parameter variable">--partitions</span> <span class="token number">3</span> <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> --replication-factor <span class="token number">1</span> <span class="token parameter variable">--zookeeper</span> node01:2181,node02:2181,node03:2181
</code></pre>
    <h6>
     <a id="622__1116">
     </a>
     6.2.2 代码实现：
    </h6>
    <pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>kafka</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Properties

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>state<span class="token punctuation">.</span></span>RocksDBStateBackend
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span></span>CheckpointingMode
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span>CheckpointConfig
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataStream<span class="token punctuation">,</span> StreamExecutionEnvironment<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span>FlinkKafkaConsumer
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>util<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span>SimpleStringSchema

<span class="token comment">/**
  *  将kafka作为flink的source来使用
  */</span>
<span class="token keyword">object</span> FlinkKafkaSource <span class="token punctuation">{<!-- --></span>

  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token comment">//**隐式转换</span>
    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>_
    <span class="token comment">//checkpoint**配置</span>
    env<span class="token punctuation">.</span>enableCheckpointing<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>
    env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointingMode<span class="token punctuation">(</span>CheckpointingMode<span class="token punctuation">.</span>EXACTLY_ONCE<span class="token punctuation">)</span>
    env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setMinPauseBetweenCheckpoints<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>
    env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointTimeout<span class="token punctuation">(</span><span class="token number">60000</span><span class="token punctuation">)</span>
    env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setMaxConcurrentCheckpoints<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>enableExternalizedCheckpoints<span class="token punctuation">(</span>CheckpointConfig<span class="token punctuation">.</span>ExternalizedCheckpointCleanup<span class="token punctuation">.</span>RETAIN_ON_CANCELLATION<span class="token punctuation">)</span>
    <span class="token comment">//设置statebackend</span>
    env<span class="token punctuation">.</span>setStateBackend<span class="token punctuation">(</span><span class="token keyword">new</span> RocksDBStateBackend<span class="token punctuation">(</span><span class="token string">"hdfs://node01:8020/flink_kafka_sink/checkpoints"</span><span class="token punctuation">,</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">val</span> topic <span class="token operator">=</span> <span class="token string">"test"</span>
    <span class="token keyword">val</span> prop <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>
    prop<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span><span class="token string">"node01:9092,node02:9092,node03:9092"</span><span class="token punctuation">)</span>
    prop<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span><span class="token string">"con1"</span><span class="token punctuation">)</span>
    prop<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    prop<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">val</span> kafkaConsumer <span class="token operator">=</span> <span class="token keyword">new</span> FlinkKafkaConsumer<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"test"</span><span class="token punctuation">,</span><span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">,</span>prop<span class="token punctuation">)</span>
    kafkaConsumer<span class="token punctuation">.</span>setCommitOffsetsOnCheckpoints<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> kafkaSource<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> env<span class="token punctuation">.</span>addSource<span class="token punctuation">(</span>kafkaConsumer<span class="token punctuation">)</span>
    kafkaSource<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>


  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre>
    <h6>
     <a id="623_kafka_1169">
     </a>
     6.2.3 kafka生产数据
    </h6>
    <ul>
     <li>
      node01执行以下命令，通过shell命令行来生产数据到kafka当中去
     </li>
    </ul>
    <pre><code class="prism language-shell"><span class="token comment">##创建topic</span>
 kafka-topics.sh <span class="token parameter variable">--create</span> <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> <span class="token parameter variable">--partitions</span> <span class="token number">3</span> --replication-factor <span class="token number">2</span> <span class="token parameter variable">--zookeeper</span> node01:2181,node02:2181,node03:2181 

<span class="token comment">##发送数据</span>
kafka-console-producer.sh --broker-list node01:9092,node02:9092,node03:9092 <span class="token parameter variable">--topic</span>  <span class="token builtin class-name">test</span>
</code></pre>
    <h5>
     <a id="63_kafkaflinksink_1183">
     </a>
     6.3 将kafka作为flink的sink来使用
    </h5>
    <ul>
     <li>
      我们也可以将kafka作为flink的sink来使用，就是将flink处理完成之后的数据写入到kafka当中去
     </li>
    </ul>
    <h6>
     <a id="631_socket_1187">
     </a>
     6.3.1 socket发送数据
    </h6>
    <ul>
     <li>
      node01执行以下命令，从socket当中发送数据
     </li>
    </ul>
    <pre><code> nc -lk 9999
</code></pre>
    <h6>
     <a id="632__1195">
     </a>
     6.3.2 代码实现
    </h6>
    <pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>kafka</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Properties

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>state<span class="token punctuation">.</span></span>RocksDBStateBackend
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span></span>CheckpointingMode
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span>CheckpointConfig
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>StreamExecutionEnvironment
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span>FlinkKafkaProducer
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>internals<span class="token punctuation">.</span></span>KeyedSerializationSchemaWrapper
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>util<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span>SimpleStringSchema

<span class="token comment">/**
  * 将kafka作为flink的sink来使用
  */</span>
<span class="token keyword">object</span> FlinkKafkaSink <span class="token punctuation">{<!-- --></span>

  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> env <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token comment">//隐式转换</span>
    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>_
      
    <span class="token comment">//checkpoint配置</span>
    env<span class="token punctuation">.</span>enableCheckpointing<span class="token punctuation">(</span><span class="token number">5000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointingMode<span class="token punctuation">(</span>CheckpointingMode<span class="token punctuation">.</span>EXACTLY_ONCE<span class="token punctuation">)</span><span class="token punctuation">;</span>
    env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setMinPauseBetweenCheckpoints<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointTimeout<span class="token punctuation">(</span><span class="token number">60000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setMaxConcurrentCheckpoints<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>enableExternalizedCheckpoints<span class="token punctuation">(</span>CheckpointConfig<span class="token punctuation">.</span>ExternalizedCheckpointCleanup<span class="token punctuation">.</span>RETAIN_ON_CANCELLATION<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">//设置statebackend</span>
    env<span class="token punctuation">.</span>setStateBackend<span class="token punctuation">(</span><span class="token keyword">new</span> RocksDBStateBackend<span class="token punctuation">(</span><span class="token string">"hdfs://node01:8020/flink_kafka_sink/checkpoints"</span><span class="token punctuation">,</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">val</span> socketStream <span class="token operator">=</span> env<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"node01"</span><span class="token punctuation">,</span><span class="token number">9999</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> topic <span class="token operator">=</span> <span class="token string">"test"</span>
    <span class="token keyword">val</span> prop <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>
    prop<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span><span class="token string">"node01:9092,node02:9092,node03:9092"</span><span class="token punctuation">)</span>
    prop<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span><span class="token string">"kafka_group1"</span><span class="token punctuation">)</span>
    <span class="token comment">//第一种解决方案，设置FlinkKafkaProducer里面的事务超时时间</span>
    <span class="token comment">//设置事务超时时间</span>
    prop<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"transaction.timeout.ms"</span><span class="token punctuation">,</span><span class="token number">60000</span><span class="token operator">*</span><span class="token number">15</span><span class="token operator">+</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      
    <span class="token comment">//第二种解决方案，设置kafka的最大事务超时时间</span>
    <span class="token comment">//FlinkKafkaProducer011&lt;String&gt; myProducer = new FlinkKafkaProducer&lt;&gt;(brokerList, topic, new SimpleStringSchema());</span>
    
      <span class="token comment">//使用支持仅一次语义的形式</span>
    <span class="token comment">/**
      * defaultTopic: String,
      * serializationSchema: KafkaSerializationSchema[IN],
      * producerConfig: Properties,
      * semantic: FlinkKafkaProducer.Semantic
      */</span>
    <span class="token keyword">val</span> kafkaSink <span class="token operator">=</span> <span class="token keyword">new</span> FlinkKafkaProducer<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span><span class="token keyword">new</span> KeyedSerializationSchemaWrapper<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token keyword">new</span> SimpleStringSchema<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> prop<span class="token punctuation">,</span>FlinkKafkaProducer<span class="token punctuation">.</span>Semantic<span class="token punctuation">.</span>EXACTLY_ONCE<span class="token punctuation">)</span>
    socketStream<span class="token punctuation">.</span>addSink<span class="token punctuation">(</span>kafkaSink<span class="token punctuation">)</span>

    env<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"StreamingFromCollectionScala"</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre>
    <h6>
     <a id="633_kafka_1258">
     </a>
     6.3.3 启动kafka消费者
    </h6>
    <ul>
     <li>
      node01执行以下命令启动kafka消费者，消费数据
     </li>
    </ul>
    <pre><code class="prism language-shell">kafka-console-consumer.sh --bootstrap-server node01:9092,node02:9092,node03:9092 <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span>
</code></pre>
    <h3>
     <a id="book_7_Flinkwindow_1268">
     </a>
     📖 7. Flink当中的window窗口
    </h3>
    <ul>
     <li>
      <p>
       对于流式处理，如果我们需要求取总和，平均值，或者最大值，最小值等，是做不到的，因为数据一直在源源不断的产生，即数据是没有边界的，所以没法求最大值，最小值，平均值等，所以为了一些数值统计的功能，我们必须指定时间段，对某一段时间的数据求取一些数据值是可以做到的。或者对某一些数据求取数据值也是可以做到的
      </p>
     </li>
     <li>
      <p>
       所以，流上的聚合需要由 window 来划定范围，比如 “计算过去的5分钟” ，或者 “最后100个元素的和” 。
      </p>
     </li>
     <li>
      <p>
       window是一种可以把无限数据切割为有限数据块的手段
      </p>
      <ul>
       <li>
        窗口可以是 时间驱动的 【Time Window】（比如：每30秒）
       </li>
       <li>
        或者 数据驱动的【Count Window】 （比如：每100个元素）
        <br/>
        <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/4227af9b6b1649c1ae6cf7d42ff85515.png"/>
       </li>
      </ul>
     </li>
     <li>
      <p>
       窗口类型汇总：
       <br/>
       <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/673373c734034a11913cb93e065daf57.png"/>
      </p>
     </li>
    </ul>
    <h5>
     <a id="71__1285">
     </a>
     7.1 窗口的基本类型介绍
    </h5>
    <ul>
     <li>
      窗口通常被区分为不同的类型:
      <ul>
       <li>
        <p>
         tumbling windows：滚动窗口 【没有重叠】
        </p>
        <ul>
         <li>
          滚动窗口下窗口之间之间不重叠，且窗口长度是固定的
         </li>
        </ul>
        <p>
         <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b1fc82b047bf4ea39da2ba30fe5f0112.png"/>
        </p>
       </li>
       <li>
        <p>
         sliding windows：滑动窗口 【有重叠】
        </p>
        <ul>
         <li>
          滑动窗口以一个步长（Slide）不断向前滑动，窗口的长度固定
         </li>
        </ul>
        <p>
         <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/e8696432522643728c428c75c4c3d797.png"/>
        </p>
       </li>
       <li>
        <p>
         session windows：会话窗口 ，一般没人用
        </p>
        <ul>
         <li>
          Session window的窗口大小，则是由数据本身决定，它没有固定的开始和结束时间。
         </li>
         <li>
          会话窗口根据Session gap切分不同的窗口，当一个窗口在大于Session gap的时间内没有接收到新数据时，窗口将关闭
         </li>
        </ul>
       </li>
      </ul>
     </li>
    </ul>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/eb12d356819d475b8677ce6ee2b6c2bb.png"/>
    </p>
    <h5>
     <a id="72__Flink_1311">
     </a>
     7.2 Flink的窗口介绍
    </h5>
    <h6>
     <a id="721_Time_Window_1313">
     </a>
     7.2.1 Time Window窗口的应用
    </h6>
    <ul>
     <li>
      time window又分为滚动窗口和滑动窗口，这两种窗口调用方法都是一样的，都是调用timeWindow这个方法，如果传入
      <mark>
       一个参数就是滚动窗口
      </mark>
      ，如果传入
      <mark>
       两个参数就是滑动窗口
      </mark>
     </li>
    </ul>
    <p>
     ​
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/e05acaddbc254232833567e978da277e.png"/>
    </p>
    <ul>
     <li>
      <p>
       需求：每隔5s时间，统计最近10s出现的数据
      </p>
     </li>
     <li>
      <p>
       代码实现：
      </p>
     </li>
    </ul>
    <pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataStream<span class="token punctuation">,</span> StreamExecutionEnvironment<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>windowing<span class="token punctuation">.</span>time<span class="token punctuation">.</span></span>Time

<span class="token keyword">object</span> TestTimeWindow <span class="token punctuation">{<!-- --></span>

  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> environment<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment

    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>_
    <span class="token keyword">val</span> socketSource<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> environment<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"node01"</span><span class="token punctuation">,</span><span class="token number">9999</span><span class="token punctuation">)</span>

    socketSource
      <span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>timeWindow<span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    environment<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>

<span class="token punctuation">}</span>
</code></pre>
    <h6>
     <a id="722_Count_Windos_1352">
     </a>
     7.2.2 Count Windos窗口的应用
    </h6>
    <ul>
     <li>
      <p>
       与timeWindow类型，CountWinodw也可以分为滚动窗口和滑动窗口，这两个窗口调用方法一样，都是调用countWindow，如果传入一个参数就是滚动窗口，如果传入两个参数就是滑动窗口
      </p>
      <p>
       ​
       <br/>
       <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/295036358afe42f8b06a515448580f96.png"/>
      </p>
     </li>
     <li>
      <p>
       需求：使用count Window 统计最近5条数的最大值
      </p>
     </li>
    </ul>
    <pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>AggregateFunction
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataStream<span class="token punctuation">,</span> StreamExecutionEnvironment<span class="token punctuation">}</span>

<span class="token comment">/**
  * 使用countWindow统计最近5条数据的最大值
  */</span>
<span class="token keyword">object</span> TestCountWindow <span class="token punctuation">{<!-- --></span>

  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> environment<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>_
    <span class="token keyword">val</span> socketSource<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> environment<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"node01"</span><span class="token punctuation">,</span><span class="token number">9999</span><span class="token punctuation">)</span>

    <span class="token comment">/**
      * 发送数据
      * spark 1
      * spark 2
      * spark 3
      * spark 4
      * spark 5
      * hello 100
      * hello 90
      * hello 80
      * hello 70
      * hello 60
      * hello 10
      */</span>
    socketSource<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>countWindow<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span>aggregate<span class="token punctuation">(</span><span class="token keyword">new</span> AggregateFunction<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">,</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">{<!-- --></span>
          <span class="token keyword">var</span> initAccumulator <span class="token operator">:</span><span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">0</span>
          <span class="token keyword">override</span> <span class="token keyword">def</span> createAccumulator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            initAccumulator
          <span class="token punctuation">}</span>

          <span class="token keyword">override</span> <span class="token keyword">def</span> add<span class="token punctuation">(</span>value<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">,</span> accumulator<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">if</span><span class="token punctuation">(</span>accumulator <span class="token operator">&gt;=</span> value<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
              accumulator
            <span class="token punctuation">}</span><span class="token keyword">else</span><span class="token punctuation">{<!-- --></span>
              value<span class="token punctuation">.</span>_2
            <span class="token punctuation">}</span>
          <span class="token punctuation">}</span>

          <span class="token keyword">override</span> <span class="token keyword">def</span> getResult<span class="token punctuation">(</span>accumulator<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Double</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            accumulator

          <span class="token punctuation">}</span>

          <span class="token keyword">override</span> <span class="token keyword">def</span> merge<span class="token punctuation">(</span>a<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> b<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">if</span><span class="token punctuation">(</span>a<span class="token operator">&gt;=</span>b<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
              a
            <span class="token punctuation">}</span><span class="token keyword">else</span><span class="token punctuation">{<!-- --></span>
              b
            <span class="token punctuation">}</span>
          <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>

    environment<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
    <h6>
     <a id="723_window_1427">
     </a>
     7.2.3 自定义window的应用
    </h6>
    <ul>
     <li>
      <p>
       如果time window 和 countWindow 还不够用的话，我们还可以使用自定义window来实现数据的统计等功能。
      </p>
      <p>
       <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/f3f1c51d1509402d979d2e9231718518.png"/>
      </p>
     </li>
    </ul>
    <h5>
     <a id="73_window_1437">
     </a>
     7.3 window窗口数据的集合统计
    </h5>
    <ul>
     <li>
      <p>
       前面我们可以通过aggregrate实现数据的聚合，对于求最大值，最小值，平均值等操作，我们也可以通过process方法来实现
      </p>
     </li>
     <li>
      <p>
       对于某一个window内的数值统计，我们可以增量的聚合统计或者全量的聚合统计
      </p>
     </li>
    </ul>
    <h6>
     <a id="731__1443">
     </a>
     7.3.1 增量聚合统计
    </h6>
    <ul>
     <li>
      窗口当中每加入一条数据，就进行一次统计
     </li>
     <li>
      常用的聚合算子
      <ul>
       <li>
        reduce(reduceFunction)
       </li>
       <li>
        aggregate(aggregateFunction)
       </li>
      </ul>
     </li>
    </ul>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/fae9c823a64447a3804410681419a2fe.png"/>
    </p>
    <ul>
     <li>
      <p>
       需求
      </p>
      <ul>
       <li>
        通过接收socket当中输入的数据，统计每5秒钟数据的累计的值
       </li>
      </ul>
     </li>
     <li>
      <p>
       代码实现
      </p>
     </li>
    </ul>
    <pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>window</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataStream<span class="token punctuation">,</span> StreamExecutionEnvironment<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>windowing<span class="token punctuation">.</span>time<span class="token punctuation">.</span></span>Time

<span class="token keyword">object</span> FlinkTimeCount <span class="token punctuation">{<!-- --></span>

  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>

      <span class="token keyword">val</span> environment<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment
      <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>_

      <span class="token keyword">val</span> socketStream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> environment<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"node01"</span><span class="token punctuation">,</span><span class="token number">9999</span><span class="token punctuation">)</span>

      socketStream<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>toInt<span class="token punctuation">)</span><span class="token punctuation">)</span>
                  <span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
                  <span class="token punctuation">.</span>timeWindow<span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                  <span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">(</span>c1<span class="token punctuation">,</span>c2<span class="token punctuation">)</span><span class="token keyword">=&gt;</span><span class="token punctuation">(</span>c1<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>c1<span class="token punctuation">.</span>_2<span class="token operator">+</span>c2<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span>
                  <span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>

      environment<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"FlinkTimeCount"</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>

<span class="token punctuation">}</span>


</code></pre>
    <h6>
     <a id="732__1489">
     </a>
     7.3.2 全量聚合统计
    </h6>
    <ul>
     <li>
      <p>
       等到窗口截止，或者窗口内的数据全部到齐，然后再进行统计，可以用于求窗口内的数据的最大值，或者最小值，平均值等
      </p>
     </li>
     <li>
      <p>
       等属于窗口的数据到齐，才开始进行聚合计算【可以实现对窗口内的数据进行排序等需求】
      </p>
      <ul>
       <li>
        apply(windowFunction)
       </li>
       <li>
        process(processWindowFunction)
       </li>
       <li>
        processWindowFunction比windowFunction提供了更多的上下文信息。
       </li>
      </ul>
     </li>
     <li>
      <p>
       需求
      </p>
      <ul>
       <li>
        通过全量聚合统计，求取每3条数据的平均值
       </li>
      </ul>
     </li>
     <li>
      <p>
       代码实现
      </p>
     </li>
    </ul>
    <pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>window</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span>Tuple
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span>function<span class="token punctuation">.</span></span>ProcessWindowFunction
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataStream<span class="token punctuation">,</span> StreamExecutionEnvironment<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>windowing<span class="token punctuation">.</span>windows<span class="token punctuation">.</span></span>GlobalWindow
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Collector

<span class="token comment">/**
  * 求取每3条数据的平均值
  */</span>
<span class="token keyword">object</span> FlinkCountWindowAvg <span class="token punctuation">{<!-- --></span>
  <span class="token comment">/**
    * 输入数据
    * 1
    * 2
    * 3
    * 4
    * 5
    * 6
    * @param args
    */</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> environment<span class="token operator">:</span> StreamExecutionEnvironment <span class="token operator">=</span> StreamExecutionEnvironment<span class="token punctuation">.</span>getExecutionEnvironment

    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>scala<span class="token punctuation">.</span></span>_

    <span class="token keyword">val</span> socketStream<span class="token operator">:</span> DataStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> environment<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"node01"</span><span class="token punctuation">,</span><span class="token number">9999</span><span class="token punctuation">)</span>

    <span class="token comment">//统计一个窗口内的数据的平均值</span>
    socketStream<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>toInt<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span>keyBy<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span>countWindow<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
                <span class="token comment">//通过process方法来统计窗口的平均值</span>
                <span class="token punctuation">.</span>process<span class="token punctuation">(</span><span class="token keyword">new</span> MyProcessWindowFunctionclass<span class="token punctuation">)</span>
                <span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//必须调用execute方法，否则程序不会执行</span>
    environment<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"count avg"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token comment">/**ProcessWindowFunction 需要跟四个参数
  * 输入参数类型，输出参数类型，聚合的key的类型，window的下界
  *
  */</span>
<span class="token keyword">class</span> MyProcessWindowFunctionclass <span class="token keyword">extends</span> ProcessWindowFunction<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span> <span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token punctuation">,</span> <span class="token builtin">Double</span> <span class="token punctuation">,</span> Tuple <span class="token punctuation">,</span> GlobalWindow<span class="token punctuation">]</span><span class="token punctuation">{<!-- --></span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> process<span class="token punctuation">(</span>key<span class="token operator">:</span> Tuple<span class="token punctuation">,</span> context<span class="token operator">:</span> Context<span class="token punctuation">,</span> elements<span class="token operator">:</span> Iterable<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> out<span class="token operator">:</span> Collector<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">var</span> totalNum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token keyword">var</span> countNum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span>data <span class="token keyword">&lt;-</span>  elements<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
      totalNum <span class="token operator">+=</span><span class="token number">1</span>
      countNum <span class="token operator">+=</span> data<span class="token punctuation">.</span>_2
    <span class="token punctuation">}</span>
    out<span class="token punctuation">.</span>collect<span class="token punctuation">(</span>countNum<span class="token operator">/</span>totalNum<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
    <h3>
     <a id="_star8_checkpoint_1567">
     </a>
     📖 ⭐️8. checkpoint机制原理深度剖析
    </h3>
    <ul>
     <li>
      checkpoint是flink为了解决state一致性和容错性引入的一种分布式的状态快照机制。
     </li>
    </ul>
    <h5>
     <a id="81_Flink_1571">
     </a>
     8.1 Flink分布式快照流程
    </h5>
    <ul>
     <li>
      首先我们来看一下一个简单的Checkpoint的大致流程：
      <ol>
       <li>
        暂停处理新流入数据，将新数据缓存起来。
       </li>
       <li>
        将算子子任务的本地状态数据拷贝到一个远程的持久化存储上。
       </li>
       <li>
        继续处理新流入的数据，包括刚才缓存起来的数据。
       </li>
      </ol>
     </li>
    </ul>
    <h5>
     <a id="82__Barrier_1580">
     </a>
     8.2 Barrier机制
    </h5>
    <blockquote>
     <p>
      ​ flink是如何来实现分布式状态快照的呢，由于flink是流式的计算引擎，基于这种特定的场景，Flink通过向流数据中注入特殊的事件来作为快照的信号，这种特殊事件就叫Barrier（屏障，栅栏）。当算子任务处理到Barrier n的时候就会执行状态的快照并把它标记为n的状态快照。
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/30033d9a206c412b8801b58f510ed6f5.png"/>
     </p>
    </blockquote>
    <ul>
     <li>
      <p>
       checkpoint的调用流程：
      </p>
      <ul>
       <li>
        <ol>
         <li>
          首先是JobManager中的checkpoint Coordinator(协调器) 向任务中的所有source Task周期性发送barrier（栅栏）进行快照请求。
         </li>
        </ol>
       </li>
       <li>
        <ol start="2">
         <li>
          source Task接受到barrier后， 会把当前自己的状态进行snapshot(可以保存在HDFS上)。
         </li>
        </ol>
       </li>
       <li>
        <ol start="3">
         <li>
          source向checkpoint coordinator确认snapshot已经完成。
         </li>
        </ol>
       </li>
       <li>
        <ol start="4">
         <li>
          source继续向下游transformation operator发送 barrier。
         </li>
        </ol>
       </li>
       <li>
        <ol start="5">
         <li>
          transformation operator重复source的操作，直到sink operator向协调器确认snapshot完成。
         </li>
        </ol>
       </li>
       <li>
        <ol start="6">
         <li>
          coordinator确认完成本周期的snapshot已经完成。
         </li>
        </ol>
       </li>
      </ul>
      <pre><code class="prism language-scala">
<span class="token comment">// 5秒启动一次checkpoint</span>
env<span class="token punctuation">.</span>enableCheckpointing<span class="token punctuation">(</span><span class="token number">5000</span><span class="token punctuation">)</span>

<span class="token comment">// 设置checkpoint只checkpoint一次</span>
env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointingMode<span class="token punctuation">(</span>CheckpointingMode<span class="token punctuation">.</span>EXACTLY_ONCE<span class="token punctuation">)</span>

<span class="token comment">// 设置两次checkpoint的最小时间间隔</span>
env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setMinPauseBetweenCheckpoints<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span>

<span class="token comment">// checkpoint超时的时长</span>
env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setCheckpointTimeout<span class="token punctuation">(</span><span class="token number">60000</span><span class="token punctuation">)</span>

<span class="token comment">// 允许的最大checkpoint并行度</span>
env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>setMaxConcurrentCheckpoints<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment">// 当程序关闭的时，触发额外的checkpoint</span>
env<span class="token punctuation">.</span>getCheckpointConfig<span class="token punctuation">.</span>enableExternalizedCheckpoints<span class="token punctuation">(</span>CheckpointConfig<span class="token punctuation">.</span>ExternalizedCheckpointCleanup<span class="token punctuation">.</span>RETAIN_ON_CANCELLATION<span class="token punctuation">)</span>

<span class="token comment">// 设置checkpoint的地址</span>
env<span class="token punctuation">.</span>setStateBackend<span class="token punctuation">(</span><span class="token keyword">new</span> FsStateBackend<span class="token punctuation">(</span><span class="token string">"hdfs://node01:8020/flink-checkpoint/"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
     </li>
     <li>
      <p>
       注意
      </p>
      <blockquote>
       <p>
        Checkpoint Barrier被插入到数据流中，它将数据流切分成段。Flink的Checkpoint逻辑是，一段新数据流入导致状态发生了变化，Flink的算子接收到Checkpoint Barrier后，对状态进行快照。每个Checkpoint Barrier有一个ID，表示该段数据属于哪次Checkpoint。如图所示，当ID为n的Checkpoint Barrier到达每个算子后，表示要对n-1和n之间状态的更新做快照。
       </p>
      </blockquote>
     </li>
    </ul>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/070e9923546e4e48adba64b29161da8c.png"/>
    </p>
    <h5>
     <a id="83_checkpoint_1627">
     </a>
     8.3 多任务并行下的checkpoint
    </h5>
    <ul>
     <li>
      我们构建一个并行数据流图，用这个并行数据流图来演示Flink的分布式快照机制。这个数据流图有两个Source子任务，数据流会在这些并行算子上从Source流动到Sink。
     </li>
    </ul>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/e43b5c7090af425091e5acc610971ae5.png"/>
    </p>
    <ul>
     <li>
      首先，Flink的检查点协调器（Checkpoint Coordinator）触发一次Checkpoint（Trigger Checkpoint），这个请求会发送给Source的各个子任务。
     </li>
    </ul>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/40c05f2982ce4b0f8a4d480b59384a59.png"/>
    </p>
    <ul>
     <li>
      各Source算子子任务接收到这个Checkpoint请求之后，会将自己的状态写入到状态后端，生成一次快照，并且会向下游广播Checkpoint Barrier。
     </li>
    </ul>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b5e3ddd23f684c0e929319fc1ba95101.png"/>
    </p>
    <ul>
     <li>
      Source算子做完快照后，还会给Checkpoint Coodinator发送一个确认，告知自己已经做完了相应的工作。这个确认中包括了一些元数据，其中就包括刚才备份到State Backend的状态句柄，或者说是指向状态的指针。至此，Source完成了一次Checkpoint。跟Watermark的传播一样，一个算子子任务要把Checkpoint Barrier发送给所连接的所有下游算子子任务。
     </li>
     <li>
      对于下游算子来说，可能有多个与之相连的上游输入，我们将算子之间的边称为通道。
      <mark>
       Source要将一个ID为n的Checkpoint Barrier向所有下游算子广播，这也意味着下游算子的多个输入里都有同一个Checkpoint Barrier，而且不同输入里Checkpoint Barrier的流入进度可能不同。
      </mark>
      <strong>
       Checkpoint Barrier传播的过程需要进行对齐（Barrier Alignment），我们从数据流图中截取一小部分来分析Checkpoint Barrier是如何在算子间传播和对齐的
      </strong>
      。
     </li>
    </ul>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/ff547ddccc704691ab2354274ad0189f.png"/>
    </p>
    <blockquote>
     <p>
      如上图所示，对齐分为四步：
     </p>
     <p>
      (1). 算子子任务在某个输入通道中收到第一个ID为n的Checkpoint Barrier，但是其他输入通道中ID为n的Checkpoint Barrier还未到达，该算子子任务开始准备进行对齐。
     </p>
     <p>
      (2). 算子子任务将第一个输入通道的数据缓存下来，同时继续处理其他输入通道的数据，这个过程被称为对齐。
     </p>
     <p>
      (3). 第二个输入通道的Checkpoint Barrier抵达该算子子任务，该算子子任务执行快照，将状态写入State Backend，然后将ID为n的Checkpoint Barrier向下游所有输出通道广播。
     </p>
     <p>
      (4). 对于这个算子子任务，快照执行结束，继续处理各个通道中新流入数据，包括刚才缓存起来的数据。
     </p>
    </blockquote>
    <ul>
     <li>
      数据流图中的每个算子子任务都要完成一遍上述的对齐、快照、确认的工作，当最后所有Sink算子确认完成快照之后，说明ID为n的Checkpoint执行结束，Checkpoint Coordinator向State Backend写入一些本次Checkpoint的元数据。
     </li>
    </ul>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/d14c9c7502e848d090455b2a131ce267.png"/>
    </p>
    <blockquote>
     <p>
      ​ 之所以要进行barrier对齐，主要是为了保证一个Flink作业所有算子的状态是一致的。也就是说，某个ID为n的Checkpoint Barrier从前到后流入所有算子子任务后，所有算子子任务都能将同样的一段数据写入快照。
     </p>
    </blockquote>
    <h5>
     <a id="84__1670">
     </a>
     8.4 快照性能优化方案
    </h5>
    <ul>
     <li>
      <p>
       上面讲到了一致性快照的具体流程，这种方式保证了数据的一致性，但有一些潜在的问题
      </p>
      <ul>
       <li>
        <p>
         （1）每次进行Checkpoint前，都需要暂停处理新流入数据，然后开始执行快照，假如状态比较大，一次快照可能长达几秒甚至几分钟。
        </p>
       </li>
       <li>
        <p>
         （2）Checkpoint Barrier对齐时，必须等待所有上游通道都处理完，假如某个上游通道处理很慢，这可能造成整个数据流堵塞。
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       优化方案
      </p>
      <blockquote>
       <ul>
        <li>
         （1）对于第一个问题，Flink提供了异步快照（Asynchronous Snapshot）的机制。当实际执行快照时，Flink可以立即向下广播Checkpoint Barrier，表示自己已经执行完自己部分的快照。一旦数据同步完成，再给Checkpoint Coordinator发送确认信息
        </li>
        <li>
         （2）对于第二个问题，Flink允许跳过对齐这一步，或者说一个算子子任务不需要等待所有上游通道的Checkpoint Barrier，直接将Checkpoint Barrier广播，执行快照并继续处理后续流入数据。为了保证数据一致性，Flink必须将那些较慢的数据流中的元素也一起快照，一旦重启，这些元素会被重新处理一遍。
        </li>
       </ul>
      </blockquote>
     </li>
    </ul>
    <p>
     ⭐️
     <br/>
     <a href="https://blog.csdn.net/u010342213/article/details/146116566?sharetype=blogdetail&amp;sharerId=146116566&amp;sharerefer=PC&amp;sharesource=u010342213&amp;spm=1011.2480.3001.8118">
      Barrier对齐会影响执行效率，怎么跳过Barrier对齐，跳过后还能保证‌Exactly-Once语义吗？
     </a>
    </p>
    <h5>
     <a id="85__1688">
     </a>
     8.5 任务重启恢复流程
    </h5>
    <ul>
     <li>
      <p>
       Flink的重启恢复逻辑相对比较简单：
      </p>
      <blockquote>
       <ul>
        <li>
         <p>
          1、重启应用，在集群上重新部署数据流图。
         </p>
        </li>
        <li>
         <p>
          2、从持久化存储上读取最近一次的Checkpoint数据，加载到各算子子任务上。
         </p>
        </li>
        <li>
         <p>
          3、继续处理新流入的数据。
         </p>
        </li>
       </ul>
      </blockquote>
     </li>
     <li>
      <p>
       这样的机制可以保证Flink内部状态的Excatly-Once一致性。至于端到端的Exactly-Once一致性，要根据Source和Sink的具体实现而定。当发生故障时，一部分数据有可能已经流入系统，但还未进行Checkpoint，Source的Checkpoint记录了输入的Offset；当重启时，Flink能把最近一次的Checkpoint恢复到内存中，并根据Offset，让Source从该位置重新发送一遍数据，以保证数据不丢不重。像Kafka等消息队列是提供重发功能的，
       <code>
        socketTextStream
       </code>
       就不具有这种功能，也意味着不能保证Exactly-Once投递保障。
      </p>
     </li>
    </ul>
    <h3>
     <a id="_9_Flink_TwoPhaseCommit_1706">
     </a>
     📖 9. Flink两阶段提交 TwoPhaseCommit
    </h3>
    <h5>
     <a id="91_EXACTLY_ONCE_1708">
     </a>
     9.1 EXACTLY_ONCE语义概述
    </h5>
    <ul>
     <li>
      何为EXACTLY_ONCE？
      <ul>
       <li>
        EXACTLY_ONCE简称EOS，每条输入消息只会影响最终结果一次，注意这里是影响一次，而非处理一次，Flink一直宣称自己支持EOS，实际上主要是对于Flink应用内部来说的，对于外部系统(端到端)则有比较强的限制
       </li>
       <li>
        Flink实现端到端的EXACTLY_ONCE语义需要满足：
        <ul>
         <li>
          1.外部系统写入支持幂等性
         </li>
         <li>
          2.外部系统支持以事务的方式写入
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li>
      Flink的基本思路就是将状态定时地checkpiont到hdfs中去，当发生failure的时候恢复上一次的状态，然后将输出update到外部。这里需要注意的是输入流的offset也是状态的一部分，因此一旦发生failure就能从最后一次状态恢复，从而保证输出的结果是exactly once。这是Flink1.4之前的实现。
     </li>
     <li>
      Flink在1.4.0版本引入了TwoPhaseCommitSinkFunction接口，并在Kafka Producer的connector中实现了它，支持了对外部Kafka Sink的EXACTLY_ONCE语义，来让开发者用更少的代码来实现端到端的exactly-once语义
     </li>
    </ul>
    <h5>
     <a id="92__1720">
     </a>
     9.2 两阶段提交协议介绍
    </h5>
    <ul>
     <li>
      <p>
       两阶段提交协议是协调所有分布式原子事务参与者，并决定提交或取消（回滚）的分布式算法
      </p>
     </li>
     <li>
      <p>
       协议参与者
      </p>
     </li>
    </ul>
    <blockquote>
     <p>
      两阶段提交指的是一种协议，经常用来实现分布式事务，可以简单理解为预提交+实际提交，一般分为协调器Coordinator(以下简称C)和若干事务参与者Participant(以下简称P)两种角色。
     </p>
    </blockquote>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/fecdc9c7a1ca4fc6b59db0573c67c339.png"/>
    </p>
    <ul>
     <li>
      <p>
       <mark>
        两个阶段的执行
       </mark>
      </p>
      <ul>
       <li>
        <p>
         1.请求阶段（commit-request phase，或称表决阶段，voting phase）
        </p>
        <pre><code>在请求阶段，协调者将通知事务参与者准备提交或取消事务，然后进入表决过程。
在表决过程中，参与者将告知协调者自己的决策：同意（事务参与者本地作业执行成功）或取消（本地作业执行故障）。
</code></pre>
       </li>
       <li>
        <ol start="2">
         <li>
          提交阶段（commit phase）
         </li>
        </ol>
        <pre><code>在该阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消。
当且仅当所有的参与者同意提交事务协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者取消事务。
参与者在接收到协调者发来的消息后将执行响应的操作。
</code></pre>
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <a id="93__1750">
     </a>
     9.3 两阶段提交实现原理机制
    </h5>
    <ul>
     <li>
      <p>
       Flink和外部系统(如Kafka)之间的消息传递如何做到exactly once呢?
      </p>
     </li>
     <li>
      <p>
       先看下面这幅图会出现的问题
      </p>
      <p>
       <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/68818f70a3014eca94c71d72b4fe6885.png"/>
      </p>
      <ul>
       <li>
        当sink A已经往Kafka写入了数据,而sink B fail.
       </li>
       <li>
        根据Flink的exactly once保证,系统会回滚到最近的checkpoint,
       </li>
       <li>
        但是sink A已经把数据写入到kafka了.
       </li>
       <li>
        Flink无法回滚kafka的state.因此,kafka将在之后再次接收到一份同样的来自sink A的数据,
       </li>
       <li>
        这样的message delivery便成为了at least once
       </li>
      </ul>
     </li>
     <li>
      <p>
       Flink采用Two phase commit来解决这个问题.
      </p>
      <ul>
       <li>
        <p>
         Two phase commit
        </p>
        <blockquote>
         <ul>
          <li>
           Phase 1: Pre-commit 预提交
           <ul>
            <li>
             Flink的JobManager向source注入checkpoint barrier以开启这snapshot，barrier从source流向sink,
            </li>
            <li>
             每个进行snapshot的算子成功snapshot后,都会向JobManager发送ACK.
            </li>
            <li>
             当sink完成snapshot后, 向JobManager发送ACK的同时向kafka进行pre-commit.
            </li>
           </ul>
          </li>
         </ul>
        </blockquote>
        <blockquote>
         <ul>
          <li>
           Phase 2: Commit 实际提交
           <ul>
            <li>
             当JobManager接收到所有算子的ACK后, 就会通知所有的算子这次checkpoint已经完成
            </li>
            <li>
             Sink接收到这个通知后, 就向kafka进行commit, 正式把数据写入到kafka
            </li>
           </ul>
          </li>
         </ul>
        </blockquote>
       </li>
      </ul>
     </li>
     <li>
      <p>
       下面我们来看看flink消费并写入kafka的例子是如何通过两部提交来保证exactly-once语义的。
      </p>
      <ul>
       <li>
        <p>
         kafka从0.11开始支持事物操作，若要使用flink端到端exactly-once语义需要flink的sink的kafka是0.11版本以上的
        </p>
       </li>
       <li>
        <p>
         这个例子包括以下几个步骤：
        </p>
        <ul>
         <li>
          从kafka读取数据
         </li>
         <li>
          一个聚合窗操作
         </li>
         <li>
          向kafka写入数据
         </li>
        </ul>
        <p>
         <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/8e94144ad5fe4014ac68bfeedb8157a9.png"/>
        </p>
       </li>
       <li>
        <p>
         1、JobManager向Source发送Barrier，开始进入pre-Commit阶段，当Source收到Barrier后，将自身的状态进行保存，后端可以根据配置进行选择，
         <mark>
          这里的状态是指消费的每个分区对应的offset
         </mark>
         。然后将Barrier发送给下一个Operator。
        </p>
        <p>
         <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/378bbea756f748999c49b5bbe4825cc4.png"/>
        </p>
       </li>
       <li>
        <p>
         2、当Window这个Operator收到Barrier之后，对自己的状态进行保存，这里的状态是指聚合的结果(sum或count的结果)，然后将Barrier发送给Sink。Sink收到后也对自己的状态进行保存，之后会进行一次预提交。
        </p>
        <p>
         <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/4de6759ad3d24d679b9c432fbb8dc095.png"/>
        </p>
       </li>
       <li>
        <p>
         3、预提交成功后，JobManager通知每个Operator，这一轮检查点已经完成，这个时候，Kafka Sink会向Kafka进行真正的事务Commit。
        </p>
        <p>
         <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/a335c777a07448af9d494ac23acc44b0.png"/>
        </p>
       </li>
      </ul>
     </li>
    </ul>
    <blockquote>
     <p>
      以上便是两阶段的完整流程，不同阶段fail over的recovery举措:
     </p>
     <p>
      ​ (1) 在pre-commit前fail over, 系统恢复到最近的checkponit
     </p>
     <p>
      ​ (2) 在pre-commit后,commit前fail over,系统恢复到刚完成pre-commit时的状态
     </p>
     <p>
      因此，所有opeartor必须对checkpoint最终结果达成共识：
     </p>
     <p>
      ​ 即所有operator都必须认定数据提交要么成功执行，要么被终止然后回滚。
     </p>
    </blockquote>
    <h5>
     <a id="94_TwoPhaseCommitSinkFunction_1819">
     </a>
     9.4 两阶段提交的TwoPhaseCommitSinkFunction类
    </h5>
    <ul>
     <li>
      <p>
       在使用两步提交算子时，我们可以继承TwoPhaseCommitSinkFunction这个类。
      </p>
      <ul>
       <li>
        <p>
         TwoPhaseCommitSinkFunction有4个方法
        </p>
        <ul>
         <li>
          <ol>
           <li>
            <p>
             beginTransaction()
            </p>
            <pre><code>开启事务：创建一个临时文件.后续把原要写入到外部系统的数据写入到这个临时文件
</code></pre>
           </li>
          </ol>
         </li>
         <li>
          <ol start="2">
           <li>
            preCommit()
           </li>
          </ol>
          <pre><code>预提交：flush并close这个文件,之后便不再往其中写数据.同时开启一个新的事务供下个checkponit使用
</code></pre>
         </li>
         <li>
          <ol start="3">
           <li>
            <p>
             commit()
            </p>
            <pre><code>正式提交: 把pre-committed的临时文件移动到指定目录
</code></pre>
           </li>
          </ol>
         </li>
         <li>
          <ol start="4">
           <li>
            <p>
             abort()
            </p>
            <pre><code>丢弃: 删除掉pre-committed的临时文件
</code></pre>
           </li>
          </ol>
         </li>
        </ul>
       </li>
      </ul>
     </li>
    </ul>
    <h3>
     <a id="seven___1861">
     </a>
     7️⃣ 把所有的代码都敲一遍
    </h3>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f753031303334323231332f:61727469636c652f64657461696c732f313436313030383136" class_="artid" style="display:none">
 </p>
</div>


