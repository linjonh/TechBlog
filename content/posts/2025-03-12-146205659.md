---
layout: post
title: "论文笔记FFA-Net-Feature-Fusion-Attention-Network-for-Single-Image-Dehazing"
date: 2025-03-12 15:03:27 +08:00
description: "的主要思想是：不同的通道特征包含不同的加权信息，尤其是在去雾任务中，某些通道可能包含更多的有用信息（如颜色、纹理等），而其他通道可能包含较少的信息。：考虑到不同通道特征包含完全不同的加权信息，且雾在图像像素上分布不均匀，FA模块旨在为不同的通道和像素分配不同的权重，以突出重要的特征，抑制不重要的特征，从而提供处理不同类型信息的灵活性，扩展CNN的表示能力。将不同层次的特征进行融合，保留浅层信息并传递到深层，同时自适应学习不同层次特征信息的权重，给予重要特征更多权重，以提高网络性能。"
keywords: "【论文笔记】FFA-Net: Feature Fusion Attention Network for Single Image Dehazing"
categories: ['论文笔记']
tags: ['计算机视觉']
artid: "146205659"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146205659
    alt: "论文笔记FFA-Net-Feature-Fusion-Attention-Network-for-Single-Image-Dehazing"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146205659
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146205659
cover: https://bing.ee123.net/img/rand?artid=146205659
image: https://bing.ee123.net/img/rand?artid=146205659
img: https://bing.ee123.net/img/rand?artid=146205659
---

# 【论文笔记】FFA-Net: Feature Fusion Attention Network for Single Image Dehazing
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b456e3d41fe9496280c6724ab4eee47c.gif#pic\_center)
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c5c7ec09391b4a3d871aba149dfe85dd.png)
## 1\. 研究背景
\* \*\*图像去雾的重要性\*\*
\* 单图像去雾是计算机视觉中的基本低级视觉任务。由于大气中存在烟雾、灰尘等悬浮粒子，拍摄的图像常出现色彩失真、模糊和低对比度等问题，这不仅影响图像质量，还会给后续的分类、跟踪等高级视觉任务带来困难。因此，图像去雾旨在从受损的输入图像中恢复出清晰的无雾图像，作为高级视觉任务的预处理步骤。
\* \*\*现有方法的局限性\*\*
\* \*\*传统先验方法\*\* ：早期的去雾方法大多基于物理散射模型，如DCP（Dark Channel Prior）等。这些方法基于不同的图像统计先验，将其作为额外约束来补偿信息损失。然而，先验可能在实际中不可靠，例如当场景对象与大气光相似时，会导致传输图估计不准确，在某些实际情况下效果不佳。
\* \*\*深度学习方法\*\* ：随着深度学习的兴起，出现了许多基于神经网络的去雾方法，如DehazeNet、MSCNN等。这些方法直接回归中间传输图或最终的无雾图像，相比传统方法具有更好的性能和鲁棒性。但\*\*现有的基于CNN的图像去雾网络通常对通道和像素特征同等对待，无法处理雾在图像中不均匀分布的情况，且随着网络加深，浅层特征信息难以保留。\*\*
## 2\. FFA - Net网络结构
![](https://i-blog.csdnimg.cn/img\_convert/1664758f52328383fce3a9d03fd8833f.png)
\* \*\*整体架构\*\*
\* FFA - Net是一个端到端的特征融合注意力网络，用于直接恢复无雾图像。其架构主要由三个关键部分组成（如图2所示）：
\* \*\*浅层特征提取部分\*\* ：输入为雾图，首先经过这部分提取浅层特征。
\* \*\*多个带有跳跃连接的组结构（Group Architectures）\*\* ：提取的浅层特征被送入N个组结构，每个组结构包含B个基本块结构（Basic Block Structure），且具有跳跃连接。这些组结构用于进一步提取和处理特征。
\* \*\*特征融合与重建部分\*\* ：组结构输出的特征通过特征注意力（Feature Attention，FA）模块进行融合，然后经过重建部分（包括两层卷积网络和全局残差学习结构）得到无雾输出。
\* \*\*关键模块\*\*
\* \*\*特征注意力（FA）模块\*\*
![](https://i-blog.csdnimg.cn/img\_convert/8cfe4b448c0aefc66e9b0c9eaf9d101f.png)
\* \*\*目的\*\* ：考虑到不同通道特征包含完全不同的加权信息，且雾在图像像素上分布不均匀，FA模块旨在为不同的通道和像素分配不同的权重，以突出重要的特征，抑制不重要的特征，从而提供处理不同类型信息的灵活性，扩展CNN的表示能力。
\* \*\*结构与工作原理\*\*
\* \*\*通道注意力（Channel Attention，CA）\*\* ：
\* 首先对输入特征图进行全局平均池化，将通道方向的全局空间信息整合到一个通道描述符中。公式为：
g c = H p ( F c ) = 1 H × W ∑ i = 1 H ∑ j = 1 W X c ( i , j )
g\_{c}=H\_{p}\left(F\_{c}\right)=\frac{1}{H × W} \sum\_{i=1}^{H}
\sum\_{j=1}^{W}X\_{c}(i,j) gc​=Hp​(Fc​)=H×W1​i=1∑H​j=1∑W​Xc​(i,j)
其中 X c ( i , j ) X\_{c}(i, j) Xc​(i,j) 是第 c c c 个通道 x c x\_{c} xc​ 在位置 ( i ,
j ) (i, j) (i,j) 的值， H p H\_{p} Hp​ 是全局池化函数，得到一个 C × 1 × 1 C ×1 ×1 C×1×1 的向量
g c g\_{c} gc​。
\* 然后特征经过两个卷积层和 ReLU、sigmoid 激活函数得到不同通道的权重：
C A c = σ ( C o n v ( δ ( C o n v ( g c ) ) ) )
CA\_{c}=\sigma\left(Conv\left(\delta\left(Conv\left(g\_{c}\right)\right)\right)\right)
CAc​=σ(Conv(δ(Conv(gc​))))
其中 σ \sigma σ 是 sigmoid 函数， δ \delta δ 是 ReLU 函数。
\* 最后将输入特征 F c F\_{c} Fc​ 与通道权重 C A c CA\_{c} CAc​ 进行逐元素乘法操作，得到经过通道注意力加权后的特征：
F c ∗ = C A c ⊗ F c F\_{c}^{\*}=CA\_{c} \otimes F\_{c} Fc∗​=CAc​⊗Fc​
\* \*\*像素注意力（Pixel Attention，PA）\*\* ：
\* 以通道注意力的输出 F ∗ F^{\*} F∗ 为输入，将其送入两个带有 ReLU 和 sigmoid 激活函数的卷积层，形状从 C × H × W C ×H ×W C×H×W 变为 1 × H × W 1 ×H ×W 1×H×W，得到像素注意力权重：
P A = σ ( C o n v ( δ ( C o n v ( F ∗ ) ) ) )
PA=\sigma\left(Conv\left(\delta\left(Conv\left(F^{\*}\right)\right)\right)\right)
PA=σ(Conv(δ(Conv(F∗))))
\* 最后将 F ∗ F^{\*} F∗ 与 P A PA PA 进行逐元素乘法操作，得到经过像素注意力加权后的特征：
F ~ = F ∗ ⊗ P A \tilde{F}=F^{\*} \otimes PA F~=F∗⊗PA
此即为 FA 模块的输出。
\* \*\*基本块结构（Basic Block Structure）\*\*
![](https://i-blog.csdnimg.cn/img\_convert/7f39e1d2019772508c442ae606ae78b2.png)
\* \*\*目的\*\* ：由局部残差学习（Local Residual Learning，LRL）和特征注意力（FA）模块组成，旨在允许薄雾区域或低频等不重要信息通过多个局部残差连接绕过，使主网络专注于有效信息，同时提高网络性能和训练稳定性。
\* \*\*工作原理\*\* ：局部残差学习通过跳跃连接，将不重要信息绕过主网络路径，而特征注意力模块则进一步对特征进行加权处理，突出重要信息。
\* \*\*注意力基础的不同层次特征融合（Attention-based Different Levels Feature Fusion，FFA）结构\*\*
\* \*\*目的\*\* ：
将不同层次的特征进行融合，保留浅层信息并传递到深层，同时自适应学习不同层次特征信息的权重，给予重要特征更多权重，以提高网络性能。
\* \*\*工作原理\*\* ：
1. 首先将 G G G 个组结构输出的所有特征图在通道方向上进行拼接：
F concat = Concat ( F 1 , F 2 , . . . , F G ) F\_{\text{concat}} =
\text{Concat}(F\_1, F\_2, ..., F\_G) Fconcat​=Concat(F1​,F2​,...,FG​)
2. 然后通过 FA 模块计算注意力权重，并进行乘法融合：
F output = FA ( F concat ) ⊗ F concat F\_{\text{output}} =
\text{FA}(F\_{\text{concat}}) \otimes F\_{\text{concat}}
Foutput​=FA(Fconcat​)⊗Fconcat​
这样能够有效增强不同层次特征的贡献，提高网络性能。
## 3\. 实验结果
\* \*\*与现有方法比较\*\*
\* 在RESIDE数据集的SOTS测试集上，与DCP、AOD - Net、DehazeNet、GCANet等四种不同的现有先进去雾算法进行比较。结果表明，FFA - Net在PSNR和SSIM指标上大幅超越现有方法，例如在室内测试集上，PSNR从30.23dB提升到36.39dB。从定性比较来看，FFA - Net在图像细节和色彩保真度恢复上表现更优，能更好地处理厚雾和纹理丰富区域。
\* \*\*消融实验\*\*
\* 为进一步证明FFA - Net架构的优越性，对网络的不同模块进行消融实验，主要考虑FA模块、LRL与FA的组合以及FFA结构。实验结果表明，每个考虑的因素都对网络性能起着重要作用，尤其是FFA结构。即使仅使用FA结构，网络也具有竞争力，LRL可稳定训练并提升性能，FA和FFA的结合使结果达到很高水平。
## 4\. 研究贡献
\* 提出FFA - Net用于单图像去雾，该网络性能大幅超越现有方法。
\* 提出FA模块，结合通道注意力和像素注意力机制，为处理不同类型信息提供额外灵活性，更关注厚雾像素和重要通道信息。
\* 提出由LRL和FA组成的基本块结构，允许不重要信息绕过，提高网络性能和训练稳定性。
\* 提出FFA结构，能保留并融合不同层次特征信息，自适应学习特征权重，效果优于其他特征融合方法。
## 5\. 重点详解
在FFA-Net中，\*\*通道注意力（Channel Attention, CA）\*\*和\*\* 像素注意力（Pixel Attention,
PA）\*\*是两个关键的注意力机制模块，它们分别用于处理不同通道和不同像素的特征信息。这两个模块的设计目的是为了更好地处理图像中不均匀的雾霾分布和不同通道的特征权重差异，从而提高去雾效果。
### 1\. 通道注意力（Channel Attention, CA）
\*\*通道注意力\*\*
的主要思想是：不同的通道特征包含不同的加权信息，尤其是在去雾任务中，某些通道可能包含更多的有用信息（如颜色、纹理等），而其他通道可能包含较少的信息。因此，通道注意力机制通过自适应地学习每个通道的权重，使得网络能够更加关注那些对去雾任务更重要的通道。
#### 通道注意力的实现步骤：
1. \*\*全局平均池化（Global Average Pooling）\*\* ：
首先，对每个通道的特征图进行全局平均池化，将每个通道的全局空间信息压缩为一个标量值。公式如下：
g c = H p ( F c ) = 1 H × W ∑ i = 1 H ∑ j = 1 W X c ( i , j )
g\_{c}=H\_{p}\left(F\_{c}\right)=\frac{1}{H × W} \sum\_{i=1}^{H}
\sum\_{j=1}^{W}X\_{c}(i,j) gc​=Hp​(Fc​)=H×W1​i=1∑H​j=1∑W​Xc​(i,j)
其中 X c ( i , j ) X\_{c}(i, j) Xc​(i,j)是第 c c c个通道 x c x\_{c} xc​在位置 ( i , j )
(i, j) (i,j)的值， H p H\_{p} Hp​是全局池化函数，得到一个 C × 1 × 1 C ×1 ×1 C×1×1的向量 g c g\_{c}
gc​
2. \*\*卷积层和激活函数\*\* ：
接下来，将全局平均池化后的特征通过两个卷积层，并使用ReLU和Sigmoid激活函数来生成每个通道的权重。公式如下：
C A c = σ ( C o n v ( δ ( C o n v ( g c ) ) ) )
CA\_{c}=\sigma\left(Conv\left(\delta\left(Conv\left(g\_{c}\right)\right)\right)\right)
CAc​=σ(Conv(δ(Conv(gc​))))
，其中 σ \sigma σ是sigmoid函数， δ \delta δ是ReLU函数。
3. \*\*通道加权\*\* ：
最后，将生成的通道权重 (CA\_c) 与原始输入特征 (F\_c) 进行逐元素相乘，得到加权后的通道特征：
F c ∗ = C A c ⊗ F c F\_{c}^{\*}=CA\_{c} \otimes F\_{c} Fc∗​=CAc​⊗Fc​
这样，每个通道的特征都根据其重要性进行了加权，网络可以更加关注那些对去雾任务更重要的通道。
### 2\. 像素注意力（Pixel Attention, PA）
\*\*像素注意力\*\*
的主要思想是：图像中的雾霾分布是不均匀的，某些像素区域（如浓雾区域或高频纹理区域）可能包含更多的信息，而其他区域（如薄雾区域或低频区域）可能包含较少的信息。因此，像素注意力机制通过自适应地学习每个像素的权重，使得网络能够更加关注那些对去雾任务更重要的像素。
#### 像素注意力的实现步骤：
1. \*\*卷积层和激活函数\*\* ：
像素注意力的输入是经过通道注意力加权后的特征 F\*。首先，将 F\* 通过两个卷积层，并使用ReLU和Sigmoid激活函数来生成每个像素的权重。公式如下：
P A = σ ( C o n v ( δ ( C o n v ( F ∗ ) ) ) )
PA=\sigma\left(Conv\left(\delta\left(Conv\left(F^{\*}\right)\right)\right)\right)
PA=σ(Conv(δ(Conv(F∗))))
经过这两个卷积层后，特征图的形状从 C × H × W C ×H ×W C×H×W \*\*变为\*\* 1 × H × W 1 ×H ×W
1×H×W，即每个像素都有一个对应的权重。
2. \*\*像素加权\*\* ：
最后，将生成的像素权重 (PA) 与输入特征 (F^\*) 进行逐元素相乘，得到加权后的像素特征：
F ~ = F ∗ ⊗ P A \tilde{F}=F^{\*} \otimes PA F~=F∗⊗PA
这样，每个像素的特征都根据其重要性进行了加权，网络可以更加关注那些对去雾任务更重要的像素区域。
### 3\. 结合通道注意力与像素注意力
通道注意力（CA）和像素注意力（PA）相结合，形成了FFA-Net的特征注意力（FA）模块：
1. \*\*CA 首先作用于特征图，提升关键通道的权重\*\* 。
2. \*\*PA 进一步作用于 CA 处理后的特征，使网络更关注关键像素区域\*\* 。
3. \*\*最终输出的特征具有更强的表达能力，能够更好地处理雾气的去除任务\*\* 。
\* \* \*
⭐感谢你的阅读，希望本文能够对你有所帮助。如果你喜欢我的内容，记得点赞关注收藏我的博客，我会继续分享更多的内容。⭐