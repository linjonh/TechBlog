---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34343138343835322f:61727469636c652f64657461696c732f313436303538313337"
layout: post
title: "CVPR-2024实时目标检测D-FINE将DETRS中的回归任务重新定义为细粒度分布优化"
date: 2025-03-06 08:53:07 +08:00
description: "我们推出了D-FINE，这是一种强大的实时目标检测器，通过重新定义DETR模型中的边界框回归任务，实现了卓越的定位精度。D-FINE包含两个关键组件：细粒度分布优化（FDR）和全局最优定位自蒸馏（GO-LSD）。FDR将回归过程从预测固定坐标转变为迭代优化概率分布，提供了细粒度的中间表示，显著提升了定位精度。GO-LSD是一种双向优化策略，通过自蒸馏将定位知识从优化后的分布传递到较浅层，同时简化了较深层的残差预测任务。"
keywords: "d-fine可以用windows操作码"
categories: ['目标检测']
tags: ['目标检测', '回归', '人工智能']
artid: "146058137"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146058137
    alt: "CVPR-2024实时目标检测D-FINE将DETRS中的回归任务重新定义为细粒度分布优化"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146058137
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146058137
cover: https://bing.ee123.net/img/rand?artid=146058137
image: https://bing.ee123.net/img/rand?artid=146058137
img: https://bing.ee123.net/img/rand?artid=146058137
---

# 【CVPR 2024】【实时目标检测】D-FINE：将DETRS中的回归任务重新定义为细粒度分布优化

D-FINE：REDEFINE REGRESSION TASK IN DETRS AS FINE-GRAINED DISTRIBUTION REFINEMENT
  
D-FINE：将DETRS中的回归任务重新定义为细粒度分布优化

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a00361dc4d6a4b4689edc55f7f45c777.png)

## 0.论文摘要

我们推出了D-FINE，这是一种强大的实时目标检测器，通过重新定义DETR模型中的边界框回归任务，实现了卓越的定位精度。D-FINE包含两个关键组件：细粒度分布优化（FDR）和全局最优定位自蒸馏（GO-LSD）。FDR将回归过程从预测固定坐标转变为迭代优化概率分布，提供了细粒度的中间表示，显著提升了定位精度。GO-LSD是一种双向优化策略，通过自蒸馏将定位知识从优化后的分布传递到较浅层，同时简化了较深层的残差预测任务。此外，D-FINE在计算密集型模块和操作中引入了轻量级优化，实现了速度与精度之间的更好平衡。具体而言，D-FINE-L / X在NVIDIA T4 GPU上以124 / 78 FPS的速度在COCO数据集上达到了54.0% / 55.8%的AP。在Objects365上预训练后，D-FINE-L / X分别达到了57.1% / 59.3%的AP，超越了所有现有的实时检测器。此外，我们的方法显著提升了多种DETR模型的性能，最高提升了5.3%的AP，且额外参数和训练成本几乎可以忽略不计。

[论文链接](https://arxiv.org/abs/2410.13842)
  
[代码链接](https://github.com/Peterande/D-FINE)
  
，它们通常受到高延迟和计算需求的限制（Zhu等，2020；Liu等，2021；Li等，2022；Zhang等，2022）。RT-DETR（Zhao等，2024）通过开发实时变体，解决了这些限制，为YOLO检测器提供了一种端到端的替代方案。此外，LW-DETR（Chen等，2024）表明，DETR在大规模数据集（如Objects365，Shao等，2019）上训练时，能够达到比YOLO更高的性能上限。

尽管实时目标检测领域取得了显著进展，但一些未解决的问题仍然限制了检测器的性能。其中一个关键挑战是边界框回归的公式化。大多数检测器通过回归固定坐标来预测边界框，将边缘视为由狄拉克δ分布建模的精确值（Liu等，2016；Ren等，2015；Tian等，2019；Lyu等，2022）。虽然这种方法简单直接，但未能建模定位不确定性。因此，模型被限制使用L1损失和IoU损失，这些损失无法为独立调整每个边缘提供足够的指导（Girshick，2015）。这使得优化过程对小的坐标变化非常敏感，导致收敛速度慢和性能欠佳。尽管像GFocal（Li等，2020；2021）这样的方法通过概率分布解决了不确定性问题，但它们仍然受到锚点依赖性、粗略定位和缺乏迭代优化的限制。另一个挑战在于最大化实时检测器的效率，这些检测器受限于有限的计算和参数预算以保持速度。知识蒸馏（KD）是一种有前景的解决方案，它将知识从较大的教师模型转移到较小的学生模型，以在不增加成本的情况下提高性能（Hinton等，2015）。然而，传统的KD方法如Logit模仿和特征模仿在检测任务中已被证明效率低下，甚至可能导致最先进模型的性能下降（Zheng等，2022）。相比之下，定位蒸馏（LD）在检测任务中表现更好。然而，由于LD的训练开销较大且与无锚点检测器不兼容，其集成仍然具有挑战性。

为了解决这些问题，我们提出了D-FINE，一种新颖的实时目标检测器，它重新定义了边界框回归并引入了一种有效的自蒸馏策略。我们的方法解决了固定坐标回归中优化困难、无法建模定位不确定性以及需要以较低训练成本进行有效蒸馏的问题。我们引入了细粒度分布优化（FDR），将边界框回归从预测固定坐标转变为建模概率分布，提供了更细粒度的中间表示。FDR以残差方式迭代优化这些分布，允许逐步进行更精细的调整，从而提高定位精度。我们认识到，更深层的网络通过在其概率分布中捕获更丰富的定位信息，能够产生更准确的预测，因此我们引入了全局最优定位自蒸馏（GO-LSD）。GO-LSD以几乎可以忽略的额外训练成本，将定位知识从深层传递到浅层。通过将浅层的预测与后续层的优化输出对齐，模型学会了产生更好的早期调整，加速收敛并提高整体性能。此外，我们简化了现有实时DETR架构（Zhao等，2024；Chen等，2024）中计算密集的模块和操作，使D-FINE更快、更轻量。虽然这些修改通常会导致性能下降，但FDR和GO-LSD有效地缓解了这种退化，实现了速度与准确性之间更好的平衡。

在COCO数据集（Lin等，2014a）上的实验结果表明，D-FINE在实时目标检测中实现了最先进的性能，在准确性和效率方面超越了现有模型。D-FINE-L和D-FINE-X在COCO val2017上分别达到了54.0%和55.8%的AP，在NVIDIA T4 GPU上分别以124 FPS和78 FPS的速度运行。在更大的数据集如Objects365（Shao等，2019）上进行预训练后，D-FINE系列达到了高达59.3%的AP，超越了所有现有的实时检测器，展示了其可扩展性和鲁棒性。此外，我们的方法将多种DETR模型的AP提升了高达5.3%，而额外的参数和训练成本几乎可以忽略不计，展示了其灵活性和通用性。总之，D-FINE推动了实时检测器的性能边界。通过FDR和GO-LSD解决了边界框回归和蒸馏效率中的关键挑战，我们在目标检测领域迈出了有意义的一步，激发了该领域的进一步探索。

## 2.相关工作

### 实时/端到端目标检测器

YOLO系列在实时目标检测领域一直处于领先地位，通过架构创新、数据增强和训练技术的不断演进（Redmon等，2016a；Wang等，2023a；b；Glenn，2023；Wang与Liao，2024；Glenn，2024）。尽管高效，YOLO通常依赖于非极大值抑制（NMS），这引入了延迟，并在速度与准确性之间带来了不稳定性。DETR（Carion等，2020）通过消除对手工设计组件（如NMS和锚点）的需求，彻底改变了目标检测。传统的DETR（Zhu等，2020；Meng等，2021；Zhang等，2022；Wang等，2022；Liu等，2021；Li等，2022；Chen等，2022a；c）虽然取得了卓越的性能，但计算需求高，使其不适合实时应用。最近，RTDETR（Zhao等，2024）和LW-DETR（Chen等，2024）成功地将DETR应用于实时场景。与此同时，YOLOv10（Wang等，2024a）也消除了对NMS的需求，标志着YOLO系列向端到端检测的重大转变。

### 基于分布的目标检测

传统的边界框回归方法（Redmon等，2016b；Liu等，2016；Ren等，2015）依赖于狄拉克δ分布，将边界框的边缘视为精确且固定的，这使得建模定位不确定性变得具有挑战性。为了解决这一问题，最近的模型采用了高斯分布或离散分布来表示边界框（Choi等，2019；Li等，2020；Qiu等，2020；Li等，2021），从而增强了对不确定性的建模。然而，这些方法都依赖于基于锚点的框架，这限制了它们与现代无锚点检测器（如YOLOX（Ge等，2021）和DETR（Carion等，2020））的兼容性。此外，它们的分布表示通常以粗粒度的方式构建，缺乏有效的细化，阻碍了它们实现更准确预测的能力。

### 知识蒸馏

知识蒸馏（KD）（Hinton等，2015）是一种强大的模型压缩技术。传统的KD通常专注于通过Logit模仿来传递知识（Zagoruyko & Komodakis，2017；Mirzadeh等，2020；Son等，2021）。FitNets（Romero等，2015）首次提出了特征模仿，这一思想激发了一系列后续工作，进一步扩展了这一概念（Chen等，2017；Dai等，2021；Guo等，2021；Li等，2017；Wang等，2019）。大多数针对DETR的方法（Chang等，2023；Wang等，2024b）都结合了Logit和各种中间表示的混合蒸馏。最近，定位蒸馏（LD）（Zheng等，2022）表明，传递定位知识对于检测任务更为有效。自蒸馏（Zhang等，2019；2021）是KD的一种特殊情况，它使早期层能够从模型自身的精炼输出中学习，由于无需单独训练教师模型，因此所需的额外训练成本大大减少。

## 3.预备

### 边界框回归

在目标检测中，边界框回归传统上依赖于对狄拉克δ分布的建模，通常采用基于中心点的

{
x
,
y
,
w
,
h
}
\{x, y, w, h\}





{

x

,



y

,



w

,



h

}
形式或基于边缘距离的

{
c
,
d
}
\{c, d\}





{

c

,



d

}
形式，其中距离

d
=
{
t
,
b
,
l
,
r
}
d = \{t, b, l, r\}





d



=





{

t

,



b

,



l

,



r

}
是从锚点

c
=
{
x
c
,
y
c
}
c = \{x\_c, y\_c\}





c



=





{


x









c

​


,




y









c

​


}
测量的。然而，狄拉克δ假设将边界框边缘视为精确且固定的，这使得在模糊情况下难以建模定位不确定性。这种僵化的表示不仅限制了优化，还会在预测出现微小偏移时导致显著的定位误差。

为了解决这些问题，GFocal（Li 等人，2020；2021）使用离散概率分布回归从锚点到四个边缘的距离，从而提供了更灵活的边界框建模。在实际应用中，边界框距离

d
=
{
t
,
b
,
l
,
r
}
d = \{t, b, l, r\}





d



=





{

t

,



b

,



l

,



r

}
被建模为：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/81fa9f52e33847d0b472ca3247a23a1f.png)

其中，

d
m
a
x
d\_{max}






d










ma

x

​

是一个标量，用于限制与锚点中心的最大距离，

P
(
n
)
P\_{(n)}






P










(

n

)

​

表示四条边每个候选距离的概率。尽管 GFocal 通过概率分布在处理模糊性和不确定性方面迈出了一步，但其回归方法仍存在一些特定挑战：(1) 锚点依赖性：回归与锚框中心绑定，限制了预测的多样性以及与无锚框架的兼容性。(2) 无迭代优化：预测是一次性完成的，没有迭代优化，降低了回归的鲁棒性。(3) 粗略定位：固定的距离范围和均匀的区间划分可能导致定位不精确，尤其是对于小物体，因为每个区间代表了一个较宽的可能值范围。

### 定位蒸馏

定位蒸馏（Localization Distillation, LD）是一种颇具前景的方法，研究表明，在检测任务中传递定位知识更为有效（Zheng等，2022）。该方法基于GFocal，通过从教师模型中蒸馏出有价值的定位知识来增强学生模型，而不是简单地模仿分类逻辑或特征图。尽管具有这些优势，该方法仍然依赖于基于锚点的架构，并且会带来额外的训练成本。

## 4.方法

我们提出了D-FINE，一种在速度、规模、计算成本和准确性方面表现出色的强大实时目标检测器。D-FINE通过利用两个关键组件来解决现有边界框回归方法的不足：细粒度分布优化（FDR）和全局最优定位自蒸馏（GO-LSD）。这两个组件协同工作，显著提升了性能，同时仅增加了可忽略的额外参数和训练时间成本。

(1) FDR通过迭代优化概率分布，作为对边界框预测的修正，提供了一种更细粒度的中间表示。该方法独立地捕捉并优化每条边缘的不确定性。通过利用非均匀加权函数，FDR在每一解码层允许更精确和渐进的调整，从而提高定位精度并减少预测误差。FDR在无锚框、端到端的框架内运行，实现了更灵活和稳健的优化过程。

(2) GO-LSD从精炼的分布中提取定位知识，并将其传递到更浅的层中。随着训练的进行，最终层生成的软标签越来越精确。通过GO-LSD，较浅的层将其预测与这些标签对齐，从而产生更准确的预测。随着早期预测的改进，后续层可以专注于细化较小的残差。这种相互促进产生了协同效应，使得定位精度逐步提高。

为了进一步提升D-FINE的效率，我们对现有实时DETR架构（Zhao等，2024）中计算密集型的模块和操作进行了优化，使D-FINE更快、更轻量化。尽管这些修改通常会带来一定的性能损失，但FDR和GO-LSD有效地缓解了这种性能下降。详细的修改内容列于表3中。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5124590e60a941b28a8d9eaefcb62b70.png)

### 4.1 细粒度分布优化

#### 细粒度分布优化 (FDR)

细粒度分布优化（FDR）通过迭代优化由解码器层生成的细粒度分布，如图2所示。最初，第一个解码器层通过传统的边界框回归头和D-FINE头（两者均为MLP，仅输出维度不同）预测初步边界框和初步概率分布。每个边界框与四个分布相关联，每个边缘对应一个分布。初始边界框作为参考框，而后续层则通过残差方式调整分布来对其进行优化。优化后的分布随后用于调整相应初始边界框的四个边缘，逐步提高其精度。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/7b9d79297aea457abae78eb4547a912d.png)

图2：带有FDR的D-FINE概述。作为更细粒度中间表示的概率分布通过解码器层以残差方式迭代优化。应用非均匀加权函数以实现更精细的定位。

在数学上，设

b
0
=
{
x
,
y
,
W
,
H
}
b^0 = \{x, y, W, H\}






b









0



=





{

x

,



y

,



W

,



H

}
表示初始的边界框预测，其中

{
x
,
y
}
\{x, y\}





{

x

,



y

}
表示预测的边界框中心，

{
W
,
H
}
\{W, H\}





{

W

,



H

}
表示框的宽度和高度。然后，我们可以将

b
0
b^0






b









0
转换为中心坐标

c
0
=
{
x
,
y
}
c^0 = \{x, y\}






c









0



=





{

x

,



y

}
和边缘距离

d
0
=
{
t
,
b
,
l
,
r
}
d^0 = \{t, b, l, r\}






d









0



=





{

t

,



b

,



l

,



r

}
，这些距离分别表示从中心到上、下、左、右边缘的距离。对于第

l
l





l
层，精炼后的边缘距离

d
l
=
{
t
l
,
b
l
,
l
l
,
r
l
}
d^l = \{t^l, b^l, l^l, r^l\}






d









l



=





{


t









l

,




b









l

,




l









l

,




r









l

}
计算如下：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/64a4f4494da542609d5e5d0f601cf5a1.png)

其中，

P
r
l
(
n
)
=
{
P
t
l
(
n
)
,
P
r
b
l
(
n
)
,
P
r
l
l
(
n
)
,
P
r
r
l
(
n
)
}
Pr^l(n) = \{P^l\_t(n), Pr^l\_b(n), Pr^l\_l(n), Pr^l\_r(n)\}





P


r









l

(

n

)



=





{


P









t





l

​


(

n

)

,



P


r









b





l

​


(

n

)

,



P


r









l





l

​


(

n

)

,



P


r









r





l

​


(

n

)}
表示四个独立的分布，分别对应每条边。每个分布预测对应边的候选偏移值的可能性。这些候选值由权重函数

W
(
n
)
W(n)





W

(

n

)
确定，其中

n
n





n
索引

N
N





N
个离散区间中的某个区间，每个区间对应一个潜在的边偏移。分布的加权和产生边偏移。然后，这些边偏移通过初始边界框的高度

H
H





H
和宽度

W
W





W
进行缩放，以确保调整与框的大小成比例。

精炼后的分布通过残差调整进行更新，定义如下：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/48b2ab7a237e4d47a70a400265e0365e.png)

前一层的logits

l
o
g
i
t
s
l
−
1
(
n
)
logits^{l−1}(n)





l

o

g

i

t


s










l

−

1

(

n

)
反映了每个边缘的四个偏移值在各自区间内的置信度。当前层预测残差logits

∆
l
o
g
i
t
s
l
(
n
)
∆logits^l(n)





∆

l

o

g

i

t


s









l

(

n

)
，这些残差logits与前一层的logits相加，形成更新后的logits

l
o
g
i
t
s
l
(
n
)
logits^l(n)





l

o

g

i

t


s









l

(

n

)
。然后，这些更新后的logits通过softmax函数进行归一化，生成精炼的概率分布。

为了便于进行精确和灵活的调整，权重函数

W
(
n
)
W(n)





W

(

n

)
定义如下：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/2cdb7887192e46dbbd791fa93c74c0da.png)

其中，a 和 c 是控制函数上界和曲率的超参数。如图 2 所示，

W
(
n
)
W(n)





W

(

n

)
的形状确保了当边界框预测接近准确时，

W
(
n
)
W(n)





W

(

n

)
中的较小曲率允许进行更精细的调整。相反，如果边界框预测与准确值相差较远，

W
(
n
)
W(n)





W

(

n

)
边缘附近的较大曲率和边界处的急剧变化则确保了足够的灵活性以进行大幅度的修正。

为了进一步提高分布预测的准确性并使其与真实值对齐，受分布焦点损失（DFL）（Li等，2020）的启发，我们提出了一种新的损失函数——细粒度定位（FGL）损失，其计算公式如下：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/085e6d1401bb4d2b899c4d19bec3d030.png)

其中，

P
r
l
(
n
)
k
Pr^l(n)\_k





P


r









l

(

n


)









k

​

表示第 k 个预测对应的概率分布。

φ
φ





φ
是相对偏移量，计算公式为

φ
=
(
d
G
T
−
d
0
)
/
{
H
,
H
,
W
,
W
}
φ = (d^{GT} −d^0)/\{H, H, W, W \}





φ



=





(


d










GT



−






d









0

)

/

{

H

,



H

,



W

,



W

}
。

d
G
T
d^{GT}






d










GT
表示真实边缘距离，

n
←
n←





n



←
和

n
→
n→





n



→
是与

φ
φ





φ
相邻的区间索引。带有权重

ω
←
ω←





ω



←
和

ω
→
ω→





ω



→
的交叉熵（CE）损失确保区间之间的插值与真实偏移量精确对齐。通过引入基于 IoU 的加权，FGL 损失鼓励不确定性较低的分布更加集中，从而实现更精确和可靠的边界框回归。

### 4.2 全局最优定位自蒸馏

#### 全局最优定位自蒸馏 (GO-LSD)

全局最优定位自蒸馏（GO-LSD）利用最终层的精炼分布预测，将定位知识蒸馏到较浅的层中，如图3所示。该过程首先对每一层的预测应用匈牙利匹配（Carion等，2020），识别模型每个阶段的局部边界框匹配。为了进行全局优化，GO-LSD将所有层的匹配索引聚合到一个统一的联合集中。该联合集结合了各层中最准确的候选预测，确保它们都能从蒸馏过程中受益。除了精炼全局匹配外，GO-LSD还在训练过程中优化未匹配的预测，以提高整体稳定性，从而提升整体性能。尽管定位通过该联合集进行了优化，但分类任务仍遵循一对一匹配原则，确保没有冗余的边界框。这种严格的匹配意味着联合集中的一些预测定位准确但置信度较低。这些低置信度的预测通常代表定位精确的候选框，仍需有效蒸馏。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3b9626903a8a4d79b041a00e678e0171.png)

图3：GO-LSD过程概述。通过采用解耦加权策略的DDF损失，将最终层精炼分布中的定位知识蒸馏到较浅层中。

为了解决这一问题，我们提出了解耦蒸馏焦点（DDF）损失，该损失采用解耦加权策略，确保对高IoU但低置信度的预测给予适当的权重。DDF损失还根据匹配和未匹配预测的数量进行加权，平衡它们的整体贡献和个体损失。这种方法使得蒸馏过程更加稳定和有效。解耦蒸馏焦点损失LDDF的公式如下：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/24e5fc15bd4b402aacf18ab6d9ee95ce.png)

其中，KL 表示 Kullback-Leibler 散度（Hinton 等，2015），

T
T





T
是用于平滑 logits 的温度参数。第

k
k





k
个匹配预测的蒸馏损失由

α
k
α\_k






α









k

​

加权，其中

K
m
K\_m






K









m

​

和

K
u
K\_u






K









u

​

分别是匹配预测和不匹配预测的数量。对于第

k
k





k
个不匹配预测，权重为

β
k
β\_k






β









k

​

，其中

C
o
n
f
k
Conf\_k





C

o

n


f









k

​

表示分类置信度。

## 5.实验

### 5.1 实验设置

为了验证我们提出方法的有效性，我们在COCO（Lin等，2014a）和Objects365（Shao等，2019）数据集上进行了实验。我们使用标准的COCO指标评估了我们的D-FINE模型，包括在IoU阈值从0.50到0.95范围内的平均精度（AP），以及在特定阈值下的AP（AP50和AP75）和不同物体尺度下的AP：小物体（APS）、中物体（APM）和大物体（APL）。此外，我们还提供了模型效率指标，包括参数数量（#Params.）、计算成本（GFLOPs）和端到端延迟。延迟是在NVIDIA T4 GPU上使用TensorRT FP16进行测量的。

### 5.2 与实时检测器的比较

表1提供了D-FINE与多种实时目标检测器在COCO val2017上的全面对比。D-FINE在多个指标上实现了效率与准确性的出色平衡。具体而言，D-FINE-L以3100万参数和91 GFLOPs的计算量，达到了54.0%的AP，并保持了8.07毫秒的低延迟。此外，D-FINE-X以6200万参数和202 GFLOPs的计算量，实现了55.8%的AP，运行延迟为12.89毫秒。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/20d0e59869934a1cbd51601bbb5b95d1.png)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5dc74ec091c04573a4f780623a36e38a.png)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c2d2881320384ec0be3c875d4fbac6ef.png)

如图1所示，图中展示了延迟与AP、参数量与AP以及FLOPs与AP的散点图，D-FINE在所有关键维度上均优于其他最先进的模型。D-FINE-L实现了更高的AP（54.0%），相比YOLOv10-L（53.2%）、RTDETR-R50（53.1%）和LW-DETR-X（53.0%），同时所需的计算资源更少（91 GFLOPs vs. 120、136和174）。同样，D-FINE-X在性能上超越了YOLOv10-X和RT-DETR-R101，达到了更高的AP（55.8% vs. 54.4%和54.3%），并在参数量、FLOPs和延迟方面表现出更高的效率。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c9a7651bb12c43deb6d105a2ae7c39ed.png)

图1：与其他检测器在延迟（左）、模型大小（中）和计算成本（右）方面的比较。我们在NVIDIA T4 GPU上使用TensorRT FP16测量端到端延迟。

我们进一步在Objects365数据集（Shao等，2019）上对D-FINE和YOLOv10进行预训练，然后在COCO数据集上进行微调。预训练后，D-FINE-L和D-FINE-X均表现出显著的性能提升，分别达到了57.1%和59.3%的AP。这些改进使它们分别比YOLOv10-L和YOLOv10-X高出3.1%和4.4%的AP，从而在此次比较中成为表现最佳的模型。此外，按照YOLOv8（Glenn，2023）的预训练协议，YOLOv10在Objects365上进行了300个epoch的预训练。相比之下，D-FINE仅需21个epoch即可实现其显著的性能提升。这些发现验证了LW-DETR（Chen等，2024）的结论，表明基于DETR的模型相比YOLO等其他检测器，从预训练中获益更多。

### 5.3 在各种DETR模型上的有效性

表2展示了我们提出的FDR和GO-LSD方法在COCO val2017数据集上对多种基于DETR的目标检测器的有效性。我们的方法设计灵活，可以无缝集成到任何DETR架构中，在不增加参数数量和计算负担的情况下显著提升性能。将FDR和GO-LSD应用于Deformable DETR、DAD-DETR、DN-DETR和DINO后，检测精度均得到提升，提升幅度在2.0%到5.3%之间。这些结果凸显了FDR和GO-LSD在提高定位精度和最大化效率方面的有效性，展示了它们在不同端到端检测框架中的适应性和显著影响。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/96589930fe4c4ec99d2d2b3cb5e0383f.png)

### 5.4 消融实验

#### 5.4.1 D-FINE的路线图

表3展示了从基线模型（RT-DETR-HGNetv2-L，Zhao等，2024）逐步演进到我们提出的D-FINE框架的过程。从基线指标53.0% AP、32M参数、110 GFLOPs和9.25 ms延迟开始，我们首先移除了所有解码器投影层。这一修改将GFLOPs减少至97，并将延迟降低至8.02 ms，尽管AP下降至52.4%。为了解决这一下降，我们引入了目标门控层，将AP恢复至52.8%，同时仅略微增加了计算成本。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/539528b69ef943c79ec1d6dd24f0791b.png)
  
表3：从基线模型到D-FINE的逐步修改。每一步展示了AP、参数数量、延迟和FLOPs的变化。

目标门控层被策略性地放置在解码器的交叉注意力模块之后，取代了残差连接。它允许查询在不同层之间动态切换对不同目标的关注，从而有效防止信息纠缠。该机制的运作方式如下：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/52991a0c19ba4e159015322a6379148e.png)

其中，

x
1
x\_1






x









1

​

表示先前的查询，

x
2
x\_2






x









2

​

是交叉注意力结果。

σ
σ





σ
是应用于拼接输出的 sigmoid 激活函数，

[
.
]
[.]





[

.

]
表示拼接操作。

接下来，我们将编码器的CSP层替换为GELAN层（Wang & Liao, 2024）。这一替换将AP提升至53.5%，但也增加了参数量、GFLOPs和延迟。为了缓解复杂度的增加，我们减小了GELAN的隐藏维度，从而在保持AP为52.8%的同时平衡了模型的复杂度并提高了效率。我们进一步通过在不同尺度上实施不均匀采样（S: 3, M: 6, L: 3）来优化采样点，这使AP略微提升至52.9%。然而，其他采样组合如（S: 6, M: 3, L: 3）和（S: 3, M: 3, L: 6）会导致AP小幅下降0.1%。采用RT-DETRv2训练策略（Lv et al., 2024）（详见附录A.1.1）在不影响参数量或延迟的情况下将AP提升至53.0%。最后，集成FDR和GO-LSD模块将AP提升至54.0%，与基线模型相比，延迟减少了13%，GFLOPs减少了17%。这些逐步的改进展示了我们D-FINE框架的鲁棒性和有效性。

#### 5.4.2 超参数敏感性分析

第5.4.1节展示了一部分超参数消融研究，评估了我们的模型对FDR和GO-LSD模块中关键参数的敏感性。我们研究了权重函数参数

a
a





a
和

c
c





c
、分布区间数量

N
N





N
以及用于平滑KL散度中logits的温度参数

T
T





T
。

(1) 将a设为1.2，c设为1.4时，AP达到最高的53.3%。值得注意的是，将a和c作为可学习参数（ã, c̃）时，AP略微下降至53.1%，这表明固定值简化了优化过程。当c极大时，加权函数近似于等间隔的线性函数，导致AP降至53.0%。此外，a值过大或过小都会降低精细度或限制灵活性，从而对定位精度产生不利影响。

(2) 增加分布区间的数量可以提高性能，当N=32时，AP达到最高的53.7%。超过N=32后，未观察到显著提升。

(3) 温度T控制蒸馏过程中logits的平滑程度。当T=5时，AP达到最优的54.0%，这表明在软化分布和保持有效知识传递之间取得了平衡。

#### 5.4.3 蒸馏方法的比较

第5.4.1节比较了不同蒸馏方法在性能、训练时间和GPU内存使用方面的表现。基线模型的AP为53.0%，每个epoch的训练时间为29分钟，在四块NVIDIA RTX 4090 GPU上的内存使用量为8552 MB。由于DETR中一对一匹配的不稳定性，传统的蒸馏技术如Logit Mimicking和Feature Imitation并未提升性能；Logit Mimicking将AP降低至52.6%，而Feature Imitation的AP为52.9%。引入我们的FDR模块后，AP提升至53.8%，且训练成本增加极少。应用vanilla Localization Distillation（Zheng等，2022）进一步将AP提升至53.7%。我们的GO-LSD方法达到了最高的AP，为54.5%，与基线相比，训练时间仅增加6%，内存使用量仅增加2%。值得注意的是，在此比较中未应用任何轻量化优化，仅专注于蒸馏性能。

### 5.5 可视化分析

图4展示了FDR在不同检测场景中的处理过程。我们在图像上叠加了两个边界框来显示过滤后的检测结果。红色框表示来自第一解码器层的初始预测，而绿色框表示来自最终解码器层的精炼预测。最终预测与目标物体更加吻合。图像下方的第一行显示了四条边（左、上、右、下）的未加权概率分布。第二行显示了加权分布，其中应用了加权函数

W
(
n
)
W(n)





W

(

n

)
。红色曲线表示初始分布，而绿色曲线显示了最终的精炼分布。加权分布强调了在准确预测附近的细微调整，并允许在较大调整时进行快速变化，进一步说明了FDR如何精炼初始边界框的偏移，从而实现越来越精确的定位。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/eb1876c0c9c749b0b8552ef1e2f56b47.png)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/1e1afd603f7b45d8b67d592d7eea0de2.png)

图4：展示了在不同检测场景下，初始和优化后的边界框的FDR可视化结果，以及未加权和加权的分布情况，突显了定位精度的提升。

## 6.总结

在本文中，我们介绍了D-FINE，一种强大的实时目标检测器，它通过细粒度分布优化（FDR）和全局最优定位自蒸馏（GO-LSD）重新定义了DETR模型中的边界框回归任务。在COCO数据集上的实验结果表明，D-FINE在准确性和效率方面达到了最先进的水平，超越了所有现有的实时检测器。局限性与未来工作：然而，轻量级D-FINE模型与其他紧凑模型之间的性能差距仍然较小。一个可能的原因是浅层解码器层可能产生不太准确的最终层预测，限制了将定位知识蒸馏到早期层的效果。解决这一挑战需要在增加推理延迟的情况下增强轻量级模型的定位能力。未来的研究可以探索先进的架构设计或新颖的训练范式，允许在训练期间包含额外的复杂解码器层，同时在测试时通过简单地丢弃它们来保持轻量级推理。我们希望D-FINE能够激发这一领域的进一步进展。

## 7.附录

### A.1 实现细节

#### A.1.1 超参数配置

表6总结了D-FINE模型的超参数配置。所有变体均使用在ImageNet上预训练的HGNetV2骨干网络（Cui等，2021；Russakovsky等，2015）和AdamW优化器。D-FINE-X的嵌入维度设置为384，前馈维度为2048，而其他模型分别使用256和1024。D-FINE-X和D-FINE-L有6个解码层，而D-FINE-M和D-FINE-S分别有4个和3个解码层。GELAN模块逐步减少隐藏维度和深度，从D-FINE-X的192维和3层到D-FINE-S的64维和1层。D-FINE-X和D-FINE-L的基础学习率和权重衰减分别为

2.5
×
1
0
−
4
2.5 × 10^{−4}





2.5



×





1


0










−

4
和

1.25
×
1
0
−
4
1.25 × 10^{−4}





1.25



×





1


0










−

4
，而D-FINE-M和D-FINE-S使用

2
×
1
0
−
4
2 × 10^{−4}





2



×





1


0










−

4
和

1
×
1
0
−
4
1 × 10^{−4}





1



×





1


0










−

4
。较小的模型还具有比大模型更高的骨干网络学习率。所有变体的总批量大小为32。训练计划包括72个使用高级数据增强（RandomPhotometricDistort、RandomZoomOut、RandomIoUCrop和RMultiScaleInput）的epoch，随后是2个不使用高级数据增强的epoch（适用于D-FINE-X和D-FINE-L），以及120个使用高级数据增强的epoch，随后是4个不使用高级数据增强的epoch（适用于D-FINE-M和D-FINE-S）（参见表3中的RT-DETRv2训练策略（Lv等，2024））。D-FINE-X和D-FINE-L模型的预训练epoch数为21，而D-FINE-M和D-FINE-S模型的预训练epoch数在28到29之间。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4b32bee4005f40888882930014151445.png)
  
表6：不同D-FINE模型的超参数配置。

#### A.1.2 数据集设置

在预训练阶段，我们遵循（Chen et al., 2022b; Zhang et al., 2022; Chen et al., 2024）中的方法，将Objects365（Shao et al., 2019）训练集与验证集结合，并排除前5000张图像。为了进一步提高训练效率，我们预先将所有分辨率超过640×640的图像调整为640×640。我们采用标准的COCO2017（Lin et al., 2014b）数据划分策略，在COCO train2017上进行训练，并在COCO val2017上进行评估。

图5展示了D-FINE-X模型的鲁棒性，可视化了其在各种挑战性场景中的预测结果。这些场景包括遮挡、低光照条件、运动模糊、景深效果、旋转以及密集场景中多个物体近距离分布的情况。尽管面临这些困难，该模型仍能准确识别并定位物体，如动物、车辆和人物。这一可视化结果突显了模型在处理复杂现实条件的同时，仍能保持稳健的检测性能。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/231505e3a870423092eabe9c8f8a4d47.png)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/08411b2f18ab416ea8796e1079bb8831.png)

图5：D-FINE-X（未在Objects365上进行预训练）在具有挑战性条件下的预测可视化，包括遮挡、低光照、运动模糊、景深效果、旋转以及密集场景（置信度阈值=0.5）。

### A.3 与轻量级检测器的比较

表7全面对比了D-FINE模型与多种轻量级实时目标检测器在COCO val2017数据集上的S和M模型尺寸表现。D-FINE-S以48.5%的AP值取得了令人印象深刻的成绩，超越了Gold-YOLO-S（46.4%）和RT-DETRv2-S（48.1%）等其他轻量级模型，同时保持了3.49毫秒的低延迟，仅需10.2M参数和25.2 GFLOPs。在Objects365数据集上的预训练进一步将D-FINE-S提升至50.7%，实现了+2.2%的改进。同样，D-FINE-M以19.2M参数和56.6 GFLOPs在5.62毫秒内达到了52.3%的AP值，优于YOLOv10-M（51.1%）和RT-DETRv2-M（49.9%）。在Objects365上的预训练持续提升了D-FINE-M，带来了+2.8%的增益。这些结果表明，D-FINE模型在准确性和效率之间取得了极佳的平衡，始终超越其他最先进的轻量级检测器，同时保持了实时性能。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/fa983408afae4c9e955a07c9069b281d.png)
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4bbd3f0726604740a8c38bc322179cc1.png)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/74d649fc61384bffb4bf8c6c6a628b90.png)

表7：S和M尺寸实时目标检测器在COCO val2017上的性能对比。

### A.4 初始层细化说明

在正文中，我们将第l层的精炼分布定义为：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/ce69e907ad69403f8254941ca24654e6.png)

其中，

∆
l
o
g
i
t
s
l
(
n
)
∆logits^l(n)





∆

l

o

g

i

t


s









l

(

n

)
是第

l
l





l
层预测的残差 logits，

l
o
g
i
t
s
l
−
1
(
n
)
logits^{l−1}(n)





l

o

g

i

t


s










l

−

1

(

n

)
是前一层的 logits。

对于初始层（l = 1），由于没有前一层，因此公式简化为：

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e1731729237a40798c85c3d1128ecf64.png)

此处，

l
o
g
i
t
s
1
(
n
)
logits^1(n)





l

o

g

i

t


s









1

(

n

)
是由第一层预测的 logits。这一澄清确保了公式在所有层中保持一致且数学上严谨。