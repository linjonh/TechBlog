---
layout: post
title: "LLM时代的小模型思考What-is-the-Role-of-Small-Models-in-the-LLM-Era-A-Survey论文笔记"
date: 2025-03-08 14:25:31 +0800
description: "What is the Role of Small Models in the LLM Era: A Survey论文阅读，主要讲解大模型与小模型之间的关系。"
keywords: "LLM时代的小模型思考：《What is the Role of Small Models in the LLM Era: A Survey》论文笔记"
categories: ['Reading', 'Paper', 'Nlp', 'Learning']
tags: ['论文阅读']
artid: "146115935"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146115935
    alt: "LLM时代的小模型思考What-is-the-Role-of-Small-Models-in-the-LLM-Era-A-Survey论文笔记"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146115935
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146115935
cover: https://bing.ee123.net/img/rand?artid=146115935
image: https://bing.ee123.net/img/rand?artid=146115935
img: https://bing.ee123.net/img/rand?artid=146115935
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     LLM时代的小模型思考：《What is the Role of Small Models in the LLM Era: A Survey》论文笔记
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <blockquote>
     <p>
      论文：What is the Role of Small Models in the LLM Era: A Survey
     </p>
     <p>
      作者：Lihu Chen et al.
     </p>
     <p>
      单位：Imperial College London
     </p>
    </blockquote>
    <h4>
     <a id="Abstract_6">
     </a>
     Abstract
    </h4>
    <p>
     问题：
    </p>
    <ol>
     <li>
      扩大模型大小会导致计算成本和能耗呈指数级增长，这使得这些模型对于学术研究人员和资源有限的企业来说不切实际
     </li>
     <li>
      小型模型 （SMs） 经常用于实际环境中，引发了关于小模型在 LLM 时代的作用的重要问题，且关注有限
     </li>
    </ol>
    <p>
     方法：系统性研究LLM与SM之间的关系：合作与竞争
    </p>
    <h4>
     <a id="Introduction_15">
     </a>
     Introduction
    </h4>
    <p>
     规模定律引发的模型能力增强，但随着规模增大资源消耗呈指数级增长，使得资源有限的研究者受制约
    </p>
    <p>
     现象：小模型仍然大量存在，并且业务广泛
    </p>
    <p>
     小模型：指参数数量相对较少的模型，不仅包括语言模型，还包括简单的统计模型和浅层神经网络
    </p>
    <p>
     4个评估维度：
    </p>
    <ol>
     <li>
      准确率
     </li>
     <li>
      泛化能力
     </li>
     <li>
      模型效率
     </li>
     <li>
      可解释性
     </li>
    </ol>
    <p>
     <img alt="LLM vs SM" src="https://i-blog.csdnimg.cn/direct/4d77b1ea45524f0f8c63160f1672dcaa.jpeg"/>
    </p>
    <p>
     2个方面考虑：
    </p>
    <ol>
     <li>
      合作：LLM 和 SM 之间的协作可以在功率和效率之间取得平衡，使系统能够实现资源高效、可扩展、可解释且经济高效的系统，同时保持高性能和灵活性
     </li>
     <li>
      竞争：根据任务或应用程序的具体要求，仔细评估 LLM 和 SM 之间的权衡至关重要
     </li>
    </ol>
    <h4>
     <a id="Collaboration_38">
     </a>
     Collaboration
    </h4>
    <p>
     <img alt="Survey" src="https://i-blog.csdnimg.cn/direct/475dc07321de40b49c9b99af77d7a0e2.jpeg"/>
    </p>
    <h5>
     <a id="Small_Models_Enhance_LLMs_43">
     </a>
     Small Models Enhance LLMs
    </h5>
    <p>
     <strong>
      数据管理
     </strong>
     :
    </p>
    <ol>
     <li>
      整理预训练数据：
      <ul>
       <li>
        问题：
        <ul>
         <li>
          数据可用性是有限的，并且公共人类文本数据可能很快就会耗尽
         </li>
         <li>
          数据噪声、低质
         </li>
        </ul>
       </li>
       <li>
        数据选择方法：
        <ul>
         <li>
          使用小模型判断数据质量，移除噪声、隐私数据
         </li>
         <li>
          打分评估
         </li>
        </ul>
       </li>
       <li>
        数据重新加权方法：使用小模型设置领域权重，增强大模型跨领域的泛化能力
       </li>
      </ul>
     </li>
     <li>
      整理指令调优数据：
      <ul>
       <li>
        使用小得多的数据集可以实现强对齐
       </li>
       <li>
        面向模型的数据选择：较小的模型可用于选择有影响力的数据，不仅适用于较大的模型，还可用于选择来自不同系列的模型
       </li>
      </ul>
     </li>
    </ol>
    <p>
     <strong>
      从弱到强的范式
     </strong>
     ：通过单/多个的小模型进行评价/输出标签，增强模型的在弱监督情况下的对齐
    </p>
    <p>
     问题：由于模型能力过强，人类评估者难以衡量输出的正确性与安全性。
    </p>
    <p>
     大的、更强的模型在由较小、能力较弱的模型生成的标签上进行微调，使强模型能够超越其较弱的监督者的限制进行泛化
    </p>
    <p>
     <strong>
      高效推理
     </strong>
     ：
    </p>
    <ol>
     <li>
      模型集成：
      <ul>
       <li>
        模型级联：涉及按顺序使用多个模型进行预测或决策，其中级联中的每个模型具有不同的复杂程度。
       </li>
       <li>
        模型路由：通过将输入数据动态定向到最合适的模型，优化不同大小的多个模型的部署
       </li>
      </ul>
     </li>
     <li>
      推测解码：加快生成模型的解码过程，这通常涉及使用更小、更快的辅助模型以及主要的较大模型。
     </li>
    </ol>
    <p>
     <strong>
      评估LLMs
     </strong>
     ：
    </p>
    <ol>
     <li>
      传统评估手段无法捕捉生成文本的细微语义含义和组合多样性，难以评估LLM
     </li>
     <li>
      BERTSCORE、NLI模型应用到评估LLM表现
     </li>
    </ol>
    <p>
     <strong>
      领域适应性
     </strong>
     ：使用较小的模型调整 LLM
    </p>
    <ol>
     <li>
      白盒适配：通常涉及微调小型模型，以调整特定目标域的冻结 LLM 的令牌分配，不适合API方式的LLM调用
     </li>
     <li>
      适配适配：涉及使用特定于小领域的模型，通过提供文本相关知识来引导 LLM 走向目标领域
     </li>
    </ol>
    <p>
     <strong>
      RAG
     </strong>
     ：
    </p>
    <ol>
     <li>
      结构化文档：Wikipedia、跨语言文本、特定领域语料库、法律文献等，小模型包括了BM25、基于BERT的检索器等
     </li>
     <li>
      结构化知识：KnowledgeGPT、T-RAG、StructGPT
     </li>
     <li>
      其他数据源：DocPrompting
     </li>
    </ol>
    <p>
     <strong>
      提示学习
     </strong>
     ：
    </p>
    <ol>
     <li>
      使用小型模型来增强提示，从而提高大型模型的性能
      <ul>
       <li>
        Uprise （小模型自动检索Prompt并优化）
       </li>
       <li>
        DaSLaM（小模型进行任务分解）
       </li>
      </ul>
     </li>
     <li>
      使用小模型生成伪标签
     </li>
     <li>
      使用小模型验证/重写
     </li>
    </ol>
    <p>
     <strong>
      缺陷修复
     </strong>
     ：LLM 可能会生成重复的、不真实的和有毒的内容，可以使用小模型来修复这些缺陷
    </p>
    <ol>
     <li>
      对比解码：通过选择最大化对数似然差的标记，利用较大模型 （EXPERT） 和较小模型 （amateur） 之间的对比。
     </li>
     <li>
      小模型插件：微调专用的小模型，以解决较大模型的一些缺点
     </li>
    </ol>
    <h5>
     <a id="LLMs_Enhance_Small_Models_101">
     </a>
     LLMs Enhance Small Models
    </h5>
    <p>
     <strong>
      知识蒸馏
     </strong>
     ：
    </p>
    <p>
     问题：将模型扩展到更大的大小是提高性能的一种简单方法，但事实证明，对于向众多用户进行广泛部署而言，它的计算成本通常太高
    </p>
    <ol>
     <li>
      白盒知识蒸馏：涉及使用 Teacher 模型的内部状态，这在 Student 模型的训练过程中提供了透明度
     </li>
     <li>
      黑盒知识蒸馏：通过教师 LLM 生成蒸馏数据集，然后将其用于微调学生模型
     </li>
    </ol>
    <p>
     <strong>
      数据合成
     </strong>
     ：使用 LLM 为小模型训练生成训练数据既高效又可行
    </p>
    <ol>
     <li>
      训练数据生成：首先使用 LLM（例如 ChatGPT）以无监督的方式从头开始生成数据集，然后在合成的数据集上训练一个特定于任务的小型模型
     </li>
     <li>
      数据增强：使用 LLM 修改现有数据点，从而增加数据多样性，然后可以直接用于训练较小的模型
     </li>
    </ol>
    <h4>
     <a id="Competition_115">
     </a>
     Competition
    </h4>
    <h5>
     <a id="Computationconstrained_Environment_117">
     </a>
     Computation-constrained Environment
    </h5>
    <p>
     问题：扩展模型大小会导致训练时间呈指数级增长，并且推理延迟显著增加
    </p>
    <p>
     趋势：在对可访问性、效率和民主化的需求的推动下，人们越来越多地转向更小、更高效的模型
    </p>
    <h5>
     <a id="Taskspecific_Environment_123">
     </a>
     Task-specific Environment
    </h5>
    <p>
     问题：对于某些专业域，通常没有足够的数据，无法支撑大模型训练
    </p>
    <p>
     任务包括了：
    </p>
    <ol>
     <li>
      特定领域任务：生物医学或法律领域等领域通常可用的训练令牌较少
     </li>
     <li>
      表格学习：由于这些特性，与表格数据的大型深度学习模型相比，基于树的小型模型可以实现有竞争力的性能
     </li>
     <li>
      短文任务：简短的文本表示和推理通常不需要广泛的背景知识
     </li>
     <li>
      其他特殊任务：机器生成的文本检测
     </li>
    </ol>
    <h5>
     <a id="Interpretabilityrequired_Environment_134">
     </a>
     Interpretability-required Environment
    </h5>
    <p>
     可解释性的目标是为模型的内部推理过程提供人类可理解的解释
    </p>
    <p>
     与更大（例如深层）和更简单的（例如基于树的）模型相比，LLER（例如浅层）和更简单的（例如基于树）模型提供了更好的可解释性
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34303733373739382f:61727469636c652f64657461696c732f313436313135393335" class_="artid" style="display:none">
 </p>
</div>


