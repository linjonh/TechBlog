---
layout: post
title: "LLM时代的小模型思考What-is-the-Role-of-Small-Models-in-the-LLM-Era-A-Survey论文笔记"
date: 2025-03-08 14:25:31 +0800
description: "What is the Role of Small Models in the LLM Era: A Survey论文阅读，主要讲解大模型与小模型之间的关系。"
keywords: "LLM时代的小模型思考：《What is the Role of Small Models in the LLM Era: A Survey》论文笔记"
categories: ['Reading', 'Paper', 'Nlp', 'Learning']
tags: ['论文阅读']
artid: "146115935"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146115935
    alt: "LLM时代的小模型思考What-is-the-Role-of-Small-Models-in-the-LLM-Era-A-Survey论文笔记"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146115935
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146115935
cover: https://bing.ee123.net/img/rand?artid=146115935
image: https://bing.ee123.net/img/rand?artid=146115935
img: https://bing.ee123.net/img/rand?artid=146115935
---

# LLM时代的小模型思考：《What is the Role of Small Models in the LLM Era: A Survey》论文笔记

> 论文：What is the Role of Small Models in the LLM Era: A Survey
>
> 作者：Lihu Chen et al.
>
> 单位：Imperial College London

#### Abstract

问题：

  1. 扩大模型大小会导致计算成本和能耗呈指数级增长，这使得这些模型对于学术研究人员和资源有限的企业来说不切实际
  2. 小型模型 （SMs） 经常用于实际环境中，引发了关于小模型在 LLM 时代的作用的重要问题，且关注有限

方法：系统性研究LLM与SM之间的关系：合作与竞争

#### Introduction

规模定律引发的模型能力增强，但随着规模增大资源消耗呈指数级增长，使得资源有限的研究者受制约

现象：小模型仍然大量存在，并且业务广泛

小模型：指参数数量相对较少的模型，不仅包括语言模型，还包括简单的统计模型和浅层神经网络

4个评估维度：

  1. 准确率
  2. 泛化能力
  3. 模型效率
  4. 可解释性

![LLM vs
SM](https://i-blog.csdnimg.cn/direct/4d77b1ea45524f0f8c63160f1672dcaa.jpeg)

2个方面考虑：

  1. 合作：LLM 和 SM 之间的协作可以在功率和效率之间取得平衡，使系统能够实现资源高效、可扩展、可解释且经济高效的系统，同时保持高性能和灵活性
  2. 竞争：根据任务或应用程序的具体要求，仔细评估 LLM 和 SM 之间的权衡至关重要

#### Collaboration

![Survey](https://i-blog.csdnimg.cn/direct/475dc07321de40b49c9b99af77d7a0e2.jpeg)

##### Small Models Enhance LLMs

**数据管理** :

  1. 整理预训练数据： 
     * 问题： 
       * 数据可用性是有限的，并且公共人类文本数据可能很快就会耗尽
       * 数据噪声、低质
     * 数据选择方法： 
       * 使用小模型判断数据质量，移除噪声、隐私数据
       * 打分评估
     * 数据重新加权方法：使用小模型设置领域权重，增强大模型跨领域的泛化能力
  2. 整理指令调优数据： 
     * 使用小得多的数据集可以实现强对齐
     * 面向模型的数据选择：较小的模型可用于选择有影响力的数据，不仅适用于较大的模型，还可用于选择来自不同系列的模型

**从弱到强的范式** ：通过单/多个的小模型进行评价/输出标签，增强模型的在弱监督情况下的对齐

问题：由于模型能力过强，人类评估者难以衡量输出的正确性与安全性。

大的、更强的模型在由较小、能力较弱的模型生成的标签上进行微调，使强模型能够超越其较弱的监督者的限制进行泛化

**高效推理** ：

  1. 模型集成： 
     * 模型级联：涉及按顺序使用多个模型进行预测或决策，其中级联中的每个模型具有不同的复杂程度。
     * 模型路由：通过将输入数据动态定向到最合适的模型，优化不同大小的多个模型的部署
  2. 推测解码：加快生成模型的解码过程，这通常涉及使用更小、更快的辅助模型以及主要的较大模型。

**评估LLMs** ：

  1. 传统评估手段无法捕捉生成文本的细微语义含义和组合多样性，难以评估LLM
  2. BERTSCORE、NLI模型应用到评估LLM表现

**领域适应性** ：使用较小的模型调整 LLM

  1. 白盒适配：通常涉及微调小型模型，以调整特定目标域的冻结 LLM 的令牌分配，不适合API方式的LLM调用
  2. 适配适配：涉及使用特定于小领域的模型，通过提供文本相关知识来引导 LLM 走向目标领域

**RAG** ：

  1. 结构化文档：Wikipedia、跨语言文本、特定领域语料库、法律文献等，小模型包括了BM25、基于BERT的检索器等
  2. 结构化知识：KnowledgeGPT、T-RAG、StructGPT
  3. 其他数据源：DocPrompting

**提示学习** ：

  1. 使用小型模型来增强提示，从而提高大型模型的性能 
     * Uprise （小模型自动检索Prompt并优化）
     * DaSLaM（小模型进行任务分解）
  2. 使用小模型生成伪标签
  3. 使用小模型验证/重写

**缺陷修复** ：LLM 可能会生成重复的、不真实的和有毒的内容，可以使用小模型来修复这些缺陷

  1. 对比解码：通过选择最大化对数似然差的标记，利用较大模型 （EXPERT） 和较小模型 （amateur） 之间的对比。
  2. 小模型插件：微调专用的小模型，以解决较大模型的一些缺点

##### LLMs Enhance Small Models

**知识蒸馏** ：

问题：将模型扩展到更大的大小是提高性能的一种简单方法，但事实证明，对于向众多用户进行广泛部署而言，它的计算成本通常太高

  1. 白盒知识蒸馏：涉及使用 Teacher 模型的内部状态，这在 Student 模型的训练过程中提供了透明度
  2. 黑盒知识蒸馏：通过教师 LLM 生成蒸馏数据集，然后将其用于微调学生模型

**数据合成** ：使用 LLM 为小模型训练生成训练数据既高效又可行

  1. 训练数据生成：首先使用 LLM（例如 ChatGPT）以无监督的方式从头开始生成数据集，然后在合成的数据集上训练一个特定于任务的小型模型
  2. 数据增强：使用 LLM 修改现有数据点，从而增加数据多样性，然后可以直接用于训练较小的模型

#### Competition

##### Computation-constrained Environment

问题：扩展模型大小会导致训练时间呈指数级增长，并且推理延迟显著增加

趋势：在对可访问性、效率和民主化的需求的推动下，人们越来越多地转向更小、更高效的模型

##### Task-specific Environment

问题：对于某些专业域，通常没有足够的数据，无法支撑大模型训练

任务包括了：

  1. 特定领域任务：生物医学或法律领域等领域通常可用的训练令牌较少
  2. 表格学习：由于这些特性，与表格数据的大型深度学习模型相比，基于树的小型模型可以实现有竞争力的性能
  3. 短文任务：简短的文本表示和推理通常不需要广泛的背景知识
  4. 其他特殊任务：机器生成的文本检测

##### Interpretability-required Environment

可解释性的目标是为模型的内部推理过程提供人类可理解的解释

与更大（例如深层）和更简单的（例如基于树的）模型相比，LLER（例如浅层）和更简单的（例如基于树）模型提供了更好的可解释性



