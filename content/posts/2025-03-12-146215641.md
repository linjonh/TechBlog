---
layout: post
title: "大模型微调使用-LLaMA-Factory-微调-Llama3-8B-Chinese-Chat-完成知识问答任务"
date: 2025-03-12 23:16:54 +0800
description: "本篇博客记录如何使用 LLaMA-Factory 微调 Llama3-8B-Chinese-Chat 完成知识问答任务，并介绍相应报错的解决方法。"
keywords: "大模型微调｜使用 LLaMA-Factory 微调 Llama3-8B-Chinese-Chat 完成知识问答任务"
categories: ['碎片笔记', '大模型']
tags: ['微调', '大模型微调', '大模型', 'Unsloth', 'Llm', 'Llama', 'Factory']
artid: "146215641"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146215641
    alt: "大模型微调使用-LLaMA-Factory-微调-Llama3-8B-Chinese-Chat-完成知识问答任务"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146215641
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146215641
cover: https://bing.ee123.net/img/rand?artid=146215641
image: https://bing.ee123.net/img/rand?artid=146215641
img: https://bing.ee123.net/img/rand?artid=146215641
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     大模型微调｜使用 LLaMA-Factory 微调 Llama3-8B-Chinese-Chat 完成知识问答任务
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <blockquote>
     <p>
      <strong>
       前言
      </strong>
      ：本篇博客分享如何基于LLaMA-Factory使用现有金融数据集实现LLaMA3的微调，以完成金融领域的知识问答任务。
     </p>
     <p>
      –
      <br/>
      参考教程：
      <a href="https://github.com/echonoshy/cgft-llm/tree/master/llama-factory">
       https://github.com/echonoshy/cgft-llm/tree/master/llama-factory
      </a>
      <br/>
      相关视频：
      <a href="https://www.bilibili.com/video/BV1uw4m1S7Cd/" rel="nofollow">
       https://www.bilibili.com/video/BV1uw4m1S7Cd/
      </a>
     </p>
    </blockquote>
    <p>
     📝写在前面：其实github教程已经很详细了，但是自己在按照教程里的步骤实现的时候，由于环境版本各种不适配等原因，还是遇到了很多问题，在此记录一下，希望能够帮到大家。
    </p>
    <p>
    </p>
    <p>
    </p>
    <hr/>
    <h2>
     <a id="0_cuda_12">
     </a>
     0. 计算资源介绍（显卡&amp;cuda）
    </h2>
    <p>
     使用的服务器资源信息：
    </p>
    <ol>
     <li>
      RTX 4090 (24GB) × 1
     </li>
     <li>
      cuda版本 12.0
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/5e6e7716deb24751bf5d3365c7522051.png"/>
     </li>
    </ol>
    <hr/>
    <h2>
     <a id="1_CondaPython_310_19">
     </a>
     1. Conda环境搭建（Python 3.10）
    </h2>
    <p>
     新建conda环境，⚠️python版本要高于3.9（否则无法正常使用llamafactory），这里选取python 3.10版本。
    </p>
    <pre><code class="prism language-python">conda create <span class="token operator">-</span>n demo python<span class="token operator">==</span><span class="token number">3.10</span>
conda activate demo <span class="token comment">#切换到新建的demo环境中</span>
</code></pre>
    <p>
     然后，安装必要的库，以下是关键库的版本信息：
    </p>
    <p>
     ⚠️：我这里给出的版本不一定适用于各位，要结合自己的cuda版本（使用
     <code>
      nvidia-smi
     </code>
     命令查看）来安装，保证版本的兼容。
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/772eeb3abdaa4916ab2e703e3cb09c13.png">
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/612f26a8c65d4755b065e07ca5511f2f.png"/>
     </img>
    </p>
    <p>
     ⚠️：这一步很关键！一定要选择适合硬件版本的库，否则在后续的微调过程中会经历长时间的debug……
    </p>
    <hr/>
    <h2>
     <a id="2_LLaMA3_8B_37">
     </a>
     2. 基座模型下载（LLaMA3 8B）
    </h2>
    <p>
     选用基于中文数据训练过的 LLaMA3 8B 模型：
     <a href="https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat" rel="nofollow">
      shenzhi-wang/Llama3-8B-Chinese-Chat
     </a>
    </p>
    <p>
     依次执行以下命令下载上述模型：
    </p>
    <pre><code class="prism language-python">pip install <span class="token operator">-</span>U huggingface_hub
export HF_ENDPOINT<span class="token operator">=</span>https<span class="token punctuation">:</span><span class="token operator">//</span>hf<span class="token operator">-</span>mirror<span class="token punctuation">.</span>com  <span class="token comment"># （可选）配置 hf 国内镜像站 </span>
huggingface<span class="token operator">-</span>cli download <span class="token operator">-</span><span class="token operator">-</span>resume<span class="token operator">-</span>download shenzhi<span class="token operator">-</span>wang<span class="token operator">/</span>Llama3<span class="token operator">-</span>8B<span class="token operator">-</span>Chinese<span class="token operator">-</span>Chat <span class="token operator">-</span><span class="token operator">-</span>local<span class="token operator">-</span><span class="token builtin">dir</span> <span class="token operator">/</span>newdata<span class="token operator">/</span>z_demo<span class="token operator">/</span>Llama3<span class="token operator">-</span>8B<span class="token operator">-</span>Chinese<span class="token operator">-</span>Chat 
</code></pre>
    <p>
     –local-dir参数
     <code>
      /newdata/z_demo/Llama3-8B-Chinese-Chat
     </code>
     替换为下载路径。
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/1ab3250776c548efbcffaaf37ec9f13b.png"/>
    </p>
    <hr/>
    <h2>
     <a id="3_LLaMAFactory__52">
     </a>
     3. LLaMA-Factory 框架安装
    </h2>
    <p>
     首先下载LLaMA-Factory，有以下两种方式：
    </p>
    <ul>
     <li>
      执行
      <code>
       git clone https://github.com/hiyouga/LLaMA-Factory.git
      </code>
      自动下载LLaMA-Factory，但该方法常常由于网络原因下载失败。
     </li>
     <li>
      手动下载该项目后上传到服务器对应目录下。
     </li>
    </ul>
    <p>
     下载完成后，终端执行
     <code>
      cd LLaMA-Factory-main
     </code>
     命令切换到对应目录下，然后执行
     <code>
      pip install -e .
     </code>
     安装。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/16a42d552c65425683b90dfea26da42a.png">
      <br/>
      （安装需要一定时间，本人这里网速较慢，大约1h完成）
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/8b01e487a36e4a738252768c3b6b32dd.png"/>
     </img>
    </p>
    <hr/>
    <h2>
     <a id="4__67">
     </a>
     4. 训练数据准备
    </h2>
    <p>
     下载训练数据，将其放到LLaMA-Factory-main的data子目录下，包括
     <code>
      identity.json（457行）
     </code>
     、
     <code>
      fintech.json（2648行）
     </code>
     以及
     <code>
      dataset_info.json（484行）
     </code>
     这三个文件。
    </p>
    <p>
     ⚠️：这里的训练数据就是接下来模型微调会用到的数据。
    </p>
    <hr/>
    <h2>
     <a id="5__75">
     </a>
     5. 模型微调
    </h2>
    <p>
     ⚠️：可以在步骤5.1的UI界面中开启微调，也可以采用步骤5.2中命令行的方法微调（本博客中选择后者）。
    </p>
    <h3>
     <a id="51_WebUI_78">
     </a>
     5.1 基于WebUI的微调
    </h3>
    <p>
     终端执行
     <code>
      cd LLaMA-Factory-main
     </code>
     切换到该目录，然后执行
     <code>
      llamafactory-cli webui
     </code>
     打开UI界面：
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/4b21d5ee821a4e30b2081fb6b16c75fb.png"/>
    </p>
    <h3>
     <a id="52__84">
     </a>
     5.2 基于命令的微调
    </h3>
    <p>
     首先将
     <code>
      LLaMA-Factory-main/cust/train_llama3_lora_sft.yaml
     </code>
     文件中的模型加载路径
     <code>
      model_name_or_path
     </code>
     和保存路径
     <code>
      output_dir
     </code>
     进行如实修改：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/c2d398f33c9c4f4e8771f0d9cd2c9ae2.png"/>
    </p>
    <p>
     然后在终端依次执行命令：
    </p>
    <pre><code class="prism language-python">export NCCL_IB_DISABLE<span class="token operator">=</span><span class="token number">1</span>
export NCCL_P2P_DISABLE<span class="token operator">=</span><span class="token number">1</span>
CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">0</span> llamafactory<span class="token operator">-</span>cli train cust<span class="token operator">/</span>train_llama3_lora_sft<span class="token punctuation">.</span>yaml <span class="token comment"># 指定使用id=0的显卡</span>
</code></pre>
    <p>
     成功训练：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/bbb15620919d4c5790eb48a3d1acacc5.png">
      <br/>
      经过一段时间（30min左右）的等待，训练完毕：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/57f4692a9fcb444a9c0086c95a95e9d0.png"/>
     </img>
    </p>
    <p>
     至此，得到训练好的 LoRA Adapter（150M左右），保存在之前设置好的
     <code>
      output_dir
     </code>
     （saves/LLaMA3-8B-Chinese-Chat/lora/train_demo）目录下，训练loss变化图也在其中（如下）。
    </p>
    <p>
     <img alt="在这里插入图片描述" height="250" src="https://i-blog.csdnimg.cn/direct/134fe8f7e2b84a11b3e6bc3634e3dd9d.png"/>
    </p>
    <h2>
     <a id="6_Debug_104">
     </a>
     6. 微调Debug历程故障排除
    </h2>
    <p>
     ⚠️：如果不执行上面那两个export相关命令会报如下错误：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/5681df09eef04654b3fd27df91938dcb.png"/>
    </p>
    <p>
     ⚠️： 如果在环境搭建时未安装unsloth库，则会报错如下：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/9a9b4f30b8464a0f8a532d76d838ac17.png"/>
    </p>
    <p>
     ⚠️：如果遇到下述错误：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/106db6a45562493f921fd7d185a2e835.png"/>
    </p>
    <p>
     根据
     <a href="https://github.com/huggingface/datasets/issues/1784">
      相关资料
     </a>
     ，解决方案为：
    </p>
    <p>
     在
     <code>
      LLaMA-Factory-main/src/llamafactory/extras/env.py
     </code>
     文件中添加下列代码：
    </p>
    <pre><code class="prism language-python">datasets<span class="token punctuation">.</span>builder<span class="token punctuation">.</span>has_sufficient_disk_space <span class="token operator">=</span> <span class="token keyword">lambda</span> needed_bytes<span class="token punctuation">,</span> directory<span class="token operator">=</span><span class="token string">'.'</span><span class="token punctuation">:</span> <span class="token boolean">True</span>
</code></pre>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/81f0953d8c1d4dc3b3ebf199500485cf.png"/>
    </p>
    <p>
     ⚠️：如果遇到如下错误，说明triton库的版本出了问题，参见
     <code>
      步骤1 环境搭建
     </code>
     安装合适版本的triton库。
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/c63a394aa6514b409e2906babac80f9b.png"/>
    </p>
    <hr/>
    <h2>
     <a id="7__130">
     </a>
     7. 在线对话
    </h2>
    <p>
     这里挑选了
     <code>
      fintech.json
     </code>
     文件中的一个例子：
    </p>
    <blockquote>
     <p>
      根据金融研报，为什么白酒板块的估值下探空间已经不大？\n基于以下材料回答上述问题:\n\n投资建议：前期估值和市值对预期反应充分，近期刺激消费的政策陆续出台，我们认为居民消费信心有望逐步恢复，下半年改善节奏有望加速。 白酒板块：三重底部估值底、预期底、基本面底或已确认，预计当前在宏观环境边际改善、业绩确定性较强情况下估值下探空间或已不大、下半年基本面压力趋缓的情况下可以逐步乐观。 首推优质龙头，推荐泸州老窖、贵州茅台、五粮液、山西汾酒、古井贡酒；其次看多超跌的弹性品种，老白干酒、金种子酒、酒鬼酒、顺鑫农业。 大众品板块：消费本身中长期逻辑（消费升级+集中度提升）未发生重大变化，宏观政策向好提振消费信心，我们预计与餐饮、出行相关的消费场景有望优先恢复。
     </p>
    </blockquote>
    <h3>
     <a id="71_Web_UI__136">
     </a>
     7.1 Web UI 对话
    </h3>
    <p>
     <strong>
      方式一
     </strong>
     ：使用 Web UI 界面进行对话：在
     <code>
      LLaMA-Factory-main
     </code>
     目录下执行命令
     <code>
      CUDA_VISIBLE_DEVICES=0 llamafactory-cli webchat cust/train_llama3_lora_sft.yaml
     </code>
     ，报错如下：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/0e714c69495f4e24adb9609b18dbf40f.png"/>
     <br/>
     根据
     <a href="https://github.com/hiyouga/LLaMA-Factory/issues/6757">
      相关资料
     </a>
     参考，尝试删除
     <code>
      train_llama3_lora_sft.yaml
     </code>
     文件中的未使用参数
     <code>
      ['do_train', 'fp16', 'gradient_accumulation_steps', 'learning_rate', 'logging_steps', 'lr_scheduler_type', 'max_grad_norm', 'num_train_epochs', 'optim', 'output_dir', 'per_device_train_batch_size', 'report_to', 'save_steps', 'warmup_steps']
     </code>
     ，再次运行：
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/fb8c4fb918784ba5ad5a02d3331f7f64.png"/>
     <br/>
     成功跳转到下述页面：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b96c2a1817af466b98d9e3e62824eb4e.png"/>
    </p>
    <p>
     Web UI 界面语言默认
     <code>
      en
     </code>
     （英文），改成
     <code>
      zh
     </code>
     （中文），浅浅尝试一下效果：
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/61fbe9370f0f4385b828616fdff3e554.png"/>
     <br/>
     回答如下：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/2bfed1138e4f422697998785aab4feb0.png"/>
    </p>
    <h3>
     <a id="72__151">
     </a>
     7.2 终端对话
    </h3>
    <p>
     <strong>
      方式二
     </strong>
     ：直接在终端对话，在
     <code>
      LLaMA-Factory-main
     </code>
     目录下执行命令
     <code>
      CUDA_VISIBLE_DEVICES=0 llamafactory-cli chat cust/train_llama3_lora_sft.yaml
     </code>
     ：
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/ec6c6f7b3edb419683c919b6ec31329b.png"/>
    </p>
    <h3>
     <a id="73_OpenAI_API__157">
     </a>
     7.3 OpenAI API 对话
    </h3>
    <p>
     <strong>
      方式三
     </strong>
     ：使用OpenAI API风格进行对话：
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 指定多卡和端口</span>
CUDA_VISIBLE_DEVICES<span class="token operator">=</span><span class="token number">0</span> API_PORT<span class="token operator">=</span><span class="token number">8000</span> 
llamafactory<span class="token operator">-</span>cli api cust<span class="token operator">/</span>train_llama3_lora_sft<span class="token punctuation">.</span>yaml
</code></pre>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/884f5c5c5b0145ef9e58d3ff9a1511db.png"/>
    </p>
    <p>
     ⚠️：这种方式未成功，知道原因的小伙伴可以分享一下解决方案，在这里不深究了
    </p>
    <p>
     <img alt="在这里插入图片描述" height="100" src="https://i-blog.csdnimg.cn/direct/c60428f8ae984f7289e48258178856b5.png"/>
    </p>
    <hr/>
    <h2>
     <a id="8__173">
     </a>
     8. 模型合并
    </h2>
    <p>
     运行
     <code>
      llamafactory-cli export cust/merge_llama3_lora_sft.yaml
     </code>
     命令，将步骤2中的基座模型与步骤6中训练好的 LoRA Adapter 合并成一个新的模型。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/69b807b4595449c9b2b18e95ec5263b3.png"/>
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/5083e34f63e3470f95629801cab316a8.png"/>
    </p>
    <hr/>
    <blockquote>
     <p>
      <strong>
       收获
      </strong>
      ：本次复现首次了解到unsloth库，能够加速⏩大模型微调。此前只是使用过LoRA微调Qwen/llama大模型完成文本分类任务，这次也尝试了使用LLaMA-Factory微调llama，完成专业领域的知识问答任务。之后可以尝试更换微调数据集，完成其他领域的大模型微调。
     </p>
    </blockquote>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f33363333323636302f:61727469636c652f64657461696c732f313436323135363431" class_="artid" style="display:none">
 </p>
</div>


