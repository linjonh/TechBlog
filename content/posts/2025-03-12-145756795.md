---
layout: post
title: "网络爬虫-1发送请求维持会话代理设置超时设置"
date: 2025-03-12 15:48:35 +0800
description: "1.基于get发送请求2.基于post发送请求3.维持会话4.代理设置/超时设置"
keywords: "网络爬虫-1:发送请求+维持会话+代理设置/超时设置"
categories: ['网络爬虫']
tags: ['爬虫', 'Python']
artid: "145756795"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145756795
    alt: "网络爬虫-1发送请求维持会话代理设置超时设置"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145756795
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145756795
cover: https://bing.ee123.net/img/rand?artid=145756795
image: https://bing.ee123.net/img/rand?artid=145756795
img: https://bing.ee123.net/img/rand?artid=145756795
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     网络爬虫-1:发送请求+维持会话+代理设置/超时设置
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <blockquote>
     <p>
      1.基于get发送请求
      <br/>
      2.基于post发送请求
      <br/>
      3.维持会话
      <br/>
      4.代理设置/超时设置
     </p>
    </blockquote>
    <h2>
     一.基于get发送请求
    </h2>
    <h3>
     1.获取网页源码1
    </h3>
    <p>
     <span style="color:#fe2c24">
      <strong>
       使用json库中的json.loads(),将json格式的字符串变为Python的字典形式
      </strong>
     </span>
    </p>
    <p>
     以下通过
     <a href="http://httpbin.org/get" rel="nofollow" title="http://httpbin.org/get">
      http://httpbin.org/get
     </a>
     网址进行基本练习操作
    </p>
    <pre><code class="language-python">import requests
import json
url='http://httpbin.org/get'  #目标站点url
r=requests.get(url)           #发送get请求
dict_data=json.loads(r.text)
print("网页源码:\n",r.text)
print("网页源码的类型:\n",type(r.text))
print("键值对形式:\n",dict_data)
print("响应状态码:\n",r.status_code)     </code></pre>
    <p>
     1.网页源码通常为 HTML、JSON 或其他文本格式。
    </p>
    <p>
     2.通过type函数可知,返回的网页源码是
     <strong>
      JSON 格式的字符串
     </strong>
     。
    </p>
    <p>
     3.响应状态码一般有:200(请求成功),404(未找到),500(服务器内部错误)。
    </p>
    <p>
     通过以上操作就获得了一个简单的网页源码爬取
    </p>
    <pre><code class="language-python">网页源码:
 {
  "args": {}, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.32.3", 
    "X-Amzn-Trace-Id": "Root=1-67b6f01c-2e488d805a9188994c10307a"
  }, 
  "origin": "112.240.55.236", 
  "url": "http://httpbin.org/get"
}

网页源码的类型:
 &lt;class 'str'&gt;
键值对形式:
 {'args': {}, 'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.32.3', 'X-Amzn-Trace-Id': 'Root=1-67b6f01c-2e488d805a9188994c10307a'}, 'origin': '112.240.55.236', 'url': 'http://httpbin.org/get'}
响应状态码:
 200</code></pre>
    <h3>
     2.获取网页源码2
    </h3>
    <p>
     <strong>
      <span style="color:#fe2c24">
       使用r.json()
      </span>
     </strong>
    </p>
    <pre><code class="language-python">import requests
import json
url='http://httpbin.org/get'  #目标站点url
r=requests.get(url)           #发送get请求
dict_data=r.json()
print("键值对形式:\n",dict_data)
</code></pre>
    <pre><code class="language-python">键值对形式:
 {'args': {}, 'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.32.3', 'X-Amzn-Trace-Id': 'Root=1-67b6f1fb-77329c48412b3c3c3c0aa26e'}, 'origin': '112.240.55.236', 'url': 'http://httpbin.org/get'}</code></pre>
    <h3>
     3.网页源码(为图片或音频时)
    </h3>
    <p>
     <span style="color:#fe2c24">
      <strong>
       使用r.content
      </strong>
     </span>
    </p>
    <pre><code class="language-python">import requests

url='https://www.baidu.com/img/baidu_jgylogo3.gif'  #以图片为例
r = requests.get(url)                               #发送get请求
print(r.content)                                    #获取为二进制形式,图片或音频
print(type(r.content))                              #&lt;class 'bytes'&gt;表示二进制
#保存二进制图片
with open('test.jpg','wb') as f:
    f.write(r.content)</code></pre>
    <h3>
     4.设置参数1
    </h3>
    <p>
     该练习网站可以自己设置参数args,
     <span style="color:#fe2c24">
      <strong>
       通过在网址后面加?,参数后面加&amp;
      </strong>
     </span>
     ,会在args这一栏显示设置的参数
    </p>
    <pre><code class="language-python">import requests
url='http://httpbin.org/get?age=12&amp;time=11.9&amp;name=12'#目标站点
r=requests.get(url)
print(r.text)
</code></pre>
    <p>
     在返回的网页源码中,会出现我们在url后面设置的参数
    </p>
    <pre><code class="language-python">{
  "args": {
    "age": "12", 
    "name": "12", 
    "time": "11.9"
  }, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.32.3", 
    "X-Amzn-Trace-Id": "Root=1-67b6e74e-2ecdb89860e0144f3c399d39"
  }, 
  "origin": "112.240.55.236", 
  "url": "http://httpbin.org/get?age=12&amp;time=11.9&amp;name=12"
}</code></pre>
    <h3>
     5.设置参数2
    </h3>
    <p>
     推荐使用的参数添加方式:使用字典,并在
     <strong>
      <span style="color:#fe2c24">
       params参数中加上data
      </span>
     </strong>
     ,即可实现在网址后加上参数的操作
    </p>
    <pre><code class="language-python">url='http://httpbin.org/get?'
data={
    'age':12,
    'time':11.9
}
r=requests.get(url,params=data)
print(r.text)</code></pre>
    <pre><code class="language-python">{
  "args": {
    "age": "12", 
    "time": "11.9"
  }, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.32.3", 
    "X-Amzn-Trace-Id": "Root=1-67a08088-56abf4e11348b1622190c6ca"
  }, 
  "origin": "123.13.93.50", 
  "url": "http://httpbin.org/get?age=12&amp;time=11.9"
}</code></pre>
    <h3>
     6.爬虫伪装-1
    </h3>
    <pre><code class="language-python">import requests
import random
url='https://www.zhihu.com/explore'
#构建用户信息
USER_AGENTS = [
"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NET CLR 1.1.4322; .NET CLR 2.0.50727)",
"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)",
"Mozilla/4.0 (compatible; MSIE 7.0; AOL 9.5; AOLBuild 4337.35; Windows NT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)",
"Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US)",
"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)",
"Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)",
"Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)",
"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)",
"Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6",
"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1",
"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0",
"Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5",
"Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.8) Gecko Fedora/1.9.0.8-1.fc10 Kazehakase/0.5.6",
"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11",
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.20 (KHTML, like Gecko) Chrome/19.0.1036.7 Safari/535.20",
"Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; fr) Presto/2.9.168 Version/11.52",
"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.11 TaoBrowser/2.0 Safari/536.11",
"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.71 Safari/537.1 LBBROWSER",
"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; LBBROWSER)",
"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E; LBBROWSER)",
"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.84 Safari/535.11 LBBROWSER",
"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)",
"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; QQBrowser/7.0.3698.400)",
"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E)",
"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SV1; QQDownload 732; .NET4.0C; .NET4.0E; 360SE)",
"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E)",
"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)",
"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.89 Safari/537.1",
"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.89 Safari/537.1",
"Mozilla/5.0 (iPad; U; CPU OS 4_2_1 like Mac OS X; zh-cn) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8C148 Safari/6533.18.5",
"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0b13pre) Gecko/20110307 Firefox/4.0b13pre",
"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:16.0) Gecko/20100101 Firefox/16.0",
"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11",
"Mozilla/5.0 (X11; U; Linux x86_64; zh-CN; rv:1.9.2.10) Gecko/20100922 Ubuntu/10.10 (maverick) Firefox/3.6.10"
]
UA={
    'User-Agent': random.choice(USER_AGENTS),
}
#参数设置
data={
    "age":12,
    "time":11.9
}
response=requests.get(url,params=data,headers=UA)
print("响应状态码:\n",response.status_code)
print("网页源码前200:\n",response.text[:200])
</code></pre>
    <h2>
     二.基于post发送请求
    </h2>
    <h3>
     1.获取网页源码1
    </h3>
    <p>
     <span style="color:#fe2c24">
      <strong>
       使用json库中的json.loads(),将json格式的字符串变为Python的字典形式
      </strong>
     </span>
    </p>
    <pre><code class="language-python">import requests
import json
url='http://httpbin.org/post'    #目标站点
r = requests.post(url)           #发送post请求
dict_data=json.loads(r.text)     #将JSON 格式的字符串转换为 Python 字典(方便后续通过键名操作)
url_=dict_data["url"]            #获取网页源码中的url
print("输出json形式的网页源码:\n",dict_data)
print(url_)</code></pre>
    <pre><code class="language-python">输出json形式的网页源码:
 {'args': {}, 'data': '', 'files': {}, 'form': {}, 'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '0', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.32.3', 'X-Amzn-Trace-Id': 'Root=1-67b6ea62-559651c6763bbd4a2659f360'}, 'json': None, 'origin': '112.240.55.236', 'url': 'http://httpbin.org/post'}
http://httpbin.org/post</code></pre>
    <h3>
     2.获取网页源码2
    </h3>
    <p>
     <span style="color:#fe2c24">
      <strong>
       使用r.json()
      </strong>
     </span>
    </p>
    <pre><code class="language-python">import requests
import json
url='http://httpbin.org/post'#目标站点
r = requests.post(url)
dict_data=r.json()
print(dict_data)
print(dict_data["url"])</code></pre>
    <pre><code class="language-python">{'args': {}, 'data': '', 'files': {}, 'form': {}, 'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '0', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.32.3', 'X-Amzn-Trace-Id': 'Root=1-67b6ee93-0580883d7de493eb16e3b93a'}, 'json': None, 'origin': '112.240.55.236', 'url': 'http://httpbin.org/post'}
http://httpbin.org/post
</code></pre>
    <h3>
     3.设置参数
    </h3>
    <p>
     <strong>
      <span style="color:#fe2c24">
       json形式,基于post请求增加参数,使用data=data进行参数的增加
      </span>
     </strong>
    </p>
    <pre><code class="language-python">import requests

url='http://httpbin.org/post'  #目标站点post请求
data={
    "age":12,
    "time":11.9
}                              #参数
response = requests.post(url,data=data)
print("网页源码:\n",response.text)
print("网页源码(键值对形式):\n",response.json())</code></pre>
    <pre><code class="language-python">网页源码:
 {
  "args": {}, 
  "data": "", 
  "files": {}, 
  "form": {
    "age": "12", 
    "time": "11.9"
  }, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Content-Length": "16", 
    "Content-Type": "application/x-www-form-urlencoded", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.32.3", 
    "X-Amzn-Trace-Id": "Root=1-67b6f31c-37e0c7ac11daa02a0d09daad"
  }, 
  "json": null, 
  "origin": "112.240.55.236", 
  "url": "http://httpbin.org/post"
}

网页源码(键值对形式):
 {'args': {}, 'data': '', 'files': {}, 'form': {'age': '12', 'time': '11.9'}, 'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '16', 'Content-Type': 'application/x-www-form-urlencoded', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.32.3', 'X-Amzn-Trace-Id': 'Root=1-67b6f31c-37e0c7ac11daa02a0d09daad'}, 'json': None, 'origin': '112.240.55.236', 'url': 'http://httpbin.org/post'}</code></pre>
    <h2>
     三.维持会话
    </h2>
    <p>
     <strong>
      用途:
     </strong>
     登录网站使用 Cookies 或 Session 维持登录状态，访问需要登录的页面。
    </p>
    <h3>
     3.1通过cookies维持会话
    </h3>
    <pre><code class="language-python">import requests
#好处:容易请求到需要登录的请求
#坏处:容易被反爬封号
head={
    "cookie":"...............",
    
    "user-agent":"................"
}
url='https://www.jianshu.com'
response=requests.get(url,headers=head)
</code></pre>
    <h3>
     3.2通过session维持会话
    </h3>
    <pre><code class="language-python">import requests

s=requests.Session()
url='https://www.jianshu.com'
response1 = s.get(url,headers=head)
</code></pre>
    <h4>
     <strong>
      Cookies 和 Session 的区别
     </strong>
    </h4>
    <table>
     <thead>
      <tr>
       <th>
        <strong>
         特性
        </strong>
       </th>
       <th>
        <strong>
         Cookies
        </strong>
       </th>
       <th>
        <strong>
         Session
        </strong>
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        <strong>
         存储位置
        </strong>
       </td>
       <td>
        客户端（浏览器或爬虫）
       </td>
       <td>
        服务器端
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         数据安全性
        </strong>
       </td>
       <td>
        较低（可以被客户端修改）
       </td>
       <td>
        较高（存储在服务器）
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         生命周期
        </strong>
       </td>
       <td>
        可以设置过期时间
       </td>
       <td>
        通常随会话结束而失效
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         性能影响
        </strong>
       </td>
       <td>
        每次请求都会携带 Cookies，增加带宽
       </td>
       <td>
        服务器需要存储 Session 数据
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         适用场景
        </strong>
       </td>
       <td>
        简单的状态维持（如登录状态）
       </td>
       <td>
        复杂的状态管理（如购物车、多步操作）
       </td>
      </tr>
     </tbody>
    </table>
    <h2>
     四.代理设置/超时设置
    </h2>
    <p>
     使用proxies携带ip地址,使用timeout进行超时反馈,当ip不能用时,防止一直访问而不自知
    </p>
    <p>
     超时（Timeout）是指爬虫在发送请求后，等待服务器响应的最长时间。如果超过这个时间仍未收到响应，爬虫会停止等待并抛出异常。
    </p>
    <pre><code class="language-python">url='https://www.jianshu.com'
ip = {
    "https":"172.16.17.32:8000",
}
response2=requests.get(url,proxies=ip,timeout=4)</code></pre>
    <p>
     <strong>
      超时参数详解
     </strong>
    </p>
    <ul>
     <li>
      <p>
       <code>
        timeout=5
       </code>
       ：表示总超时时间为 5 秒（包括连接时间和读取时间）。
      </p>
     </li>
     <li>
      <p>
       <code>
        timeout=(3, 5)
       </code>
       ：表示连接超时为 3 秒，读取超时为 5 秒。
      </p>
     </li>
    </ul>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f323330335f38313133333831312f:61727469636c652f64657461696c732f313435373536373935" class_="artid" style="display:none">
 </p>
</div>


