---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34333739303932352f:61727469636c652f64657461696c732f313436313335323638"
layout: post
title: "Denoising-as-Adaptation-Noise-Space-Domain-Adaptation-for-Image-Restoration"
date: 2025-03-09 17:30:11 +0800
description: "尽管基于学习的图像恢复方法取得了重大进展，但由于合成数据训练造成的巨大领域差距，它们仍然难以对现实世界场景进行有限的泛化。现有的方法通过改进数据合成管道、估计退化核、采用深度内部学习以及执行域自适应和正则化来解决这个问题。先前的域自适应方法试图通过在特征或像素空间中学习域不变知识来弥合域差距。然而，这些技术往往难以在稳定紧凑的框架内扩展到低级视觉任务。在本文中，我们证明了使用扩散模型通过噪声空间进行域自适应是可能的。"
keywords: "Denoising as Adaptation Noise-Space Domain Adaptation for Image Restoration"
categories: ['扩散模型', '图像去噪', 'Transformer']
tags: ['计算机视觉', '深度学习', '人工智能']
artid: "146135268"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146135268
    alt: "Denoising-as-Adaptation-Noise-Space-Domain-Adaptation-for-Image-Restoration"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146135268
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146135268
cover: https://bing.ee123.net/img/rand?artid=146135268
image: https://bing.ee123.net/img/rand?artid=146135268
img: https://bing.ee123.net/img/rand?artid=146135268
---

# Denoising as Adaptation Noise-Space Domain Adaptation for Image Restoration

## 去噪即自适应：用于图像恢复的噪声空间域自适应

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/caa3b48131084f798f5e9580536a743e.png#pic_center)

论文链接：
<https://arxiv.org/html/2406.18516v3>

项目链接：
<https://kangliao929.github.io/projects/noise-da/>

### ABSTRACT

尽管基于学习的图像恢复方法取得了重大进展，但由于合成数据训练造成的巨大领域差距，它们仍然难以对现实世界场景进行有限的泛化。现有的方法通过改进数据合成管道、估计退化核、采用深度内部学习以及执行域自适应和正则化来解决这个问题。先前的域自适应方法试图通过在特征或像素空间中学习域不变知识来弥合域差距。然而，这些技术往往难以在稳定紧凑的框架内扩展到低级视觉任务。在本文中，我们证明了使用扩散模型通过噪声空间进行域自适应是可能的。特别是，通过利用辅助条件输入如何影响多步去噪过程的独特特性，我们得出了一个有意义的扩散损失，该损失指导恢复模型逐步将恢复的合成和现实世界输出与目标干净分布对齐。我们将这种方法称为自适应去噪。为了防止联合训练中的捷径，我们在扩散模型中提出了关键策略，如通道洗牌层和残差交换对比学习。它们隐含地模糊了条件合成数据和真实数据之间的界限，并防止模型依赖于易于区分的特征。对三个经典图像恢复任务（即去噪、去模糊和去噪）的实验结果证明了所提出方法的有效性。

### 1 INTRODUCTION

图像恢复是计算机视觉中一个长期存在但具有挑战性的问题。它包括各种子任务，例如去噪（Zhang等人，2017；Yue等人，2024）、去模糊（Pan等人，2016；Ren等人，2020）和去雨（Fu等人，17；Wang等人，2021），每一个子任务都受到了研究的关注。许多方法都基于深度学习，通常遵循监督学习管道。由于注释样本在现实世界中不可用，即退化未知，一种常见的技术是基于对退化过程的假设，从高质量图像中生成合成的低质量数据，以获得训练对。这项技术取得了相当大的成功，但并不完美，因为合成数据无法覆盖所有未知或不可预测的退化因素，这些因素可能因不可控的环境条件而变化很大。因此，现有的方法往往难以很好地推广到现实世界的场景。

已经进行了广泛的研究来解决缺乏真实世界训练数据的问题。一些恢复方法改进了数据合成管道，以生成更真实的退化输入用于训练（Zhang等人，2023；Luo等人，2022）。其他盲恢复方法在推理过程中根据真实的退化输入估计退化核，并将其用作指导恢复的条件输入（Gu等人，2019；Bell Kligler等人，2019）。无监督方法（Lehtinen等人，2018；Shocher等人，2018，Chen等人，2023；Ren等人，2020；Lee等人，2022）在不依赖预定义的干净和退化图像对的情况下提高了输入质量。这些方法通常使用深度内部学习或自监督学习，其中模型学习直接从噪声或失真的数据本身预测干净的图像。在本文中，我们研究了假设合成数据和真实世界退化图像都存在的问题。这种情形符合典型的域适应（domain adaptation）设置，在这种设置中，现有方法可分为特征空间（Tzeng等人，2014年；Ganin和Lempitsky，2015年；Long等人，2015年；Tzeng等人，2015年；Bousmalis等人，2016年）和像素空间（Taigman等人，2016年；Shrivastava等人，2017年；Bousmalis等人，2017年）两类方法。这两种范式都有其弱点：在特征空间中对齐高级深度表示可能会忽略图像恢复所必需的低级变化，而像素空间方法通常涉及计算密集型对抗范式，这可能会导致训练过程中的不稳定。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a680c98f71d248169a4f520a7405f9aa.png#pic_center)

在这项工作中，我们提出了一种新的图像恢复域自适应方法，该方法允许有意义的扩散损失，以减轻合成图像和真实世界退化图像之间的域差距。我们的主要想法源于图1（a）所示的观察结果。在这里，我们测量了以目标图像的噪声版本为条件的扩散模型的噪声预测误差。图1（a）中的趋势表明，腐败程度较低的条件有助于降低扩散模型的预测误差。换言之，“好”条件导致低扩散损失，“坏”条件导致高扩散损失。虽然这种行为可能是预期的，但它揭示了一个有趣的特性，即条件输入如何影响扩散模型的预测误差。我们的方法通过改良一个扩散模型来利用这一现象，该模型以恢复的合成图像和来自恢复网络的恢复的真实图像为条件，如图1（b）所示。这两个网络都是联合训练的，恢复网络经过优化，提供了良好的条件来最小化扩散模型的噪声预测误差，旨在实现干净的目标分布。这样的目标促使恢复网络学习提高其输出的质量。训练后，丢弃扩散模型，只留下训练好的恢复网络进行推理。

虽然多步去噪过程有助于恢复网络，但可能会出现一种潜在的捷径学习：扩散模型根据通道索引或像素与噪声合成标签的相似性来学习识别条件，从而忽略真实数据。为了缓解这一问题，我们提出了关键策略来欺骗扩散模型，使其难以区分这两种情况。具体来说，我们在扩散模型中加入了一个通道洗牌层，并设计了一种残差交换对比学习策略，以确保模型真正学会准确地恢复图像，而不是依赖于易于区分的特征。这些策略隐含地模糊了合成数据和真实数据之间的界限，确保了两者在联合训练中都能有效地做出贡献，并促进了它们与目标分布的一致性。

为了验证我们的方法的有效性，我们对三种经典的图像恢复任务（去噪、去模糊和去雨）进行了广泛的实验，显示出有前景的恢复性能和对不同网络的可扩展性。总之，我们做出了以下贡献：

* 我们的工作代表了解决噪声空间中用于图像恢复的域自适应的第一次尝试。我们展示了扩散损失在消除合成数据和真实数据之间的差距方面的独特优势，这是使用现有损失无法实现的。
* 为了消除联合训练中的捷径学习，我们设计了策略来欺骗扩散模型，使其难以区分合成条件和真实条件，从而鼓励两者与目标清洁分布保持一致。
* 我们的方法提供了一种通用且灵活的适应策略，适用于特定的恢复任务之外。它不需要噪声分布或退化模型的先验知识，并且与各种恢复网络兼容。扩散模型在训练后被丢弃，在恢复推理过程中不会产生额外的计算成本。

### 2 RELATED WORK

**图像恢复**
旨在恢复因噪声、模糊或数据丢失等因素而退化的图像。在各种网络的能力的推动下（Dong等人，2014；2015；Zamir等人，2022；Liang等人，2021），在图像去噪（Zhang等人，2021；Ren等人，2021郭等人，2019；Kim等人，2020；2024；Fu等人，2023；Kousha等人，2022）、图像去模糊（Kupyn等人，2018；Suin等人，2020）和图像去噪等子领域取得了重大进展。在图像恢复中，损失函数对于训练模型至关重要。例如，L1损失使平均绝对像素差最小化，确保像素级精度。感知损失使用预先训练的网络来比较高级特征，确保感知相似性。对抗性损失涉及一个区分真实图像和合成图像的鉴别器，推动生成器创建更逼真的输出。然而，在具有这些传统损失的合成图像上训练的模型在应用于现实世界领域时仍然无法避免性能的显著下降。

为了解决训练和测试退化之间的不匹配问题，一些监督图像恢复技术（Zhang等人，2023；Luo等人，2022）改进了数据合成管道，重点是创建一个训练退化分布，在现实世界场景中平衡准确性和泛化性。一些方法（Gu等人，2019；Bell Kligler等人，2019）估计和校正退化核以提高恢复质量。我们的工作与这些方法正交，旨在弥合训练和测试退化之间的差距。

用于图像恢复的无监督学习方法利用了不依赖于配对训练样本的模型（Huang等人，2021；Chen等人，2023；Huo等人，2023，Chen等人，2024）。Noise2Noise（Lehtinen等人，2018）、Noise2Oide（Krull等人，2019）和Deep Image Prior（Ulyanov等人，2018年）等技术利用了图像的内在特性，网络通过理解自然图像统计数据或自我监督来学习恢复图像。这些方法已被证明在恢复任务中是有效的，取得了与监督学习方法相当的令人印象深刻的结果。然而，由于它们依赖于学习的分布和固有的图像属性，它们经常难以处理高度复杂或损坏的图像，这些属性可能无法完全捕捉到复杂的细节，并且对其他任务的泛化能力有限。

**域自适应**
：为了消除源领域和目标领域之间的差异，提出了域自适应的概念（Saenko等人，2010年; Torralba & Efros，2011）来促进学习模型的泛化能力。以前的方法可以分为特征空间和像素空间方法。例如，特征空间自适应方法通过调整从网络中提取的特征，使其在不同的域之间保持一致，其中一些经典的技术如最小化特征空间之间的距离（Tzeng et al，2014; Long et al，2015）和引入域对抗目标（Ganin & Lempitsky，2015; Tzeng et al，2017）。对齐高水平的深度表示可能会忽略关键的低水平差异，这些差异对于图像恢复等目标任务至关重要。相比之下，像素空间自适应方法（Liu & Tuzel，2016; Taigman等人，2016; Shrivastava等人，2017; Bousmalis等人，2017）通过转换源数据以匹配目标域的“风格”，直接在原始像素级别实现分布对齐。虽然它们更容易理解和验证域转移可视化的有效性，像素空间自适应方法需要仔细调整，并且在训练期间可能不稳定。最近的方法（霍夫曼等人，2018; Zheng等人，2018; Chen等人，2019）通过联合对齐特征空间和像素空间来补偿孤立域自适应的限制。然而，由于需要训练多个网络和周期一致性损失的复杂性，它们往往在计算上要求很高（Zhu et al，2017）。与上述特征空间和像素空间方法不同，我们提出了一种新的噪声空间解决方案，其在紧凑且稳定的框架内跨不同域保留低级别外观。

**扩散模型**
。扩散模型（Sohl-Dickstein et al，2015; Ho et al，2020; Nichol &达里瓦尔，2021）在生成建模中获得了极大的关注。它们通过一系列步骤将简单分布逐渐转化为复杂分布，从而逆转扩散过程。这种方法在文本到图像的生成方面取得了显著的成功（Saharia等人，2022 b; Ruiz等人，2023）和图像恢复（Saharia等人，2022 a;c;通常，条件被馈送到扩散模型以用于条件生成，例如文本（Rombach等人，2022），分类标签（Ho & Salimans，2022），视觉提示（Bar et al，2022）和低分辨率图像（Wang等人，2024），为了便于目标分布的近似。最近的一些工作提出了适应图像恢复及其相关任务的扩散模型，JPEG盲恢复（Welker等人，2024），开集图像恢复（Gou等人，2024），以及退化图像的分类（Daultani et al，2024）。然而，它们在训练和推理阶段都需要扩散模型。在这项工作中，我们表明，扩散的前向去噪过程有可能作为一个训练代理任务，以提高图像恢复模型的泛化能力。

### 3 METHODOLOGY

**问题定义**
。我们首先在图像恢复的背景下制定噪声空间域自适应问题。给定来自合成域的标记数据集和来自真实世界域的未标记数据集，我们的目标是在合成和真实的数据上训练模型，该模型可以很好地推广到真实世界域。假设

D
s
=
{
(
x
i
s
,
y
i
s
)
}
i
=
1
N
s
\mathcal{D}^s = \{(x^s\_i, y^s\_i)\} ^{N^s}\_{i=1}






D









s



=





{(


x









i





s

​


,




y









i





s

​


)


}










i

=

1







N









s

​

表示包含来自源合成域的

N
s
N^s






N









s
个样本的标记数据集，

D
r
=
{
x
i
r
}
i
=
1
N
r
\mathcal{D}^r = \{x^r\_i \}^{N^r}\_{i=1}






D









r



=





{


x









i





r

​



}










i

=

1







N









r

​

表示具有来自目标真实世界域的

N
r
N^r






N









r
个样本的未标记数据集，其中

y
s
y^s






y









s
是干净图像，

x
s
x^s






x









s
是相应的合成退化图像，而

x
r
x^r






x









r
是真实世界的退化图像。

**图像恢复基线**
。恢复网络可以用公式表示为深度神经网络

G
(
⋅
;
θ
~
G
)
G(\cdot;\tilde{\boldsymbol{\theta}}\_G)





G

(

⋅

;













θ





~









G

​


)
，参数为可学习参数

θ
G
\boldsymbol{\theta}\_G








θ









G

​

。该网络经过训练，可以从合成域上的退化观测值

x
s
x^s






x









s
中预测ground truth

y
s
y^s






y









s
。我们的域适应不限于特定类型的网络架构。可以从现有网络（如DnCNN）中进行选择（Zhang et al，2017），U-Net（Yue等人，2019），RCAN（Zhang et al，2018 b）和SwinIR该方法还与图像恢复中使用的现有损失函数正交，例如L1或L2损失、Charbonnier损失（Zamir等人，2021），感知损失（约翰逊等人，2016），以及对抗性损失（Wang et al，2018）。为了更好地验证所提出方法的通用性，我们采用广泛使用的U-Net架构

f
θ
(
⋅
)
f\_\theta(\cdot)






f









θ

​


(

⋅

)
和Charbonnier损失

L
R
e
s
\mathcal{L}\_{Res}






L










R

es

​

作为我们的基线。在联合训练中，使用扩散目标

L
D
i
f
\mathcal{L}\_{Dif}






L










D

i

f

​

训练扩散模型，同时使用

L
R
e
s
\mathcal{L}\_{Res}






L










R

es

​

和

L
D
i
f
\mathcal{L}\_{Dif}






L










D

i

f

​

两者更新恢复网络。

#### 3.1 噪声空间域自适应

理想情况下，ground truth图像和通过图像恢复模型从合成数据和真实世界数据恢复的那些图像应该位于高质量干净图像的共享分布中。然而，获得这样一个理想的模型，可以普遍映射到任何退化图像的分布，是非常具有挑战性的。假设一个高质量的图像

x
x





x
作为一个实现来自一个随机向量

X
X





X
，它属于干净的分布

P
X
P\_{X}






P










X

​

。我们然后定义恢复的合成和真实世界的输出从恢复网络为

X
s
^
\hat{X^{s}}













X










s





^
和

X
r
^
\hat{X^{r}}













X










r





^
。在这项工作中，我们研究开发一个有意义的扩散损失，以指导合成和真实世界输出的条件分布与目标干净分布对齐，即

P
X
=
P
X
^
s
=
P
X
^
r
P\_X=P\_{\hat{X}^s}=P\_{\hat{X}^r}






P









X

​




=






P


















X





^









s

​




=






P


















X





^









r

​

。

鉴于通常采用的情况下，从合成数据集的ground truth图像是可用的，我们首先探索适应目标清洁分布与配对数据的角度。不失一般性，让我们考虑来自合成域的具有其ground truth

y
s
y^\mathrm{s}






y









s
的合成退化图像

x
s
^
\hat{x^\mathrm{s}}













x









s





^
和来自真实世界域的真实的退化图像

x
r
x^r






x









r
。使用恢复网络

G
(
⋅
;
θ
G
)
G(\cdot;\boldsymbol{\theta}\_G)





G

(

⋅

;






θ









G

​


)
，我们可以分别获得恢复图像

y
^
s
\hat{\boldsymbol{y}}^s















y





^

​










s
和

y
^
r
\hat{\boldsymbol{y}}^r















y





^

​










r
。然后，基于我们观察到扩散模型的预测误差高度依赖于条件输入的质量，我们将多步去噪过程作为代理任务纳入训练过程。它使用预测图像

y
^
s
\hat{y}^s













y





^

​










s
和

y
^
r
\hat{y}^r













y





^

​










r
作为条件，以帮助扩散模型拟合干净的分布。遵循DDPM中的符号（Ho等人，2020），我们将扩散模型表示为

ϵ
θ
\epsilon\_\theta






ϵ









θ

​

，并将其优化公式化为以下目标：
  




L
D
i
f
=
E
∥
ϵ
−
ϵ
θ
(
y
~
s
∣
C
(
y
^
s
,
y
^
r
)
,
t
)
∥
2
,
(1)
\mathcal{L}\_{Dif}=\mathbb{E}\left\|\boldsymbol{\epsilon}-\boldsymbol{\epsilon}\_\theta\left(\tilde{\boldsymbol{y}}^s\right|\mathbf{C}(\hat{\boldsymbol{y}}^s,\hat{\boldsymbol{y}}^r),t)\right\|\_2, \tag{1}






L










D

i

f

​




=





E





∥



ϵ



−






ϵ









θ

​





(











y





~

​










s

∣



C

(











y





^

​










s

,













y





^

​










r

)

,



t

)

∥









2

​




,





(


1

)
  
其中

y
~
s
=
α
ˉ
t
y
s
+
1
−
α
ˉ
t
ϵ
,
ϵ
∼
N
(
0
,
I
)
,
α
ˉ
t
\tilde{\boldsymbol{y}}^s=\sqrt{\bar{\alpha}\_t}\boldsymbol{y}^s+\sqrt{1-\bar{\alpha}\_t}\boldsymbol{\epsilon},\boldsymbol{\epsilon}\sim N(0,\boldsymbol{I}),\bar{\alpha}\_t















y





~

​










s



=





















α





ˉ









t

​


​





y









s



+













1



−











α





ˉ









t

​


​




ϵ

,





ϵ



∼





N

(

0

,





I

)

,











α





ˉ









t

​

是噪声调度的超参数，

C
(
⋅
,
⋅
)
\mathbf{C}(\cdot,\cdot)





C

(

⋅

,



⋅

)
表示通道级级联。在联合训练过程中，如果条件

y
^
s
\hat{\boldsymbol{y}}^s















y





^

​










s
和

y
^
r
\hat{\boldsymbol{y}}^r















y





^

​










r
恢复不足（即偏离预期分布较远），那么来自扩散损失的监督信息将会反向传播至这些条件。这鼓励恢复网络尽可能地将

y
^
s
\hat{\boldsymbol{y}}^s















y





^

​










s
和

y
^
r
\hat{\boldsymbol{y}}^r















y





^

​










r
与目标域对齐。特别是，扩散输入“泄漏”的知识起着重要作用，可能提供无退化指导，以帮助将退化的真实世界图像适应干净的分布。更多讨论见第A5.2节。

然而，联合训练可能会导致琐碎的解决方案或捷径，如图2所示。例如，很容易通过

y
^
s
\hat{\boldsymbol{y}}^s















y





^

​










s
和

y
^
r
\hat{\boldsymbol{y}}^r















y





^

​










r
之间的像素相似性或通道索引来区分合成条件和真实世界条件。因此，恢复网络将通过粗略地降低真实世界图像中的高频信息来欺骗扩散网络。如图2（bottom）所示，我们在这个训练过程中确定了三个阶段：（I）扩散网络努力识别哪些条件有助于去噪，因为两者都严重退化，促进恢复网络增强两者;（II）合成图像被清晰地恢复，并且容易从其外观中区分出来;（III）扩散模型倾向于区分条件，导致其关注合成数据而忽略真实世界数据。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/79b464238ccb4d7397b630c7c0a3caa4.png#pic_center)

#### 3.2 消除扩散中的捷径学习

为了避免扩散模型中的上述捷径，如图3所示，我们首先提出一个通道重排层

f
c
s
f\_{cs}






f










cs

​

，在每次迭代时随机重排合成条件和真实条件的通道索引，然后将它们连接起来，即

C
(
f
c
s
(
y
^
s
,
y
^
r
)
)
2
\mathbf{C}(f\_{cs}(\hat{\boldsymbol{y}}^s,\hat{\boldsymbol{y}}^r))^2





C

(


f










cs

​


(











y





^

​










s

,













y





^

​










r

)


)









2
。我们在实验中表明，这种策略对于弥合合成数据和真实的数据之间的差距很重要。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/612fa4f207b1401a8ec3af51ef6bdc91.png#pic_center)

除了通道混洗之外，我们还设计了一种残差交换对比学习策略，以确保网络学习真正恢复，而不是过度拟合成对的合成外观。使用ground truth噪声作为anchor，我们构建了一个由等式1导出的正例

ϵ
p
o
s
\epsilon^{pos}






ϵ










p

os
：

ϵ
p
o
s
=
ϵ
θ
(
y
~
s
∣
C
(
y
^
s
,
y
^
r
)
,
t
)
.
\epsilon^{pos}=\epsilon\_{\theta}(\tilde{
{\boldsymbol{y}}}^{s}|\mathbf{C}(\hat{\boldsymbol{y}}^{s},\hat{\boldsymbol{y}}^{r}),t).






ϵ










p

os



=






ϵ










θ

​


(












y





~

​











s

∣

C

(











y





^

​











s

,













y





^

​











r

)

,



t

)

.
，即，来自以恢复的合成图像和真实世界图像为条件的扩散模型的预期噪声。然后，我们交换这两个条件的残差图，并如下公式化负示例

ϵ
n
e
g
\epsilon^{neg}






ϵ










n

e

g
：
  




ϵ
n
e
g
=
ϵ
θ
(
y
~
s
∣
C
(
y
^
s
←
r
,
y
^
r
←
s
)
,
t
)
,
y
^
s
←
r
=
x
s
⊕
R
r
,
y
^
r
←
s
=
x
r
⊕
R
s
,
(2)
\epsilon^{neg}= \epsilon\_\theta\left(\tilde{\boldsymbol{y}}^s|\mathbf{C}(\hat{\boldsymbol{y}}^{s\leftarrow r},\hat{\boldsymbol{y}}^{r\leftarrow s}),t\right),\hat{\boldsymbol{y}}^{s\leftarrow r} =\boldsymbol{x}^s\oplus\mathcal{R}^r,\hat{\boldsymbol{y}}^{r\leftarrow s} =\boldsymbol{x}^r\oplus\mathcal{R}^s, \tag{2}






ϵ










n

e

g



=






ϵ









θ

​





(











y





~

​










s

∣

C

(











y





^

​











s

←

r

,













y





^

​











r

←

s

)

,



t

)



,













y





^

​











s

←

r



=








x









s



⊕






R









r

,













y





^

​











r

←

s



=








x









r



⊕






R









s

,





(


2

)
  
其中

R
s
\mathcal{R}^s






R









s
和

R
r
\mathcal{R}^r






R









r
是来自恢复网络的合成图像和真实世界图像的估计残差图，并且

R
r
\mathcal{R}^r






R









r
是逐像素加法运算符。通过交换两个条件的残差，我们约束扩散模型，使其忽略上下文关系，使错误恢复结果与预期干净分布之间的距离增大（即相互排斥）。基于正、负和anchor示例，紧凑的残差交换对比学习可以公式化为：
  




L
C
o
n
=
max
⁡
(
∥
ϵ
−
ϵ
p
o
s
∥
2
−
∥
ϵ
−
ϵ
n
e
g
∥
2
+
δ
,
0
)
,
(3)
\mathcal{L}\_{Con}=\max\left(\|\boldsymbol{\epsilon}-\boldsymbol{\epsilon}^{pos}\|\_{2}-\|\boldsymbol{\epsilon}-\boldsymbol{\epsilon}^{neg}\|\_{2}+\delta,0\right), \tag{3}






L










C

o

n

​




=





max




(

∥



ϵ



−






ϵ










p

os


∥










2

​




−



∥



ϵ



−






ϵ










n

e

g


∥










2

​




+



δ

,



0

)



,





(


3

)
  
其中，

δ
δ





δ
表示分隔正样本和负样本的预定义裕度。这样，扩散损失模型取公式1和公式3的平均值，形成最终的扩散损失

L
D
i
f
\mathcal{L}\_{Dif}






L










D

i

f

​

。使用上述策略，我们挑战扩散模型，以区分基于平凡解的合成和真实的条件，鼓励两者与目标干净分布一致。

在上述公式中，表示为

y
^
s
\hat{y}^s













y





^

​










s
的条件的恢复的合成图像和表示为

y
~
s
\tilde{y}^s













y





~

​










s
的扩散模型的输入形成具有明显的逐像素相似性的一对数据。这种相似性可能会误导扩散模型，使其忽略图2中所分析的条件下的真实的恢复图像

y
^
r
\hat{y}^r













y





^

​










r
。重要的是要注意，目标分布封装了高质量干净图像的域知识，包括但不限于合成数据集中的ground truth图像。所提出的方法可以进一步扩展，通过用

y
~
c
\tilde{\boldsymbol{y}}^c















y





~

​










c
代替噪声输入

y
~
s
\tilde{\boldsymbol{y}}^s















y





~

​










s
，

y
~
c
\tilde{\boldsymbol{y}}^c















y





~

​










c
定义为

y
~
c
=
α
ˉ
t
y
˙
c
+
1
−
α
ˉ
t
ϵ
\tilde{\boldsymbol{y}}^c=\sqrt{\bar{\alpha}\_t}\dot{\boldsymbol{y}}^c+\sqrt{1-\bar{\alpha}\_t}\epsilon















y





~

​










c



=





















α





ˉ









t

​


​












y





˙

​










c



+













1



−











α





ˉ









t

​


​


ϵ
，其中

y
c
\boldsymbol{y}^c








y









c
是从未配对的广泛高质量图像数据集中随机采样的。该策略破坏了合成条件和扩散输入之间的像素相似性，从而强制扩散模型指导域级别的恢复网络预测的合成和真实的条件。我们将在附录A4.1中对此设置进行详细说明。

#### 3.3 训练

在所提出的训练策略中，通过以下方式联合优化图像恢复模型：
  




L
=
L
R
e
s
+
λ
D
i
f
L
D
i
f
.
(4)
\mathcal{L}=\mathcal{L}\_{Res}+\lambda\_{Dif}\mathcal{L}\_{Dif}. \tag{4}





L



=






L










R

es

​




+






λ










D

i

f

​



L










D

i

f

​


.





(


4

)
  
在之前的工作（Ganin & Lempitsky，2015）之后，我们逐渐将

λ
D
i
f
λ\_{Dif}






λ










D

i

f

​

从

0
0





0
更改为

β
β





β
，以避免在训练过程的早期阶段对主要图像恢复任务的干扰：
  




λ
D
i
f
=
(
2
1
+
exp
⁡
(
−
γ
⋅
p
)
−
1
)
⋅
β
,
(5)
\lambda\_{Dif}=\left(\frac{2}{1+\exp(-\gamma\cdot p)}-1\right)\cdot\beta, \tag{5}






λ










D

i

f

​




=







(












1



+



exp

(

−

γ



⋅



p

)











2

​




−



1


)



⋅





β

,





(


5

)
  
其中，在所有实验中，

γ
γ





γ
和

β
β





β
分别根据经验设置为5和0.2，

p
=
min
⁡
(
n
N
,
1
)
p=\min\left(\frac nN,1\right)





p



=





min





(













N












n

​


,



1


)
，其中

n
n





n
表示当前epoch索引，

N
N





N
表示训练时期的总数。

#### 3.4 讨论

所提出的作为自适应的去噪让人想起由（Ganin & Lempitsky，2015）。主要区别在于，我们不使用带有梯度反转层的域分类器，而是使用扩散网络进行损失。我们将方法分类为（Ganin & Lempitsky，2015）作为特征空间域适应方法。与这些方法不同，我们表明，作为自适应的去噪更适合于图像恢复，因为它可以更好地保留像素噪声空间中的低级别外观。与通常需要多个生成器和多个网络的像素空间方法相比，我们的方法采用了一个紧凑的框架，只包含一个额外的去噪U-Net，确保稳定的自适应训练。训练后，扩散网络被丢弃，只需要恢复网络进行推理。上述三种方法的框架比较见附录A2。

### 4 EXPERIMENTS

**数据集**
。对于图像去噪，我们遵循以前的作品（Zhang et al，2018 a; Zamir等人，2022），并基于DIV 2K构建合成训练数据集（Jumefte等人，2017），Flickr 2K（Nah等人，2019），WED（Ma et al，2016）和BSD（Martin等人，2001）。通过添加噪声水平为σ ∈ [0，我们使用SIDD的训练数据集（Abdelhamed et al，2018）作为真实世界的数据。对于图像去雨，合成和真实世界的训练数据集分别从Rain13 K（Yang et al，2017）和SPA（Wang et al，2019）中获得。对于图像去模糊，分别选择GoPro（Nah et al，2017）和RealBlur-J（Rim et al，2020）作为合成和真实世界的训练数据集。请注意，我们仅将这些真实世界数据集中的退化图像（不包含真实标注数据）用于训练目的。对于大规模非配对干净图像，使用MS-COCO数据集（Lin et al，2014）中的所有图像，并使用真实世界数据集（SIDD，SPA，RealBlur-J）的测试图像来评估相应图像恢复模型的性能。

**训练设置**
。为了训练扩散模型，我们采用α条件和线性噪声时间表，范围从1e
-6
到1e
-2
，遵循先前的工作（Saharia et al，2022 a;c; Chen et al，2020）。此外，在我们的实验中也使用了衰减因子为0.9999的EMA策略。恢复和扩散网络都是在128 × 128个patch上训练的，这些patch经过随机裁剪和旋转处理以增强数据。我们的模型使用Adam（Kingma & Ba，2014）算法以固定的学习率5e
-5
进行训练，批量大小设置为40。

**度量**
：各种方法的性能主要使用经典的度量进行评估：PSNR，SSIM和LPIPS。对于图像去噪，我们使用YCbCr颜色空间中的Y通道来计算PSNR/SSIM，遵循现有的方法（Jiang et al，2020; Purohit et al，2021; Zamir et al，2022）。

#### 4.1 与最先进方法的比较

我们使用一个简单而经典的U-Net结构来实现图像恢复网络，并使用本文提出的噪声空间域自适应策略来训练该网络，为了验证其有效性，我们将本文提出的方法与先前的域自适应方法（包括DANN）进行了比较（Ganin & Lempitsky，2015），DSN（Bousmalis等人，2016），PixelDA（Bousmalis et al，2017）和CyCADA（霍夫曼等人，2018），涵盖了特征空间和像素空间的解决方案。为了公平比较，我们使用相同的标准设置和数据集重新训练了这些方法。此外，我们还考虑了一些无监督恢复方法和代表性的监督方法，如Ne2Ne（Huang et al，2021），MaskedD（Chen et al，2023），NLCL（Ye et al，2022），SelfDeflur（Ren et al，2020），VDIP（Huo et al，2023）和Restormer（Zamir et al，2022）。

**比较结果**
。定量和定性比较结果如表1-3和图4-5所示。从比较结果来看，该方法在三个图像恢复任务上领先于比较方法。特别是，以往的特征空间域适应方法（Ganin和Lempitsky，2015年；Bousmalis等人，2016年；Hoffman等人，2018年）无法感知至关重要的低层次信息，而像素空间域适应方法（Bousmalis等人，2017年；Hoffman等人，2018年）由于在对抗训练过程中难以精确控制两个域之间的风格转换，因此效果欠佳。此外，自监督和无监督恢复方法（Huang等，2021; Chen等，2023; Ye等，2022; Huo et al，2023）由于某些不可避免的信息丢失和特定降级的手工设计，显示出明显的伪影和有限的泛化性能。我们的方法确保了跨各种任务的逐像素噪声空间中的一般和精细域自适应，而不引入不稳定的训练。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a8ba5aba44894945afb8208ccd06a4d5.png#pic_center)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/fc4d179bb4104749bdfddac38e499d75.png#pic_center)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/ac436881f7d24c698045e6f863b11fe4.png#pic_center)

**分析**
。从上述结果中，我们可以观察到，所提出的方法在涉及高频噪声的任务（如图像去噪）上实现了超出基线的显著改进。特别是，+8.13/0.3070 PSNR增益/我们认为图像去噪的目标与扩散模型中的前向去噪过程的目标自然吻合，因此，如果条件图像恢复不足，则强烈的扩散损失将反向传播，并且恢复网络试图尽可能地消除合成图像和真实世界图像上的噪声。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a51ea3fa3005430fa71d5431ff67dc83.png#pic_center)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b1012438ca9141a79d2db05018ef4def.png#pic_center)

#### 4.2 消融研究

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6c5a9f3376bb4ebe8e272ecdd696ae5b.png#pic_center)

我们对扩散模型的采样噪声水平（由时间步长t确定）和避免捷径学习的训练策略进行消融研究，如表4和图6所示。具体地说，在低噪声强度下，例如t ∈ [1，100]，即使在恢复条件欠恢复的情况下，扩散模型也很容易区分成对合成数据的相似性，因此，在训练过程中，捷径学习发生得更早，真实世界退化图像被恢复网络严重破坏，其中大部分细节被过滤掉。另一方面，当采样噪声强度较高时，例如t ∈ [900，1000]，扩散模型难以收敛，整个框架已陷入局部最优。通过从t ∈ [1，1000]的更多样化范围采样噪声，恢复结果可以逐渐适应干净的分布。此外，通过设计通道重排层（CS）和残差交换对比学习策略（RS），进一步提高了恢复网络的泛化能力，有效地消除了扩散模型的捷径学习。因此，从表4和图6中的（d）到（e）和（f）可以观察到对真实世界图像的更高恢复性能和更逼真的视觉外观。我们还证明了合成数据和真实的数据对于我们的域适应都是不可或缺的，排除它们中的每一个都将导致现实世界性能的急剧下降（如表4最后两行所示）。特别是对于排除真实的数据，性能几乎退化到Vanilla模型。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3b17cb67080444878a425014c62cd8e9.png#pic_center)

#### 4.3 扩展性

**比较**
。在这项工作中，我们的目标是提出一个通用的域自适应策略，用于各种恢复任务，这是可扩展的任何恢复网络。特别是，一个基本的和轻量级的U-网是用来验证我们的方法的有效性。然而，与一些针对特定任务设计的近期自监督研究工作（Jang等人，2021年；Lee等人，2022年；Jang等人，2024年；Cai等人，2021年）相比，这样的架构本质上限制了恢复性能的上限。

在这里，我们提供了实验来证明使用所提出的自适应策略的高级恢复网络可以实现更高的性能。比较结果如表5所示。在这个实验中，我们采用了基于具有更深层的U-Net架构的恢复网络（名为Ours\*，不同复原网络的复杂程度详列于附录的表A2）结果表明，SIDD测试集上的去噪性能从34.71 dB提高到35.52 dB。此外，我们表明，所提出的方法可以推广到其他看不见的真实的-这些数据集在网络的训练过程中不会遇到，并且落在训练数据集的分布之外。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e78c585548fa4e74b3697a960f501066.png#pic_center)

我们相信更强大的恢复网络可以实现进一步的改进，但追求特定任务的卓越性能并不是这项工作的目标。

**讨论**
。与自监督的方法相比（Chen et al，2023; Ren et al，2020; Huo et al，2023; Jang et al，2021; Lee et al，2022），我们的工作显示出以下独特的优势：它不受特定任务的限制;它不受潜在噪声分布和退化模式的先验知识的影响；并且对前级恢复网络的类型友好。我们还讨论了域自适应和自监督学习方法之间的区别：领域自适应将知识从一个域转移到另一个具有不同分布的域，从而提高在新的、不可见的环境中的性能。通过生成伪标签或从数据本身探索目标分布来从未标记的数据中学习。这两种方法都减少了对大型标记数据的依赖，但解决了不同的挑战：域适应侧重于弥合域差距，而自监督学习则利用数据的固有结构。

**性能与复杂性**
。我们使用基于U-Net的恢复网络和其他类型的架构（如基于Transformer-based网络）的不同变体来验证所提出方法的可扩展性（Wang et al，2022）。特别地，我们根据模型大小对这些网络进行分类，并获得：Unet-T、Unet-S（第4.1节中应用的模型）、Unet-B、Uformer-T、Uformer-S和Uformer-B。附录中列出了更多详细信息。图7显示了定量结果与计算成本的关系。正如我们所观察到的，随着复杂性的增加，香草恢复网络（橙子元素）倾向于过拟合训练合成数据集，并且在测试真实世界数据集上表现更差。相比之下，所提出的方法能够提高具有不同规模（蓝色元素）的恢复模型的泛化能力。同样有趣的是，对于每种类型的架构，我们的方法可以促进更好的性能，因为恢复网络的复杂性增加，证明了它在解决大型模型的过拟合问题的有效性。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c2d69038bb824cc19f949750498f647d.png#pic_center)

#### 4.4 限制

扩散模型的自然使命是预测输入中混合的噪声，这些噪声是从高频分布中采样的。扩散模型擅长捕捉和建模这些小尺度变化，因为它们能够通过去噪过程学习细粒度细节。因此，在图像去噪和去雨任务中可以观察到更直观的改进，这些任务通常涉及图像中的高频噪声。相比之下，模糊图像中的伪影（由强度的平滑渐进变化组成）对于扩散模型可能不太敏感。它们影响图像的较大区域，并且需要模型校正广泛的扫描失真，而不是精细的细节。因此，与高频噪声相比，扩散模型可能很难完全恢复低频噪声的图像。我们将其作为未来的工作之一。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/0b8cb6f319ff43b4b20b8f3d33cb34ed.png#pic_center)

### 5 CONCLUSION

在这项工作中，我们提出了一种新的方法，利用扩散模型作为代理网络来解决图像恢复任务中的域自适应问题。与以前的特征空间和像素空间自适应方法不同，所提出的方法使恢复结果适应像素噪声空间中的目标干净分布，从而在紧凑和稳定的训练框架内显著地改善低级外观。为了减轻由恢复和扩散模型的联合训练引起的捷径问题，我们对两个条件的通道索引进行随机混洗，并提出了一种残差交换的对比学习策略，以防止模型根据成对相似性来区分条件，此外，通过放松扩散模型的输入约束，可以扩展所提出的方法，引入多种不成对的干净图像作为去噪输入。实验结果证明了我们的方法比特征空间和像素空间域自适应方法的有效性，以及它的可扩展性超过了跨一系列图像恢复任务的自监督方法。

### APPENDIX

#### A1 实施细节

##### A1.1 对扩展模型的条件评估

这项工作的灵感来自于有利条件促进扩散模型去噪过程的有益效果，如图1（a）所示。在这个初步实验中，我们首先在扩散模型的常规输入之外使用额外的输入来调节和训练扩散模型。然后，我们测试了这个模型在不同条件下的噪声预测性能。具体来说，我们通过将噪声水平为σ ∈ [0，80]的加性白色高斯噪声（AWGN）添加到其原始干净图像来破坏条件，这是在MS-COCO测试数据集中的1，000张图像上执行的使用均方误差（MSE）度量来评估扩散模型的噪声预测误差。

##### A1.2 比较设置

在对比实验中，我们主要将所提出的方法与三种先前的方法进行比较：域自适应方法，包括DANN（Ganin & Lempitsky，2015），DSN（Bousmalis等人，2016），PixelDA（Bousmalis et al，2017）和CyCADA（霍夫曼等人，2018）；无监督图像恢复方法，包括Ne 2Ne（Huang等人，2021），MaskedD（Chen等人，2023），NLCL（Ye等人，2022），SelfDeflur（Ren等人，2020）和VDIP（Huo等人，2023）；一些有代表性的监督方法作为图像恢复中的强基线，如Restormer（Zamir等人，2022），以全面评估不同方法的泛化性能。（Chen等人，2023）提出了掩蔽训练来增强去噪网络的泛化性能，显示出直接应用于现实世界场景的潜力。它与我们的工作目标相同。

##### A1.3 可扩展性评估

为了对所提出的方法进行全面的评估，我们在实验中应用了六种图像恢复网络，包括三种基于卷积的网络（Ronneberger et al，2015）：Unet-T（Tiny）、Unet-S（Small）和Unet-B（Base）;以及基于Transformer的网络的三种变体（Wang et al，2022）：Uformer-T（Tiny）、Uformer-S（Small）和UformerB（Base）。这些变体在每个编码器和解码器阶段的特征通道数量（C）和层数上有所不同。具体配置、计算成本和参数数量如下：

```python
• Unet-T: C=32, depths of Encoder = {2, 2, 2, 2}, GMACs: 3.14G, Parameter: 2.14M,
• Unet-S: C=64, depths of Encoder = {2, 2, 2, 2}, GMACs: 12.48G, Parameter: 8.56M,
• Unet-B: C=76, depths of Encoder = {2, 2, 2, 2}, GMACs: 17.58G, Parameter: 12.07M,
• Uformer-T: C=16, depths of Encoder = {2, 2, 2, 2}, GMACs: 15.49G, Parameter: 9.50M,
• Uformer-S: C=32, depths of Encoder = {2, 2, 2, 2}, GMACs: 34.76G, Parameter: 21.38M,
• Uformer-B: C=32, depths of Encoder = {1, 2, 8, 8}, GMACs: 86.97G, Parameter: 53.58M,

```

并且解码器的深度与编码器的深度匹配。

#### A2 不同域自适应方法的讨论

如第3.4节所讨论的，我们描述了所提出的方法的有效性，超越了以前的特征空间和像素空间域自适应方法。我们进一步在图A1中展示了它们的具体框架。与以前的自适应方法相比，我们的方法通过引入有意义的扩散损失函数，不受域分类器或自适应器的限制。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/32e3b5be30ff4126a326979758a39aa0.png#pic_center)

#### A3 消融的附加分析

我们提供了一个消融研究，以显示真实的数据的必要性，其中只有合成或真实的数据才适用于扩散模型。SIDD测试数据集的定量结果列在表4中。值得注意的是，合成和真实的数据对于扩散模型中的有效域适应都是必不可少的。省略任何一种类型都会导致真实世界性能的显著下降。特别是，当排除真实的数据时，性能几乎下降到Vanilla模型的水平。我们进一步分析每个条件的必要性如下：（1）真实的数据通常充当向扩散模型引入额外噪声的“坏”条件，因为恢复网络在域间隙下不能很好地恢复它。有效且强的扩散损失将反向传播到恢复网络，促进其学习提供“良好”条件。作为消除捷径的建议策略的一个好处，该模型以多步去噪的方式使真实的数据逐步适应目标干净分布。（2）两种情况下的合成数据可以在早期训练阶段提供有用的指导，确保扩散模型持续关注这些条件通道。

#### A4 其他比较结果

##### A4.1 扩展

如第3.2节所述，我们的方法可以通过使用来自其他干净数据集的图像放松扩散的输入来扩展到未配对条件的情况。由于不存在匹配输入和条件之间像素相似性等琐碎的解决方案，因此可以潜在地消除捷径问题。这种扩展保留了通道洗牌层，但不需要进行残差交换对比学习。我们在表A1中显示定量评价。我们结果表明，尽管条件和扩散输入是不成对的，但我们的方法仍然可以学习使来自合成域和真实域的恢复结果适应干净的图像分布，这也补充了配对解决方案在某些任务中的恢复性能，如去雨和去模糊。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/f9378f1649d74e23b4c1edf6a6f14d6e.png#pic_center)

##### A4.2 更先进的恢复网络

如第4.3节所述，所提出的域自适应方法在各种图像恢复网络之间提供了强大的可扩展性。此外，通过采用更先进的恢复网络，并将所提出的去噪作为自适应（Ours\*），可以进一步提高性能，产生的结果在感知上更符合ground truth，如图A2所示。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e958916f45634d94b2a68598b95b9b6c.png#pic_center)

表A2中列出了网络。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/d28da56207fd46b9891a593b8276745b.png#pic_center)

##### A4.3 附加目视比较结果

我们在图A3中的图像去噪任务、图A4中的图像去雨任务和图A5中的图像去模糊任务上可视化了更多的比较结果。特别地，我们将所提出的方法及其扩展分别命名为“Ours”和“Ours-Ex”。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c5907c538ec741ba93c9f8f82fcd506c.png#pic_center)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/102393affe1d41b78247b4c4c63363a1.png#pic_center)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/0b3bf10ede4a4e668e6d4e66ed19c6c7.png#pic_center)

##### A4.4 其他真实世界数据集的额外视觉结果

为了展示所提出的方法的泛化能力，我们还在图A6，图A7，图A8中可视化了所提出的方法在其他真实世界数据集上的恢复结果（Plotz & Roth，2017; Yang et al，2017）。请注意，这些数据集在网络训练期间没有看到，并且落在训练数据集的分布之外。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b3491928f0c34c279b3d546b77320a52.png#pic_center)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c030383499de4b57849ad6664144da15.png#pic_center)

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/ad187851c29e4580871e4383e8100276.png#pic_center)

##### A4.5 失败案例

我们在图A9中展示了我们的方法和比较方法的失败案例。特别是，我们的方法无法恢复具有挑战性退化失真的图像，例如强噪声和分布外噪声。这些真实世界的退化与合成数据集相比产生了显著的差距，从而加重了学习模型的负担，以有效地将恢复结果适应干净的域。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/f6884af0bd4c464281f2044df0892c25.png#pic_center)

##### A4.6 训练细节和复杂性分析

为了证明在训练过程中引入扩散损失的影响，我们在图A10（左）中可视化了训练动态的相关度量。很容易发现，在合成数据集上仅使用L1损失训练的恢复模型往往会快速过拟合，并且在真实世界的验证集上表现不佳。相比之下，扩散损失可以有效地指导恢复模型以多步去噪的方式适应真实世界域，持续提高真实世界验证集上的恢复性能。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/0e7890992b664e2d902679fd903417b5.png#pic_center)

此外，我们在图A10（右）中显示了验证不同复杂度的扩散模型的结果。具体来说，我们根据每个层的复杂度将扩散模型分为三种类型：Diffusion-T：[32，32，64，64]，Diffusion-S：[32，64，128，128]，DiffusionB：[64，128，256，512]正如我们所观察到的，随着扩散模型复杂度的增加，即从扩散-T到扩散-B，真实世界的恢复性能得到了进一步的改善。我们还提供了与MAR相比时恢复任务中扩散损失的深入分析（Li et al，2024）：MAR使用小的MLP作为扩散模型对每个令牌的概率分布进行建模。它与AR模型联合训练，以实现高效的图像生成。特别是token尺寸小，代表高级语义特征。相比之下，我们的扩散模型服务于低级别的图像恢复问题。它直接在密集和宽尺度像素级别上调整恢复结果，需要准确区分图像的丰富纹理。因此，在将恢复模型调整到真实世界域的背景下，扩散模型不能被极度简化。

##### A4.7 更多恢复模型的验证

我们的工作为图像恢复提供了一种新的和通用的域自适应策略，这是当前自监督方法无法取代的。为此，我们进一步在常用的和SOTA恢复模型上验证了我们的方法，如DnCNN，Restormer和SwinIR。这些比较方法的定量评估报告在表A3中。正如我们所观察到的，所有在合成数据集上训练的恢复模型都不能很好地推广到真实世界的数据集，通过引入所提出的域自适应训练策略，这些模型的真实世界性能得到了显著的改善，证明了我们的方法具有良好的推广性和可扩展性。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/244dc6e3ed6645db96a9903da9fa3e5a.png#pic_center)

#### A5 额外的训练细节

##### A5.1 训练和推理

为了清楚地区分和描述训练和推理阶段，我们分别在Alg. 1和Alg. 2中展示了它们的详细过程。为了清楚起见，我们省略了消除捷径解决方案的策略（在Alg. 1的第7步中使用），例如通道洗牌层和剩余交换对比学习。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/fafe8e4b95994b34a45bffa9c309bc77.png#pic_center)

##### A5.2 两个域之间的信息指导

我们做这项工作的动机来自一个有趣的观察：条件扩散模型的预测误差依赖于条件的质量（如图1（a）所示）。因此，在反向传播的扩散损失的指导下，恢复网络被优化以提供“良好”条件来最小化扩散模型的噪声预测误差，在该联合训练期间，合成GT用作扩散模型中的去噪目标，其潜在地提供真实纹理以帮助使降级的真实世界图像适应干净分布。换句话说，由扩散的输入（以多步去噪方式）“泄漏”的干净知识/信息在桥接不同域之间的差距中起重要作用。

通常，ground truth图像和通过恢复模型恢复的那些图像，无论是来自合成域还是来自真实世界域，都应该驻留在高质量、干净图像的共同分布内。然而，合成真实标注数据（GT：Ground Truth）的外观与恢复后的真实世界数据的外观并无关联，这使得扩散模型会利用一种捷径，仅仅依赖成对的合成数据，过度拟合其去噪能力。为此，我们进一步设计关键战略，（例如，通道混洗层和残差交换对比学习）来隐式地模糊条件合成数据和真实的数据之间的边界，并防止模型对容易区分的特征的依赖。因此，从干净分布到退化图像的主动“泄漏”可以在整个训练过程中有效地起作用，不断提高对真实世界图像的恢复性能。