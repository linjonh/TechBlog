---
layout: post
title: "Stable-Diffusion教程快速入门SD绘画原理与安装"
date: 2025-03-06 10:19:33 +0800
description: "什么是Stable Diffusion，什么是炼丹师？根据市场研究机构预测，到2025年全球AI绘画市场规模将达到100亿美元，其中Stable Diffusion（简称SD）作为一种先进的图像生成技术之一，市场份额也在不断增长，越来越多的人参与到AI掘金这场运动中来。炼丹师，就是指那些专门研究、开发与应用Stable Diffusion模型的专业人士或爱好者，他们在实践中不断优化模型，使其产生更高质量、更具创意的图像。"
keywords: "Stable Diffusion教程|快速入门SD绘画原理与安装"
categories: ['未分类']
tags: ['炼丹师', '本地部署', '安装包', 'Stable', 'Sd', 'Diffusion', 'Aigc', 'Ai']
artid: "146060716"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146060716
    alt: "Stable-Diffusion教程快速入门SD绘画原理与安装"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146060716
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146060716
cover: https://bing.ee123.net/img/rand?artid=146060716
image: https://bing.ee123.net/img/rand?artid=146060716
img: https://bing.ee123.net/img/rand?artid=146060716
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Stable Diffusion教程|快速入门SD绘画原理与安装
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     什么是Stable Diffusion，什么是炼丹师？根据市场研究机构预测，到2025年全球AI绘画市场规模将达到100亿美元，其中Stable Diffusion（简称SD）作为一种先进的图像生成技术之一，市场份额也在不断增长，越来越多的人参与到AI掘金这场运动中来。炼丹师，就是指那些专门研究、开发与应用Stable Diffusion模型的专业人士或爱好者，他们在实践中不断优化模型，使其产生更高质量、更具创意的图像。
    </p>
    <p>
     目录
    </p>
    <p>
     _1 SD绘画原理
     <br/>
     _
    </p>
    <p>
     <em>
      2 本地部署安装SD WebUI
     </em>
    </p>
    <p>
     <em>
      3 生成第一张SD绘画
     </em>
    </p>
    <p>
     **一、**
     <strong>
      SD绘画原理
     </strong>
    </p>
    <p>
     <strong>
      基本概念
     </strong>
    </p>
    <table align="center">
     <tbody>
      <tr>
       <td colspan="1" rowspan="1" width="128">
        名词
        <br/>
       </td>
       <td colspan="1" rowspan="1" width="255">
        解释说明‍
        <br/>
       </td>
      </tr>
      <tr>
       <td width="108">
        <strong>
         Stable Diffusion
        </strong>
       </td>
       <td width="255">
        是一种基于
        <strong>
         扩散模型的先进的人工智能技术
        </strong>
        ，特别适用于文本到图像（Text-to-Image）的生成任务。该模型由CompVis、Stability AI、LAION等研究机构和公司合作研发，它利用扩散过程在潜在空间（latent space）中生成图像，而不是直接在高维像素空间中操作。
       </td>
      </tr>
      <tr>
       <td width="128">
        SD WebUI
       </td>
       <td width="255">
        Stable Diffusion Web UI (SD WebUI) 是一个用于交互式控制和使用 Stable Diffusion 模型的
        <strong>
         网页应用程序界面
        </strong>
        。用户可以通过这个界面输入文本提示（prompt）来驱动模型生成相应的图像，提供了简单易用的方式来体验和定制基于 Stable Diffusion 的文本到图像生成过程。
       </td>
      </tr>
      <tr>
       <td width="128">
        Python
       </td>
       <td width="255">
        是一种广泛使用的高级编程语言，以其语法简洁清晰和代码可读性强而著称。在AI领域，Python尤为流行，因为它拥有丰富的科学计算、机器学习和数据处理相关的库，比如NumPy、Pandas和TensorFlow等。在部署和使用像Stable Diffusion这样的深度学习模型时，Python常被作为开发和
        <strong>
         运行环境
        </strong>
        的基础。
       </td>
      </tr>
      <tr>
       <td width="128">
        Controlnet插件
        <br/>
       </td>
       <td width="255">
        是针对 Stable Diffusion 模型开发的一种功能
        <strong>
         扩展插件
        </strong>
        ，它允许用户在文本生成图像的过程中实现更为细致和精确的控制。该插件使得用户不仅能够通过文本提示（prompt）指导模型生成图像，还能添加额外的输入条件，比如
        <strong>
         控制图像的构图、颜色、纹理、物体位置、人物姿势、景深、线条草图、图像分割等多种图像特征
        </strong>
        。通过这种方式，ControlNet 提升了 AI 绘画系统的
        <strong>
         可控性和灵活性
        </strong>
        ，使得艺术创作和图像编辑更加精细化。
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1" width="128">
        Controlnet模型
       </td>
       <td colspan="1" rowspan="1" width="255">
        是配合上述插件工作的一个组成部分，它是经过训练以实现对大型预训练扩散模型（如 Stable Diffusion）进行
        <strong>
         细粒度控制的附加神经网络模型
        </strong>
        。ControlNet 模型可以学习如何根据用户的特定需求去调整原始扩散模型的输出，即便是在训练数据有限的情况下，依然能够确保生成结果的质量和稳定性。例如，ControlNet 可能包括用于识别和利用边缘映射、分割映射或关键点信息的子模块，从而实现对生成图像的特定区域进行针对性修改或强化。
       </td>
      </tr>
      <tr>
       <td width="128">
        VAE
       </td>
       <td width="255">
        <p>
         Variational Autoencoder (VAE): 变分自编码器是
         <strong>
          一种概率生成模型
         </strong>
         ，它结合了编码器（将输入数据编码为潜在空间中的概率分布）和解码器（从潜在空间重构数据）的概念。在图像生成场景中，VAE可以用来学习数据的潜在表示，并基于这些表示生成新的图像。
        </p>
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1" width="108">
        CHECKPOINT
        <br/>
       </td>
       <td colspan="1" rowspan="1" width="235">
        SD能够绘图的基础模型，因此被称为
        <strong>
         大模型、底模型或者主模型
        </strong>
        ，WebUI上就叫它Stable Diffusion模型。安装完SD软件后，必须搭配主模型才能使用。不同的主模型，其画风和擅长的领域会有侧重。checkpoint模型包含生成图像所需的一切，不需要额外的文件。
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1" width="108">
        hyper-network
       </td>
       <td colspan="1" rowspan="1" width="235">
        超网络是一种模型微调技术，最初是由NOVA AI 公司开发的。它是一个附属于Stable Diffusion 稳定扩散模型的小型神经网络，是一种额外训练出来的
        <strong>
         辅助模型
        </strong>
        ，用于修正SD稳定扩散模型的风格。
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1" width="108">
        LORA‍
        <br/>
       </td>
       <td colspan="1" rowspan="1" width="235">
        全称是Low-Rank Adaptation of Large Language Models 低秩的适应大语言模型，可以理解为
        <strong>
         SD模型的一种插件
        </strong>
        ，和hyper-network，controlNet一样，都是在不修改SD模型的前提下，利用少量数据训练出一种画风/IP/人物，实现定制化需求，所需的训练资源比训练SD模要小很多，非常适合社区使用者和个人开发者。LoRA最初应用于NLP领域，用于微调GPT-3等模型（也就是ChatGPT的前生）。由于GPT参数量超过千亿，训练成本太高，因此LoRA采用了一个办法，仅训练低秩矩阵（low rank matrics），使用时将LoRA模型的参数注入（inject）SD模型，从而改变SD模型的生成风格，或者为SD模型添加新的人物/IP。
        <br/>
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1" width="108">
        <p>
         prompt
        </p>
       </td>
       <td colspan="1" rowspan="1" width="235">
        提示词/咒语
        <br/>
       </td>
      </tr>
     </tbody>
    </table>
    <p>
     <strong>
      工作原理
     </strong>
    </p>
    <p>
     Stable Diffusion就是一个接收文本提示词，并生成相应图像的生成模型。
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/img_convert/8f609182fd315e95d9cda2eb7322242b.png"/>
    </p>
    <p>
     SD来自于扩散模型（Diffusion Model）
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/img_convert/3ed3f962129e9e49f470b601f907f75b.png"/>
    </p>
    <p>
     扩散模型：（Diffusion Model）的核心原理被生动地比喻为物理学中的扩散过程，通过前向扩散过程逐渐将图像转化为噪声图像，然后通过反向扩散过程恢复出清晰的图像。在Stable Diffusion中，模型训练了一个噪声预测器（noise predictor），它是一个U-Net结构的神经网络，可以预测并从图像中去除噪声，从而重构原始图像。
    </p>
    <p>
     然而，传统的扩散模型在图像空间中的运算效率极低，不适合实时应用。为此，Stable Diffusion采用了在潜在空间（latent space）中进行扩散的过程，利用变分自编码器（VAE）将图像压缩到较低维度的空间，极大地提高了计算速度和效率。
    </p>
    <p>
     Stable Diffusion的具体工作流程包括：
    </p>
    <ol>
     <li>
      <p>
       输入图像被编码到潜在空间。
      </p>
     </li>
     <li>
      <p>
       添加噪声，并通过噪声预测器估算添加的噪声量。
      </p>
     </li>
     <li>
      <p>
       反复迭代，通过噪声预测器预测并减去潜在噪声。
      </p>
     </li>
     <li>
      <p>
       使用VAE的解码器将清理过的潜在图像转换回像素空间，生成最终图像。
      </p>
     </li>
    </ol>
    <p>
     <strong>
      学习资料
     </strong>
    </p>
    <p>
     国外一手资料:
    </p>
    <blockquote>
     <p>
      stability.ai官网
      <br/>
      https://stability.ai/about
     </p>
     <p>
      github开源项目
     </p>
     <p>
      https://github.com/CompVis/stable-diffusion/blob/main/README.md
     </p>
     <p>
      The Illustrated Stable Diffusion @Jay Alammar 讲的原理
      <br/>
      https://jalammar.github.io/illustrated-stable-diffusion/
      <br/>
      这份完整版的SD整合包已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【
      <code>
       保证100%免费
      </code>
      】
     </p>
    </blockquote>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/dba3f11cff454be59b9c8402a935e6c6.jpeg#pic_center"/>
    </p>
    <p>
     <strong>
      二、本地部署安装SD WebUI
     </strong>
    </p>
    <p>
     <strong>
      硬件条件
     </strong>
    </p>
    <p>
     说明：本地部署的硬件要求，当然使用云端部署租赁更高端的机器也是没问题。
    </p>
    <table>
     <tbody>
      <tr>
       <td colspan="1" rowspan="1" width="228">
        <br/>
       </td>
       <td colspan="1" rowspan="1" width="228">
        <p>
         最低推荐配置
        </p>
       </td>
       <td colspan="1" rowspan="1" width="228">
        <p>
         推荐配置
        </p>
       </td>
       <td colspan="1" rowspan="1" width="228">
        <p>
         备注
        </p>
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1" width="228">
        <p>
         显卡（GPU）
        </p>
       </td>
       <td colspan="1" rowspan="1" width="228">
        <p>
         GTX1050Ti
        </p>
       </td>
       <td colspan="1" rowspan="1" width="228">
        <p>
         低配推荐：RTX4060Ti-16G高配推荐：RTX4090
        </p>
       </td>
       <td colspan="1" rowspan="1" width="228">
        <p>
         为达到良好的体验，请尽可能使用8GB显存及以上显卡。低显存虽然能跑，但是体验极差
        </p>
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1" width="228">
        <p>
         内存（RAM）
        </p>
       </td>
       <td colspan="1" rowspan="1" width="228">
        <p>
         8GB内存
        </p>
       </td>
       <td colspan="1" rowspan="1" width="228">
        <p>
         总内存24GB及以上
        </p>
       </td>
       <td colspan="1" rowspan="1" width="228">
        <p>
         可以开启虚拟内存，内存过小会在加载模型的时候出现问题
        </p>
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1" width="228">
        <p>
         存储空间
        </p>
       </td>
       <td colspan="1" rowspan="1" width="228">
        <p>
         20GB任意存储设备
        </p>
       </td>
       <td colspan="1" rowspan="1" width="228">
        <p>
         500GB以上固态硬盘
        </p>
       </td>
       <td colspan="1" rowspan="1" width="228">
        <p>
         强烈建议单独使用一个盘符，如果不想启动的时候等10分钟的话，那么只推荐使用SSD
        </p>
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1" width="228">
        <p>
         CPU
        </p>
       </td>
       <td colspan="3" rowspan="1" width="686">
        <p>
         x86架构的Intel或AMD等处理器都可以，
        </p>
        <p>
         若为Mac电脑建议使用搭载M系列芯片的机型。
        </p>
       </td>
      </tr>
     </tbody>
    </table>
    <ol>
     <li>
      显卡VRAM在4GB以下的会很容易遇到显存不足的问题，即使使用放大插件也就非常慢（以时间换显存）
     </li>
    </ol>
    <p>
     2. 显卡较差/显存严重不足时可以开启CPU模式，但是速度非常慢。你不希望一个小时一张图的话那就别想着用CPU跑图。
    </p>
    <p>
     <strong>
      软件需求
     </strong>
    </p>
    <p>
     Windows：最低要求为Windows 10 64比特，请确保系统已更新至最新版本。
    </p>
    <p>
     macOS：最低要求为macOS Monterey (12.5)，如果可以的话请使用最新版macOS。建议使用搭载Apple Silicon M芯片 (M1、M2) 的Mac机型。旧款Mac需配备AMD独立显卡，只有Intel核显的不能使用。
    </p>
    <p>
     <strong>
      下载地址 (不藏着掖着，直接拿走不谢)
     </strong>
     <br/>
     这份完整版的SD整合包已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【
     <code>
      保证100%免费
     </code>
     】
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/477f68e316c44781a270635a3faa1621.jpeg#pic_center"/>
    </p>
    <p>
     <strong>
      安装部署
     </strong>
    </p>
    <p>
     2025.1月 更新了最新的整合包，无需任何操作即可达到最佳速度，解压打开即用，内置启动器。
    </p>
    <p>
     整合包做了哪些事情？打包了 Python、Git、CUDA 等等必须的环境，并且放了运行必须的模型。简单来说，整合包就是 SD-WebUI内核+启动器+安装好的环境+必须的模型。你只需下载它解压就可以直接启动运行！
    </p>
    <p>
     特别鸣谢，安装包作者@秋葉aaaki
    </p>
    <p>
     **三、**
     <strong>
      生成第一张SD绘画
     </strong>
    </p>
    <p>
     <strong>
      启动“A启动器.exe”
     </strong>
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/img_convert/0ec6f10b767ebcdbfa38dcb923ab16dd.png"/>
    </p>
    <p>
     加载更新
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/img_convert/409ee6a885d908673125f1b3a6aee1e9.png"/>
    </p>
    <p>
     点击“一键启动”
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/img_convert/8ecab7145b01ac5f8bb33ade453209db.png"/>
    </p>
    <p>
     [不要关闭它],它会自动打开，浏览器地址"http://127.0.0.1:7860/?__theme=dark"
    </p>
    <p>
     <strong>
      基本功能介绍
     </strong>
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/img_convert/0e33e0b6257b608341597800f80fcdbf.png"/>
    </p>
    <table>
     <tbody>
      <tr>
       <td align="center" colspan="2" rowspan="1" width="463">
        界面及操作说明
        <br/>
       </td>
      </tr>
      <tr>
       <td width="146">
        stable diffusion模型
        <br/>
       </td>
       <td width="337">
        下拉，替换大模型/底模
        <br/>
       </td>
      </tr>
      <tr>
       <td width="126">
        正面提示词 Tag
        <br/>
       </td>
       <td width="337">
        <p>
         （想要的内容，提示词）
        </p>
        <p>
         如：masterpiece, best quality,
        </p>
       </td>
      </tr>
      <tr>
       <td width="146">
        反面提示词 Tag
       </td>
       <td width="337">
        <p>
         （不想要的内容，提示词）
        </p>
        <p>
         如：lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry
        </p>
       </td>
      </tr>
      <tr>
       <td width="146">
        提示词加权重
        <br/>
       </td>
       <td width="337">
        <p>
         (girl) 加权重，这里是1.1倍。
        </p>
        <p>
         （(girl)) 加很多权重，1.1*1.1=1.21倍，以此类推。
        </p>
       </td>
      </tr>
      <tr>
       <td width="146">
        提示词减权重
       </td>
       <td width="337">
        [girl] 减权重，一般用的少。减权重也一般就用下面的指定倍数。
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1">
        提示词指定权重
        <br/>
       </td>
       <td colspan="1" rowspan="1" width="7">
        (girl:1.5) 指定倍数，这里是1.5倍的权重。还可以 (girl:0.9) 达到减权重的效果
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1">
        采样迭代步数
       </td>
       <td colspan="1" rowspan="1" width="7">
        <p>
         不需要太大，一般在50以内。通常28是一个不错的值。
        </p>
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1">
        采样方法
        <br/>
       </td>
       <td colspan="1" rowspan="1" width="7">
        没有优劣之分，但是他们速度不同。全看个人喜好。推荐的是图中圈出来的几个，速度效果都不错
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1">
        提示词相关性
       </td>
       <td colspan="1" rowspan="1" width="7">
        代表你输入的 Tag 对画面的引导程度有多大，可以理解为 “越小AI越自由发挥”，太大会出现锐化、线条变粗的效果。太小AI就自由发挥了，不看 Tag
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1">
        随机种子
       </td>
       <td colspan="1" rowspan="1" width="7">
        生成过程中所有随机性的源头 每个种子都是一幅不一样的画。默认的 -1 是代表每次都换一个随机种子。由随机种子，生成了随机的噪声图，再交给AI进行画出来
       </td>
      </tr>
     </tbody>
    </table>
    <p>
     切换webUI黑白皮肤，修改浏览器http地址：
     <br/>
     白：http://127.0.0.1:7860/?__theme=light
     <br/>
     黑：http://127.0.0.1:7860/?__theme=dark
    </p>
    <p>
     <strong>
      输入提示词【1 girl】，点击生成即可：
     </strong>
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/img_convert/06b286890959ec800c7ce30cc31a6490.png"/>
    </p>
    <p>
     （我安装了皮肤插件，所以和你运行的界面稍微酷炫一点
     <sup>
      _
     </sup>
     ）
    </p>
    <p>
     **点点下方【收藏】和【
     <strong>
      点
      <strong>
       <strong>
        赞
       </strong>
      </strong>
      】再走，赠人玫瑰 手留余香！****
      <img alt="" src="https://i-blog.csdnimg.cn/img_convert/abe7cde6a1ac54a5574c24096c6e3d14.gif"/>
     </strong>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f323430315f38333034383139372f:61727469636c652f64657461696c732f313436303630373136" class_="artid" style="display:none">
 </p>
</div>


