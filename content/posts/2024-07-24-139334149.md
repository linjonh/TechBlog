---
layout: post
title: 2024-07-24-大模型微调部署实战及类GPT工具的高效使用
date: 2024-07-24 07:00:00 +0800
categories: ['大模型微调部署实战及类Gpt工具的高效使用']
tags: ['大模型', '微调', '大模型微调', '大模型部署', 'Gpt']
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=139334149
  alt: 大模型微调部署实战及类GPT工具的高效使用
artid: 139334149
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=139334149
featuredImagePreview: https://bing.ee123.net/img/rand?artid=139334149
---

# 大模型微调部署实战及类GPT工具的高效使用

大家好，我是herosunly。985院校硕士毕业，现担任算法研究员一职，热衷于大模型算法的研究与应用。曾担任百度千帆大模型比赛、BPAA算法大赛评委，编写微软OpenAI考试认证指导手册。曾获得阿里云天池比赛第一名，CCF比赛第二名，科大讯飞比赛第三名。授权多项发明专利。对机器学习和深度学习拥有自己独到的见解。曾经辅导过若干个非计算机专业的学生进入到算法行业就业。希望和大家一起成长进步。

本文主要介绍了专栏《大模型微调部署实战及类GPT工具的高效使用》的核心内容，希望对使用大语言模型的同学们有所帮助。

#### 文章目录

* [1. 前言](#1__5)
* [2. 专栏亮点](#2__33)
* [3. 你的收获](#3__38)
* [4. 详细目录](#4__45)

## 1. 前言

随着时间的齿轮转动到2024年，各种
`行业大模型`
如雨后春笋般涌现。如何基于
`基座模型`
和
`领域数据`
构建
`行业大模型`
成为了近期研究和落地的热点方向。因此基于大模型进行
`微调`
和
`部署`
成为了大多数企业的日常操作，但模型微调存在相当的技术门槛，稍有差池或者经验不足极易造成过拟合（严重的灾难性遗忘）、或者欠拟合（无法有效学习特定领域知识）的情形。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/e438ca1837b43a43f8fba21cba6b3274.png#pic_center)

与此同时，
**善用AI**
的人利用各种GPT工具完成写文章、写总结、写代码、阅读论文、文本翻译等
**日常任务**
，极大提升了工作和生活的效率。为了帮助大家更好地理解和掌握上述内容，个人精心打造了全面且不断迭代的
**系统性课程**
。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/b24dbb799a300ecba5a0eaf04676b564.png#pic_center)

但在大模型实践过程中，往往存在着各种各样的坑，不管是大模型的下载和使用，还是大模型的微调与部署，一个看似简单的小问题就需要花费非专业人士数个小时，更何况很多同学是刚入门不久的小白，所以
**很容易就从入门走向放弃**
。

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/b2ef5adbd6fd4a1bd386c9c0f28cc266.png#pic_center)
  
但市面上的大模型实战课程质量参差不齐，要么步骤不够详细，要么只包含文字（没有必要的截图）。很多同学可能会卡在某个点上很长时间，从易到难比如：无法连接
`huggingface`
、下载高速下载
`github`
源码、微调前不知从何入手、微调过程中不知如何进行迭代和精进、微调后不知如何选择比较好的checkpoint、微调后无法判断是否达到了预期的效果。

**首先需要说明的是：由于现阶段推理模型（DeepSeek-R1）是一大研究热点，所以已开启狂暴更新模式，一周至少更新3篇+，希望能对同学们有所帮助。**

另外本课程包括以下主要内容：首先，我们将深入解析
**大模型的基本概念**
，其中包括从入门到精进的提示工程、主流大模型的System Prompt、GPT和LLaMA模型的进化之路。
**大模型的部署与推理**
是模型微调的前提，所以详细介绍了huggingface高速下载模型的实战代码、多种部署大模型API的实战教程、不同语言及其代码（包括Text2SQL）大模型的部署方案。接着，我们将详细讲解
**大模型微调的技巧和实验方法**
，包括大模型微调数据集构建方法、大模型微调选择模型的实战技巧、LoRA微调调参的实战技巧、LLama Factory单机和多机微调等实战教程、Lora Adapter可视化的实战教程、判断大模型微调是否产生灾难性遗忘的实战方案、大模型微调出错的解决方案。除此之外，我们将详细讲解
**GPT工具在不同场景下的高效使用方法**
，包括智能搜索、阅读论文、文本翻译、代码生成等实际场景。为了让大家更好的使用工作流提升工作效率和接入业务场景，近期也在更新
**大模型工作流**
的相关文章。

本专栏致力于以图文并茂、通俗易懂、步骤详尽的形式对大模型重要知识点进行系统性讲解。 每一篇都是经过亲身的实践经历总结而来的，已订阅人数超过1100+，已更新文章125+，并且将持续更新，近期更新频率为一周2~3篇。帮助多名同学解决大模型部署、微调及其测评等各类实战问题。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a4eadb792a92431cb26d76e9d38d668b.png)

## 2. 专栏亮点

* 系统全面的大模型概念详解和实战应用课程，覆盖了大模型理论基础和实战应用的完整路径。
* 每一篇文章都是经过精心撰写而成的，文章平均质量分数为92（
  **远超其他热门和同类专栏**
  ）。
* 实战文章均来自于亲身的实践经验，为了方便小白学习，通过图文的形式详细介绍了每一步的操作和正确执行结果，方便进行逐步的验证。
* 持续更新前沿文章，近期更新频率为一周2~3篇，已更新篇数为106篇，目标更新篇数为500篇。

## 3. 你的收获

* 掌握大模型的核心概念和应用实战，尤其是对大模型进行微调和部署。
* 掌握使用GPT工具的方法和技巧，早日成为善用AI的人。
* 高效学习精炼后的大模型前沿知识，有效提升学习效率。
* 购买专栏可加入大模型交流群学习，群里还有不定期抽奖送书等福利。

## 4. 详细目录

第一章：大模型的基础知识与核心概念

1. [ChatGPT启蒙之旅：弟弟妹妹的关键概念入门](https://blog.csdn.net/herosunly/article/details/133544962)
2. [GPT内功心法：搜索思维到GPT思维的转换](https://blog.csdn.net/herosunly/article/details/132245449)
3. [从用户的角度谈GPT时代技术突破的两大关键逻辑](https://blog.csdn.net/herosunly/article/details/131869554)
4. [AIGC提示(prompt)工程之开宗明义篇](https://blog.csdn.net/herosunly/article/details/131263997)
5. [AIGC提示(prompt)飞升方法：走向专家之路](https://blog.csdn.net/herosunly/article/details/138589447)
6. [GPT-4o模型介绍和使用方法](https://blog.csdn.net/herosunly/article/details/138897396)
7. [Claude3系统解读与使用测评](https://blog.csdn.net/herosunly/article/details/136604263)
8. [LLaMA模型系统解读](https://blog.csdn.net/herosunly/article/details/130793858)
9. [多图详解LLaMA 3的使用方法和进化之路](https://blog.csdn.net/herosunly/article/details/138030224)
10. [Meta大佬亲授LLaMA 3的奥秘](https://blog.csdn.net/herosunly/article/details/138319698)
11. [从System Prompt来看Claude3、Kimi和ChatGLM4之间的差距](https://blog.csdn.net/herosunly/article/details/139306303)
12. [从System Prompt来看GPT-3.5到GPT-4的进化](https://blog.csdn.net/herosunly/article/details/139105430)
13. [详解OpenAI大佬每日读物: The Bitter Lesson](https://blog.csdn.net/herosunly/article/details/136263738)
14. [如何从宏观层面构建优秀的大语言模型](https://blog.csdn.net/herosunly/article/details/130905326)
15. [大模型训练数据多样性的重要性](https://blog.csdn.net/herosunly/article/details/130712802)
16. [大模型量化方法总结](https://blog.csdn.net/herosunly/article/details/136198531)
17. [查看大模型对应的准确参数量和网络结构的实战代码](https://blog.csdn.net/herosunly/article/details/135160844)
18. [详解LangChain Agents](https://blog.csdn.net/herosunly/article/details/136454366)
19. [baichuan 2模型使用的注意事项](https://blog.csdn.net/herosunly/article/details/137705431)
20. [baichuan(百川)1和2的tokenizer的比较](https://blog.csdn.net/herosunly/article/details/137593774)

---

第二章：大模型的部署与推理

1. [huggingface连接不上的解决方案(持续更新)](https://blog.csdn.net/herosunly/article/details/13298f9540)
2. [github连接不上的解决方案](https://blog.csdn.net/herosunly/article/details/140602713)
3. [huggingface高速下载模型的实战代码](https://blog.csdn.net/herosunly/article/details/135879220)
4. [计算huggingface模型占用硬盘空间的实战代码](https://blog.csdn.net/herosunly/article/details/136001388)
5. [FP16、BF16、INT8、INT4精度模型加载所需显存以及硬件适配的分析](https://blog.csdn.net/herosunly/article/details/138413400)
6. [部署大模型API的实战教程](https://blog.csdn.net/herosunly/article/details/135608714)
7. [大模型推理加速框架vllm部署的实战方案](https://blog.csdn.net/herosunly/article/details/134610440)
8. [详解FastChat部署大模型API的实战教程](https://blog.csdn.net/herosunly/article/details/138245511)
9. [本地部署GPT的实战方案](https://blog.csdn.net/herosunly/article/details/134672820)
10. [ChatGPT API实现多轮对话的实战代码](https://blog.csdn.net/herosunly/article/details/130778551)
11. [Qwen2本地部署的实战教程](https://blog.csdn.net/herosunly/article/details/139513956)
12. [GLM-4本地部署的实战教程](https://blog.csdn.net/herosunly/article/details/139469337)
13. [Llama3本地部署的解决方案](https://blog.csdn.net/herosunly/article/details/138088627)
14. [中文开源模型Command R+的在线使用和本地部署的解决方案](https://blog.csdn.net/herosunly/article/details/137978789)
15. [ChatDoctor本地部署应用的实战方案](https://blog.csdn.net/herosunly/article/details/129933237)
16. [通义千问7B本地部署的实战方案](https://blog.csdn.net/herosunly/article/details/132124697)
17. [baichuan2(百川2)本地部署的实战方案](https://blog.csdn.net/herosunly/article/details/132755541)
18. [CodeLlama本地部署的实战方案](https://blog.csdn.net/herosunly/article/details/132516034)
19. [ChatGLM2本地部署的实战方案](ChatGLM2%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E7%9A%84%E5%AE%9E%E6%88%98%E6%96%B9%E6%A1%88)
20. [ChatGLM3 本地部署的解决方案](https://blog.csdn.net/herosunly/article/details/134083456)
21. [ChatGLM3设置角色和工具调用的解决方案](https://blog.csdn.net/herosunly/article/details/134211146)
22. [GLM-130B本地部署的实战方案](https://blog.csdn.net/herosunly/article/details/131523682)
23. [MiniGPT-4本地部署的实战方案](https://blog.csdn.net/herosunly/article/details/131352251)
24. [Vicuna本地部署的实战方案](https://blog.csdn.net/herosunly/article/details/131206577)
25. [CPM-Bee本地部署的实战方案](https://blog.csdn.net/herosunly/article/details/131025472)
26. [天鹰340亿(AquilaChat2-34B-16K)本地部署的解决方案](https://blog.csdn.net/herosunly/article/details/133830497)
27. [Orion-14B-Chat-RAG本地部署的解决方案](https://blog.csdn.net/herosunly/article/details/135933586)
28. [Orion-14B-Chat-Plugin本地部署的解决方案](https://blog.csdn.net/herosunly/article/details/135933586)
29. [Orion-14B-Chat-Plugin [model server error]解决方案](https://blog.csdn.net/herosunly/article/details/135932996)
30. [下载马斯克Grok-1模型的实战代码](https://blog.csdn.net/herosunly/article/details/136841447)
31. [大模型推理速度测评的实战代码](https://blog.csdn.net/herosunly/article/details/135414984)
32. [LLaMA Factory在预测阶段时添加原有问题的实战代码](https://blog.csdn.net/herosunly/article/details/138374808)

---

第三章：大模型的微调与优化

1. [大模型微调数据集构建方法(持续更新)](https://herosunly.blog.csdn.net/article/details/139441555)
2. [大模型LoRA微调调参的实战技巧(持续更新)](https://herosunly.blog.csdn.net/article/details/138367828)
3. [大模型微调选择模型的实战技巧(持续更新)](https://blog.csdn.net/herosunly/article/details/140342216)
4. [模型全参数训练和LoRA微调所需显存的分析](https://blog.csdn.net/herosunly/article/details/138472324)
5. [LLaMA Factory单机微调的实战教程](https://blog.csdn.net/herosunly/article/details/138170100)
6. [LLaMA Factory多卡微调的实战教程](https://blog.csdn.net/herosunly/article/details/138166217)
7. [基于大模型的Text2SQL微调的实战教程](https://blog.csdn.net/herosunly/article/details/131833028)
8. [基于大模型的Text2SQL微调的实战教程(二)](https://blog.csdn.net/herosunly/article/details/138120791)
9. [Lora Adapter可视化的实战教程](https://blog.csdn.net/herosunly/article/details/139019892)
10. [大模型自我认知微调的实战教程](https://blog.csdn.net/herosunly/article/details/135288527)
11. [ChatGLM LoRA微调实战方案](https://blog.csdn.net/herosunly/article/details/130409847)
12. [ChatGLM ptuning 的实战方案](https://blog.csdn.net/herosunly/article/details/130347068)
13. [判断大模型微调是否产生灾难性遗忘的实战方案](https://blog.csdn.net/herosunly/article/details/138682323)
14. [大模型微调和RAG的应用场景](https://blog.csdn.net/herosunly/article/details/139813879)
15. [大模型微调出错的解决方案](https://blog.csdn.net/herosunly/article/details/139653011)
16. [大模型提问中包括时间的实战方案](https://blog.csdn.net/herosunly/article/details/140171778)

---

第四章：Text2SQL

1. [Text2SQL基座模型选择的实战教程](https://blog.csdn.net/herosunly/article/details/139843005)
2. [最强开源Text2SQL大模型本地部署的解决方案](https://blog.csdn.net/herosunly/article/details/133770845)
3. [基于大模型的Text2SQL微调的实战教程(新)](https://blog.csdn.net/herosunly/article/details/138120791)
4. [Text2SQL中不同数据库SQL之间转换的实战代码](https://blog.csdn.net/herosunly/article/details/139984250)
5. [Langchain+本地大语言模型进行数据库操作的实战代码](https://blog.csdn.net/herosunly/article/details/131339108)
6. [Text2SQL提问中包括时间的实战方案](https://blog.csdn.net/herosunly/article/details/140248429)
7. [Text2SQL中反思纠错的实战方案](https://blog.csdn.net/herosunly/article/details/140061032)

---

第五章：GPT工具的高效使用方法

1. [AIGC时代高效阅读论文实操](https://blog.csdn.net/herosunly/article/details/135726345)
2. [AIGC高效进行网页总结的工具使用](https://blog.csdn.net/herosunly/article/details/137829838)
3. [高效翻译工具GPT插件的使用教程](https://blog.csdn.net/herosunly/article/details/133990844)
4. [国内智能搜索工具实战教程](https://blog.csdn.net/herosunly/article/details/138758838)
5. [基于GPT-3.5和GPT-4的免费代码生成工具](https://blog.csdn.net/herosunly/article/details/129619972)
6. [搜索神器Perplexity的详细使用方法](https://blog.csdn.net/herosunly/article/details/129213487)
7. [搜索神器Phind的详细使用方法](https://blog.csdn.net/herosunly/article/details/129326671)
8. [探寻大模型回答9.9和9.11犯错的根本原因](https://blog.csdn.net/herosunly/article/details/140513537)
9. [不同问题来评测百度、谷歌、ChatGPT、Phind、GPT-4](https://blog.csdn.net/herosunly/article/details/130564384)
10. [速评谷歌开源大模型Gemma 7B](https://blog.csdn.net/herosunly/article/details/136229345)
11. [使用AIGC工具巧用Linux系统](https://blog.csdn.net/herosunly/article/details/130718813)
12. [使用AIGC工具提升论文阅读效率](https://blog.csdn.net/herosunly/article/details/131142438)
13. [使用ChatGPT工具阅读文献的实战教程](https://blog.csdn.net/herosunly/article/details/130476938)
14. [使用ChatGPT设计选择题](https://blog.csdn.net/herosunly/article/details/130968193)
15. [使用ChatGPT提升记忆效率](https://blog.csdn.net/herosunly/article/details/130963705)
16. [用好GPT关键诀窍之上下文学习](https://blog.csdn.net/herosunly/article/details/131960173)
17. [用好ChatGPT之准确分配角色](https://blog.csdn.net/herosunly/article/details/129953816)
18. [使用范例调教ChatGPT](https://blog.csdn.net/herosunly/article/details/129900855)
19. [ChatGPT和GPT-4帮你写人物传记](https://blog.csdn.net/herosunly/article/details/130216942)
20. [ChatGPT和GPT-4带你选笔记本电脑](https://blog.csdn.net/herosunly/article/details/130015811)
21. [大模型生成人物关系思维导图的实战教程](https://blog.csdn.net/herosunly/article/details/140393893)
22. [图文详解GPT-4最强对手Claude2的使用方法](https://blog.csdn.net/herosunly/article/details/131710909)
23. [Claude2轻松解决代码Bug的实战方案](https://blog.csdn.net/herosunly/article/details/131732086)

---

第六章：DeepSeek模型相关内容（正在更新中）

1. [deepseek提示词实战教程（持续更新）](https://blog.csdn.net/herosunly/article/details/145547796)
2. [DeepSeek R1蒸馏版模型部署的实战教程](https://blog.csdn.net/herosunly/article/details/145490150)

---

第七章：大模型工作流（正在更新中）

1. [通过命令行工作流提升工作效率的实战教程（持续更新）](https://blog.csdn.net/herosunly/article/details/140476210)
2. [使用工作流产生高质量翻译内容的实战教程](https://blog.csdn.net/herosunly/article/details/140573582)

68747470733a2f:2f626c6f672e6373646e2e6e65742f6865726f73756e6c792f:61727469636c652f64657461696c732f313339333334313439