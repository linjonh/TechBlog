---
arturl_encode: "687474:70733a2f2f626c6f672e6373646e2e6e65742f6c63616c7166:2f61727469636c652f64657461696c732f3539353136343933"
layout: post
title: "音视频同步网络抖动"
date: 2024-12-24 08:50:13 +08:00
description: "今天在一个流媒体群里，看到一个大神分享自己解决网络抖动、音视频同步的方法，记录一下学习学习。注：时间"
keywords: "new audioinputstream(line) 丢帧"
categories: ['编解码']
tags: ['无标签']
artid: "59516493"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=59516493
    alt: "音视频同步网络抖动"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=59516493
featuredImagePreview: https://bing.ee123.net/img/rand?artid=59516493
---

# 音视频同步、网络抖动

今天在一个流媒体群里，看到一个大神分享自己解决网络抖动、音视频同步的方法，记录一下学习学习。

注：时间是用的相对时间戳，则时间越小播放越快，注释很明白相信大家一看就明白了。

```cpp
变量名称
static int m_timer_realtime_video ;      //每一次回调渲染数据定时器时间，可根据时间戳变化，毫秒
static long long m_audio_list_node_pts;                //当前从pcm的list中取出的时间最新  //解决网络抖动问题
static long long m_audio_openal_pts;                   //音频当前正在播放时间戳 //解决网络抖动问题
//存放解码后yuv数据的list
static list<Raw_data_yuv> m_list_Raw_data_yuv;
//存放解码后pcm数据的list
static list<Raw_data_pcm> m_list_Raw_data_pcm;
```

  
  

![](https://img-blog.csdn.net/20170302145011396?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGNhbHFm/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

优化版本

![](https://img-blog.csdn.net/20170302145239459?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGNhbHFm/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

音视频同步

![](https://img-blog.csdn.net/20170302145300600?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGNhbHFm/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
![](https://img-blog.csdn.net/20170302145309194?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGNhbHFm/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

//具体算法

见大神博客
<http://blog.csdn.net/zhuweigangzwg/article/details/59528378>

```cpp
//得到当前音频从包里拿出的pts减去第一帧pts所得时间再减去openal缓存的时间。//解决网络抖动问题
long long m_audio_real_pts = (m_audio_list_node_pts - m_first_audio_pts) - lvs_openal_getnumqueuedsize_realpts();

int delay = 0;
int diff = 0;;
//算出一帧视频本应该显示的时间
delay = 40;
// update delay to sync to audio 
long long video_real_pts = yuv_data_node.pts - m_first_video_pts;

printf("yuv_data_node.ActualLen : %lld video_real_pts :%lld\n",yuv_data_node.ActualLen,video_real_pts);

//音频过快大于200毫秒 并且有音频存在的情况下 ,以及音频队列或缓存不为传输中间空     //解决网络抖动问题
if (m_audio_real_pts - video_real_pts > 200 && m_isfind_first_audio_pts == 1 && 
	(m_list_Raw_data_pcm.size() != 0 || lvs_openal_getnumqueuedsize() != 0 ))
{
	m_timer_realtime_video = 1;
}
//视频过快大于200毫秒 并且有音频存在的情况下,以及音频队列或缓存不为传输中间空      //解决网络抖动问题
else if (video_real_pts - m_audio_real_pts > 200 && m_isfind_first_audio_pts ==1 &&
(m_list_Raw_data_pcm.size() != 0 || lvs_openal_getnumqueuedsize() != 0 ))
{
	m_timer_realtime_video = delay* 5; //如果 视频显示过快 则停留 5帧的时间
}
else
{
	diff = video_real_pts - m_audio_openal_pts; 

	if(abs(diff) < AV_NOSYNC_THRESHOLD) //求浮点数x的绝对值
	{
		if(diff <= -delay) 
		{
			delay = 10;       //如果 视频显示过慢，离音频 过于远 则 显示时间为10ms
		} 
		else if(diff >= delay)
		{
			delay = 2 * delay;  //如果 视频显示过快 则停留 两帧的时间
		}
	}
	m_timer_realtime_video = delay;
}
```

  
  

顺便请教了大神一些问题。下面是我整理的大神的分享。

当播放器接入服务器播放的时候不一定每次都切到I帧，

一旦产生切到P帧或者B帧的时候会出现花屏或者黑屏的情况，甚至播不出来。这时候就有两个方案来处理这个问题。

1：帧精确
  
2：fastpaly

帧精确好理解 就是把一个gop切到的重新编码，即服务器把切到的P帧再重新编码为I帧，再下发但这样效率会很低

更多的 更好的是才用第二种
  
比如一个gop 25帧，你播放器切到了第10帧 是个p帧，整个gop从i帧到你切的这个p帧数据一定要照常发送才能解码出来不花屏。但最核心的是要改这个gop的时间戳 ，从i帧到这个切的p帧 。假设你切的这个p帧时间戳是100，那前面的10帧就是90 91 ....100，这就是fastpaly，既解决延迟 又解决花屏，即修改当前gop中的I帧到切换的P帧中的所有帧的时间，服务器端默认都会缓冲一个gop的。

例如开源的srs 服务器 在 src/app/srs_app_source.h中有个  SrsGopCache类进行gop缓冲，SrsRtmpJitter进行时间戳抖动处理，如果需要大家可以去看看。