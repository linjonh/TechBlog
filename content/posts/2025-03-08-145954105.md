---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34343932343639342f:61727469636c652f64657461696c732f313435393534313035"
layout: post
title: "线性代数之矩阵特征值与特征向量的数值求解方法"
date: 2025-03-08 17:11:42 +08:00
description: "特征方程与求解方法根据定义A−λIu0A−λIu0若A−λIA−λI非奇异，则方程只有零解。det⁡A−λI0。"
keywords: "lanczos算法求特征值"
categories: ['线性代数']
tags: ['线性代数', '矩阵']
artid: "145954105"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145954105
    alt: "线性代数之矩阵特征值与特征向量的数值求解方法"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145954105
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145954105
cover: https://bing.ee123.net/img/rand?artid=145954105
image: https://bing.ee123.net/img/rand?artid=145954105
img: https://bing.ee123.net/img/rand?artid=145954105
---

# 线性代数之矩阵特征值与特征向量的数值求解方法

## 前言

定n×n维矩阵A，满足下式的数λ称作矩阵A的一个特征值：
  




A
u
=
λ
u
Au = \lambda u





A

u



=





λ

u
  
**推广形式**

特征值问题可推广到更一般的形式。假设

u
=
f
(
x
)
u = f(x)





u



=





f

(

x

)
是一个连续函数，

A
=
d
d
x
A = \frac{d}{dx}





A



=
















d

x











d

​

表示微分运算，则二阶微分方程：
  




d
2
u
d
x
2
=
k
2
u
\frac{d^2u}{dx^2} = k^2u
















d


x









2












d









2

u

​




=






k









2

u
  
可表示为：
  




A
2
u
=
k
2
u
A^2u = k^2u






A









2

u



=






k









2

u
  
这是特征值问题在微分算子中的表现形式。

---

**特征方程与求解方法**

根据定义

(
A
−
λ
I
)
u
=
0
(A - \lambda I)\mathbf{u} = 0





(

A



−





λ

I

)

u



=





0
  
若

A
−
λ
I
A - \lambda I





A



−





λ

I
非奇异，则方程只有零解。因此，特征值需满足：
  




det
⁡
(
A
−
λ
I
)
=
0
\det(A - \lambda I) = 0





det

(

A



−





λ

I

)



=





0
  
此方程称为
**特征方程**
，其根即为矩阵

A
A





A
的特征值。

---

**示例**

给定矩阵：
  




A
=
[
1
2
3
2
]
A = \begin{bmatrix} 1 & 2 \\ 3 & 2 \end{bmatrix}





A



=







[











1





3

​














2





2

​



]
  
其特征方程为：
  




det
⁡
[
1
−
λ
2
3
2
−
λ
]
=
(
1
−
λ
)
(
2
−
λ
)
−
6
=
0
\det\begin{bmatrix} 1 - \lambda & 2 \\ 3 & 2 - \lambda \end{bmatrix} = (1 - \lambda)(2 - \lambda) - 6 = 0





det





[











1



−



λ





3

​














2





2



−



λ

​



]



=





(

1



−





λ

)

(

2



−





λ

)



−





6



=





0
  
展开并化简：
  




λ
2
−
3
λ
−
4
=
0
  
⟹
  
λ
1
=
4
,
 
λ
2
=
−
1
\lambda^2 - 3\lambda - 4 = 0 \implies \lambda\_1 = 4,\ \lambda\_2 = -1






λ









2



−





3

λ



−





4



=





0





⟹






λ









1

​




=





4

,






λ









2

​




=





−

1

然而，对于高阶矩阵，特征值的解析解通常难以直接计算，需借助数值方法（如QR算法、幂迭代法等）进行求解。

---

## 1. 幂迭代法（Power Iteration）

**目标**
：求解矩阵的
**模最大特征值**
及其对应特征向量。

### 幂法与反幂法求解矩阵特征值

本节介绍如何使用幂法和反幂法分别求解矩阵的模最大和模最小特征值。给定矩阵

A
A





A
，假设其有

n
n





n
个实特征值：
  




∣
λ
1
∣
>
∣
λ
2
∣
>
⋯
>
∣
λ
n
∣
|λ\_1| > |λ\_2| > \cdots > |λ\_n|





∣


λ









1

​


∣



>





∣


λ









2

​


∣



>





⋯



>





∣


λ









n

​


∣
  
对应的特征向量为

u
1
,
u
2
,
…
,
u
n
u\_1, u\_2, \ldots, u\_n






u









1

​


,




u









2

​


,



…



,




u









n

​

。

---

### 幂法求最大特征值

**步骤说明：**

1. **初始向量选取：**
     
   随机选取初始向量

   x
   1
   x\_1






   x









   1

   ​

   ，可表示为特征向量的线性组合：
     




   x
   1
   =
   c
   1
   u
   1
   +
   c
   2
   u
   2
   +
   ⋯
   +
   c
   n
   u
   n
   x\_1 = c\_1u\_1 + c\_2u\_2 + \cdots + c\_nu\_n






   x









   1

   ​




   =






   c









   1

   ​



   u









   1

   ​




   +






   c









   2

   ​



   u









   2

   ​




   +





   ⋯



   +






   c









   n

   ​



   u









   n

   ​
2. **迭代计算：**

   * 第一次迭代：
       




     A
     x
     1
     =
     c
     1
     A
     u
     1
     +
     c
     2
     A
     u
     2
     +
     ⋯
     +
     c
     n
     A
     u
     n
     =
     λ
     1
     c
     1
     x
     2
     Ax\_1 = c\_1Au\_1 + c\_2Au\_2 + \cdots + c\_nAu\_n = λ\_1c\_1x\_2





     A


     x









     1

     ​




     =






     c









     1

     ​


     A


     u









     1

     ​




     +






     c









     2

     ​


     A


     u









     2

     ​




     +





     ⋯



     +






     c









     n

     ​


     A


     u









     n

     ​




     =






     λ









     1

     ​



     c









     1

     ​



     x









     2

     ​

       
     规范化后得到：
       




     x
     2
     =
     u
     1
     +
     c
     2
     c
     1
     λ
     2
     λ
     1
     u
     2
     +
     ⋯
     +
     c
     n
     c
     1
     λ
     n
     λ
     1
     u
     n
     x\_2 = u\_1 + \frac{c\_2}{c\_1} \frac{λ\_2}{λ\_1}u\_2 + \cdots + \frac{c\_n}{c\_1} \frac{λ\_n}{λ\_1}u\_n






     x









     2

     ​




     =






     u









     1

     ​




     +

















     c









     1

     ​













     c









     2

     ​


     ​














     λ









     1

     ​













     λ









     2

     ​


     ​



     u









     2

     ​




     +





     ⋯



     +

















     c









     1

     ​













     c









     n

     ​


     ​














     λ









     1

     ​













     λ









     n

     ​


     ​



     u









     n

     ​
   * 第二次迭代：
       




     A
     x
     2
     =
     λ
     1
     u
     1
     +
     c
     2
     c
     1
     λ
     2
     2
     λ
     1
     u
     2
     +
     ⋯
     +
     c
     n
     c
     1
     λ
     n
     2
     λ
     1
     u
     n
     =
     λ
     1
     x
     3
     Ax\_2 = λ\_1u\_1 + \frac{c\_2}{c\_1} \frac{λ\_2^2}{λ\_1}u\_2 + \cdots + \frac{c\_n}{c\_1} \frac{λ\_n^2}{λ\_1}u\_n = λ\_1x\_3





     A


     x









     2

     ​




     =






     λ









     1

     ​



     u









     1

     ​




     +

















     c









     1

     ​













     c









     2

     ​


     ​














     λ









     1

     ​













     λ









     2





     2

     ​


     ​



     u









     2

     ​




     +





     ⋯



     +

















     c









     1

     ​













     c









     n

     ​


     ​














     λ









     1

     ​













     λ









     n





     2

     ​


     ​



     u









     n

     ​




     =






     λ









     1

     ​



     x









     3

     ​

       
     规范化后得到：
       




     x
     3
     =
     u
     1
     +
     c
     2
     c
     1
     λ
     2
     2
     λ
     1
     2
     u
     2
     +
     ⋯
     +
     c
     n
     c
     1
     λ
     n
     2
     λ
     1
     2
     u
     n
     x\_3 = u\_1 + \frac{c\_2}{c\_1} \frac{λ\_2^2}{λ\_1^2}u\_2 + \cdots + \frac{c\_n}{c\_1} \frac{λ\_n^2}{λ\_1^2}u\_n






     x









     3

     ​




     =






     u









     1

     ​




     +

















     c









     1

     ​













     c









     2

     ​


     ​














     λ









     1





     2

     ​













     λ









     2





     2

     ​


     ​



     u









     2

     ​




     +





     ⋯



     +

















     c









     1

     ​













     c









     n

     ​


     ​














     λ









     1





     2

     ​













     λ









     n





     2

     ​


     ​



     u









     n

     ​
3. **通用迭代公式：**
     
   第

   k
   k





   k
   次迭代的通式为：
     




   x
   k
   +
   1
   =
   u
   1
   +
   c
   2
   c
   1
   λ
   2
   k
   λ
   1
   k
   u
   2
   +
   ⋯
   +
   c
   n
   c
   1
   λ
   n
   k
   λ
   1
   k
   u
   n
   x\_{k+1} = u\_1 + \frac{c\_2}{c\_1} \frac{λ\_2^k}{λ\_1^k}u\_2 + \cdots + \frac{c\_n}{c\_1} \frac{λ\_n^k}{λ\_1^k}u\_n






   x










   k

   +

   1

   ​




   =






   u









   1

   ​




   +

















   c









   1

   ​













   c









   2

   ​


   ​














   λ









   1





   k

   ​













   λ









   2





   k

   ​


   ​



   u









   2

   ​




   +





   ⋯



   +

















   c









   1

   ​













   c









   n

   ​


   ​














   λ









   1





   k

   ​













   λ









   n





   k

   ​


   ​



   u









   n

   ​
4. **收敛性分析：**
     
   由于

   ∣
   λ
   1
   ∣
   >
   ∣
   λ
   i
   ∣
    
   (
   i
   ≥
   2
   )
   |λ\_1| > |λ\_i| \, (i \geq 2)





   ∣


   λ









   1

   ​


   ∣



   >





   ∣


   λ









   i

   ​


   ∣



   (

   i



   ≥





   2

   )
   ，当

   k
   k





   k
   充分大时，高阶小项趋于零，可得：
     




   A
   x
   k
   +
   1
   ≈
   λ
   1
   u
   1
   ,
   x
   k
   +
   1
   ≈
   u
   1
   Ax\_{k+1} \approx λ\_1u\_1, \quad x\_{k+1} \approx u\_1





   A


   x










   k

   +

   1

   ​




   ≈






   λ









   1

   ​



   u









   1

   ​


   ,






   x










   k

   +

   1

   ​




   ≈






   u









   1

   ​

---

**具体实现步骤**
：

1. 随机初始化非零向量

   v
   0
   \boldsymbol{v}\_0








   v









   0

   ​

   。
2. 迭代计算：
     




   v
   k
   +
   1
   =
   A
   v
   k
   ∥
   A
   v
   k
   ∥
   \boldsymbol{v}\_{k+1} = \frac{A\boldsymbol{v}\_k}{\|A\boldsymbol{v}\_k\|}








   v










   k

   +

   1

   ​




   =
















   ∥

   A




   v









   k

   ​


   ∥











   A




   v









   k

   ​


   ​
3. 估计特征值：
     




   λ
   ≈
   v
   k
   ⊤
   A
   v
   k
   \lambda \approx \boldsymbol{v}\_k^\top A \boldsymbol{v}\_k





   λ



   ≈








   v









   k





   ⊤

   ​


   A




   v









   k

   ​

### 编程实现

具体实现时，并没有λ1和u1的值，因此，迭代计算

x
k
+
1
=
A
x
k
x\_{k+1}=Ax\_k






x










k

+

1

​




=





A


x









k

​

后，规范化

x
k
+
1
x\_{k+1}






x










k

+

1

​

即可。注意：最大特征值是指模最大的那个特征值

```matlab
% 幂法求最大特征值
clc;
clear;
close all;
% 第一种写法
A=[4 2 -2; -2 8 1 ; 2 4 -4];
x = ones(size(A));
for i=1:40
    x=A*x;
    [mx,id] = max(abs(x));
    x=x/x(id);
end
e = A*x./x;
[mx,id] = max(abs(e));
e = e(id)

eig(A)

% 第二种写法
v0 = [1;1;1];
u0 = [1;1;1];
% A = [2,-1,0;-1,2,-1;0,-1,2];
v = A * u0;
u = v / norm(v, inf);
i = 0;
while norm(u - u0, inf) >= 1e-6
    u0 = u;
    v = A * u0;
    u = v / norm(v, inf);
    i = i+1;
end
norm(v, inf)
i
u

```

### 补充说明

* **最大特征值：**
  幂法求得的是模最大的特征值

  λ
  1
  λ\_1






  λ









  1

  ​

  。

---

## 2. 逆幂迭代法（Inverse Iteration）

**目标**
：求解靠近

μ
\mu





μ
的
**最小模特征值**
。

给定矩阵 ( A )，假设其有 ( n ) 个实特征值：

∣
λ
1
∣
>
∣
λ
2
∣
>
⋯
>
∣
λ
n
∣
|\lambda\_1| > |\lambda\_2| > \cdots > |\lambda\_n|





∣


λ









1

​


∣



>





∣


λ









2

​


∣



>





⋯



>





∣


λ









n

​


∣

其对应的特征向量为(

u
1
,
u
2
u\_1, u\_2






u









1

​


,




u









2

​

,

…
,
u
n
\ldots, u\_n





…



,




u









n

​

)。(

λ
n
\lambda\_n






λ









n

​

) 是最小特征值。首先注意到如果 (

A
u
=
λ
u
Au= \lambda u





A

u



=





λ

u
)，则：

A
−
1
A
u
=
A
−
1
λ
u
  
⟹
  
u
=
A
−
1
λ
u
A^{-1}Au = A^{-1}\lambda u \implies u = A^{-1}\lambda u






A










−

1

A

u



=






A










−

1

λ

u





⟹





u



=






A










−

1

λ

u

因此有：

A
−
1
u
=
1
λ
u
A^{-1}u = \frac{1}{\lambda}u






A










−

1

u



=
















λ











1

​


u

可以看到，当

λ
n
\lambda\_n






λ









n

​

为矩阵 A 的最小特征值时，(

1
λ
n
\frac{1}{\lambda\_n}


















λ









n

​













1

​

) 将是

A
−
1
A^{-1}






A










−

1
的最大特征值。此时运用幂法求解

A
−
1
A^{-1}






A










−

1
的最大特征值，取倒数，即为 A 的最小特征值。反幂算法中需要注意的是，当最小特征值为 0 时，其倒数是没有定义的，此时反幂法求解的是第二小的特征值，且需要采用移位反幂法。

```matlab
function e = MinEig(A)
    invA = inv(A);
    x = ones(size(A));
    for i=1:40
        x=invA*x; 
        [mx,id] = max(abs(x));
        x=x/x(id);
    end
    e = invA*x./x; 
    [mx,id] = max(abs(e));
    e = 1/e(id);
end

```

### 移位反幂法

**步骤**
：

1. 对

   (
   A
   −
   μ
   I
   )
   (A - \mu I)





   (

   A



   −





   μ

   I

   )
   进行 LU 分解。
2. 随机初始化向量

   v
   0
   \boldsymbol{v}\_0








   v









   0

   ​

   。
3. 迭代求解：
     




   (
   A
   −
   μ
   I
   )
   v
   k
   +
   1
   =
   v
   k
   ⇒
   v
   k
   +
   1
   =
   v
   k
   +
   1
   ∥
   v
   k
   +
   1
   ∥
   (A - \mu I)\boldsymbol{v}\_{k+1} = \boldsymbol{v}\_k \quad \Rightarrow \quad \boldsymbol{v}\_{k+1} = \frac{\boldsymbol{v}\_{k+1}}{\|\boldsymbol{v}\_{k+1}\|}





   (

   A



   −





   μ

   I

   )




   v










   k

   +

   1

   ​




   =








   v









   k

   ​






   ⇒








   v










   k

   +

   1

   ​




   =
















   ∥




   v










   k

   +

   1

   ​


   ∥














   v










   k

   +

   1

   ​


   ​

```matlab
A = [3,0,-10;-1,3,4;0,1,-2];
I = eye(3,3);
p = 4.3;
u0 = [1;1;1];
v = inv(A - p * I) * u0;
u = v / norm(v, inf);
i = 0;
while norm(u - u0, inf) > 1e-5
    u0 = u;
    v = inv(A - p * I) * u0;
    u = v / norm(v, inf);
    i ++;
end;
i
u
x = p + 1 / norm(v, inf)

```

**综述所述，可以总结反幂法求解特征向量的特点如下：**

**位移技术：**
对每个已求得的特征值

λ
i
\lambda\_i






λ









i

​

，构造矩阵

A
0
−
λ
i
I
A\_0-\lambda\_iI






A









0

​




−






λ









i

​


I
，使其接近奇异；

**加速收敛：**
反幂法迭代公式为

x
k
+
1
=
(
A
−
σ
I
)
−
1
x
k
x\_{k+1}=(A-\sigma I)^{-1}x\_k






x










k

+

1

​




=





(

A



−





σ

I


)










−

1


x









k

​

，其中

σ
\sigma





σ
接近特征值。此时

(
A
−
σ
I
)
−
1
(A-\sigma I)^{-1}





(

A



−





σ

I


)










−

1
的模最大特征值对应的特征向量即为A的

σ
\sigma





σ
附近特征值的特征向量。

**高精度优势：**
当

λ
i
\lambda\_i






λ









i

​

精度较高时，反幂法可以在少量迭代内快速收敛到对应特征向量。

---

## 3. QR 算法（QR Algorithm）——稠密矩阵

**目标**
：求解
**所有特征值**
（稠密矩阵）。
  
**步骤**
：

1. 将

   A
   A





   A
   转化为上 Hessenberg 矩阵。
2. 迭代 QR 分解：
     




   A
   k
   =
   Q
   k
   R
   k
   ,
   A
   k
   +
   1
   =
   R
   k
   Q
   k
   A\_k = Q\_k R\_k, \quad A\_{k+1} = R\_k Q\_k






   A









   k

   ​




   =






   Q









   k

   ​



   R









   k

   ​


   ,






   A










   k

   +

   1

   ​




   =






   R









   k

   ​



   Q









   k

   ​
3. 当

   A
   k
   A\_k






   A









   k

   ​

   收敛为上三角矩阵时，对角线元素即为特征值。

### 理论推导

幂法与反幂法用于求解矩阵的最大特征值与最小特征值。若想求解矩阵的所有特征值，可以使用
**QR分解法**
。假设矩阵 A 是

n
×
n
n \times n





n



×





n
的方阵，且其 n 个特征值均为互不相同的实数。QR分解法的理论保证如下：

若对矩阵 A 进行相似变换

B
=
C
−
1
A
C
B = C^{-1}AC





B



=






C










−

1

A

C
，则变换后的矩阵 B 的特征值与 A 一致。这是因为：
  
若

A
u
=
λ
u
Au = \lambda u





A

u



=





λ

u
，令

v
=
C
−
1
u
v = C^{-1}u





v



=






C










−

1

u
，则有
  




A
C
v
=
A
u
=
λ
C
v
ACv = Au = \lambda Cv





A

C

v



=





A

u



=





λ

C

v
  
进一步可得
  




C
−
1
A
C
v
=
λ
v
C^{-1}ACv = \lambda v






C










−

1

A

C

v



=





λ

v
  
因此，

λ
\lambda





λ
也是

C
−
1
A
C
C^{-1}AC






C










−

1

A

C
的特征值。

**据此，可以通过以下步骤实现特征值和特征向量的求解：**

1. **初始化**

   * 令 ( A\_1 = A )，并对 ( A\_1 ) 进行QR分解：
       




     A
     1
     =
     Q
     1
     R
     1
     A\_1 = Q\_1R\_1






     A









     1

     ​




     =






     Q









     1

     ​



     R









     1

     ​

       
     其中，( Q\_1 ) 是正交矩阵（满足 ( Q\_1Q\_1^T = I )），( R\_1 ) 是上三角矩阵。
2. **迭代生成新矩阵**

   * 计算 ( A\_2 = R\_1Q\_1 )，即：
       




     A
     2
     =
     Q
     1
     −
     1
     A
     1
     Q
     1
     A\_2 = Q\_1^{-1}A\_1Q\_1






     A









     2

     ​




     =






     Q









     1






     −

     1

     ​



     A









     1

     ​



     Q









     1

     ​

       
     此时 ( A\_2 ) 的特征值与 ( A ) 一致。继续对 ( A\_2 ) 进行QR分解：
       




     A
     2
     =
     Q
     2
     R
     2
     A\_2 = Q\_2R\_2






     A









     2

     ​




     =






     Q









     2

     ​



     R









     2

     ​
3. **重复迭代**

   * 计算 ( A\_3 = R\_2Q\_2 )，即：
       




     A
     3
     =
     Q
     2
     −
     1
     A
     2
     Q
     2
     =
     Q
     2
     −
     1
     Q
     1
     −
     1
     A
     1
     Q
     1
     Q
     2
     A\_3 = Q\_2^{-1}A\_2Q\_2 = Q\_2^{-1}Q\_1^{-1}A\_1Q\_1Q\_2






     A









     3

     ​




     =






     Q









     2






     −

     1

     ​



     A









     2

     ​



     Q









     2

     ​




     =






     Q









     2






     −

     1

     ​



     Q









     1






     −

     1

     ​



     A









     1

     ​



     Q









     1

     ​



     Q









     2

     ​
4. **终止条件**

   * 重复上述步骤，直至 ( A\_n ) 收敛为一个上三角矩阵。此时，矩阵对角线上的元素即为 ( A ) 的所有特征值。

**注**
：QR分解通过不断迭代将原矩阵相似变换为上三角矩阵，从而直接读取对角线元素作为特征值。此方法适用于实对称矩阵或具有实特征值的方阵。

### 编程实现

```matlab
A=[ 6 -7 2 ; 4 -5 2; 1 -1 1]
A0=A;
for i=1:40
    [Q R]=qr(A);
    A=R*Q;
end
A
ev=diag(A)
eig(A0)

```

**特点**
：

* 复杂度

  O
  (
  n
  3
  )
  O(n^3)





  O

  (


  n









  3

  )
  ，LAPACK 的核心算法。
* 结合位移（如 Wilkinson 位移）优化收敛。

**‌特征值修正‌**
  
QR方法得到的特征值可能存在微小误差，反幂法可进一步修正

```matlab
A=[ 6 -7 2 ; 4 -5 2; 1 -1 1]
A0=A;
for i=1:40
    [Q R]=qr(A);
    A=R*Q;
end
A
ev=diag(A)
Q
eig(A0)

% 使用反幂法求特征向量，并对特征值进行修正
a = ev;
n = size(a,1);
x = zeros(n);
for i = 1:n
    x0 = ones(n,1);
    [b,x0] = MinEig(A0-a(i,1)*eye(n));
    x(:,i) = x0;
    a(i,:) = a(i,:) + b;
end

a
x

```

---

## 4. 雅可比方法（Jacobi Method）——对称矩阵

**目标**
：求解
**对称矩阵**
的所有特征值和特征向量。

Jacobi方法的基本思想是通过一次正交变换,将A中的一对非零的非对角元素化成零并且使得非对角元素的平方和减小。反复进行上述过程,使变换后的矩阵的非对角元素的平方和趋于零，从而使该矩阵近似为对角矩阵，得到全部特征值和特征向量。

**步骤**
：

1. 通过 Givens 旋转矩阵

   G
   k
   G\_k






   G









   k

   ​

   逐步对角化：
     




   A
   k
   +
   1
   =
   G
   k
   ⊤
   A
   k
   G
   k
   A\_{k+1} = G\_k^\top A\_k G\_k






   A










   k

   +

   1

   ​




   =






   G









   k





   ⊤

   ​



   A









   k

   ​



   G









   k

   ​
2. 重复直到非对角元素接近零。

**特点**
：

* 稳定但收敛慢，特征向量通过旋转矩阵累积。

### 编程实现

```matlab
function [D,V,iter]=Jacobi_classical(A,maxIter,tol)
n = size(A, 1); % 矩阵的大小
V = eye(n); % 初始化特征向量矩阵为单位矩阵
iter = 0; % 初始化迭代次数
% 设置最大迭代次数和误差精度
if nargin < 3 || isempty(tol)
    tol = 1e-9; % 默认误差精度
end
if nargin < 2 || isempty(maxIter)
    maxIter = 1000; % 默认最大迭代次数
end
while(iter < maxIter)
    iter=iter+1;
    D=A;
    n=size(D,1);
    p=1;q=2;
    for i=1:n
        for j=i+1:n
            if(abs(D(i,j))>abs(D(p,q)))%找到对称矩阵的上三角矩阵中最大的元素的下标
                p=i;q=j;
            end
        end
    end
    if(abs(D(p,q))<tol)
        break;
    end
    if(A(p,q)~=0)
        d=(A(q,q)-A(p,p))/(2*A(p,q));
        if(d>0)
            t=1/(d+sqrt(d^2+1));
        else
            t=-1/(-d+sqrt(d^2+1));
        end
        c=1/sqrt(t^2+1);s=c*t;
    else
        c=1;s=0;
    end
    R=[c s;-s c];
    A([p,q],:)=R'*A([p,q],:);
    A(:,[p,q])=A(:,[p,q])*R;
    V(:, [p, q]) = V(:,[p,q])*R;
end
D = diag(diag(D));  % 提取特征值
end

```

结果测试：

```matlab
clc;
clear;
close all;

A=[ 6 -7 2 ; 4 -5 2; 1 -1 1]
[D, V, iter] = Jacobi_classical(A, 2000)
eig(A)

```

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3ae1c339d9ee490ba07363751ae70a1e.png)

---

## 5. Lanczos 算法（稀疏矩阵）

**目标**
：求解稀疏矩阵的
**部分极端特征值**
。
  
**步骤**
：

1. 生成 Krylov 子空间的正交基底。
2. 投影到三对角矩阵

   T
   k
   T\_k






   T









   k

   ​

   ：
     




   T
   k
   =
   V
   k
   ⊤
   A
   V
   k
   T\_k = V\_k^\top A V\_k






   T









   k

   ​




   =






   V









   k





   ⊤

   ​


   A


   V









   k

   ​
3. 对

   T
   k
   T\_k






   T









   k

   ​

   应用 QR 算法求特征值。
     
   **特点**
   ：

* 仅需矩阵-向量乘法，适合大规模稀疏矩阵。

---

## 6. 分治法

**目标**
：高效求解对称三对角矩阵的所有特征值。
  
**步骤**
：

1. 将矩阵分解为子矩阵。
2. 递归求解子矩阵特征值。
3. 合并子问题解并修正。

**特点**
：

* 复杂度

  O
  (
  n
  2
  )
  O(n^2)





  O

  (


  n









  2

  )
  ，适合大规模三对角矩阵。

---

## 7. 方法选择指南

| **场景** | **推荐方法** |
| --- | --- |
| 中小规模稠密矩阵 | QR 算法 |
| 对称矩阵 | Jacobi 或 QR 算法 |
| 稀疏矩阵的极端特征值 | Lanczos/Arnoldi 迭代 |
| 最小/靠近  μ \mu      μ 的特征值 | 逆幂迭代法 + 位移 |
| 工程问题中的部分特征值 | 子空间迭代法 |

---

## 8. 关键公式与说明

**特征方程**
  
矩阵

A
A





A
的特征值满足：
  




det
⁡
(
A
−
λ
I
)
=
0
\det(A - \lambda I) = 0





det

(

A



−





λ

I

)



=





0

* **2x2 矩阵**
  ：
    




  λ
  2
  −
  tr
  (
  A
  )
  λ
  +
  det
  ⁡
  (
  A
  )
  =
  0
  \lambda^2 - \text{tr}(A)\lambda + \det(A) = 0






  λ









  2



  −






  tr

  (

  A

  )

  λ



  +





  det

  (

  A

  )



  =





  0
* **n 阶矩阵**
  ：
    




  P
  (
  λ
  )
  =
  (
  −
  1
  )
  n
  λ
  n
  +
  ⋯
  +
  det
  ⁡
  (
  A
  )
  P(\lambda) = (-1)^n \lambda^n + \dots + \det(A)





  P

  (

  λ

  )



  =





  (

  −

  1


  )









  n


  λ









  n



  +





  ⋯



  +





  det

  (

  A

  )

---

**提示**
：

* 高阶矩阵避免解析法，优先使用数值库（如 LAPACK、ARPACK）。
* 对称矩阵的特征向量可正交化，提升计算稳定性。

## 参考文献

[1] \*
[数值计算day5-特征值与特征向量](https://blog.csdn.net/weixin_30278311/article/details/101085268)
  
[2]
[数值计算方法 Chapter7. 计算矩阵的特征值和特征向量](https://blog.csdn.net/codename_cys/article/details/125360615)
  
[3]
[数值线性代数：Arnoldi求解特征值/特征向量](https://blog.csdn.net/qq_26221775/article/details/131690666)
  
[4]
[使用Matlab实现：幂法、反幂法(原点位移)](https://blog.csdn.net/yancr/article/details/84640974/)
  
[5]
[MATLAB求解矩阵特征值的六种方法](https://blog.csdn.net/weixin_47567401/article/details/113648113)