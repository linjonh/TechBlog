---
arturl_encode: "68747470733a2f2f626c6f67:2e6373646e2e6e65742f73696e61745f32363830393235352f:61727469636c652f64657461696c732f313436303939383732"
layout: post
title: "openstack搭建openstack云平台部署-详细完整教程"
date: 2025-03-07 16:51:40 +08:00
description: "openstack云平台部署（完整教程）环境要求Openstack硬件环境：Vmware虚拟机3台，控制节点配置需求4C8G20G，计算节点2C4G20GOpenstack网络要求：至少一套网络，使用Vmware虚拟机的网络即可操作系统要求：centos7*即可，openstack开源版本均支持大部分开源操作系统，centos、ubnutu、suse等等，centos7操作系统的安装详见操作系统安装文档。本指南中使用的ip控制节点：controller:192.168.44.3。"
keywords: "（openstack搭建）openstack云平台部署-详细完整教程"
categories: ['未分类']
tags: ['Openstack']
artid: "146099872"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146099872
    alt: "openstack搭建openstack云平台部署-详细完整教程"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146099872
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146099872
cover: https://bing.ee123.net/img/rand?artid=146099872
image: https://bing.ee123.net/img/rand?artid=146099872
img: https://bing.ee123.net/img/rand?artid=146099872
---

# （openstack搭建）openstack云平台部署-详细完整教程

openstack云平台部署（完整教程）
  
环境要求
  
Openstack硬件环境：Vmware虚拟机3台，控制节点配置需求4C8G20G，计算节点2C4G20G

Openstack网络要求：至少一套网络，使用Vmware虚拟机的网络即可

操作系统要求：centos7\*即可，openstack开源版本均支持大部分开源操作系统，centos、ubnutu、suse等等，centos7操作系统的安装详见操作系统安装文档。
  
本指南中使用的ip
  
控制节点：controller:192.168.44.3
  
计算节点：compute1:192.168.44.4
  
compute2:192.168.44.5

一、安装openstack前的前置操作(以下3台虚拟机均同样操作)：
  
1 关闭防火墙

systemctl stop firewalld && systemctl disable firewalld

2 关闭selinux

1、vim /etc/selinux/config
  
SELINUX=enforcing #把enforcing改为disabled
  
2、setenforce 0
  
3、reboot #重新启动让其生效

3、hostname机hosts配置

[root@localhost ~]hostnamectl set-hostname --pretty controller
  
[root@localhost ~]hostnamectl set-hostname --static controller
  
[root@localhost ~]hostnamectl set-hostname --transient controller

[root@localhost ~]vi /etc/hosts

192.168.44.3 controller
  
192.168.44.4 compute1
  
192.168.44.5 compute2

4、安装openstack及ceph的yum源
  
能连接外网的情况下：
  
下载安装openstack存储库：

yum install centos-release-openstack-train

安装后会自行在源配置路径/etc/yum.repo.d/下生成配置文件，之后加载即可使用

yum clean all && yum makecache

如果虚拟机无法上网的话，需要去
  
http://mirror.centos.org/centos-7/7.9.2009/cloud/x86\_64/openstack-train/上拿取源包，放到虚拟机上配置本地源使用
  
5. 配置时间同步ntpd

[root@controller ~]yum -y install ntp\*
  
[root@controller ~]systemctl start ntpd
  
[root@controller ~]systemctl enable ntpd
  
[root@controller ~]ntpdate ntp1.aliyun.com

二、安装openstack总体步骤
  
安装rabbitmq
  
安装etcd
  
安装memcached
  
安装MySQL
  
安装keystone
  
操作系统环境变量配置
  
安装glance
  
安装placement
  
安装nova
  
计算节点nova
  
安装neutron
  
计算节点neutron
  
安装dashboard
  
安装 cinder
  
计算节点cinder

1.Rabbitmq:安装：

yum install rabbitmq-server -y

启动并配置为自动启动

systemctl enable rabbitmq-server.service
  
systemctl start rabbitmq-server.service

在rabbitmq中添加openstack用户：

[root@controller ~]rabbitmqctl add\_user openstack RABBIT\_PASS #RABBIT\_PASS换成合适的密码
  
Creating user “openstack” …

配置改用户的权限

rabbitmqctl set\_permissions openstack “.
*" ".*
” “.\*”
  
Setting permissions for user “openstack” in vhost “/” …

开启管理界面插件：

rabbitmq-plugins enable rabbitmq\_management

openstack部署成功后可以登录rabbitmq web管理界面：http://192.168.44.3:15672 如出现无法访问情况 检查端口：
  
netstat -anlp | grep 15672 如果还无法访问，手动添加安全组规则 端口15672 5672，然后重启服务
  
输入用户名:guest 密码:guest，点击login就可以登录

另，安装openstack客户端：

yum install python-openstackclient openstack-selinux -y

2.Etcd
  
安装：

yum install etcd -y

编辑配置文件：

vi /etc/etcd/etcd.conf

#[Member]
  
ETCD\_DATA\_DIR=“/var/lib/etcd/default.etcd”
  
ETCD\_LISTEN\_PEER\_URLS=“http://192.168.44.3:2380”
  
ETCD\_LISTEN\_CLIENT\_URLS=“http://192.168.44.3:2379”
  
ETCD\_NAME=“controller”
  
#[Clustering]
  
ETCD\_INITIAL\_ADVERTISE\_PEER\_URLS=“http://192.168.44.3:2380”
  
ETCD\_ADVERTISE\_CLIENT\_URLS=“http://192.168.44.3:2379”
  
ETCD\_INITIAL\_CLUSTER=“controller=http://192.168.44.3:2380”
  
ETCD\_INITIAL\_CLUSTER\_TOKEN=“etcd-cluster”
  
ETCD\_INITIAL\_CLUSTER\_STATE=“new”

启动etcd

systemctl enable etcd
  
systemctl start etcd

3.Memcached

yum install memcached python-memcached -y

编辑配置文件/etc/sysconfig/memcached ，在最后添加上控制节点的主机名:

vi /etc/sysconfig/memcached

OPTIONS=“-l 127.0.0.1,::1,controller”

启动

systemctl enable memcached.service
  
systemctl start memcached.service

4.MySQL

yum install mariadb mariadb-server python2-PyMySQL -y

创建和编辑/etc/my.cnf.d/openstack.cnf /etc/my.cnf.d/文件（如果需要，备份现有的配置文件）并完成以下操作：
  
创建一个[mysqld]section，设置bind-address key为controller节点的管理IP地址，允许其他节点通过管理网络访问。设置附加键以启用有用的选项和 UTF-8 字符集：

vi /etc/my.cnf.d/openstack.cnf

[mysqld]
  
bind-address = 192.168.44.3

default-storage-engine = innodb
  
innodb\_file\_per\_table = on
  
max\_connections = 4096
  
collation-server = utf8\_general\_ci
  
character-set-server = utf8

完成安装
  
启动数据库服务并配置它在系统启动时启动：

systemctl enable mariadb.service
  
systemctl start mariadb.service

初始化数据库并设置密码(123456)

mysql\_secure\_installation
  
5.Keystone
  
安装mariadb数据库

mysql -u root -p

创建keystone数据库：

MariaDB [(none)]> CREATE DATABASE keystone;

授予对keystone数据库的适当访问权限：

MariaDB [(none)]> GRANT ALL PRIVILEGES ON keystone.\* TO ‘keystone’@‘localhost’ IDENTIFIED BY ‘KEYSTONE\_DBPASS’;
  
MariaDB [(none)]> GRANT ALL PRIVILEGES ON keystone.\* TO ‘keystone’@‘%’ IDENTIFIED BY ‘KEYSTONE\_DBPASS’;
  
#（用合适的密码替换 KEYSTONE\_DBPASS ）
  
GRANT ALL PRIVILEGES ON keystone.\* TO ‘keystone’@‘localhost’ IDENTIFIED BY ‘123456’;
  
GRANT ALL PRIVILEGES ON keystone.\* TO ‘keystone’@‘%’ IDENTIFIED BY ‘123456’;
  
安装keystone

yum install openstack-keystone httpd mod\_wsgi -y

编辑/etc/keystone/keystone.conf文件并完成以下操作：
  
在该[database]部分中，配置数据库访问：

vim /etc/keystone/keystone.conf

[database]
  
connection = mysql+pymysql://keystone:KEYSTONE\_DBPASS@controller/keystone
  
#替换KEYSTONE\_DBPASS为您为数据库选择的密码。
  
#注释掉或删除connection该[database]部分中的任何其他选项 。
  
#在[token]部分中，配置 Fernet 令牌提供程序：
  
[token]
  
provider = fernet

填充身份服务数据库：

su -s /bin/sh -c “keystone-manage db\_sync” keystone

初始化 Fernet 密钥库：

在–keystone-user和–keystone-group标志用于指定将用于运行keystone操作系统的用户/组。提供这些是为了允许在另一个操作系统用户/组下运行
  
keystone。在下面的示例中，我们调用 user & group keystone。

keystone-manage fernet\_setup --keystone-user keystone --keystone-group keystone
  
keystone-manage credential\_setup --keystone-user keystone --keystone-group keystone

引导身份服务：

keystone-manage bootstrap --bootstrap-password ADMIN\_PASS
  
–bootstrap-admin-url http://controller:5000/v3/
  
–bootstrap-internal-url http://controller:5000/v3/
  
–bootstrap-public-url http://controller:5000/v3/
  
–bootstrap-region-id RegionOne
  
#替换ADMIN\_PASS为适合管理用户的密码。

配置 Apache HTTP 服务器
  
编辑/etc/httpd/conf/httpd.conf文件并配置 ServerName选项以引用控制器节点：

vim etc/httpd/conf/httpd.conf

ServerName controller

如果该ServerName条目尚不存在，则需要添加该条目。

创建/usr/share/keystone/wsgi-keystone.conf文件链接：

vim usr/share/keystone/wsgi-keystone.conf

ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/

启动 Apache HTTP 服务并配置它在系统启动时启动：

systemctl enable httpd.service
  
systemctl start httpd.service

通过设置适当的环境变量来配置管理帐户：

export OS\_USERNAME=admin
  
export OS\_PASSWORD=ADMIN\_PASS
  
export OS\_PROJECT\_NAME=admin
  
export OS\_USER\_DOMAIN\_NAME=Default
  
export OS\_PROJECT\_DOMAIN\_NAME=Default
  
export OS\_AUTH\_URL=http://controller:5000/v3
  
export OS\_IDENTITY\_API\_VERSION=3

创建域、项目、用户和角色
  
1.尽管本指南中的keystone-manage 引导步骤中已经存在“默认”域，但创建新域的正式方法是：

openstack domain create --description “An Example Domain” example

2.本指南使用一个服务项目，其中包含每个用户的唯一用户 添加到环境中的服务。创建项目：service

openstack project create --domain default --description “Service Project” service

3.常规（非管理员）任务应使用非特权项目和用户。例如，本指南创建myproject项目和myuser 用户。
  
创建myproject项目：

openstack project create --domain default --description “Demo Project” myproject

为该项目创建其他用户时不要重复此步骤。
  
创建myuser用户：

openstack user create --domain default --password-prompt myuser

创建myrole角色：

openstack role create myrole

将myrole角色添加到myproject项目和myuser用户：

$ openstack role add --project myproject --user myuser myrole
  
1
  
创建 OpenStack 客户端环境脚本
  
为 和 项目和用户创建客户端环境脚本。本指南的后续部分将参考这些内容 用于为客户端操作加载相应凭据的脚本。
  
1.创建并编辑文件并添加以下内容：admin-openrc

$ vi admin-openrc

export OS\_PROJECT\_DOMAIN\_NAME=Default
  
export OS\_USER\_DOMAIN\_NAME=Default
  
export OS\_PROJECT\_NAME=admin
  
export OS\_USERNAME=admin
  
export OS\_PASSWORD=ADMIN\_PASS
  
export OS\_AUTH\_URL=http://controller:5000/v3
  
export OS\_IDENTITY\_API\_VERSION=3
  
export OS\_IMAGE\_API\_VERSION=2
  
#替换为您选择的密码 对于标识服务中的用户。ADMIN\_PASS admin

2.创建并编辑文件并添加以下内容：demo-openrc

$ vi demo-openrc

export OS\_PROJECT\_DOMAIN\_NAME=Default
  
export OS\_USER\_DOMAIN\_NAME=Default
  
export OS\_PROJECT\_NAME=myproject
  
export OS\_USERNAME=myuser
  
export OS\_PASSWORD=DEMO\_PASS
  
export OS\_AUTH\_URL=http://controller:5000/v3
  
export OS\_IDENTITY\_API\_VERSION=3
  
export OS\_IMAGE\_API\_VERSION=2
  
#替换为您选择的密码 对于标识服务中的用户。DEMO\_PASS videmo
  
使用脚本
  
要以特定项目和用户身份运行客户端，只需加载即可 运行它们之前的关联客户端环境脚本。 例如：
  
加载文件以填充 具有标识服务位置的环境变量 以及项目和用户凭据：admin-openrc

$ sh admin-openrc

请求身份验证令牌：

openstack token issue

6.操作系统环境配置
  
sysctl.conf文件配置：

vi /etc/sysctl.conf

net.ipv4.tcp\_syncookies = 1
  
net.ipv4.tcp\_tw\_reuse = 1
  
net.ipv4.tcp\_tw\_recycle = 1
  
net.ipv4.tcp\_fin\_timeout = 30
  
net.ipv4.tcp\_keepalive\_time = 1200
  
net.ipv4.tcp\_keepalive\_intvl = 2
  
net.ipv4.tcp\_keepalive\_probes = 1
  
#net.ipv4.ip\_local\_port\_range = 10000 65000
  
net.ipv4.tcp\_max\_syn\_backlog = 8192
  
net.ipv4.tcp\_max\_tw\_buckets = 5000
  
net.ipv4.tcp\_synack\_retries = 2
  
net.ipv4.neigh.default.gc\_stale\_time=120
  
net.ipv4.conf.all.rp\_filter=0
  
net.ipv4.conf.default.rp\_filter=0
  
net.ipv4.conf.default.arp\_announce = 2
  
net.ipv4.conf.lo.arp\_announce=2
  
net.ipv4.conf.all.arp\_announce=2
  
net.ipv4.ip\_forward = 1

net.ipv6.conf.all.disable\_ipv6 = 0
  
net.ipv6.conf.default.disable\_ipv6 = 0
  
net.ipv6.conf.lo.disable\_ipv6 = 0

net.core.somaxconn=8192

vm.swappiness = 0

/etc/sudoers文件配置：

cepher ALL=(ALL) NOPASSWD: ALL
  
nova ALL=(ALL) NOPASSWD: ALL
  
neutron ALL=(ALL) NOPASSWD: ALL
  
ceilometer ALL = (root) NOPASSWD: /usr/bin/ceilometer-rootwrap /etc/ceilometer/rootwrap.conf \*

/etc/security/limits.conf文件配置(end前)：

* soft nofile 65530
* hard nofile 65530
* + memlock unlimited
* + nofile 100000
* + nproc 32768
* + as unlimited
      
    /etc/systemd/system.conf #资源限制连接数

DefaultLimitNOFILE=20480
  
DefaultLimitNPROC=20480

上面这些配置完后要重启才能生效

7.Glance
  
在安装和配置 Image 服务之前，您必须创建数据库、服务凭证和 API 端点。
  
1.要创建数据库，请完成以下步骤：
  
使用数据库访问客户端以root用户身份连接数据库服务器：

mysql -u root -p

创建glance数据库：

MariaDB [(none)]> CREATE DATABASE glance;

授予对glance数据库的适当访问权限：

MariaDB [(none)]> GRANT ALL PRIVILEGES ON glance.\* TO ‘glance’@‘localhost’ IDENTIFIED BY ‘GLANCE\_DBPASS’;
  
MariaDB [(none)]> GRANT ALL PRIVILEGES ON glance.\* TO ‘glance’@‘%’ IDENTIFIED BY ‘GLANCE\_DBPASS’;

替换GLANCE\_DBPASS为合适的密码。

退出数据库访问客户端。

2.来源admin凭据来访问仅管理员CLI命令：

sh admin-openrc

报错处理source admin-openrc

3.要创建服务凭证，请完成以下步骤：
  
创建glance用户：

openstack user create --domain default --password-prompt glance

将admin角色添加到glance用户和 service项目：

openstack role add --project service --user glance admin

创建glance服务实体：

openstack service create --name glance --description “OpenStack Image” image

创建镜像服务 API 端点：

$ openstack endpoint create --region RegionOne image public http://controller:9292
  
$ openstack endpoint create --region RegionOne image internal http://controller:9292
  
$ openstack endpoint create --region RegionOne image admin http://controller:9292

安装和配置组件
  
安装软件包：

yum install openstack-glance -y

编辑/etc/glance/glance-api.conf文件并完成以下操作：
  
在该[database]部分中，配置数据库访问：
  
#vi /etc/glance/glance-api.conf

[database]

## …

connection = mysql+pymysql://glance:GLANCE\_DBPASS@controller/glance

替换GLANCE\_DBPASS为您为Glance:服务数据库选择的密码。

在[keystone\_authtoken]和[paste\_deploy]部分，配置身份服务访问：

[keystone\_authtoken]
  
…
  
www\_authenticate\_uri = http://controller:5000
  
auth\_url = http://controller:5000
  
memcached\_servers = controller:11211
  
auth\_type = password
  
project\_domain\_name = Default
  
user\_domain\_name = Default
  
project\_name = service
  
username = glance
  
password = GLANCE\_PASS

[paste\_deploy]
  
…
  
flavor = keystone

替换GLANCE\_PASS为您glance在身份服务中为用户选择的密码 。

在该[glance\_store]部分中，配置本地文件系统存储和镜像文件的位置：

[glance\_store]

## …

stores = file,http
  
default\_store = file
  
filesystem\_store\_datadir = /var/lib/glance/images

填充glance服务数据库：

su -s /bin/sh -c “glance-manage db\_sync” glance

编辑/etc/glance/glance-registry.conf文件并完成以下操作：

在该[database]部分中，配置数据库访问：

[database]

#…
  
connection = mysql+pymysql://glance:GLANCE\_DBPASS@controller/glance

替换GLANCE\_DBPASS为您为Glance服务数据库选择的密码。

在[keystone\_authtoken]和[paste\_deploy]部分，配置身份服务访问：

[keystone\_authtoken]
  
#…
  
www\_authenticate\_uri = http://controller:5000
  
auth\_url = http://controller:5000
  
memcached\_servers = controller:11211
  
auth\_type = password
  
project\_domain\_name = Default
  
user\_domain\_name = Default
  
project\_name = service
  
username = glance
  
password = GLANCE\_PASS

[paste\_deploy]
  
…
  
flavor = keystone

替换GLANCE\_PASS为您glance在身份服务中为用户选择的密码 。
  
完成安装
  
启动 Image 服务并将它们配置为在系统启动时启动：

systemctl enable openstack-glance-api.service
  
systemctl start openstack-glance-api.service

8.placement
  
1.创建数据库
  
要创建数据库，请完成以下步骤：
  
使用数据库访问客户端以root用户身份连接数据库服务器：

$ mysql -u root -p
  
创建placement数据库：

MariaDB [(none)]> CREATE DATABASE placement;

授予对数据库的适当访问权限：

MariaDB [(none)]> GRANT ALL PRIVILEGES ON placement.\* TO ‘placement’@‘localhost’ IDENTIFIED BY ‘PLACEMENT\_DBPASS’;
  
MariaDB [(none)]> GRANT ALL PRIVILEGES ON placement.\* TO ‘placement’@‘%’ IDENTIFIED BY ‘PLACEMENT\_DBPASS’;

替换PLACEMENT\_DBPASS为合适的密码。

退出数据库访问客户端。

2.配置用户和端点
  
来源admin凭据来访问仅管理员CLI命令：

$ . admin-openrc

使用您选择的创建一个安置服务用户PLACEMENT\_PASS：

$ openstack user create --domain default --password-prompt placement

3.将 Placement 用户添加到具有 admin 角色的服务项目：

$ openstack role add --project service --user placement admin

4.在服务目录中创建 Placement API 条目：

$ openstack service create --name placement
  
–description “Placement API” placement

5.创建 Placement API 服务端点：
  
（根据环境，端点的 URL 会因端口（可能是 8780 而不是 8778，或者根本没有端口）和主机名而异。确定正确的 URL。）

$ openstack endpoint create --region RegionOne
  
placement public http://controller:8778
  
$ openstack endpoint create --region RegionOne
  
placement internal http://controller:8778
  
$ openstack endpoint create --region RegionOne
  
placement admin http://controller:8778

安装和配置组件
  
1.安装软件包：

yum install openstack-placement-api -y

2.编辑/etc/placement/placement.conf文件并完成以下操作：
  
#vi /etc/placement/placement.conf

在该[placement\_database]部分中，配置数据库访问：

[placement\_database]

## …

connection = mysql+pymysql://placement:PLACEMENT\_DBPASS@controller/placement

替换PLACEMENT\_DBPASS为您为展示位置数据库选择的密码。

在[api]和[keystone\_authtoken]部分，配置身份服务访问：

[api]
  
…
  
auth\_strategy = keystone

[keystone\_authtoken]
  
#…
  
auth\_url = http://controller:5000/v3
  
memcached\_servers = controller:11211
  
auth\_type = password
  
project\_domain\_name = Default
  
user\_domain\_name = Default
  
project\_name = service
  
username = placement
  
password = PLACEMENT\_PASS

替换PLACEMENT\_PASS为您placement在身份服务中为用户选择的密码 。

笔记 注释掉或删除该[keystone\_authtoken] 部分中的任何其他选项。
  
、的值user\_name，password，project\_domain\_name并
  
user\_domain\_name需要在你的keystone配置同步。

3.填充placement数据库：

su -s /bin/sh -c “placement-manage db sync” placement

完成安装
  
4.重启httpd服务：

systemctl restart httpd

9.nova控制节点
  
1.使用数据库访问客户端以root用户身份连接数据库服务器：

$ mysql -u root -p

创建nova\_api，nova和nova\_cell0数据库：

MariaDB [(none)]> CREATE DATABASE nova\_api;
  
MariaDB [(none)]> CREATE DATABASE nova;
  
MariaDB [(none)]> CREATE DATABASE nova\_cell0;
  
授予对数据库的适当访问权限：

MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova\_api.\* TO ‘nova’@‘localhost’
  
IDENTIFIED BY ‘123456’;
  
MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova\_api.\* TO ‘nova’@‘%’
  
IDENTIFIED BY ‘123456’;

MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova.\* TO ‘nova’@‘localhost’
  
IDENTIFIED BY ‘123456’;
  
MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova.\* TO ‘nova’@‘%’
  
IDENTIFIED BY ‘123456’;

MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova\_cell0.\* TO ‘nova’@‘localhost’
  
IDENTIFIED BY ‘123456’;
  
MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova\_cell0.\* TO ‘nova’@‘%’
  
IDENTIFIED BY ‘123456’;

替换NOVA\_DBPASS为合适的密码。（这里设置的是123456）

数据库访问客户端。

2.来源admin凭据来访问仅管理员CLI命令：

$ . admin-openrc

3.创建计算服务凭证：
  
创建nova用户：

$ openstack user create --domain default --password-prompt nova

admin为nova用户添加角色：

$ openstack role add --project service --user nova admin

此命令不提供任何输出。

创建nova服务实体：

$ openstack service create --name nova
  
–description “OpenStack Compute” compute

4.创建 Compute API 服务端点：

$ openstack endpoint create --region RegionOne
  
compute public http://controller:8774/v2.1

$ openstack endpoint create --region RegionOne
  
compute internal http://controller:8774/v2.1

$ openstack endpoint create --region RegionOne
  
compute admin http://controller:8774/v2.1

安装和配置组件
  
1.安装软件包：

yum install openstack-nova-api openstack-nova-conductor
  
openstack-nova-novncproxy openstack-nova-scheduler libvirt -y

2.编辑/etc/nova/nova.conf文件并完成以下操作：
  
#vi /etc/nova/nova.conf
  
在该[DEFAULT]部分中，仅启用计算和元数据 API：

[DEFAULT]
  
#…
  
enabled\_apis = osapi\_compute,metadata

在[api\_database]和[database]部分，配置数据库访问：

[api\_database]
  
…
  
connection = mysql+pymysql://nova:NOVA\_DBPASS@controller/nova\_api

[database]
  
…
  
connection = mysql+pymysql://nova:NOVA\_DBPASS@controller/nova

替换NOVA\_DBPASS为您为 数据库选择的密码。

在该[DEFAULT]部分，配置RabbitMQ消息队列访问：

[DEFAULT]
  
…
  
transport\_url = rabbit://openstack:RABBIT\_PASS@controller:5672/

替换RABBIT\_PASS为您为 中的openstack 帐户选择的密码。

在[api]和[keystone\_authtoken]部分，配置身份服务访问：

[api]
  
…
  
auth\_strategy = keystone

[keystone\_authtoken]
  
…
  
www\_authenticate\_uri = http://controller:5000/
  
auth\_url = http://controller:5000/
  
memcached\_servers = controller:11211
  
auth\_type = password
  
project\_domain\_name = Default
  
user\_domain\_name = Default
  
project\_name = service
  
username = nova
  
password = NOVA\_PASS

替换NOVA\_PASS为您nova在身份服务中为用户选择的密码。

笔记 注释掉或删除该[keystone\_authtoken] 部分中的任何其他选项。

在该[DEFAULT]部分中，配置my\_ip选项以使用控制器节点的管理接口 IP 地址：

[DEFAULT]
  
…
  
my\_ip = 192.168.44.3

在该[DEFAULT]部分中，启用对网络服务的支持：

[DEFAULT]
  
…
  
use\_neutron = true
  
firewall\_driver = nova.virt.firewall.NoopFirewallDriver

笔记 默认情况下，Compute
  
使用内部防火墙驱动程序。由于网络服务包括防火墙驱动程序，您必须使用nova.virt.firewall.NoopFirewallDriver防火墙驱动程序禁用计算防火墙驱动程序。

配置/etc/nova/nova.conf的[neutron]部分。有关更多详细信息，请参阅网络服务安装指南。

在该[vnc]部分中，将 VNC 代理配置为使用控制器节点的管理接口 IP 地址：

[vnc]
  
enabled = true
  
…
  
server\_listen = $my\_ip
  
server\_proxyclient\_address = $my\_ip

在该[glance]部分中，配置 Image 服务 API 的位置：

[glance]
  
…
  
api\_servers = http://controller:9292

在该[oslo\_concurrency]部分中，配置锁定路径：

[oslo\_concurrency]
  
…
  
lock\_path = /var/lib/nova/tmp

在[placement]部分中，配置对 Placement 服务的访问：

[placement]
  
…
  
region\_name = RegionOne
  
project\_domain\_name = Default
  
project\_name = service
  
auth\_type = password
  
user\_domain\_name = Default
  
auth\_url = http://controller:5000/v3
  
username = placement
  
password = PLACEMENT\_PASS

替换PLACEMENT\_PASS为您为placement安装Placement时创建的服务用户 选择的密码 。注释掉或删除该[placement]部分中的任何其他选项。

3.填充nova-api数据库：

su -s /bin/sh -c “nova-manage api\_db sync” nova

4.注册cell0数据库：

su -s /bin/sh -c “nova-manage cell\_v2 map\_cell0” nova

5.创建cell1单元格：

su -s /bin/sh -c “nova-manage cell\_v2 create\_cell --name=cell1 --verbose” nova

6.填充 nova 数据库：

su -s /bin/sh -c “nova-manage db sync” nova

7.验证 nova cell0 和 cell1 是否正确注册：

su -s /bin/sh -c “nova-manage cell\_v2 list\_cells” nova

完成安装
  
启动 Compute 服务并将它们配置为在系统启动时启动：

systemctl enable
  
openstack-nova-api.service
  
openstack-nova-scheduler.service
  
openstack-nova-conductor.service
  
openstack-nova-novncproxy.service
  
systemctl start
  
openstack-nova-api.service
  
openstack-nova-scheduler.service
  
openstack-nova-conductor.service
  
openstack-nova-novncproxy.service

10.nova计算节点
  
安装软件包：

yum install openstack-nova-compute libvirt -y

编辑/etc/nova/nova.conf文件并完成以下操作：
  
#vi /etc/nova/nova.conf
  
在该[DEFAULT]部分中，仅启用计算和元数据 API：

[DEFAULT]
  
…
  
enabled\_apis = osapi\_compute,metadata

在该[DEFAULT]部分，配置RabbitMQ消息队列访问：

[DEFAULT]
  
…
  
transport\_url = rabbit://openstack:RABBIT\_PASS@controller

替换RABBIT\_PASS为您为 中的openstack 帐户选择的密码。

在[api]和[keystone\_authtoken]部分，配置身份服务访问：

[api]
  
…
  
auth\_strategy = keystone

[keystone\_authtoken]
  
…
  
www\_authenticate\_uri = http://controller:5000/
  
auth\_url = http://controller:5000/
  
memcached\_servers = controller:11211
  
auth\_type = password
  
project\_domain\_name = Default
  
user\_domain\_name = Default
  
project\_name = service
  
username = nova
  
password = NOVA\_PASS

替换NOVA\_PASS为您nova在身份服务中为用户选择的密码。

在该[DEFAULT]部分中，配置my\_ip选项：

[DEFAULT]
  
…
  
my\_ip = MANAGEMENT\_INTERFACE\_IP\_ADDRESS

替换MANAGEMENT\_INTERFACE\_IP\_ADDRESS为计算节点上管理网络接口的 IP 地址，
  
在该[DEFAULT]部分中，启用对网络服务的支持：

[DEFAULT]
  
…
  
use\_neutron = true
  
firewall\_driver = nova.virt.firewall.NoopFirewallDriver

笔记 默认情况下，Compute 使用内部防火墙服务。由于网络包括防火墙服务，您必须使用nova.virt.firewall.NoopFirewallDriver防火墙驱动程序禁用计算防火墙服务。

在[vnc]部分中，启用和配置远程控制台访问：

[vnc]
  
…
  
enabled = true
  
server\_listen = 0.0.0.0
  
server\_proxyclient\_address = $my\_ip
  
novncproxy\_base\_url = http://controller:6080/vnc\_auto.html

服务器组件侦听所有 IP 地址，代理组件仅侦听计算节点的管理接口 IP 地址。基本 URL 指示您可以使用 Web浏览器访问此计算节点上实例的远程控制台的位置。 如果用于访问远程控制台的 Web
  
浏览器驻留在无法解析controller主机名的主机上，则必须替换 controller为控制器节点的管理接口 IP 地址。

在该[glance]部分中，配置 Image 服务 API 的位置：

[glance]
  
…
  
api\_servers = http://controller:9292

在该[oslo\_concurrency]部分中，配置锁定路径：

[oslo\_concurrency]
  
…
  
lock\_path = /var/lib/nova/tmp

在[placement]部分中，配置 Placement API：

[placement]
  
…
  
region\_name = RegionOne
  
project\_domain\_name = Default
  
project\_name = service
  
auth\_type = password
  
user\_domain\_name = Default
  
auth\_url = http://controller:5000/v3
  
username = placement
  
password = PLACEMENT\_PASS

替换PLACEMENT\_PASS为您placement在身份服务中为用户选择的密码 。注释掉该[placement]部分中的任何其他选项。
  
完成安装
  
1.确定计算节点是否支持虚拟机的硬件加速：

$ egrep -c ‘(vmx|svm)’ /proc/cpuinfo

如果此命令返回值one or greater，则计算节点支持硬件加速，这通常不需要额外配置。
  
如果此命令返回值zero，则计算节点不支持硬件加速，您必须配置libvirt为使用 QEMU 而不是 KVM。

编辑文件中的[libvirt]部分，/etc/nova/nova.conf如下所示：

[libvirt]
  
…
  
virt\_type = qemu

启动 Compute 服务及其依赖项，并将它们配置为在系统启动时自动启动：

systemctl enable libvirtd.service openstack-nova-compute.service
  
systemctl start libvirtd.service openstack-nova-compute.service

如果有遇到起不起来rabbitmq一直报连接不上的加下这条

compute\_driver=libvirt.LibvirtDriver

将计算节点添加到单元数据库
  
在控制器节点上运行以下命令：
  
1.获取管理员凭据以启用仅限管理员的 CLI 命令，然后确认数据库中有计算主机：

$ . admin-openrc
  
$ openstack compute service list --service nova-compute

2.发现计算主机

su -s /bin/sh -c “nova-manage cell\_v2 discover\_hosts --verbose” nova

11.neutron控制节点
  
1.要创建数据库，请完成以下步骤：
  
用数据库访问客户端以root用户身份连接数据库服务器：

$ mysql -u root -p

创建neutron数据库：

MariaDB [(none)] CREATE DATABASE neutron;

授予对neutron数据库的适当访问权限，替换 NEUTRON\_DBPASS为合适的密码：

MariaDB [(none)]> GRANT ALL PRIVILEGES ON neutron.\* TO ‘neutron’@‘localhost’ IDENTIFIED BY ‘NEUTRON\_DBPASS’;
  
MariaDB [(none)]> GRANT ALL PRIVILEGES ON neutron.\* TO ‘neutron’@‘%’ IDENTIFIED BY ‘NEUTRON\_DBPASS’;

退出数据库访问客户端。
  
2.来源admin凭据来访问仅管理员CLI命令：

$ . admin-openrc

3.要创建服务凭证，请完成以下步骤：
  
创建neutron用户：

$ openstack user create --domain default --password-prompt neutron

admin为neutron用户添加角色：

$ openstack role add --project service --user neutron admin

此命令不提供任何输出。

创建neutron服务实体：

$ openstack service create --name neutron
  
–description “OpenStack Networking” network

4.创建网络服务 API 端点：

$ openstack endpoint create --region RegionOne
  
network public http://controller:9696
  
$ openstack endpoint create --region RegionOne
  
network internal http://controller:9696

$ openstack endpoint create --region RegionOne
  
network admin http://controller:9696

配置网络选项 可以使用以下两种体系结构之一部署网络服务 以选项1和2为代表。

选项 1 部署了最简单的体系结构，该体系结构仅支持 将实例附加到提供商（外部）网络。没有自助服务（私人） 网络、路由器或浮动 IP
  
地址。只有 或其他 特权用户可以管理提供商网络。admin

选项 2 使用支持连接的第 1 层服务扩充选项 3 实例到自助服务网络。或其他非特权 用户可以管理自助服务网络，包括提供
  
自助服务和提供商网络之间的连接。此外 浮动 IP 地址使用自助服务提供与实例的连接 来自外部网络（如互联网）的网络。demo

自助服务网络通常使用覆盖网络。叠加网络 VXLAN 等协议包括增加开销的其他标头 并减少可用于有效负载或用户数据的空间。没有知识
  
的虚拟网络基础结构，实例尝试发送数据包 使用默认以太网最大传输单元 （MTU） 1500 字节。网络服务自动提供正确的 MTU 值 通过
  
DHCP 传输到实例。但是，某些云映像不使用 DHCP 或忽略 DHCP MTU 选项，并需要使用元数据或脚本进行配置。

注意 选项 2 还支持将实例附加到提供商网络。
  
选项1请参考官网：https://docs.openstack.org/neutron/train/install/controller-install-option1-rdo.html
  
网络选项 2：自助服务网络

yum install openstack-neutron openstack-neutron-ml2
  
openstack-neutron-linuxbridge ebtables ipset -y
  
配置服务器组件
  
编辑/etc/neutron/neutron.conf文件并完成以下操作：
  
#vi /etc/neutron/neutron.conf
  
在该[database]部分中，配置数据库访问：

[database]
  
…
  
connection = mysql+pymysql://neutron:NEUTRON\_DBPASS@controller/neutron

替换NEUTRON\_DBPASS为您为数据库选择的密码。

在该[DEFAULT]部分中，启用模块化第 2 层 (ML2) 插件、路由器服务和重叠 IP 地址：

[DEFAULT]
  
…
  
core\_plugin = ml2
  
service\_plugins = router
  
allow\_overlapping\_ips = true

在该[DEFAULT]部分，配置RabbitMQ 消息队列访问：

[DEFAULT]
  
#…
  
transport\_url = rabbit://openstack:RABBIT\_PASS@controller

替换RABBIT\_PASS为您openstack在 RabbitMQ 中为帐户选择的密码 。

在[DEFAULT]和[keystone\_authtoken]部分，配置身份服务访问：

[DEFAULT]
  
…
  
auth\_strategy = keystone

[keystone\_authtoken]
  
…
  
www\_authenticate\_uri = http://controller:5000
  
auth\_url = http://controller:5000
  
memcached\_servers = controller:11211
  
auth\_type = password
  
project\_domain\_name = default
  
user\_domain\_name = default
  
project\_name = service
  
username = neutron
  
password = NEUTRON\_PASS

替换NEUTRON\_PASS为您neutron 在身份服务中为用户选择的密码。

注释掉或删除该[keystone\_authtoken]部分中的任何其他选项 。

在[DEFAULT]和[nova]部分中，配置 Networking 以通知 Compute 网络拓扑更改：

[DEFAULT]
  
…
  
notify\_nova\_on\_port\_status\_changes = true
  
notify\_nova\_on\_port\_data\_changes = true

[nova]
  
…
  
auth\_url = http://controller:5000
  
auth\_type = password
  
project\_domain\_name = default
  
user\_domain\_name = default
  
region\_name = RegionOne
  
project\_name = service
  
username = nova
  
password = NOVA\_PASS

替换NOVA\_PASS为您nova 在身份服务中为用户选择的密码。

在该[oslo\_concurrency]部分中，配置锁定路径：

[oslo\_concurrency]
  
…
  
lock\_path = /var/lib/neutron/tmp

配置模块化第 2 层 (ML2) 插件
  
ML2 插件使用 Linux 桥接机制为实例构建第 2 层（桥接和交换）虚拟网络基础设施。
  
编辑/etc/neutron/plugins/ml2/ml2\_conf.ini文件并完成以下操作：
  
#vi /etc/neutron/plugins/ml2/ml2\_conf.ini
  
在该[ml2]部分中，启用平面、VLAN 和 VXLAN 网络：

[ml2]
  
…
  
type\_drivers = flat,vlan,vxlan

在该[ml2]部分中，启用 VXLAN 自助网络：

[ml2]
  
…
  
tenant\_network\_types = vxlan

在该[ml2]部分中，启用 Linux 桥接和二层填充机制：

[ml2]

…
  
mechanism\_drivers = linuxbridge,l2population

警告 配置 ML2 插件后，删除type\_drivers选项中的值 可能会导致数据库不一致。

Linux 网桥代理仅支持 VXLAN 覆盖网络。

在该[ml2]部分中，启用端口安全扩展驱动程序：

[ml2]
  
…
  
extension\_drivers = port\_security

在该[ml2\_type\_flat]部分中，将提供者虚拟网络配置为平面网络：

[ml2\_type\_flat]
  
…
  
flat\_networks = provider

在该[ml2\_type\_vxlan]部分中，配置自助网络的 VXLAN 网络标识符范围：

[ml2\_type\_vxlan]
  
#…
  
vni\_ranges = 1:1000

在该[securitygroup]部分中，启用ipset以提高安全组规则的效率：

[securitygroup]
  
…
  
enable\_ipset = true

配置 Linux 网桥代理
  
Linux 桥接代理为实例构建第 2 层（桥接和交换）虚拟网络基础架构并处理安全组。
  
编辑/etc/neutron/plugins/ml2/linuxbridge\_agent.ini文件并完成以下操作：
  
在该[linux\_bridge]部分中，将提供者虚拟网络映射到提供者物理网络接口：

[linux\_bridge]
  
physical\_interface\_mappings = provider:PROVIDER\_INTERFACE\_NAME

替换PROVIDER\_INTERFACE\_NAME为底层提供者物理网络接口的名称。ens33
  
在该[vxlan]部分中，启用VXLAN覆盖网络，配置处理覆盖网络的物理网络接口的IP地址，并启用二层填充：

[vxlan]
  
enable\_vxlan = true
  
local\_ip = OVERLAY\_INTERFACE\_IP\_ADDRESS
  
l2\_population = true

替换OVERLAY\_INTERFACE\_IP\_ADDRESS为处理覆盖网络的底层物理网络接口的 IP 地址。示例架构使用管理接口将流量隧道传输到其他节点。因此，替换OVERLAY\_INTERFACE\_IP\_ADDRESS为控制器节点的管理 IP 地址。有关详细信息，请参阅 主机网络。

在该[securitygroup]部分中，启用安全组并配置 Linux 网桥 iptables 防火墙驱动程序：

[securitygroup]
  
…
  
enable\_security\_group = true
  
firewall\_driver = neutron.agent.linux.iptables\_firewall.IptablesFirewallDriver

通过验证以下所有sysctl值都设置为，确保您的 Linux 操作系统内核支持网桥过滤器1：
  
编辑/etc/sysctl.conf加入：

net.bridge.bridge-nf-call-iptables = 1
  
net.bridge.bridge-nf-call-ip6tables = 1

保存退出，输入modprobe br\_netfilter加载内核模块，最后sysctl -p查看是否生效

modprobe br\_netfilter
  
sysctl -p

要启用网络桥接支持，通常br\_netfilter需要加载内核模块。有关启用此模块的其他详细信息，请查看操作系统的文档。

配置三层代理
  
第 3 层 (L3) 代理为自助服务虚拟网络提供路由和 NAT 服务。

编辑/etc/neutron/l3\_agent.ini文件并完成以下操作：

在该[DEFAULT]部分中，配置 Linux 桥接接口驱动程序：

[DEFAULT]
  
…
  
interface\_driver = linuxbridge

配置 DHCP 代理
  
DHCP 代理为虚拟网络提供 DHCP 服务。
  
编辑/etc/neutron/dhcp\_agent.ini文件并完成以下操作：
  
在该[DEFAULT]部分中，配置 Linux 桥接接口驱动程序、Dnsmasq DHCP 驱动程序，并启用隔离元数据，以便提供商网络上的实例可以通过网络访问元数据：

[DEFAULT]
  
…
  
interface\_driver = linuxbridge
  
dhcp\_driver = neutron.agent.linux.dhcp.Dnsmasq
  
enable\_isolated\_metadata = true

配置元数据代理
  
元数据代理向实例提供配置信息，例如凭据。

编辑/etc/neutron/metadata\_agent.ini文件并完成以下操作：

在该[DEFAULT]部分中，配置元数据主机和共享密钥：

[DEFAULT]
  
…
  
nova\_metadata\_host = controller
  
metadata\_proxy\_shared\_secret = METADATA\_SECRET

替换METADATA\_SECRET为元数据代理的合适密钥。

配置 Compute 服务以使用 Networking 服务

笔记 必须安装 Nova 计算服务才能完成此步骤。有关更多详细信息，请参阅文档网站安装指南部分下的计算安装指南 。

编辑/etc/nova/nova.conf文件并执行以下操作：

在该[neutron]部分中，配置访问参数，启用元数据代理，并配置密钥：

[neutron]
  
…
  
auth\_url = http://controller:5000
  
auth\_type = password
  
project\_domain\_name = default
  
user\_domain\_name = default
  
region\_name = RegionOne
  
project\_name = service
  
username = neutron
  
password = NEUTRON\_PASS
  
service\_metadata\_proxy = true
  
metadata\_proxy\_shared\_secret = METADATA\_SECRET

替换NEUTRON\_PASS为您neutron 在身份服务中为用户选择的密码。
  
替换METADATA\_SECRET为您为元数据代理选择的机密。
  
请参阅计算服务配置指南 以获取完整的选项集，包括必要时覆盖服务目录端点 URL。

完成安装
  
1.网络服务初始化脚本需要一个/etc/neutron/plugin.ini指向 ML2 插件配置文件的符号链接 /etc/neutron/plugins/ml2/ml2\_conf.ini。如果此符号链接不存在，请使用以下命令创建它：

ln -s /etc/neutron/plugins/ml2/ml2\_conf.ini /etc/neutron/plugin.ini

2.填充数据库：

su -s /bin/sh -c “neutron-db-manage --config-file /etc/neutron/neutron.conf
  
–config-file /etc/neutron/plugins/ml2/ml2\_conf.ini upgrade head” neutron

3.重启计算 API 服务：

systemctl restart openstack-nova-api.service

4.启动网络服务并将它们配置为在系统启动时启动。

对于两个网络选项：

systemctl enable neutron-server.service
  
neutron-linuxbridge-agent.service neutron-dhcp-agent.service
  
neutron-metadata-agent.service
  
systemctl start neutron-server.service
  
neutron-linuxbridge-agent.service neutron-dhcp-agent.service
  
neutron-metadata-agent.service

对于网络选项 2，还启用并启动第 3 层服务：

systemctl enable neutron-l3-agent.service
  
systemctl start neutron-l3-agent.service

12.neutron计算节点
  
安装组件

yum install openstack-neutron-linuxbridge ebtables ipset -y

配置通用组件
  
Networking 通用组件配置包括身份验证机制、消息队列和插件。

编辑/etc/neutron/neutron.conf文件并完成以下操作：
  
在该[database]部分中，注释掉所有connection选项，因为计算节点不直接访问数据库。
  
在该[DEFAULT]部分，配置RabbitMQ 消息队列访问：

[DEFAULT]
  
…
  
transport\_url = rabbit://openstack:RABBIT\_PASS@controller

替换RABBIT\_PASS为您openstack 在 RabbitMQ 中为帐户选择的密码。

在[DEFAULT]和[keystone\_authtoken]部分，配置身份服务访问：

[DEFAULT]
  
…
  
auth\_strategy = keystone

[keystone\_authtoken]
  
…
  
www\_authenticate\_uri = http://controller:5000
  
auth\_url = http://controller:5000
  
memcached\_servers = controller:11211
  
auth\_type = password
  
project\_domain\_name = default
  
user\_domain\_name = default
  
project\_name = service
  
username = neutron
  
password = NEUTRON\_PASS

替换NEUTRON\_PASS为您neutron 在身份服务中为用户选择的密码。

在该[oslo\_concurrency]部分中，配置锁定路径：

[oslo\_concurrency]
  
…
  
lock\_path = /var/lib/neutron/tmp

在计算节点上配置网络组件。

配置 Linux 网桥代理
  
Linux 桥接代理为实例构建第 2 层（桥接和交换）虚拟网络基础架构并处理安全组。

编辑/etc/neutron/plugins/ml2/linuxbridge\_agent.ini文件并完成以下操作：

在该[linux\_bridge]部分中，将提供者虚拟网络映射到提供者物理网络接口：

[linux\_bridge]
  
physical\_interface\_mappings = provider:PROVIDER\_INTERFACE\_NAME

替换PROVIDER\_INTERFACE\_NAME为底层提供者物理网络接口的名称。有关 详细信息，请参阅主机网络。

在该[vxlan]部分中，启用VXLAN覆盖网络，配置处理覆盖网络的物理网络接口的IP地址，并启用二层填充：

[vxlan]
  
enable\_vxlan = true
  
local\_ip = OVERLAY\_INTERFACE\_IP\_ADDRESS
  
l2\_population = true

替换OVERLAY\_INTERFACE\_IP\_ADDRESS为处理覆盖网络的底层物理网络接口的 IP 地址。示例架构使用管理接口将流量隧道传输到其他节点。因此，替换OVERLAY\_INTERFACE\_IP\_ADDRESS为计算节点的管理IP地址。有关详细信息，请参阅 主机网络。

在该[securitygroup]部分中，启用安全组并配置 Linux 网桥 iptables 防火墙驱动程序：

[securitygroup]
  
…
  
enable\_security\_group = true
  
firewall\_driver = neutron.agent.linux.iptables\_firewall.IptablesFirewallDriver

通过验证以下所有sysctl值都设置为，确保您的 Linux 操作系统内核支持网桥过滤器1：
  
编辑/etc/sysctl.conf加入：

net.bridge.bridge-nf-call-iptables = 1
  
net.bridge.bridge-nf-call-ip6tables = 1

保存退出，输入modprobe br\_netfilter加载内核模块，最后sysctl -p查看是否生效

modprobe br\_netfilter
  
sysctl -p

要启用网络桥接支持，通常br\_netfilter需要加载内核模块。有关启用此模块的其他详细信息，请查看操作系统的文档。

配置 Compute 服务以使用 Networking 服务
  
编辑/etc/nova/nova.conf文件并完成以下操作：

在该[neutron]部分，配置访问参数：

[neutron]
  
…
  
auth\_url = http://controller:5000
  
auth\_type = password
  
project\_domain\_name = default
  
user\_domain\_name = default
  
region\_name = RegionOne
  
project\_name = service
  
username = neutron
  
password = NEUTRON\_PASS

替换NEUTRON\_PASS为您neutron 在身份服务中为用户选择的密码。

完成安装
  
1.重启计算服务：

systemctl restart openstack-nova-compute.service

2.启动 Linux 网桥代理并将其配置为在系统启动时启动：

systemctl enable neutron-linuxbridge-agent.service
  
systemctl start neutron-linuxbridge-agent.service

13.dashboard：
  
本节假设使用 Apache HTTP 服务器和 Memcached 服务正确安装、配置和操作 Identity 服务。
  
安装和配置组件
  
1.安装软件包：

yum install openstack-dashboard -y

2.编辑 /etc/openstack-dashboard/local\_settings 文件并完成以下操作：
  
配置仪表板以在controller节点上使用 OpenStack 服务 ：

OPENSTACK\_HOST = “controller”
  
ALLOWED\_HOSTS = [‘horizon.example.com’, ‘\*’]
  
SESSION\_ENGINE = ‘django.contrib.sessions.backends.cache’
  
CACHES = {
  
‘default’: {
  
‘BACKEND’:
  
‘django.core.cache.backends.memcached.MemcachedCache’,
  
‘LOCATION’: ‘controller:11211’,
  
}
  
}
  
OPENSTACK\_KEYSTONE\_URL = “http://%s:5000/v3” % OPENSTACK\_HOST
  
OPENSTACK\_KEYSTONE\_MULTIDOMAIN\_SUPPORT = True
  
OPENSTACK\_API\_VERSIONS = {
  
“identity”: 3,
  
“image”: 2,
  
“volume”: 3,
  
}
  
OPENSTACK\_KEYSTONE\_DEFAULT\_DOMAIN = “Default”
  
OPENSTACK\_KEYSTONE\_DEFAULT\_ROLE = “user”
  
OPENSTACK\_NEUTRON\_NETWORK = {
  
‘enable\_lb’: False,
  
‘enable\_firewall’: False,
  
‘enable\_vpn’: False,
  
‘enable\_auto\_allocated\_network’: False,
  
‘enable\_distributed\_router’: False,
  
‘enable\_fip\_topology\_check’: False,
  
‘enable\_ha\_router’: False,
  
‘enable\_ipv6’: False,
  
‘enable\_quotas’: False,
  
‘enable\_rbac\_policy’: False,
  
‘enable\_router’: False,
  
}
  
TIME\_ZONE = “Asia/Shanghai”
  
WEBROOT=“/dashboard”

替换TIME\_ZONE为适当的时区标识符。有关更多信息，请参阅时区列表。

/etc/httpd/conf.d/openstack-dashboard.conf如果不包括，则添加以下行 。

WSGIApplicationGroup %{GLOBAL}

完成安装
  
重新启动 Web 服务器和会话存储服务：

systemctl restart httpd.service memcached.service

14.cinder控制节点
  
1.使用数据库访问客户端以root用户身份连接数据库服务器：

$ mysql -u root -p

创建cinder数据库：

MariaDB [(none)]> CREATE DATABASE cinder;

授予对cinder数据库的适当访问权限：

MariaDB [(none)]> GRANT ALL PRIVILEGES ON cinder.\* TO ‘cinder’@‘localhost’
  
IDENTIFIED BY ‘CINDER\_DBPASS’;
  
MariaDB [(none)]> GRANT ALL PRIVILEGES ON cinder.\* TO ‘cinder’@‘%’
  
IDENTIFIED BY ‘CINDER\_DBPASS’;

替换CINDER\_DBPASS为合适的密码。
  
退出数据库访问客户端。

2.来源admin凭据来访问仅管理员CLI命令：

$ . admin-openrc

3.要创建服务凭证，请完成以下步骤：
  
创建cinder用户：

$ openstack user create --domain default --password-prompt cinder

admin为cinder用户添加角色：

$ openstack role add --project service --user cinder admin

创建cinderv2和cinderv3服务实体：

$ openstack service create --name cinderv2
  
–description “OpenStack Block Storage” volumev2

$ openstack service create --name cinderv3
  
–description “OpenStack Block Storage” volumev3

（块存储服务需要两个服务实体。）

4.创建块存储服务 API 端点：

$ openstack endpoint create --region RegionOne
  
volumev2 public http://controller:8776/v2/%(project\_id)s
  
$ openstack endpoint create --region RegionOne
  
volumev2 internal http://controller:8776/v2/%(project\_id)s
  
$ openstack endpoint create --region RegionOne
  
volumev2 admin http://controller:8776/v2/%(project\_id)s
  
$ openstack endpoint create --region RegionOne
  
volumev3 public http://controller:8776/v3/%(project\_id)s
  
$ openstack endpoint create --region RegionOne
  
volumev3 internal http://controller:8776/v3/%(project\_id)s
  
$ openstack endpoint create --region RegionOne
  
volumev3 admin http://controller:8776/v3/%(project\_id)s

（块存储服务需要每个服务实体的端点。）

安装和配置组件
  
1.安装软件包：

yum install openstack-cinder -y

2.编辑/etc/cinder/cinder.conf文件并完成以下操作：
  
#vi /etc/cinder/cinder.conf
  
在该[database]部分中，配置数据库访问：

[database]
  
…
  
connection = mysql+pymysql://cinder:CINDER\_DBPASS@controller/cinder

替换CINDER\_DBPASS为您为 Block Storage 数据库选择的密码。

在该[DEFAULT]部分，配置RabbitMQ 消息队列访问：

[DEFAULT]
  
…
  
transport\_url = rabbit://openstack:RABBIT\_PASS@controller

替换RABBIT\_PASS为您为 中的openstack帐户选择的密码 RabbitMQ。

在[DEFAULT]和[keystone\_authtoken]部分，配置身份服务访问：

[DEFAULT]
  
…
  
auth\_strategy = keystone

[keystone\_authtoken]
  
…
  
www\_authenticate\_uri = http://controller:5000
  
auth\_url = http://controller:5000
  
memcached\_servers = controller:11211
  
auth\_type = password
  
project\_domain\_name = default
  
user\_domain\_name = default
  
project\_name = service
  
username = cinder
  
password = CINDER\_PASS

替换CINDER\_PASS为您cinder在身份服务中为用户选择的密码。

注释掉或删除该[keystone\_authtoken]部分中的任何其他选项 。

在该[DEFAULT]部分中，配置my\_ip选项以使用控制器节点的管理接口 IP 地址：

[DEFAULT]
  
…
  
my\_ip = 192.168.44.3

3.在该[oslo\_concurrency]部分中，配置锁定路径：

[oslo\_concurrency]
  
…
  
lock\_path = /var/lib/cinder/tmp

4.填充块存储数据库：

su -s /bin/sh -c “cinder-manage db sync” cinder

（忽略此输出中的任何弃用消息。）

配置 Compute 以使用块存储
  
1.编辑/etc/nova/nova.conf文件并将以下内容添加到其中：

[cinder]
  
os\_region\_name = RegionOne

完成安装
  
1.重启计算 API 服务：

systemctl restart openstack-nova-api.service

2.启动块存储服务并配置它们在系统启动时启动：

systemctl enable openstack-cinder-api.service openstack-cinder-scheduler.service
  
systemctl start openstack-cinder-api.service openstack-cinder-scheduler.service

15.cinder计算节点
  
1.安装支持的实用程序包：
  
安装 LVM 包：

yum install lvm2 device-mapper-persistent-data

启动 LVM 元数据服务并将其配置为在系统启动时启动：

systemctl enable lvm2-lvmetad.service
  
systemctl start lvm2-lvmetad.service

2.创建 LVM 物理卷/dev/sdb;

$ pvcreate /dev/sdb
  
Physical volume “/dev/sda1” successfully created

3.创建 LVM 卷组cinder-volumes：

$ vgcreate cinder-volumes /dev/sdb
  
Volume group “cinder-volumes” successfully created

Block Storage 服务在这个卷组中创建逻辑卷。

4.只有实例可以访问块存储卷。但是，底层操作系统管理与卷关联的设备。默认情况下，LVM 卷扫描工具会扫描/dev包含卷的块存储设备的 目录。如果项目在其卷上使用 LVM，扫描工具会检测这些卷并尝试缓存它们，这可能会导致底层操作系统和项目卷出现各种问题。您必须重新配置 LVM 以仅扫描包含cinder-volumes卷组的设备。编辑 /etc/lvm/lvm.conf文件并完成以下操作：
  
在该devices部分中，添加一个接受/dev/sdb设备并拒绝所有其他设备的过滤 器：

devices {
  
…
  
filter = [ “a/sdb/”, “r/.\*/”]

滤波器阵列中的每个项目开始于a用于接受或 r用于拒绝，并且包括用于所述装置名称的正则表达式。该阵列必须r/.\*/以拒绝任何剩余设备结束。您可以使用vgs -vvvv命令来测试过滤器。

警告 如果您的存储节点在操作系统磁盘上使用 LVM，您还必须将关联的设备添加到过滤器中。例如，如果/dev/sda设备包含操作系统：
  
filter = [ “a/sda/”, “a/sdb/”, “r/./"] 同样，如果您的计算节点在操作系统磁盘上使用
  
LVM，您还必须修改/etc/lvm/lvm.conf这些节点上文件中的过滤器 以仅包含操作系统磁盘。例如，如果/dev/sda
  
设备包含操作系统： filter = [ “a/sda/”, "r/./”]

安装和配置组件
  
1.安装软件包：

yum install openstack-cinder targetcli python-keystone -y

2.编辑/etc/cinder/cinder.conf文件并完成以下操作：
  
在该[database]部分中，配置数据库访问：

[database]
  
…
  
connection = mysql+pymysql://cinder:CINDER\_DBPASS@controller/cinder

替换CINDER\_DBPASS为您为 Block Storage 数据库选择的密码。

在该[DEFAULT]部分，配置RabbitMQ 消息队列访问：

[DEFAULT]
  
…
  
transport\_url = rabbit://openstack:RABBIT\_PASS@controller

替换RABBIT\_PASS为您为 中的openstack帐户选择的密码。

在[DEFAULT]和[keystone\_authtoken]部分，配置身份服务访问：

[DEFAULT]
  
…
  
auth\_strategy = keystone

[keystone\_authtoken]
  
…
  
www\_authenticate\_uri = http://controller:5000
  
auth\_url = http://controller:5000
  
memcached\_servers = controller:11211
  
auth\_type = password
  
project\_domain\_name = default
  
user\_domain\_name = default
  
project\_name = service
  
username = cinder
  
password = CINDER\_PASS

替换CINDER\_PASS为您cinder在身份服务中为用户选择的密码 。

注释掉或删除该[keystone\_authtoken]部分中的任何其他选项 。

在该[DEFAULT]部分中，配置my\_ip选项：

[DEFAULT]
  
…
  
my\_ip = MANAGEMENT\_INTERFACE\_IP\_ADDRESS

替换MANAGEMENT\_INTERFACE\_IP\_ADDRESS为存储节点上管理网络接口的 IP 地址

在该[lvm]部分中，使用 LVM 驱动程序、cinder-volumes卷组、iSCSI 协议和适当的 iSCSI 服务配置 LVM 后端。如果该[lvm]部分不存在，请创建它：

[lvm]
  
volume\_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
  
volume\_group = cinder-volumes
  
target\_protocol = iscsi
  
target\_helper = lioadm

在该[DEFAULT]部分中，启用 LVM 后端：

[DEFAULT]
  
…
  
enabled\_backends = lvm

后端名称是任意的。例如，本指南使用驱动程序的名称作为后端的名称。

在该[DEFAULT]部分中，配置 Image 服务 API 的位置：

[DEFAULT]
  
…
  
glance\_api\_servers = http://controller:9292

在该[oslo\_concurrency]部分中，配置锁定路径：

[oslo\_concurrency]
  
#…
  
lock\_path = /var/lib/cinder/tmp

完成安装
  
启动 Block Storage 卷服务及其依赖项，并将它们配置为在系统启动时启动：

systemctl enable openstack-cinder-volume.service target.service
  
systemctl start openstack-cinder-volume.service target.service

登录dsahboard

http://192.168.44.3/dashboard

控制节点ip登录

下面进行安装好openstack后的操作，在控制节点上，加载. admin-openrc后进行创建网络、规格、安全组、密钥等

创建网络：

openstack network create --share --external --provider-physical-network provider --provider-network-type flat provider
  
openstack subnet create --network provider --allocation-pool start=192.168.44.10,end=192.168.50.254 --gateway 192.168.0.254 --subnet-range 192.168.0.0/16 provider

创建规格：

openstack flavor create --id 0 --vcpus 1 --ram 64 --disk 1 m1.nano

创建密钥对：

ssh-keygen -q -N “”
  
openstack keypair create --public-key ~/.ssh/id\_rsa.pub mykey

创建安全组并允许SSH访问：

openstack security group rule create --proto icmp default
  
openstack security group rule create --proto tcp --dst-port 22 default

创建个user的，不然后面创建项目创建用户会报找不到token

openstack role create user

创建一个镜像文件

Touch cirros-0.5.2-x86\_64-disk.img

上传镜像：

openstack image create NEW\_IMAGE\_NAME --container-format bare --disk-format qcow2 --file IMAGE\_URL

最后，在dashboard界面台中创建实例吧

openstack云镜像下载地址：https://cloud.centos.org/centos/7/images/
  
官方文档：https://docs.openstack.org/install-guide/

参考：
  
https://www.cnblogs.com/powell/p/17958801