---
layout: post
title: "openstack搭建openstack云平台部署-详细完整教程"
date: 2025-03-07 16:51:40 +0800
description: "openstack云平台部署（完整教程）环境要求Openstack硬件环境：Vmware虚拟机3台，控制节点配置需求4C8G20G，计算节点2C4G20GOpenstack网络要求：至少一套网络，使用Vmware虚拟机的网络即可操作系统要求：centos7*即可，openstack开源版本均支持大部分开源操作系统，centos、ubnutu、suse等等，centos7操作系统的安装详见操作系统安装文档。本指南中使用的ip控制节点：controller:192.168.44.3。"
keywords: "（openstack搭建）openstack云平台部署-详细完整教程"
categories: ['未分类']
tags: ['Openstack']
artid: "146099872"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146099872
    alt: "openstack搭建openstack云平台部署-详细完整教程"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146099872
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146099872
cover: https://bing.ee123.net/img/rand?artid=146099872
image: https://bing.ee123.net/img/rand?artid=146099872
img: https://bing.ee123.net/img/rand?artid=146099872
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     （openstack搭建）openstack云平台部署-详细完整教程
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     openstack云平台部署（完整教程）
     <br/>
     环境要求
     <br/>
     Openstack硬件环境：Vmware虚拟机3台，控制节点配置需求4C8G20G，计算节点2C4G20G
    </p>
    <p>
     Openstack网络要求：至少一套网络，使用Vmware虚拟机的网络即可
    </p>
    <p>
     操作系统要求：centos7*即可，openstack开源版本均支持大部分开源操作系统，centos、ubnutu、suse等等，centos7操作系统的安装详见操作系统安装文档。
     <br/>
     本指南中使用的ip
     <br/>
     控制节点：controller:192.168.44.3
     <br/>
     计算节点：compute1:192.168.44.4
     <br/>
     compute2:192.168.44.5
    </p>
    <p>
     一、安装openstack前的前置操作(以下3台虚拟机均同样操作)：
     <br/>
     1 关闭防火墙
    </p>
    <p>
     systemctl stop firewalld &amp;&amp; systemctl disable firewalld
    </p>
    <p>
     2 关闭selinux
    </p>
    <p>
     1、vim /etc/selinux/config
     <br/>
     SELINUX=enforcing #把enforcing改为disabled
     <br/>
     2、setenforce 0
     <br/>
     3、reboot #重新启动让其生效
    </p>
    <p>
     3、hostname机hosts配置
    </p>
    <p>
     [root@localhost ~]hostnamectl set-hostname --pretty controller
     <br/>
     [root@localhost ~]hostnamectl set-hostname --static controller
     <br/>
     [root@localhost ~]hostnamectl set-hostname --transient controller
    </p>
    <p>
     [root@localhost ~]vi /etc/hosts
    </p>
    <p>
     192.168.44.3 controller
     <br/>
     192.168.44.4 compute1
     <br/>
     192.168.44.5 compute2
    </p>
    <p>
     4、安装openstack及ceph的yum源
     <br/>
     能连接外网的情况下：
     <br/>
     下载安装openstack存储库：
    </p>
    <p>
     yum install centos-release-openstack-train
    </p>
    <p>
     安装后会自行在源配置路径/etc/yum.repo.d/下生成配置文件，之后加载即可使用
    </p>
    <p>
     yum clean all &amp;&amp; yum makecache
    </p>
    <p>
     如果虚拟机无法上网的话，需要去
     <br/>
     http://mirror.centos.org/centos-7/7.9.2009/cloud/x86_64/openstack-train/上拿取源包，放到虚拟机上配置本地源使用
     <br/>
     5. 配置时间同步ntpd
    </p>
    <p>
     [root@controller ~]yum -y install ntp*
     <br/>
     [root@controller ~]systemctl start ntpd
     <br/>
     [root@controller ~]systemctl enable ntpd
     <br/>
     [root@controller ~]ntpdate ntp1.aliyun.com
    </p>
    <p>
     二、安装openstack总体步骤
     <br/>
     安装rabbitmq
     <br/>
     安装etcd
     <br/>
     安装memcached
     <br/>
     安装MySQL
     <br/>
     安装keystone
     <br/>
     操作系统环境变量配置
     <br/>
     安装glance
     <br/>
     安装placement
     <br/>
     安装nova
     <br/>
     计算节点nova
     <br/>
     安装neutron
     <br/>
     计算节点neutron
     <br/>
     安装dashboard
     <br/>
     安装 cinder
     <br/>
     计算节点cinder
    </p>
    <p>
     1.Rabbitmq:安装：
    </p>
    <p>
     yum install rabbitmq-server -y
    </p>
    <p>
     启动并配置为自动启动
    </p>
    <p>
     systemctl enable rabbitmq-server.service
     <br/>
     systemctl start rabbitmq-server.service
    </p>
    <p>
     在rabbitmq中添加openstack用户：
    </p>
    <p>
     [root@controller ~]rabbitmqctl add_user openstack RABBIT_PASS #RABBIT_PASS换成合适的密码
     <br/>
     Creating user “openstack” …
    </p>
    <p>
     配置改用户的权限
    </p>
    <p>
     rabbitmqctl set_permissions openstack “.
     <em>
      " ".
     </em>
     ” “.*”
     <br/>
     Setting permissions for user “openstack” in vhost “/” …
    </p>
    <p>
     开启管理界面插件：
    </p>
    <p>
     rabbitmq-plugins enable rabbitmq_management
    </p>
    <p>
     openstack部署成功后可以登录rabbitmq web管理界面：http://192.168.44.3:15672 如出现无法访问情况 检查端口：
     <br/>
     netstat -anlp | grep 15672 如果还无法访问，手动添加安全组规则 端口15672 5672，然后重启服务
     <br/>
     输入用户名:guest 密码:guest，点击login就可以登录
    </p>
    <p>
     另，安装openstack客户端：
    </p>
    <p>
     yum install python-openstackclient openstack-selinux -y
    </p>
    <p>
     2.Etcd
     <br/>
     安装：
    </p>
    <p>
     yum install etcd -y
    </p>
    <p>
     编辑配置文件：
    </p>
    <p>
     vi /etc/etcd/etcd.conf
    </p>
    <p>
     #[Member]
     <br/>
     ETCD_DATA_DIR=“/var/lib/etcd/default.etcd”
     <br/>
     ETCD_LISTEN_PEER_URLS=“http://192.168.44.3:2380”
     <br/>
     ETCD_LISTEN_CLIENT_URLS=“http://192.168.44.3:2379”
     <br/>
     ETCD_NAME=“controller”
     <br/>
     #[Clustering]
     <br/>
     ETCD_INITIAL_ADVERTISE_PEER_URLS=“http://192.168.44.3:2380”
     <br/>
     ETCD_ADVERTISE_CLIENT_URLS=“http://192.168.44.3:2379”
     <br/>
     ETCD_INITIAL_CLUSTER=“controller=http://192.168.44.3:2380”
     <br/>
     ETCD_INITIAL_CLUSTER_TOKEN=“etcd-cluster”
     <br/>
     ETCD_INITIAL_CLUSTER_STATE=“new”
    </p>
    <p>
     启动etcd
    </p>
    <p>
     systemctl enable etcd
     <br/>
     systemctl start etcd
    </p>
    <p>
     3.Memcached
    </p>
    <p>
     yum install memcached python-memcached -y
    </p>
    <p>
     编辑配置文件/etc/sysconfig/memcached ，在最后添加上控制节点的主机名:
    </p>
    <p>
     vi /etc/sysconfig/memcached
    </p>
    <p>
     OPTIONS=“-l 127.0.0.1,::1,controller”
    </p>
    <p>
     启动
    </p>
    <p>
     systemctl enable memcached.service
     <br/>
     systemctl start memcached.service
    </p>
    <p>
     4.MySQL
    </p>
    <p>
     yum install mariadb mariadb-server python2-PyMySQL -y
    </p>
    <p>
     创建和编辑/etc/my.cnf.d/openstack.cnf /etc/my.cnf.d/文件（如果需要，备份现有的配置文件）并完成以下操作：
     <br/>
     创建一个[mysqld]section，设置bind-address key为controller节点的管理IP地址，允许其他节点通过管理网络访问。设置附加键以启用有用的选项和 UTF-8 字符集：
    </p>
    <p>
     vi /etc/my.cnf.d/openstack.cnf
    </p>
    <p>
     [mysqld]
     <br/>
     bind-address = 192.168.44.3
    </p>
    <p>
     default-storage-engine = innodb
     <br/>
     innodb_file_per_table = on
     <br/>
     max_connections = 4096
     <br/>
     collation-server = utf8_general_ci
     <br/>
     character-set-server = utf8
    </p>
    <p>
     完成安装
     <br/>
     启动数据库服务并配置它在系统启动时启动：
    </p>
    <p>
     systemctl enable mariadb.service
     <br/>
     systemctl start mariadb.service
    </p>
    <p>
     初始化数据库并设置密码(123456)
    </p>
    <p>
     mysql_secure_installation
     <br/>
     5.Keystone
     <br/>
     安装mariadb数据库
    </p>
    <p>
     mysql -u root -p
    </p>
    <p>
     创建keystone数据库：
    </p>
    <p>
     MariaDB [(none)]&gt; CREATE DATABASE keystone;
    </p>
    <p>
     授予对keystone数据库的适当访问权限：
    </p>
    <p>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON keystone.* TO ‘keystone’@‘localhost’ IDENTIFIED BY ‘KEYSTONE_DBPASS’;
     <br/>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON keystone.* TO ‘keystone’@‘%’ IDENTIFIED BY ‘KEYSTONE_DBPASS’;
     <br/>
     #（用合适的密码替换 KEYSTONE_DBPASS ）
     <br/>
     GRANT ALL PRIVILEGES ON keystone.* TO ‘keystone’@‘localhost’ IDENTIFIED BY ‘123456’;
     <br/>
     GRANT ALL PRIVILEGES ON keystone.* TO ‘keystone’@‘%’ IDENTIFIED BY ‘123456’;
     <br/>
     安装keystone
    </p>
    <p>
     yum install openstack-keystone httpd mod_wsgi -y
    </p>
    <p>
     编辑/etc/keystone/keystone.conf文件并完成以下操作：
     <br/>
     在该[database]部分中，配置数据库访问：
    </p>
    <p>
     vim /etc/keystone/keystone.conf
    </p>
    <p>
     [database]
     <br/>
     connection = mysql+pymysql://keystone:KEYSTONE_DBPASS@controller/keystone
     <br/>
     #替换KEYSTONE_DBPASS为您为数据库选择的密码。
     <br/>
     #注释掉或删除connection该[database]部分中的任何其他选项 。
     <br/>
     #在[token]部分中，配置 Fernet 令牌提供程序：
     <br/>
     [token]
     <br/>
     provider = fernet
    </p>
    <p>
     填充身份服务数据库：
    </p>
    <p>
     su -s /bin/sh -c “keystone-manage db_sync” keystone
    </p>
    <p>
     初始化 Fernet 密钥库：
    </p>
    <p>
     在–keystone-user和–keystone-group标志用于指定将用于运行keystone操作系统的用户/组。提供这些是为了允许在另一个操作系统用户/组下运行
     <br/>
     keystone。在下面的示例中，我们调用 user &amp; group keystone。
    </p>
    <p>
     keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone
     <br/>
     keystone-manage credential_setup --keystone-user keystone --keystone-group keystone
    </p>
    <p>
     引导身份服务：
    </p>
    <p>
     keystone-manage bootstrap --bootstrap-password ADMIN_PASS
     <br/>
     –bootstrap-admin-url http://controller:5000/v3/
     <br/>
     –bootstrap-internal-url http://controller:5000/v3/
     <br/>
     –bootstrap-public-url http://controller:5000/v3/
     <br/>
     –bootstrap-region-id RegionOne
     <br/>
     #替换ADMIN_PASS为适合管理用户的密码。
    </p>
    <p>
     配置 Apache HTTP 服务器
     <br/>
     编辑/etc/httpd/conf/httpd.conf文件并配置 ServerName选项以引用控制器节点：
    </p>
    <p>
     vim etc/httpd/conf/httpd.conf
    </p>
    <p>
     ServerName controller
    </p>
    <p>
     如果该ServerName条目尚不存在，则需要添加该条目。
    </p>
    <p>
     创建/usr/share/keystone/wsgi-keystone.conf文件链接：
    </p>
    <p>
     vim usr/share/keystone/wsgi-keystone.conf
    </p>
    <p>
     ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/
    </p>
    <p>
     启动 Apache HTTP 服务并配置它在系统启动时启动：
    </p>
    <p>
     systemctl enable httpd.service
     <br/>
     systemctl start httpd.service
    </p>
    <p>
     通过设置适当的环境变量来配置管理帐户：
    </p>
    <p>
     export OS_USERNAME=admin
     <br/>
     export OS_PASSWORD=ADMIN_PASS
     <br/>
     export OS_PROJECT_NAME=admin
     <br/>
     export OS_USER_DOMAIN_NAME=Default
     <br/>
     export OS_PROJECT_DOMAIN_NAME=Default
     <br/>
     export OS_AUTH_URL=http://controller:5000/v3
     <br/>
     export OS_IDENTITY_API_VERSION=3
    </p>
    <p>
     创建域、项目、用户和角色
     <br/>
     1.尽管本指南中的keystone-manage 引导步骤中已经存在“默认”域，但创建新域的正式方法是：
    </p>
    <p>
     openstack domain create --description “An Example Domain” example
    </p>
    <p>
     2.本指南使用一个服务项目，其中包含每个用户的唯一用户 添加到环境中的服务。创建项目：service
    </p>
    <p>
     openstack project create --domain default --description “Service Project” service
    </p>
    <p>
     3.常规（非管理员）任务应使用非特权项目和用户。例如，本指南创建myproject项目和myuser 用户。
     <br/>
     创建myproject项目：
    </p>
    <p>
     openstack project create --domain default --description “Demo Project” myproject
    </p>
    <p>
     为该项目创建其他用户时不要重复此步骤。
     <br/>
     创建myuser用户：
    </p>
    <p>
     openstack user create --domain default --password-prompt myuser
    </p>
    <p>
     创建myrole角色：
    </p>
    <p>
     openstack role create myrole
    </p>
    <p>
     将myrole角色添加到myproject项目和myuser用户：
    </p>
    <p>
     $ openstack role add --project myproject --user myuser myrole
     <br/>
     1
     <br/>
     创建 OpenStack 客户端环境脚本
     <br/>
     为 和 项目和用户创建客户端环境脚本。本指南的后续部分将参考这些内容 用于为客户端操作加载相应凭据的脚本。
     <br/>
     1.创建并编辑文件并添加以下内容：admin-openrc
    </p>
    <p>
     $ vi admin-openrc
    </p>
    <p>
     export OS_PROJECT_DOMAIN_NAME=Default
     <br/>
     export OS_USER_DOMAIN_NAME=Default
     <br/>
     export OS_PROJECT_NAME=admin
     <br/>
     export OS_USERNAME=admin
     <br/>
     export OS_PASSWORD=ADMIN_PASS
     <br/>
     export OS_AUTH_URL=http://controller:5000/v3
     <br/>
     export OS_IDENTITY_API_VERSION=3
     <br/>
     export OS_IMAGE_API_VERSION=2
     <br/>
     #替换为您选择的密码 对于标识服务中的用户。ADMIN_PASS admin
    </p>
    <p>
     2.创建并编辑文件并添加以下内容：demo-openrc
    </p>
    <p>
     $ vi demo-openrc
    </p>
    <p>
     export OS_PROJECT_DOMAIN_NAME=Default
     <br/>
     export OS_USER_DOMAIN_NAME=Default
     <br/>
     export OS_PROJECT_NAME=myproject
     <br/>
     export OS_USERNAME=myuser
     <br/>
     export OS_PASSWORD=DEMO_PASS
     <br/>
     export OS_AUTH_URL=http://controller:5000/v3
     <br/>
     export OS_IDENTITY_API_VERSION=3
     <br/>
     export OS_IMAGE_API_VERSION=2
     <br/>
     #替换为您选择的密码 对于标识服务中的用户。DEMO_PASS videmo
     <br/>
     使用脚本
     <br/>
     要以特定项目和用户身份运行客户端，只需加载即可 运行它们之前的关联客户端环境脚本。 例如：
     <br/>
     加载文件以填充 具有标识服务位置的环境变量 以及项目和用户凭据：admin-openrc
    </p>
    <p>
     $ sh admin-openrc
    </p>
    <p>
     请求身份验证令牌：
    </p>
    <p>
     openstack token issue
    </p>
    <p>
     6.操作系统环境配置
     <br/>
     sysctl.conf文件配置：
    </p>
    <p>
     vi /etc/sysctl.conf
    </p>
    <p>
     net.ipv4.tcp_syncookies = 1
     <br/>
     net.ipv4.tcp_tw_reuse = 1
     <br/>
     net.ipv4.tcp_tw_recycle = 1
     <br/>
     net.ipv4.tcp_fin_timeout = 30
     <br/>
     net.ipv4.tcp_keepalive_time = 1200
     <br/>
     net.ipv4.tcp_keepalive_intvl = 2
     <br/>
     net.ipv4.tcp_keepalive_probes = 1
     <br/>
     #net.ipv4.ip_local_port_range = 10000 65000
     <br/>
     net.ipv4.tcp_max_syn_backlog = 8192
     <br/>
     net.ipv4.tcp_max_tw_buckets = 5000
     <br/>
     net.ipv4.tcp_synack_retries = 2
     <br/>
     net.ipv4.neigh.default.gc_stale_time=120
     <br/>
     net.ipv4.conf.all.rp_filter=0
     <br/>
     net.ipv4.conf.default.rp_filter=0
     <br/>
     net.ipv4.conf.default.arp_announce = 2
     <br/>
     net.ipv4.conf.lo.arp_announce=2
     <br/>
     net.ipv4.conf.all.arp_announce=2
     <br/>
     net.ipv4.ip_forward = 1
    </p>
    <p>
     net.ipv6.conf.all.disable_ipv6 = 0
     <br/>
     net.ipv6.conf.default.disable_ipv6 = 0
     <br/>
     net.ipv6.conf.lo.disable_ipv6 = 0
    </p>
    <p>
     net.core.somaxconn=8192
    </p>
    <p>
     vm.swappiness = 0
    </p>
    <p>
     /etc/sudoers文件配置：
    </p>
    <p>
     cepher ALL=(ALL) NOPASSWD: ALL
     <br/>
     nova ALL=(ALL) NOPASSWD: ALL
     <br/>
     neutron ALL=(ALL) NOPASSWD: ALL
     <br/>
     ceilometer ALL = (root) NOPASSWD: /usr/bin/ceilometer-rootwrap /etc/ceilometer/rootwrap.conf *
    </p>
    <p>
     /etc/security/limits.conf文件配置(end前)：
    </p>
    <ul>
     <li>
      <p>
       soft nofile 65530
      </p>
     </li>
     <li>
      <p>
       hard nofile 65530
      </p>
     </li>
     <li>
      <ul>
       <li>
        memlock unlimited
       </li>
      </ul>
     </li>
     <li>
      <ul>
       <li>
        nofile 100000
       </li>
      </ul>
     </li>
     <li>
      <ul>
       <li>
        nproc 32768
       </li>
      </ul>
     </li>
     <li>
      <ul>
       <li>
        as unlimited
        <br/>
        /etc/systemd/system.conf #资源限制连接数
       </li>
      </ul>
     </li>
    </ul>
    <p>
     DefaultLimitNOFILE=20480
     <br/>
     DefaultLimitNPROC=20480
    </p>
    <p>
     上面这些配置完后要重启才能生效
    </p>
    <p>
     7.Glance
     <br/>
     在安装和配置 Image 服务之前，您必须创建数据库、服务凭证和 API 端点。
     <br/>
     1.要创建数据库，请完成以下步骤：
     <br/>
     使用数据库访问客户端以root用户身份连接数据库服务器：
    </p>
    <p>
     mysql -u root -p
    </p>
    <p>
     创建glance数据库：
    </p>
    <p>
     MariaDB [(none)]&gt; CREATE DATABASE glance;
    </p>
    <p>
     授予对glance数据库的适当访问权限：
    </p>
    <p>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO ‘glance’@‘localhost’ IDENTIFIED BY ‘GLANCE_DBPASS’;
     <br/>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO ‘glance’@‘%’ IDENTIFIED BY ‘GLANCE_DBPASS’;
    </p>
    <p>
     替换GLANCE_DBPASS为合适的密码。
    </p>
    <p>
     退出数据库访问客户端。
    </p>
    <p>
     2.来源admin凭据来访问仅管理员CLI命令：
    </p>
    <p>
     sh admin-openrc
    </p>
    <p>
     报错处理source admin-openrc
    </p>
    <p>
     3.要创建服务凭证，请完成以下步骤：
     <br/>
     创建glance用户：
    </p>
    <p>
     openstack user create --domain default --password-prompt glance
    </p>
    <p>
     将admin角色添加到glance用户和 service项目：
    </p>
    <p>
     openstack role add --project service --user glance admin
    </p>
    <p>
     创建glance服务实体：
    </p>
    <p>
     openstack service create --name glance --description “OpenStack Image” image
    </p>
    <p>
     创建镜像服务 API 端点：
    </p>
    <p>
     $ openstack endpoint create --region RegionOne image public http://controller:9292
     <br/>
     $ openstack endpoint create --region RegionOne image internal http://controller:9292
     <br/>
     $ openstack endpoint create --region RegionOne image admin http://controller:9292
    </p>
    <p>
     安装和配置组件
     <br/>
     安装软件包：
    </p>
    <p>
     yum install openstack-glance -y
    </p>
    <p>
     编辑/etc/glance/glance-api.conf文件并完成以下操作：
     <br/>
     在该[database]部分中，配置数据库访问：
     <br/>
     #vi /etc/glance/glance-api.conf
    </p>
    <p>
     [database]
    </p>
    <h2>
     <a id="_472">
     </a>
     …
    </h2>
    <p>
     connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance
    </p>
    <p>
     替换GLANCE_DBPASS为您为Glance:服务数据库选择的密码。
    </p>
    <p>
     在[keystone_authtoken]和[paste_deploy]部分，配置身份服务访问：
    </p>
    <p>
     [keystone_authtoken]
     <br/>
     …
     <br/>
     www_authenticate_uri = http://controller:5000
     <br/>
     auth_url = http://controller:5000
     <br/>
     memcached_servers = controller:11211
     <br/>
     auth_type = password
     <br/>
     project_domain_name = Default
     <br/>
     user_domain_name = Default
     <br/>
     project_name = service
     <br/>
     username = glance
     <br/>
     password = GLANCE_PASS
    </p>
    <p>
     [paste_deploy]
     <br/>
     …
     <br/>
     flavor = keystone
    </p>
    <p>
     替换GLANCE_PASS为您glance在身份服务中为用户选择的密码 。
    </p>
    <p>
     在该[glance_store]部分中，配置本地文件系统存储和镜像文件的位置：
    </p>
    <p>
     [glance_store]
    </p>
    <h2>
     <a id="_501">
     </a>
     …
    </h2>
    <p>
     stores = file,http
     <br/>
     default_store = file
     <br/>
     filesystem_store_datadir = /var/lib/glance/images
    </p>
    <p>
     填充glance服务数据库：
    </p>
    <p>
     su -s /bin/sh -c “glance-manage db_sync” glance
    </p>
    <p>
     编辑/etc/glance/glance-registry.conf文件并完成以下操作：
    </p>
    <p>
     在该[database]部分中，配置数据库访问：
    </p>
    <p>
     [database]
    </p>
    <p>
     #…
     <br/>
     connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance
    </p>
    <p>
     替换GLANCE_DBPASS为您为Glance服务数据库选择的密码。
    </p>
    <p>
     在[keystone_authtoken]和[paste_deploy]部分，配置身份服务访问：
    </p>
    <p>
     [keystone_authtoken]
     <br/>
     #…
     <br/>
     www_authenticate_uri = http://controller:5000
     <br/>
     auth_url = http://controller:5000
     <br/>
     memcached_servers = controller:11211
     <br/>
     auth_type = password
     <br/>
     project_domain_name = Default
     <br/>
     user_domain_name = Default
     <br/>
     project_name = service
     <br/>
     username = glance
     <br/>
     password = GLANCE_PASS
    </p>
    <p>
     [paste_deploy]
     <br/>
     …
     <br/>
     flavor = keystone
    </p>
    <p>
     替换GLANCE_PASS为您glance在身份服务中为用户选择的密码 。
     <br/>
     完成安装
     <br/>
     启动 Image 服务并将它们配置为在系统启动时启动：
    </p>
    <p>
     systemctl enable openstack-glance-api.service
     <br/>
     systemctl start openstack-glance-api.service
    </p>
    <p>
     8.placement
     <br/>
     1.创建数据库
     <br/>
     要创建数据库，请完成以下步骤：
     <br/>
     使用数据库访问客户端以root用户身份连接数据库服务器：
    </p>
    <p>
     $ mysql -u root -p
     <br/>
     创建placement数据库：
    </p>
    <p>
     MariaDB [(none)]&gt; CREATE DATABASE placement;
    </p>
    <p>
     授予对数据库的适当访问权限：
    </p>
    <p>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON placement.* TO ‘placement’@‘localhost’ IDENTIFIED BY ‘PLACEMENT_DBPASS’;
     <br/>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON placement.* TO ‘placement’@‘%’ IDENTIFIED BY ‘PLACEMENT_DBPASS’;
    </p>
    <p>
     替换PLACEMENT_DBPASS为合适的密码。
    </p>
    <p>
     退出数据库访问客户端。
    </p>
    <p>
     2.配置用户和端点
     <br/>
     来源admin凭据来访问仅管理员CLI命令：
    </p>
    <p>
     $ . admin-openrc
    </p>
    <p>
     使用您选择的创建一个安置服务用户PLACEMENT_PASS：
    </p>
    <p>
     $ openstack user create --domain default --password-prompt placement
    </p>
    <p>
     3.将 Placement 用户添加到具有 admin 角色的服务项目：
    </p>
    <p>
     $ openstack role add --project service --user placement admin
    </p>
    <p>
     4.在服务目录中创建 Placement API 条目：
    </p>
    <p>
     $ openstack service create --name placement
     <br/>
     –description “Placement API” placement
    </p>
    <p>
     5.创建 Placement API 服务端点：
     <br/>
     （根据环境，端点的 URL 会因端口（可能是 8780 而不是 8778，或者根本没有端口）和主机名而异。确定正确的 URL。）
    </p>
    <p>
     $ openstack endpoint create --region RegionOne
     <br/>
     placement public http://controller:8778
     <br/>
     $ openstack endpoint create --region RegionOne
     <br/>
     placement internal http://controller:8778
     <br/>
     $ openstack endpoint create --region RegionOne
     <br/>
     placement admin http://controller:8778
    </p>
    <p>
     安装和配置组件
     <br/>
     1.安装软件包：
    </p>
    <p>
     yum install openstack-placement-api -y
    </p>
    <p>
     2.编辑/etc/placement/placement.conf文件并完成以下操作：
     <br/>
     #vi /etc/placement/placement.conf
    </p>
    <p>
     在该[placement_database]部分中，配置数据库访问：
    </p>
    <p>
     [placement_database]
    </p>
    <h2>
     <a id="_619">
     </a>
     …
    </h2>
    <p>
     connection = mysql+pymysql://placement:PLACEMENT_DBPASS@controller/placement
    </p>
    <p>
     替换PLACEMENT_DBPASS为您为展示位置数据库选择的密码。
    </p>
    <p>
     在[api]和[keystone_authtoken]部分，配置身份服务访问：
    </p>
    <p>
     [api]
     <br/>
     …
     <br/>
     auth_strategy = keystone
    </p>
    <p>
     [keystone_authtoken]
     <br/>
     #…
     <br/>
     auth_url = http://controller:5000/v3
     <br/>
     memcached_servers = controller:11211
     <br/>
     auth_type = password
     <br/>
     project_domain_name = Default
     <br/>
     user_domain_name = Default
     <br/>
     project_name = service
     <br/>
     username = placement
     <br/>
     password = PLACEMENT_PASS
    </p>
    <p>
     替换PLACEMENT_PASS为您placement在身份服务中为用户选择的密码 。
    </p>
    <p>
     笔记 注释掉或删除该[keystone_authtoken] 部分中的任何其他选项。
     <br/>
     、的值user_name，password，project_domain_name并
     <br/>
     user_domain_name需要在你的keystone配置同步。
    </p>
    <p>
     3.填充placement数据库：
    </p>
    <p>
     su -s /bin/sh -c “placement-manage db sync” placement
    </p>
    <p>
     完成安装
     <br/>
     4.重启httpd服务：
    </p>
    <p>
     systemctl restart httpd
    </p>
    <p>
     9.nova控制节点
     <br/>
     1.使用数据库访问客户端以root用户身份连接数据库服务器：
    </p>
    <p>
     $ mysql -u root -p
    </p>
    <p>
     创建nova_api，nova和nova_cell0数据库：
    </p>
    <p>
     MariaDB [(none)]&gt; CREATE DATABASE nova_api;
     <br/>
     MariaDB [(none)]&gt; CREATE DATABASE nova;
     <br/>
     MariaDB [(none)]&gt; CREATE DATABASE nova_cell0;
     <br/>
     授予对数据库的适当访问权限：
    </p>
    <p>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_api.* TO ‘nova’@‘localhost’
     <br/>
     IDENTIFIED BY ‘123456’;
     <br/>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_api.* TO ‘nova’@‘%’
     <br/>
     IDENTIFIED BY ‘123456’;
    </p>
    <p>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO ‘nova’@‘localhost’
     <br/>
     IDENTIFIED BY ‘123456’;
     <br/>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO ‘nova’@‘%’
     <br/>
     IDENTIFIED BY ‘123456’;
    </p>
    <p>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_cell0.* TO ‘nova’@‘localhost’
     <br/>
     IDENTIFIED BY ‘123456’;
     <br/>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_cell0.* TO ‘nova’@‘%’
     <br/>
     IDENTIFIED BY ‘123456’;
    </p>
    <p>
     替换NOVA_DBPASS为合适的密码。（这里设置的是123456）
    </p>
    <p>
     数据库访问客户端。
    </p>
    <p>
     2.来源admin凭据来访问仅管理员CLI命令：
    </p>
    <p>
     $ . admin-openrc
    </p>
    <p>
     3.创建计算服务凭证：
     <br/>
     创建nova用户：
    </p>
    <p>
     $ openstack user create --domain default --password-prompt nova
    </p>
    <p>
     admin为nova用户添加角色：
    </p>
    <p>
     $ openstack role add --project service --user nova admin
    </p>
    <p>
     此命令不提供任何输出。
    </p>
    <p>
     创建nova服务实体：
    </p>
    <p>
     $ openstack service create --name nova
     <br/>
     –description “OpenStack Compute” compute
    </p>
    <p>
     4.创建 Compute API 服务端点：
    </p>
    <p>
     $ openstack endpoint create --region RegionOne
     <br/>
     compute public http://controller:8774/v2.1
    </p>
    <p>
     $ openstack endpoint create --region RegionOne
     <br/>
     compute internal http://controller:8774/v2.1
    </p>
    <p>
     $ openstack endpoint create --region RegionOne
     <br/>
     compute admin http://controller:8774/v2.1
    </p>
    <p>
     安装和配置组件
     <br/>
     1.安装软件包：
    </p>
    <p>
     yum install openstack-nova-api openstack-nova-conductor
     <br/>
     openstack-nova-novncproxy openstack-nova-scheduler libvirt -y
    </p>
    <p>
     2.编辑/etc/nova/nova.conf文件并完成以下操作：
     <br/>
     #vi /etc/nova/nova.conf
     <br/>
     在该[DEFAULT]部分中，仅启用计算和元数据 API：
    </p>
    <p>
     [DEFAULT]
     <br/>
     #…
     <br/>
     enabled_apis = osapi_compute,metadata
    </p>
    <p>
     在[api_database]和[database]部分，配置数据库访问：
    </p>
    <p>
     [api_database]
     <br/>
     …
     <br/>
     connection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova_api
    </p>
    <p>
     [database]
     <br/>
     …
     <br/>
     connection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova
    </p>
    <p>
     替换NOVA_DBPASS为您为 数据库选择的密码。
    </p>
    <p>
     在该[DEFAULT]部分，配置RabbitMQ消息队列访问：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     transport_url = rabbit://openstack:RABBIT_PASS@controller:5672/
    </p>
    <p>
     替换RABBIT_PASS为您为 中的openstack 帐户选择的密码。
    </p>
    <p>
     在[api]和[keystone_authtoken]部分，配置身份服务访问：
    </p>
    <p>
     [api]
     <br/>
     …
     <br/>
     auth_strategy = keystone
    </p>
    <p>
     [keystone_authtoken]
     <br/>
     …
     <br/>
     www_authenticate_uri = http://controller:5000/
     <br/>
     auth_url = http://controller:5000/
     <br/>
     memcached_servers = controller:11211
     <br/>
     auth_type = password
     <br/>
     project_domain_name = Default
     <br/>
     user_domain_name = Default
     <br/>
     project_name = service
     <br/>
     username = nova
     <br/>
     password = NOVA_PASS
    </p>
    <p>
     替换NOVA_PASS为您nova在身份服务中为用户选择的密码。
    </p>
    <p>
     笔记 注释掉或删除该[keystone_authtoken] 部分中的任何其他选项。
    </p>
    <p>
     在该[DEFAULT]部分中，配置my_ip选项以使用控制器节点的管理接口 IP 地址：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     my_ip = 192.168.44.3
    </p>
    <p>
     在该[DEFAULT]部分中，启用对网络服务的支持：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     use_neutron = true
     <br/>
     firewall_driver = nova.virt.firewall.NoopFirewallDriver
    </p>
    <p>
     笔记 默认情况下，Compute
     <br/>
     使用内部防火墙驱动程序。由于网络服务包括防火墙驱动程序，您必须使用nova.virt.firewall.NoopFirewallDriver防火墙驱动程序禁用计算防火墙驱动程序。
    </p>
    <p>
     配置/etc/nova/nova.conf的[neutron]部分。有关更多详细信息，请参阅网络服务安装指南。
    </p>
    <p>
     在该[vnc]部分中，将 VNC 代理配置为使用控制器节点的管理接口 IP 地址：
    </p>
    <p>
     [vnc]
     <br/>
     enabled = true
     <br/>
     …
     <br/>
     server_listen = $my_ip
     <br/>
     server_proxyclient_address = $my_ip
    </p>
    <p>
     在该[glance]部分中，配置 Image 服务 API 的位置：
    </p>
    <p>
     [glance]
     <br/>
     …
     <br/>
     api_servers = http://controller:9292
    </p>
    <p>
     在该[oslo_concurrency]部分中，配置锁定路径：
    </p>
    <p>
     [oslo_concurrency]
     <br/>
     …
     <br/>
     lock_path = /var/lib/nova/tmp
    </p>
    <p>
     在[placement]部分中，配置对 Placement 服务的访问：
    </p>
    <p>
     [placement]
     <br/>
     …
     <br/>
     region_name = RegionOne
     <br/>
     project_domain_name = Default
     <br/>
     project_name = service
     <br/>
     auth_type = password
     <br/>
     user_domain_name = Default
     <br/>
     auth_url = http://controller:5000/v3
     <br/>
     username = placement
     <br/>
     password = PLACEMENT_PASS
    </p>
    <p>
     替换PLACEMENT_PASS为您为placement安装Placement时创建的服务用户 选择的密码 。注释掉或删除该[placement]部分中的任何其他选项。
    </p>
    <p>
     3.填充nova-api数据库：
    </p>
    <p>
     su -s /bin/sh -c “nova-manage api_db sync” nova
    </p>
    <p>
     4.注册cell0数据库：
    </p>
    <p>
     su -s /bin/sh -c “nova-manage cell_v2 map_cell0” nova
    </p>
    <p>
     5.创建cell1单元格：
    </p>
    <p>
     su -s /bin/sh -c “nova-manage cell_v2 create_cell --name=cell1 --verbose” nova
    </p>
    <p>
     6.填充 nova 数据库：
    </p>
    <p>
     su -s /bin/sh -c “nova-manage db sync” nova
    </p>
    <p>
     7.验证 nova cell0 和 cell1 是否正确注册：
    </p>
    <p>
     su -s /bin/sh -c “nova-manage cell_v2 list_cells” nova
    </p>
    <p>
     完成安装
     <br/>
     启动 Compute 服务并将它们配置为在系统启动时启动：
    </p>
    <p>
     systemctl enable
     <br/>
     openstack-nova-api.service
     <br/>
     openstack-nova-scheduler.service
     <br/>
     openstack-nova-conductor.service
     <br/>
     openstack-nova-novncproxy.service
     <br/>
     systemctl start
     <br/>
     openstack-nova-api.service
     <br/>
     openstack-nova-scheduler.service
     <br/>
     openstack-nova-conductor.service
     <br/>
     openstack-nova-novncproxy.service
    </p>
    <p>
     10.nova计算节点
     <br/>
     安装软件包：
    </p>
    <p>
     yum install openstack-nova-compute libvirt -y
    </p>
    <p>
     编辑/etc/nova/nova.conf文件并完成以下操作：
     <br/>
     #vi /etc/nova/nova.conf
     <br/>
     在该[DEFAULT]部分中，仅启用计算和元数据 API：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     enabled_apis = osapi_compute,metadata
    </p>
    <p>
     在该[DEFAULT]部分，配置RabbitMQ消息队列访问：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     transport_url = rabbit://openstack:RABBIT_PASS@controller
    </p>
    <p>
     替换RABBIT_PASS为您为 中的openstack 帐户选择的密码。
    </p>
    <p>
     在[api]和[keystone_authtoken]部分，配置身份服务访问：
    </p>
    <p>
     [api]
     <br/>
     …
     <br/>
     auth_strategy = keystone
    </p>
    <p>
     [keystone_authtoken]
     <br/>
     …
     <br/>
     www_authenticate_uri = http://controller:5000/
     <br/>
     auth_url = http://controller:5000/
     <br/>
     memcached_servers = controller:11211
     <br/>
     auth_type = password
     <br/>
     project_domain_name = Default
     <br/>
     user_domain_name = Default
     <br/>
     project_name = service
     <br/>
     username = nova
     <br/>
     password = NOVA_PASS
    </p>
    <p>
     替换NOVA_PASS为您nova在身份服务中为用户选择的密码。
    </p>
    <p>
     在该[DEFAULT]部分中，配置my_ip选项：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     my_ip = MANAGEMENT_INTERFACE_IP_ADDRESS
    </p>
    <p>
     替换MANAGEMENT_INTERFACE_IP_ADDRESS为计算节点上管理网络接口的 IP 地址，
     <br/>
     在该[DEFAULT]部分中，启用对网络服务的支持：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     use_neutron = true
     <br/>
     firewall_driver = nova.virt.firewall.NoopFirewallDriver
    </p>
    <p>
     笔记 默认情况下，Compute 使用内部防火墙服务。由于网络包括防火墙服务，您必须使用nova.virt.firewall.NoopFirewallDriver防火墙驱动程序禁用计算防火墙服务。
    </p>
    <p>
     在[vnc]部分中，启用和配置远程控制台访问：
    </p>
    <p>
     [vnc]
     <br/>
     …
     <br/>
     enabled = true
     <br/>
     server_listen = 0.0.0.0
     <br/>
     server_proxyclient_address = $my_ip
     <br/>
     novncproxy_base_url = http://controller:6080/vnc_auto.html
    </p>
    <p>
     服务器组件侦听所有 IP 地址，代理组件仅侦听计算节点的管理接口 IP 地址。基本 URL 指示您可以使用 Web浏览器访问此计算节点上实例的远程控制台的位置。 如果用于访问远程控制台的 Web
     <br/>
     浏览器驻留在无法解析controller主机名的主机上，则必须替换 controller为控制器节点的管理接口 IP 地址。
    </p>
    <p>
     在该[glance]部分中，配置 Image 服务 API 的位置：
    </p>
    <p>
     [glance]
     <br/>
     …
     <br/>
     api_servers = http://controller:9292
    </p>
    <p>
     在该[oslo_concurrency]部分中，配置锁定路径：
    </p>
    <p>
     [oslo_concurrency]
     <br/>
     …
     <br/>
     lock_path = /var/lib/nova/tmp
    </p>
    <p>
     在[placement]部分中，配置 Placement API：
    </p>
    <p>
     [placement]
     <br/>
     …
     <br/>
     region_name = RegionOne
     <br/>
     project_domain_name = Default
     <br/>
     project_name = service
     <br/>
     auth_type = password
     <br/>
     user_domain_name = Default
     <br/>
     auth_url = http://controller:5000/v3
     <br/>
     username = placement
     <br/>
     password = PLACEMENT_PASS
    </p>
    <p>
     替换PLACEMENT_PASS为您placement在身份服务中为用户选择的密码 。注释掉该[placement]部分中的任何其他选项。
     <br/>
     完成安装
     <br/>
     1.确定计算节点是否支持虚拟机的硬件加速：
    </p>
    <p>
     $ egrep -c ‘(vmx|svm)’ /proc/cpuinfo
    </p>
    <p>
     如果此命令返回值one or greater，则计算节点支持硬件加速，这通常不需要额外配置。
     <br/>
     如果此命令返回值zero，则计算节点不支持硬件加速，您必须配置libvirt为使用 QEMU 而不是 KVM。
    </p>
    <p>
     编辑文件中的[libvirt]部分，/etc/nova/nova.conf如下所示：
    </p>
    <p>
     [libvirt]
     <br/>
     …
     <br/>
     virt_type = qemu
    </p>
    <p>
     启动 Compute 服务及其依赖项，并将它们配置为在系统启动时自动启动：
    </p>
    <p>
     systemctl enable libvirtd.service openstack-nova-compute.service
     <br/>
     systemctl start libvirtd.service openstack-nova-compute.service
    </p>
    <p>
     如果有遇到起不起来rabbitmq一直报连接不上的加下这条
    </p>
    <p>
     compute_driver=libvirt.LibvirtDriver
    </p>
    <p>
     将计算节点添加到单元数据库
     <br/>
     在控制器节点上运行以下命令：
     <br/>
     1.获取管理员凭据以启用仅限管理员的 CLI 命令，然后确认数据库中有计算主机：
    </p>
    <p>
     $ . admin-openrc
     <br/>
     $ openstack compute service list --service nova-compute
    </p>
    <p>
     2.发现计算主机
    </p>
    <p>
     su -s /bin/sh -c “nova-manage cell_v2 discover_hosts --verbose” nova
    </p>
    <p>
     11.neutron控制节点
     <br/>
     1.要创建数据库，请完成以下步骤：
     <br/>
     用数据库访问客户端以root用户身份连接数据库服务器：
    </p>
    <p>
     $ mysql -u root -p
    </p>
    <p>
     创建neutron数据库：
    </p>
    <p>
     MariaDB [(none)] CREATE DATABASE neutron;
    </p>
    <p>
     授予对neutron数据库的适当访问权限，替换 NEUTRON_DBPASS为合适的密码：
    </p>
    <p>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO ‘neutron’@‘localhost’ IDENTIFIED BY ‘NEUTRON_DBPASS’;
     <br/>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO ‘neutron’@‘%’ IDENTIFIED BY ‘NEUTRON_DBPASS’;
    </p>
    <p>
     退出数据库访问客户端。
     <br/>
     2.来源admin凭据来访问仅管理员CLI命令：
    </p>
    <p>
     $ . admin-openrc
    </p>
    <p>
     3.要创建服务凭证，请完成以下步骤：
     <br/>
     创建neutron用户：
    </p>
    <p>
     $ openstack user create --domain default --password-prompt neutron
    </p>
    <p>
     admin为neutron用户添加角色：
    </p>
    <p>
     $ openstack role add --project service --user neutron admin
    </p>
    <p>
     此命令不提供任何输出。
    </p>
    <p>
     创建neutron服务实体：
    </p>
    <p>
     $ openstack service create --name neutron
     <br/>
     –description “OpenStack Networking” network
    </p>
    <p>
     4.创建网络服务 API 端点：
    </p>
    <p>
     $ openstack endpoint create --region RegionOne
     <br/>
     network public http://controller:9696
     <br/>
     $ openstack endpoint create --region RegionOne
     <br/>
     network internal http://controller:9696
    </p>
    <p>
     $ openstack endpoint create --region RegionOne
     <br/>
     network admin http://controller:9696
    </p>
    <p>
     配置网络选项 可以使用以下两种体系结构之一部署网络服务 以选项1和2为代表。
    </p>
    <p>
     选项 1 部署了最简单的体系结构，该体系结构仅支持 将实例附加到提供商（外部）网络。没有自助服务（私人） 网络、路由器或浮动 IP
     <br/>
     地址。只有 或其他 特权用户可以管理提供商网络。admin
    </p>
    <p>
     选项 2 使用支持连接的第 1 层服务扩充选项 3 实例到自助服务网络。或其他非特权 用户可以管理自助服务网络，包括提供
     <br/>
     自助服务和提供商网络之间的连接。此外 浮动 IP 地址使用自助服务提供与实例的连接 来自外部网络（如互联网）的网络。demo
    </p>
    <p>
     自助服务网络通常使用覆盖网络。叠加网络 VXLAN 等协议包括增加开销的其他标头 并减少可用于有效负载或用户数据的空间。没有知识
     <br/>
     的虚拟网络基础结构，实例尝试发送数据包 使用默认以太网最大传输单元 （MTU） 1500 字节。网络服务自动提供正确的 MTU 值 通过
     <br/>
     DHCP 传输到实例。但是，某些云映像不使用 DHCP 或忽略 DHCP MTU 选项，并需要使用元数据或脚本进行配置。
    </p>
    <p>
     注意 选项 2 还支持将实例附加到提供商网络。
     <br/>
     选项1请参考官网：https://docs.openstack.org/neutron/train/install/controller-install-option1-rdo.html
     <br/>
     网络选项 2：自助服务网络
    </p>
    <p>
     yum install openstack-neutron openstack-neutron-ml2
     <br/>
     openstack-neutron-linuxbridge ebtables ipset -y
     <br/>
     配置服务器组件
     <br/>
     编辑/etc/neutron/neutron.conf文件并完成以下操作：
     <br/>
     #vi /etc/neutron/neutron.conf
     <br/>
     在该[database]部分中，配置数据库访问：
    </p>
    <p>
     [database]
     <br/>
     …
     <br/>
     connection = mysql+pymysql://neutron:NEUTRON_DBPASS@controller/neutron
    </p>
    <p>
     替换NEUTRON_DBPASS为您为数据库选择的密码。
    </p>
    <p>
     在该[DEFAULT]部分中，启用模块化第 2 层 (ML2) 插件、路由器服务和重叠 IP 地址：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     core_plugin = ml2
     <br/>
     service_plugins = router
     <br/>
     allow_overlapping_ips = true
    </p>
    <p>
     在该[DEFAULT]部分，配置RabbitMQ 消息队列访问：
    </p>
    <p>
     [DEFAULT]
     <br/>
     #…
     <br/>
     transport_url = rabbit://openstack:RABBIT_PASS@controller
    </p>
    <p>
     替换RABBIT_PASS为您openstack在 RabbitMQ 中为帐户选择的密码 。
    </p>
    <p>
     在[DEFAULT]和[keystone_authtoken]部分，配置身份服务访问：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     auth_strategy = keystone
    </p>
    <p>
     [keystone_authtoken]
     <br/>
     …
     <br/>
     www_authenticate_uri = http://controller:5000
     <br/>
     auth_url = http://controller:5000
     <br/>
     memcached_servers = controller:11211
     <br/>
     auth_type = password
     <br/>
     project_domain_name = default
     <br/>
     user_domain_name = default
     <br/>
     project_name = service
     <br/>
     username = neutron
     <br/>
     password = NEUTRON_PASS
    </p>
    <p>
     替换NEUTRON_PASS为您neutron 在身份服务中为用户选择的密码。
    </p>
    <p>
     注释掉或删除该[keystone_authtoken]部分中的任何其他选项 。
    </p>
    <p>
     在[DEFAULT]和[nova]部分中，配置 Networking 以通知 Compute 网络拓扑更改：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     notify_nova_on_port_status_changes = true
     <br/>
     notify_nova_on_port_data_changes = true
    </p>
    <p>
     [nova]
     <br/>
     …
     <br/>
     auth_url = http://controller:5000
     <br/>
     auth_type = password
     <br/>
     project_domain_name = default
     <br/>
     user_domain_name = default
     <br/>
     region_name = RegionOne
     <br/>
     project_name = service
     <br/>
     username = nova
     <br/>
     password = NOVA_PASS
    </p>
    <p>
     替换NOVA_PASS为您nova 在身份服务中为用户选择的密码。
    </p>
    <p>
     在该[oslo_concurrency]部分中，配置锁定路径：
    </p>
    <p>
     [oslo_concurrency]
     <br/>
     …
     <br/>
     lock_path = /var/lib/neutron/tmp
    </p>
    <p>
     配置模块化第 2 层 (ML2) 插件
     <br/>
     ML2 插件使用 Linux 桥接机制为实例构建第 2 层（桥接和交换）虚拟网络基础设施。
     <br/>
     编辑/etc/neutron/plugins/ml2/ml2_conf.ini文件并完成以下操作：
     <br/>
     #vi /etc/neutron/plugins/ml2/ml2_conf.ini
     <br/>
     在该[ml2]部分中，启用平面、VLAN 和 VXLAN 网络：
    </p>
    <p>
     [ml2]
     <br/>
     …
     <br/>
     type_drivers = flat,vlan,vxlan
    </p>
    <p>
     在该[ml2]部分中，启用 VXLAN 自助网络：
    </p>
    <p>
     [ml2]
     <br/>
     …
     <br/>
     tenant_network_types = vxlan
    </p>
    <p>
     在该[ml2]部分中，启用 Linux 桥接和二层填充机制：
    </p>
    <p>
     [ml2]
    </p>
    <p>
     …
     <br/>
     mechanism_drivers = linuxbridge,l2population
    </p>
    <p>
     警告 配置 ML2 插件后，删除type_drivers选项中的值 可能会导致数据库不一致。
    </p>
    <p>
     Linux 网桥代理仅支持 VXLAN 覆盖网络。
    </p>
    <p>
     在该[ml2]部分中，启用端口安全扩展驱动程序：
    </p>
    <p>
     [ml2]
     <br/>
     …
     <br/>
     extension_drivers = port_security
    </p>
    <p>
     在该[ml2_type_flat]部分中，将提供者虚拟网络配置为平面网络：
    </p>
    <p>
     [ml2_type_flat]
     <br/>
     …
     <br/>
     flat_networks = provider
    </p>
    <p>
     在该[ml2_type_vxlan]部分中，配置自助网络的 VXLAN 网络标识符范围：
    </p>
    <p>
     [ml2_type_vxlan]
     <br/>
     #…
     <br/>
     vni_ranges = 1:1000
    </p>
    <p>
     在该[securitygroup]部分中，启用ipset以提高安全组规则的效率：
    </p>
    <p>
     [securitygroup]
     <br/>
     …
     <br/>
     enable_ipset = true
    </p>
    <p>
     配置 Linux 网桥代理
     <br/>
     Linux 桥接代理为实例构建第 2 层（桥接和交换）虚拟网络基础架构并处理安全组。
     <br/>
     编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件并完成以下操作：
     <br/>
     在该[linux_bridge]部分中，将提供者虚拟网络映射到提供者物理网络接口：
    </p>
    <p>
     [linux_bridge]
     <br/>
     physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME
    </p>
    <p>
     替换PROVIDER_INTERFACE_NAME为底层提供者物理网络接口的名称。ens33
     <br/>
     在该[vxlan]部分中，启用VXLAN覆盖网络，配置处理覆盖网络的物理网络接口的IP地址，并启用二层填充：
    </p>
    <p>
     [vxlan]
     <br/>
     enable_vxlan = true
     <br/>
     local_ip = OVERLAY_INTERFACE_IP_ADDRESS
     <br/>
     l2_population = true
    </p>
    <p>
     替换OVERLAY_INTERFACE_IP_ADDRESS为处理覆盖网络的底层物理网络接口的 IP 地址。示例架构使用管理接口将流量隧道传输到其他节点。因此，替换OVERLAY_INTERFACE_IP_ADDRESS为控制器节点的管理 IP 地址。有关详细信息，请参阅 主机网络。
    </p>
    <p>
     在该[securitygroup]部分中，启用安全组并配置 Linux 网桥 iptables 防火墙驱动程序：
    </p>
    <p>
     [securitygroup]
     <br/>
     …
     <br/>
     enable_security_group = true
     <br/>
     firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver
    </p>
    <p>
     通过验证以下所有sysctl值都设置为，确保您的 Linux 操作系统内核支持网桥过滤器1：
     <br/>
     编辑/etc/sysctl.conf加入：
    </p>
    <p>
     net.bridge.bridge-nf-call-iptables = 1
     <br/>
     net.bridge.bridge-nf-call-ip6tables = 1
    </p>
    <p>
     保存退出，输入modprobe br_netfilter加载内核模块，最后sysctl -p查看是否生效
    </p>
    <p>
     modprobe br_netfilter
     <br/>
     sysctl -p
    </p>
    <p>
     要启用网络桥接支持，通常br_netfilter需要加载内核模块。有关启用此模块的其他详细信息，请查看操作系统的文档。
    </p>
    <p>
     配置三层代理
     <br/>
     第 3 层 (L3) 代理为自助服务虚拟网络提供路由和 NAT 服务。
    </p>
    <p>
     编辑/etc/neutron/l3_agent.ini文件并完成以下操作：
    </p>
    <p>
     在该[DEFAULT]部分中，配置 Linux 桥接接口驱动程序：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     interface_driver = linuxbridge
    </p>
    <p>
     配置 DHCP 代理
     <br/>
     DHCP 代理为虚拟网络提供 DHCP 服务。
     <br/>
     编辑/etc/neutron/dhcp_agent.ini文件并完成以下操作：
     <br/>
     在该[DEFAULT]部分中，配置 Linux 桥接接口驱动程序、Dnsmasq DHCP 驱动程序，并启用隔离元数据，以便提供商网络上的实例可以通过网络访问元数据：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     interface_driver = linuxbridge
     <br/>
     dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
     <br/>
     enable_isolated_metadata = true
    </p>
    <p>
     配置元数据代理
     <br/>
     元数据代理向实例提供配置信息，例如凭据。
    </p>
    <p>
     编辑/etc/neutron/metadata_agent.ini文件并完成以下操作：
    </p>
    <p>
     在该[DEFAULT]部分中，配置元数据主机和共享密钥：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     nova_metadata_host = controller
     <br/>
     metadata_proxy_shared_secret = METADATA_SECRET
    </p>
    <p>
     替换METADATA_SECRET为元数据代理的合适密钥。
    </p>
    <p>
     配置 Compute 服务以使用 Networking 服务
    </p>
    <p>
     笔记 必须安装 Nova 计算服务才能完成此步骤。有关更多详细信息，请参阅文档网站安装指南部分下的计算安装指南 。
    </p>
    <p>
     编辑/etc/nova/nova.conf文件并执行以下操作：
    </p>
    <p>
     在该[neutron]部分中，配置访问参数，启用元数据代理，并配置密钥：
    </p>
    <p>
     [neutron]
     <br/>
     …
     <br/>
     auth_url = http://controller:5000
     <br/>
     auth_type = password
     <br/>
     project_domain_name = default
     <br/>
     user_domain_name = default
     <br/>
     region_name = RegionOne
     <br/>
     project_name = service
     <br/>
     username = neutron
     <br/>
     password = NEUTRON_PASS
     <br/>
     service_metadata_proxy = true
     <br/>
     metadata_proxy_shared_secret = METADATA_SECRET
    </p>
    <p>
     替换NEUTRON_PASS为您neutron 在身份服务中为用户选择的密码。
     <br/>
     替换METADATA_SECRET为您为元数据代理选择的机密。
     <br/>
     请参阅计算服务配置指南 以获取完整的选项集，包括必要时覆盖服务目录端点 URL。
    </p>
    <p>
     完成安装
     <br/>
     1.网络服务初始化脚本需要一个/etc/neutron/plugin.ini指向 ML2 插件配置文件的符号链接 /etc/neutron/plugins/ml2/ml2_conf.ini。如果此符号链接不存在，请使用以下命令创建它：
    </p>
    <p>
     ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini
    </p>
    <p>
     2.填充数据库：
    </p>
    <p>
     su -s /bin/sh -c “neutron-db-manage --config-file /etc/neutron/neutron.conf
     <br/>
     –config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head” neutron
    </p>
    <p>
     3.重启计算 API 服务：
    </p>
    <p>
     systemctl restart openstack-nova-api.service
    </p>
    <p>
     4.启动网络服务并将它们配置为在系统启动时启动。
    </p>
    <p>
     对于两个网络选项：
    </p>
    <p>
     systemctl enable neutron-server.service
     <br/>
     neutron-linuxbridge-agent.service neutron-dhcp-agent.service
     <br/>
     neutron-metadata-agent.service
     <br/>
     systemctl start neutron-server.service
     <br/>
     neutron-linuxbridge-agent.service neutron-dhcp-agent.service
     <br/>
     neutron-metadata-agent.service
    </p>
    <p>
     对于网络选项 2，还启用并启动第 3 层服务：
    </p>
    <p>
     systemctl enable neutron-l3-agent.service
     <br/>
     systemctl start neutron-l3-agent.service
    </p>
    <p>
     12.neutron计算节点
     <br/>
     安装组件
    </p>
    <p>
     yum install openstack-neutron-linuxbridge ebtables ipset -y
    </p>
    <p>
     配置通用组件
     <br/>
     Networking 通用组件配置包括身份验证机制、消息队列和插件。
    </p>
    <p>
     编辑/etc/neutron/neutron.conf文件并完成以下操作：
     <br/>
     在该[database]部分中，注释掉所有connection选项，因为计算节点不直接访问数据库。
     <br/>
     在该[DEFAULT]部分，配置RabbitMQ 消息队列访问：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     transport_url = rabbit://openstack:RABBIT_PASS@controller
    </p>
    <p>
     替换RABBIT_PASS为您openstack 在 RabbitMQ 中为帐户选择的密码。
    </p>
    <p>
     在[DEFAULT]和[keystone_authtoken]部分，配置身份服务访问：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     auth_strategy = keystone
    </p>
    <p>
     [keystone_authtoken]
     <br/>
     …
     <br/>
     www_authenticate_uri = http://controller:5000
     <br/>
     auth_url = http://controller:5000
     <br/>
     memcached_servers = controller:11211
     <br/>
     auth_type = password
     <br/>
     project_domain_name = default
     <br/>
     user_domain_name = default
     <br/>
     project_name = service
     <br/>
     username = neutron
     <br/>
     password = NEUTRON_PASS
    </p>
    <p>
     替换NEUTRON_PASS为您neutron 在身份服务中为用户选择的密码。
    </p>
    <p>
     在该[oslo_concurrency]部分中，配置锁定路径：
    </p>
    <p>
     [oslo_concurrency]
     <br/>
     …
     <br/>
     lock_path = /var/lib/neutron/tmp
    </p>
    <p>
     在计算节点上配置网络组件。
    </p>
    <p>
     配置 Linux 网桥代理
     <br/>
     Linux 桥接代理为实例构建第 2 层（桥接和交换）虚拟网络基础架构并处理安全组。
    </p>
    <p>
     编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件并完成以下操作：
    </p>
    <p>
     在该[linux_bridge]部分中，将提供者虚拟网络映射到提供者物理网络接口：
    </p>
    <p>
     [linux_bridge]
     <br/>
     physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME
    </p>
    <p>
     替换PROVIDER_INTERFACE_NAME为底层提供者物理网络接口的名称。有关 详细信息，请参阅主机网络。
    </p>
    <p>
     在该[vxlan]部分中，启用VXLAN覆盖网络，配置处理覆盖网络的物理网络接口的IP地址，并启用二层填充：
    </p>
    <p>
     [vxlan]
     <br/>
     enable_vxlan = true
     <br/>
     local_ip = OVERLAY_INTERFACE_IP_ADDRESS
     <br/>
     l2_population = true
    </p>
    <p>
     替换OVERLAY_INTERFACE_IP_ADDRESS为处理覆盖网络的底层物理网络接口的 IP 地址。示例架构使用管理接口将流量隧道传输到其他节点。因此，替换OVERLAY_INTERFACE_IP_ADDRESS为计算节点的管理IP地址。有关详细信息，请参阅 主机网络。
    </p>
    <p>
     在该[securitygroup]部分中，启用安全组并配置 Linux 网桥 iptables 防火墙驱动程序：
    </p>
    <p>
     [securitygroup]
     <br/>
     …
     <br/>
     enable_security_group = true
     <br/>
     firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver
    </p>
    <p>
     通过验证以下所有sysctl值都设置为，确保您的 Linux 操作系统内核支持网桥过滤器1：
     <br/>
     编辑/etc/sysctl.conf加入：
    </p>
    <p>
     net.bridge.bridge-nf-call-iptables = 1
     <br/>
     net.bridge.bridge-nf-call-ip6tables = 1
    </p>
    <p>
     保存退出，输入modprobe br_netfilter加载内核模块，最后sysctl -p查看是否生效
    </p>
    <p>
     modprobe br_netfilter
     <br/>
     sysctl -p
    </p>
    <p>
     要启用网络桥接支持，通常br_netfilter需要加载内核模块。有关启用此模块的其他详细信息，请查看操作系统的文档。
    </p>
    <p>
     配置 Compute 服务以使用 Networking 服务
     <br/>
     编辑/etc/nova/nova.conf文件并完成以下操作：
    </p>
    <p>
     在该[neutron]部分，配置访问参数：
    </p>
    <p>
     [neutron]
     <br/>
     …
     <br/>
     auth_url = http://controller:5000
     <br/>
     auth_type = password
     <br/>
     project_domain_name = default
     <br/>
     user_domain_name = default
     <br/>
     region_name = RegionOne
     <br/>
     project_name = service
     <br/>
     username = neutron
     <br/>
     password = NEUTRON_PASS
    </p>
    <p>
     替换NEUTRON_PASS为您neutron 在身份服务中为用户选择的密码。
    </p>
    <p>
     完成安装
     <br/>
     1.重启计算服务：
    </p>
    <p>
     systemctl restart openstack-nova-compute.service
    </p>
    <p>
     2.启动 Linux 网桥代理并将其配置为在系统启动时启动：
    </p>
    <p>
     systemctl enable neutron-linuxbridge-agent.service
     <br/>
     systemctl start neutron-linuxbridge-agent.service
    </p>
    <p>
     13.dashboard：
     <br/>
     本节假设使用 Apache HTTP 服务器和 Memcached 服务正确安装、配置和操作 Identity 服务。
     <br/>
     安装和配置组件
     <br/>
     1.安装软件包：
    </p>
    <p>
     yum install openstack-dashboard -y
    </p>
    <p>
     2.编辑 /etc/openstack-dashboard/local_settings 文件并完成以下操作：
     <br/>
     配置仪表板以在controller节点上使用 OpenStack 服务 ：
    </p>
    <p>
     OPENSTACK_HOST = “controller”
     <br/>
     ALLOWED_HOSTS = [‘horizon.example.com’, ‘*’]
     <br/>
     SESSION_ENGINE = ‘django.contrib.sessions.backends.cache’
     <br/>
     CACHES = {
     <!-- -->
     <br/>
     ‘default’: {
     <!-- -->
     <br/>
     ‘BACKEND’:
     <br/>
     ‘django.core.cache.backends.memcached.MemcachedCache’,
     <br/>
     ‘LOCATION’: ‘controller:11211’,
     <br/>
     }
     <br/>
     }
     <br/>
     OPENSTACK_KEYSTONE_URL = “http://%s:5000/v3” % OPENSTACK_HOST
     <br/>
     OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True
     <br/>
     OPENSTACK_API_VERSIONS = {
     <!-- -->
     <br/>
     “identity”: 3,
     <br/>
     “image”: 2,
     <br/>
     “volume”: 3,
     <br/>
     }
     <br/>
     OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = “Default”
     <br/>
     OPENSTACK_KEYSTONE_DEFAULT_ROLE = “user”
     <br/>
     OPENSTACK_NEUTRON_NETWORK = {
     <!-- -->
     <br/>
     ‘enable_lb’: False,
     <br/>
     ‘enable_firewall’: False,
     <br/>
     ‘enable_vpn’: False,
     <br/>
     ‘enable_auto_allocated_network’: False,
     <br/>
     ‘enable_distributed_router’: False,
     <br/>
     ‘enable_fip_topology_check’: False,
     <br/>
     ‘enable_ha_router’: False,
     <br/>
     ‘enable_ipv6’: False,
     <br/>
     ‘enable_quotas’: False,
     <br/>
     ‘enable_rbac_policy’: False,
     <br/>
     ‘enable_router’: False,
     <br/>
     }
     <br/>
     TIME_ZONE = “Asia/Shanghai”
     <br/>
     WEBROOT=“/dashboard”
    </p>
    <p>
     替换TIME_ZONE为适当的时区标识符。有关更多信息，请参阅时区列表。
    </p>
    <p>
     /etc/httpd/conf.d/openstack-dashboard.conf如果不包括，则添加以下行 。
    </p>
    <p>
     WSGIApplicationGroup %{GLOBAL}
    </p>
    <p>
     完成安装
     <br/>
     重新启动 Web 服务器和会话存储服务：
    </p>
    <p>
     systemctl restart httpd.service memcached.service
    </p>
    <p>
     14.cinder控制节点
     <br/>
     1.使用数据库访问客户端以root用户身份连接数据库服务器：
    </p>
    <p>
     $ mysql -u root -p
    </p>
    <p>
     创建cinder数据库：
    </p>
    <p>
     MariaDB [(none)]&gt; CREATE DATABASE cinder;
    </p>
    <p>
     授予对cinder数据库的适当访问权限：
    </p>
    <p>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON cinder.* TO ‘cinder’@‘localhost’
     <br/>
     IDENTIFIED BY ‘CINDER_DBPASS’;
     <br/>
     MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON cinder.* TO ‘cinder’@‘%’
     <br/>
     IDENTIFIED BY ‘CINDER_DBPASS’;
    </p>
    <p>
     替换CINDER_DBPASS为合适的密码。
     <br/>
     退出数据库访问客户端。
    </p>
    <p>
     2.来源admin凭据来访问仅管理员CLI命令：
    </p>
    <p>
     $ . admin-openrc
    </p>
    <p>
     3.要创建服务凭证，请完成以下步骤：
     <br/>
     创建cinder用户：
    </p>
    <p>
     $ openstack user create --domain default --password-prompt cinder
    </p>
    <p>
     admin为cinder用户添加角色：
    </p>
    <p>
     $ openstack role add --project service --user cinder admin
    </p>
    <p>
     创建cinderv2和cinderv3服务实体：
    </p>
    <p>
     $ openstack service create --name cinderv2
     <br/>
     –description “OpenStack Block Storage” volumev2
    </p>
    <p>
     $ openstack service create --name cinderv3
     <br/>
     –description “OpenStack Block Storage” volumev3
    </p>
    <p>
     （块存储服务需要两个服务实体。）
    </p>
    <p>
     4.创建块存储服务 API 端点：
    </p>
    <p>
     $ openstack endpoint create --region RegionOne
     <br/>
     volumev2 public http://controller:8776/v2/%(project_id)s
     <br/>
     $ openstack endpoint create --region RegionOne
     <br/>
     volumev2 internal http://controller:8776/v2/%(project_id)s
     <br/>
     $ openstack endpoint create --region RegionOne
     <br/>
     volumev2 admin http://controller:8776/v2/%(project_id)s
     <br/>
     $ openstack endpoint create --region RegionOne
     <br/>
     volumev3 public http://controller:8776/v3/%(project_id)s
     <br/>
     $ openstack endpoint create --region RegionOne
     <br/>
     volumev3 internal http://controller:8776/v3/%(project_id)s
     <br/>
     $ openstack endpoint create --region RegionOne
     <br/>
     volumev3 admin http://controller:8776/v3/%(project_id)s
    </p>
    <p>
     （块存储服务需要每个服务实体的端点。）
    </p>
    <p>
     安装和配置组件
     <br/>
     1.安装软件包：
    </p>
    <p>
     yum install openstack-cinder -y
    </p>
    <p>
     2.编辑/etc/cinder/cinder.conf文件并完成以下操作：
     <br/>
     #vi /etc/cinder/cinder.conf
     <br/>
     在该[database]部分中，配置数据库访问：
    </p>
    <p>
     [database]
     <br/>
     …
     <br/>
     connection = mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder
    </p>
    <p>
     替换CINDER_DBPASS为您为 Block Storage 数据库选择的密码。
    </p>
    <p>
     在该[DEFAULT]部分，配置RabbitMQ 消息队列访问：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     transport_url = rabbit://openstack:RABBIT_PASS@controller
    </p>
    <p>
     替换RABBIT_PASS为您为 中的openstack帐户选择的密码 RabbitMQ。
    </p>
    <p>
     在[DEFAULT]和[keystone_authtoken]部分，配置身份服务访问：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     auth_strategy = keystone
    </p>
    <p>
     [keystone_authtoken]
     <br/>
     …
     <br/>
     www_authenticate_uri = http://controller:5000
     <br/>
     auth_url = http://controller:5000
     <br/>
     memcached_servers = controller:11211
     <br/>
     auth_type = password
     <br/>
     project_domain_name = default
     <br/>
     user_domain_name = default
     <br/>
     project_name = service
     <br/>
     username = cinder
     <br/>
     password = CINDER_PASS
    </p>
    <p>
     替换CINDER_PASS为您cinder在身份服务中为用户选择的密码。
    </p>
    <p>
     注释掉或删除该[keystone_authtoken]部分中的任何其他选项 。
    </p>
    <p>
     在该[DEFAULT]部分中，配置my_ip选项以使用控制器节点的管理接口 IP 地址：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     my_ip = 192.168.44.3
    </p>
    <p>
     3.在该[oslo_concurrency]部分中，配置锁定路径：
    </p>
    <p>
     [oslo_concurrency]
     <br/>
     …
     <br/>
     lock_path = /var/lib/cinder/tmp
    </p>
    <p>
     4.填充块存储数据库：
    </p>
    <p>
     su -s /bin/sh -c “cinder-manage db sync” cinder
    </p>
    <p>
     （忽略此输出中的任何弃用消息。）
    </p>
    <p>
     配置 Compute 以使用块存储
     <br/>
     1.编辑/etc/nova/nova.conf文件并将以下内容添加到其中：
    </p>
    <p>
     [cinder]
     <br/>
     os_region_name = RegionOne
    </p>
    <p>
     完成安装
     <br/>
     1.重启计算 API 服务：
    </p>
    <p>
     systemctl restart openstack-nova-api.service
    </p>
    <p>
     2.启动块存储服务并配置它们在系统启动时启动：
    </p>
    <p>
     systemctl enable openstack-cinder-api.service openstack-cinder-scheduler.service
     <br/>
     systemctl start openstack-cinder-api.service openstack-cinder-scheduler.service
    </p>
    <p>
     15.cinder计算节点
     <br/>
     1.安装支持的实用程序包：
     <br/>
     安装 LVM 包：
    </p>
    <p>
     yum install lvm2 device-mapper-persistent-data
    </p>
    <p>
     启动 LVM 元数据服务并将其配置为在系统启动时启动：
    </p>
    <p>
     systemctl enable lvm2-lvmetad.service
     <br/>
     systemctl start lvm2-lvmetad.service
    </p>
    <p>
     2.创建 LVM 物理卷/dev/sdb;
    </p>
    <p>
     $ pvcreate /dev/sdb
     <br/>
     Physical volume “/dev/sda1” successfully created
    </p>
    <p>
     3.创建 LVM 卷组cinder-volumes：
    </p>
    <p>
     $ vgcreate cinder-volumes /dev/sdb
     <br/>
     Volume group “cinder-volumes” successfully created
    </p>
    <p>
     Block Storage 服务在这个卷组中创建逻辑卷。
    </p>
    <p>
     4.只有实例可以访问块存储卷。但是，底层操作系统管理与卷关联的设备。默认情况下，LVM 卷扫描工具会扫描/dev包含卷的块存储设备的 目录。如果项目在其卷上使用 LVM，扫描工具会检测这些卷并尝试缓存它们，这可能会导致底层操作系统和项目卷出现各种问题。您必须重新配置 LVM 以仅扫描包含cinder-volumes卷组的设备。编辑 /etc/lvm/lvm.conf文件并完成以下操作：
     <br/>
     在该devices部分中，添加一个接受/dev/sdb设备并拒绝所有其他设备的过滤 器：
    </p>
    <p>
     devices {
     <!-- -->
     <br/>
     …
     <br/>
     filter = [ “a/sdb/”, “r/.*/”]
    </p>
    <p>
     滤波器阵列中的每个项目开始于a用于接受或 r用于拒绝，并且包括用于所述装置名称的正则表达式。该阵列必须r/.*/以拒绝任何剩余设备结束。您可以使用vgs -vvvv命令来测试过滤器。
    </p>
    <p>
     警告 如果您的存储节点在操作系统磁盘上使用 LVM，您还必须将关联的设备添加到过滤器中。例如，如果/dev/sda设备包含操作系统：
     <br/>
     filter = [ “a/sda/”, “a/sdb/”, “r/./"] 同样，如果您的计算节点在操作系统磁盘上使用
     <br/>
     LVM，您还必须修改/etc/lvm/lvm.conf这些节点上文件中的过滤器 以仅包含操作系统磁盘。例如，如果/dev/sda
     <br/>
     设备包含操作系统： filter = [ “a/sda/”, "r/./”]
    </p>
    <p>
     安装和配置组件
     <br/>
     1.安装软件包：
    </p>
    <p>
     yum install openstack-cinder targetcli python-keystone -y
    </p>
    <p>
     2.编辑/etc/cinder/cinder.conf文件并完成以下操作：
     <br/>
     在该[database]部分中，配置数据库访问：
    </p>
    <p>
     [database]
     <br/>
     …
     <br/>
     connection = mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder
    </p>
    <p>
     替换CINDER_DBPASS为您为 Block Storage 数据库选择的密码。
    </p>
    <p>
     在该[DEFAULT]部分，配置RabbitMQ 消息队列访问：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     transport_url = rabbit://openstack:RABBIT_PASS@controller
    </p>
    <p>
     替换RABBIT_PASS为您为 中的openstack帐户选择的密码。
    </p>
    <p>
     在[DEFAULT]和[keystone_authtoken]部分，配置身份服务访问：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     auth_strategy = keystone
    </p>
    <p>
     [keystone_authtoken]
     <br/>
     …
     <br/>
     www_authenticate_uri = http://controller:5000
     <br/>
     auth_url = http://controller:5000
     <br/>
     memcached_servers = controller:11211
     <br/>
     auth_type = password
     <br/>
     project_domain_name = default
     <br/>
     user_domain_name = default
     <br/>
     project_name = service
     <br/>
     username = cinder
     <br/>
     password = CINDER_PASS
    </p>
    <p>
     替换CINDER_PASS为您cinder在身份服务中为用户选择的密码 。
    </p>
    <p>
     注释掉或删除该[keystone_authtoken]部分中的任何其他选项 。
    </p>
    <p>
     在该[DEFAULT]部分中，配置my_ip选项：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     my_ip = MANAGEMENT_INTERFACE_IP_ADDRESS
    </p>
    <p>
     替换MANAGEMENT_INTERFACE_IP_ADDRESS为存储节点上管理网络接口的 IP 地址
    </p>
    <p>
     在该[lvm]部分中，使用 LVM 驱动程序、cinder-volumes卷组、iSCSI 协议和适当的 iSCSI 服务配置 LVM 后端。如果该[lvm]部分不存在，请创建它：
    </p>
    <p>
     [lvm]
     <br/>
     volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
     <br/>
     volume_group = cinder-volumes
     <br/>
     target_protocol = iscsi
     <br/>
     target_helper = lioadm
    </p>
    <p>
     在该[DEFAULT]部分中，启用 LVM 后端：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     enabled_backends = lvm
    </p>
    <p>
     后端名称是任意的。例如，本指南使用驱动程序的名称作为后端的名称。
    </p>
    <p>
     在该[DEFAULT]部分中，配置 Image 服务 API 的位置：
    </p>
    <p>
     [DEFAULT]
     <br/>
     …
     <br/>
     glance_api_servers = http://controller:9292
    </p>
    <p>
     在该[oslo_concurrency]部分中，配置锁定路径：
    </p>
    <p>
     [oslo_concurrency]
     <br/>
     #…
     <br/>
     lock_path = /var/lib/cinder/tmp
    </p>
    <p>
     完成安装
     <br/>
     启动 Block Storage 卷服务及其依赖项，并将它们配置为在系统启动时启动：
    </p>
    <p>
     systemctl enable openstack-cinder-volume.service target.service
     <br/>
     systemctl start openstack-cinder-volume.service target.service
    </p>
    <p>
     登录dsahboard
    </p>
    <p>
     http://192.168.44.3/dashboard
    </p>
    <p>
     控制节点ip登录
    </p>
    <p>
     下面进行安装好openstack后的操作，在控制节点上，加载. admin-openrc后进行创建网络、规格、安全组、密钥等
    </p>
    <p>
     创建网络：
    </p>
    <p>
     openstack network create --share --external --provider-physical-network provider --provider-network-type flat provider
     <br/>
     openstack subnet create --network provider --allocation-pool start=192.168.44.10,end=192.168.50.254 --gateway 192.168.0.254 --subnet-range 192.168.0.0/16 provider
    </p>
    <p>
     创建规格：
    </p>
    <p>
     openstack flavor create --id 0 --vcpus 1 --ram 64 --disk 1 m1.nano
    </p>
    <p>
     创建密钥对：
    </p>
    <p>
     ssh-keygen -q -N “”
     <br/>
     openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey
    </p>
    <p>
     创建安全组并允许SSH访问：
    </p>
    <p>
     openstack security group rule create --proto icmp default
     <br/>
     openstack security group rule create --proto tcp --dst-port 22 default
    </p>
    <p>
     创建个user的，不然后面创建项目创建用户会报找不到token
    </p>
    <p>
     openstack role create user
    </p>
    <p>
     创建一个镜像文件
    </p>
    <p>
     Touch cirros-0.5.2-x86_64-disk.img
    </p>
    <p>
     上传镜像：
    </p>
    <p>
     openstack image create NEW_IMAGE_NAME --container-format bare --disk-format qcow2 --file IMAGE_URL
    </p>
    <p>
     最后，在dashboard界面台中创建实例吧
    </p>
    <p>
     openstack云镜像下载地址：https://cloud.centos.org/centos/7/images/
     <br/>
     官方文档：https://docs.openstack.org/install-guide/
    </p>
    <p>
     参考：
     <br/>
     https://www.cnblogs.com/powell/p/17958801
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f67:2e6373646e2e6e65742f73696e61745f32363830393235352f:61727469636c652f64657461696c732f313436303939383732" class_="artid" style="display:none">
 </p>
</div>


