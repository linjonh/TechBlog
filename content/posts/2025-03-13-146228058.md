---
layout: post
title: "计算机视觉超详细Meta视觉大模型Segment-AnythingSAM源码解剖"
date: 2025-03-13 13:11:21 +0800
description: "在计算机视觉领域，图像分割是一个核心且具有挑战性的任务，旨在将图像中的不同物体或区域进行划分和识别，广泛应用于自动驾驶、医学影像分析、安防监控等领域。Segment Anything Model（SAM）由 Meta AI 实验室发布，其引入了基于 Prompt 的交互式分割能力，显著提升了图像分割的灵活性和泛化能力。"
keywords: "计算机视觉｜超详细！Meta视觉大模型Segment Anything（SAM）源码解剖"
categories: ['计算机视觉', '炼金厂', '深度学习', 'Ai']
tags: ['计算机视觉', '机器学习', '人工智能', 'Sam', 'Sam']
artid: "146228058"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146228058
    alt: "计算机视觉超详细Meta视觉大模型Segment-AnythingSAM源码解剖"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146228058
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146228058
cover: https://bing.ee123.net/img/rand?artid=146228058
image: https://bing.ee123.net/img/rand?artid=146228058
img: https://bing.ee123.net/img/rand?artid=146228058
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     计算机视觉｜超详细！Meta视觉大模型Segment Anything（SAM）源码解剖
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-github-gist" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="font_color311b92font_0">
     </a>
     <font color="#311b92">
      一、引言
     </font>
    </h3>
    <p>
     在计算机视觉领域，图像分割是一个核心且具有挑战性的任务，旨在将图像中的不同物体或区域进行划分和识别，广泛应用于自动驾驶、医学影像分析、安防监控等领域。Segment Anything Model（SAM）由 Meta AI 实验室发布，其引入了基于
     <strong>
      Prompt 的交互式分割能力
     </strong>
     ，显著提升了图像分割的灵活性和泛化能力。
    </p>
    <p>
     SAM 通过在海量且多样化的数据集上训练，具备处理未见过对象类别和场景的能力。这一特性使其在学术界引发广泛研究，如模型轻量化、领域适应、多模态融合等方向；在工业界也迅速应用于医学图像分析中的肿瘤检测、遥感图像处理中的卫星图像分析以及视频处理中的目标跟踪等领域。
    </p>
    <p>
     对于计算机视觉爱好者和开发者而言，深入剖析 SAM 的源码有助于理解其核心技术原理，为进一步创新和应用提供基础。本文将从原理到源码逐步解析 SAM 的工作机制，探索其实现高效图像编码、提示编码及掩码解码的过程。
    </p>
    <h3>
     <a id="font_color311b92SAM_font_8">
     </a>
     <font color="#311b92">
      二、SAM 原理速览
     </font>
    </h3>
    <h4>
     <a id="font_color311b92font_10">
     </a>
     <font color="#311b92">
      （一）核心概念
     </font>
    </h4>
    <p>
     SAM 的核心在于其
     <strong>
      “分割一切”
     </strong>
     的能力，这一能力依赖于基于 Prompt 的分割策略。Prompt 可以是点（points）、框（boxes）、掩码（masks）或文本（text），为模型提供分割目标的关键信息。例如，点击图像中的一个点，SAM 能够识别并分割该点所在物体；给定一个框，SAM 则专注于框内物体的分割。
    </p>
    <h4>
     <a id="font_color311b92font_14">
     </a>
     <font color="#311b92">
      （二）模型架构
     </font>
    </h4>
    <p>
     SAM 的架构包含三个核心组件：
     <strong>
      Image Encoder（图像编码器）
     </strong>
     、
     <strong>
      Prompt Encoder（提示编码器）
     </strong>
     和
     <strong>
      Mask Decoder（掩码解码器）
     </strong>
     ，其协作方式如下图所示：
     <br/>
     <img alt="图 1：SAM 模型架构示意图，展示图像编码、提示编码及掩码解码的协作流程" src="https://i-blog.csdnimg.cn/direct/1d635cb1866941779e758790a481d340.png"/>
    </p>
    <ul>
     <li>
      <strong>
       Image Encoder
      </strong>
      ：将输入图像转换为高维特征表示，通常使用预训练的 Vision Transformer（ViT），如 ViT-H、ViT-L、ViT-B。例如，对于分辨率为
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         1024 
         
        
          × 
         
        
          1024 
         
        
       
         1024 \times 1024
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;">
          </span>
          <span class="mord">
           1024
          </span>
          <span class="mspace" style="margin-right: 0.2222em;">
          </span>
          <span class="mbin">
           ×
          </span>
          <span class="mspace" style="margin-right: 0.2222em;">
          </span>
         </span>
         <span class="base">
          <span class="strut" style="height: 0.6444em;">
          </span>
          <span class="mord">
           1024
          </span>
         </span>
        </span>
       </span>
      </span>
      的图像，经过 Patch Embedding 操作划分为
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         16 
         
        
          × 
         
        
          16 
         
        
       
         16 \times 16
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;">
          </span>
          <span class="mord">
           16
          </span>
          <span class="mspace" style="margin-right: 0.2222em;">
          </span>
          <span class="mbin">
           ×
          </span>
          <span class="mspace" style="margin-right: 0.2222em;">
          </span>
         </span>
         <span class="base">
          <span class="strut" style="height: 0.6444em;">
          </span>
          <span class="mord">
           16
          </span>
         </span>
        </span>
       </span>
      </span>
      的 patches，特征图尺寸缩小为原来的
      <span class="katex--inline">
       <span class="katex">
        <span class="katex-mathml">
         1 
          
         
           16 
          
         
        
       
         \frac{1}{16}
        </span>
        <span class="katex-html">
         <span class="base">
          <span class="strut" style="height: 1.1901em; vertical-align: -0.345em;">
          </span>
          <span class="mord">
           <span class="mopen nulldelimiter">
           </span>
           <span class="mfrac">
            <span class="vlist-t vlist-t2">
             <span class="vlist-r">
              <span class="vlist" style="height: 0.8451em;">
               <span class="" style="top: -2.655em;">
                <span class="pstrut" style="height: 3em;">
                </span>
                <span class="sizing reset-size6 size3 mtight">
                 <span class="mord mtight">
                  <span class="mord mtight">
                   16
                  </span>
                 </span>
                </span>
               </span>
               <span class="" style="top: -3.23em;">
                <span class="pstrut" style="height: 3em;">
                </span>
                <span class="frac-line" style="border-bottom-width: 0.04em;">
                </span>
               </span>
               <span class="" style="top: -3.394em;">
                <span class="pstrut" style="height: 3em;">
                </span>
                <span class="sizing reset-size6 size3 mtight">
                 <span class="mord mtight">
                  <span class="mord mtight">
                   1
                  </span>
                 </span>
                </span>
               </span>
              </span>
              <span class="vlist-s">
               ​
              </span>
             </span>
             <span class="vlist-r">
              <span class="vlist" style="height: 0.345em;">
               <span class="">
               </span>
              </span>
             </span>
            </span>
           </span>
           <span class="mclose nulldelimiter">
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
      ，通道数从 3 映射到 768。
     </li>
     <li>
      <strong>
       Prompt Encoder
      </strong>
      ：处理不同类型的 Prompt，将其编码为与图像嵌入兼容的特征。对点和框使用位置编码（Positional Encoding）；对文本使用 CLIP 文本编码器；对掩码则通过轻量级卷积网络编码。
     </li>
     <li>
      <strong>
       Mask Decoder
      </strong>
      ：融合图像嵌入和提示嵌入，通过 Transformer 结构解码为分割掩码，默认生成 3 个候选掩码并按置信度排序。
     </li>
    </ul>
    <h3>
     <a id="font_color311b92font_23">
     </a>
     <font color="#311b92">
      三、源码结构总览
     </font>
    </h3>
    <h4>
     <a id="font_color311b92font_25">
     </a>
     <font color="#311b92">
      （一）代码目录解析
     </font>
    </h4>
    <p>
     SAM 的代码目录结构如下：
    </p>
    <pre><code>segment-anything/
├── assets              # 示例图片等资源
├── demo                # 前端部署代码
├── notebooks           # Jupyter Notebook 示例
├── script              # 模型导出脚本
├── segment_anything    # 核心代码目录
│   ├── build_sam.py    # 模型构建脚本
│   ├── config.py       # 配置文件
│   ├── mask_decoder.py # 掩码解码器实现
│   ├── model_registry.py # 模型注册模块
│   ├── predictor.py    # 预测接口
│   ├── sam.py          # SAM 整体结构
│   ├── sam_arch.py     # 架构细节
│   ├── utils.py        # 工具函数
│   └── automatic_mask_generator.py # 自动掩码生成
└── setup.py            # 安装脚本
</code></pre>
    <p>
     <strong>
      segment_anything
     </strong>
     是核心目录，后续分析将聚焦于此。
    </p>
    <h4>
     <a id="font_color311b92font_50">
     </a>
     <font color="#311b92">
      （二）关键文件与模块
     </font>
    </h4>
    <ul>
     <li>
      <strong>
       build_sam.py
      </strong>
      ：定义模型构建函数，支持不同版本（如 vit_h、vit_l、vit_b）。示例代码：
     </li>
    </ul>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">build_sam_vit_h</span><span class="token punctuation">(</span>checkpoint<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token comment"># 构建 vit_h 版本的 SAM 模型</span>
      <span class="token keyword">return</span> _build_sam<span class="token punctuation">(</span>
          encoder_embed_dim<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span>           <span class="token comment"># 编码器嵌入维度</span>
          encoder_depth<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>                 <span class="token comment"># 编码器层数</span>
          encoder_num_heads<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>             <span class="token comment"># 注意力头数</span>
          encoder_global_attn_indexes<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">31</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 全局注意力层索引</span>
          checkpoint<span class="token operator">=</span>checkpoint<span class="token punctuation">,</span>            <span class="token comment"># 预训练权重文件路径</span>
      <span class="token punctuation">)</span>
</code></pre>
    <ul>
     <li>
      <strong>
       predictor.py
      </strong>
      ：提供预测接口，
      <code>
       set_image
      </code>
      处理图像预处理，
      <code>
       predict
      </code>
      根据提示生成掩码。核心代码：
     </li>
    </ul>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">set_image</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
   <span class="token comment"># 检查输入图像维度和通道数是否符合要求</span>
   <span class="token keyword">if</span> image<span class="token punctuation">.</span>ndim <span class="token operator">!=</span> <span class="token number">3</span> <span class="token keyword">or</span> image<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token keyword">not</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
       <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Image must be 3D with 3 or 4 channels"</span><span class="token punctuation">)</span>
   <span class="token comment"># 应用图像变换（如缩放、归一化）</span>
   input_image <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">.</span>apply_image<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
   <span class="token comment"># 转换为 PyTorch 张量并调整维度为 [1, C, H, W]</span>
   input_image_torch <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>input_image<span class="token punctuation">,</span> device<span class="token operator">=</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
   self<span class="token punctuation">.</span>set_torch_image<span class="token punctuation">(</span>input_image_torch<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> image<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <ul>
     <li>
      <strong>
       automatic_mask_generator.py
      </strong>
      ：自动生成所有物体掩码，基于点提示网格。核心代码：
     </li>
    </ul>
    <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
   <span class="token comment"># 预处理输入图像</span>
   input_image <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>preprocess<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
   <span class="token comment"># 使用无梯度计算图像嵌入</span>
   <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
       image_embedding <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>image_encoder<span class="token punctuation">(</span>input_image<span class="token punctuation">)</span>
   <span class="token comment"># 生成点提示网格</span>
   points <span class="token operator">=</span> self<span class="token punctuation">.</span>_generate_points<span class="token punctuation">(</span>image<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
   all_masks<span class="token punctuation">,</span> all_scores <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
   <span class="token comment"># 按批次处理点提示并预测掩码</span>
   <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>points<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>points_per_batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
       batch_points <span class="token operator">=</span> points<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i <span class="token operator">+</span> self<span class="token punctuation">.</span>points_per_batch<span class="token punctuation">]</span>
       batch_masks<span class="token punctuation">,</span> batch_scores <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_masks<span class="token punctuation">(</span>image_embedding<span class="token punctuation">,</span> batch_points<span class="token punctuation">)</span>
       all_masks<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>batch_masks<span class="token punctuation">)</span>
       all_scores<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>batch_scores<span class="token punctuation">)</span>
   <span class="token comment"># 返回掩码和对应置信度列表</span>
   <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"segmentation"</span><span class="token punctuation">:</span> m<span class="token punctuation">,</span> <span class="token string">"score"</span><span class="token punctuation">:</span> s<span class="token punctuation">}</span> <span class="token keyword">for</span> m<span class="token punctuation">,</span> s <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>all_masks<span class="token punctuation">,</span> all_scores<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <h3>
     <a id="font_color311b92font_99">
     </a>
     <font color="#311b92">
      四、核心代码深度剖析
     </font>
    </h3>
    <h4>
     <a id="font_color311b92Image_Encoder_font_101">
     </a>
     <font color="#311b92">
      （一）Image Encoder 源码解析
     </font>
    </h4>
    <ul>
     <li>
      <strong>
       Patch Embedding
      </strong>
      ：将图像划分为 patches 并映射为特征向量：
     </li>
    </ul>
    <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">PatchEmbed</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span> in_chans<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> embed_dim<span class="token operator">=</span><span class="token number">768</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token comment"># 初始化 Patch Embedding 模块</span>
       <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
       <span class="token comment"># 定义卷积层，将图像划分为 patches 并映射到嵌入维度</span>
       self<span class="token punctuation">.</span>proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_chans<span class="token punctuation">,</span> embed_dim<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> stride<span class="token punctuation">)</span>
   
   <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">:</span>
       <span class="token comment"># 对输入图像进行卷积操作，生成特征图</span>
       x <span class="token operator">=</span> self<span class="token punctuation">.</span>proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
       <span class="token comment"># 调整维度顺序为 [B, H/16, W/16, C]，适配 Transformer 输入</span>
       <span class="token keyword">return</span> x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     输入图像
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        [ 
        
       
         B 
        
       
         , 
        
       
         3 
        
       
         , 
        
       
         H 
        
       
         , 
        
       
         W 
        
       
         ] 
        
       
      
        [B, 3, H, W]
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 1em; vertical-align: -0.25em;">
         </span>
         <span class="mopen">
          [
         </span>
         <span class="mord mathnormal" style="margin-right: 0.0502em;">
          B
         </span>
         <span class="mpunct">
          ,
         </span>
         <span class="mspace" style="margin-right: 0.1667em;">
         </span>
         <span class="mord">
          3
         </span>
         <span class="mpunct">
          ,
         </span>
         <span class="mspace" style="margin-right: 0.1667em;">
         </span>
         <span class="mord mathnormal" style="margin-right: 0.0813em;">
          H
         </span>
         <span class="mpunct">
          ,
         </span>
         <span class="mspace" style="margin-right: 0.1667em;">
         </span>
         <span class="mord mathnormal" style="margin-right: 0.1389em;">
          W
         </span>
         <span class="mclose">
          ]
         </span>
        </span>
       </span>
      </span>
     </span>
     转换为
     <span class="katex--inline">
      <span class="katex">
       <span class="katex-mathml">
        [ 
        
       
         B 
        
       
         , 
        
        
        
          H 
         
        
          16 
         
        
       
         , 
        
        
        
          W 
         
        
          16 
         
        
       
         , 
        
       
         768 
        
       
         ] 
        
       
      
        [B, \frac{H}{16}, \frac{W}{16}, 768]
       </span>
       <span class="katex-html">
        <span class="base">
         <span class="strut" style="height: 1.2173em; vertical-align: -0.345em;">
         </span>
         <span class="mopen">
          [
         </span>
         <span class="mord mathnormal" style="margin-right: 0.0502em;">
          B
         </span>
         <span class="mpunct">
          ,
         </span>
         <span class="mspace" style="margin-right: 0.1667em;">
         </span>
         <span class="mord">
          <span class="mopen nulldelimiter">
          </span>
          <span class="mfrac">
           <span class="vlist-t vlist-t2">
            <span class="vlist-r">
             <span class="vlist" style="height: 0.8723em;">
              <span class="" style="top: -2.655em;">
               <span class="pstrut" style="height: 3em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mtight">
                 <span class="mord mtight">
                  16
                 </span>
                </span>
               </span>
              </span>
              <span class="" style="top: -3.23em;">
               <span class="pstrut" style="height: 3em;">
               </span>
               <span class="frac-line" style="border-bottom-width: 0.04em;">
               </span>
              </span>
              <span class="" style="top: -3.394em;">
               <span class="pstrut" style="height: 3em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mtight">
                 <span class="mord mathnormal mtight" style="margin-right: 0.0813em;">
                  H
                 </span>
                </span>
               </span>
              </span>
             </span>
             <span class="vlist-s">
              ​
             </span>
            </span>
            <span class="vlist-r">
             <span class="vlist" style="height: 0.345em;">
              <span class="">
              </span>
             </span>
            </span>
           </span>
          </span>
          <span class="mclose nulldelimiter">
          </span>
         </span>
         <span class="mpunct">
          ,
         </span>
         <span class="mspace" style="margin-right: 0.1667em;">
         </span>
         <span class="mord">
          <span class="mopen nulldelimiter">
          </span>
          <span class="mfrac">
           <span class="vlist-t vlist-t2">
            <span class="vlist-r">
             <span class="vlist" style="height: 0.8723em;">
              <span class="" style="top: -2.655em;">
               <span class="pstrut" style="height: 3em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mtight">
                 <span class="mord mtight">
                  16
                 </span>
                </span>
               </span>
              </span>
              <span class="" style="top: -3.23em;">
               <span class="pstrut" style="height: 3em;">
               </span>
               <span class="frac-line" style="border-bottom-width: 0.04em;">
               </span>
              </span>
              <span class="" style="top: -3.394em;">
               <span class="pstrut" style="height: 3em;">
               </span>
               <span class="sizing reset-size6 size3 mtight">
                <span class="mord mtight">
                 <span class="mord mathnormal mtight" style="margin-right: 0.1389em;">
                  W
                 </span>
                </span>
               </span>
              </span>
             </span>
             <span class="vlist-s">
              ​
             </span>
            </span>
            <span class="vlist-r">
             <span class="vlist" style="height: 0.345em;">
              <span class="">
              </span>
             </span>
            </span>
           </span>
          </span>
          <span class="mclose nulldelimiter">
          </span>
         </span>
         <span class="mpunct">
          ,
         </span>
         <span class="mspace" style="margin-right: 0.1667em;">
         </span>
         <span class="mord">
          768
         </span>
         <span class="mclose">
          ]
         </span>
        </span>
       </span>
      </span>
     </span>
     。
    </p>
    <ul>
     <li>
      <strong>
       Transformer Encoder
      </strong>
      ：堆叠多个 Transformer Block 提取特征：
     </li>
    </ul>
    <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Block</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> mlp_ratio<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 初始化 Transformer Block</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 第一层归一化</span>
        self<span class="token punctuation">.</span>norm1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>
        <span class="token comment"># 多头注意力模块</span>
        self<span class="token punctuation">.</span>attn <span class="token operator">=</span> Attention<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> num_heads<span class="token punctuation">)</span>
        <span class="token comment"># 第二层归一化</span>
        self<span class="token punctuation">.</span>norm2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>
        <span class="token comment"># 多层感知机，隐藏层维度为 dim * mlp_ratio</span>
        self<span class="token punctuation">.</span>mlp <span class="token operator">=</span> Mlp<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>dim <span class="token operator">*</span> mlp_ratio<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 自注意力计算并残差连接</span>
        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>attn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># MLP 计算并残差连接</span>
        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>mlp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
</code></pre>
    <h4>
     <a id="font_color311b92Prompt_Encoder_font_143">
     </a>
     <font color="#311b92">
      （二）Prompt Encoder 源码解析
     </font>
    </h4>
    <p>
     编码不同类型提示：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">PromptEncoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> embed_dim<span class="token punctuation">,</span> image_embedding_size<span class="token punctuation">,</span> input_image_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 初始化 Prompt Encoder 模块</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 位置编码层，使用随机高斯矩阵生成</span>
        self<span class="token punctuation">.</span>pe_layer <span class="token operator">=</span> PositionEmbeddingRandom<span class="token punctuation">(</span>embed_dim <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token comment"># 提示嵌入层，处理点和框提示</span>
        self<span class="token punctuation">.</span>prompt_embed_layer <span class="token operator">=</span> PromptEmbedding<span class="token punctuation">(</span>embed_dim<span class="token punctuation">,</span> input_image_size<span class="token punctuation">,</span> image_embedding_size<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> points<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> boxes<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> masks<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 初始化稀疏嵌入张量，维度为 [batch_size, 0, embed_dim]</span>
        sparse_embed <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>embed_dim<span class="token punctuation">,</span> device<span class="token operator">=</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
        <span class="token keyword">if</span> points<span class="token punctuation">:</span>
            <span class="token comment"># 提取点提示的坐标和标签</span>
            coords<span class="token punctuation">,</span> labels <span class="token operator">=</span> points
            <span class="token comment"># 生成点嵌入并拼接到稀疏嵌入中</span>
            sparse_embed <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>sparse_embed<span class="token punctuation">,</span> self<span class="token punctuation">.</span>prompt_embed_layer<span class="token punctuation">.</span>point_embedding<span class="token punctuation">(</span>coords<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 返回稀疏嵌入和密集嵌入（未完全展示 masks 处理部分）</span>
        <span class="token keyword">return</span> sparse_embed<span class="token punctuation">,</span> dense_embed
</code></pre>
    <h3>
     <a id="font_color311b92font_168">
     </a>
     <font color="#311b92">
      五、实战演练
     </font>
    </h3>
    <h4>
     <a id="font_color311b92font_170">
     </a>
     <font color="#311b92">
      （一）环境搭建与配置
     </font>
    </h4>
    <ol>
     <li>
      <strong>
       安装 Python
      </strong>
      ：版本 ≥ 3.8。
     </li>
     <li>
      <strong>
       安装 PyTorch
      </strong>
      ：
      <pre><code class="prism language-bash">pip <span class="token function">install</span> <span class="token assign-left variable">torch</span><span class="token operator">==</span><span class="token number">2.0</span>.1+cu117 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.15</span>.2+cu117 <span class="token parameter variable">-f</span> https://download.pytorch.org/whl/cu117
</code></pre>
     </li>
     <li>
      <strong>
       安装 SAM
      </strong>
      ：
      <pre><code class="prism language-bash">pip <span class="token function">install</span> <span class="token parameter variable">-U</span> <span class="token string">"git+https://github.com/facebookresearch/segment-anything.git"</span>
</code></pre>
     </li>
    </ol>
    <h4>
     <a id="font_color311b92font_182">
     </a>
     <font color="#311b92">
      （二）代码运行与结果分析
     </font>
    </h4>
    <p>
     示例代码：
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> segment_anything <span class="token keyword">import</span> sam_model_registry<span class="token punctuation">,</span> SamPredictor
<span class="token keyword">import</span> cv2
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># 加载 vit_b 版本的 SAM 模型并移动到 GPU</span>
sam <span class="token operator">=</span> sam_model_registry<span class="token punctuation">[</span><span class="token string">"vit_b"</span><span class="token punctuation">]</span><span class="token punctuation">(</span>checkpoint<span class="token operator">=</span><span class="token string">"sam_vit_b_01ec64.pth"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>
<span class="token comment"># 初始化预测器</span>
predictor <span class="token operator">=</span> SamPredictor<span class="token punctuation">(</span>sam<span class="token punctuation">)</span>
<span class="token comment"># 读取图像并转换为 RGB 格式</span>
image <span class="token operator">=</span> cv2<span class="token punctuation">.</span>cvtColor<span class="token punctuation">(</span>cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">"test_image.jpg"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>COLOR_BGR2RGB<span class="token punctuation">)</span>
<span class="token comment"># 设置输入图像，进行预处理和特征提取</span>
predictor<span class="token punctuation">.</span>set_image<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
<span class="token comment"># 定义点提示坐标和标签（1 表示前景）</span>
masks<span class="token punctuation">,</span> scores<span class="token punctuation">,</span> _ <span class="token operator">=</span> predictor<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>point_coords<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">375</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> point_labels<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> multimask_output<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 遍历掩码和分数，显示结果</span>
<span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>mask<span class="token punctuation">,</span> score<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>masks<span class="token punctuation">,</span> scores<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image<span class="token punctuation">)</span>  <span class="token comment"># 显示原始图像</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>mask<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span>  <span class="token comment"># 显示掩码，透明度为 0.6</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Mask </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">, Score: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>score<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>  <span class="token comment"># 设置标题，显示掩码编号和置信度</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 显示图像</span>
</code></pre>
    <p>
     <strong>
      结果分析
     </strong>
     ：SAM 根据点提示生成多个掩码，分数反映置信度。高分掩码通常更准确，低分掩码可能包含错误分割。
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/22fd1168d82141e59f3b1d4b8d674134.png"/>
    </p>
    <h3>
     <a id="font_color311b92font_213">
     </a>
     <font color="#311b92">
      六、总结与展望
     </font>
    </h3>
    <p>
     SAM 通过高效的图像编码、提示编码和掩码解码实现了灵活的图像分割。未来，其在医学影像、自动驾驶和视频处理中的应用潜力巨大。技术发展方向包括模型轻量化、多模态融合和领域适应，为计算机视觉带来更多可能性。
    </p>
    <hr/>
    <p>
     <font color="#311b92">
      <strong>
       延伸阅读
      </strong>
     </font>
    </p>
    <ul>
     <li>
      <p>
       <a href="https://blog.csdn.net/u013132758/category_12908083.html">
        <font color="#311b92">
         <strong>
          AI Agent 系列文章
         </strong>
        </font>
       </a>
      </p>
      <hr/>
     </li>
     <li>
      <p>
       <a href="https://blog.csdn.net/u013132758/category_12899414.html">
        <font color="#311b92">
         <strong>
          计算机视觉系列文章
         </strong>
        </font>
       </a>
      </p>
      <hr/>
     </li>
     <li>
      <p>
       <a href="https://blog.csdn.net/u013132758/category_12898016.html">
        <font color="#311b92">
         <strong>
          机器学习核心算法系列文章
         </strong>
        </font>
       </a>
      </p>
      <hr/>
     </li>
     <li>
      <p>
       <a href="https://blog.csdn.net/u013132758/category_12898012.html">
        <font color="#311b92">
         <strong>
          深度学习系列文章
         </strong>
        </font>
       </a>
      </p>
     </li>
    </ul>
    <hr/>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f753031333133323735382f:61727469636c652f64657461696c732f313436323238303538" class_="artid" style="display:none">
 </p>
</div>


