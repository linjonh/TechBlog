---
layout: post
title: "数字人本地部署之llama-本地推理模型"
date: 2025-03-16 03:27:59 +0800
description: "属于命令行选项，一般用来指定要加载的模型文件。是模型文件的路径。gguf格式的文件是一种用于存储语言模型权重的文件格式，服务器会加载这个文件里的模型权重，从而使用对应的语言模型开展任务。也是命令行选项，其作用是指定服务器要监听的端口号。"
keywords: "数字人本地部署之llama-本地推理模型"
categories: ['新时代办公基础']
tags: ['数字人', '人工智能', 'Llama']
artid: "146289384"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146289384
    alt: "数字人本地部署之llama-本地推理模型"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146289384
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146289384
cover: https://bing.ee123.net/img/rand?artid=146289384
image: https://bing.ee123.net/img/rand?artid=146289384
img: https://bing.ee123.net/img/rand?artid=146289384
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     数字人本地部署之llama-本地推理模型
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     llama 本地服务命令
    </h2>
    <p id="articleContentId">
     llama-server.exe -m "data/LLM/my.gguf" --port   8080
    </p>
    <h4>
     <code>
      -m data/LLM/my.gguf
     </code>
    </h4>
    <p>
    </p>
    <p>
     <code>
      -m
     </code>
     属于命令行选项，一般用来指定要加载的模型文件。
    </p>
    <p>
     <code>
      data/LLM/my.gguf
     </code>
     是模型文件的路径。
     <code>
      gguf
     </code>
     格式的文件是一种用于存储语言模型权重的文件格式，服务器会加载这个文件里的模型权重，从而使用对应的语言模型开展任务。
    </p>
    <p>
     <code>
      --port 8080
     </code>
    </p>
    <p>
    </p>
    <p>
     <code>
      --port
     </code>
     也是命令行选项，其作用是指定服务器要监听的端口号。
    </p>
    <h2>
     二、llama帮助命令
    </h2>
    <p>
     llama-server.exe --help
    </p>
    <h2>
     三、llama命令工具下载
    </h2>
    <p>
     <a href="https://github.com/ggml-org/llama.cpp/releases" title="https://github.com/ggml-org/llama.cpp/releases">
      https://github.com/ggml-org/llama.cpp/releases
     </a>
    </p>
    <p>
     <img alt="" height="567" src="https://i-blog.csdnimg.cn/direct/00c128da7ac8408195d5bacbc8de6e31.png" width="1081"/>
    </p>
    <p>
     如何选择下载版本
    </p>
    <p>
     cuda
    </p>
    <p>
     cudart-llama-bin-win-cu11.7-x64.zip
    </p>
    <p>
     <img alt="" height="489" src="https://i-blog.csdnimg.cn/direct/39619ec5378c4653b8369c8d292ce638.png" width="1042"/>
    </p>
    <h2>
     四、如何查看自己电脑CPU指令
    </h2>
    <p>
     <a href="http://51.onelink.ynwlzc.net/o2o/index.php/appshow/Rsv" rel="nofollow" title="未来商城—APPSTORE">
      未来商城—APPSTORE
     </a>
    </p>
    <p>
     <img alt="" height="339" src="https://i-blog.csdnimg.cn/direct/f73381a1beb648b993dbd5be2ef275e2.png" width="394"/>
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f:2f626c6f672e6373646e2e6e65742f6379626572736e6f772f:61727469636c652f64657461696c732f313436323839333834" class_="artid" style="display:none">
 </p>
</div>


