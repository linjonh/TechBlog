---
layout: post
title: "java.io.IOException-java.io.EOFException-Unexpected-end-of-input-stream错误"
date: 2023-07-21 11:30:48 +0800
description: "报错现象：Diagnostic Messages for this Task:Error: java"
keywords: "Hadoop,Hive,IOException"
categories: ['未分类']
tags: ['大数据', 'Viewui', 'Javascript', 'Java']
artid: "98410781"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=98410781
  alt: "java.io.IOException-java.io.EOFException-Unexpected-end-of-input-stream错误"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=98410781
featuredImagePreview: https://bing.ee123.net/img/rand?artid=98410781
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     java.io.IOException: java.io.EOFException: Unexpected end of input stream错误
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <div class="blogpost-body" id="cnblogs_post_body">
     <p>
      报错现象：
     </p>
     <p>
      Diagnostic Messages for this Task:
      <br/>
      Error: java.io.IOException: java.io.EOFException: Unexpected end of input stream
      <br/>
      at org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderNextException(HiveIOExceptionHandlerChain.java:121)
      <br/>
      at org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderNextException(HiveIOExceptionHandlerUtil.java:77)
      <br/>
      at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:344)
      <br/>
      at org.apache.hadoop.hive.ql.io.HiveRecordReader.doNext(HiveRecordReader.java:79)
      <br/>
      at org.apache.hadoop.hive.ql.io.HiveRecordReader.doNext(HiveRecordReader.java:33)
      <br/>
      at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.next(HiveContextAwareRecordReader.java:122)
      <br/>
      at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:199)
      <br/>
      at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:185)
      <br/>
      at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)
      <br/>
      at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)
      <br/>
      at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
      <br/>
      at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)
      <br/>
      at java.security.AccessController.doPrivileged(Native Method)
      <br/>
      at javax.security.auth.Subject.doAs(Subject.java:415)
      <br/>
      at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1642)
      <br/>
      at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)
      <br/>
      Caused by: java.io.EOFException: Unexpected end of input stream
      <br/>
      at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:145)
      <br/>
      at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:85)
      <br/>
      at java.io.InputStream.read(InputStream.java:101)
      <br/>
      at org.apache.hadoop.util.LineReader.fillBuffer(LineReader.java:180)
      <br/>
      at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
      <br/>
      at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
      <br/>
      at org.apache.hadoop.mapred.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:206)
      <br/>
      at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:244)
      <br/>
      at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:47)
      <br/>
      at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:339)
      <br/>
      ... 13 more
     </p>
     <p>
      Container killed by the ApplicationMaster.
      <br/>
      Container killed on request. Exit code is 143
      <br/>
      Container exited with a non-zero exit code 143
     </p>
     <p>
      <br/>
      FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
     </p>
     <p>
      原因：
     </p>
     <p>
      hdfs 文件异常造成；
     </p>
     <p>
      解决：
     </p>
     <p>
      定位failed attempt，找到处理报错的file;
     </p>
     <p>
      使用zcat进行测试报错：
     </p>
     <p>
      <img alt="" src="//images2015.cnblogs.com/blog/359231/201608/359231-20160801125954325-1736686615.png"/>
     </p>
     <p>
      删除报错file解决问题；
     </p>
     <p>
     </p>
     <p>
     </p>
     <p>
      REF:http://caiguangguang.blog.51cto.com/1652935/1436077/
     </p>
    </div>
    <p>
     转载于:https://www.cnblogs.com/chao1118/p/5725434.html
    </p>
   </div>
  </div>
  <div id="recommendDown">
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f67:2e6373646e2e6e65742f77656978696e5f3330343137343837:2f61727469636c652f64657461696c732f3938343130373831" class_="artid" style="display:none">
 </p>
</div>
