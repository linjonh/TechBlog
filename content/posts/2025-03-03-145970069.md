---
arturl_encode: "68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34393432363131352f:61727469636c652f64657461696c732f313435393730303639"
layout: post
title: "DeepSeek-隐私泄露"
date: 2025-03-03 12:00:00 +0800
description: "最近，一位社科专业的朋友问我：“如果把一些自己研究方向相关的涉密英文材料上传到 DeepSeek，让它帮忙提取文本并翻译，其他用户会不会通过拷打AI或其他方式获取这些材料的内容？”换句话说，像 DeepSeek 这样的 AI 平台，会不会悄悄地使用用户上传的数据来训练模型？"
keywords: "deepseek上传的文档会泄露吗"
categories: ['经验']
tags: ['人工智能', 'Chatgpt']
artid: "145970069"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145970069
    alt: "DeepSeek-隐私泄露"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145970069
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145970069
cover: https://bing.ee123.net/img/rand?artid=145970069
image: https://bing.ee123.net/img/rand?artid=145970069
img: https://bing.ee123.net/img/rand?artid=145970069
---

# DeepSeek 隐私泄露？

大家好，我是钢板兽。

最近，一位社科专业的朋友问我：“如果把一些自己研究方向相关的
**涉密英文材料**
上传到 DeepSeek，让它帮忙提取文本并翻译，其他用户会不会通过拷打AI或其他方式获取这些材料的内容？”换句话说，
**像 DeepSeek 这样的 AI 平台，会不会悄悄地使用用户上传的数据来训练模型？**

这个问题让我有点犯难。按常理来说，DeepSeek、ChatGPT 这些大模型平台应该会在服务器中为每位用户创建独立的存储空间，确保数据安全。但事实真的如此吗？

> “你会收集我提供给你的材料进行训练吗？”

当我向 DeepSeek、ChatGPT 等 AI 平台询问这个问题时，得到的回答几乎一致：所有大模型都声称不会收集、存储或利用用户输入的数据进行训练。

听起来很安心，对吧？但现实真的如此简单吗？

![DeepSeek的回答](https://i-blog.csdnimg.cn/img_convert/b9336b3bf659f5bfc9c19feff4bdf8d2.png)

![ChatGPT的回答](https://i-blog.csdnimg.cn/img_convert/3d9999ba1064d2865c33c841702856b3.png)

事实上，在这些平台的用户协议和隐私政策中，我们能发现一些微妙的措辞。例如，部分平台会记录用户的交互信息，并以“
**优化模型、改善服务**
”为由保留这些数据，甚至可能在“匿名化”后用于训练。

也就是说，虽然 AI 平台不会直接把你的输入一字不落地“喂”给模型，但它们仍可能以其他方式利用你的数据来提升 AI 的表现。

以 DeepSeek 为例，它的
[隐私政策](https://cdn.deepseek.com/policies/en-US/deepseek-privacy-policy.html)
中写道：

> “我们使用您的信息来改进和开发服务，并训练和改进我们的技术，例如我们的机器学习模型和算法……”

![DeepSeek隐私政策](https://i-blog.csdnimg.cn/img_convert/19d868a7321c507caba46f676a64b755.png)

而 OpenAI 则更为直白地在
[隐私政策](https://openai.com/consumer-privacy/)
中写明：

> “用户可以在设置中选择是否为未来的模型做出贡献。”
>
> “临时聊天不会用于训练模型”
>
> “默认情况下，不使用 API、ChatGPT Enterprise 和 ChatGPT Team 客户数据进行训练。”

![OpenAI隐私政策](https://i-blog.csdnimg.cn/img_convert/a2859d8c4058291083a8a6c3542ec1c9.png)

也就是说在
**默认设置**
的情况下，我们所上传的数据是会被OpenAI用于AI模型训练的，尤其是
**非API用户**
（比如免费版ChatGPT），我赶紧看了看自己的ChatGPT账户（plus套餐）设置，果然发现ChatGPT默认为我开启了“模型改进”的选项。

如果你现在去查看自己的 ChatGPT 设置，很可能也会发现这个选项是
**默认打开的**
。

![ChatGPT账户设置](https://i-blog.csdnimg.cn/img_convert/59776aa8d50d5c7d44fbbfa9776aced5.png)

这样看来，尽管所有AI 平台在明面上否认收集数据用于训练，但实际上用户输入的内容仍可能被存储并用于改善 AI 的表现。

除了 AI 平台可能会收集用户数据用于训练，在我们将数据上传到AI平台之后的一系列流程中都会有数据泄露的风险：

* 数据传输过程中，用户输入的信息会通过互联网传输到云端进行计算，如果传输过程
  **缺乏足够的加密保护**
  ，黑客有可能在数据流动过程中拦截你的信息。
* 很多大模型平台都会
  **暂存用户的输入记录**
  ，哪怕它们不会直接用这些数据训练模型。这些存储的数据如果被恶意攻击者获取，也可能会带来信息泄露风险。

---

如果你的输入涉及隐私或敏感信息，那么
**最安全的做法就是避免将这些数据上传到大模型平台**
！但如果你
**不得不**
使用 AI 处理相关内容，这里提供几点建议：

* 在使用 AI 前，阅读该平台的隐私政策，了解它是否存储用户数据、是否会用于训练，以及是否提供数据删除选项。
  **如果可以关闭“改进模型”功能，一定要关掉！**
* 如果数据涉及隐私，可以先删除敏感部分，用符号或代号代替真实信息，让 AI 处理后再手动补充。
* 如果你的数据涉及公司或研究机密，最安全的方式是避免上传到云端 AI。可以选择
  **本地化 AI 工具**
  ，比如 Llama、ChatGLM、DeepSeek 本地版等，都可以部署在自己的电脑或服务器上，这样数据完全不会上传到云端，极大降低了数据泄露的风险。

那么今天关于使用AI过程中数据泄露的内容就介绍到这里了，希望这篇文章可以帮到你。

阅读完这篇文章，你有什么想说的吗，你在使用AI工具的过程中又遇到什么问题吗？欢迎在评论区留言。