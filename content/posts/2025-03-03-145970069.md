---
layout: post
title: "DeepSeek-隐私泄露"
date: 2025-03-03 12:00:00 +0800
description: "最近，一位社科专业的朋友问我：“如果把一些自己研究方向相关的涉密英文材料上传到 DeepSeek，让它帮忙提取文本并翻译，其他用户会不会通过拷打AI或其他方式获取这些材料的内容？”换句话说，像 DeepSeek 这样的 AI 平台，会不会悄悄地使用用户上传的数据来训练模型？"
keywords: "deepseek上传的文档会泄露吗"
categories: ['经验']
tags: ['人工智能', 'Chatgpt']
artid: "145970069"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145970069
    alt: "DeepSeek-隐私泄露"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145970069
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145970069
cover: https://bing.ee123.net/img/rand?artid=145970069
image: https://bing.ee123.net/img/rand?artid=145970069
img: https://bing.ee123.net/img/rand?artid=145970069
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     DeepSeek 隐私泄露？
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     大家好，我是钢板兽。
    </p>
    <p>
     最近，一位社科专业的朋友问我：“如果把一些自己研究方向相关的
     <strong>
      涉密英文材料
     </strong>
     上传到 DeepSeek，让它帮忙提取文本并翻译，其他用户会不会通过拷打AI或其他方式获取这些材料的内容？”换句话说，
     <strong>
      像 DeepSeek 这样的 AI 平台，会不会悄悄地使用用户上传的数据来训练模型？
     </strong>
    </p>
    <p>
     这个问题让我有点犯难。按常理来说，DeepSeek、ChatGPT 这些大模型平台应该会在服务器中为每位用户创建独立的存储空间，确保数据安全。但事实真的如此吗？
    </p>
    <blockquote>
     <p>
      “你会收集我提供给你的材料进行训练吗？”
     </p>
    </blockquote>
    <p>
     当我向 DeepSeek、ChatGPT 等 AI 平台询问这个问题时，得到的回答几乎一致：所有大模型都声称不会收集、存储或利用用户输入的数据进行训练。
    </p>
    <p>
     听起来很安心，对吧？但现实真的如此简单吗？
    </p>
    <p>
     <img alt="DeepSeek的回答" src="https://i-blog.csdnimg.cn/img_convert/b9336b3bf659f5bfc9c19feff4bdf8d2.png"/>
    </p>
    <p>
     <img alt="ChatGPT的回答" src="https://i-blog.csdnimg.cn/img_convert/3d9999ba1064d2865c33c841702856b3.png"/>
    </p>
    <p>
     事实上，在这些平台的用户协议和隐私政策中，我们能发现一些微妙的措辞。例如，部分平台会记录用户的交互信息，并以“
     <strong>
      优化模型、改善服务
     </strong>
     ”为由保留这些数据，甚至可能在“匿名化”后用于训练。
    </p>
    <p>
     也就是说，虽然 AI 平台不会直接把你的输入一字不落地“喂”给模型，但它们仍可能以其他方式利用你的数据来提升 AI 的表现。
    </p>
    <p>
     以 DeepSeek 为例，它的
     <a href="https://cdn.deepseek.com/policies/en-US/deepseek-privacy-policy.html" rel="nofollow">
      隐私政策
     </a>
     中写道：
    </p>
    <blockquote>
     <p>
      “我们使用您的信息来改进和开发服务，并训练和改进我们的技术，例如我们的机器学习模型和算法……”
     </p>
    </blockquote>
    <p>
     <img alt="DeepSeek隐私政策" src="https://i-blog.csdnimg.cn/img_convert/19d868a7321c507caba46f676a64b755.png"/>
    </p>
    <p>
     而 OpenAI 则更为直白地在
     <a href="https://openai.com/consumer-privacy/" rel="nofollow">
      隐私政策
     </a>
     中写明：
    </p>
    <blockquote>
     <p>
      “用户可以在设置中选择是否为未来的模型做出贡献。”
     </p>
     <p>
      “临时聊天不会用于训练模型”
     </p>
     <p>
      “默认情况下，不使用 API、ChatGPT Enterprise 和 ChatGPT Team 客户数据进行训练。”
     </p>
    </blockquote>
    <p>
     <img alt="OpenAI隐私政策" src="https://i-blog.csdnimg.cn/img_convert/a2859d8c4058291083a8a6c3542ec1c9.png"/>
    </p>
    <p>
     也就是说在
     <strong>
      默认设置
     </strong>
     的情况下，我们所上传的数据是会被OpenAI用于AI模型训练的，尤其是
     <strong>
      非API用户
     </strong>
     （比如免费版ChatGPT），我赶紧看了看自己的ChatGPT账户（plus套餐）设置，果然发现ChatGPT默认为我开启了“模型改进”的选项。
    </p>
    <p>
     如果你现在去查看自己的 ChatGPT 设置，很可能也会发现这个选项是
     <strong>
      默认打开的
     </strong>
     。
    </p>
    <p>
     <img alt="ChatGPT账户设置" src="https://i-blog.csdnimg.cn/img_convert/59776aa8d50d5c7d44fbbfa9776aced5.png"/>
    </p>
    <p>
     这样看来，尽管所有AI 平台在明面上否认收集数据用于训练，但实际上用户输入的内容仍可能被存储并用于改善 AI 的表现。
    </p>
    <p>
     除了 AI 平台可能会收集用户数据用于训练，在我们将数据上传到AI平台之后的一系列流程中都会有数据泄露的风险：
    </p>
    <ul>
     <li>
      数据传输过程中，用户输入的信息会通过互联网传输到云端进行计算，如果传输过程
      <strong>
       缺乏足够的加密保护
      </strong>
      ，黑客有可能在数据流动过程中拦截你的信息。
     </li>
     <li>
      很多大模型平台都会
      <strong>
       暂存用户的输入记录
      </strong>
      ，哪怕它们不会直接用这些数据训练模型。这些存储的数据如果被恶意攻击者获取，也可能会带来信息泄露风险。
     </li>
    </ul>
    <hr/>
    <p>
     如果你的输入涉及隐私或敏感信息，那么
     <strong>
      最安全的做法就是避免将这些数据上传到大模型平台
     </strong>
     ！但如果你
     <strong>
      不得不
     </strong>
     使用 AI 处理相关内容，这里提供几点建议：
    </p>
    <ul>
     <li>
      在使用 AI 前，阅读该平台的隐私政策，了解它是否存储用户数据、是否会用于训练，以及是否提供数据删除选项。
      <strong>
       如果可以关闭“改进模型”功能，一定要关掉！
      </strong>
     </li>
     <li>
      如果数据涉及隐私，可以先删除敏感部分，用符号或代号代替真实信息，让 AI 处理后再手动补充。
     </li>
     <li>
      如果你的数据涉及公司或研究机密，最安全的方式是避免上传到云端 AI。可以选择
      <strong>
       本地化 AI 工具
      </strong>
      ，比如 Llama、ChatGLM、DeepSeek 本地版等，都可以部署在自己的电脑或服务器上，这样数据完全不会上传到云端，极大降低了数据泄露的风险。
     </li>
    </ul>
    <p>
     那么今天关于使用AI过程中数据泄露的内容就介绍到这里了，希望这篇文章可以帮到你。
    </p>
    <p>
     阅读完这篇文章，你有什么想说的吗，你在使用AI工具的过程中又遇到什么问题吗？欢迎在评论区留言。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f34393432363131352f:61727469636c652f64657461696c732f313435393730303639" class_="artid" style="display:none">
 </p>
</div>


