---
layout: post
title: "QwQ-32B-开源本地部署微调教程来了"
date: 2025-03-09 13:47:52 +0800
description: "今天，通义千问开源了推理模型QwQ-32BQwQ-32B 在一系列基准测试中进行了评估，测试了数学推理、编程能力和通用能力。以下结果展示了 QwQ-32B 与其他领先模型的性能对比，包括 DeepSeek-R1-Distilled-Qwen-32B、DeepSeek-R1-Distilled-Llama-70B、o1-mini 以及原始的 DeepSeek-R1。"
keywords: "QwQ-32B 开源！本地部署+微调教程来了"
categories: ['大模型']
tags: ['面试题', '面试', '算法', '深度学习', '大模型']
artid: "146131431"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146131431
    alt: "QwQ-32B-开源本地部署微调教程来了"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146131431
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146131431
cover: https://bing.ee123.net/img/rand?artid=146131431
image: https://bing.ee123.net/img/rand?artid=146131431
img: https://bing.ee123.net/img/rand?artid=146131431
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     QwQ-32B 开源！本地部署+微调教程来了
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="./../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="./../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     今天，通义千问开源了推理模型QwQ-32B
    </p>
    <p>
     QwQ-32B 在一系列基准测试中进行了评估，测试了数学推理、编程能力和通用能力。以下结果展示了 QwQ-32B 与其他领先模型的性能对比，包括 DeepSeek-R1-Distilled-Qwen-32B、DeepSeek-R1-Distilled-Llama-70B、o1-mini 以及原始的 DeepSeek-R1。
    </p>
    <p>
     <img alt="图片" src="https://i-blog.csdnimg.cn/img_convert/778f728766d01fe759ed81846cbf5f89.jpeg"/>
    </p>
    <p>
     在测试数学能力的 AIME24 评测集上，以及评估代码能力的 LiveCodeBench 中，千问 QwQ-32B 表现与DeepSeek-R1相当，远胜于 o1-mini 及相同尺寸的R1 蒸馏模型；在由Meta首席科学家杨立昆领衔的“最难LLMs评测榜” LiveBench、谷歌等提出的指令遵循能力IFEval评测集、由加州大学伯克利分校等提出的评估准确调用函数或工具方面的BFCL测试中，千问 QwQ-32B 的得分均超越了 DeepSeek- R1。
    </p>
    <hr/>
    <p>
     最近这一两周不少公司已开启春招。
    </p>
    <p>
     不同以往的是，当前职场环境已不再是那个双向奔赴时代了。求职者在变多，HC 在变少，岗位要求还更高了。
    </p>
    <p>
     最近，我们又陆续整理了很多大厂的面试题，帮助一些球友解惑答疑，分享技术面试中的那些弯弯绕绕。
    </p>
    <p>
     总结如下：
    </p>
    <p>
     <a href="https://blog.csdn.net/m0_59596990/article/details/145441648">
      《大模型面试宝典》(2025版) 发布！
     </a>
    </p>
    <p>
     <strong>
      喜欢本文记得收藏、关注、点赞
     </strong>
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b1c6cd718a614605b0044ece1a1c58f7.png#pic_center" width="600"/>
    </p>
    <hr/>
    <p>
     <strong>
      大规模强化学习
     </strong>
    </p>
    <p>
     研究团队在冷启动的基础上开展了大规模强化学习。在初始阶段，特别针对数学和编程任务进行了 RL 训练。与依赖传统的奖励模型（reward model）不同，研究团队通过校验生成答案的正确性来为数学问题提供反馈，并通过代码执行服务器评估生成的代码是否成功通过测试用例来提供代码的反馈。
    </p>
    <p>
     研究团队发现在
     <strong>
      RL 扩展过程
     </strong>
     中，随着训练轮次的推进，这两个领域中的性能均表现出持续的提升。
    </p>
    <p>
     在第一阶段的 RL 过后，研究团队增加了另一个针对通用能力的 RL。此阶段使用通用奖励模型和一些基于规则的验证器进行训练。研究团队发现，通过少量步骤的通用 RL，可以提升其他通用能力，同时在数学和编程任务上的性能没有显著下降。
    </p>
    <h3>
     <a id="_48">
     </a>
     模型推理
    </h3>
    <p>
     <strong>
      Transformers
     </strong>
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> modelscope <span class="token keyword">import</span> AutoModelForCausalLM<span class="token punctuation">,</span> AutoTokenizer

model_name <span class="token operator">=</span> <span class="token string">"Qwen/QwQ-32B"</span>

model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    model_name<span class="token punctuation">,</span>
    torch_dtype<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">,</span>
    device_map<span class="token operator">=</span><span class="token string">"auto"</span>
<span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_name<span class="token punctuation">)</span>

prompt <span class="token operator">=</span> <span class="token string">"How many r's are in the word \"strawberry\""</span>
messages <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span>
<span class="token punctuation">]</span>
text <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>apply_chat_template<span class="token punctuation">(</span>
    messages<span class="token punctuation">,</span>
    tokenize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    add_generation_prompt<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

model_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token punctuation">[</span>text<span class="token punctuation">]</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>model<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

generated_ids <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>
    <span class="token operator">**</span>model_inputs<span class="token punctuation">,</span>
    max_new_tokens<span class="token operator">=</span><span class="token number">32768</span>
<span class="token punctuation">)</span>
generated_ids <span class="token operator">=</span> <span class="token punctuation">[</span>
    output_ids<span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token keyword">for</span> input_ids<span class="token punctuation">,</span> output_ids <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>model_inputs<span class="token punctuation">.</span>input_ids<span class="token punctuation">,</span> generated_ids<span class="token punctuation">)</span>
<span class="token punctuation">]</span>

response <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>generated_ids<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="Ollama_96">
     </a>
     Ollama本地拉起
    </h3>
    <p>
     通过Ollama与魔搭平台的整合，开发者也可以直接在本地的Ollama环境，直接运行QwQ-32B模型：
    </p>
    <pre><code class="prism language-bash">ollama run modelscope.cn/Qwen/QwQ-32B-GGUF
</code></pre>
    <p>
     <img alt="图片" src="https://i-blog.csdnimg.cn/img_convert/f0ca5a430e26a7d2e52a596e0827c6ce.png"/>
    </p>
    <h3>
     <a id="_106">
     </a>
     模型微调
    </h3>
    <p>
     我们展示对QwQ-32B进行微调的demo，并给出自定义数据集的格式。
    </p>
    <p>
     在开始微调之前，请确保您的环境已准备妥当。
    </p>
    <pre><code class="prism language-bash"><span class="token comment"># pip install git+https://github.com/modelscope/ms-swift.git</span>

<span class="token function">git</span> clone https://github.com/modelscope/ms-swift.git
<span class="token builtin class-name">cd</span> ms-swift
pip <span class="token function">install</span> <span class="token parameter variable">-e</span> <span class="token builtin class-name">.</span>
</code></pre>
    <p>
     首先我们使用QWQ-32B蒸馏部分数据，保持其思考的能力，将蒸馏的数据保存在本地路径：qwq-32b-distill.jsonl。
    </p>
    <pre><code class="prism language-bash"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span> <span class="token punctuation">\</span>
swift infer <span class="token punctuation">\</span>
    <span class="token parameter variable">--model</span> Qwen/QwQ-32B <span class="token punctuation">\</span>
    <span class="token parameter variable">--infer_backend</span> vllm <span class="token punctuation">\</span>
    <span class="token parameter variable">--val_dataset</span> <span class="token string">'AI-ModelScope/alpaca-gpt4-data-zh#1000'</span> <span class="token string">'AI-ModelScope/alpaca-gpt4-data-en#1000'</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--gpu_memory_utilization</span> <span class="token number">0.9</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--max_model_len</span> <span class="token number">32768</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--max_new_tokens</span> <span class="token number">8192</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--result_path</span> qwq-32b-distill.jsonl <span class="token punctuation">\</span>
    <span class="token parameter variable">--tensor_parallel_size</span> <span class="token number">2</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--disable_custom_all_reduce</span> <span class="token boolean">true</span>
</code></pre>
    <p>
     微调脚本如下：
    </p>
    <pre><code class="prism language-bash"><span class="token assign-left variable">NPROC_PER_NODE</span><span class="token operator">=</span><span class="token number">2</span> <span class="token punctuation">\</span>
<span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0,1</span> <span class="token punctuation">\</span>
swift sft <span class="token punctuation">\</span>
    <span class="token parameter variable">--model</span> Qwen/QwQ-32B <span class="token punctuation">\</span>
    <span class="token parameter variable">--train_type</span> lora <span class="token punctuation">\</span>
    <span class="token parameter variable">--dataset</span> <span class="token string">'qwq-32b-distill.jsonl'</span> <span class="token punctuation">\</span>
              <span class="token string">'&lt;your-dataset-path&gt;'</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--torch_dtype</span> bfloat16 <span class="token punctuation">\</span>
    <span class="token parameter variable">--num_train_epochs</span> <span class="token number">1</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--per_device_train_batch_size</span> <span class="token number">1</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--per_device_eval_batch_size</span> <span class="token number">1</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--learning_rate</span> 1e-4 <span class="token punctuation">\</span>
    <span class="token parameter variable">--lora_rank</span> <span class="token number">8</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--lora_alpha</span> <span class="token number">32</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--target_modules</span> all-linear <span class="token punctuation">\</span>
    <span class="token parameter variable">--gradient_accumulation_steps</span> <span class="token number">8</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--eval_steps</span> <span class="token number">50</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--save_steps</span> <span class="token number">50</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--save_total_limit</span> <span class="token number">5</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--logging_steps</span> <span class="token number">5</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--max_length</span> <span class="token number">4096</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--output_dir</span> output <span class="token punctuation">\</span>
    <span class="token parameter variable">--warmup_ratio</span> <span class="token number">0.05</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--dataloader_num_workers</span> <span class="token number">4</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--model_author</span> swift <span class="token punctuation">\</span>
    <span class="token parameter variable">--model_name</span> swift-robot <span class="token punctuation">\</span>
    <span class="token parameter variable">--deepspeed</span> zero2
</code></pre>
    <p>
     自定义数据集可以参考以下格式：
    </p>
    <pre><code class="prism language-bash"><span class="token punctuation">{<!-- --></span><span class="token string">"messages"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token builtin class-name">:</span> <span class="token string">"system"</span>, <span class="token string">"content"</span><span class="token builtin class-name">:</span> <span class="token string">"你是个有用无害的助手"</span><span class="token punctuation">}</span>, <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token builtin class-name">:</span> <span class="token string">"user"</span>, <span class="token string">"content"</span><span class="token builtin class-name">:</span> <span class="token string">"告诉我明天的天气"</span><span class="token punctuation">}</span>, <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token builtin class-name">:</span> <span class="token string">"assistant"</span>, <span class="token string">"content"</span><span class="token builtin class-name">:</span> <span class="token string">"&lt;think&gt;<span class="token entity" title="\n">\n</span>...&lt;/think&gt;<span class="token entity" title="\n">\n</span><span class="token entity" title="\n">\n</span>明天天气晴朗"</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
<span class="token punctuation">{<!-- --></span><span class="token string">"messages"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token builtin class-name">:</span> <span class="token string">"system"</span>, <span class="token string">"content"</span><span class="token builtin class-name">:</span> <span class="token string">"你是个有用无害的数学计算器"</span><span class="token punctuation">}</span>, <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token builtin class-name">:</span> <span class="token string">"user"</span>, <span class="token string">"content"</span><span class="token builtin class-name">:</span> <span class="token string">"1+1等于几"</span><span class="token punctuation">}</span>, <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token builtin class-name">:</span> <span class="token string">"assistant"</span>, <span class="token string">"content"</span><span class="token builtin class-name">:</span> <span class="token string">"&lt;think&gt;<span class="token entity" title="\n">\n</span>...&lt;/think&gt;<span class="token entity" title="\n">\n</span><span class="token entity" title="\n">\n</span>等于2"</span><span class="token punctuation">}</span>, <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token builtin class-name">:</span> <span class="token string">"user"</span>, <span class="token string">"content"</span><span class="token builtin class-name">:</span> <span class="token string">"再加1呢"</span><span class="token punctuation">}</span>, <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token builtin class-name">:</span> <span class="token string">"assistant"</span>, <span class="token string">"content"</span><span class="token builtin class-name">:</span> <span class="token string">"&lt;think&gt;<span class="token entity" title="\n">\n</span>...&lt;/think&gt;<span class="token entity" title="\n">\n</span><span class="token entity" title="\n">\n</span>等于3"</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre>
    <p>
     训练显存占用：
    </p>
    <p>
     <img alt="图片" src="https://i-blog.csdnimg.cn/img_convert/6c411a2dc8eff602f2a5c05317d2bfa0.png"/>
    </p>
    <p>
     训练完成后，使用以下命令对训练后的权重进行推理，这里的`–adapters`需要替换成训练生成的last checkpoint文件夹。
    </p>
    <pre><code class="prism language-bash"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0</span> <span class="token punctuation">\</span>
swift infer <span class="token punctuation">\</span>
    <span class="token parameter variable">--adapters</span> output/vx-xxx/checkpoint-xxx <span class="token punctuation">\</span>
    <span class="token parameter variable">--stream</span> <span class="token boolean">true</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--max_new_tokens</span> <span class="token number">2048</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--infer_backend</span> pt
</code></pre>
    <p>
     推送模型到ModelScope：
    </p>
    <pre><code class="prism language-bash"><span class="token assign-left variable">CUDA_VISIBLE_DEVICES</span><span class="token operator">=</span><span class="token number">0</span> <span class="token punctuation">\</span>
swift <span class="token builtin class-name">export</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--adapters</span> output/vx-xxx/checkpoint-xxx <span class="token punctuation">\</span>
    <span class="token parameter variable">--push_to_hub</span> <span class="token boolean">true</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--hub_model_id</span> <span class="token string">'&lt;your-model-id&gt;'</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--hub_token</span> <span class="token string">'&lt;your-sdk-token&gt;'</span>
</code></pre>
   </div>
   <link href="./../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="./../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f35393539363939302f:61727469636c652f64657461696c732f313436313331343331" class_="artid" style="display:none">
 </p>
</div>


