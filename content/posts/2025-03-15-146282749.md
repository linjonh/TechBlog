---
layout: post
title: "SegRNN-源码理解验证集和测试集"
date: 2025-03-15 19:35:45 +0800
description: "问题，验证集到底是什么？验证集和测试集不是一样的嘛，调用的函数都是一样的。"
keywords: "【SegRNN 源码理解】验证集和测试集"
categories: ['扒代码']
tags: ['深度学习', '机器学习', 'Python']
artid: "146282749"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146282749
    alt: "SegRNN-源码理解验证集和测试集"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146282749
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146282749
cover: https://bing.ee123.net/img/rand?artid=146282749
image: https://bing.ee123.net/img/rand?artid=146282749
img: https://bing.ee123.net/img/rand?artid=146282749
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     【SegRNN 源码理解】验证集和测试集
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <pre><code class="hljs">       print("Epoch: {} cost time: {}".format(epoch + 1, time.time() - epoch_time))
            train_loss = np.average(train_loss)
            vali_loss = self.vali(vali_data, vali_loader, criterion)
            test_loss = self.vali(test_data, test_loader, criterion)</code></pre>
    <p>
     问题，验证集到底是什么？验证集和测试集不是一样的嘛，调用的函数都是一样的
    </p>
    <ul>
     <li>
      ‌
      <strong>
       训练集
      </strong>
      ‌：用于模型拟合的数据样本，模型通过训练集学习数据的模式。‌23
     </li>
     <li>
      ‌
      <strong>
       验证集
      </strong>
      ‌：在模型训练过程中单独留出的样本集，用于调整模型的超参数和初步评估模型的能力。
     </li>
     <li>
      ‌
      <strong>
       测试集
      </strong>
      ‌：用于评估最终模型的泛化能力，但不能用于调参或选择特征等算法相关的选择。
     </li>
    </ul>
    <h2>
     模型训练
    </h2>
    <pre><code class="hljs">Use GPU: cuda:0
&gt;&gt;&gt;&gt;&gt;&gt;&gt;start training : illness_60_24_SegRNN_custom_ftM_sl60_pl24_dm512_dr0.0_rtgru_dwpmf_sl12_mae_test_0&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
train 593
val 74
test 170
Epoch: 1 cost time: 207.93248915672302
Epoch: 1, Steps: 37 | Train Loss: 0.6410040 Vali Loss: 0.6463686 Test Loss: 1.3848118
Validation loss decreased (inf --&gt; 0.646369).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 62.998446226119995
Epoch: 2, Steps: 37 | Train Loss: 0.4989109 Vali Loss: 0.3734880 Test Loss: 1.0756294
Validation loss decreased (0.646369 --&gt; 0.373488).  Saving model ...
Updating learning rate to 0.001
Epoch: 3 cost time: 9.611003160476685
Epoch: 3, Steps: 37 | Train Loss: 0.3889044 Vali Loss: 0.3518658 Test Loss: 1.0003682
Validation loss decreased (0.373488 --&gt; 0.351866).  Saving model ...
Updating learning rate to 0.001
Epoch: 4 cost time: 9.890604734420776
Epoch: 4, Steps: 37 | Train Loss: 0.3497405 Vali Loss: 0.4116149 Test Loss: 1.0889241
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0008
Epoch: 5 cost time: 11.188161849975586
Epoch: 5, Steps: 37 | Train Loss: 0.3310404 Vali Loss: 0.3023584 Test Loss: 0.8752079
Validation loss decreased (0.351866 --&gt; 0.302358).  Saving model ...
Updating learning rate to 0.0006400000000000002
Epoch: 6 cost time: 10.03389573097229
Epoch: 6, Steps: 37 | Train Loss: 0.2898096 Vali Loss: 0.3139473 Test Loss: 0.8356396
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005120000000000001
Epoch: 7 cost time: 9.94393253326416
Epoch: 7, Steps: 37 | Train Loss: 0.2752131 Vali Loss: 0.2802873 Test Loss: 0.8298662
Validation loss decreased (0.302358 --&gt; 0.280287).  Saving model ...
Updating learning rate to 0.0004096000000000001
Epoch: 8 cost time: 47.79346227645874
Epoch: 8, Steps: 37 | Train Loss: 0.2621685 Vali Loss: 0.2933615 Test Loss: 0.7996481
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003276800000000001
Epoch: 9 cost time: 13.392791509628296
Epoch: 9, Steps: 37 | Train Loss: 0.2522859 Vali Loss: 0.2907325 Test Loss: 0.7990233
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0002621440000000001
Epoch: 10 cost time: 13.887414693832397
Epoch: 10, Steps: 37 | Train Loss: 0.2448694 Vali Loss: 0.2579939 Test Loss: 0.7900772
Validation loss decreased (0.280287 --&gt; 0.257994).  Saving model ...
Updating learning rate to 0.0002097152000000001
Epoch: 11 cost time: 10.111633777618408
Epoch: 11, Steps: 37 | Train Loss: 0.2389001 Vali Loss: 0.2839487 Test Loss: 0.7887061
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001677721600000001
Epoch: 12 cost time: 10.194474697113037
Epoch: 12, Steps: 37 | Train Loss: 0.2347271 Vali Loss: 0.2807631 Test Loss: 0.7819831
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00013421772800000008
Epoch: 13 cost time: 10.330410718917847
Epoch: 13, Steps: 37 | Train Loss: 0.2332735 Vali Loss: 0.2688113 Test Loss: 0.7899975
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00010737418240000006
Epoch: 14 cost time: 10.05665922164917
Epoch: 14, Steps: 37 | Train Loss: 0.2266295 Vali Loss: 0.2714401 Test Loss: 0.7808742
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.589934592000005e-05
Epoch: 15 cost time: 9.99810791015625
Epoch: 15, Steps: 37 | Train Loss: 0.2243598 Vali Loss: 0.2903035 Test Loss: 0.7775844
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.871947673600005e-05
Epoch: 16 cost time: 10.282510757446289
Epoch: 16, Steps: 37 | Train Loss: 0.2225707 Vali Loss: 0.2826172 Test Loss: 0.7801220
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.497558138880004e-05
Epoch: 17 cost time: 10.422674179077148
Epoch: 17, Steps: 37 | Train Loss: 0.2194050 Vali Loss: 0.2822956 Test Loss: 0.7810600
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.398046511104004e-05
Epoch: 18 cost time: 10.491711378097534
Epoch: 18, Steps: 37 | Train Loss: 0.2180462 Vali Loss: 0.2709097 Test Loss: 0.7783265
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.518437208883203e-05
Epoch: 19 cost time: 10.142646074295044
Epoch: 19, Steps: 37 | Train Loss: 0.2161210 Vali Loss: 0.2623108 Test Loss: 0.7727545
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.8147497671065623e-05
Epoch: 20 cost time: 9.860526323318481
Epoch: 20, Steps: 37 | Train Loss: 0.2158552 Vali Loss: 0.2736951 Test Loss: 0.7759588
EarlyStopping counter: 10 out of 10
Early stopping
&gt;&gt;&gt;&gt;&gt;&gt;&gt;testing : illness_60_24_SegRNN_custom_ftM_sl60_pl24_dm512_dr0.0_rtgru_dwpmf_sl12_mae_test_0&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</code></pre>
    <h2>
     <img alt="" height="622" src="https://i-blog.csdnimg.cn/direct/3d2f454f87514f95881603b392b0106a.png" width="2018">
      <img alt="" height="1218" src="https://i-blog.csdnimg.cn/direct/5d2da23d66b347b1a435c01968be738e.png" width="1960"/>
     </img>
    </h2>
    <p>
     <img alt="" height="824" src="https://i-blog.csdnimg.cn/direct/21b267b384e445ad94fd4cb60da5ef59.png" width="1984"/>
    </p>
    <h2>
     早停机制
    </h2>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f323330315f37373534393937372f:61727469636c652f64657461696c732f313436323832373439" class_="artid" style="display:none">
 </p>
</div>


