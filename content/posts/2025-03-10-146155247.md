---
layout: post
title: "动手学习深度学习13.丢弃法-Dropout"
date: 2025-03-10 15:19:32 +0800
description: "丢弃法，控制模型复杂度方法，多用在多层感知机的隐藏层输出上"
keywords: "[动手学习深度学习]13.丢弃法 Dropout"
categories: ['深度学习']
tags: ['深度学习', '学习', '人工智能']
artid: "146155247"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146155247
    alt: "动手学习深度学习13.丢弃法-Dropout"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146155247
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146155247
cover: https://bing.ee123.net/img/rand?artid=146155247
image: https://bing.ee123.net/img/rand?artid=146155247
img: https://bing.ee123.net/img/rand?artid=146155247
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     [动手学习深度学习]13.丢弃法 Dropout
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     权重衰退是常见处理过拟合的方法
     <br/>
     丢弃法比权重衰退效果要好
    </p>
    <h2>
     <a id="_2">
     </a>
     动机
    </h2>
    <ul>
     <li>
      一个好的模型 需要第输入数据的扰动具有鲁棒性
      <ul>
       <li>
        使用有噪音的数据等价于Tikhonov正则
       </li>
       <li>
        丢弃法：在层之间加入噪音
       </li>
      </ul>
     </li>
    </ul>
    <p>
     （所以丢弃法其实是一个正则）
    </p>
    <h2>
     <a id="_8">
     </a>
     无偏差的加入噪音
    </h2>
    <ul>
     <li>
      对x加入噪音得到x’，我们希望
      <br/>
      <span class="katex--display">
       <span class="katex-display">
        <span class="katex">
         <span class="katex-mathml">
          E 
          
         
           [ 
          
          
          
            x 
           
          
            ′ 
           
          
         
           ] 
          
         
           = 
          
         
           x 
          
         
        
          E[x'] = x
         </span>
         <span class="katex-html">
          <span class="base">
           <span class="strut" style="height: 1.0519em; vertical-align: -0.25em;">
           </span>
           <span class="mord mathnormal" style="margin-right: 0.0576em;">
            E
           </span>
           <span class="mopen">
            [
           </span>
           <span class="mord">
            <span class="mord mathnormal">
             x
            </span>
            <span class="msupsub">
             <span class="vlist-t">
              <span class="vlist-r">
               <span class="vlist" style="height: 0.8019em;">
                <span class="" style="top: -3.113em; margin-right: 0.05em;">
                 <span class="pstrut" style="height: 2.7em;">
                 </span>
                 <span class="sizing reset-size6 size3 mtight">
                  <span class="mord mtight">
                   <span class="mord mtight">
                    ′
                   </span>
                  </span>
                 </span>
                </span>
               </span>
              </span>
             </span>
            </span>
           </span>
           <span class="mclose">
            ]
           </span>
           <span class="mspace" style="margin-right: 0.2778em;">
           </span>
           <span class="mrel">
            =
           </span>
           <span class="mspace" style="margin-right: 0.2778em;">
           </span>
          </span>
          <span class="base">
           <span class="strut" style="height: 0.4306em;">
           </span>
           <span class="mord mathnormal">
            x
           </span>
          </span>
         </span>
        </span>
       </span>
      </span>
     </li>
     <li>
      丢弃法对每个元素进行如下扰动
      <br/>
      <img alt="" src="https://i-blog.csdnimg.cn/direct/8439e27d5aef4141afd9ae768490bc84.png"/>
     </li>
    </ul>
    <h2>
     <a id="_15">
     </a>
     使用
    </h2>
    <p>
     通常将丢弃法作用在隐藏全连接层的输出上
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/f30c75aa8cd34650ac4252289ca322e8.png">
      <br/>
      对隐藏层的每一个神经元做dropout，使每一个都有p概率变为0
      <br/>
      即去掉一些权重（每次可能去掉的不一样）
     </img>
    </p>
    <blockquote>
     <p>
      在训练中使用
     </p>
    </blockquote>
    <h2>
     <a id="_21">
     </a>
     推理中的丢弃法
    </h2>
    <ul>
     <li>
      正则项只在训练中使用：他们影响模型参数的更新
     </li>
     <li>
      在推理过程中，dropout直接返回输入
      <pre><code class="prism language-python">h<span class="token operator">=</span>dropout<span class="token punctuation">(</span>h<span class="token punctuation">)</span>
</code></pre>
      这样也能保证确定性的输出
      <br/>
      每次随机的采样一些子神经网络
     </li>
    </ul>
    <h2>
     <a id="_29">
     </a>
     总结
    </h2>
    <ul>
     <li>
      丢弃法将一些输出项随机置0来控制模型复杂度
     </li>
     <li>
      常作用在多层感知机的隐藏层输出上
     </li>
     <li>
      丢弃概率使控制模型复杂度的超参数
     </li>
    </ul>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f79757269353135312f:61727469636c652f64657461696c732f313436313535323437" class_="artid" style="display:none">
 </p>
</div>


