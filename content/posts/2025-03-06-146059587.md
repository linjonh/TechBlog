---
arturl_encode: "68747470733a2f2f:626c6f672e6373646e2e6e65742f753031323734353439392f:61727469636c652f64657461696c732f313436303539353837"
layout: post
title: "Kafka-消息不丢失全方位保障策略"
date: 2025-03-06 09:41:01 +0800
description: "要确保 Kafka 消息不丢失，需要从生产者、Broker 和消费者三个层面进行综合考虑和配置。生产者通过合理设置确认机制和重试机制，Broker 利用多副本、最小同步副本数和刷盘策略，消费者采用手动提交偏移量和异常处理等方法，全方位保障消息的可靠传输。在实际应用中，需要根据具体的业务场景和性能要求，灵活调整这些配置，以达到消息可靠性和系统性能的平衡。"
keywords: "Kafka 消息不丢失：全方位保障策略"
categories: ['未分类']
tags: ['分布式', 'Linq', 'Kafka']
artid: "146059587"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146059587
    alt: "Kafka-消息不丢失全方位保障策略"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146059587
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146059587
cover: https://bing.ee123.net/img/rand?artid=146059587
image: https://bing.ee123.net/img/rand?artid=146059587
img: https://bing.ee123.net/img/rand?artid=146059587
---

# Kafka 消息不丢失：全方位保障策略

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/2efd88d350b94c49b6e50d0c6838b813.png)

## Kafka 消息不丢失：全方位保障策略

### 引言

在现代分布式系统中，Kafka 作为一款高性能、高可扩展性的消息队列，被广泛应用于数据传输、日志收集、实时流处理等场景。然而，消息丢失是使用 Kafka 时可能面临的一个严重问题，这可能会导致数据不一致、业务逻辑错误等后果。因此，确保 Kafka 消息不丢失至关重要。本文将从生产者、Broker 和消费者三个层面详细介绍保障 Kafka 消息不丢失的方法。

### 生产者层面保障

#### 确认机制（acks）

生产者在发送消息时，
`acks`
参数决定了消息的确认机制，它有三个可选值：

* **acks = 0**
  ：生产者发送消息后，不等待 Broker 的确认，直接认为消息发送成功。这种方式虽然吞吐量最高，但存在消息丢失的风险。因为如果消息在传输过程中丢失，生产者无法得知。
* **acks = 1**
  ：生产者发送消息后，等待 Leader 分区的确认。只要 Leader 分区接收到消息并写入本地日志，就会给生产者返回确认信息。此方式能保证消息在 Leader 分区不丢失，但如果 Leader 分区在将消息同步到 Follower 分区之前发生故障，可能会导致消息丢失。
* **acks = all 或 -1**
  ：生产者发送消息后，等待 Leader 分区和所有 ISR（In - Sync Replicas，同步副本集合）中的 Follower 分区都确认收到消息后，才认为消息发送成功。这种方式能最大程度保证消息不丢失，但会降低吞吐量。

以下是 Java 代码示例：

```java
import org.apache.kafka.clients.producer.*;
import java.util.Properties;

public class KafkaProducerExample {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        // 设置 acks 为 all
        props.put("acks", "all"); 

        Producer<String, String> producer = new KafkaProducer<>(props);
        ProducerRecord<String, String> record = new ProducerRecord<>("test - topic", "key", "value");
        producer.send(record, new Callback() {
            @Override
            public void onCompletion(RecordMetadata metadata, Exception exception) {
                if (exception != null) {
                    System.err.println("Failed to send message: " + exception.getMessage());
                } else {
                    System.out.println("Message sent successfully. Offset: " + metadata.offset());
                }
            }
        });
        producer.close();
    }
}

```

#### 重试机制

生产者可以设置
`retries`
参数来指定消息发送失败时的重试次数。当消息发送失败时，生产者会自动进行重试，直到达到重试次数上限。示例代码如下：

```java
props.put("retries", 3); 

```

### Broker 层面保障

#### 多副本机制

Kafka 通过多副本机制保证消息的可靠性。每个分区可以有多个副本，其中一个是 Leader 副本，其余是 Follower 副本。生产者和消费者只与 Leader 副本进行交互，Follower 副本会从 Leader 副本同步消息。
  
通过配置
`replication.factor`
参数来指定每个分区的副本数，建议将其设置为大于 1 的值，例如在
`server.properties`
中设置：

```properties
default.replication.factor = 3

```

#### 最小同步副本数（min.insync.replicas）

设置
`min.insync.replicas`
参数可以指定 ISR 集合中至少需要多少个副本同步消息，生产者才能认为消息发送成功。例如：

```properties
min.insync.replicas = 2

```

当
`acks = all`
时，只有当 ISR 集合中至少有
`min.insync.replicas`
个副本同步了消息，生产者才会收到确认信息。

#### 刷盘策略

可以通过调整
`log.flush.interval.messages`
和
`log.flush.interval.ms`
参数来控制消息刷盘的频率。例如：

```properties
# 每 10000 条消息刷一次盘
log.flush.interval.messages = 10000
# 每 1000 毫秒刷一次盘
log.flush.interval.ms = 1000

```

### 消费者层面保障

#### 手动提交偏移量

消费者可以通过设置
`enable.auto.commit`
为
`false`
来关闭自动提交偏移量功能，然后手动提交偏移量。只有在消息处理完成后，才提交偏移量，这样可以避免在消息处理过程中出现异常导致消息丢失。

以下是 Java 代码示例：

```java
import org.apache.kafka.clients.consumer.*;
import java.time.Duration;
import java.util.Collections;
import java.util.Properties;

public class KafkaConsumerExample {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "test - group");
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        // 关闭自动提交偏移量
        props.put("enable.auto.commit", "false"); 

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList("test - topic"));

        try {
            while (true) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
                for (ConsumerRecord<String, String> record : records) {
                    System.out.printf("Received message: key = %s, value = %s%n", record.key(), record.value());
                    // 处理消息
                }
                // 手动提交偏移量
                consumer.commitSync(); 
            }
        } finally {
            consumer.close();
        }
    }
}

```

#### 处理消费异常

在消费者处理消息的过程中，需要捕获并处理可能出现的异常，确保在异常情况下不会丢失消息。例如，在处理消息时可以使用事务机制，保证消息处理的原子性。

### 总结

要确保 Kafka 消息不丢失，需要从生产者、Broker 和消费者三个层面进行综合考虑和配置。生产者通过合理设置确认机制和重试机制，Broker 利用多副本、最小同步副本数和刷盘策略，消费者采用手动提交偏移量和异常处理等方法，全方位保障消息的可靠传输。在实际应用中，需要根据具体的业务场景和性能要求，灵活调整这些配置，以达到消息可靠性和系统性能的平衡。