---
layout: post
title: "动手实验TCP-orphan-socket-的产生与消亡"
date: 2025-03-07 10:40:47 +0800
description: "没有在 Wiki 中找到关于孤儿 socket 的定义，在 StackOverflow 中找到了一个比较通俗易懂的解释：下面一段是 DeepSeek 给出的解释：总的来说就是当程序调用 close() 函数关闭 socket 后，socket 就和应用程序无关了，但此时 TCP 终止流程还没有走完，所以内核里还有这些 socket 的数据，这些 socket 就是所谓的孤儿 socket。下面我们结合源码和实验分析下哪些情况下的 socket 会被视为孤儿 socket。可以用ss -s或者。"
keywords: "【动手实验】TCP orphan socket 的产生与消亡"
categories: ['未分类']
tags: ['网络协议', '网络', 'Tcp']
artid: "146089453"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146089453
    alt: "动手实验TCP-orphan-socket-的产生与消亡"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146089453
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146089453
cover: https://bing.ee123.net/img/rand?artid=146089453
image: https://bing.ee123.net/img/rand?artid=146089453
img: https://bing.ee123.net/img/rand?artid=146089453
---

# 【动手实验】TCP orphan socket 的产生与消亡

之前在实验中提到了 tcp_max_orphans 和 tcp_orphan_retries 两个参数，我们使用 `ss -s` 命令查看当前系统中的
socket 状态也有 orphan 状态的 socket，本篇文章我们就来分析下到底什么情况下的 socket 才会被视为 orphan socket。

    
    
    # ubuntu @ node1 in ~ [12:07:15]
    $ ss -s
    Total: 184
    TCP:   14 (estab 5, closed 1, orphaned 0, timewait 1)
    

### 什么是孤儿(Orphan) socket？

没有在 Wiki 中找到关于孤儿 socket 的定义，在 StackOverflow 中找到了一个比较通俗易懂的解释：

> Do you have “too many” orphan sockets?
>
> First of all: what’s an orphan socket? It’s simply a socket that isn’t
> associated to a file descriptor. For instance, after you close() a socket,
> you no longer hold a file descriptor to reference it, but it still exists
> because the kernel has to keep it around for a bit more until TCP is done
> with it. Because orphan sockets aren’t very useful to applications (since
> applications can’t interact with them), the kernel is trying to limit the
> amount of memory consumed by orphans, and it does so by limiting the number
> of orphans that stick around. If you’re running a frontend web server (or an
> HTTP load balancer), then you’ll most likely have a sizeable number of
> orphans, and that’s perfectly normal.

下面一段是 DeepSeek 给出的解释：

> Orphan Sockets refer to TCP sockets that no longer have an associated user
> process but remain in the operating system’s kernel network stack. These
> sockets persist because the owning process terminated (e.g., crashed or
> exited abruptly) without properly closing the socket, leaving the kernel to
> manage cleanup

总的来说就是当程序调用 close() 函数关闭 socket 后，socket 就和应用程序无关了，但此时 TCP 终止流程还没有走完，所以内核里还有这些
socket 的数据，这些 socket 就是所谓的孤儿 socket。下面我们结合源码和实验分析下哪些情况下的 socket 会被视为孤儿 socket。

### Orphan socket 的产生

上面提到内核是在程序调用 close() 函数后的状态视为 orphan socket，因此内核中 orphan socket 的产生主要是在
`tcp_close` 函数中，其内部调用 `__tcp_close` 函数执行主要逻辑：我们来分析下。

    
    
    // https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp.c#L2910
    void tcp_close(struct sock *sk, long timeout)
    {
    	lock_sock(sk);
    	__tcp_close(sk, timeout);
    	release_sock(sk);
    	sock_put(sk);
    }
    
    void __tcp_close(struct sock *sk, long timeout)
    {
    	struct sk_buff *skb;
    	int data_was_unread = 0;
    	int state;
    
    	WRITE_ONCE(sk->sk_shutdown, SHUTDOWN_MASK);
       
      // 处于 listen 状态，直接进入 TCP_CLOSE 状态
    	if (sk->sk_state == TCP_LISTEN) {
    		tcp_set_state(sk, TCP_CLOSE);
    
    		/* Special case. */
    		inet_csk_listen_stop(sk);
    
    		goto adjudge_to_death;
    	}
     // ... 代码省略
    }
    

可以看到，在 __tcp_close 函数中，有一个 `adjudge_to_death`的 goto 标签，这部分代码执行了**将 socket 变为
orphan 状态的逻辑，并增加 orphan socket 计数** ，然后执行一系列状态变迁逻辑后，如果 socket 处于 TCP_CLOSE
状态，则清理掉 socket 并减少 orphan socket 计数。

  * 执行清理，增加 orphan socket 计数

    
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp.c#L2828
    adjudge_to_death:
    	state = sk->sk_state;
    	sock_hold(sk);
      // 执行清理，将 socket 变为 orphan 状态
    	sock_orphan(sk);
    	local_bh_disable();
    	bh_lock_sock(sk);
    	/* remove backlog if any, without releasing ownership. */
    	__release_sock(sk);
      // 增加 orphan socket 计数
    	this_cpu_inc(tcp_orphan_count);
    
    // ...代码省略：状态变迁逻辑
    
    

  * 具体的清理任务

    
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/include/net/sock.h#L1992
    /* Detach socket from process context.
     * Announce socket dead, detach it from wait queue and inode.
     * Note that parent inode held reference count on this struct sock,
     * we do not release it in this function, because protocol
     * probably wants some additional cleanups or even continuing
     * to work with this socket (TCP).
     */
    static inline void sock_orphan(struct sock *sk)
    {
    	write_lock_bh(&sk->sk_callback_lock);
      // 设置 SOCK_DEAD 标志，标记 socket 已死亡，不在于任何进程有关系
    	sock_set_flag(sk, SOCK_DEAD);
      // 设置 socket 为 NULL，不在于文件描述符有关系
    	sk_set_socket(sk, NULL);
      // 清空等待队列
    	sk->sk_wq  = NULL;
    	write_unlock_bh(&sk->sk_callback_lock);
    }
    

  * 减少 orphan socket 计数

    
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp.c#L2890
    void __tcp_close(struct sock *sk, long timeout)
    {
      // ... 代码省略
    
      // 如果 socket 处于 TCP_CLOSE 状态，则执行清理
    	if (sk->sk_state == TCP_CLOSE) {
    		// ... 代码省略
        // 销毁 socket，减少 orphan socket 计数
    		inet_csk_destroy_sock(sk);
    	}
    }
    
    // 具体的销毁任务
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/inet_connection_sock.c#L1005
    void inet_csk_destroy_sock(struct sock *sk)
    {
    	// ... 代码省略
      // 减少 orphan socket 计数
    	this_cpu_dec(*sk->sk_prot->orphan_count);
    
    	sock_put(sk);
    }
    

由此我们知道，内核在执行 close() 时会先将 socket 视为 orphan 状态，增加计数，执行完 TCP 状态转换后，如果 socket 进入
CLOSE 状态，那么 orphan socket 计数会减少，也就是说此时不会有 orphan socket
了。我们在来分析下具体的状态转换逻辑，看哪些情况下 socket 会进入 CLOSE 状态。

  1. TCP 主动关闭连接。如果 socket 处于 TCP_LISTEN 状态，则直接进入 TCP_CLOSE 状态，然后执行 adjudge_to_death 标签，增加 orphan socket 计数，但最终会走到 `inet_csk_destroy_sock` 函数，减少 orphan socket 计数，并销毁 socket。

    
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp.c#L2747
    if (sk->sk_state == TCP_LISTEN) {
      // 设置 socket 为 TCP_CLOSE 状态
    	tcp_set_state(sk, TCP_CLOSE);
    
    		/* Special case. */
    		inet_csk_listen_stop(sk);
    
    		goto adjudge_to_death;
    	}
    

  2. 如果接收队列中存在未被应用读取的数据，则进入 TCP_CLOSE 状态，并向对端发送 RST 报文，然后销毁 socket。正常情况下，应用应该会在处理完数据后调用 close()，所以如果调用 close() 时还没有处理完数据，会被视为异常关闭，比如在应用异常崩溃、网络中断时会出现这种情况，因此会直接发送 RST 报文，并销毁 socket。

    
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp.c#L2784
     else if (data_was_unread) {
    		/* Unread data was tossed, zap the connection. */
    		NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPABORTONCLOSE);
        // 设置 socket 为 TCP_CLOSE 状态
    		tcp_set_state(sk, TCP_CLOSE);
    		tcp_send_active_reset(sk, sk->sk_allocation);
    
    

  3. 系统开启了 so_linger 并设置为0，表示 0 延迟关闭 ，socket 会丢弃数据并发送 RST 报文，然后进入 TCP_CLOSE 状态，并销毁 socket。

    
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp.c#L2789
    else if (sock_flag(sk, SOCK_LINGER) && !sk->sk_lingertime) {
    		/* Check zero linger _after_ checking for unread data. */
    		sk->sk_prot->disconnect(sk, 0);
    		NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPABORTONDATA);
    	}
    

disconnect 调用会执行 `tcp_disconnect` 函数，该函数会发送 RST 报文，并设置 socket 为 TCP_CLOSE
状态，然后销毁 socket。

    
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp.c#L2967
    int tcp_disconnect(struct sock *sk, int flags)
    {
    	struct inet_sock *inet = inet_sk(sk);
    	struct inet_connection_sock *icsk = inet_csk(sk);
    	struct tcp_sock *tp = tcp_sk(sk);
    	int old_state = sk->sk_state;
    	u32 seq;
    
    	/* Deny disconnect if other threads are blocked in sk_wait_event()
    	 * or inet_wait_for_connect().
    	 */
    	if (sk->sk_wait_pending)
    		return -EBUSY;
    
      // 设置 socket 为 TCP_CLOSE 状态
    	if (old_state != TCP_CLOSE)
    		tcp_set_state(sk, TCP_CLOSE);
    

除了以上 3 种情况，后面就是正常的 TCP
状态转换逻辑了，代码从状态机映射中，获取到下个状态值做状态转换，我们最常看到的关闭时的状态转换就是在这里执行的，可以结合图例加深理解。

![](https://i-blog.csdnimg.cn/img_convert/80261e68f36acbf45272bda0d343a013.png)

    
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp.c#L2793
    else if (tcp_close_state(sk)) {
    		// 完成状态转换后，发送 FIN 报文
    		tcp_send_fin(sk);
    	}
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp.c#L2664
    
    static const unsigned char new_state[16] = {
      /* current state:        new state:      action:	*/
      [0 /* (Invalid) */]	= TCP_CLOSE,
      [TCP_ESTABLISHED]	= TCP_FIN_WAIT1 | TCP_ACTION_FIN,
      [TCP_SYN_SENT]	= TCP_CLOSE,
      [TCP_SYN_RECV]	= TCP_FIN_WAIT1 | TCP_ACTION_FIN,
      [TCP_FIN_WAIT1]	= TCP_FIN_WAIT1,
      [TCP_FIN_WAIT2]	= TCP_FIN_WAIT2,
      [TCP_TIME_WAIT]	= TCP_CLOSE,
      [TCP_CLOSE]		= TCP_CLOSE,
      [TCP_CLOSE_WAIT]	= TCP_LAST_ACK  | TCP_ACTION_FIN,
      [TCP_LAST_ACK]	= TCP_LAST_ACK,
      [TCP_LISTEN]		= TCP_CLOSE,
      [TCP_CLOSING]		= TCP_CLOSING,
      [TCP_NEW_SYN_RECV]	= TCP_CLOSE,	/* should not happen ! */
    };
    
    static int tcp_close_state(struct sock *sk)
    {
    	int next = (int)new_state[sk->sk_state];
    	int ns = next & TCP_STATE_MASK;
    
    	tcp_set_state(sk, ns);
    
    	return next & TCP_ACTION_FIN;
    }
    

结合状态变迁和后续的代码执行，我们知道最终 socket 的状态只会是
CLOSE，FIN_WAIT1、FIN_WAIT_2、CLOSING、LAST_ACK中的一种。除了 CLOSE 状态，其他状态下都不会执行
`inet_csk_destroy_sock` 函数，也就不会减少 orphan socket 计数，因此这些状态的 socket 都会被视为 orphan
socket。CLOSING 状态的构造相对麻烦，这里我们做实验看下 socket 在 FIN_WAIT_1，LAST_ACK 状态时 orphan
socket 的计数变化。FIN_WAIT_2 状态的处理有一些特殊，我们在下一节做更详细的探讨。

首先服务端和客户端查看 socket 统计信息，orphan 计数为 0。

    
    
    $ ss -s
    Total: 176
    TCP:   15 (estab 5, closed 5, orphaned 0, timewait 5)
    

#### 1\. FIN_WAIT_1 状态

这里用 Go 程序做服务端和客户端，代码如下：

  * 服务端程序

    
    
    package main
    
    import (
      "log"
      "net"
      "time"
    )
    
    func main() {
      l, err := net.Listen("tcp", ":8888")
      if err != nil {
        log.Printf("failed to listen due to %v", err)
      }
      defer l.Close()
      log.Println("listen :8888 success")
    
      for {
        time.Sleep(time.Second * 100)
      }
    }
    

  * 客户端程序

    
    
    package main
    
    import (
      "context"
      "log"
      "net"
      "os"
      "os/signal"
      "sync"
      "syscall"
      "time"
    )
    
    var wg sync.WaitGroup
    
    func establishConn(ctx context.Context, i int) {
      defer wg.Done()
      conn, err := net.DialTimeout("tcp", "172.19.0.12:8888", time.Second*50)
      if err != nil {
        log.Printf("%d, dial error: %v", i, err)
        return
      }
      log.Printf("%d, dial success", i)
      _, err = conn.Write([]byte("hello world"))
      if err != nil {
        log.Printf("%d, send error: %v", i, err)
        return
      }
      select {
      case <-ctx.Done():
        log.Printf("%d, dail close", i)
      }
    }
    
    func main() {
      ctx, cancel := context.WithCancel(context.Background())
      // 并发请求 10 次服务端，连接建立成功后发送数据
      for i := 0; i < 10; i++ {
        wg.Add(1)
       time.Sleep(1 * time.Millisecond)
        go establishConn(ctx, i)
      }
    
      go func() {
        sc := make(chan os.Signal, 1)
        signal.Notify(sc, syscall.SIGINT)
        select {
        case <-sc:
          cancel()
        }
      }()
    
      wg.Wait()
      log.Printf("client exit")
    }
    

我们使用 iptables DROP 掉服务端返回的 ACK 包，使客户端处于 FIN_WAIT_1 状态，然后查看 socket 统计信息，预期
orphan 计数为 10。

服务端 DROP 客户端的 FIN 包

    
    
    $ sudo iptables -A INPUT -p tcp --dport 8888 --tcp-flags FIN FIN -j DROP
    

我们运行客户端命令后按下 ctrl+c 中断客户端程序，查看 socket 统计信息，orphan 计数为 10，符合预期。

    
    
    $ ss -ant | grep -E "Recv|8888"
    State      Recv-Q Send-Q Local Address:Port    Peer Address:Port Process
    FIN-WAIT-1 0      1        172.19.0.15:48344    172.19.0.12:8888
    FIN-WAIT-1 0      1        172.19.0.15:48290    172.19.0.12:8888
    FIN-WAIT-1 0      1        172.19.0.15:48300    172.19.0.12:8888
    FIN-WAIT-1 0      1        172.19.0.15:48322    172.19.0.12:8888
    FIN-WAIT-1 0      1        172.19.0.15:48276    172.19.0.12:8888
    FIN-WAIT-1 0      1        172.19.0.15:48302    172.19.0.12:8888
    FIN-WAIT-1 0      1        172.19.0.15:48330    172.19.0.12:8888
    FIN-WAIT-1 0      1        172.19.0.15:48288    172.19.0.12:8888
    FIN-WAIT-1 0      1        172.19.0.15:48310    172.19.0.12:8888
    FIN-WAIT-1 0      1        172.19.0.15:48334    172.19.0.12:8888
    
    # ubuntu @ node3 in ~ [18:03:09]
    $ ss -s
    Total: 209
    TCP:   30 (estab 10, closed 4, orphaned 10, timewait 4)
    

#### 2\. LAST_ACK 状态

这里我用 nc 启动服务端，然后在客户端发起两次连接:

    
    
    # 服务端
    $ nc -k -l 172.19.0.12 8888
    
    # 客户端，开两个终端发起两次
    $ nc 172.19.0.12 8888
    

因为 nc 没有数据需要处理，所以服务端收到客户端的 FIN 包后会将 ACK-FIN 包一起发，然后进入 LAST_ACK 状态，我们在客户端设置
iptables 规则将包丢弃，这样客户端就不会收到 ACK-FIN 包，服务端就会一直处于 LAST_ACK 状态。

    
    
    # DROP 源端口为 8888 的 ACK-FIN 包
    sudo iptables -A INPUT -p tcp --sport 8888 --tcp-flags ACK,FIN ACK,FIN -j DROP
    

设置完成后客户端按下 ctrl+c 中断连接，查看服务端的 socket 统计信息，可以看到有 2 个 LAST_ACK 状态的 socket，orphan
计数为 2，符合预期。

    
    
    $ ss -ant | grep -E "Recv|:8888" && ss -s
    State      Recv-Q Send-Q Local Address:Port    Peer Address:Port Process
    LISTEN     0      1        172.19.0.12:8888         0.0.0.0:*
    LAST-ACK   0      1        172.19.0.12:8888     172.19.0.15:48566
    LAST-ACK   0      1        172.19.0.12:8888     172.19.0.15:36574
    Total: 212
    TCP:   21 (estab 10, closed 2, orphaned 2, timewait 2)
    

### Orphan socket 的消亡

知道了哪些状态的 socket 会被视为 orphan socket，我们就可以分析下这些 socket 是如何消失的。

#### FIN-WAIT-2 下的 socket 处理

我们上面分析了 FIN_WAIT_2 状态下的 socket 应该也算是 orphan，但如果执行正常连接关闭操作时，查看 `ss -s` 统计会发现
orphan 为 0。下面用实验验证下：

  * 服务端使用 nc 监听 8888，客户端发起三个连接

    
    
    # 服务端
    $ nc -k -l 172.19.0.12 8888
    
    # 客户端，开三个窗口连接服务端
    $ nc 172.19.0.12 8888
    

连接建立成功后，使用 iptables 将服务端的 FIN 包 drop 点然后 ctrl + c 终止客户端连接，查看统计。

    
    
    $ sudo iptables -A INPUT -p tcp --sport 8888 --tcp-flags FIN FIN -j DROP
    

可以看到客户端有 3 条 FIN-WAIT-2 的 socket，但 orphaned 计数为 0。

    
    
    $ ss -ant | grep -E "Recv|:8888" && ss -s
    State      Recv-Q Send-Q Local Address:Port    Peer Address:Port Process
    ESTAB      0      0        172.19.0.15:42190    172.19.0.12:8888
    ESTAB      0      0        172.19.0.15:42174    172.19.0.12:8888
    ESTAB      0      0        172.19.0.15:41654    172.19.0.12:8888
    Total: 222
    TCP:   27 (estab 15, closed 6, orphaned 0, timewait 6)
    
    Transport Total     IP        IPv6
    RAW	  1         0         1
    UDP	  9         7         2
    TCP	  21        20        1
    INET	  31        27        4
    FRAG	  0         0         0
    
    
    # ubuntu @ node3 in ~ [15:46:37]
    $ ss -ant | grep -E "Recv|:8888" && ss -s
    State      Recv-Q Send-Q Local Address:Port    Peer Address:Port Process
    FIN-WAIT-2 0      0        172.19.0.15:42190    172.19.0.12:8888
    FIN-WAIT-2 0      0        172.19.0.15:42174    172.19.0.12:8888
    FIN-WAIT-2 0      0        172.19.0.15:41654    172.19.0.12:8888
    Total: 219
    TCP:   29 (estab 12, closed 10, orphaned 0, timewait 10)
    

我们结合源码来分析下内核对 FIN-WAIT-2 状态 socket 的处理。

##### 1\. FIN-WAIT-2 状态下的 0 延迟关闭，不计入 orphan

当 socket 处于 FIN-WAIT-2 状态并且设置了零延迟关闭时，会直接将 socket 设置为 TCP_CLOSE 状态，并发送 RST
报文，然后销毁 socket，最终减少 orphan socket 计数。

    
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp.c#L2858
    static void tcp_close(struct sock *sk, long timeout)
    if (sk->sk_state == TCP_FIN_WAIT2) {
    		struct tcp_sock *tp = tcp_sk(sk);
        // 如果 linger2 小于 0，则设置 socket 为 TCP_CLOSE 状态，并发送 RST 报文
    		if (tp->linger2 < 0) {
    			tcp_set_state(sk, TCP_CLOSE);
    			tcp_send_active_reset(sk, GFP_ATOMIC);
    			__NET_INC_STATS(sock_net(sk),
    					LINUX_MIB_TCPABORTONLINGER);
    		} else {
          // 计算 超时时间
    			const int tmo = tcp_fin_time(sk);
    
    			if (tmo > TCP_TIMEWAIT_LEN) {
    				inet_csk_reset_keepalive_timer(sk,
    						tmo - TCP_TIMEWAIT_LEN);
    			} else {
    				tcp_time_wait(sk, TCP_FIN_WAIT2, tmo);
    				goto out;
    			}
    		}
    	}
    

关于零延迟关闭这里多提一点，这个设置指的是当应用调用 close 函数时，如果应用还有数据没有发送完成，则需要等待一定的延迟时间，如果设置了为 0
，socket 的数据就会被丢弃  
掉并向对方发送一个 RST 包来中断连接，因此对于服务端来说最好永远不要设置为
0；但对于探活类的程序则是一种非常好的配置。具体可以参考皓哥的文章[从一次经历谈 TIME_WAIT
的那些事](https://coolshell.cn/articles/22263.html)。

##### 2\. FIN-WAIT-2 下等待超时，启用 keepalive，计入 orphan

如果没有满足 0 延迟关闭的条件，内核转而会计算 socket 的超时时间，如果大于 60s 则启用 keepalive 定时器，注意这里是没有将
socket 状态设置为 CLOSE 的，因此可以认为超时时间大于 60s 的 FIN-WAIT-2 状态的 socket 被计入 orphan。  
否则会执行 tcp_time_wait 代码将 socket 视为 timewait 状态。

    
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp.c#L2866
    
    const int tmo = tcp_fin_time(sk);
    
    if (tmo > TCP_TIMEWAIT_LEN) {
    		inet_csk_reset_keepalive_timer(sk,
    		tmo - TCP_TIMEWAIT_LEN);
    } else {
    		tcp_time_wait(sk, TCP_FIN_WAIT2, tmo);
    		goto out;
    	}
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/include/net/tcp.h#L123
    #define TCP_TIMEWAIT_LEN (60*HZ) /* how long to wait to destroy TIME-WAIT
    				  * state, about 60 seconds	*/
    

这里的超时计算是根据 tcp_fin_timeout 来的，默认是 60s，我们把这个值改大然后在客户端屏蔽掉服务端的 FIN 包后，在查看客户端 FIN-
WAIT-2 状态的 socket 就已经被计入 orphan socket了。如果没有设置，则会被计入 timewait 状态。

    
    
    # 没有修改时会被认为是 timewait 计数
    $ ss -ant | grep -E "Recv|:8888" && ss -s
    State      Recv-Q Send-Q        Local Address:Port          Peer Address:Port Process
    FIN-WAIT-2 0      0               172.19.0.15:48172          172.19.0.12:8888
    FIN-WAIT-2 0      0               172.19.0.15:48116          172.19.0.12:8888
    FIN-WAIT-2 0      0               172.19.0.15:48130          172.19.0.12:8888
    FIN-WAIT-2 0      0               172.19.0.15:48220          172.19.0.12:8888
    FIN-WAIT-2 0      0               172.19.0.15:48206          172.19.0.12:8888
    FIN-WAIT-2 0      0               172.19.0.15:48194          172.19.0.12:8888
    FIN-WAIT-2 0      0               172.19.0.15:48162          172.19.0.12:8888
    FIN-WAIT-2 0      0               172.19.0.15:48182          172.19.0.12:8888
    FIN-WAIT-2 0      0               172.19.0.15:48126          172.19.0.12:8888
    FIN-WAIT-2 0      0               172.19.0.15:48146          172.19.0.12:8888
    Total: 221
    TCP:   41 (estab 14, closed 16, orphaned 0, timewait 16)
    # 客户端修改 tcp_fin_timeout
     sudo sysctl -w  net.ipv4.tcp_fin_timeout=120
    
    
    
    # 查看客户端统计信息
    $ ss -ant | grep -E "Recv|:8888" && ss -s
    State      Recv-Q Send-Q Local Address:Port    Peer Address:Port Process
    FIN-WAIT-2 0      0        172.19.0.15:59016    172.19.0.12:8888
    FIN-WAIT-2 0      0        172.19.0.15:58996    172.19.0.12:8888
    FIN-WAIT-2 0      0        172.19.0.15:58966    172.19.0.12:8888
    FIN-WAIT-2 0      0        172.19.0.15:58936    172.19.0.12:8888
    FIN-WAIT-2 0      0        172.19.0.15:58956    172.19.0.12:8888
    FIN-WAIT-2 0      0        172.19.0.15:59030    172.19.0.12:8888
    FIN-WAIT-2 0      0        172.19.0.15:58940    172.19.0.12:8888
    FIN-WAIT-2 0      0        172.19.0.15:58984    172.19.0.12:8888
    FIN-WAIT-2 0      0        172.19.0.15:59012    172.19.0.12:8888
    FIN-WAIT-2 0      0        172.19.0.15:58982    172.19.0.12:8888
    Total: 243
    TCP:   37 (estab 14, closed 5, orphaned 11, timewait 5)
    
    Transport Total     IP        IPv6
    RAW	  1         0         1
    UDP	  9         7         2
    TCP	  32        31        1
    INET	  42        38        4
    FRAG	  0         0         0
    
    
    # ubuntu @ node3 in ~ [17:33:06]
    $ sudo netstat -anpo | grep -E "Recv-Q|8888"
    Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name     Timer
    tcp        0      0 172.19.0.15:59016       172.19.0.12:8888        FIN_WAIT2   -                    keepalive (13.92/0/0)
    tcp        0      0 172.19.0.15:58996       172.19.0.12:8888        FIN_WAIT2   -                    keepalive (13.92/0/0)
    tcp        0      0 172.19.0.15:58966       172.19.0.12:8888        FIN_WAIT2   -                    keepalive (13.92/0/0)
    tcp        0      0 172.19.0.15:58936       172.19.0.12:8888        FIN_WAIT2   -                    keepalive (13.92/0/0)
    tcp        0      0 172.19.0.15:58956       172.19.0.12:8888        FIN_WAIT2   -                    keepalive (13.92/0/0)
    tcp        0      0 172.19.0.15:59030       172.19.0.12:8888        FIN_WAIT2   -                    keepalive (13.92/0/0)
    tcp        0      0 172.19.0.15:58940       172.19.0.12:8888        FIN_WAIT2   -                    keepalive (13.92/0/0)
    tcp        0      0 172.19.0.15:58984       172.19.0.12:8888        FIN_WAIT2   -                    keepalive (13.92/0/0)
    tcp        0      0 172.19.0.15:59012       172.19.0.12:8888        FIN_WAIT2   -                    keepalive (13.92/0/0)
    tcp        0      0 172.19.0.15:58982       172.19.0.12:8888        FIN_WAIT2   -                    keepalive (13.92/0/0)
    

可以看到每个 FIN_WAIT_2 状态的 socket 都有一个 keeplive 定时器，并且 orphan 的统计数发生了变化。

#### 2\. orphan socket 过多清理资源

完成了 FIN-FIN_WAIT_2 状态的判断后，如果 Socket 状态还不是 CLOSE，内核会判断当前 orphan 的 socket
数量是否过多，如果过多的话会执行资源清理。内核会根据 `net.ipv4.tcp_max_orphans`  
参数判断 orphan socket 的数量是否过多。计算的时候内核会传一个 shift 参数，取值范围是 0~2，因此内核实际可能会拿当前 orphan
数量的 2 倍甚至 4 倍去做比较。

    
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp.c#L2877
    if (sk->sk_state != TCP_CLOSE) {
    		sk_mem_reclaim(sk);
    		if (tcp_check_oom(sk, 0)) {
    			tcp_set_state(sk, TCP_CLOSE);
    			tcp_send_active_reset(sk, GFP_ATOMIC);
    			__NET_INC_STATS(sock_net(sk),
    					LINUX_MIB_TCPABORTONMEMORY);
    		} else if (!check_net(sock_net(sk))) {
    			/* Not possible to send reset; just close */
    			tcp_set_state(sk, TCP_CLOSE);
    		}
    	}
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp.c#L2719
    static bool tcp_too_many_orphans(int shift)
    {
    	return READ_ONCE(tcp_orphan_cache) << shift >
    		READ_ONCE(sysctl_tcp_max_orphans);
    }
    

#### 3\. 定时器执行资源清理

系统有两个参数和 orphan 有关：

  * `net.ipv4.tcp_max_orphans`：上面提到的 orphan socket 的最大数量。
  * `net.ipv4.tcp_orphan_retries`：该字段控制 FIN 包的最大重传字数，设置默认为 0。如果为 0，内核会重置为 8。

当内核处于 FIN_WAIT 状态时，会有定时器执行包的重传或者探活，此时也会执行上面提到的资源清理操作。此时如果重传次数已到，或者 orphan
socket 数量过多，也会执行清理操作。

    
    
    // 源码地址：https://elixir.bootlin.com/linux/v5.15.130/source/net/ipv4/tcp_timer.c#L231
    
    static int tcp_write_timeout(struct sock *sk)
    {
    	  // 代码省略
    		if (sock_flag(sk, SOCK_DEAD)) {
    			const bool alive = icsk->icsk_rto < TCP_RTO_MAX;
    
          // 基于重试次数判断是否 reset
    			retry_until = tcp_orphan_retries(sk, alive);
    			do_reset = alive ||
    				!retransmits_timed_out(sk, retry_until, 0);
          // 判断是否需要释放资源
    			if (tcp_out_of_resources(sk, do_reset))
    				return 1;
    		}
    	}
    
    static int tcp_out_of_resources(struct sock *sk, bool do_reset)
    {
    	struct tcp_sock *tp = tcp_sk(sk);
    	int shift = 0;
    
    	/* If peer does not open window for long time, or did not transmit
    	 * anything for long time, penalize it. */
    	if ((s32)(tcp_jiffies32 - tp->lsndtime) > 2*TCP_RTO_MAX || !do_reset)
    		shift++;
    
    	/* If some dubious ICMP arrived, penalize even more. */
    	if (sk->sk_err_soft)
    		shift++;
      // 计算移位（0 - 2），判断 orphan socket 是否过多
    	if (tcp_check_oom(sk, shift)) {
    		/* Catch exceptional cases, when connection requires reset.
    		 *      1. Last segment was sent recently. */
    		if ((s32)(tcp_jiffies32 - tp->lsndtime) <= TCP_TIMEWAIT_LEN ||
    		    /*  2. Window is closed. */
    		    (!tp->snd_wnd && !tp->packets_out))
    			do_reset = true;
    		if (do_reset)
    			tcp_send_active_reset(sk, GFP_ATOMIC);
    		tcp_done(sk);
    		__NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPABORTONMEMORY);
    		return 1;
    	}
    
    }
    

### 简要总结

  1. 可以用 `ss -s` 或者 `cat /proc/net/sockstat` 查看孤儿套接字是否过多。

  2. 根据[文档](https://sysctl-explorer.net/net/ipv4/tcp_max_orphans/) 介绍，每个 orphan socket 大约占用 64KB 内存。

  3. FIN_WAIT_1、LAST_ACK、CLOSING 状态下的 socket 都可以归类为 orphan socket。

  4. 超时时间小于 60s 的 FIN_WAIT_2 计入 timewait，而大约 60s 的则记为 orphan socket。

  5. 相关参数：net.ipv4.tcp_orphan_retries、net.ipv4.tcp_max_orphans。

  6. LAST_ACK、FIN_WAIT_1 状态下的连接都在等待回复，因此可以像发起 SYN Flood 那样的攻击，客户端故意断开但不在返回 ACK 信息，这样会导致服务器资源被占用。因此可以适当调整  
上面两个参数，减少重传次数以及 orphan 最大数量，从而可以更快的清理掉无用的 socket。

### 参考资料

  * [结合案例深入解析orphan socket产生与消亡（一）](https://developer.aliyun.com/article/91966)
  * [结合案例深入解析orphan socket产生与消亡（二）](https://developer.aliyun.com/article/92925)



