---
layout: post
title: "MOEFeedForward-模块"
date: 2025-03-13 18:40:11 +0800
description: "这是一个典型的 MoE（Mixture of Experts）实现，用于大型语言模型中提高模型容量和计算效率。包含多个专家（FeedForward）和一个门控网络（MoEGate）"
keywords: "MOEFeedForward 模块"
categories: ['深度学习模块']
tags: ['深度学习', 'Pytorch', 'Python']
artid: "146239127"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146239127
    alt: "MOEFeedForward-模块"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146239127
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146239127
cover: https://bing.ee123.net/img/rand?artid=146239127
image: https://bing.ee123.net/img/rand?artid=146239127
img: https://bing.ee123.net/img/rand?artid=146239127
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     MOEFeedForward 模块
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="_0">
     </a>
     代码
    </h3>
    <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">FeedForward</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> config<span class="token punctuation">:</span> LMConfig<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> config<span class="token punctuation">.</span>hidden_dim <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            hidden_dim <span class="token operator">=</span> <span class="token number">4</span> <span class="token operator">*</span> config<span class="token punctuation">.</span>dim
            hidden_dim <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> hidden_dim <span class="token operator">/</span> <span class="token number">3</span><span class="token punctuation">)</span>
            config<span class="token punctuation">.</span>hidden_dim <span class="token operator">=</span> config<span class="token punctuation">.</span>multiple_of <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>hidden_dim <span class="token operator">+</span> config<span class="token punctuation">.</span>multiple_of <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> config<span class="token punctuation">.</span>multiple_of<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>w1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>config<span class="token punctuation">.</span>dim<span class="token punctuation">,</span> config<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>w2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>config<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">,</span> config<span class="token punctuation">.</span>dim<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>w3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>config<span class="token punctuation">.</span>dim<span class="token punctuation">,</span> config<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>config<span class="token punctuation">.</span>dropout<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w2<span class="token punctuation">(</span>F<span class="token punctuation">.</span>silu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>w3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">MoEGate</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> config<span class="token punctuation">:</span> LMConfig<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>config <span class="token operator">=</span> config
        self<span class="token punctuation">.</span>top_k <span class="token operator">=</span> config<span class="token punctuation">.</span>num_experts_per_tok
        self<span class="token punctuation">.</span>n_routed_experts <span class="token operator">=</span> config<span class="token punctuation">.</span>n_routed_experts

        self<span class="token punctuation">.</span>scoring_func <span class="token operator">=</span> config<span class="token punctuation">.</span>scoring_func
        self<span class="token punctuation">.</span>alpha <span class="token operator">=</span> config<span class="token punctuation">.</span>aux_loss_alpha
        self<span class="token punctuation">.</span>seq_aux <span class="token operator">=</span> config<span class="token punctuation">.</span>seq_aux

        self<span class="token punctuation">.</span>norm_topk_prob <span class="token operator">=</span> config<span class="token punctuation">.</span>norm_topk_prob
        self<span class="token punctuation">.</span>gating_dim <span class="token operator">=</span> config<span class="token punctuation">.</span>dim
        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_routed_experts<span class="token punctuation">,</span> self<span class="token punctuation">.</span>gating_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>reset_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">reset_parameters</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init <span class="token keyword">as</span> init
        init<span class="token punctuation">.</span>kaiming_uniform_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> a<span class="token operator">=</span>math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_states<span class="token punctuation">)</span><span class="token punctuation">:</span>
        bsz<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> h <span class="token operator">=</span> hidden_states<span class="token punctuation">.</span>shape
        hidden_states <span class="token operator">=</span> hidden_states<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> h<span class="token punctuation">)</span>
        logits <span class="token operator">=</span> F<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>hidden_states<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>scoring_func <span class="token operator">==</span> <span class="token string">'softmax'</span><span class="token punctuation">:</span>
            scores <span class="token operator">=</span> logits<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> NotImplementedError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'insupportable scoring function for MoE gating: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>self<span class="token punctuation">.</span>scoring_func<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

        topk_weight<span class="token punctuation">,</span> topk_idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> k<span class="token operator">=</span>self<span class="token punctuation">.</span>top_k<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">sorted</span><span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>top_k <span class="token operator">&gt;</span> <span class="token number">1</span> <span class="token keyword">and</span> self<span class="token punctuation">.</span>norm_topk_prob<span class="token punctuation">:</span>
            denominator <span class="token operator">=</span> topk_weight<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1e-20</span>
            topk_weight <span class="token operator">=</span> topk_weight <span class="token operator">/</span> denominator

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training <span class="token keyword">and</span> self<span class="token punctuation">.</span>alpha <span class="token operator">&gt;</span> <span class="token number">0.0</span><span class="token punctuation">:</span>
            scores_for_aux <span class="token operator">=</span> scores
            aux_topk <span class="token operator">=</span> self<span class="token punctuation">.</span>top_k
            topk_idx_for_aux_loss <span class="token operator">=</span> topk_idx<span class="token punctuation">.</span>view<span class="token punctuation">(</span>bsz<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>seq_aux<span class="token punctuation">:</span>
                scores_for_seq_aux <span class="token operator">=</span> scores_for_aux<span class="token punctuation">.</span>view<span class="token punctuation">(</span>bsz<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
                ce <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>bsz<span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_routed_experts<span class="token punctuation">,</span> device<span class="token operator">=</span>hidden_states<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
                ce<span class="token punctuation">.</span>scatter_add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> topk_idx_for_aux_loss<span class="token punctuation">,</span>
                                torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>bsz<span class="token punctuation">,</span> seq_len <span class="token operator">*</span> aux_topk<span class="token punctuation">,</span> device<span class="token operator">=</span>hidden_states<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>div_<span class="token punctuation">(</span>
                    seq_len <span class="token operator">*</span> aux_topk <span class="token operator">/</span> self<span class="token punctuation">.</span>n_routed_experts<span class="token punctuation">)</span>
                aux_loss <span class="token operator">=</span> <span class="token punctuation">(</span>ce <span class="token operator">*</span> scores_for_seq_aux<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>alpha
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                mask_ce <span class="token operator">=</span> F<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>topk_idx_for_aux_loss<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span>self<span class="token punctuation">.</span>n_routed_experts<span class="token punctuation">)</span>
                ce <span class="token operator">=</span> mask_ce<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
                Pi <span class="token operator">=</span> scores_for_aux<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
                fi <span class="token operator">=</span> ce <span class="token operator">*</span> self<span class="token punctuation">.</span>n_routed_experts
                aux_loss <span class="token operator">=</span> <span class="token punctuation">(</span>Pi <span class="token operator">*</span> fi<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>alpha
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            aux_loss <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">return</span> topk_idx<span class="token punctuation">,</span> topk_weight<span class="token punctuation">,</span> aux_loss


<span class="token keyword">class</span> <span class="token class-name">MOEFeedForward</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> config<span class="token punctuation">:</span> LMConfig<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>config <span class="token operator">=</span> config
        self<span class="token punctuation">.</span>experts <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
            FeedForward<span class="token punctuation">(</span>config<span class="token punctuation">)</span>
            <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>n_routed_experts<span class="token punctuation">)</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gate <span class="token operator">=</span> MoEGate<span class="token punctuation">(</span>config<span class="token punctuation">)</span>
        <span class="token keyword">if</span> config<span class="token punctuation">.</span>n_shared_experts <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>shared_experts <span class="token operator">=</span> FeedForward<span class="token punctuation">(</span>config<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        identity <span class="token operator">=</span> x
        orig_shape <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        bsz<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> _ <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        <span class="token comment"># 使用门控机制选择专家</span>
        topk_idx<span class="token punctuation">,</span> topk_weight<span class="token punctuation">,</span> aux_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>gate<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        flat_topk_idx <span class="token operator">=</span> topk_idx<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>
            <span class="token comment"># 训练模式下，重复输入数据</span>
            x <span class="token operator">=</span> x<span class="token punctuation">.</span>repeat_interleave<span class="token punctuation">(</span>self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>num_experts_per_tok<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
            y <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty_like<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">)</span>
            <span class="token keyword">for</span> i<span class="token punctuation">,</span> expert <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>experts<span class="token punctuation">)</span><span class="token punctuation">:</span>
                y<span class="token punctuation">[</span>flat_topk_idx <span class="token operator">==</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> expert<span class="token punctuation">(</span>x<span class="token punctuation">[</span>flat_topk_idx <span class="token operator">==</span> i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>y<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>  <span class="token comment"># 确保类型一致</span>
            y <span class="token operator">=</span> <span class="token punctuation">(</span>y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">*</span>topk_weight<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> topk_weight<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            y <span class="token operator">=</span> y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">*</span>orig_shape<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># 推理模式下，只选择最优专家</span>
            y <span class="token operator">=</span> self<span class="token punctuation">.</span>moe_infer<span class="token punctuation">(</span>x<span class="token punctuation">,</span> flat_topk_idx<span class="token punctuation">,</span> topk_weight<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">*</span>orig_shape<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>n_shared_experts <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            y <span class="token operator">=</span> y <span class="token operator">+</span> self<span class="token punctuation">.</span>shared_experts<span class="token punctuation">(</span>identity<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>aux_loss <span class="token operator">=</span> aux_loss
        <span class="token keyword">return</span> y

    <span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">moe_infer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> flat_expert_indices<span class="token punctuation">,</span> flat_expert_weights<span class="token punctuation">)</span><span class="token punctuation">:</span>
        expert_cache <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        idxs <span class="token operator">=</span> flat_expert_indices<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span><span class="token punctuation">)</span>
        tokens_per_expert <span class="token operator">=</span> flat_expert_indices<span class="token punctuation">.</span>bincount<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        token_idxs <span class="token operator">=</span> idxs <span class="token operator">//</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>num_experts_per_tok
        <span class="token comment"># 例如当tokens_per_expert=[6, 15, 20, 26, 33, 38, 46, 52]</span>
        <span class="token comment"># 当token_idxs=[3, 7, 19, 21, 24, 25,  4,  5,  6, 10, 11, 12...]</span>
        <span class="token comment"># 意味着当token_idxs[:6] -&gt; [3,  7, 19, 21, 24, 25,  4]位置的token都由专家0处理，token_idxs[6:15]位置的token都由专家1处理......</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> end_idx <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>tokens_per_expert<span class="token punctuation">)</span><span class="token punctuation">:</span>
            start_idx <span class="token operator">=</span> <span class="token number">0</span> <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">else</span> tokens_per_expert<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span>
            <span class="token keyword">if</span> start_idx <span class="token operator">==</span> end_idx<span class="token punctuation">:</span>
                <span class="token keyword">continue</span>
            expert <span class="token operator">=</span> self<span class="token punctuation">.</span>experts<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            exp_token_idx <span class="token operator">=</span> token_idxs<span class="token punctuation">[</span>start_idx<span class="token punctuation">:</span>end_idx<span class="token punctuation">]</span>
            expert_tokens <span class="token operator">=</span> x<span class="token punctuation">[</span>exp_token_idx<span class="token punctuation">]</span>
            expert_out <span class="token operator">=</span> expert<span class="token punctuation">(</span>expert_tokens<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>expert_cache<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
            expert_out<span class="token punctuation">.</span>mul_<span class="token punctuation">(</span>flat_expert_weights<span class="token punctuation">[</span>idxs<span class="token punctuation">[</span>start_idx<span class="token punctuation">:</span>end_idx<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token comment"># 使用 scatter_add_ 进行 sum 操作</span>
            expert_cache<span class="token punctuation">.</span>scatter_add_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> exp_token_idx<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> expert_out<span class="token punctuation">)</span>

        <span class="token keyword">return</span> expert_cache
</code></pre>
    <h3>
     <a id="_134">
     </a>
     代码解释
    </h3>
    <p>
     解释一下这段代码的主要组成部分：
    </p>
    <ol>
     <li>
      <code>
       FeedForward
      </code>
      类：
     </li>
    </ol>
    <ul>
     <li>
      实现了一个基础的前馈网络
     </li>
     <li>
      使用 SwiGLU 激活函数（
      <code>
       F.silu(self.w1(x)) * self.w3(x)
      </code>
      ）
     </li>
     <li>
      包含三个线性层（w1、w2、w3）和一个 dropout 层
     </li>
    </ul>
    <ol start="2">
     <li>
      <code>
       MoEGate
      </code>
      类（门控机制）：
     </li>
    </ol>
    <ul>
     <li>
      负责决定每个 token 应该由哪些专家处理
     </li>
     <li>
      主要步骤：
      <ol>
       <li>
        计算每个 token 对应每个专家的分数（使用 softmax）
       </li>
       <li>
        选择 top-k 个最高分的专家
       </li>
       <li>
        计算辅助损失（aux_loss）来平衡专家的使用
       </li>
      </ol>
     </li>
    </ul>
    <ol start="3">
     <li>
      <code>
       MOEFeedForward
      </code>
      类（混合专家系统）：
     </li>
    </ol>
    <ul>
     <li>
      <p>
       包含多个专家（FeedForward）和一个门控网络（MoEGate）
      </p>
     </li>
     <li>
      <p>
       训练模式：
      </p>
      <ol>
       <li>
        使用门控网络选择每个 token 的专家
       </li>
       <li>
        将输入数据复制多份，分发给不同专家
       </li>
       <li>
        专家并行处理数据
       </li>
       <li>
        根据门控权重合并结果
       </li>
      </ol>
     </li>
     <li>
      <p>
       推理模式（
       <code>
        moe_infer
       </code>
       ）：
      </p>
      <ol>
       <li>
        对专家索引排序，将相同专家的 token 批量处理
       </li>
       <li>
        使用
        <code>
         scatter_add_
        </code>
        将专家输出累加到正确位置
       </li>
       <li>
        更高效的推理实现，避免了数据重复
       </li>
      </ol>
     </li>
    </ul>
    <ol start="4">
     <li>
      特殊功能：
     </li>
    </ol>
    <ul>
     <li>
      支持共享专家（
      <code>
       n_shared_experts
      </code>
      ）
     </li>
     <li>
      实现了专家负载均衡（通过辅助损失）
     </li>
     <li>
      支持每个 token 选择多个专家（
      <code>
       num_experts_per_tok
      </code>
      ）
     </li>
    </ul>
    <p>
     这是一个典型的 MoE（Mixture of Experts）实现，用于大型语言模型中提高模型容量和计算效率。
    </p>
    <h3>
     <a id="_168">
     </a>
     示例
    </h3>
    <pre><code class="prism language-python"><span class="token comment"># 创建 MoE 实例</span>
dim <span class="token operator">=</span> <span class="token number">512</span>                    <span class="token comment"># 输入维度</span>
n_routed_experts <span class="token operator">=</span> <span class="token number">4</span>         <span class="token comment"># 专家数量</span>
num_experts_per_tok <span class="token operator">=</span> <span class="token number">2</span>      <span class="token comment"># 每个token选择的专家数量</span>

moe <span class="token operator">=</span> MOEFeedForward<span class="token punctuation">(</span>
    dim<span class="token operator">=</span>dim<span class="token punctuation">,</span>
    n_routed_experts<span class="token operator">=</span>n_routed_experts<span class="token punctuation">,</span>
    num_experts_per_tok<span class="token operator">=</span>num_experts_per_tok<span class="token punctuation">,</span>
    hidden_dim<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>         <span class="token comment"># FFN隐藏层维度，None时自动计算</span>
    dropout<span class="token operator">=</span><span class="token number">0.1</span>             <span class="token comment"># dropout比率</span>
<span class="token punctuation">)</span>

<span class="token comment"># 创建示例输入</span>
batch_size <span class="token operator">=</span> <span class="token number">2</span>
seq_len <span class="token operator">=</span> <span class="token number">10</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>  <span class="token comment"># 形状: [2, 10, 512]</span>

moe<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre>
    <p>
     输出
    </p>
    <pre><code>After gate - topk_idx.shape: torch.Size([20, 2]), topk_weight.shape: torch.Size([20, 2])
After view - x.shape: torch.Size([20, 512]), flat_topk_idx.shape: torch.Size([40])
After repeat_interleave - x.shape: torch.Size([40, 512])
Empty y tensor shape: torch.Size([40, 512])
Expert 0 - input shape: torch.Size([9, 512])
Expert 0 - output shape: torch.Size([9, 512])
Expert 1 - input shape: torch.Size([13, 512])
Expert 1 - output shape: torch.Size([13, 512])
Expert 2 - input shape: torch.Size([11, 512])
Expert 2 - output shape: torch.Size([11, 512])
Expert 3 - input shape: torch.Size([7, 512])
Expert 3 - output shape: torch.Size([7, 512])
Before view - y.shape: torch.Size([40, 512])
topk_weight.shape: torch.Size([20, 2])
After view and sum - y.shape: torch.Size([20, 512])
Final y.shape: torch.Size([2, 10, 512])
</code></pre>
    <h3>
     <a id="torch_209">
     </a>
     相应的torch函数
    </h3>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token comment"># empty: 创建未初始化的张量</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 创建形状为 2x3 的未初始化张量</span>

<span class="token comment"># zeros_like: 创建与输入相同形状的全零张量</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>a<span class="token punctuation">)</span>  <span class="token comment"># 创建形状为 2x2 的全零张量</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span>  <span class="token comment"># tensor([[0, 0], [0, 0]])</span>
</code></pre>
    <pre><code>tensor([[0, 0],
        [0, 0]])
</code></pre>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># view: 改变张量形状</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 展平为一维</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>  <span class="token comment"># tensor([1, 2, 3, 4, 5, 6, 7, 8])</span>

<span class="token comment"># -1 表示自动计算该维度大小</span>
z <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># 重塑为 4x2</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>  <span class="token comment"># tensor([[1, 2], [3, 4], [5, 6], [7, 8]])</span>
</code></pre>
    <pre><code>tensor([1, 2, 3, 4, 5, 6, 7, 8])
tensor([[1, 2],
        [3, 4],
        [5, 6],
        [7, 8]])
</code></pre>
    <pre><code class="prism language-python"><span class="token comment"># linear: 线性变换 y = xA^T + b</span>
<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># 2个样本，每个3维</span>
weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># 输出4维</span>
output <span class="token operator">=</span> F<span class="token punctuation">.</span>linear<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> weight<span class="token punctuation">)</span>  <span class="token comment"># 形状变为 [2, 4]</span>

<span class="token comment"># softmax: 将数值转换为概率分布</span>
logits <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
probs <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>probs<span class="token punctuation">)</span>  <span class="token comment"># tensor([0.0900, 0.2447, 0.6652])</span>
</code></pre>
    <pre><code>tensor([0.0900, 0.2447, 0.6652])
</code></pre>
    <pre><code class="prism language-python"><span class="token comment"># 找出最大的k个值及其索引</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
values<span class="token punctuation">,</span> indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>x<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>values<span class="token punctuation">)</span>   <span class="token comment"># tensor([8, 5])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>indices<span class="token punctuation">)</span>  <span class="token comment"># tensor([3, 1])</span>
</code></pre>
    <pre><code>tensor([8, 5])
tensor([3, 1])
</code></pre>
    <pre><code class="prism language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 每个元素重复2次</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span>repeat_interleave<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>  <span class="token comment"># tensor([1, 1, 2, 2, 3, 3])</span>
</code></pre>
    <pre><code>tensor([1, 1, 2, 2, 3, 3])
</code></pre>
    <pre><code class="prism language-python"><span class="token comment"># 统计每个数字出现的次数</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
counts <span class="token operator">=</span> x<span class="token punctuation">.</span>bincount<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>counts<span class="token punctuation">)</span>  <span class="token comment"># tensor([0, 3, 2, 1])  # 0出现0次，1出现3次，2出现2次，3出现1次</span>
</code></pre>
    <pre><code>tensor([0, 3, 2, 1])
</code></pre>
    <pre><code class="prism language-python"><span class="token comment"># 在指定位置累加值</span>
src <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>  <span class="token comment"># 指定数据类型为 float</span>
index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
out <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>  <span class="token comment"># 确保与 src 的数据类型相同</span>
out<span class="token punctuation">.</span>scatter_add_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> index<span class="token punctuation">,</span> src<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span> 
</code></pre>
    <pre><code>tensor([[4., 0.],
        [0., 6.]])
</code></pre>
    <pre><code class="prism language-python"><span class="token comment"># 返回排序后的索引</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
indices <span class="token operator">=</span> x<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>indices<span class="token punctuation">)</span>  <span class="token comment"># tensor([1, 3, 0, 2, 4])  # 最小值在位置1和3，然后是0,2,4</span>
</code></pre>
    <pre><code>tensor([1, 3, 0, 2, 4])
</code></pre>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34313437323230352f:61727469636c652f64657461696c732f313436323339313237" class_="artid" style="display:none">
 </p>
</div>


