---
arturl_encode: "68747470733a2f2f626c:6f672e6373646e2e6e65742f6c69756a696e6768756131362f:61727469636c652f64657461696c732f313436313334303430"
layout: post
title: "测试大语言模型在嵌入式设备部署的可能性-ollama本地部署测试"
date: 2025-03-09 17:19:48 +0800
description: "测试当前已有的各种大语言模型的小型模型，测试哪个更适合在嵌入式设备上部署"
keywords: "测试大语言模型在嵌入式设备部署的可能性-ollama本地部署测试"
categories: ['未分类']
tags: ['语言模型', '自然语言处理', '人工智能']
artid: "146134040"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146134040
    alt: "测试大语言模型在嵌入式设备部署的可能性-ollama本地部署测试"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146134040
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146134040
cover: https://bing.ee123.net/img/rand?artid=146134040
image: https://bing.ee123.net/img/rand?artid=146134040
img: https://bing.ee123.net/img/rand?artid=146134040
---

# 测试大语言模型在嵌入式设备部署的可能性-ollama本地部署测试

### 前言

当今各种大语言模型百花齐放，为了方便使用者更加自由的使用大模型，将大模型变成如同棒球棍一样每个人都能用，并且顺手方便的工具，本地私有化具有重要意义。

> 本次测试使用ollama完成模型下载，过程简单快捷。
>   
> 1、进入ollama：https://ollama.com/下载对应系统的ollama
>   
> 2、windows中使用cmd或powershell执行ollama server进入ollama命令行
>   
> 3、ollama run llm-model即可检测是否下载模型，并运行模型

本次测试的大语言模型大小均在1GB左右，具体如下图所示：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3df8ab442a3c4edabffd88f2aa6e10db.png)
  
以上使用的模型最大的是llama3.2:1b，大小达到了1.3GB
  
在ollam项目的github:
<https://github.com/ollama/ollama>
页面可以看到提示：
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/9c47163b448f4d6e87e1186c3b5d3a25.png)
  
因此，考虑到边缘嵌入式设备的内存大小，并且如果需要大语言模型能够在嵌入式设备中运行，那么必须要要留足空间给大语言模型。此外，还要留出一部分空间给比如数据库、UI等各种资源的。
  
如果大语言模型占用了1GB，个人认为嵌入式设备的RAM大小至少要3GB可能才不会影响其他进程的运行。

### 测试过程

#### 测试问题

*从解释性编程语言编程、日常问题和长句问题，三个方向出问题测试：*

1. 使用python编写一个贪吃蛇游戏
2. 天空为什么是蓝色的？
3. 当今时代，大语言模型大行其道，大量的文员类工作可能很快被大语言模型替代，如果因此被辞退应该何去何从？

#### 测试效果

##### qwen2.5:1.5b

###### 问题1

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/9fbd439d5f774d749cab25e0a5c432a2.png)

###### 问题2

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4988bbe513dc4641b05ca812e6a264ca.png)

###### 问题3

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/90ca535fb4d84281a886e5c84a8478f8.png)

---

##### qwen2.5-coder:0.5b

###### 问题1

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5889483bd099406ba764a04b68245fe3.png)

###### 问题2

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/736401aa8d8d41b48f4ea1bd95c18377.png)

###### 问题3

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/33c01cdfbe4d46ba822f8f5432708a8c.png)

---

##### qwen2.5:0.5b

###### 问题1

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/fcce345a48a2494b8298e69c2a0b12df.png)

###### 问题2

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/f262035f32da4595b04fc5f30df16bc2.png)

###### 问题3

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/39af1071f5cf45e6b0fc23517fc5764f.png)

---

##### llama3.2:1b

###### 问题1

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/23d882e16ae04967afbe75dab400b834.png)
  
测试过程中出现过中文全部乱码的问题。

###### 问题2

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/72861fcedf4145f18b5d8c65944aa5b6.png)

###### 问题3

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/02f268aa51784f20887ce25f4a9cb547.png)

---

##### deepseek-r1:1.5b

###### 问题1

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/9bef8ab83aac49d59270f6283c37d439.png)
  
编写代码大概率（3次测试出现2次）出现编写代码循环重复和无法停止的问题。

###### 问题2

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/26bfadd1f4114da3b3f38493f34a2d2f.png)

###### 问题3

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/54c4fee71585473096737a47b91d4f37.png)

---

### 结论

从反应速度（完成问题回答）、回答问题准确性（语言一致性，但不包括回答正确性），两方面进行比较，分别分为低中高三个档次。

| 模型 | 模型大小 | 反应速度 | 准确性 |
| --- | --- | --- | --- |
| qwen2.5:1.5b | 986 MB | 中 | 高 |
| qwen2.5-coder:0.5b | 531 MB | 高 | 中 |
| qwen2.5:0.5b | 397 MB | 高 | 中 |
| llama3.2:1b | 1.3 GB | 中 | 低 |
| deepseek-r1:1.5b | 1.1 GB | 低 | 中 |

总体来说qwen2.5:1.5b在边缘嵌入式设备部署最具有综合竞争力。同时，qwen2.5:0.5b在除了代码编程当中比较不足，但qwen2.5-coder:0.5b又专门提供了这方面的能力，两者的总大小小于qwen2.5:1.5b。
  
可以考虑使用一个折中的方法，主模型使用qwen2.5:0.5b用户回答问题，在回答问题前先问是否是需要编程，或使用正则表达式判断问题当中是否有
`python,cpp,c++,c语言,java`
等字段。如果需要编程则转到作为子模型的qwen2.5-coder:0.5b回答问题。
  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b32d6d4077d64373825f8a104743fed9.png)