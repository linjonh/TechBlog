---
layout: post
title: "测试大语言模型在嵌入式设备部署的可能性-ollama本地部署测试"
date: 2025-03-09 17:19:48 +0800
description: "测试当前已有的各种大语言模型的小型模型，测试哪个更适合在嵌入式设备上部署"
keywords: "测试大语言模型在嵌入式设备部署的可能性-ollama本地部署测试"
categories: ['未分类']
tags: ['语言模型', '自然语言处理', '人工智能']
artid: "146134040"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146134040
    alt: "测试大语言模型在嵌入式设备部署的可能性-ollama本地部署测试"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146134040
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146134040
cover: https://bing.ee123.net/img/rand?artid=146134040
image: https://bing.ee123.net/img/rand?artid=146134040
img: https://bing.ee123.net/img/rand?artid=146134040
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     测试大语言模型在嵌入式设备部署的可能性-ollama本地部署测试
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="_0">
     </a>
     前言
    </h3>
    <p>
     当今各种大语言模型百花齐放，为了方便使用者更加自由的使用大模型，将大模型变成如同棒球棍一样每个人都能用，并且顺手方便的工具，本地私有化具有重要意义。
    </p>
    <blockquote>
     <p>
      本次测试使用ollama完成模型下载，过程简单快捷。
      <br/>
      1、进入ollama：https://ollama.com/下载对应系统的ollama
      <br/>
      2、windows中使用cmd或powershell执行ollama server进入ollama命令行
      <br/>
      3、ollama run llm-model即可检测是否下载模型，并运行模型
     </p>
    </blockquote>
    <p>
     本次测试的大语言模型大小均在1GB左右，具体如下图所示：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/3df8ab442a3c4edabffd88f2aa6e10db.png">
      <br/>
      以上使用的模型最大的是llama3.2:1b，大小达到了1.3GB
      <br/>
      在ollam项目的github:
      <a href="https://github.com/ollama/ollama">
       https://github.com/ollama/ollama
      </a>
      页面可以看到提示：
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/9c47163b448f4d6e87e1186c3b5d3a25.png">
       <br/>
       因此，考虑到边缘嵌入式设备的内存大小，并且如果需要大语言模型能够在嵌入式设备中运行，那么必须要要留足空间给大语言模型。此外，还要留出一部分空间给比如数据库、UI等各种资源的。
       <br/>
       如果大语言模型占用了1GB，个人认为嵌入式设备的RAM大小至少要3GB可能才不会影响其他进程的运行。
      </img>
     </img>
    </p>
    <h3>
     <a id="_15">
     </a>
     测试过程
    </h3>
    <h4>
     <a id="_16">
     </a>
     测试问题
    </h4>
    <p>
     <em>
      从解释性编程语言编程、日常问题和长句问题，三个方向出问题测试：
     </em>
    </p>
    <ol>
     <li>
      使用python编写一个贪吃蛇游戏
     </li>
     <li>
      天空为什么是蓝色的？
     </li>
     <li>
      当今时代，大语言模型大行其道，大量的文员类工作可能很快被大语言模型替代，如果因此被辞退应该何去何从？
     </li>
    </ol>
    <h4>
     <a id="_22">
     </a>
     测试效果
    </h4>
    <h5>
     <a id="qwen2515b_24">
     </a>
     qwen2.5:1.5b
    </h5>
    <h6>
     <a id="1_26">
     </a>
     问题1
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/9fbd439d5f774d749cab25e0a5c432a2.png"/>
    </p>
    <h6>
     <a id="2_28">
     </a>
     问题2
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/4988bbe513dc4641b05ca812e6a264ca.png"/>
    </p>
    <h6>
     <a id="3_30">
     </a>
     问题3
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/90ca535fb4d84281a886e5c84a8478f8.png"/>
    </p>
    <hr/>
    <h5>
     <a id="qwen25coder05b_34">
     </a>
     qwen2.5-coder:0.5b
    </h5>
    <h6>
     <a id="1_35">
     </a>
     问题1
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/5889483bd099406ba764a04b68245fe3.png"/>
    </p>
    <h6>
     <a id="2_37">
     </a>
     问题2
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/736401aa8d8d41b48f4ea1bd95c18377.png"/>
    </p>
    <h6>
     <a id="3_40">
     </a>
     问题3
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/33c01cdfbe4d46ba822f8f5432708a8c.png"/>
    </p>
    <hr/>
    <h5>
     <a id="qwen2505b_44">
     </a>
     qwen2.5:0.5b
    </h5>
    <h6>
     <a id="1_45">
     </a>
     问题1
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/fcce345a48a2494b8298e69c2a0b12df.png"/>
    </p>
    <h6>
     <a id="2_47">
     </a>
     问题2
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/f262035f32da4595b04fc5f30df16bc2.png"/>
    </p>
    <h6>
     <a id="3_50">
     </a>
     问题3
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/39af1071f5cf45e6b0fc23517fc5764f.png"/>
    </p>
    <hr/>
    <h5>
     <a id="llama321b_54">
     </a>
     llama3.2:1b
    </h5>
    <h6>
     <a id="1_55">
     </a>
     问题1
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/23d882e16ae04967afbe75dab400b834.png"/>
     <br/>
     测试过程中出现过中文全部乱码的问题。
    </p>
    <h6>
     <a id="2_58">
     </a>
     问题2
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/72861fcedf4145f18b5d8c65944aa5b6.png"/>
    </p>
    <h6>
     <a id="3_61">
     </a>
     问题3
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/02f268aa51784f20887ce25f4a9cb547.png"/>
    </p>
    <hr/>
    <h5>
     <a id="deepseekr115b_65">
     </a>
     deepseek-r1:1.5b
    </h5>
    <h6>
     <a id="1_66">
     </a>
     问题1
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/9bef8ab83aac49d59270f6283c37d439.png"/>
     <br/>
     编写代码大概率（3次测试出现2次）出现编写代码循环重复和无法停止的问题。
    </p>
    <h6>
     <a id="2_69">
     </a>
     问题2
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/26bfadd1f4114da3b3f38493f34a2d2f.png"/>
    </p>
    <h6>
     <a id="3_72">
     </a>
     问题3
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/54c4fee71585473096737a47b91d4f37.png"/>
    </p>
    <hr/>
    <h3>
     <a id="_76">
     </a>
     结论
    </h3>
    <p>
     从反应速度（完成问题回答）、回答问题准确性（语言一致性，但不包括回答正确性），两方面进行比较，分别分为低中高三个档次。
    </p>
    <table>
     <thead>
      <tr>
       <th>
        模型
       </th>
       <th>
        模型大小
       </th>
       <th>
        反应速度
       </th>
       <th>
        准确性
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        qwen2.5:1.5b
       </td>
       <td>
        986 MB
       </td>
       <td>
        中
       </td>
       <td>
        高
       </td>
      </tr>
      <tr>
       <td>
        qwen2.5-coder:0.5b
       </td>
       <td>
        531 MB
       </td>
       <td>
        高
       </td>
       <td>
        中
       </td>
      </tr>
      <tr>
       <td>
        qwen2.5:0.5b
       </td>
       <td>
        397 MB
       </td>
       <td>
        高
       </td>
       <td>
        中
       </td>
      </tr>
      <tr>
       <td>
        llama3.2:1b
       </td>
       <td>
        1.3 GB
       </td>
       <td>
        中
       </td>
       <td>
        低
       </td>
      </tr>
      <tr>
       <td>
        deepseek-r1:1.5b
       </td>
       <td>
        1.1 GB
       </td>
       <td>
        低
       </td>
       <td>
        中
       </td>
      </tr>
     </tbody>
    </table>
    <p>
     总体来说qwen2.5:1.5b在边缘嵌入式设备部署最具有综合竞争力。同时，qwen2.5:0.5b在除了代码编程当中比较不足，但qwen2.5-coder:0.5b又专门提供了这方面的能力，两者的总大小小于qwen2.5:1.5b。
     <br/>
     可以考虑使用一个折中的方法，主模型使用qwen2.5:0.5b用户回答问题，在回答问题前先问是否是需要编程，或使用正则表达式判断问题当中是否有
     <code>
      python,cpp,c++,c语言,java
     </code>
     等字段。如果需要编程则转到作为子模型的qwen2.5-coder:0.5b回答问题。
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b32d6d4077d64373825f8a104743fed9.png"/>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c:6f672e6373646e2e6e65742f6c69756a696e6768756131362f:61727469636c652f64657461696c732f313436313334303430" class_="artid" style="display:none">
 </p>
</div>


