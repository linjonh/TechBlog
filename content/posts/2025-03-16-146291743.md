---
layout: post
title: "AI技术学习笔记系列004GPU常识"
date: 2025-03-16 10:53:21 +0800
description: "从研发投入、性能指标到生态布局，Blackwell不仅延续了英伟达的技术霸权，更将AI算力推向了新的高度，成为2020年代中后期全球AI基础设施的核心支柱。显卡通信技术的提升（如HBM3e、NVLink）与AI专用硬件（Tensor Core、NPU）的演进，共同推动了AI计算的高效化与平民化。未来，随着Chiplet、存算一体等技术的成熟，显卡将进一步模糊与专用AI芯片的边界，成为异构计算的“万能胶水”，推动游戏、创作与科学计算的全面革新。显卡架构是GPU设计的核心，不同厂商有其独特的架构演进。"
keywords: "AI技术学习笔记系列004：GPU常识"
categories: ['未分类']
tags: ['笔记', '学习', '人工智能']
artid: "146291743"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146291743
    alt: "AI技术学习笔记系列004GPU常识"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146291743
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146291743
cover: https://bing.ee123.net/img/rand?artid=146291743
image: https://bing.ee123.net/img/rand?artid=146291743
img: https://bing.ee123.net/img/rand?artid=146291743
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     AI技术学习笔记系列004：GPU常识
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     显卡架构是GPU设计的核心，不同厂商有其独特的架构演进。以下是主要厂商的显卡架构概述：
    </p>
    <h4>
     <a id="NVIDIA_3">
     </a>
     <strong>
      一、NVIDIA
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        Tesla
       </strong>
       （2006-2010）
      </p>
      <ul>
       <li>
        代表产品：GeForce 8000系列（G80）。
       </li>
       <li>
        特点：首款统一着色架构，支持CUDA。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        Fermi
       </strong>
       （2010）
      </p>
      <ul>
       <li>
        产品：GTX 400/500系列。
       </li>
       <li>
        特点：引入L2缓存，支持ECC内存。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        Kepler
       </strong>
       （2012）
      </p>
      <ul>
       <li>
        产品：GTX 600/700系列。
       </li>
       <li>
        特点：能效提升，支持GPU Boost。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        Maxwell
       </strong>
       （2014）
      </p>
      <ul>
       <li>
        产品：GTX 900系列。
       </li>
       <li>
        特点：高能效比，SMM单元优化。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        Pascal
       </strong>
       （2016）
      </p>
      <ul>
       <li>
        产品：GTX 10系列（如1080）。
       </li>
       <li>
        特点：16nm工艺，支持NVLink。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        Volta
       </strong>
       （2017）
      </p>
      <ul>
       <li>
        产品：Tesla V100（数据中心）。
       </li>
       <li>
        特点：Tensor Core加速AI计算。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        Turing
       </strong>
       （2018）
      </p>
      <ul>
       <li>
        产品：RTX 20系列。
       </li>
       <li>
        特点：首次支持光线追踪和DLSS。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        Ampere
       </strong>
       （2020）
      </p>
      <ul>
       <li>
        产品：RTX 30系列、A100。
       </li>
       <li>
        特点：第二代光追，第三代Tensor Core。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        Ada Lovelace
       </strong>
       （2022）
      </p>
      <ul>
       <li>
        产品：RTX 40系列。
       </li>
       <li>
        特点：DLSS 3，第四代光追。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        Hopper
       </strong>
       （2022）
      </p>
      <ul>
       <li>
        产品：H100（数据中心）。
       </li>
       <li>
        特点：Transformer引擎，HBM3内存。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="AMD_46">
     </a>
     <strong>
      二、AMD
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        GCN（Graphics Core Next）
       </strong>
       （2012-2018）
      </p>
      <ul>
       <li>
        产品：Radeon HD 7000系列至RX 500系列。
       </li>
       <li>
        特点：统一计算架构，支持Mantle API。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        RDNA（Radeon DNA）
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         RDNA 1
        </strong>
        （2019）：RX 5000系列，7nm工艺，提升能效。
       </li>
       <li>
        <strong>
         RDNA 2
        </strong>
        （2020）：RX 6000系列（如6900 XT），支持光线追踪和FSR。
       </li>
       <li>
        <strong>
         RDNA 3
        </strong>
        （2022）：RX 7000系列，5nm工艺，Chiplet设计。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        CDNA
       </strong>
       （2020-至今）
      </p>
      <ul>
       <li>
        产品：Instinct MI系列（如MI250X）。
       </li>
       <li>
        特点：专为计算优化，支持Infinity Fabric。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="Intel_62">
     </a>
     <strong>
      三、Intel
     </strong>
    </h4>
    <ol>
     <li>
      <strong>
       Xe架构
      </strong>
      <ul>
       <li>
        <strong>
         Xe LP
        </strong>
        （2020）：集成显卡（如Iris Xe）。
       </li>
       <li>
        <strong>
         Xe HPG
        </strong>
        （2022）：Arc A系列（如A770），支持光线追踪和XeSS。
       </li>
       <li>
        <strong>
         Xe HPC
        </strong>
        （2022）：Ponte Vecchio（数据中心）。
       </li>
       <li>
        <strong>
         Xe HP
        </strong>
        ：多芯片设计，面向服务器。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_71">
     </a>
     <strong>
      四、其他厂商
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        Imagination PowerVR
       </strong>
      </p>
      <ul>
       <li>
        用于移动设备（如旧款iPhone），低功耗设计。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        ARM Mali
       </strong>
      </p>
      <ul>
       <li>
        集成于移动SoC（如三星Exynos），侧重能效。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        高通 Adreno
       </strong>
      </p>
      <ul>
       <li>
        源自ATI Imageon，用于骁龙芯片（如Adreno 740）。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_83">
     </a>
     <strong>
      五、应用领域
     </strong>
    </h4>
    <ul>
     <li>
      <strong>
       游戏/消费级
      </strong>
      ：NVIDIA Ada Lovelace、AMD RDNA、Intel Xe HPG。
     </li>
     <li>
      <strong>
       数据中心
      </strong>
      ：NVIDIA Hopper、AMD CDNA、Intel Xe HPC。
     </li>
     <li>
      <strong>
       移动/嵌入式
      </strong>
      ：ARM Mali、PowerVR、Adreno。
     </li>
    </ul>
    <h4>
     <a id="Blackwell_88">
     </a>
     <strong>
      六、英伟达Blackwell架构
     </strong>
    </h4>
    <p>
     以下是英伟达Blackwell架构的历史发展脉络，结合技术演进、市场背景与行业影响进行综合分析：
    </p>
    <hr/>
    <h4>
     <a id="_94">
     </a>
     <strong>
      一、起源与命名
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        发布背景
       </strong>
       <br/>
       Blackwell架构是英伟达在AI算力需求爆炸式增长、摩尔定律逐渐放缓的背景下推出的新一代GPU架构。其目标是通过技术创新解决用户对高画质、高帧率与低功耗的双重需求，同时支撑万亿参数级AI模型的训练与推理。
      </p>
     </li>
     <li>
      <p>
       <strong>
        命名由来
       </strong>
       <br/>
       架构以美国数学家
       <strong>
        David Blackwell
       </strong>
       （首位入选美国国家科学院的黑人学者）命名，延续了英伟达以科学家命名的传统（如Turing、Ampere等），旨在致敬其对统计学和博弈论的贡献。
      </p>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_103">
     </a>
     <strong>
      二、研发投入与时间线
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        研发周期与成本
       </strong>
      </p>
      <ul>
       <li>
        研发始于2021年，历时3年，投入约2.5万名工程师，人力成本估算达
        <strong>
         163亿美元
        </strong>
        （仅薪酬部分）。
       </li>
       <li>
        作为对比，前代Hopper架构研发成本约为其一半，但Blackwell的复杂性与技术突破显著提升。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        发布与延迟
       </strong>
      </p>
      <ul>
       <li>
        2024年3月，英伟达在
        <strong>
         GTC开发者大会
        </strong>
        上首次公布Blackwell架构，并推出首款产品GB200芯片。
       </li>
       <li>
        原计划2024年底量产，但因台积电CoWoS封装工艺问题推迟至2025年第一季度。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_114">
     </a>
     <strong>
      三、技术演进与架构继承
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        前代架构的积累
       </strong>
       <br/>
       Blackwell继承了英伟达GPU架构的迭代基因：
      </p>
      <ul>
       <li>
        <strong>
         Pascal
        </strong>
        （2016）：首推统一着色器设计，奠定CUDA核心灵活性基础。
       </li>
       <li>
        <strong>
         Volta
        </strong>
        （2017）：引入Tensor Core，开启AI专用加速时代。
       </li>
       <li>
        <strong>
         Ampere
        </strong>
        （2020）：NVLink 3.0与HBM2e显存提升多卡协作效率。
       </li>
       <li>
        <strong>
         Hopper
        </strong>
        （2022）：HBM3显存与FP8精度优化大模型训练。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        Blackwell的核心突破
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         晶体管与工艺
        </strong>
        ：采用台积电4nm工艺，集成
        <strong>
         2080亿晶体管
        </strong>
        （Hopper的两倍）。
       </li>
       <li>
        <strong>
         显存技术
        </strong>
        ：配备192GB HBM3e显存，带宽达
        <strong>
         8TB/s
        </strong>
        ，支持万亿参数模型实时推理。
       </li>
       <li>
        <strong>
         计算单元
        </strong>
        ：第五代Tensor Core支持
        <strong>
         FP4/FP6低精度计算
        </strong>
        ，AI算力提升至
        <strong>
         20千万亿次/秒
        </strong>
        （H100的5倍）。
       </li>
       <li>
        <strong>
         互联技术
        </strong>
        ：NVLink 5提供
        <strong>
         1.8TB/s双向带宽
        </strong>
        ，支持576个GPU无缝互联，构建超大规模集群。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_130">
     </a>
     <strong>
      四、产品化与市场布局
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        关键产品线
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         数据中心
        </strong>
        ：GB200 NVL72系统（72个GPU + 36个Grace CPU），专为万亿参数大语言模型设计，推理性能较H100提升30倍。
       </li>
       <li>
        <strong>
         消费级显卡
        </strong>
        ：RTX 50系列（如RTX 5090），采用GDDR7显存（30Gbps带宽）与神经网络着色器，支持DLSS 4与8K 165Hz显示。
       </li>
       <li>
        <strong>
         AI芯片
        </strong>
        ：B300芯片（288GB HBM3e显存），TDP提升至1400W，面向超大规模AI训练。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        行业合作与生态
       </strong>
      </p>
      <ul>
       <li>
        亚马逊、谷歌、微软等云服务商首批采用Blackwell平台。
       </li>
       <li>
        与CUDA生态深度绑定，巩固英伟达在AI芯片市场
        <strong>
         90%的份额
        </strong>
        ，同时面临“UXL基金会”等开源联盟的挑战。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_142">
     </a>
     <strong>
      五、历史意义与行业影响
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        技术里程碑
       </strong>
       <br/>
       Blackwell标志着GPU从“图形处理器”向“通用AI加速器”的彻底转型，其多精度计算、海量互联与能效优化重新定义了高性能计算的标准。
      </p>
     </li>
     <li>
      <p>
       <strong>
        市场格局重塑
       </strong>
      </p>
      <ul>
       <li>
        推动AI模型规模从万亿向十万亿参数迈进，加速生成式AI（如3D视频生成）的平民化。
       </li>
       <li>
        巩固英伟达在AI芯片市场的垄断地位，但也引发对技术依赖与生态封闭性的争议。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        未来方向
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         Chiplet与光互联
        </strong>
        ：Blackwell的模块化设计为后续多芯片集成铺路，硅光技术或成下一代互联核心。
       </li>
       <li>
        <strong>
         量子计算协同
        </strong>
        ：通过cuQuantum项目探索GPU加速量子模拟，拓展异构计算边界。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <p>
     Blackwell架构是英伟达继Hopper后的又一里程碑，其技术突破与市场策略体现了“AI驱动计算”的行业趋势。从研发投入、性能指标到生态布局，Blackwell不仅延续了英伟达的技术霸权，更将AI算力推向了新的高度，成为2020年代中后期全球AI基础设施的核心支柱。
    </p>
    <hr/>
    <h4>
     <a id="_161">
     </a>
     <strong>
      补充内容：历史架构与冷门厂商
     </strong>
    </h4>
    <h5>
     <a id="1__162">
     </a>
     <strong>
      1. 经典老架构（已退出市场）
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        3dfx Voodoo
       </strong>
       （1990年代）
      </p>
      <ul>
       <li>
        <strong>
         Voodoo Graphics
        </strong>
        （1996）：首款3D加速卡，支持Glide API。
       </li>
       <li>
        <strong>
         Voodoo2
        </strong>
        （1998）：SLI多卡互联技术先驱。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        NVIDIA NV1
       </strong>
       （1995）
      </p>
      <ul>
       <li>
        集成2D+3D+声卡功能，但采用四边形渲染（非主流三角形），最终失败。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        ATI Rage/R300
       </strong>
       （1990s-2000s）
      </p>
      <ul>
       <li>
        <strong>
         Rage 128
        </strong>
        （1998）：对抗Voodoo的早期尝试。
       </li>
       <li>
        <strong>
         Radeon 9700（R300）
        </strong>
        （2002）：首款支持DirectX 9的显卡，击败同期NVIDIA FX 5800。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        S3 Graphics
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         S3 Virge
        </strong>
        （1995）：首款“2D+3D加速”消费级显卡，但3D性能较弱。
       </li>
       <li>
        <strong>
         S3 Savage
        </strong>
        （1998）：支持纹理压缩，但驱动问题导致市场失利。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        Matrox
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         Parhelia
        </strong>
        （2002）：首款支持三屏输出的显卡，主打专业多屏市场。
       </li>
      </ul>
     </li>
    </ul>
    <hr/>
    <h5>
     <a id="2__183">
     </a>
     <strong>
      2. 技术细节补充
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        统一着色器架构
       </strong>
       （Unified Shaders）
      </p>
      <ul>
       <li>
        起源：2006年NVIDIA Tesla架构首次实现，取代了传统的固定管线（VS/PS分离）。
       </li>
       <li>
        意义：允许GPU动态分配计算资源，提升通用计算能力。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        显存技术演进
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         GDDR3→GDDR5→GDDR6→GDDR6X
        </strong>
        ：带宽与频率逐代提升。
       </li>
       <li>
        <strong>
         HBM
        </strong>
        （High Bandwidth Memory）：AMD Fury系列（2015）首次采用，通过3D堆叠实现高带宽。
       </li>
       <li>
        <strong>
         HBM3
        </strong>
        ：Hopper架构的H100使用，带宽达3TB/s。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        制造工艺节点
       </strong>
      </p>
      <ul>
       <li>
        NVIDIA Fermi（40nm）→Pascal（16nm）→Ampere（8nm）→Ada Lovelace（4nm）。
       </li>
       <li>
        AMD RDNA 3（5nm+6nm Chiplet） vs Intel Xe HPG（TSMC 6nm）。
       </li>
      </ul>
     </li>
    </ul>
    <hr/>
    <h5>
     <a id="3__199">
     </a>
     <strong>
      3. 架构对比关键指标
     </strong>
    </h5>
    <table>
     <thead>
      <tr>
       <th>
        <strong>
         架构
        </strong>
       </th>
       <th>
        <strong>
         核心创新
        </strong>
       </th>
       <th>
        <strong>
         制程工艺
        </strong>
       </th>
       <th>
        <strong>
         代表技术
        </strong>
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        <strong>
         NVIDIA Turing
        </strong>
       </td>
       <td>
        光线追踪硬件单元（RT Core）
       </td>
       <td>
        12nm
       </td>
       <td>
        DLSS 1.0、RTX Voice
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         AMD RDNA 2
        </strong>
       </td>
       <td>
        Infinity Cache（高速缓存优化）
       </td>
       <td>
        7nm
       </td>
       <td>
        FSR 1.0、硬件光追加速
       </td>
      </tr>
      <tr>
       <td>
        <strong>
         Intel Xe HPG
        </strong>
       </td>
       <td>
        独立显卡市场突破
       </td>
       <td>
        6nm
       </td>
       <td>
        XeSS超分、Deep Link协同计算
       </td>
      </tr>
     </tbody>
    </table>
    <hr/>
    <h4>
     <a id="4__208">
     </a>
     <strong>
      4. 未来趋势
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        Chiplet设计
       </strong>
      </p>
      <ul>
       <li>
        AMD RDNA 3和CDNA 2采用多芯片模块化设计，提升良率与扩展性。
       </li>
       <li>
        NVIDIA未来可能跟进（如Hopper的MCM布局）。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        AI与GPU深度融合
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         DLSS/FSR/XeSS
        </strong>
        ：超分辨率技术依赖AI计算。
       </li>
       <li>
        <strong>
         AI降噪
        </strong>
        ：光线追踪中加速渲染（如OptiX AI）。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        量子计算与GPU混合
       </strong>
      </p>
      <ul>
       <li>
        NVIDIA cuQuantum项目探索GPU加速量子模拟。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        存算一体架构
       </strong>
      </p>
      <ul>
       <li>
        三星、SK海力士研发HBM-PIM（内存内计算），减少数据搬运延迟。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="5__225">
     </a>
     <strong>
      5. 小众/新兴玩家
     </strong>
    </h4>
    <ul>
     <li>
      <p>
       <strong>
        国产GPU
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         摩尔线程MTT S80
        </strong>
        ：基于PowerVR架构，支持PCIe 5.0。
       </li>
       <li>
        <strong>
         壁仞科技BR100
        </strong>
        ：7nm工艺，对标数据中心GPU。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        开源架构
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         RISC-V GPU
        </strong>
        ：如Imagination推出的RISC-V兼容GPU IP。
       </li>
       <li>
        <strong>
         Mesa 3D
        </strong>
        ：开源驱动推动老旧显卡兼容新API（如Vulkan）。
       </li>
      </ul>
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="6__236">
     </a>
     <strong>
      6. 冷知识
     </strong>
    </h4>
    <ul>
     <li>
      <strong>
       NVIDIA的代号来源
      </strong>
      ：历代架构以科学家命名（如Turing→艾伦·图灵，Ampere→安培）。
     </li>
     <li>
      <strong>
       AMD的“RDNA”含义
      </strong>
      ：源自“Radeon DNA”，强调架构基因革新。
     </li>
     <li>
      <strong>
       Intel Xe的野心
      </strong>
      ：Xe涵盖集成显卡、游戏卡、数据中心，试图统一GPU生态。
     </li>
    </ul>
    <hr/>
    <p>
     以下是基于显卡架构演进历程，对
     <strong>
      显卡通信技术
     </strong>
     与**AI专用硬件（“AI颗粒”）**两大方面的综合分析：
    </p>
    <hr/>
    <h4>
     <a id="_250">
     </a>
     <strong>
      一、显卡通信技术的演进
     </strong>
    </h4>
    <h5>
     <a id="1__251">
     </a>
     <strong>
      1. 高带宽显存与互联技术
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       GDDR到HBM的跨越
      </strong>
      ：
      <br/>
      早期显卡依赖GDDR显存（如GDDR3到GDDR6X），带宽逐步提升至1TB/s以上（如RTX 4090）。2015年AMD首次引入HBM（High Bandwidth Memory），通过3D堆叠实现更高带宽；英伟达在Blackwell架构中采用HBM3e，显存带宽达8TB/s，为大规模AI模型训练提供数据吞吐保障。
     </li>
     <li>
      <strong>
       NVLink与PCIe的协同
      </strong>
      ：
      <br/>
      NVIDIA在Pascal架构（2016）推出NVLink，单卡互联带宽达160GB/s，解决多GPU协作瓶颈。Volta架构（2017）扩展至6通道NVLink，双向带宽提升至300GB/s。PCIe 6.0的引入（带宽128GB/s）进一步优化CPU-GPU通信，降低延迟。
     </li>
    </ul>
    <h5>
     <a id="2__257">
     </a>
     <strong>
      2. 多卡协同与分布式计算
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       数据中心级互联方案
      </strong>
      ：
      <br/>
      Blackwell架构的GB200机架方案采用CPO（共封装光学）技术，通过光引擎与芯片集成，缩短传输距离，降低功耗。H200 GPU支持多卡协同训练，效率较H100提升4倍，显存容量扩展至192GB HBM3e，适用于千亿参数大模型。
     </li>
     <li>
      <strong>
       消费级多卡潜力
      </strong>
      ：
      <br/>
      用户通过魔改多张RTX 4090实现本地大模型推理（如70B参数Llama-2），借助PCIe 5.0与NVLink的混合方案，平衡成本与性能。
     </li>
    </ul>
    <h5>
     <a id="3_Chiplet_263">
     </a>
     <strong>
      3. 未来趋势：光互联与Chiplet设计
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       硅光技术与Chiplet
      </strong>
      ：
      <br/>
      AMD的RDNA 3和CDNA 2采用Chiplet设计，分离计算单元与I/O模块，提升良率与扩展性。英伟达探索硅光技术，通过光互联优化数据中心内GPU集群通信效率。
     </li>
     <li>
      <strong>
       存算一体架构
      </strong>
      ：
      <br/>
      三星HBM-PIM（内存内计算）技术将部分计算逻辑嵌入显存，减少数据搬运延迟，适用于实时AI推理场景。
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="AIAI_271">
     </a>
     <strong>
      二、AI专用硬件（“AI颗粒”）的演进
     </strong>
    </h4>
    <h5>
     <a id="1__272">
     </a>
     <strong>
      1. 从通用计算到专用加速单元
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       Tensor Core的诞生与进化
      </strong>
      ：
      <br/>
      Volta架构（2017）首次引入Tensor Core，专为张量计算优化，支持FP16混合精度。Turing架构（2018）扩展至INT8/INT4量化计算，Ampere架构（2020）新增TF32与BF16支持，Blackwell架构（2024）引入FP4/FP6精度，降低大模型存储与计算开销。
     </li>
     <li>
      <strong>
       NPU与CUDA核心的协同
      </strong>
      ：
      <br/>
      NVIDIA在RTX 500系列笔记本显卡中集成NPU（神经网络处理单元），专用于轻型AI任务（如语音识别），与GPU的Tensor Core分工协作，提升能效比。
     </li>
    </ul>
    <h5>
     <a id="2_AI_278">
     </a>
     <strong>
      2. AI计算与图形渲染的融合
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       DLSS/FSR/XeSS超分技术
      </strong>
      ：
      <br/>
      基于AI的超分辨率技术（如DLSS 3）利用Tensor Core实时生成高分辨率帧，减少原生渲染负载。AMD FSR与Intel XeSS通过算法优化，实现类似效果。
     </li>
     <li>
      <strong>
       光线追踪与AI降噪
      </strong>
      ：
      <br/>
      RT Core处理光线追踪路径计算，Tensor Core通过AI算法（如OptiX AI）加速降噪，提升实时渲染效率。例如《赛博朋克2077》的路径追踪模式依赖二者协同。
     </li>
    </ul>
    <h5>
     <a id="3_AI_284">
     </a>
     <strong>
      3. 未来趋势：AI驱动的硬件定制化
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       量化与低精度计算
      </strong>
      ：
      <br/>
      Blackwell架构支持FP4/FP6精度，结合模型压缩技术，使70B参数模型可在单卡运行，推理速度提升2倍。
     </li>
     <li>
      <strong>
       AI辅助芯片设计
      </strong>
      ：
      <br/>
      英伟达CuLitho技术利用GPU加速光刻模拟，将芯片设计周期从2周缩短至8小时，推动更高效的AI芯片迭代。
     </li>
     <li>
      <strong>
       开源生态与国产GPU
      </strong>
      ：
      <br/>
      摩尔线程MTT S80基于PowerVR架构支持PCIe 5.0，壁仞科技BR100对标数据中心GPU，国产GPU逐步融入AI计算生态。
     </li>
    </ul>
    <p>
     以下是关于显卡通信技术提升与AI专用硬件（“AI颗粒”）发展的综合分析，结合了当前技术趋势和厂商动态：
    </p>
    <hr/>
    <h4>
     <a id="_299">
     </a>
     <strong>
      一、显卡通信技术的革新
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        高带宽显存与互联技术
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         HBM3e与GDDR6X
        </strong>
        ：英伟达Blackwell架构的HBM3e显存带宽翻倍，达3TB/s，显著提升AI大模型的数据吞吐效率。AMD的RDNA 3也采用HBM3，而消费级显卡如RTX 4090使用GDDR6X，带宽突破1TB/s。
       </li>
       <li>
        <strong>
         NVLink与PCIe 6.0
        </strong>
        ：NVLink在Blackwell中带宽翻倍，支持多GPU高速互联；PCIe 6.0的引入进一步降低CPU与GPU间的通信延迟，适用于数据中心和高端计算场景。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        光模块与芯片互联优化
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         CPO（共封装光学）技术
        </strong>
        ：通过将光引擎与芯片集成，缩短传输距离，降低功耗（如英伟达GB200机架方案）。
       </li>
       <li>
        <strong>
         硅光技术
        </strong>
        ：提升数据中心内GPU集群的通信效率，支持大规模AI训练。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        多卡协同与分布式计算
       </strong>
      </p>
      <ul>
       <li>
        英伟达的GB200方案通过优化CPU:GPU配比，降低总拥有成本（TCO），同时支持多卡协同训练，效率达H100的4倍。
       </li>
       <li>
        消费级用户可通过魔改多张RTX 4090实现本地大模型推理（如70B参数模型）。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="AIAI_314">
     </a>
     <strong>
      二、AI专用硬件（“AI颗粒”）的演进
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        Tensor Core与NPU的融合
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         英伟达Tensor Core
        </strong>
        ：第四代Tensor Core（Ada Lovelace架构）支持FP8精度，AI计算效率提升3倍，适用于DLSS 3和生成式AI任务。
       </li>
       <li>
        <strong>
         NPU（神经网络处理单元）
        </strong>
        ：英伟达RTX 500/1000系列笔记本显卡集成NPU，专用于轻型AI任务（如语音识别），与GPU协同降低功耗。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        CUDA核心的双模式设计
       </strong>
      </p>
      <ul>
       <li>
        英伟达RTX 50系列（Blackwell架构）的CUDA核心支持FP32/INT32双数据模式，复兴Pascal时代的灵活设计，提升AI推理和游戏渲染的并行效率。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        英特尔与AMD的AI加速方案
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         英特尔XMX引擎
        </strong>
        ：Xe2架构集成增强版XMX单元，支持VVC编解码和AI图像生成（如AI Playground应用）。
       </li>
       <li>
        <strong>
         AMD CDNA架构
        </strong>
        ：专为计算优化，Infinity Fabric技术提升多GPU协作能力，适用于数据中心AI训练。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <h4>
     <a id="_328">
     </a>
     <strong>
      三、技术融合与未来趋势
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        AI与图形计算的深度结合
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         实时AI渲染
        </strong>
        ：通过Tensor Core加速光线追踪降噪（如OptiX AI），或动态生成游戏场景（如《方舟：生存飞升》中的G-Assist AI助手）。
       </li>
       <li>
        <strong>
         创作工具革新
        </strong>
        ：AI Playground、DALL-E等工具依赖显卡的并行计算能力，实现本地化图像生成与编辑。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        Chiplet与存算一体架构
       </strong>
      </p>
      <ul>
       <li>
        AMD RDNA 3和CDNA 2采用Chiplet设计，提升良率与扩展性；三星HBM-PIM技术探索内存内计算，减少数据搬运延迟。
       </li>
       <li>
        未来显卡可能集成量子计算模块（如NVIDIA cuQuantum），加速复杂模拟任务。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        能效与生态整合
       </strong>
      </p>
      <ul>
       <li>
        英伟达DLSS/AMD FSR/Intel XeSS等超分技术依赖AI优化，在提升画质的同时降低GPU负载。
       </li>
       <li>
        开源社区推动RISC-V GPU与Mesa 3D驱动发展，降低AI开发门槛。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <p>
     以下是基于NVIDIA、AMD和Intel等厂商的显卡架构演进历程，对其技术改进方向及驱动原因的分析：
    </p>
    <hr/>
    <h4>
     <a id="NVIDIA_347">
     </a>
     <strong>
      一、NVIDIA架构演进的技术方向
     </strong>
    </h4>
    <h5>
     <a id="1_Tesla__Fermi__Kepler_348">
     </a>
     <strong>
      1. 早期架构（Tesla → Fermi → Kepler）
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        统一计算与并行化（Tesla架构）
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         技术改进
        </strong>
        ：首次引入统一着色器模型（Unified Shaders），支持CUDA编程，将顶点、几何和像素处理统一为通用计算单元。
       </li>
       <li>
        <strong>
         原因
        </strong>
        ：满足通用计算需求（如科学模拟），突破传统固定管线限制，为GPU计算奠定基础。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        双精度计算与缓存优化（Fermi架构）
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         技术改进
        </strong>
        ：增加双精度浮点单元（FP64）、ECC内存支持和L2缓存层级设计。
       </li>
       <li>
        <strong>
         原因
        </strong>
        ：进军高性能计算（HPC）市场，提升数据中心应用的可靠性和计算精度。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        能效与SM单元重构（Kepler架构）
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         技术改进
        </strong>
        ：引入SMX单元，CUDA核心数激增（每组SMX含192核心），优化功耗比。
       </li>
       <li>
        <strong>
         原因
        </strong>
        ：应对移动设备和云计算对能效的敏感需求，降低单位计算成本。
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <a id="2_Maxwell__Pascal__Volta__Turing__Ampere__Blackwell_361">
     </a>
     <strong>
      2. 现代架构（Maxwell → Pascal → Volta → Turing → Ampere → Blackwell）
     </strong>
    </h5>
    <ul>
     <li>
      <p>
       <strong>
        能效与架构精简（Maxwell架构）
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         技术改进
        </strong>
        ：SMM单元采用模块化设计，CUDA核心精简但逻辑控制增强，显存压缩技术提升带宽利用率。
       </li>
       <li>
        <strong>
         原因
        </strong>
        ：优化游戏显卡的功耗表现，适应轻薄笔记本和嵌入式设备需求。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        深度学习与互联技术（Pascal架构）
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         技术改进
        </strong>
        ：16nm工艺、NVLink多GPU互联、支持FP16半精度计算。
       </li>
       <li>
        <strong>
         原因
        </strong>
        ：AI浪潮兴起，需加速深度学习训练（如AlphaGo），提升多卡协同效率。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        专用AI单元（Volta架构）
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         技术改进
        </strong>
        ：首次集成Tensor Core，支持混合精度（FP16/FP32）计算，提升AI推理速度。
       </li>
       <li>
        <strong>
         原因
        </strong>
        ：应对AI模型复杂化（如Transformer），降低训练成本。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        实时光追与AI超分（Turing架构）
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         技术改进
        </strong>
        ：引入RT Core（光线追踪硬件单元）和DLSS（AI超分辨率）。
       </li>
       <li>
        <strong>
         原因
        </strong>
        ：推动游戏画质革命，解决光追性能瓶颈，通过AI降低渲染负载。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        多领域融合（Ampere架构）
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         技术改进
        </strong>
        ：第三代Tensor Core支持稀疏计算，显存带宽提升（HBM2e/GDDR6X），支持PCIe 4.0。
       </li>
       <li>
        <strong>
         原因
        </strong>
        ：兼顾游戏、数据中心和AI推理，满足多任务场景需求。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        神经网络渲染与显存革新（Blackwell架构）
       </strong>
      </p>
      <ul>
       <li>
        <strong>
         技术改进
        </strong>
        ：第五代Tensor Core支持FP4低精度计算，GDDR7显存（PAM3编码），引入神经网络着色器和AI管理处理器（AMP）。
       </li>
       <li>
        <strong>
         原因
        </strong>
        ：应对万亿参数大模型训练需求，降低显存占用，提升AI推理效率；通过神经网络渲染优化游戏材质生成效率。
       </li>
      </ul>
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="AMD_388">
     </a>
     <strong>
      二、AMD架构演进的技术方向
     </strong>
    </h4>
    <h5>
     <a id="1_GCN20122018_389">
     </a>
     <strong>
      1. GCN架构（2012-2018）
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       统一计算与显存优化
      </strong>
      <ul>
       <li>
        <strong>
         技术改进
        </strong>
        ：统一计算单元（CU）、HBM显存首次应用（Fury系列）。
       </li>
       <li>
        <strong>
         原因
        </strong>
        ：对标NVIDIA的通用计算能力，提升带宽密集型任务（如4K游戏）表现。
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <a id="2_RDNA2019_394">
     </a>
     <strong>
      2. RDNA架构（2019至今）
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       能效与游戏优化（RDNA 1/2/3）
      </strong>
      <ul>
       <li>
        <strong>
         技术改进
        </strong>
        ：Infinity Cache（高速缓存）、硬件光追加速、Chiplet设计（RDNA 3）。
       </li>
       <li>
        <strong>
         原因
        </strong>
        ：缩小与NVIDIA的游戏性能差距，通过模块化设计提升良率和扩展性。
       </li>
      </ul>
     </li>
    </ul>
    <h5>
     <a id="3_CDNA2020_399">
     </a>
     <strong>
      3. CDNA架构（2020至今）
     </strong>
    </h5>
    <ul>
     <li>
      <strong>
       计算专用优化
      </strong>
      <ul>
       <li>
        <strong>
         技术改进
        </strong>
        ：Infinity Fabric互联、双精度计算强化，支持ROCm生态。
       </li>
       <li>
        <strong>
         原因
        </strong>
        ：争夺数据中心和AI市场，针对HPC和机器学习任务优化。
       </li>
      </ul>
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="Intel_Xe_406">
     </a>
     <strong>
      三、Intel Xe架构的技术方向
     </strong>
    </h4>
    <ul>
     <li>
      <strong>
       多场景覆盖（Xe LP/HPG/HPC）
      </strong>
      <ul>
       <li>
        <strong>
         技术改进
        </strong>
        ：Xe HPG支持硬件光追和XeSS超分，Xe HPC采用Chiplet和HBM显存。
       </li>
       <li>
        <strong>
         原因
        </strong>
        ：进军独立显卡市场，覆盖从集成显卡到数据中心的多元化需求，挑战NVIDIA和AMD的垄断。
       </li>
      </ul>
     </li>
    </ul>
    <hr/>
    <h4>
     <a id="_413">
     </a>
     <strong>
      四、技术改进的共性驱动因素
     </strong>
    </h4>
    <ol>
     <li>
      <p>
       <strong>
        市场需求变化
       </strong>
      </p>
      <ul>
       <li>
        游戏画质升级（光追、高帧率）推动硬件加速单元（RT Core）；
       </li>
       <li>
        AI计算需求（如ChatGPT）催生专用AI核心（Tensor Core）。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        制程工艺进步
       </strong>
      </p>
      <ul>
       <li>
        从28nm（Kepler）到4nm（Blackwell），晶体管密度提升支持更复杂架构。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        能效与环保压力
       </strong>
      </p>
      <ul>
       <li>
        GDDR7显存功耗降低50%，Chiplet设计减少芯片废品率。
       </li>
      </ul>
     </li>
     <li>
      <p>
       <strong>
        竞争与生态建设
       </strong>
      </p>
      <ul>
       <li>
        NVIDIA通过CUDA生态绑定开发者，AMD以开源ROCm和性价比策略应对。
       </li>
      </ul>
     </li>
    </ol>
    <hr/>
    <p>
     显卡架构的演进始终围绕
     <strong>
      性能提升
     </strong>
     、
     <strong>
      能效优化
     </strong>
     和
     <strong>
      场景适配
     </strong>
     三大核心方向。从早期的通用计算到如今的AI与光追融合，每一次技术革新都反映了市场需求（如游戏、AI、HPC）、工艺突破（如先进制程、HBM）和竞争格局的演变。未来，随着Chiplet、存算一体和量子计算协同技术的发展，显卡将进一步打破传统边界，成为异构计算的基石。
    </p>
    <h4>
     <a id="_432">
     </a>
     <strong>
      总结
     </strong>
    </h4>
    <p>
     显卡架构随技术进步不断演进，NVIDIA在光追和AI领先，AMD注重能效与性价比，Intel通过Xe进军独立显卡市场，移动端则由ARM、高通等主导。
    </p>
    <p>
     除了之前提到的核心架构，还有一些补充内容，包括历史架构、技术细节和新兴趋势：
    </p>
    <p>
     显卡架构不仅是硬件设计的进化史，更是计算需求的缩影——从早期3D加速到光追与AI，从固定管线到通用计算。未来，随着Chiplet、存算一体等技术的成熟，GPU可能进一步模糊与CPU、专用加速器的边界，成为异构计算的“万能胶水”。
    </p>
    <hr/>
    <p>
     架构演进的核心驱动力**
    </p>
    <ol>
     <li>
      <strong>
       通信技术
      </strong>
      ：从GDDR到HBM3e，从PCIe到NVLink/光互联，显存带宽与多卡协作效率的持续提升，支撑了AI大模型的训练与推理需求。
     </li>
     <li>
      <strong>
       AI硬件
      </strong>
      ：从通用CUDA核心到专用Tensor Core/NPU，计算精度与能效的优化，使GPU从图形处理器进化为通用AI加速器。
     </li>
    </ol>
    <p>
     未来，随着Chiplet、存算一体等技术的成熟，显卡将进一步模糊与专用AI芯片的边界，成为异构计算的“万能胶水”，推动游戏、创作与科学计算的全面革新。
    </p>
    <p>
     显卡通信技术的提升（如HBM3e、NVLink）与AI专用硬件（Tensor Core、NPU）的演进，共同推动了AI计算的高效化与平民化。未来，随着Chiplet、存算一体等技术的成熟，显卡将进一步成为异构计算的核心，同时支持游戏、创作与科学计算等多重场景。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f62656966656e6732303230303130312f:61727469636c652f64657461696c732f313436323931373433" class_="artid" style="display:none">
 </p>
</div>


