---
layout: post
title: "大语言模型学习及复习笔记1语言模型的发展历程"
date: 2025-03-13 02:57:28 +0800
description: "大模型核心技术 规模扩展：扩展定律奠定了早期大模型的技术路线，产生了巨大的性能提升 数据工程：数据数量、数据质量以及配制方法极其关键 高效预训练：需要建立可预测、可扩展的大规模训练架构 能力激发：预训练后可以通过微调、对齐、提示工程等技术进行能力激活 人类对齐：需要设计对齐技术减少模型使用风险，并进一步提升模型性能 工具使用：使用外部工具加强模型的弱点，拓展其能力范围。传统语言模型存在局限性,需要使用特殊的技术进行模型能力提升。语言模型通常是指能够建模自然语言文本生成概率的模型。全能输入输出，实时联网。"
keywords: "大语言模型学习及复习笔记（1）语言模型的发展历程"
categories: ['未分类']
tags: ['语言模型', '笔记', '学习']
artid: "146220259"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146220259
    alt: "大语言模型学习及复习笔记1语言模型的发展历程"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146220259
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146220259
cover: https://bing.ee123.net/img/rand?artid=146220259
image: https://bing.ee123.net/img/rand?artid=146220259
img: https://bing.ee123.net/img/rand?artid=146220259
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     大语言模型学习及复习笔记（1）语言模型的发展历程
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     1.大模型进入人们视野
    </h2>
    <p>
     ChatGPT 于2022年11月底上线
    </p>
    <table>
     <tbody>
      <tr>
       <td colspan="1" rowspan="1">
        <p>
         模型名称
        </p>
       </td>
       <td colspan="1" rowspan="1">
        <p>
         发布时间
        </p>
       </td>
       <td colspan="1" rowspan="1">
        <p>
         核心突破
        </p>
       </td>
       <td rowspan="1">
       </td>
       <td rowspan="1">
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1">
        <p>
         GPT-3
        </p>
       </td>
       <td colspan="1" rowspan="1">
        <p>
         2020年6月
        </p>
       </td>
       <td colspan="1" rowspan="1">
        <p>
         首款千亿参数模型，少样本学习
        </p>
       </td>
       <td rowspan="1">
        <img alt="" height="2250" src="https://i-blog.csdnimg.cn/direct/6a449ed44d3a416f86d01c5de4973069.png" width="4000"/>
       </td>
       <td rowspan="1">
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1">
        <p>
         GPT-3.5-Turbo
        </p>
       </td>
       <td colspan="1" rowspan="1">
        <p>
         2022年11月
        </p>
       </td>
       <td colspan="1" rowspan="1">
        <p>
         对话能力优化，用户级应用落地
        </p>
       </td>
       <td rowspan="1">
        <img alt="" height="2250" src="https://i-blog.csdnimg.cn/direct/3bd13266c1494b00b519f81e442b643a.png" width="4000"/>
       </td>
       <td rowspan="1">
        <img alt="" height="2250" src="https://i-blog.csdnimg.cn/direct/08e8d96142f54d4c96705b858e8f7134.png" width="4000"/>
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1">
        <p>
         GPT-4
        </p>
       </td>
       <td colspan="1" rowspan="1">
        <p>
         2023年3月
        </p>
       </td>
       <td colspan="1" rowspan="1">
        <p>
         多模态、强逻辑推理
        </p>
       </td>
       <td rowspan="1">
        <img alt="" height="2250" src="https://i-blog.csdnimg.cn/direct/859916234269468a9938fcfc7e773d9e.png" width="4000"/>
       </td>
       <td rowspan="1">
       </td>
      </tr>
      <tr>
       <td colspan="1" rowspan="1">
        <p>
         GPT-4o / GPT-4 Omni
        </p>
       </td>
       <td colspan="1" rowspan="1">
        <p>
         2024年5月
        </p>
       </td>
       <td colspan="1" rowspan="1">
        <p>
         全能输入输出，实时联网
        </p>
       </td>
       <td rowspan="1">
        <img alt="" height="2250" src="https://i-blog.csdnimg.cn/direct/1a312d85ad46441db5230bb72eb1a640.png" width="4000"/>
       </td>
       <td rowspan="1">
       </td>
      </tr>
      <tr>
       <td colspan="1">
        o1-preview
       </td>
       <td colspan="1">
        2024年9月
       </td>
       <td colspan="1">
       </td>
       <td>
        <img alt="" height="2250" src="https://i-blog.csdnimg.cn/direct/b134a0e041b949baa7088cd6858478db.png" width="4000"/>
       </td>
       <td>
        <img alt="" height="2250" src="https://i-blog.csdnimg.cn/direct/6f8025dc23344441bedb86d289dc4b19.png" width="4000"/>
       </td>
      </tr>
     </tbody>
    </table>
    <p>
     <img alt="" height="2250" src="https://i-blog.csdnimg.cn/direct/d5c01043db8e489d869fd1bb099e0488.png" width="4000"/>
    </p>
    <p>
    </p>
    <h2>
     2.什么是大语言模型
    </h2>
    <p>
     语言模型的核心功能是通过概率建模预测自然语言文本的生成规律。传统语言模型（如N-gram模型）主要基于统计方法，通过局部上下文预测词序列的分布。然而，
     <strong>
      大语
     </strong>
     <strong>
      言模型（Large Language Model, LLM）
     </strong>
     的出现标志着从单纯的语言建模向复杂任务求解的跃迁，其本质是通过海量数据与深度学习技术构建的通用智能系统。
    </p>
    <p>
    </p>
    <h3>
     <strong>
      2.1 传统
     </strong>
     <strong>
      语言模型的局限性
     </strong>
    </h3>
    <ol>
     <li>
      <strong>
       知识
      </strong>
      <strong>
       依赖性强
      </strong>
      ：需依赖外部知识库（如知识图谱）补充背景信息，难以自主理解隐含语义。
     </li>
    </ol>
    <ol>
     <li>
      <strong>
       泛化
      </strong>
      <strong>
       能力不足
      </strong>
      ：需针对特定任务微调模型，适配成本高且跨领域迁移效果差。
     </li>
    </ol>
    <ol>
     <li>
      <strong>
       推理
      </strong>
      <strong>
       能力受限
      </strong>
      ：处理复杂逻辑（如多步推理、因果分析）时表现较弱，需调整模型结构或引入额外训练策略。
     </li>
    </ol>
    <h3>
     <strong>
      2.2 大语
     </strong>
     <strong>
      言模型的技术突破
     </strong>
    </h3>
    <p>
     大语言模型通过以下创新解决了传统模型的瓶颈：
    </p>
    <ol>
     <li>
      <p>
       <strong>
        规模
       </strong>
       <strong>
        跃升
       </strong>
       ：参数规模达百亿至万亿级，训练数据覆盖多领域文本，可捕捉深层语言规律与常识。
      </p>
     </li>
    </ol>
    <ol>
     <li>
      <p>
       <strong>
        统一
       </strong>
       <strong>
        架构
       </strong>
       ：基于Transformer的自注意力机制，支持长距离依赖建模与上下文感知，无需任务特定结构调整。
      </p>
     </li>
    </ol>
    <ol>
     <li>
      <p>
       <strong>
        预训
       </strong>
       <strong>
        练范式
       </strong>
       ：通过海量无标注文本的自监督学习（如掩码语言建模），获得通用语义表示能力，显著降低下游任务适配成本。
      </p>
     </li>
    </ol>
    <ol>
     <li>
      <p>
       <strong>
        涌现
       </strong>
       <strong>
        能力
       </strong>
       ：在零样本/少样本场景下展现复杂推理、知识联想等能力，如代码生成、多轮对话。
      </p>
     </li>
     <li>
      <p>
       <img alt="" height="2250" src="https://i-blog.csdnimg.cn/direct/d093c5a1f44e45ddb75a3848a864cbe7.png" width="4000"/>
      </p>
     </li>
    </ol>
    <h3>
     <strong>
      2.3 传
     </strong>
     <strong>
      统模型的本质差异
     </strong>
    </h3>
    <table>
     <thead>
      <tr>
       <th>
        维度
       </th>
       <th>
        传统语言模型
       </th>
       <th>
        大语言模型
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        参数规模
       </td>
       <td>
        百万至千万级
       </td>
       <td>
        百亿至万亿级
       </td>
      </tr>
      <tr>
       <td>
        训练数据
       </td>
       <td>
        有限领域标注数据
       </td>
       <td>
        跨领域无标注文本（如网页、书籍）
       </td>
      </tr>
      <tr>
       <td>
        任务适配
       </td>
       <td>
        需针对性微调
       </td>
       <td>
        通过提示工程直接调用通用能力
       </td>
      </tr>
      <tr>
       <td>
        推理机制
       </td>
       <td>
        局部上下文依赖
       </td>
       <td>
        全局语义建模与逻辑链生成
       </td>
      </tr>
     </tbody>
    </table>
    <p>
    </p>
    <h5>
     <strong>
      应用
     </strong>
     <strong>
      与挑战
     </strong>
    </h5>
    <p>
     大语言模型已广泛应用于机器翻译、文本生成、智能问答等领域，但其仍面临幻觉问题（生成不准确内容）、算力需求高、伦理风险等挑战。未来，结合外部知识库与多模态数据可能成为进一步突破的方向。
    </p>
    <p>
    </p>
    <p>
    </p>
    <p>
    </p>
    <h2>
     3.大语言模型的定义和相关技术
    </h2>
    <p>
    </p>
    <p>
     <img alt="" height="2250" src="https://i-blog.csdnimg.cn/direct/aab49acdc89c4fecbc349df72adc0000.png" width="4000"/>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f36353436313838362f:61727469636c652f64657461696c732f313436323230323539" class_="artid" style="display:none">
 </p>
</div>


