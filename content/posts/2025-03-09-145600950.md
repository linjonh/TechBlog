---
layout: post
title: "langChainv0.3学习笔记初级篇"
date: 2025-03-09 20:50:18 +0800
description: "LangChain自0.1版本发布以来，已经历了显著的进化，特别是向AI时代的适应性提升。在0.1版本中，LangChain主要聚焦于提供基本的链式操作和工具集成，帮助开发者构建简单的语言模型应用。该版本适用于处理简单任务，但在应对更复杂的AI需求时显得有些局限。相比之下，LangChain 0.3版本展现了更为全面和强大的功能，进一步优化了其模块化架构，增强了与现代AI工具和框架的兼容性。这一版本加入了更多针对AI时代的特性，包括增强的多模态支持、自动化的推理链处理、以及更强的上下文管理能力。LangCh"
keywords: "langChainv0.3学习笔记（初级篇）"
categories: ['Ai']
tags: ['笔记', '学习', 'Ai']
artid: "145600950"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145600950
    alt: "langChainv0.3学习笔记初级篇"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=145600950
featuredImagePreview: https://bing.ee123.net/img/rand?artid=145600950
cover: https://bing.ee123.net/img/rand?artid=145600950
image: https://bing.ee123.net/img/rand?artid=145600950
img: https://bing.ee123.net/img/rand?artid=145600950
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     langChainv0.3学习笔记（初级篇）
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-tomorrow-night" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     LangChain自0.1版本发布以来，已经历了显著的进化，特别是向AI时代的适应性提升。在0.1版本中，LangChain主要聚焦于提供基本的链式操作和工具集成，帮助开发者构建简单的语言模型应用。该版本适用于处理简单任务，但在应对更复杂的AI需求时显得有些局限。
    </p>
    <p>
     相比之下，LangChain 0.3版本展现了更为全面和强大的功能，进一步优化了其模块化架构，增强了与现代AI工具和框架的兼容性。这一版本加入了更多针对AI时代的特性，包括增强的多模态支持、自动化的推理链处理、以及更强的上下文管理能力。LangChain 0.3不仅扩展了与大型语言模型（LLM）的协作功能，还引入了对更多外部工具和数据库的原生支持，使得构建复杂的RAG（Retrieval-Augmented Generation）系统变得更加简便。
    </p>
    <p>
     总的来说，LangChain 0.3版本不仅提升了功能的深度，还大幅优化了开发者的使用体验，为AI应用的快速迭代和部署提供了更多便利，是AI应用开发者在实际项目中的理想选择。
    </p>
    <p>
     本篇文章是我在参考官网文档学习时，按照自认为适合新人入门的排列顺序写成的，希望能帮到大家！
    </p>
    <p>
    </p>
    <p>
    </p>
    <h2>
     <a id="LangChain__10">
     </a>
     LangChain 介绍
    </h2>
    <p>
     LangChain 是一个
     <strong>
      用于开发由大型语言模型 (LLMs) 驱动的应用程序的框架
     </strong>
     。
    </p>
    <p>
     LangChain 简化了 LLM 应用程序生命周期的每个阶段：
    </p>
    <ul>
     <li>
      开发阶段：使用 LangChain 的开源 构建模块、组件 和 第三方集成 构建您的应用程序。 使用 LangGraph 构建具有一流流式处理和人机协作支持的有状态代理。
     </li>
     <li>
      生产化阶段：使用 LangSmith 检查、监控和评估您的链，以便您可以持续优化并自信地部署。
     </li>
     <li>
      部署阶段：将您的 LangGraph 应用程序转变为生产就绪的 API 和助手，使用 LangGraph Cloud。
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/4d27375c26dc4418b372f3ceafbcb01f.png"/>
     </li>
    </ul>
    <p>
     具体来说，该框架由以下开源库组成：
    </p>
    <ul>
     <li>
      langchain-core: 基础抽象和LangChain表达式 (LCEL)。
     </li>
     <li>
      langchain-community: 第三方集成。
     </li>
     <li>
      合作伙伴库（例如 langchain-openai、langchain-anthropic 等）：一些集成已进一步拆分为自己的轻量级库，仅依赖于 langchain-core。
     </li>
     <li>
      langchain: 组成应用程序认知架构的链、代理和检索策略。
     </li>
     <li>
      LangGraph: 通过将步骤建模为图中的边和节点，构建强大且有状态的多参与者应用程序。与LangChain无缝集成，但也可以单独使用。
     </li>
     <li>
      LangServe: 将LangChain链部署为REST API。
     </li>
     <li>
      LangSmith: 一个开发者平台，让您调试、测试、评估和监控LLM应用程序。
     </li>
    </ul>
    <p>
     从官网的架构图可以清楚的看到langChain生态的完善，langChain已经从一个简单的LLM Agent库变成了一个大而全的开发平台。
    </p>
    <p>
     同时，langChain社区庞大而活跃，引入了许许多多新特性和新集成，例如，Deepseek爆火的同时，langChain已经有了与deepseek交互的库：langChain-deepseek。
    </p>
    <p>
     再回头去看看LangChain 框架的两个主要的价值主张：
    </p>
    <ul>
     <li>
      组件：LangChain 为处理语言模型所需的组件提供模块化的抽象。LangChain 还为所有这些抽象提供了实现的集合。
     </li>
     <li>
      用例特定链：链可以被看作是以特定方式组装这些组件，以便最好地完成特定用例。这旨在成为一个更高级别的接口，使人们可以轻松地开始特定的用例。这些链也旨在可定制化。
     </li>
    </ul>
    <p>
     毫无疑问，langChain做到了！我们的应用可以看作一条链条，这个链是由多个模块串联而成，对于每一个模块你随时可以替换成另一个模块。
    </p>
    <h2>
     <a id="langChain_40">
     </a>
     安装langChain
    </h2>
    <p>
     要安装主要的 langchain 包，请运行：
    </p>
    <pre><code class="prism language-c">pip install langchain
</code></pre>
    <p>
     这个包是 LangChain 的底层代码， 但 LangChain 的大部分价值在于与各种大模型供应商、数据存储等的集成。
    </p>
    <h3>
     <a id="_48">
     </a>
     生态包
    </h3>
    <p>
     除了 langsmith SDK，LangChain 生态系统中的所有包都依赖于 langchain-core，它包含其他包使用的基础类和抽象。 下面的依赖图显示了不同包之间的关系。 一个有向箭头表示源包依赖于目标包：
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/b5d7a3a157f94a4a89c775a6e448889f.png">
      <br/>
      <strong>
       LangChain核心
      </strong>
      ：langchain-core 包包含其余 LangChain 生态系统使用的基础抽象，以及 LangChain 表达式语言。它由 langchain 自动安装，但也可以单独使用。安装命令：
      <code>
       pip install langchain-core
      </code>
     </img>
    </p>
    <p>
     <strong>
      集成包
     </strong>
     ：如 OpenAI 和 Anthropic，有自己的包。 任何需要自己包的集成将在
     <a href="https://www.langchain.com.cn/docs/integrations/platforms/" rel="nofollow">
      集成文档
     </a>
     中进行说明。 可以在
     <a href="https://api.python.langchain.com/en/latest/langchain_api_reference.html" rel="nofollow">
      API 参考
     </a>
     的 “第三方库” 下拉菜单中查看所有集成包的列表。 要安装其中一个，可以运行：
     <code>
      pip install langchain-openai
     </code>
    </p>
    <p>
     任何尚未拆分为自己包的集成将保留在 langchain-community 包中。安装方法：
     <code>
      pip install langchain-community
     </code>
    </p>
    <p>
     <strong>
      LangGraph
     </strong>
     ：langgraph 是一个用于构建有状态的多参与者应用程序的库，支持大型语言模型（LLMs）。它与 LangChain 无缝集成，但也可以单独使用。 安装方式：
     <code>
      pip install langgraph
     </code>
    </p>
    <p>
     …
    </p>
    <p>
     注：从 0.3 版本开始，LangChain 在内部使用 Pydantic 2，用户应安装 Pydantic 2，并建议避免在 LangChain API 中使用 Pydantic 2 的 pydantic.v1 命名空间！
    </p>
    <h2>
     <a id="ChatModelLLM_65">
     </a>
     ChatModel和LLM组件简介
    </h2>
    <p>
     ChatModel：聊天模型是使用一系列
     <strong>
      消息
     </strong>
     作为输入并返回聊天消息作为输出的语言模型（与使用纯文本相对）， 这些通常是较新的模型（
     <strong>
      较旧的模型通常是LLMs
     </strong>
     ）。
    </p>
    <p>
     聊天模型支持为对话消息分配不同的角色，有助于区分来自AI、用户和系统消息等指令的消息。尽管底层模型是消息输入、消息输出，但LangChain的包装器也允许这些模型接受字符串作为输入。这意味着可以轻松地使用聊天模型替代LLMs。
    </p>
    <p>
     当字符串作为输入传入时，它会被转换为HumanMessage，然后传递给底层模型。
    </p>
    <p>
     <strong>
      LangChain不托管任何聊天模型，而是依赖于第三方集成。
     </strong>
    </p>
    <p>
     在构建ChatModels时，有一些标准化参数：
    </p>
    <ul>
     <li>
      model: 模型名称
     </li>
     <li>
      temperature: 采样温度
     </li>
     <li>
      timeout: 请求超时
     </li>
     <li>
      max_tokens: 生成的最大令牌数
     </li>
     <li>
      stop: 默认停止序列
     </li>
     <li>
      max_retries: 请求重试的最大次数
     </li>
     <li>
      api_key: 大模型供应商的API密钥
     </li>
     <li>
      base_url: 发送请求的端点
     </li>
    </ul>
    <p>
     注意：
    </p>
    <ul>
     <li>
      标准参数仅适用于公开具有预期功能的参数的大模型供应商。例如，一些大模型供应商不公开最大输出令牌的配置，因此在这些大模型供应商上无法支持max_tokens。
     </li>
     <li>
      标准参数目前仅在具有自己集成包的集成上强制执行（例如 langchain-openai、langchain-anthropic 等），在 langchain-community 中的模型上不强制执行。
     </li>
    </ul>
    <p>
     多模态性：一些
     <strong>
      聊天模型
     </strong>
     是多模态的，接受图像、音频甚至视频作为输入。这些模型仍然较为少见，这意味着大模型供应商尚未在定义API的“最佳”方式上达成标准。多模态输出则更为少见。因此，langChain保持了多模态抽象的相对轻量，并计划在该领域成熟时进一步巩固多模态API和交互模式。
    </p>
    <p>
     在LangChain中，大多数支持多模态输入的聊天模型也接受OpenAI内容块格式的这些值。目前这仅限于图像输入。对于支持视频和其他字节输入的模型，如Gemini，API也支持原生的、特定于模型的表示。
    </p>
    <p>
     LLM：将字符串作为输入并返回字符串的语言模型（这些通常是较旧的模型）。
    </p>
    <p>
     <strong>
      纯文本输入/输出的大型语言模型往往较旧或较低级。即使对于非聊天用例，许多新的流行模型也最好用作聊天模型。
     </strong>
    </p>
    <p>
     尽管底层模型是字符串输入、字符串输出，但LangChain的包装器也允许这些模型接受消息作为输入。 这使它们具有与聊天模型相同的接口。 当消息作为输入传入时，它们将在底层被格式化为字符串，然后传递给底层模型。
    </p>
    <p>
     LangChain不托管任何大型语言模型，而是依赖于第三方集成。
    </p>
    <p>
     我们都知道，在LangChain v0.1版本中，ChatModel和LLM（大语言模型）被区分开来，是因为最初的设计中，这两者是为了解决不同的任务和使用场景：
    </p>
    <ul>
     <li>
      LLM（如GPT-3或其他基础语言模型）主要用于直接生成文本，比较传统的语言模型应用场景。
     </li>
     <li>
      ChatModel是为适应更复杂的对话任务设计的，特别是在对话上下文保持（例如多轮对话）和用户交互中的情境管理。
     </li>
    </ul>
    <p>
     langChain v0.1将模型分为ChatModel和LLM，而在v0.3则直接建议一律使用聊天模型：
    </p>
    <ul>
     <li>
      <p>
       统一接口：随着LangChain的迭代，团队意识到无论是
       <code>
        处理单轮任务（如问题回答）还是多轮对话
       </code>
       ，
       <strong>
        底层的模型架构和接口越来越相似
       </strong>
       ，ChatModel可以灵活适应两种情况。这种统一设计简化了开发者的使用体验，不需要选择不同的模型类型来处理不同的任务。
      </p>
     </li>
     <li>
      <p>
       增强对话管理能力：即使是单次任务，ChatModel的设计仍然能够提供更好的上下文管理功能。通过ChatModel，开发者可以更加灵活地管理对话历史、上下文以及任务状态，而这在某些复杂的任务中，尤其是需要保持上下文的场景下非常有用。
      </p>
     </li>
     <li>
      <p>
       灵活扩展性：随着技术的发展，更多的应用场景可能需要更复杂的模型功能，比如强化对话生成的控制、定制化的消息处理、对话状态的追踪等。ChatModel的设计更适合应对这些需求。
      </p>
     </li>
     <li>
      <p>
       后续兼容性：未来，LangChain可能会增加更多与对话相关的功能（如自定义对话框架、任务引擎等），因此将所有模型统一为ChatModel可以更方便地进行扩展和维护。
      </p>
     </li>
    </ul>
    <p>
     <strong>
      因此，我们下文使用的模型都是满足ChatModel接口的聊天模型
     </strong>
     。
    </p>
    <h2>
     <a id="Message_119">
     </a>
     Message组件
    </h2>
    <p>
     一些模型将消息列表作为输入并返回一条消息。 消息有几种不同的类型。 所有消息都有 role、content 和 response_metadata 属性。
    </p>
    <p>
     role 描述了谁在说这条消息。标准角色是 ‘user’、‘assistant’、‘system’ 和 ‘tool’。 LangChain 为不同角色提供了不同的消息类。
    </p>
    <p>
     content 属性描述了消息的内容。 这可以是几种不同的东西：
    </p>
    <ul>
     <li>
      一个字符串（大多数模型处理这种类型的内容）
     </li>
     <li>
      一个字典列表（用于多模态输入，其中字典包含关于该输入类型和输入位置的信息）
     </li>
    </ul>
    <p>
     可选地，消息可以有一个 name 属性，用于区分具有相同角色的多个发言者。 例如，如果聊天历史中有两个用户，区分它们可能会很有用，但
     <strong>
      并不是所有模型都支持这一点
     </strong>
     。
    </p>
    <p>
     下面是角色对应的类型：
    </p>
    <ul>
     <li>
      <p>
       UserMessage：这表示角色为“用户”的消息。
      </p>
     </li>
     <li>
      <p>
       AIMessage：这表示角色为“助手”的消息。除了content属性，这些消息还有：
      </p>
      <ul>
       <li>
        <p>
         response_metadata：response_metadata属性包含有关响应的附加元数据。这里的数据通常是特定于每个大模型供应商的。 这里可能存储诸如日志概率和令牌使用等信息。
        </p>
       </li>
       <li>
        <p>
         tool_calls：这些表示语言模型调用工具的决策。它们作为AI消息输出的一部分包含在内。 可以通过 .tool_calls 属性从那里访问。该属性返回一个 ToolCall 的列表。ToolCall 是一个包含以下参数的字典：
        </p>
        <ul>
         <li>
          name: 应该被调用的工具的名称。
         </li>
         <li>
          args: 该工具的参数。
         </li>
         <li>
          id: 该工具调用的 id。
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li>
      <p>
       SystemMessage：这表示一个角色为 “system” 的消息，告诉模型如何行为，并不是每个大模型供应商都支持这个。
      </p>
     </li>
     <li>
      <p>
       ToolMessage：这表示一个角色为 “tool” 的消息，包含调用工具的结果。除了 role 和 content，该消息还有：
      </p>
      <ul>
       <li>
        一个 tool_call_id 字段，传达调用该工具以生成此结果的调用 id。
       </li>
       <li>
        一个 artifact 字段，可以用于传递工具执行的任意工件，这些工件有助于跟踪，但不应发送给模型。
        <br/>
        在大多数聊天模型中，ToolMessage 只能在包含已填充 tool_calls 字段的 AIMessage 之后出现在聊天历史中。
       </li>
      </ul>
     </li>
     <li>
      <p>
       （遗留）FunctionMessage：这是一种遗留消息类型，对应于 OpenAI 的遗留函数调用 API。应使用 ToolMessage 来对应更新后的工具调用 API。这表示函数调用的结果。除了 role 和 content，此消息还有一个 name 参数，用于传达调用以生成此结果的函数名称。
      </p>
     </li>
    </ul>
    <h3>
     <a id="_155">
     </a>
     修剪消息
    </h3>
    <p>
     所有模型都有有限的上下文窗口，这意味着它们可以作为输入的令牌数量是有限的。如果你有非常长的消息或一个累积了长消息历史的链/代理，您需要管理传递给模型的消息长度。
    </p>
    <p>
     trim_messages 工具提供了一些基本策略，用于将消息列表修剪为特定的令牌长度。
    </p>
    <p>
     假设我们在使用过程中积攒或导入了如下大量Message：
    </p>
    <pre><code class="prism language-c">messages <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token function">SystemMessage</span><span class="token punctuation">(</span><span class="token string">"you're a good assistant, you always respond with a joke."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">HumanMessage</span><span class="token punctuation">(</span><span class="token string">"i wonder why it's called langchain"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">AIMessage</span><span class="token punctuation">(</span>
        'Well<span class="token punctuation">,</span> I guess they thought <span class="token string">"WordRope"</span> and <span class="token string">"SentenceString"</span> just didn\<span class="token char">'t have the same ring to it!'</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">HumanMessage</span><span class="token punctuation">(</span><span class="token string">"and who is harrison chasing anyways"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">AIMessage</span><span class="token punctuation">(</span>
        <span class="token string">"Hmmm let me think.\n\nWhy, he's probably chasing after the last cup of coffee in the office!"</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">HumanMessage</span><span class="token punctuation">(</span><span class="token string">"what do you call a speechless parrot"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
</code></pre>
    <p>
     此时假设模型上下文允许的最大token量为45个token！
    </p>
    <p>
     要从下往上获取max_tokens 个token的信息，可以设置 strategy=“last”：
    </p>
    <pre><code class="prism language-c"><span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">pip</span> <span class="token expression">install <span class="token operator">-</span>U langchain<span class="token operator">-</span>openai</span></span>
from langchain_core<span class="token punctuation">.</span>messages <span class="token function">import</span> <span class="token punctuation">(</span>
    AIMessage<span class="token punctuation">,</span>
    HumanMessage<span class="token punctuation">,</span>
    SystemMessage<span class="token punctuation">,</span>
    trim_messages<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
from langchain_openai import ChatOpenAI

messages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>

<span class="token function">trim_messages</span><span class="token punctuation">(</span>
    messages<span class="token punctuation">,</span>
    max_tokens<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">,</span>
    strategy<span class="token operator">=</span><span class="token string">"last"</span><span class="token punctuation">,</span>
    token_counter<span class="token operator">=</span><span class="token function">ChatOpenAI</span><span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre>
    <p>
     可以看到，我们从下往上利用gpt-4o的tokenizer截取了45个token的消息：
    </p>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"Hmmm let me think.\n\nWhy, he's probably chasing after the last cup of coffee in the office!"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span>'what <span class="token keyword">do</span> you call a speechless parrot'<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     注：对于token_counter参数，我们可以传入一个函数或一个语言模型（
     <strong>
      因为语言模型有消息令牌计数方法
     </strong>
     ）。当你在修剪消息以适应特定模型的上下文窗口时，建议传入要适配的模型。
    </p>
    <p>
     如果我们想始终保留初始系统消息，可以指定 include_system=True：
    </p>
    <pre><code class="prism language-c"><span class="token function">trim_messages</span><span class="token punctuation">(</span>
    messages<span class="token punctuation">,</span>
    max_tokens<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">,</span>
    strategy<span class="token operator">=</span><span class="token string">"last"</span><span class="token punctuation">,</span>
    token_counter<span class="token operator">=</span><span class="token function">ChatOpenAI</span><span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    include_system<span class="token operator">=</span>True<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">SystemMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"you're a good assistant, you always respond with a joke."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span>'what <span class="token keyword">do</span> you call a speechless parrot'<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     如果我们想允许拆分消息的内容，可以指定 allow_partial=True：
    </p>
    <pre><code class="prism language-c"><span class="token function">trim_messages</span><span class="token punctuation">(</span>
    messages<span class="token punctuation">,</span>
    max_tokens<span class="token operator">=</span><span class="token number">56</span><span class="token punctuation">,</span> <span class="token comment">// 增大token数,否则体现不出来做了拆分</span>
    strategy<span class="token operator">=</span><span class="token string">"last"</span><span class="token punctuation">,</span>
    token_counter<span class="token operator">=</span><span class="token function">ChatOpenAI</span><span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    include_system<span class="token operator">=</span>True<span class="token punctuation">,</span>
    allow_partial<span class="token operator">=</span>True<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">SystemMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"you're a good assistant, you always respond with a joke."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"\nWhy, he's probably chasing after the last cup of coffee in the office!"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span>'what <span class="token keyword">do</span> you call a speechless parrot'<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     如果我们需要确保我们的第一条消息（不包括系统消息）始终是特定类型，可以指定 start_on：
    </p>
    <pre><code class="prism language-c"><span class="token function">trim_messages</span><span class="token punctuation">(</span>
    messages<span class="token punctuation">,</span>
    max_tokens<span class="token operator">=</span><span class="token number">60</span><span class="token punctuation">,</span>
    strategy<span class="token operator">=</span><span class="token string">"last"</span><span class="token punctuation">,</span>
    token_counter<span class="token operator">=</span><span class="token function">ChatOpenAI</span><span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    include_system<span class="token operator">=</span>True<span class="token punctuation">,</span>
    start_on<span class="token operator">=</span><span class="token string">"human"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">SystemMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"you're a good assistant, you always respond with a joke."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span>'what <span class="token keyword">do</span> you call a speechless parrot'<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     如果想从前往后获取max_tokens 个token的Message，可以通过指定 strategy=“first” ：
    </p>
    <pre><code class="prism language-c"><span class="token function">trim_messages</span><span class="token punctuation">(</span>
    messages<span class="token punctuation">,</span>
    max_tokens<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">,</span>
    strategy<span class="token operator">=</span><span class="token string">"first"</span><span class="token punctuation">,</span>
    token_counter<span class="token operator">=</span><span class="token function">ChatOpenAI</span><span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">SystemMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"you're a good assistant, you always respond with a joke."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"i wonder why it's called langchain"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <h4>
     <a id="_273">
     </a>
     编写自定义令牌计数器
    </h4>
    <p>
     前面说过，对于token_counter参数，我们
     <strong>
      可以传入一个函数或一个语言模型
     </strong>
     。我们现在来编写一个自定义令牌计数器函数，该函数接受消息列表并返回一个整数。
    </p>
    <pre><code class="prism language-c">from typing import List
from langchain_core<span class="token punctuation">.</span>messages <span class="token function">import</span> <span class="token punctuation">(</span>
    AIMessage<span class="token punctuation">,</span>
    HumanMessage<span class="token punctuation">,</span>
    SystemMessage<span class="token punctuation">,</span>
    trim_messages<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">pip</span> <span class="token expression">install tiktoken</span></span>
import tiktoken
from langchain_core<span class="token punctuation">.</span>messages import BaseMessage<span class="token punctuation">,</span> ToolMessage


def <span class="token function">str_token_counter</span><span class="token punctuation">(</span>text<span class="token operator">:</span> str<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> <span class="token keyword">int</span><span class="token operator">:</span>
    enc <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span><span class="token function">get_encoding</span><span class="token punctuation">(</span><span class="token string">"o200k_base"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token function">len</span><span class="token punctuation">(</span>enc<span class="token punctuation">.</span><span class="token function">encode</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>


def <span class="token function">tiktoken_counter</span><span class="token punctuation">(</span>messages<span class="token operator">:</span> List<span class="token punctuation">[</span>BaseMessage<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-&gt;</span> <span class="token keyword">int</span><span class="token operator">:</span>
    <span class="token string">""</span>"Approximately reproduce https<span class="token operator">:</span><span class="token comment">//github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb</span>

    For simplicity only supports str Message<span class="token punctuation">.</span>contents<span class="token punctuation">.</span>
    <span class="token string">""</span>"
    num_tokens <span class="token operator">=</span> <span class="token number">3</span>  # every reply is primed with <span class="token operator">&lt;</span><span class="token operator">|</span>start<span class="token operator">|</span><span class="token operator">&gt;</span>assistant<span class="token operator">&lt;</span><span class="token operator">|</span>message<span class="token operator">|</span><span class="token operator">&gt;</span>
    tokens_per_message <span class="token operator">=</span> <span class="token number">3</span>
    tokens_per_name <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">for</span> msg in messages<span class="token operator">:</span>
        <span class="token keyword">if</span> <span class="token function">isinstance</span><span class="token punctuation">(</span>msg<span class="token punctuation">,</span> HumanMessage<span class="token punctuation">)</span><span class="token operator">:</span>
            role <span class="token operator">=</span> <span class="token string">"user"</span>
        elif <span class="token function">isinstance</span><span class="token punctuation">(</span>msg<span class="token punctuation">,</span> AIMessage<span class="token punctuation">)</span><span class="token operator">:</span>
            role <span class="token operator">=</span> <span class="token string">"assistant"</span>
        elif <span class="token function">isinstance</span><span class="token punctuation">(</span>msg<span class="token punctuation">,</span> ToolMessage<span class="token punctuation">)</span><span class="token operator">:</span>
            role <span class="token operator">=</span> <span class="token string">"tool"</span>
        elif <span class="token function">isinstance</span><span class="token punctuation">(</span>msg<span class="token punctuation">,</span> SystemMessage<span class="token punctuation">)</span><span class="token operator">:</span>
            role <span class="token operator">=</span> <span class="token string">"system"</span>
        <span class="token keyword">else</span><span class="token operator">:</span>
            raise <span class="token function">ValueError</span><span class="token punctuation">(</span>f<span class="token string">"Unsupported messages type {msg.__class__}"</span><span class="token punctuation">)</span>
        num_tokens <span class="token operator">+=</span> <span class="token punctuation">(</span>
            tokens_per_message
            <span class="token operator">+</span> <span class="token function">str_token_counter</span><span class="token punctuation">(</span>role<span class="token punctuation">)</span>
            <span class="token operator">+</span> <span class="token function">str_token_counter</span><span class="token punctuation">(</span>msg<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">if</span> msg<span class="token punctuation">.</span>name<span class="token operator">:</span>
            num_tokens <span class="token operator">+=</span> tokens_per_name <span class="token operator">+</span> <span class="token function">str_token_counter</span><span class="token punctuation">(</span>msg<span class="token punctuation">.</span>name<span class="token punctuation">)</span>
    <span class="token keyword">return</span> num_tokens


<span class="token function">trim_messages</span><span class="token punctuation">(</span>
    messages<span class="token punctuation">,</span>
    max_tokens<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">,</span>
    strategy<span class="token operator">=</span><span class="token string">"last"</span><span class="token punctuation">,</span>
    token_counter<span class="token operator">=</span>tiktoken_counter<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre>
    <ol>
     <li>
      <p>
       <strong>
        <code>
         num_tokens = 3
        </code>
       </strong>
       ：
       <br/>
       这个值的含义是每个回复都由一个起始标记
       <code>
        &lt;|start|&gt;assistant&lt;|message|&gt;
       </code>
       开始。这通常是模型的初始状态或开头的标记，它告诉模型回复即将开始。每个消息都会有这些额外的token，初始化为3是为了模拟这个标记的占用。
      </p>
     </li>
     <li>
      <p>
       <strong>
        <code>
         tokens_per_message = 3
        </code>
       </strong>
       ：
       <br/>
       每个消息（不论是用户、助手、工具还是系统消息）都需要额外的token，这三个token通常是消息头部的结构性标记，像是“&lt;|message|&gt;”等。这个初始化值代表每个消息可能需要的基础token数。比如，它可以是对话中的每一条消息被格式化时需要的最小token数。
      </p>
     </li>
     <li>
      <p>
       <strong>
        <code>
         tokens_per_name = 1
        </code>
       </strong>
       ：
       <br/>
       这个值表示如果消息中包含一个
       <code>
        name
       </code>
       字段（例如在某些工具消息中可能会有），那么这个
       <code>
        name
       </code>
       字段本身也会占用一定数量的token。通常情况下，name字段只会占用一个token，因为它是一个单一的标识符。
      </p>
     </li>
    </ol>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"Hmmm let me think.\n\nWhy, he's probably chasing after the last cup of coffee in the office!"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span>'what <span class="token keyword">do</span> you call a speechless parrot'<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <h4>
     <a id="_344">
     </a>
     链接
    </h4>
    <p>
     trim_messages 可以以命令式（上文）或声明式使用，使其易于与链中的其他组件组合：
    </p>
    <pre><code class="prism language-c">llm <span class="token operator">=</span> <span class="token function">ChatOpenAI</span><span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">)</span>

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Notice we don't pass in messages<span class="token punctuation">.</span> This creates</span></span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">a</span> <span class="token expression">RunnableLambda that takes messages as input</span></span>
trimmer <span class="token operator">=</span> <span class="token function">trim_messages</span><span class="token punctuation">(</span>
    max_tokens<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">,</span>
    strategy<span class="token operator">=</span><span class="token string">"last"</span><span class="token punctuation">,</span>
    token_counter<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    include_system<span class="token operator">=</span>True<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

chain <span class="token operator">=</span> trimmer <span class="token operator">|</span> llm
chain<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'A: A "Polly-gone"!'</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'token_usage'</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'completion_tokens'</span><span class="token operator">:</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token char">'prompt_tokens'</span><span class="token operator">:</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token char">'total_tokens'</span><span class="token operator">:</span> <span class="token number">41</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token char">'model_name'</span><span class="token operator">:</span> <span class="token char">'gpt-4o-2024-05-13'</span><span class="token punctuation">,</span> <span class="token char">'system_fingerprint'</span><span class="token operator">:</span> <span class="token char">'fp_66b29dffce'</span><span class="token punctuation">,</span> <span class="token char">'finish_reason'</span><span class="token operator">:</span> <span class="token char">'stop'</span><span class="token punctuation">,</span> <span class="token char">'logprobs'</span><span class="token operator">:</span> None<span class="token punctuation">}</span><span class="token punctuation">,</span> id<span class="token operator">=</span>'run<span class="token operator">-</span><span class="token number">83e96</span>ddf<span class="token operator">-</span>bcaa<span class="token operator">-</span><span class="token number">4f</span><span class="token number">63</span><span class="token operator">-</span><span class="token number">824</span>c<span class="token operator">-</span><span class="token number">98</span>b0f8a0d474<span class="token operator">-</span><span class="token number">0</span><span class="token char">', usage_metadata={'</span>input_tokens<span class="token char">': 32, '</span>output_tokens<span class="token char">': 9, '</span>total_tokens'<span class="token operator">:</span> <span class="token number">41</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     仅从修剪器来看，我们可以看到它是一个可运行的对象，可以像所有可运行对象一样被调用：
    </p>
    <pre><code class="prism language-c">trimmer<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">SystemMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"you're a good assistant, you always respond with a joke."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span>'what <span class="token keyword">do</span> you call a speechless parrot'<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <h4>
     <a id="_376">
     </a>
     使用聊天消息历史
    </h4>
    <p>
     修剪消息在处理聊天历史时特别有用，因为聊天历史可能会变得非常长：
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>chat_history import InMemoryChatMessageHistory
from langchain_core<span class="token punctuation">.</span>runnables<span class="token punctuation">.</span>history import RunnableWithMessageHistory

chat_history <span class="token operator">=</span> <span class="token function">InMemoryChatMessageHistory</span><span class="token punctuation">(</span>messages<span class="token operator">=</span>messages<span class="token punctuation">[</span><span class="token operator">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


def <span class="token function">dummy_get_session_history</span><span class="token punctuation">(</span>session_id<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token keyword">if</span> session_id <span class="token operator">!=</span> <span class="token string">"1"</span><span class="token operator">:</span>
        <span class="token keyword">return</span> <span class="token function">InMemoryChatMessageHistory</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> chat_history


llm <span class="token operator">=</span> <span class="token function">ChatOpenAI</span><span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">)</span>

trimmer <span class="token operator">=</span> <span class="token function">trim_messages</span><span class="token punctuation">(</span>
    max_tokens<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">,</span>
    strategy<span class="token operator">=</span><span class="token string">"last"</span><span class="token punctuation">,</span>
    token_counter<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    include_system<span class="token operator">=</span>True<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

chain <span class="token operator">=</span> trimmer <span class="token operator">|</span> llm
chain_with_history <span class="token operator">=</span> <span class="token function">RunnableWithMessageHistory</span><span class="token punctuation">(</span>chain<span class="token punctuation">,</span> dummy_get_session_history<span class="token punctuation">)</span>
chain_with_history<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>
    <span class="token punctuation">[</span><span class="token function">HumanMessage</span><span class="token punctuation">(</span><span class="token string">"what do you call a speechless parrot"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    config<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">"configurable"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"session_id"</span><span class="token operator">:</span> <span class="token string">"1"</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre>
    <p>
     在消息传递给模型之前，它们被修剪为仅包含系统消息和最后一条人类消息！
    </p>
    <pre><code class="prism language-c"><span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'A "polly-no-wanna-cracker"!'</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'token_usage'</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'completion_tokens'</span><span class="token operator">:</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token char">'prompt_tokens'</span><span class="token operator">:</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token char">'total_tokens'</span><span class="token operator">:</span> <span class="token number">42</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token char">'model_name'</span><span class="token operator">:</span> <span class="token char">'gpt-4o-2024-05-13'</span><span class="token punctuation">,</span> <span class="token char">'system_fingerprint'</span><span class="token operator">:</span> <span class="token char">'fp_5bf7397cd3'</span><span class="token punctuation">,</span> <span class="token char">'finish_reason'</span><span class="token operator">:</span> <span class="token char">'stop'</span><span class="token punctuation">,</span> <span class="token char">'logprobs'</span><span class="token operator">:</span> None<span class="token punctuation">}</span><span class="token punctuation">,</span> id<span class="token operator">=</span>'run<span class="token operator">-</span><span class="token number">054</span>dd309<span class="token operator">-</span><span class="token number">3497</span><span class="token operator">-</span><span class="token number">4e7</span>b<span class="token operator">-</span>b22a<span class="token operator">-</span>c1859f11d32e<span class="token operator">-</span><span class="token number">0</span><span class="token char">', usage_metadata={'</span>input_tokens<span class="token char">': 32, '</span>output_tokens<span class="token char">': 10, '</span>total_tokens'<span class="token operator">:</span> <span class="token number">42</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="_413">
     </a>
     过滤消息
    </h3>
    <p>
     在更复杂的链和代理中，我们可能会通过消息列表来跟踪状态。这个列表可能会开始积累来自多个不同模型、发言者、子链等的消息，我们可能只想将这个完整消息列表的子集传递给链/代理中的每个模型调用。
    </p>
    <p>
     filter_messages 工具使按
     <strong>
      类型、ID 或名称过滤消息
     </strong>
     变得简单。
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>messages <span class="token function">import</span> <span class="token punctuation">(</span>
    AIMessage<span class="token punctuation">,</span>
    HumanMessage<span class="token punctuation">,</span>
    SystemMessage<span class="token punctuation">,</span>
    filter_messages<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

messages <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token function">SystemMessage</span><span class="token punctuation">(</span><span class="token string">"you are a good assistant"</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token string">"1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">HumanMessage</span><span class="token punctuation">(</span><span class="token string">"example input"</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token string">"2"</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"example_user"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">AIMessage</span><span class="token punctuation">(</span><span class="token string">"example output"</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token string">"3"</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"example_assistant"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">HumanMessage</span><span class="token punctuation">(</span><span class="token string">"real input"</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token string">"4"</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"bob"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">AIMessage</span><span class="token punctuation">(</span><span class="token string">"real output"</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token string">"5"</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"alice"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

<span class="token function">filter_messages</span><span class="token punctuation">(</span>messages<span class="token punctuation">,</span> include_types<span class="token operator">=</span><span class="token string">"human"</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'example input'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token char">'example_user'</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token char">'2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'real input'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token char">'bob'</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token char">'4'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     按照name过滤：
    </p>
    <pre><code class="prism language-c"><span class="token function">filter_messages</span><span class="token punctuation">(</span>messages<span class="token punctuation">,</span> exclude_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"example_user"</span><span class="token punctuation">,</span> <span class="token string">"example_assistant"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">SystemMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'you are a good assistant'</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token char">'1'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'real input'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token char">'bob'</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token char">'4'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'real output'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token char">'alice'</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token char">'5'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     按照ID过滤：
    </p>
    <pre><code class="prism language-c"><span class="token function">filter_messages</span><span class="token punctuation">(</span>messages<span class="token punctuation">,</span> include_types<span class="token operator">=</span><span class="token punctuation">[</span>HumanMessage<span class="token punctuation">,</span> AIMessage<span class="token punctuation">]</span><span class="token punctuation">,</span> exclude_ids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"3"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'example input'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token char">'example_user'</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token char">'2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'real input'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token char">'bob'</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token char">'4'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'real output'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token char">'alice'</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token char">'5'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <h4>
     <a id="_459">
     </a>
     链接
    </h4>
    <p>
     filter_messages 可以以命令式（如上所示）或声明式使用，使其易于与链中的其他组件组合:
    </p>
    <pre><code class="prism language-c"><span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">pip</span> <span class="token expression">install <span class="token operator">-</span>U langchain<span class="token operator">-</span>anthropic</span></span>
from langchain_anthropic import ChatAnthropic

llm <span class="token operator">=</span> <span class="token function">ChatAnthropic</span><span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"claude-3-sonnet-20240229"</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Notice we don't pass in messages<span class="token punctuation">.</span> This creates</span></span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">a</span> <span class="token expression">RunnableLambda that takes messages as input</span></span>
filter_ <span class="token operator">=</span> <span class="token function">filter_messages</span><span class="token punctuation">(</span>exclude_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"example_user"</span><span class="token punctuation">,</span> <span class="token string">"example_assistant"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
chain <span class="token operator">=</span> filter_ <span class="token operator">|</span> llm
chain<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'id'</span><span class="token operator">:</span> <span class="token char">'msg_01Wz7gBHahAwkZ1KCBNtXmwA'</span><span class="token punctuation">,</span> <span class="token char">'model'</span><span class="token operator">:</span> <span class="token char">'claude-3-sonnet-20240229'</span><span class="token punctuation">,</span> <span class="token char">'stop_reason'</span><span class="token operator">:</span> <span class="token char">'end_turn'</span><span class="token punctuation">,</span> <span class="token char">'stop_sequence'</span><span class="token operator">:</span> None<span class="token punctuation">,</span> <span class="token char">'usage'</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'input_tokens'</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token char">'output_tokens'</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span> id<span class="token operator">=</span>'run<span class="token operator">-</span>b5d8a3fe<span class="token operator">-</span><span class="token number">004f</span><span class="token operator">-</span><span class="token number">4502</span><span class="token operator">-</span>a071<span class="token operator">-</span>a6c025031827<span class="token operator">-</span><span class="token number">0</span><span class="token char">', usage_metadata={'</span>input_tokens<span class="token char">': 16, '</span>output_tokens<span class="token char">': 3, '</span>total_tokens'<span class="token operator">:</span> <span class="token number">19</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     仅查看 filter_，我们可以看到它是一个可运行对象，可以像所有可运行对象一样被调用:
    </p>
    <pre><code class="prism language-c">filter_<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>messages<span class="token punctuation">)</span>

<span class="token punctuation">[</span><span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'real input'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token char">'bob'</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token char">'4'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'real output'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token char">'alice'</span><span class="token punctuation">,</span> id<span class="token operator">=</span><span class="token char">'5'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <h3>
     <a id="_485">
     </a>
     合并相同类型的连续消息
    </h3>
    <p>
     某些模型不支持传递相同类型的连续消息（即相同消息类型的“运行”）。
    </p>
    <p>
     merge_message_runs 工具使合并相同类型的连续消息变得简单。
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>messages <span class="token function">import</span> <span class="token punctuation">(</span>
    AIMessage<span class="token punctuation">,</span>
    HumanMessage<span class="token punctuation">,</span>
    SystemMessage<span class="token punctuation">,</span>
    merge_message_runs<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

messages <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token function">SystemMessage</span><span class="token punctuation">(</span><span class="token string">"you're a good assistant."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">SystemMessage</span><span class="token punctuation">(</span><span class="token string">"you always respond with a joke."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">HumanMessage</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"type"</span><span class="token operator">:</span> <span class="token string">"text"</span><span class="token punctuation">,</span> <span class="token string">"text"</span><span class="token operator">:</span> <span class="token string">"i wonder why it's called langchain"</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">HumanMessage</span><span class="token punctuation">(</span><span class="token string">"and who is harrison chasing anyways"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">AIMessage</span><span class="token punctuation">(</span>
        'Well<span class="token punctuation">,</span> I guess they thought <span class="token string">"WordRope"</span> and <span class="token string">"SentenceString"</span> just didn\<span class="token char">'t have the same ring to it!'</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">AIMessage</span><span class="token punctuation">(</span><span class="token string">"Why, he's probably chasing after the last cup of coffee in the office!"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

merged <span class="token operator">=</span> <span class="token function">merge_message_runs</span><span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"\n\n"</span><span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token function">repr</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x in merged<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token function">SystemMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"you're a good assistant.\nyou always respond with a joke."</span><span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token char">'type'</span><span class="token operator">:</span> <span class="token char">'text'</span><span class="token punctuation">,</span> <span class="token char">'text'</span><span class="token operator">:</span> <span class="token string">"i wonder why it's called langchain"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> 'and who is harrison chasing anyways'<span class="token punctuation">]</span><span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span>'Well<span class="token punctuation">,</span> I guess they thought <span class="token string">"WordRope"</span> and <span class="token string">"SentenceString"</span> just didn\'t have the same ring to it<span class="token operator">!</span>\nWhy<span class="token punctuation">,</span> he\'s probably chasing after the last cup of coffee in the office<span class="token operator">!</span>'<span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     请注意，如果要合并的消息内容是一个内容块的列表，则合并后的消息将包含一个内容块的列表。如果要合并的两个消息都有字符串内容，则这些内容将用换行符连接。
    </p>
    <h4>
     <a id="_522">
     </a>
     链接
    </h4>
    <p>
     merge_message_runs 可以以命令式（如上所示）或声明式使用，使其易于与链中的其他组件组合：
    </p>
    <pre><code class="prism language-c">from langchain_anthropic import ChatAnthropic
from langchain_core<span class="token punctuation">.</span>messages <span class="token function">import</span> <span class="token punctuation">(</span>
    AIMessage<span class="token punctuation">,</span>
    HumanMessage<span class="token punctuation">,</span>
    SystemMessage<span class="token punctuation">,</span>
    merge_message_runs<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

llm <span class="token operator">=</span> <span class="token function">ChatAnthropic</span><span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"claude-3-sonnet-20240229"</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Notice we don't pass in messages<span class="token punctuation">.</span> This creates</span></span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">a</span> <span class="token expression">RunnableLambda that takes messages as input</span></span>
merger <span class="token operator">=</span> <span class="token function">merge_message_runs</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
chain <span class="token operator">=</span> merger <span class="token operator">|</span> llm
chain<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'id'</span><span class="token operator">:</span> <span class="token char">'msg_01KNGUMTuzBVfwNouLDpUMwf'</span><span class="token punctuation">,</span> <span class="token char">'model'</span><span class="token operator">:</span> <span class="token char">'claude-3-sonnet-20240229'</span><span class="token punctuation">,</span> <span class="token char">'stop_reason'</span><span class="token operator">:</span> <span class="token char">'end_turn'</span><span class="token punctuation">,</span> <span class="token char">'stop_sequence'</span><span class="token operator">:</span> None<span class="token punctuation">,</span> <span class="token char">'usage'</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'input_tokens'</span><span class="token operator">:</span> <span class="token number">84</span><span class="token punctuation">,</span> <span class="token char">'output_tokens'</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span> id<span class="token operator">=</span>'run<span class="token operator">-</span>b908b198<span class="token operator">-</span><span class="token number">9</span>c24<span class="token operator">-</span><span class="token number">450</span>b<span class="token operator">-</span><span class="token number">9749</span><span class="token operator">-</span><span class="token number">9</span>d4a8182937b<span class="token operator">-</span><span class="token number">0</span><span class="token char">', usage_metadata={'</span>input_tokens<span class="token char">': 84, '</span>output_tokens<span class="token char">': 3, '</span>total_tokens'<span class="token operator">:</span> <span class="token number">87</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     仅查看合并器，我们可以看到它是一个可运行对象，可以像所有可运行对象一样被调用：
    </p>
    <pre><code class="prism language-c">merger<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">SystemMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"you're a good assistant.\nyou always respond with a joke."</span><span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token char">'type'</span><span class="token operator">:</span> <span class="token char">'text'</span><span class="token punctuation">,</span> <span class="token char">'text'</span><span class="token operator">:</span> <span class="token string">"i wonder why it's called langchain"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> 'and who is harrison chasing anyways'<span class="token punctuation">]</span><span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span>'Well<span class="token punctuation">,</span> I guess they thought <span class="token string">"WordRope"</span> and <span class="token string">"SentenceString"</span> just didn\'t have the same ring to it<span class="token operator">!</span>\nWhy<span class="token punctuation">,</span> he\'s probably chasing after the last cup of coffee in the office<span class="token operator">!</span>'<span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     可以注意到将merger追加到链中后，并没有显式传入message！这是因为，LangChain 中的一种抽象组件（例如 merger 或 llm）通常是一个“可运行的”对象（Runnable），这些对象能够自动处理传入的数据。
    </p>
    <p>
     也就是说，当你调用 chain.invoke(messages) 时：messages 会首先流经 merger（合并消息）。然后，合并后的消息会被传递给 llm（模型处理）。
    </p>
    <p>
     merge_message_runs 也可以放在提示之后：
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>prompts import ChatPromptTemplate

prompt <span class="token operator">=</span> <span class="token function">ChatPromptTemplate</span><span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
        <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You're great a {skill}"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You're also great at explaining things"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"human"</span><span class="token punctuation">,</span> <span class="token string">"{query}"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span>
chain <span class="token operator">=</span> prompt <span class="token operator">|</span> merger <span class="token operator">|</span> llm
chain<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"skill"</span><span class="token operator">:</span> <span class="token string">"math"</span><span class="token punctuation">,</span> <span class="token string">"query"</span><span class="token operator">:</span> <span class="token string">"what's the definition of a convergent series"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span>'A convergent series is an infinite series whose partial sums approach a finite value as more terms are added<span class="token punctuation">.</span> In other words<span class="token punctuation">,</span> the sequence of partial sums has a limit<span class="token punctuation">.</span>\n\nMore formally<span class="token punctuation">,</span> an infinite series Σ <span class="token function">an</span> <span class="token punctuation">(</span>where an are the terms of the series<span class="token punctuation">)</span> is said to be convergent <span class="token keyword">if</span> the sequence of partial sums<span class="token operator">:</span>\n\nS1 <span class="token operator">=</span> a1\nS2 <span class="token operator">=</span> a1 <span class="token operator">+</span> a2  \nS3 <span class="token operator">=</span> a1 <span class="token operator">+</span> a2 <span class="token operator">+</span> a3\n<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>\nSn <span class="token operator">=</span> a1 <span class="token operator">+</span> a2 <span class="token operator">+</span> a3 <span class="token operator">+</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token operator">+</span> an\n<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>\n\nconverges to some finite number S as n goes to infinity<span class="token punctuation">.</span> We write<span class="token operator">:</span>\n\nlim n→∞ Sn <span class="token operator">=</span> S\n\nThe finite number S is called the sum of the convergent infinite series<span class="token punctuation">.</span>\n\nIf the sequence of partial sums does not approach any finite limit<span class="token punctuation">,</span> the infinite series is said to be divergent<span class="token punctuation">.</span>\n\nSome key properties<span class="token operator">:</span>\n<span class="token operator">-</span> A series converges <span class="token keyword">if</span> and only <span class="token keyword">if</span> the sequence of its partial sums is a Cauchy sequence<span class="token punctuation">.</span>\n<span class="token operator">-</span> Absolute<span class="token operator">/</span>conditional convergence criteria help determine <span class="token keyword">if</span> a given series converges<span class="token punctuation">.</span>\n<span class="token operator">-</span> Convergent series have many important applications in mathematics<span class="token punctuation">,</span> physics<span class="token punctuation">,</span> engineering etc<span class="token punctuation">.</span>'<span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'id'</span><span class="token operator">:</span> <span class="token char">'msg_01MfV6y2hep7ZNvDz24A36U4'</span><span class="token punctuation">,</span> <span class="token char">'model'</span><span class="token operator">:</span> <span class="token char">'claude-3-sonnet-20240229'</span><span class="token punctuation">,</span> <span class="token char">'stop_reason'</span><span class="token operator">:</span> <span class="token char">'end_turn'</span><span class="token punctuation">,</span> <span class="token char">'stop_sequence'</span><span class="token operator">:</span> None<span class="token punctuation">,</span> <span class="token char">'usage'</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'input_tokens'</span><span class="token operator">:</span> <span class="token number">29</span><span class="token punctuation">,</span> <span class="token char">'output_tokens'</span><span class="token operator">:</span> <span class="token number">267</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span> id<span class="token operator">=</span>'run<span class="token operator">-</span><span class="token number">9</span>d925f58<span class="token operator">-</span><span class="token number">021e-4</span>bd0<span class="token operator">-</span><span class="token number">94f</span>c<span class="token operator">-</span>f8f5e91010a4<span class="token operator">-</span><span class="token number">0</span><span class="token char">', usage_metadata={'</span>input_tokens<span class="token char">': 29, '</span>output_tokens<span class="token char">': 267, '</span>total_tokens'<span class="token operator">:</span> <span class="token number">296</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
    <h2>
     <a id="Prompt_579">
     </a>
     Prompt组件
    </h2>
    <p>
     提示词模板有助于将用户输入和参数转换为语言模型的指令。 这可以用于指导模型的响应，帮助其理解上下文并生成相关且连贯的基于语言的输出。
    </p>
    <p>
     提示词模板的输入是一个字典，其中每个键表示要填充的提示词模板中的变量。
    </p>
    <p>
     提示词模板输出一个 PromptValue。此 PromptValue 可以传递给 LLM 或 ChatModel，也可以转换为字符串或消息列表。 这个 PromptValue 的存在是为了方便在
     <strong>
      字符串
     </strong>
     和
     <strong>
      消息
     </strong>
     之间切换。
    </p>
    <h3>
     <a id="Prompt_586">
     </a>
     字符串Prompt模板
    </h3>
    <p>
     这些提示词模板用于格式化单个字符串，通常用于更简单的输入。 例如，构造和使用 PromptTemplate 的一种常见方式如下：
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>prompts import PromptTemplate

prompt_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span><span class="token function">from_template</span><span class="token punctuation">(</span><span class="token string">"Tell me a joke about {topic}"</span><span class="token punctuation">)</span>

prompt <span class="token operator">=</span> prompt_template<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"topic"</span><span class="token operator">:</span> <span class="token string">"cats"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span><span class="token function">type</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">text<span class="token operator">=</span><span class="token char">'Tell me a joke about cats'</span>
<span class="token operator">&lt;</span>class 'langchain_core<span class="token punctuation">.</span>prompt_values<span class="token punctuation">.</span>StringPromptValue'<span class="token operator">&gt;</span>
</code></pre>
    <p>
     看到
     <code>
      {var}
     </code>
     符号，其实很容易就可以猜到，langChain prompt模板是使用了jinja2模板语法的，模板语法都大差不差，再比如ollama的ModelFile的模板语法就是采用的golang的模板语法。
    </p>
    <h4>
     <a id="_605">
     </a>
     部分格式化提示词模板
    </h4>
    <p>
     LangChain 以两种方式支持部分格式化提示词模板：
    </p>
    <ol>
     <li>
      使用字符串值进行部分格式化。
     </li>
     <li>
      使用返回字符串值的函数进行部分格式化。
     </li>
    </ol>
    <p>
     例如，假设您有一个提示词模板，需要两个变量，foo 和 baz。如果您在链中早期获得了 foo 值，但稍后才获得 baz 值，那么将两个变量传递整个链可能会很不方便。相反，您可以使用 foo 值部分格式化提示词模板，然后将部分格式化的提示词模板传递下去并仅使用它。下面是一个实现此操作的示例：
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>prompts import PromptTemplate

prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span><span class="token function">from_template</span><span class="token punctuation">(</span><span class="token string">"{foo}{bar}"</span><span class="token punctuation">)</span>
partial_prompt <span class="token operator">=</span> prompt<span class="token punctuation">.</span><span class="token function">partial</span><span class="token punctuation">(</span>foo<span class="token operator">=</span><span class="token string">"foo"</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>partial_prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>bar<span class="token operator">=</span><span class="token string">"baz"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">foobaz</span></span>
</code></pre>
    <p>
     还可以仅使用部分变量初始化提示词。
    </p>
    <pre><code class="prism language-c">prompt <span class="token operator">=</span> <span class="token function">PromptTemplate</span><span class="token punctuation">(</span>
    template<span class="token operator">=</span><span class="token string">"{foo}{bar}"</span><span class="token punctuation">,</span> input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"bar"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> partial_variables<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">"foo"</span><span class="token operator">:</span> <span class="token string">"foo"</span><span class="token punctuation">}</span>
<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>bar<span class="token operator">=</span><span class="token string">"baz"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">foobaz</span></span>
</code></pre>
    <p>
     另一个常见的用法是与
     <strong>
      函数进行部分应用
     </strong>
     。使用场景是当您有一个变量，您知道总是想以一种常见的方式获取它。一个典型的例子是日期或时间。想象一下，您有一个提示词，您总是希望它包含当前日期。您不能在提示词中硬编码它，并且将其与其他输入变量一起传递是不方便的。在这种情况下，能够使用一个始终返回当前日期的函数来部分应用提示词是很方便的。
    </p>
    <pre><code class="prism language-c">from datetime import datetime


def <span class="token function">_get_datetime</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    now <span class="token operator">=</span> datetime<span class="token punctuation">.</span><span class="token function">now</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> now<span class="token punctuation">.</span><span class="token function">strftime</span><span class="token punctuation">(</span><span class="token string">"%m/%d/%Y, %H:%M:%S"</span><span class="token punctuation">)</span>


prompt <span class="token operator">=</span> <span class="token function">PromptTemplate</span><span class="token punctuation">(</span>
    template<span class="token operator">=</span><span class="token string">"Tell me a {adjective} joke about the day {date}"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"adjective"</span><span class="token punctuation">,</span> <span class="token string">"date"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
partial_prompt <span class="token operator">=</span> prompt<span class="token punctuation">.</span><span class="token function">partial</span><span class="token punctuation">(</span>date<span class="token operator">=</span>_get_datetime<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>partial_prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>adjective<span class="token operator">=</span><span class="token string">"funny"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Tell me a funny joke about the day <span class="token number">04</span><span class="token operator">/</span><span class="token number">21</span><span class="token operator">/</span><span class="token number">2024</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token operator">:</span><span class="token number">43</span><span class="token operator">:</span><span class="token number">57</span></span></span>
</code></pre>
    <p>
     还可以仅使用部分变量初始化提示词，这在此工作流程中通常更有意义。
    </p>
    <pre><code class="prism language-c">prompt <span class="token operator">=</span> <span class="token function">PromptTemplate</span><span class="token punctuation">(</span>
    template<span class="token operator">=</span><span class="token string">"Tell me a {adjective} joke about the day {date}"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"adjective"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    partial_variables<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">"date"</span><span class="token operator">:</span> _get_datetime<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>adjective<span class="token operator">=</span><span class="token string">"funny"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">Tell me a funny joke about the day <span class="token number">04</span><span class="token operator">/</span><span class="token number">21</span><span class="token operator">/</span><span class="token number">2024</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token operator">:</span><span class="token number">43</span><span class="token operator">:</span><span class="token number">57</span>
</code></pre>
    <h3>
     <a id="Prompt_664">
     </a>
     聊天Prompt模板
    </h3>
    <p>
     这些提示词模板用于格式化消息列表。这些“模板”本身由一系列模板组成。 例如，构建和使用 ChatPromptTemplate 的一种常见方式如下：
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>prompts import ChatPromptTemplate

prompt_template <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span><span class="token function">from_messages</span><span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You are a helpful assistant"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"Tell me a joke about {topic}"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

prompt <span class="token operator">=</span> prompt_template<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"topic"</span><span class="token operator">:</span> <span class="token string">"cats"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span><span class="token function">type</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">messages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token function">SystemMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'You are a helpful assistant'</span><span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'Tell me a joke about cats'</span><span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token operator">&lt;</span>class 'langchain_core<span class="token punctuation">.</span>prompt_values<span class="token punctuation">.</span>ChatPromptValue'<span class="token operator">&gt;</span>
</code></pre>
    <p>
     在上述示例中，当调用此 ChatPromptTemplate 时，将构造两个消息。 第一个是SystemMessage，没有变量需要格式化。 第二个是 HumanMessage，将由用户传入的 topic 变量进行格式化。
    </p>
    <h4>
     <a id="_687">
     </a>
     组合提示词
    </h4>
    <p>
     LangChain 提供了一个用户友好的界面，用于将提示词的不同部分组合在一起。您可以使用字符串提示词或聊天提示词来实现这一点。以这种方式构建提示词可以方便地重用组件。
    </p>
    <p>
     在处理字符串提示词时，每个模板是连接在一起的。您可以直接使用提示词或字符串（列表中的第一个元素需要是一个提示词）。
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>prompts import PromptTemplate

prompt <span class="token operator">=</span> <span class="token punctuation">(</span>
    PromptTemplate<span class="token punctuation">.</span><span class="token function">from_template</span><span class="token punctuation">(</span><span class="token string">"Tell me a joke about {topic}"</span><span class="token punctuation">)</span>
    <span class="token operator">+</span> <span class="token string">", make it funny"</span>
    <span class="token operator">+</span> <span class="token string">"\n\nand in {language}"</span>
<span class="token punctuation">)</span>

<span class="token function">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
<span class="token function">PromptTemplate</span><span class="token punctuation">(</span>input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token char">'language'</span><span class="token punctuation">,</span> <span class="token char">'topic'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> template<span class="token operator">=</span>'Tell me a joke about <span class="token punctuation">{<!-- --></span>topic<span class="token punctuation">}</span><span class="token punctuation">,</span> make it funny\n\nand in <span class="token punctuation">{<!-- --></span>language<span class="token punctuation">}</span>'<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>topic<span class="token operator">=</span><span class="token string">"sports"</span><span class="token punctuation">,</span> language<span class="token operator">=</span><span class="token string">"spanish"</span><span class="token punctuation">)</span>

'Tell me a joke about sports<span class="token punctuation">,</span> make it funny\n\nand in spanish'
</code></pre>
    <p>
     聊天提示词由一系列消息组成。与上面的示例类似，我们可以连接聊天提示词模板。每个新元素都是最终提示词中的一条新消息。
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>messages import AIMessage<span class="token punctuation">,</span> HumanMessage<span class="token punctuation">,</span> SystemMessage

prompt <span class="token operator">=</span> <span class="token function">SystemMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"You are a nice pirate"</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     然后，您可以轻松创建一个管道，将其与其他消息 或 消息模板结合起来。 当没有变量需要格式化时使用 Message，当有变量需要格式化时使用 MessageTemplate。您也可以仅使用一个字符串（注意：这将自动推断为一个 HumanMessagePromptTemplate）。
    </p>
    <pre><code class="prism language-c">new_prompt <span class="token operator">=</span> <span class="token punctuation">(</span>
    prompt <span class="token operator">+</span> <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"hi"</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"what?"</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"{input}"</span>
<span class="token punctuation">)</span>
</code></pre>
    <p>
     在底层，这会创建一个 ChatPromptTemplate 类的实例，因此您可以像之前一样使用它！
    </p>
    <pre><code class="prism language-c">new_prompt<span class="token punctuation">.</span><span class="token function">format_messages</span><span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"i said hi"</span><span class="token punctuation">)</span>

<span class="token punctuation">[</span><span class="token function">SystemMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'You are a nice pirate'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'hi'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'what?'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'i said hi'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     LangChain 还包含一个名为 PipelinePromptTemplate 的类，当想重用提示词的部分时，这个类非常有用。PipelinePrompt 由两个主要部分组成：
    </p>
    <ul>
     <li>
      最终提示词：返回的最终提示词
     </li>
     <li>
      管道提示词：一个元组列表，由字符串名称和提示词模板组成。每个提示词模板将被格式化，然后作为具有相同名称的变量传递给未来的提示词模板。
     </li>
    </ul>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>prompts import PipelinePromptTemplate<span class="token punctuation">,</span> PromptTemplate

full_template <span class="token operator">=</span> <span class="token string">""</span>"<span class="token punctuation">{<!-- --></span>introduction<span class="token punctuation">}</span>

<span class="token punctuation">{<!-- --></span>example<span class="token punctuation">}</span>

<span class="token punctuation">{<!-- --></span>start<span class="token punctuation">}</span><span class="token string">""</span>"
full_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span><span class="token function">from_template</span><span class="token punctuation">(</span>full_template<span class="token punctuation">)</span>

introduction_template <span class="token operator">=</span> <span class="token string">""</span><span class="token string">"You are impersonating {person}."</span><span class="token string">""</span>
introduction_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span><span class="token function">from_template</span><span class="token punctuation">(</span>introduction_template<span class="token punctuation">)</span>

example_template <span class="token operator">=</span> <span class="token string">""</span>"Here's an example of an interaction<span class="token operator">:</span>

Q<span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>example_q<span class="token punctuation">}</span>
A<span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>example_a<span class="token punctuation">}</span><span class="token string">""</span>"
example_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span><span class="token function">from_template</span><span class="token punctuation">(</span>example_template<span class="token punctuation">)</span>

start_template <span class="token operator">=</span> <span class="token string">""</span>"Now<span class="token punctuation">,</span> <span class="token keyword">do</span> this <span class="token keyword">for</span> real<span class="token operator">!</span>

Q<span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>input<span class="token punctuation">}</span>
A<span class="token operator">:</span><span class="token string">""</span>"
start_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span><span class="token function">from_template</span><span class="token punctuation">(</span>start_template<span class="token punctuation">)</span>

input_prompts <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"introduction"</span><span class="token punctuation">,</span> introduction_prompt<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"example"</span><span class="token punctuation">,</span> example_prompt<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"start"</span><span class="token punctuation">,</span> start_prompt<span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
pipeline_prompt <span class="token operator">=</span> <span class="token function">PipelinePromptTemplate</span><span class="token punctuation">(</span>
    final_prompt<span class="token operator">=</span>full_prompt<span class="token punctuation">,</span> pipeline_prompts<span class="token operator">=</span>input_prompts
<span class="token punctuation">)</span>

pipeline_prompt<span class="token punctuation">.</span>input_variables
# <span class="token punctuation">[</span><span class="token char">'person'</span><span class="token punctuation">,</span> <span class="token char">'example_a'</span><span class="token punctuation">,</span> <span class="token char">'example_q'</span><span class="token punctuation">,</span> <span class="token char">'input'</span><span class="token punctuation">]</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token function">print</span><span class="token punctuation">(</span>
    pipeline_prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>
        person<span class="token operator">=</span><span class="token string">"Elon Musk"</span><span class="token punctuation">,</span>
        example_q<span class="token operator">=</span><span class="token string">"What's your favorite car?"</span><span class="token punctuation">,</span>
        example_a<span class="token operator">=</span><span class="token string">"Tesla"</span><span class="token punctuation">,</span>
        input<span class="token operator">=</span><span class="token string">"What's your favorite social media site?"</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>

You are impersonating Elon Musk<span class="token punctuation">.</span>

Here's an example of an interaction<span class="token operator">:</span>

Q<span class="token operator">:</span> What's your favorite car<span class="token operator">?</span>
A<span class="token operator">:</span> Tesla

Now<span class="token punctuation">,</span> <span class="token keyword">do</span> this <span class="token keyword">for</span> real<span class="token operator">!</span>

Q<span class="token operator">:</span> What's your favorite social media site<span class="token operator">?</span>
A<span class="token operator">:</span>
</code></pre>
    <h3>
     <a id="Placeholder_799">
     </a>
     消息占位符Placeholder
    </h3>
    <p>
     此提示词模板负责在特定位置添加消息列表。 在上面的 ChatPromptTemplate 中，我们看到如何格式化两个消息，每个消息都是一个字符串。 但是如果我们希望用户传入一个消息列表，并将其插入到特定位置呢？ 这就是如何使用 MessagesPlaceholder。
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>prompts import ChatPromptTemplate<span class="token punctuation">,</span> MessagesPlaceholder
from langchain_core<span class="token punctuation">.</span>messages import HumanMessage

prompt_template <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span><span class="token function">from_messages</span><span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You are a helpful assistant"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">MessagesPlaceholder</span><span class="token punctuation">(</span><span class="token string">"msgs"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

prompt <span class="token operator">=</span> prompt_template<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"msgs"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"hi!"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">messages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token function">SystemMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'You are a helpful assistant'</span><span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'hi!'</span><span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     这将生成一个包含两个消息的列表，第一个是系统消息，第二个是我们传入的 HumanMessage。 如果我们传入了 5 条消息，那么总共将生成 6 条消息（系统消息加上 5 条传入的消息）。 这对于将消息列表插入到特定位置非常有用。
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>prompts import ChatPromptTemplate<span class="token punctuation">,</span> MessagesPlaceholder
from langchain_core<span class="token punctuation">.</span>messages import HumanMessage

prompt_template <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span><span class="token function">from_messages</span><span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You are a helpful assistant"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">MessagesPlaceholder</span><span class="token punctuation">(</span><span class="token string">"msgs"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

prompt <span class="token operator">=</span> prompt_template<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"msgs"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"hi!"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"hello!"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">messages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token function">SystemMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'You are a helpful assistant'</span><span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'hi!'</span><span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'fickl'</span><span class="token punctuation">,</span> additional_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     一种不显式使用 MessagesPlaceholder 类来实现相同功能的替代方法是：
    </p>
    <pre><code class="prism language-c">prompt_template <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span><span class="token function">from_messages</span><span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You are a helpful assistant"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"placeholder"</span><span class="token punctuation">,</span> <span class="token string">"{msgs}"</span><span class="token punctuation">)</span> # <span class="token operator">&lt;</span><span class="token operator">--</span> This is the changed part
<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     但这里还是推荐使用MessagesPlaceholder占位，从代码可读性上更胜一筹！
    </p>
    <h3>
     <a id="_847">
     </a>
     示例选择器
    </h3>
    <p>
     一种常见的提示技术是将示例作为提示的一部分，以实现更好的性能。 这被称为少量示例提示（FewShotPromp）。 这给语言模型提供了具体的示例，说明它应该如何表现。 有时这些示例是硬编码到提示中的，但在更高级的情况下，动态选择它们可能更好。
    </p>
    <p>
     <strong>
      示例选择器则是负责选择并将示例格式化为提示的类
     </strong>
     。
    </p>
    <p>
     如果你有大量示例并且可能需要
     <strong>
      选择
     </strong>
     哪些示例包含在提示中，而示例选择器是负责执行此操作的类。基本接口定义如下：
    </p>
    <pre><code class="prism language-c">class <span class="token function">BaseExampleSelector</span><span class="token punctuation">(</span>ABC<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token string">""</span><span class="token string">"Interface for selecting examples to include in prompts."</span><span class="token string">""</span>

    @abstractmethod
    def <span class="token function">select_examples</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_variables<span class="token operator">:</span> Dict<span class="token punctuation">[</span>str<span class="token punctuation">,</span> str<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-&gt;</span> List<span class="token punctuation">[</span>dict<span class="token punctuation">]</span><span class="token operator">:</span>
        <span class="token string">""</span><span class="token string">"Select which examples to use based on the inputs."</span><span class="token string">""</span>
        
    @abstractmethod
    def <span class="token function">add_example</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> example<span class="token operator">:</span> Dict<span class="token punctuation">[</span>str<span class="token punctuation">,</span> str<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-&gt;</span> Any<span class="token operator">:</span>
        <span class="token string">""</span><span class="token string">"Add new example to store."</span><span class="token string">""</span>
</code></pre>
    <p>
     它需要定义的唯一方法是 select_examples 方法。该方法接受输入变量，然后返回一个示例列表。如何选择这些示例由每个具体实现决定。
    </p>
    <p>
     LangChain 有几种不同类型的示例选择器：
    </p>
    <table>
     <thead>
      <tr>
       <th>
        名称
       </th>
       <th>
        描述
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        相似性
       </td>
       <td>
        使用输入和示例之间的语义相似性来决定选择哪些示例。
       </td>
      </tr>
      <tr>
       <td>
        MMR
       </td>
       <td>
        使用输入和示例之间的最大边际相关性来决定选择哪些示例。
       </td>
      </tr>
      <tr>
       <td>
        长度
       </td>
       <td>
        根据可以适应特定长度的示例数量来选择示例。
       </td>
      </tr>
      <tr>
       <td>
        Ngram
       </td>
       <td>
        使用输入和示例之间的n-gram重叠来决定选择哪些示例。
       </td>
      </tr>
     </tbody>
    </table>
    <p>
     为了使用示例选择器，我们需要创建一个示例列表。这些通常应该是示例输入和输出。为了演示的目的，让我们想象一下我们正在选择如何将英语翻译成意大利语的示例。
    </p>
    <pre><code class="prism language-c">examples <span class="token operator">=</span> <span class="token punctuation">[</span>
	<span class="token comment">// 输入:英语</span>
	<span class="token comment">// 输入:意大利语</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"hi"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"ciao"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"bye"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"arrivederci"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"soccer"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"calcio"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
</code></pre>
    <h4>
     <a id="_884">
     </a>
     自定义示例选择器
    </h4>
    <p>
     编写一个示例选择器，根据单词的
     <strong>
      长度
     </strong>
     选择要挑选的示例：
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>example_selectors<span class="token punctuation">.</span>base import BaseExampleSelector


class <span class="token function">CustomExampleSelector</span><span class="token punctuation">(</span>BaseExampleSelector<span class="token punctuation">)</span><span class="token operator">:</span>
    def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> examples<span class="token punctuation">)</span><span class="token operator">:</span>
        self<span class="token punctuation">.</span>examples <span class="token operator">=</span> examples

    def <span class="token function">add_example</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> example<span class="token punctuation">)</span><span class="token operator">:</span>
        self<span class="token punctuation">.</span>examples<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span>

    def <span class="token function">select_examples</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_variables<span class="token punctuation">)</span><span class="token operator">:</span>
        # 这里假设输入中会有一个名为 <span class="token char">'input'</span> 的键
        new_word <span class="token operator">=</span> input_variables<span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span>
        new_word_length <span class="token operator">=</span> <span class="token function">len</span><span class="token punctuation">(</span>new_word<span class="token punctuation">)</span>

        # 初始化变量以存储最佳匹配和其长度差异
        best_match <span class="token operator">=</span> None
        smallest_diff <span class="token operator">=</span> <span class="token keyword">float</span><span class="token punctuation">(</span><span class="token string">"inf"</span><span class="token punctuation">)</span>

        # 遍历每个示例
        <span class="token keyword">for</span> example in self<span class="token punctuation">.</span>examples<span class="token operator">:</span>
            # 计算与当前示例第一个单词的长度差异
            current_diff <span class="token operator">=</span> <span class="token function">abs</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span> new_word_length<span class="token punctuation">)</span>

            # 如果当前的长度差异更小，则更新最佳匹配
            <span class="token keyword">if</span> current_diff <span class="token operator">&lt;</span> smallest_diff<span class="token operator">:</span>
                smallest_diff <span class="token operator">=</span> current_diff
                best_match <span class="token operator">=</span> example

        <span class="token keyword">return</span> <span class="token punctuation">[</span>best_match<span class="token punctuation">]</span>
</code></pre>
    <p>
     然后初始化使用：
    </p>
    <pre><code class="prism language-c">example_selector <span class="token operator">=</span> <span class="token function">CustomExampleSelector</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span>
example_selector<span class="token punctuation">.</span><span class="token function">select_examples</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"okay"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token char">'input'</span><span class="token operator">:</span> <span class="token char">'bye'</span><span class="token punctuation">,</span> <span class="token char">'output'</span><span class="token operator">:</span> <span class="token char">'arrivederci'</span><span class="token punctuation">}</span><span class="token punctuation">]</span>

example_selector<span class="token punctuation">.</span><span class="token function">add_example</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"hand"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"mano"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
example_selector<span class="token punctuation">.</span><span class="token function">select_examples</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"okay"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token char">'input'</span><span class="token operator">:</span> <span class="token char">'hand'</span><span class="token punctuation">,</span> <span class="token char">'output'</span><span class="token operator">:</span> <span class="token char">'mano'</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     我们现在可以在提示中使用这个示例选择器：
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>prompts<span class="token punctuation">.</span>few_shot import FewShotPromptTemplate
from langchain_core<span class="token punctuation">.</span>prompts<span class="token punctuation">.</span>prompt import PromptTemplate

example_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span><span class="token function">from_template</span><span class="token punctuation">(</span><span class="token string">"Input: {input} -&gt; Output: {output}"</span><span class="token punctuation">)</span>
prompt <span class="token operator">=</span> <span class="token function">FewShotPromptTemplate</span><span class="token punctuation">(</span>
    example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    suffix<span class="token operator">=</span><span class="token string">"Input: {input} -&gt; Output:"</span><span class="token punctuation">,</span>
    prefix<span class="token operator">=</span><span class="token string">"Translate the following words from English to Italian:"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token function">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"word"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">Translate the following words from English to Italian<span class="token operator">:</span>

Input<span class="token operator">:</span> hand <span class="token operator">-&gt;</span> Output<span class="token operator">:</span> mano

Input<span class="token operator">:</span> word <span class="token operator">-&gt;</span> Output<span class="token operator">:</span>
</code></pre>
    <h4>
     <a id="_955">
     </a>
     按长度选择示例
    </h4>
    <p>
     此示例选择器根据长度选择要使用的示例。当您担心构建的提示会超出上下文窗口的长度时，这非常有用。对于较长的输入，它将选择较少的示例进行包含，而对于较短的输入，它将选择更多的示例。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>example_selectors <span class="token keyword">import</span> LengthBasedExampleSelector
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> FewShotPromptTemplate<span class="token punctuation">,</span> PromptTemplate

<span class="token comment"># 一个假设任务的示例：创建反义词。</span>
examples <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"happy"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"sad"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"tall"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"short"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"energetic"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"lethargic"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"sunny"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"gloomy"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"windy"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"calm"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

example_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span><span class="token string">"Input: {input}\nOutput: {output}"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
example_selector <span class="token operator">=</span> LengthBasedExampleSelector<span class="token punctuation">(</span>
    <span class="token comment"># 它可供选择的示例。</span>
    examples<span class="token operator">=</span>examples<span class="token punctuation">,</span>
    <span class="token comment"># 用于格式化示例的PromptTemplate。</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    <span class="token comment"># 格式化后的示例应该达到的最大长度。</span>
    <span class="token comment"># 长度是通过下面的 get_text_length 函数来衡量的。</span>
    max_length<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">,</span>
    <span class="token comment"># 用于获取字符串长度的函数，它用于确定要包含哪些示例。如果没有指定，则使用默认值。</span>
    <span class="token comment"># get_text_length: Callable[[str], int] = lambda x: len(re.split("\n| ", x))</span>
<span class="token punctuation">)</span>
dynamic_prompt <span class="token operator">=</span> FewShotPromptTemplate<span class="token punctuation">(</span>
    <span class="token comment"># 我们提供了一个 ExampleSelector 而不是直接提供示例。</span>
    example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    prefix<span class="token operator">=</span><span class="token string">"Give the antonym of every input"</span><span class="token punctuation">,</span>
    suffix<span class="token operator">=</span><span class="token string">"Input: {adjective}\nOutput:"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"adjective"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

</code></pre>
    <p>
     输入一个长度较小的“输入”，则会拼接较多示例：
    </p>
    <pre><code class="prism language-c"><span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">An example with small input<span class="token punctuation">,</span> so it selects all examples<span class="token punctuation">.</span></span></span>
<span class="token function">print</span><span class="token punctuation">(</span>dynamic_prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>adjective<span class="token operator">=</span><span class="token string">"big"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
Give the antonym of every input

Input<span class="token operator">:</span> happy
Output<span class="token operator">:</span> sad

Input<span class="token operator">:</span> tall
Output<span class="token operator">:</span> <span class="token keyword">short</span>

Input<span class="token operator">:</span> energetic
Output<span class="token operator">:</span> lethargic

Input<span class="token operator">:</span> sunny
Output<span class="token operator">:</span> gloomy

Input<span class="token operator">:</span> windy
Output<span class="token operator">:</span> calm

Input<span class="token operator">:</span> big
Output<span class="token operator">:</span>
</code></pre>
    <p>
     输入一个长文本，由于length的限制，则会返回很少的样例：
    </p>
    <pre><code class="prism language-c"><span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">An example with <span class="token keyword">long</span> input<span class="token punctuation">,</span> so it selects only one example<span class="token punctuation">.</span></span></span>
long_string <span class="token operator">=</span> <span class="token string">"big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else"</span>
<span class="token function">print</span><span class="token punctuation">(</span>dynamic_prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>adjective<span class="token operator">=</span>long_string<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">Give the antonym of every input

Input<span class="token operator">:</span> happy
Output<span class="token operator">:</span> sad

Input<span class="token operator">:</span> big and huge and massive and large and gigantic and tall and much much much much much bigger than everything <span class="token keyword">else</span>
Output<span class="token operator">:</span>
</code></pre>
    <p>
     也可以添加新的案例：
    </p>
    <pre><code class="prism language-c"><span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">You can add an example to an example selector as well<span class="token punctuation">.</span></span></span>
new_example <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"big"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"small"</span><span class="token punctuation">}</span>
dynamic_prompt<span class="token punctuation">.</span>example_selector<span class="token punctuation">.</span><span class="token function">add_example</span><span class="token punctuation">(</span>new_example<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>dynamic_prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>adjective<span class="token operator">=</span><span class="token string">"enthusiastic"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <h4>
     <a id="_1046">
     </a>
     通过相似性选择示例
    </h4>
    <p>
     该对象根据与输入的相似性选择示例。它通过找到与输入具有最大
     <strong>
      余弦相似度
     </strong>
     的嵌入示例来实现这一点。
    </p>
    <p>
     <strong>
      余弦相似度基于词频（如词袋模型或TF-IDF）进行计算，因此忽略了词序和上下文信息。这意味着，如果两个句子在语法结构上不同但使用了相同的词汇，它们的相似度可能会很高，而实际语义可能并不相同。
     </strong>
    </p>
    <p>
     OpenAIEmbeddings 将句子（而不仅仅是单词）转化为一个高维的向量，这个向量捕捉到了句子层次的语义信息。因此，余弦相似度在计算句子之间的相似度时，能够更好地反映出它们的语义相似性。
    </p>
    <pre><code class="prism language-c">from langchain_chroma import Chroma
from langchain_core<span class="token punctuation">.</span>example_selectors import SemanticSimilarityExampleSelector
from langchain_core<span class="token punctuation">.</span>prompts import FewShotPromptTemplate<span class="token punctuation">,</span> PromptTemplate
from langchain_openai import OpenAIEmbeddings

example_prompt <span class="token operator">=</span> <span class="token function">PromptTemplate</span><span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span><span class="token string">"Input: {input}\nOutput: {output}"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Examples of a pretend task of creating antonyms<span class="token punctuation">.</span></span></span>
examples <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"happy"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"sad"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"tall"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"short"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"energetic"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"lethargic"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"sunny"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"gloomy"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"windy"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"calm"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

example_selector <span class="token operator">=</span> SemanticSimilarityExampleSelector<span class="token punctuation">.</span><span class="token function">from_examples</span><span class="token punctuation">(</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">The list of examples available to select from<span class="token punctuation">.</span></span></span>
    examples<span class="token punctuation">,</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">The embedding class used to produce embeddings which are used to measure semantic similarity<span class="token punctuation">.</span></span></span>
    <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">The VectorStore class that is used to store the embeddings and <span class="token keyword">do</span> a similarity search over<span class="token punctuation">.</span></span></span>
    Chroma<span class="token punctuation">,</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">The number of examples to produce<span class="token punctuation">.</span></span></span>
    k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
similar_prompt <span class="token operator">=</span> <span class="token function">FewShotPromptTemplate</span><span class="token punctuation">(</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">We provide an ExampleSelector instead of examples<span class="token punctuation">.</span></span></span>
    example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    prefix<span class="token operator">=</span><span class="token string">"Give the antonym of every input"</span><span class="token punctuation">,</span>
    suffix<span class="token operator">=</span><span class="token string">"Input: {adjective}\nOutput:"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"adjective"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre>
    <p>
     输入一个表示情感的词汇：
    </p>
    <pre><code class="prism language-c"><span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Input is a feeling<span class="token punctuation">,</span> so should select the happy<span class="token operator">/</span>sad example</span></span>
<span class="token function">print</span><span class="token punctuation">(</span>similar_prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>adjective<span class="token operator">=</span><span class="token string">"worried"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
Give the antonym of every input

Input<span class="token operator">:</span> happy
Output<span class="token operator">:</span> sad

Input<span class="token operator">:</span> worried
Output<span class="token operator">:</span>
</code></pre>
    <h4>
     <a id="_ngram__1107">
     </a>
     通过 n-gram 重叠选择示例
    </h4>
    <p>
     n-gram 重叠（n-gram overlap）是指两个文本（或句子）在n-gram（n元组）级别上的相似度，通常用于衡量两个文本之间的相似性或重合程度。
    </p>
    <p>
     n-gram 重叠度指的是两个文本中共同出现的n-gram数量。假设你有两个文本，文本A和文本B，n-gram重叠就是计算它们在n-gram层面上重合的部分。比如，两个文本中同时出现了多少相同的2-gram（bigram）。
    </p>
    <pre><code class="prism language-c">文本A：<span class="token string">"I love dogs"</span>
文本B：<span class="token string">"I love cats"</span>

文本A的<span class="token number">2</span><span class="token operator">-</span>gram（bigram）：<span class="token punctuation">[</span><span class="token string">"I love"</span><span class="token punctuation">,</span> <span class="token string">"love dogs"</span><span class="token punctuation">]</span>
文本B的<span class="token number">2</span><span class="token operator">-</span>gram（bigram）：<span class="token punctuation">[</span><span class="token string">"I love"</span><span class="token punctuation">,</span> <span class="token string">"love cats"</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     它们的2-gram重叠是[“I love”]，因为它们的2-gram中有"I love"是相同的。
    </p>
    <p>
     计算重叠度：常用的计算方式包括：
    </p>
    <ul>
     <li>
      重叠率：共享的n-gram数量除以文本A或文本B中的n-gram总数。
     </li>
     <li>
      Jaccard相似度：Jaccard(𝐴,𝐵)=∣𝐴∩𝐵∣/∣𝐴∪𝐵∣，即共享n-gram的数量除以A和B所有n-gram的并集的大小。
      <br/>
      ​
      <br/>
      n-gram重叠并不考虑词语的语义，只关注词的顺序和出现。因此，如果两个文本表达相似的意义但使用了不同的词汇，n-gram重叠可能无法反映这一相似性。
     </li>
    </ul>
    <p>
     NGramOverlapExampleSelector 根据与输入的 ngram 重叠分数选择和排序示例。ngram 重叠分数是一个介于 0.0 和 1.0 之间的浮点数（包括 0.0 和 1.0）。
    </p>
    <p>
     选择器允许设置阈值分数。ngram 重叠分数小于或等于阈值的示例将被排除。默认情况下，阈值设置为 -1.0，因此不会排除任何示例，只会重新排序。将阈值设置为 0.0 将排除与输入没有 ngram 重叠的示例。
    </p>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>example_selectors import NGramOverlapExampleSelector
from langchain_core<span class="token punctuation">.</span>prompts import FewShotPromptTemplate<span class="token punctuation">,</span> PromptTemplate

example_prompt <span class="token operator">=</span> <span class="token function">PromptTemplate</span><span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span><span class="token string">"Input: {input}\nOutput: {output}"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Examples of a fictional translation task<span class="token punctuation">.</span></span></span>
examples <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"See Spot run."</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"Ver correr a Spot."</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"My dog barks."</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"Mi perro ladra."</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"Spot can run."</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"Spot puede correr."</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
example_selector <span class="token operator">=</span> <span class="token function">NGramOverlapExampleSelector</span><span class="token punctuation">(</span>
    # 提供可以选择的示例。
    examples<span class="token operator">=</span>examples<span class="token punctuation">,</span>
    # 用于格式化示例的PromptTemplate。
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    # 阈值，达到该阈值时选择器停止。
    # 默认设置为<span class="token operator">-</span><span class="token number">1.0</span>。
    threshold<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">,</span>
    # 对于负阈值：
    # 选择器按n<span class="token operator">-</span>gram重叠得分对示例进行排序，并且不排除任何示例。
    # 对于大于<span class="token number">1.0</span>的阈值：
    # 选择器排除所有示例，并返回一个空列表。
    # 对于阈值等于<span class="token number">0.0</span>：
    # 选择器按n<span class="token operator">-</span>gram重叠得分对示例进行排序，
    # 并排除那些与输入没有n<span class="token operator">-</span>gram重叠的示例。
<span class="token punctuation">)</span>

dynamic_prompt <span class="token operator">=</span> <span class="token function">FewShotPromptTemplate</span><span class="token punctuation">(</span>
    # 我们提供一个ExampleSelector，而不是直接提供示例。
    example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    prefix<span class="token operator">=</span><span class="token string">"给出每个输入的西班牙语翻译"</span><span class="token punctuation">,</span>
    suffix<span class="token operator">=</span><span class="token string">"输入: {sentence}\n输出:"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"sentence"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">An example input with large ngram overlap with </span><span class="token string">"Spot can run."</span></span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">and</span> <span class="token expression">no overlap with </span><span class="token string">"My dog barks."</span></span>
<span class="token function">print</span><span class="token punctuation">(</span>dynamic_prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>sentence<span class="token operator">=</span><span class="token string">"Spot can run fast."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
Give the Spanish translation of every input

Input<span class="token operator">:</span> Spot can run<span class="token punctuation">.</span>
Output<span class="token operator">:</span> Spot puede correr<span class="token punctuation">.</span>

Input<span class="token operator">:</span> See Spot run<span class="token punctuation">.</span>
Output<span class="token operator">:</span> Ver correr a Spot<span class="token punctuation">.</span>

Input<span class="token operator">:</span> My dog barks<span class="token punctuation">.</span>
Output<span class="token operator">:</span> Mi perro ladra<span class="token punctuation">.</span>

Input<span class="token operator">:</span> Spot can run fast<span class="token punctuation">.</span>
Output<span class="token operator">:</span>
</code></pre>
    <p>
     也可以动态增加案例：
    </p>
    <pre><code class="prism language-c"><span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">You can add examples to NGramOverlapExampleSelector as well<span class="token punctuation">.</span></span></span>
new_example <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"Spot plays fetch."</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"Spot juega a buscar."</span><span class="token punctuation">}</span>

example_selector<span class="token punctuation">.</span><span class="token function">add_example</span><span class="token punctuation">(</span>new_example<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>dynamic_prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>sentence<span class="token operator">=</span><span class="token string">"Spot can run fast."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     或者修改阈值：
    </p>
    <pre><code class="prism language-c"># 你可以设置一个阈值，用于排除示例。
# 例如，将阈值设置为<span class="token number">0.0</span>，
# 这样会排除那些与输入没有n<span class="token operator">-</span>gram重叠的示例。
# 由于“My dog barks<span class="token punctuation">.</span>”与“Spot can run fast<span class="token punctuation">.</span>”没有n<span class="token operator">-</span>gram重叠，
# 所以它会被排除。
example_selector<span class="token punctuation">.</span>threshold <span class="token operator">=</span> <span class="token number">0.0</span>
<span class="token function">print</span><span class="token punctuation">(</span>dynamic_prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>sentence<span class="token operator">=</span><span class="token string">"Spot can run fast."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">Give the Spanish translation of every input

Input<span class="token operator">:</span> Spot can run<span class="token punctuation">.</span>
Output<span class="token operator">:</span> Spot puede correr<span class="token punctuation">.</span>

Input<span class="token operator">:</span> See Spot run<span class="token punctuation">.</span>
Output<span class="token operator">:</span> Ver correr a Spot<span class="token punctuation">.</span>

Input<span class="token operator">:</span> Spot plays fetch<span class="token punctuation">.</span>
Output<span class="token operator">:</span> Spot juega a buscar<span class="token punctuation">.</span>

Input<span class="token operator">:</span> Spot can run fast<span class="token punctuation">.</span>
Output<span class="token operator">:</span>
</code></pre>
    <h4>
     <a id="_MMR__1229">
     </a>
     通过最大边际相关性 (MMR) 选择示例
    </h4>
    <p>
     MaxMarginalRelevanceExampleSelector 根据与输入最相似的示例的组合来选择示例，同时优化多样性。它通过找到与输入具有
     <strong>
      最大余弦相似度的嵌入
     </strong>
     示例来实现这一点，然后在迭代添加这些示例的同时，对与已选择示例的接近程度进行惩罚。
    </p>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>vectorstores import FAISS
from langchain_core<span class="token punctuation">.</span>example_selectors <span class="token function">import</span> <span class="token punctuation">(</span>
    MaxMarginalRelevanceExampleSelector<span class="token punctuation">,</span>
    SemanticSimilarityExampleSelector<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
from langchain_core<span class="token punctuation">.</span>prompts import FewShotPromptTemplate<span class="token punctuation">,</span> PromptTemplate
from langchain_openai import OpenAIEmbeddings

example_prompt <span class="token operator">=</span> <span class="token function">PromptTemplate</span><span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span><span class="token string">"Input: {input}\nOutput: {output}"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Examples of a pretend task of creating antonyms<span class="token punctuation">.</span></span></span>
examples <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"happy"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"sad"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"tall"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"short"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"energetic"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"lethargic"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"sunny"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"gloomy"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"windy"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"calm"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
</code></pre>
    <pre><code class="prism language-c">example_selector <span class="token operator">=</span> MaxMarginalRelevanceExampleSelector<span class="token punctuation">.</span><span class="token function">from_examples</span><span class="token punctuation">(</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">The list of examples available to select from<span class="token punctuation">.</span></span></span>
    examples<span class="token punctuation">,</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">The embedding class used to produce embeddings which are used to measure semantic similarity<span class="token punctuation">.</span></span></span>
    <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">The VectorStore class that is used to store the embeddings and <span class="token keyword">do</span> a similarity search over<span class="token punctuation">.</span></span></span>
    FAISS<span class="token punctuation">,</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">The number of examples to produce<span class="token punctuation">.</span></span></span>
    k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
mmr_prompt <span class="token operator">=</span> <span class="token function">FewShotPromptTemplate</span><span class="token punctuation">(</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">We provide an ExampleSelector instead of examples<span class="token punctuation">.</span></span></span>
    example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    prefix<span class="token operator">=</span><span class="token string">"Give the antonym of every input"</span><span class="token punctuation">,</span>
    suffix<span class="token operator">=</span><span class="token string">"Input: {adjective}\nOutput:"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"adjective"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Input is a feeling<span class="token punctuation">,</span> so should select the happy<span class="token operator">/</span>sad example as the first one</span></span>
<span class="token function">print</span><span class="token punctuation">(</span>mmr_prompt<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>adjective<span class="token operator">=</span><span class="token string">"worried"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="FewShotPrompt_1282">
     </a>
     FewShotPrompt
    </h3>
    <p>
     提高模型性能的最有效方法之一是给模型提供希望它执行的示例。
     <strong>
      将示例输入和预期输出 添加到模型提示中的技术称为“少量示例提示”。
     </strong>
    </p>
    <p>
     在进行少量示例提示时，有几个需要考虑的事项：
    </p>
    <ul>
     <li>
      示例是如何生成的？
     </li>
     <li>
      每个提示中有多少个示例？
     </li>
     <li>
      示例是如何在运行时选择的？
     </li>
     <li>
      示例在提示中是如何格式化的？
     </li>
    </ul>
    <h4>
     <a id="_1292">
     </a>
     少量示例格式化器
    </h4>
    <p>
     我们首先为少量示例创建格式化器（模板），将少量示例格式化为字符串。该格式化器应为 PromptTemplate 对象。
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>prompts import PromptTemplate

example_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span><span class="token function">from_template</span><span class="token punctuation">(</span><span class="token string">"Question: {question}\n{answer}"</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     接下来，我们将创建一个少量示例的列表。每个示例应该是一个字典，表示我们上面定义的格式化提示的示例输入。
    </p>
    <pre><code class="prism language-c">examples <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token string">"question"</span><span class="token operator">:</span> <span class="token string">"Who lived longer, Muhammad Ali or Alan Turing?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token operator">:</span> <span class="token string">""</span>"
Are follow up questions needed here<span class="token operator">:</span> Yes<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> How old was Muhammad Ali when he died<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> Muhammad Ali was <span class="token number">74</span> years old when he died<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> How old was Alan Turing when he died<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> Alan Turing was <span class="token number">41</span> years old when he died<span class="token punctuation">.</span>
So the final answer is<span class="token operator">:</span> Muhammad Ali
<span class="token string">""</span>"<span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token string">"question"</span><span class="token operator">:</span> <span class="token string">"When was the founder of craigslist born?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token operator">:</span> <span class="token string">""</span>"
Are follow up questions needed here<span class="token operator">:</span> Yes<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Who was the founder of craigslist<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> Craigslist was founded by Craig Newmark<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> When was Craig Newmark born<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> Craig Newmark was born on December <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">1952.</span>
So the final answer is<span class="token operator">:</span> December <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">1952</span>
<span class="token string">""</span>"<span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token string">"question"</span><span class="token operator">:</span> <span class="token string">"Who was the maternal grandfather of George Washington?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token operator">:</span> <span class="token string">""</span>"
Are follow up questions needed here<span class="token operator">:</span> Yes<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Who was the mother of George Washington<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> The mother of George Washington was Mary Ball Washington<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Who was the father of Mary Ball Washington<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> The father of Mary Ball Washington was Joseph Ball<span class="token punctuation">.</span>
So the final answer is<span class="token operator">:</span> Joseph Ball
<span class="token string">""</span>"<span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token string">"question"</span><span class="token operator">:</span> <span class="token string">"Are both the directors of Jaws and Casino Royale from the same country?"</span><span class="token punctuation">,</span>
        <span class="token string">"answer"</span><span class="token operator">:</span> <span class="token string">""</span>"
Are follow up questions needed here<span class="token operator">:</span> Yes<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Who is the director of Jaws<span class="token operator">?</span>
Intermediate Answer<span class="token operator">:</span> The director of Jaws is Steven Spielberg<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Where is Steven Spielberg from<span class="token operator">?</span>
Intermediate Answer<span class="token operator">:</span> The United States<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Who is the director of Casino Royale<span class="token operator">?</span>
Intermediate Answer<span class="token operator">:</span> The director of Casino Royale is Martin Campbell<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Where is Martin Campbell from<span class="token operator">?</span>
Intermediate Answer<span class="token operator">:</span> New Zealand<span class="token punctuation">.</span>
So the final answer is<span class="token operator">:</span> No
<span class="token string">""</span>"<span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
</code></pre>
    <p>
     测试格式化提示：
    </p>
    <pre><code class="prism language-c"><span class="token function">print</span><span class="token punctuation">(</span>example_prompt<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">to_string</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">Question<span class="token operator">:</span> Who lived longer<span class="token punctuation">,</span> Muhammad Ali or Alan Turing<span class="token operator">?</span>

Are follow up questions needed here<span class="token operator">:</span> Yes<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> How old was Muhammad Ali when he died<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> Muhammad Ali was <span class="token number">74</span> years old when he died<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> How old was Alan Turing when he died<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> Alan Turing was <span class="token number">41</span> years old when he died<span class="token punctuation">.</span>
So the final answer is<span class="token operator">:</span> Muhammad Ali
</code></pre>
    <p>
     最后，创建一个 FewShotPromptTemplate 对象。该对象接受少量示例和少量示例的格式化器。当这个 FewShotPromptTemplate 被格式化时，它使用 example_prompt 格式化传递的示例，然后将它们添加到最终提示的 suffix 之前：
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>prompts import FewShotPromptTemplate

prompt <span class="token operator">=</span> <span class="token function">FewShotPromptTemplate</span><span class="token punctuation">(</span>
    examples<span class="token operator">=</span>examples<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    suffix<span class="token operator">=</span><span class="token string">"Question: {input}"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token function">print</span><span class="token punctuation">(</span>
    prompt<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"Who was the father of Mary Ball Washington?"</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">to_string</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre>
    <p>
     打印结果如下：
    </p>
    <pre><code class="prism language-c">Question<span class="token operator">:</span> Who lived longer<span class="token punctuation">,</span> Muhammad Ali or Alan Turing<span class="token operator">?</span>

Are follow up questions needed here<span class="token operator">:</span> Yes<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> How old was Muhammad Ali when he died<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> Muhammad Ali was <span class="token number">74</span> years old when he died<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> How old was Alan Turing when he died<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> Alan Turing was <span class="token number">41</span> years old when he died<span class="token punctuation">.</span>
So the final answer is<span class="token operator">:</span> Muhammad Ali


Question<span class="token operator">:</span> When was the founder of craigslist born<span class="token operator">?</span>

Are follow up questions needed here<span class="token operator">:</span> Yes<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Who was the founder of craigslist<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> Craigslist was founded by Craig Newmark<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> When was Craig Newmark born<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> Craig Newmark was born on December <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">1952.</span>
So the final answer is<span class="token operator">:</span> December <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">1952</span>


Question<span class="token operator">:</span> Who was the maternal grandfather of George Washington<span class="token operator">?</span>

Are follow up questions needed here<span class="token operator">:</span> Yes<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Who was the mother of George Washington<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> The mother of George Washington was Mary Ball Washington<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Who was the father of Mary Ball Washington<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> The father of Mary Ball Washington was Joseph Ball<span class="token punctuation">.</span>
So the final answer is<span class="token operator">:</span> Joseph Ball


Question<span class="token operator">:</span> Are both the directors of Jaws and Casino Royale from the same country<span class="token operator">?</span>

Are follow up questions needed here<span class="token operator">:</span> Yes<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Who is the director of Jaws<span class="token operator">?</span>
Intermediate Answer<span class="token operator">:</span> The director of Jaws is Steven Spielberg<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Where is Steven Spielberg from<span class="token operator">?</span>
Intermediate Answer<span class="token operator">:</span> The United States<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Who is the director of Casino Royale<span class="token operator">?</span>
Intermediate Answer<span class="token operator">:</span> The director of Casino Royale is Martin Campbell<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Where is Martin Campbell from<span class="token operator">?</span>
Intermediate Answer<span class="token operator">:</span> New Zealand<span class="token punctuation">.</span>
So the final answer is<span class="token operator">:</span> No


Question<span class="token operator">:</span> Who was the father of Mary Ball Washington<span class="token operator">?</span>
</code></pre>
    <h4>
     <a id="_1434">
     </a>
     结合示例选择器对示例进行筛选
    </h4>
    <p>
     将上文提及到的示例输入到一个名为 SemanticSimilarityExampleSelector 的 ExampleSelector 实现实例中。该类根据输入与初始集中的少量示例的相似性选择少量示例。
     <strong>
      它使用嵌入模型计算输入与少量示例之间的相似性，并使用向量存储执行最近邻搜索。
     </strong>
    </p>
    <pre><code class="prism language-c">from langchain_chroma import Chroma
from langchain_core<span class="token punctuation">.</span>example_selectors import SemanticSimilarityExampleSelector
from langchain_openai import OpenAIEmbeddings

example_selector <span class="token operator">=</span> SemanticSimilarityExampleSelector<span class="token punctuation">.</span><span class="token function">from_examples</span><span class="token punctuation">(</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">This is the list of examples available to select from<span class="token punctuation">.</span></span></span>
    examples<span class="token punctuation">,</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">This is the embedding class used to produce embeddings which are used to measure semantic similarity<span class="token punctuation">.</span></span></span>
    <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">This is the VectorStore class that is used to store the embeddings and <span class="token keyword">do</span> a similarity search over<span class="token punctuation">.</span></span></span>
    Chroma<span class="token punctuation">,</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">This is the number of examples to produce<span class="token punctuation">.</span></span></span>
    k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre>
    <p>
     现在，创建一个 FewShotPromptTemplate 对象，这次我们要传入
     <strong>
      示例选择器
     </strong>
     。
    </p>
    <pre><code class="prism language-c">example_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span><span class="token function">from_template</span><span class="token punctuation">(</span><span class="token string">"Question: {question}\n{answer}"</span><span class="token punctuation">)</span>

prompt <span class="token operator">=</span> <span class="token function">FewShotPromptTemplate</span><span class="token punctuation">(</span>
    example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    suffix<span class="token operator">=</span><span class="token string">"Question: {input}"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token function">print</span><span class="token punctuation">(</span>
    prompt<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"Who was the father of Mary Ball Washington?"</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">to_string</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre>
    <p>
     可以看到，我们的问题经过调用后，会先经过一遍模型进行向量化，然后根据相似度匹配得到最佳示例，然后填充到prompt模板中：
    </p>
    <pre><code class="prism language-c">Question<span class="token operator">:</span> Who was the maternal grandfather of George Washington<span class="token operator">?</span>

Are follow up questions needed here<span class="token operator">:</span> Yes<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Who was the mother of George Washington<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> The mother of George Washington was Mary Ball Washington<span class="token punctuation">.</span>
Follow up<span class="token operator">:</span> Who was the father of Mary Ball Washington<span class="token operator">?</span>
Intermediate answer<span class="token operator">:</span> The father of Mary Ball Washington was Joseph Ball<span class="token punctuation">.</span>
So the final answer is<span class="token operator">:</span> Joseph Ball


Question<span class="token operator">:</span> Who was the father of Mary Ball Washington<span class="token operator">?</span>
</code></pre>
    <h4>
     <a id="_1483">
     </a>
     在聊天模型中使用少量示例
    </h4>
    <p>
     我们给LLM一个不熟悉的数学运算符，用“🦜”表情符号表示，如果我们尝试询问模型这个表达式的结果，它将失败。
    </p>
    <p>
     因为大模型的权重文件是没有关于这个“🦜”运算符的知识的，因此我们需要添加一些案例，让大模型“明白”自己需要做什么。
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>prompts import ChatPromptTemplate<span class="token punctuation">,</span> FewShotChatMessagePromptTemplate

examples <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"2 🦜 2"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"4"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"2 🦜 3"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"5"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

# 接下来，将它们组装成少量示例提示模板。
example_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span><span class="token function">from_messages</span><span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
        <span class="token punctuation">(</span><span class="token string">"human"</span><span class="token punctuation">,</span> <span class="token string">"{input}"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"ai"</span><span class="token punctuation">,</span> <span class="token string">"{output}"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span>
few_shot_prompt <span class="token operator">=</span> <span class="token function">FewShotChatMessagePromptTemplate</span><span class="token punctuation">(</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    examples<span class="token operator">=</span>examples<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token function">print</span><span class="token punctuation">(</span>few_shot_prompt<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">to_messages</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
# <span class="token punctuation">[</span><span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'2 🦜 2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'4'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'2 🦜 3'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'5'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

# 最后，我们将最终提示组装如下，将 few_shot_prompt 直接传递给 from_messages 工厂方法，并与模型一起使用：
final_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span><span class="token function">from_messages</span><span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
        <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You are a wondrous wizard of math."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        few_shot_prompt<span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"human"</span><span class="token punctuation">,</span> <span class="token string">"{input}"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span>
</code></pre>
    <p>
     现在让我们向模型提出最初的问题：
    </p>
    <pre><code class="prism language-c">from langchain_openai import ChatOpenAI

chain <span class="token operator">=</span> final_prompt <span class="token operator">|</span> model

chain<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"What is 2 🦜 9?"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'11'</span><span class="token punctuation">,</span> response_metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'token_usage'</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'completion_tokens'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'prompt_tokens'</span><span class="token operator">:</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token char">'total_tokens'</span><span class="token operator">:</span> <span class="token number">61</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token char">'model_name'</span><span class="token operator">:</span> <span class="token char">'gpt-4o-mini'</span><span class="token punctuation">,</span> <span class="token char">'system_fingerprint'</span><span class="token operator">:</span> None<span class="token punctuation">,</span> <span class="token char">'finish_reason'</span><span class="token operator">:</span> <span class="token char">'stop'</span><span class="token punctuation">,</span> <span class="token char">'logprobs'</span><span class="token operator">:</span> None<span class="token punctuation">}</span><span class="token punctuation">,</span> id<span class="token operator">=</span>'run<span class="token operator">-</span><span class="token number">5</span>ec4e051<span class="token operator">-</span><span class="token number">262f</span><span class="token operator">-</span><span class="token number">408</span>e<span class="token operator">-</span>ad00<span class="token operator">-</span><span class="token number">3f</span><span class="token number">2</span>ebeb561c3<span class="token operator">-</span><span class="token number">0</span><span class="token char">', usage_metadata={'</span>input_tokens<span class="token char">': 60, '</span>output_tokens<span class="token char">': 1, '</span>total_tokens'<span class="token operator">:</span> <span class="token number">61</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     看样子大模型已经可以很好的理解，🦜运算符等价于加法运算符。
    </p>
    <p>
     有时我们可能希望根据输入仅选择整体集合中的少量示例进行展示。为此，可以用 example_selector 替换传递给 FewShotChatMessagePromptTemplate 的 examples。
    </p>
    <ul>
     <li>
      example_selector：负责为给定输入选择少量示例（以及返回的顺序）。这些实现了 BaseExampleSelector 接口。一个常见的例子是基于向量存储的 SemanticSimilarityExampleSelector
     </li>
     <li>
      example_prompt：通过其 format_messages 方法将每个示例转换为 1 个或多个消息。一个常见的例子是将每个示例转换为一个人类消息和一个 AI 消息响应，或者一个人类消息后跟一个函数调用消息。
     </li>
    </ul>
    <pre><code class="prism language-c">from langchain_chroma import Chroma
from langchain_core<span class="token punctuation">.</span>example_selectors import SemanticSimilarityExampleSelector
from langchain_openai import OpenAIEmbeddings

examples <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"2 🦜 2"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"4"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"2 🦜 3"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"5"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"2 🦜 4"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"6"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"What did the cow say to the moon?"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"nothing at all"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"Write me a poem about the moon"</span><span class="token punctuation">,</span>
        <span class="token string">"output"</span><span class="token operator">:</span> <span class="token string">"One for the moon, and one for me, who are we to talk about the moon?"</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

to_vectorize <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">" "</span><span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span>example<span class="token punctuation">.</span><span class="token function">values</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> example in examples<span class="token punctuation">]</span>
embeddings <span class="token operator">=</span> <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
vectorstore <span class="token operator">=</span> Chroma<span class="token punctuation">.</span><span class="token function">from_texts</span><span class="token punctuation">(</span>to_vectorize<span class="token punctuation">,</span> embeddings<span class="token punctuation">,</span> metadatas<span class="token operator">=</span>examples<span class="token punctuation">)</span>
</code></pre>
    <p>
     这里的Chroma是一个内存向量库！
     <a href="https://github.com/chroma-core/chroma">
      https://github.com/chroma-core/chroma
     </a>
    </p>
    <blockquote>
     <p>
      向量数据库其实最早在传统的人工智能和机器学习场景中就有所应用。在大模型兴起后，由于目前大模型的token数限制，很多开发者倾向于将数据量庞大的知识、新闻、文献、语料等先通过嵌入（embedding）算法转变为向量数据，然后存储在Chroma等向量数据库中。当用户在大模型输入问题后，将问题本身也embedding，转化为向量，在向量数据库中查找与之最匹配的相关知识，组成大模型的上下文，将其输入给大模型，最终返回大模型处理后的文本给用户，这种方式不仅降低大模型的计算量，提高响应速度，也降低成本，并避免了大模型的tokens限制，是一种简单高效的处理手段。此外，向量数据库还在大模型记忆存储等领域发挥其不可替代的作用。
     </p>
    </blockquote>
    <p>
     主流的向量数据库对比如下所示：
    </p>
    <table>
     <tbody>
      <tr>
       <th>
        向量数据库
       </th>
       <th>
        URL
       </th>
       <th>
        GitHub Star
       </th>
       <th>
        Language
       </th>
      </tr>
      <tr>
       <td>
        chroma
       </td>
       <td>
        <a class="external" href="https://link.zhihu.com/?target=https%3A//github.com/chroma-core/chroma" rel="nofollow noreferrer noopener noreferrer" target="_blank">
         <span class="invisible">
          https://
         </span>
         <span class="visible">
          github.com/chroma-core/
         </span>
         <span class="invisible">
          chroma
         </span>
         <span class="ellipsis">
         </span>
        </a>
       </td>
       <td>
        7.4K
       </td>
       <td>
        Python
       </td>
      </tr>
      <tr>
       <td>
        milvus
       </td>
       <td>
        <a class="external" href="https://link.zhihu.com/?target=https%3A//github.com/milvus-io/milvus" rel="nofollow noreferrer noopener noreferrer" target="_blank">
         <span class="invisible">
          https://
         </span>
         <span class="visible">
          github.com/milvus-io/mi
         </span>
         <span class="invisible">
          lvus
         </span>
         <span class="ellipsis">
         </span>
        </a>
       </td>
       <td>
        21.5K
       </td>
       <td>
        Go/Python/C++
       </td>
      </tr>
      <tr>
       <td>
        pinecone
       </td>
       <td>
        <a class="external" href="https://link.zhihu.com/?target=https%3A//www.pinecone.io/" rel="nofollow noreferrer noopener noreferrer" target="_blank">
         <span class="invisible">
          https://www.
         </span>
         <span class="visible">
          pinecone.io/
         </span>
         <span class="invisible">
         </span>
        </a>
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        qdrant
       </td>
       <td>
        <a class="external" href="https://link.zhihu.com/?target=https%3A//github.com/qdrant/qdrant" rel="nofollow noreferrer noopener noreferrer" target="_blank">
         <span class="invisible">
          https://
         </span>
         <span class="visible">
          github.com/qdrant/qdran
         </span>
         <span class="invisible">
          t
         </span>
         <span class="ellipsis">
         </span>
        </a>
       </td>
       <td>
        11.8K
       </td>
       <td>
        Rust
       </td>
      </tr>
      <tr>
       <td>
        typesense
       </td>
       <td>
        <a class="external" href="https://link.zhihu.com/?target=https%3A//github.com/typesense/typesense" rel="nofollow noreferrer noopener noreferrer" target="_blank">
         <span class="invisible">
          https://
         </span>
         <span class="visible">
          github.com/typesense/ty
         </span>
         <span class="invisible">
          pesense
         </span>
         <span class="ellipsis">
         </span>
        </a>
       </td>
       <td>
        12.9K
       </td>
       <td>
        C++
       </td>
      </tr>
      <tr>
       <td>
        weaviate
       </td>
       <td>
        <a class="external" href="https://link.zhihu.com/?target=https%3A//github.com/weaviate/weaviate" rel="nofollow noreferrer noopener noreferrer" target="_blank">
         <span class="invisible">
          https://
         </span>
         <span class="visible">
          github.com/weaviate/wea
         </span>
         <span class="invisible">
          viate
         </span>
         <span class="ellipsis">
         </span>
        </a>
       </td>
       <td>
        6.9K
       </td>
       <td>
        Go
       </td>
      </tr>
     </tbody>
    </table>
    <p>
     目前比较火的有milvus和chroma，chroma凭借其轻量级（如同sqllite比较与mysql）也是声名大噪：
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/72412f5438dd45f6b72f54a73c9e45d3.png">
      <br/>
      创建了向量存储后，我们可以创建 example_selector。在这里，我们将单独调用它，并将 k 设置为仅获取与输入最接近的两个示例。
     </img>
    </p>
    <pre><code class="prism language-c">example_selector <span class="token operator">=</span> <span class="token function">SemanticSimilarityExampleSelector</span><span class="token punctuation">(</span>
    vectorstore<span class="token operator">=</span>vectorstore<span class="token punctuation">,</span>
    k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">The prompt template will load examples by passing the input <span class="token keyword">do</span> the `select_examples` method</span></span>
example_selector<span class="token punctuation">.</span><span class="token function">select_examples</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"horse"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token char">'input'</span><span class="token operator">:</span> 'What did the cow say to the moon<span class="token operator">?</span><span class="token char">', '</span>output<span class="token char">': '</span>nothing at all'<span class="token punctuation">}</span><span class="token punctuation">,</span>
 <span class="token punctuation">{<!-- --></span><span class="token char">'input'</span><span class="token operator">:</span> <span class="token char">'2 🦜 4'</span><span class="token punctuation">,</span> <span class="token char">'output'</span><span class="token operator">:</span> <span class="token char">'6'</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     我们现在组装提示模板，使用上面创建的 example_selector：
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>prompts import ChatPromptTemplate<span class="token punctuation">,</span> FewShotChatMessagePromptTemplate

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Define </span><span class="token macro-name">the</span> <span class="token expression">few<span class="token operator">-</span>shot prompt<span class="token punctuation">.</span></span></span>
few_shot_prompt <span class="token operator">=</span> <span class="token function">FewShotChatMessagePromptTemplate</span><span class="token punctuation">(</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">The input variables select the values to pass to the example_selector</span></span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Define </span><span class="token macro-name">how</span> <span class="token expression">each example will be formatted<span class="token punctuation">.</span></span></span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">In this <span class="token keyword">case</span><span class="token punctuation">,</span> each example will become <span class="token number">2</span> messages<span class="token operator">:</span></span></span>
    # <span class="token number">1</span> human<span class="token punctuation">,</span> and <span class="token number">1</span> AI
    example_prompt<span class="token operator">=</span>ChatPromptTemplate<span class="token punctuation">.</span><span class="token function">from_messages</span><span class="token punctuation">(</span>
        <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"human"</span><span class="token punctuation">,</span> <span class="token string">"{input}"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"ai"</span><span class="token punctuation">,</span> <span class="token string">"{output}"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token function">print</span><span class="token punctuation">(</span>few_shot_prompt<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"What's 3 🦜 3?"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">to_messages</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     当我们询问🦜运算符时，选择器帮我们选择了最高相似度的2个示例：
    </p>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'2 🦜 3'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'5'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">HumanMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'2 🦜 4'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">AIMessage</span><span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token char">'6'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     我们可以将这个少量示例聊天消息提示模板传递到另一个聊天提示模板中：
    </p>
    <pre><code class="prism language-c">final_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span><span class="token function">from_messages</span><span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
        <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You are a wondrous wizard of math."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        few_shot_prompt<span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"human"</span><span class="token punctuation">,</span> <span class="token string">"{input}"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token function">print</span><span class="token punctuation">(</span>few_shot_prompt<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>input<span class="token operator">=</span><span class="token string">"What's 3 🦜 3?"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     最后，可以将模型连接到少量示例提示：
    </p>
    <pre><code class="prism language-c">chain <span class="token operator">=</span> final_prompt <span class="token operator">|</span> <span class="token function">ChatOpenAI</span><span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o-mini"</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>

chain<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token operator">:</span> <span class="token string">"What's 3 🦜 3?"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     我们的输入会经过prompt富化后再询问模型，这样询问模型的效果会显著提高。
    </p>
    <h2>
     <a id="_1633">
     </a>
     文档加载器组件
    </h2>
    <p>
     LangChain与各种数据源有数百个集成，可以从中加载数据。每个DocumentLoader都有其特定的参数，但它们都可以通过.load方法以相同的方式调用。 一个示例用例如下：
    </p>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>document_loaders<span class="token punctuation">.</span>csv_loader import CSVLoader

loader <span class="token operator">=</span> <span class="token function">CSVLoader</span><span class="token punctuation">(</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  # <span class="token operator">&lt;</span><span class="token operator">--</span> Integration specific parameters here
<span class="token punctuation">)</span>
data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     做RAG的时候可以基于langChain文档加载器封装形成更加便捷的文档加载器。
    </p>
    <h3>
     <a id="PDF_1646">
     </a>
     加载PDF文件
    </h3>
    <p>
     可移植文档格式 (PDF)，标准化为ISO 32000，是由Adobe于1992年开发的一种文件格式，用于以独立于应用软件、硬件和操作系统的方式呈现文档，包括文本格式和图像。
    </p>
    <p>
     PDF中的文本通常通过文本框表示。它们也可能包含图像。PDF解析器可能会执行以下某种组合：
    </p>
    <ul>
     <li>
      通过启发式或机器学习推断将文本框聚合成行、段落和其他结构；
     </li>
     <li>
      对图像运行光学字符识别 (OCR)以检测其中的文本；
     </li>
     <li>
      将文本分类为段落、列表、表格或其他结构；
     </li>
     <li>
      将文本结构化为表格行和列，或键值对。
     </li>
    </ul>
    <p>
     LangChain与多种PDF解析器集成。一些解析器简单且相对低级；其他解析器将支持OCR和图像处理，或执行高级文档布局分析。正确的选择将取决于您的需求。
    </p>
    <p>
     <strong>
      我曾经负责写过某产品中的pdf解析器，具体可以参考：
      <a href="https://blog.csdn.net/General_zy/article/details/126415879">
       python操作PDF中各类文本内容的方法
      </a>
      ，其中OCR引擎使用huggingface上下载量较大的GOT-2.0，号称下一代OCR光学字符识别引擎。
     </strong>
    </p>
    <h4>
     <a id="_1660">
     </a>
     简单快速的文本提取
    </h4>
    <p>
     如果你的pdf只有简单的文本，那么下面的方法是合适的你的需求的。简单文本pdf对于熟悉pdf协议的人完全可以自己写代码实现，不过langChain已经为我们提供了与第三方包的桥梁。
    </p>
    <p>
     LangChain 文档加载器实现了lazy_load及其异步变体alazy_load，返回Document对象的迭代器。
    </p>
    <pre><code class="prism language-c">pip install <span class="token operator">-</span>qU pypdf
</code></pre>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>document_loaders import PyPDFLoader

loader <span class="token operator">=</span> <span class="token function">PyPDFLoader</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>
pages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
async <span class="token keyword">for</span> page in loader<span class="token punctuation">.</span><span class="token function">alazy_load</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    pages<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>page<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token function">print</span><span class="token punctuation">(</span>f<span class="token string">"{pages[0].metadata}\n"</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>pages<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>
</code></pre>
    <p>
     可以看到，每个文档的元数据存储了相应的页码。
    </p>
    <pre><code class="prism language-c"><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span>docs<span class="token operator">/</span>integrations<span class="token operator">/</span>document_loaders<span class="token operator">/</span>example_data<span class="token operator">/</span>layout<span class="token operator">-</span>parser<span class="token operator">-</span>paper<span class="token punctuation">.</span>pdf<span class="token char">', '</span>page'<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">}</span>

LayoutParser <span class="token operator">:</span> A Uniﬁed Toolkit <span class="token keyword">for</span> Deep
Learning Based Document Image Analysis
Zejiang <span class="token function">Shen1</span><span class="token punctuation">(</span> �<span class="token punctuation">)</span><span class="token punctuation">,</span> Ruochen Zhang2<span class="token punctuation">,</span> Melissa Dell3<span class="token punctuation">,</span> Benjamin Charles Germain
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre>
    <h5>
     <a id="PDF_1692">
     </a>
     PDF上的向量搜索
    </h5>
    <p>
     一旦我们将PDF加载到LangChain Document对象中，我们可以以通常的方式对其进行索引（例如，RAG应用）。下面我们使用OpenAI嵌入，尽管任何LangChain 嵌入模型都可以。
    </p>
    <pre><code class="prism language-c">pip install <span class="token operator">-</span>qU langchain<span class="token operator">-</span>openai
</code></pre>
    <pre><code class="prism language-c">import getpass
import os

<span class="token keyword">if</span> <span class="token string">"OPENAI_API_KEY"</span> not in os<span class="token punctuation">.</span>environ<span class="token operator">:</span>
    os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">]</span> <span class="token operator">=</span> getpass<span class="token punctuation">.</span><span class="token function">getpass</span><span class="token punctuation">(</span><span class="token string">"OpenAI API Key:"</span><span class="token punctuation">)</span>

from langchain_core<span class="token punctuation">.</span>vectorstores import InMemoryVectorStore
from langchain_openai import OpenAIEmbeddings

vector_store <span class="token operator">=</span> InMemoryVectorStore<span class="token punctuation">.</span><span class="token function">from_documents</span><span class="token punctuation">(</span>pages<span class="token punctuation">,</span> <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
docs <span class="token operator">=</span> vector_store<span class="token punctuation">.</span><span class="token function">similarity_search</span><span class="token punctuation">(</span><span class="token string">"What is LayoutParser?"</span><span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> doc in docs<span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>f'Page <span class="token punctuation">{<!-- --></span>doc<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">"page"</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>doc<span class="token punctuation">.</span>page_content<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">300</span><span class="token punctuation">]</span><span class="token punctuation">}</span>\n
</code></pre>
    <pre><code class="prism language-c">Page <span class="token number">13</span><span class="token operator">:</span> <span class="token number">14</span> Z<span class="token punctuation">.</span> Shen et al<span class="token punctuation">.</span>
<span class="token number">6</span> Conclusion
LayoutParser provides a comprehensive toolkit <span class="token keyword">for</span> deep learning<span class="token operator">-</span>based document
image analysis<span class="token punctuation">.</span> The oﬀ<span class="token operator">-</span>the<span class="token operator">-</span>shelf library is easy to install<span class="token punctuation">,</span> and can be used to
build ﬂexible and accurate pipelines <span class="token keyword">for</span> processing documents with complicated
structures<span class="token punctuation">.</span> It also supports hi

Page <span class="token number">0</span><span class="token operator">:</span> LayoutParser <span class="token operator">:</span> A Uniﬁed Toolkit <span class="token keyword">for</span> Deep
Learning Based Document Image Analysis
Zejiang <span class="token function">Shen1</span><span class="token punctuation">(</span> �<span class="token punctuation">)</span><span class="token punctuation">,</span> Ruochen Zhang2<span class="token punctuation">,</span> Melissa Dell3<span class="token punctuation">,</span> Benjamin Charles Germain
Lee4<span class="token punctuation">,</span> Jacob Carlson3<span class="token punctuation">,</span> and Weining Li5
</code></pre>
    <p>
     由于我们是按页进行向量化的，因此根据相似度匹配后，返回的也是页面，正常RAG往往会根据复杂的规则进行切分。
    </p>
    <h4>
     <a id="_1730">
     </a>
     布局分析和从图像中提取文本
    </h4>
    <p>
     如果您需要对文本进行更细粒度的分割（例如，分成不同的段落、标题、表格或其他结构）或需要从图像中提取文本，下面的方法是合适的。它将返回一个Document对象的列表，其中每个对象表示页面上的一个结构。文档的元数据存储了页码和与对象相关的其他信息（例如，在表格对象的情况下，它可能存储表格的行和列）。
    </p>
    <p>
     在底层，它使用langchain-unstructured库。
    </p>
    <p>
     Unstructured支持多个参数用于PDF解析：
    </p>
    <ul>
     <li>
      strategy（例如，“fast"或"hi-res”）
     </li>
     <li>
      API或本地处理。您需要一个API密钥才能使用API。
     </li>
    </ul>
    <p>
     对于某些文档类型（例如图像和 PDF），Unstructured 产品提供了多种预处理方式，这些方式通过
     <code>
      strategy
     </code>
     参数进行控制。
    </p>
    <p>
     以 PDF 文档为例，它们的质量和复杂性各不相同。在简单情况下，传统的 NLP 提取技术可能足以提取文档中的所有文本。但在其他情况下，则需要先进的图像转文本模型来处理 PDF。可以将这些策略理解为两种类型：“基于规则的”工作流（因此速度较快，即
     <code>
      fast
     </code>
     ），或“基于模型的”工作流（由于需要进行模型推理，因此速度较慢，但精度更高，即
     <code>
      hi_res
     </code>
     ）。在选择分区策略时，需要权衡质量和速度。例如，
     <code>
      fast
     </code>
     策略的速度大约是领先的图像转文本模型的 100 倍。
    </p>
    <p>
     可用选项：
    </p>
    <ul>
     <li>
      <strong>
       auto（默认策略）：
      </strong>
      <code>
       "auto"
      </code>
      策略会根据文档特性和函数的参数（kwargs）自动选择合适的分区策略。
     </li>
     <li>
      <strong>
       fast：
      </strong>
      <code>
       "fast"
      </code>
      采用基于规则的策略，利用传统 NLP 提取技术快速提取文本元素。不推荐用于基于图像的文件类型。
     </li>
     <li>
      <strong>
       hi_res：
      </strong>
      <code>
       "hi_res"
      </code>
      采用基于模型的策略来识别文档布局。其优势在于利用文档的布局信息获取更多文档元素的额外信息。如果您的应用场景对文档元素的分类准确性要求较高，建议使用该策略。
     </li>
     <li>
      <strong>
       ocr_only：
      </strong>
      <code>
       "ocr_only"
      </code>
      也是一种基于模型的策略，使用光学字符识别（OCR）技术从图像文件中提取文本。
     </li>
     <li>
      <strong>
       vlm：
      </strong>
      <code>
       "vlm"
      </code>
      使用视觉语言模型（VLM）从以下文件类型中提取文本：
      <code>
       .bmp
      </code>
      ,
      <code>
       .gif
      </code>
      ,
      <code>
       .heic
      </code>
      ,
      <code>
       .jpeg
      </code>
      ,
      <code>
       .jpg
      </code>
      ,
      <code>
       .pdf
      </code>
      ,
      <code>
       .png
      </code>
      ,
      <code>
       .tiff
      </code>
      ,
      <code>
       .webp
      </code>
      。
     </li>
    </ul>
    <p>
     可用于以下分区函数：
    </p>
    <table>
     <thead>
      <tr>
       <th>
        文档类型
       </th>
       <th>
        分区函数
       </th>
       <th>
        支持的策略
       </th>
       <th>
        是否支持表格
       </th>
       <th>
        选项
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        图像（.png/.jpg/.heic）
       </td>
       <td>
        <code>
         partition_image
        </code>
       </td>
       <td>
        <code>
         "auto"
        </code>
        ,
        <code>
         "hi_res"
        </code>
        ,
        <code>
         "ocr_only"
        </code>
       </td>
       <td>
        是
       </td>
       <td>
        编码、包含分页符、推断表格结构、OCR 语言、策略
       </td>
      </tr>
      <tr>
       <td>
        PDF（.pdf）
       </td>
       <td>
        <code>
         partition_pdf
        </code>
       </td>
       <td>
        <code>
         "auto"
        </code>
        ,
        <code>
         "fast"
        </code>
        ,
        <code>
         "hi_res"
        </code>
        ,
        <code>
         "ocr_only"
        </code>
       </td>
       <td>
        是
       </td>
       <td>
        编码、包含分页符、推断表格结构、最大分区、OCR 语言、策略
       </td>
      </tr>
     </tbody>
    </table>
    <pre><code class="prism language-c">pip install <span class="token operator">-</span>qU langchain<span class="token operator">-</span>unstructured
</code></pre>
    <pre><code class="prism language-c">import getpass
import os

<span class="token keyword">if</span> <span class="token string">"UNSTRUCTURED_API_KEY"</span> not in os<span class="token punctuation">.</span>environ<span class="token operator">:</span>
	# 到UNSTRUCTURED官网申请apikey
    os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"UNSTRUCTURED_API_KEY"</span><span class="token punctuation">]</span> <span class="token operator">=</span> getpass<span class="token punctuation">.</span><span class="token function">getpass</span><span class="token punctuation">(</span><span class="token string">"Unstructured API Key:"</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     与之前一样，我们初始化一个加载器并懒加载文档：
    </p>
    <pre><code class="prism language-c">from langchain_unstructured import UnstructuredLoader

loader <span class="token operator">=</span> <span class="token function">UnstructuredLoader</span><span class="token punctuation">(</span>
    file_path<span class="token operator">=</span>file_path<span class="token punctuation">,</span>
    strategy<span class="token operator">=</span><span class="token string">"hi_res"</span><span class="token punctuation">,</span>
    partition_via_api<span class="token operator">=</span>True<span class="token punctuation">,</span>
    coordinates<span class="token operator">=</span>True<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
docs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> doc in loader<span class="token punctuation">.</span><span class="token function">lazy_load</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    docs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>
</code></pre>
    <p>
     可以看出在解析过程中会请unstructured的官网：
    </p>
    <pre><code class="prism language-c">INFO<span class="token operator">:</span> Preparing to split document <span class="token keyword">for</span> partition<span class="token punctuation">.</span>
INFO<span class="token operator">:</span> Starting page number set to <span class="token number">1</span>
INFO<span class="token operator">:</span> Allow failed set to <span class="token number">0</span>
INFO<span class="token operator">:</span> Concurrency level set to <span class="token number">5</span>
INFO<span class="token operator">:</span> Splitting pages <span class="token number">1</span> to <span class="token number">16</span> <span class="token punctuation">(</span><span class="token number">16</span> total<span class="token punctuation">)</span>
INFO<span class="token operator">:</span> Determined optimal split size of <span class="token number">4</span> pages<span class="token punctuation">.</span>
INFO<span class="token operator">:</span> Partitioning <span class="token number">4</span> files with <span class="token number">4</span> <span class="token function">page</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> each<span class="token punctuation">.</span>
INFO<span class="token operator">:</span> Partitioning set #<span class="token number">1</span> <span class="token punctuation">(</span>pages <span class="token number">1</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
INFO<span class="token operator">:</span> Partitioning set #<span class="token number">2</span> <span class="token punctuation">(</span>pages <span class="token number">5</span><span class="token operator">-</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
INFO<span class="token operator">:</span> Partitioning set #<span class="token number">3</span> <span class="token punctuation">(</span>pages <span class="token number">9</span><span class="token operator">-</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
INFO<span class="token operator">:</span> Partitioning set #<span class="token number">4</span> <span class="token punctuation">(</span>pages <span class="token number">13</span><span class="token operator">-</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
INFO<span class="token operator">:</span> HTTP Request<span class="token operator">:</span> POST https<span class="token operator">:</span><span class="token comment">//api.unstructuredapp.io/general/v0/general "HTTP/1.1 200 OK"</span>
INFO<span class="token operator">:</span> HTTP Request<span class="token operator">:</span> POST https<span class="token operator">:</span><span class="token comment">//api.unstructuredapp.io/general/v0/general "HTTP/1.1 200 OK"</span>
INFO<span class="token operator">:</span> HTTP Request<span class="token operator">:</span> POST https<span class="token operator">:</span><span class="token comment">//api.unstructuredapp.io/general/v0/general "HTTP/1.1 200 OK"</span>
INFO<span class="token operator">:</span> HTTP Request<span class="token operator">:</span> POST https<span class="token operator">:</span><span class="token comment">//api.unstructuredapp.io/general/v0/general "HTTP/1.1 200 OK"</span>
INFO<span class="token operator">:</span> Successfully partitioned set #<span class="token number">1</span><span class="token punctuation">,</span> elements added to the final result<span class="token punctuation">.</span>
INFO<span class="token operator">:</span> Successfully partitioned set #<span class="token number">2</span><span class="token punctuation">,</span> elements added to the final result<span class="token punctuation">.</span>
INFO<span class="token operator">:</span> Successfully partitioned set #<span class="token number">3</span><span class="token punctuation">,</span> elements added to the final result<span class="token punctuation">.</span>
INFO<span class="token operator">:</span> Successfully partitioned set #<span class="token number">4</span><span class="token punctuation">,</span> elements added to the final result<span class="token punctuation">.</span>
</code></pre>
    <p>
     我们可以使用文档元数据从单个页面恢复内容：
    </p>
    <pre><code class="prism language-c">first_page_docs <span class="token operator">=</span> <span class="token punctuation">[</span>doc <span class="token keyword">for</span> doc in docs <span class="token keyword">if</span> doc<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"page_number"</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> doc in first_page_docs<span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>doc<span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>

LayoutParser<span class="token operator">:</span> A Uniﬁed Toolkit <span class="token keyword">for</span> Deep Learning Based Document Image Analysis
<span class="token number">1</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">2</span> n u J <span class="token number">1</span> <span class="token number">2</span> <span class="token punctuation">]</span> V C <span class="token punctuation">.</span> s c <span class="token punctuation">[</span> <span class="token number">2</span> v <span class="token number">8</span> <span class="token number">4</span> <span class="token number">3</span> <span class="token number">5</span> <span class="token number">1</span> <span class="token punctuation">.</span> <span class="token number">3</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token operator">:</span> v i X r a
Zejiang Shen® <span class="token punctuation">(</span><span class="token operator">&lt;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Ruochen Zhang<span class="token operator">?</span><span class="token punctuation">,</span> Melissa Dell®<span class="token punctuation">,</span> Benjamin Charles Germain Lee<span class="token operator">?</span><span class="token punctuation">,</span> Jacob Carlson®<span class="token punctuation">,</span> and Weining Li®
</code></pre>
    <h5>
     <a id="_1820">
     </a>
     提取表格和其他结构
    </h5>
    <p>
     上文中，我们加载的每个Document代表一个结构，如标题、段落或表格。下面，我们识别并提取一个表格，这个pdf可以在langChain的仓库中找到：
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/edf03685dba748869c9e4de105466c62.png"/>
    </p>
    <pre><code class="prism language-c">pip install <span class="token operator">-</span>qU matplotlib PyMuPDF pillow
</code></pre>
    <blockquote>
     <p>
      MuPDF 是一个轻量级的 PDF、XPS和电子书查看器。MuPDF 由软件库、命令行工具和各种平台的查看器组成。
     </p>
     <p>
      MuPDF
      <br/>
      中的渲染器专为高质量抗锯齿图形量身定制。它以精确到像素的几分之一内的度量和间距呈现文本，以在屏幕上再现打印页面的外观时获得最高保真度。
     </p>
    </blockquote>
    <pre><code class="prism language-c">import fitz
import matplotlib<span class="token punctuation">.</span>patches as patches
import matplotlib<span class="token punctuation">.</span>pyplot as plt
from PIL import Image
from langchain_unstructured import UnstructuredLoader


def <span class="token function">plot_pdf_with_boxes</span><span class="token punctuation">(</span>pdf_page<span class="token punctuation">,</span> segments<span class="token punctuation">)</span><span class="token operator">:</span>
    pix <span class="token operator">=</span> pdf_page<span class="token punctuation">.</span><span class="token function">get_pixmap</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    pil_image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token function">frombytes</span><span class="token punctuation">(</span><span class="token string">"RGB"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>pix<span class="token punctuation">.</span>width<span class="token punctuation">,</span> pix<span class="token punctuation">.</span>height<span class="token punctuation">]</span><span class="token punctuation">,</span> pix<span class="token punctuation">.</span>samples<span class="token punctuation">)</span>

    fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span><span class="token function">subplots</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span><span class="token function">imshow</span><span class="token punctuation">(</span>pil_image<span class="token punctuation">)</span>
    categories <span class="token operator">=</span> <span class="token function">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    category_to_color <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">"Title"</span><span class="token operator">:</span> <span class="token string">"orchid"</span><span class="token punctuation">,</span>
        <span class="token string">"Image"</span><span class="token operator">:</span> <span class="token string">"forestgreen"</span><span class="token punctuation">,</span>
        <span class="token string">"Table"</span><span class="token operator">:</span> <span class="token string">"tomato"</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span>
    <span class="token keyword">for</span> segment in segments<span class="token operator">:</span>
        points <span class="token operator">=</span> segment<span class="token punctuation">[</span><span class="token string">"coordinates"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"points"</span><span class="token punctuation">]</span>
        layout_width <span class="token operator">=</span> segment<span class="token punctuation">[</span><span class="token string">"coordinates"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"layout_width"</span><span class="token punctuation">]</span>
        layout_height <span class="token operator">=</span> segment<span class="token punctuation">[</span><span class="token string">"coordinates"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"layout_height"</span><span class="token punctuation">]</span>
        scaled_points <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token punctuation">(</span>x <span class="token operator">*</span> pix<span class="token punctuation">.</span>width <span class="token operator">/</span> layout_width<span class="token punctuation">,</span> y <span class="token operator">*</span> pix<span class="token punctuation">.</span>height <span class="token operator">/</span> layout_height<span class="token punctuation">)</span>
            <span class="token keyword">for</span> x<span class="token punctuation">,</span> y in points
        <span class="token punctuation">]</span>
        box_color <span class="token operator">=</span> category_to_color<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>segment<span class="token punctuation">[</span><span class="token string">"category"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"deepskyblue"</span><span class="token punctuation">)</span>
        categories<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>segment<span class="token punctuation">[</span><span class="token string">"category"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        rect <span class="token operator">=</span> patches<span class="token punctuation">.</span><span class="token function">Polygon</span><span class="token punctuation">(</span>
            scaled_points<span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> edgecolor<span class="token operator">=</span>box_color<span class="token punctuation">,</span> facecolor<span class="token operator">=</span><span class="token string">"none"</span>
        <span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span><span class="token function">add_patch</span><span class="token punctuation">(</span>rect<span class="token punctuation">)</span>

    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Make legend</span></span>
    legend_handles <span class="token operator">=</span> <span class="token punctuation">[</span>patches<span class="token punctuation">.</span><span class="token function">Patch</span><span class="token punctuation">(</span>color<span class="token operator">=</span><span class="token string">"deepskyblue"</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Text"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> category in <span class="token punctuation">[</span><span class="token string">"Title"</span><span class="token punctuation">,</span> <span class="token string">"Image"</span><span class="token punctuation">,</span> <span class="token string">"Table"</span><span class="token punctuation">]</span><span class="token operator">:</span>
        <span class="token keyword">if</span> category in categories<span class="token operator">:</span>
            legend_handles<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>
                patches<span class="token punctuation">.</span><span class="token function">Patch</span><span class="token punctuation">(</span>color<span class="token operator">=</span>category_to_color<span class="token punctuation">[</span>category<span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span>category<span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span><span class="token function">axis</span><span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span><span class="token function">legend</span><span class="token punctuation">(</span>handles<span class="token operator">=</span>legend_handles<span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">"upper right"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span><span class="token function">tight_layout</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>


def <span class="token function">render_page</span><span class="token punctuation">(</span>doc_list<span class="token operator">:</span> list<span class="token punctuation">,</span> page_number<span class="token operator">:</span> <span class="token keyword">int</span><span class="token punctuation">,</span> print_text<span class="token operator">=</span>True<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> None<span class="token operator">:</span>
    pdf_page <span class="token operator">=</span> fitz<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">load_page</span><span class="token punctuation">(</span>page_number <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>
    page_docs <span class="token operator">=</span> <span class="token punctuation">[</span>
        doc <span class="token keyword">for</span> doc in doc_list <span class="token keyword">if</span> doc<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"page_number"</span><span class="token punctuation">)</span> <span class="token operator">==</span> page_number
    <span class="token punctuation">]</span>
    segments <span class="token operator">=</span> <span class="token punctuation">[</span>doc<span class="token punctuation">.</span>metadata <span class="token keyword">for</span> doc in page_docs<span class="token punctuation">]</span>
    <span class="token function">plot_pdf_with_boxes</span><span class="token punctuation">(</span>pdf_page<span class="token punctuation">,</span> segments<span class="token punctuation">)</span>
    <span class="token keyword">if</span> print_text<span class="token operator">:</span>
        <span class="token keyword">for</span> doc in page_docs<span class="token operator">:</span>
            <span class="token function">print</span><span class="token punctuation">(</span>f<span class="token string">"{doc.page_content}\n"</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token char">'__main__'</span><span class="token operator">:</span>
    file_path <span class="token operator">=</span> <span class="token string">"layout-parser-paper.pdf"</span>
    loader <span class="token operator">=</span> <span class="token function">UnstructuredLoader</span><span class="token punctuation">(</span>
        file_path<span class="token operator">=</span>file_path<span class="token punctuation">,</span>
        strategy<span class="token operator">=</span><span class="token string">"hi_res"</span><span class="token punctuation">,</span>
        partition_via_api<span class="token operator">=</span>True<span class="token punctuation">,</span>
        coordinates<span class="token operator">=</span>True<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    docs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> doc in loader<span class="token punctuation">.</span><span class="token function">lazy_load</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
        docs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>

    <span class="token function">render_page</span><span class="token punctuation">(</span>docs<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     由于我没有apikey就不再演示，至于plot_pdf_with_boxes函数只是根据文档类型提取区域坐标进行展示的函数，我简化为如下：
    </p>
    <pre><code class="prism language-c">import matplotlib<span class="token punctuation">.</span>patches as patches
import matplotlib<span class="token punctuation">.</span>pyplot as plt
from PIL import Image


def <span class="token function">plot_image_with_boxes</span><span class="token punctuation">(</span>image_path<span class="token punctuation">,</span> boxes<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token string">""</span>"
    在图片上绘制指定的框。

    <span class="token operator">:</span>param image_path<span class="token operator">:</span> 图片路径
    <span class="token operator">:</span>param boxes<span class="token operator">:</span> 颜色 <span class="token operator">-&gt;</span> <span class="token punctuation">[</span>x1<span class="token punctuation">,</span> y1<span class="token punctuation">,</span> x2<span class="token punctuation">,</span> y2<span class="token punctuation">]</span> 的字典
    <span class="token string">""</span>"
    # 加载图片
    pil_image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span>

    # 创建画布
    # 单位是英寸（<span class="token number">1</span> 英寸 <span class="token operator">=</span> <span class="token number">100</span> dpi 约等于 <span class="token number">100</span> 像素）。
    fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span><span class="token function">subplots</span><span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span><span class="token function">imshow</span><span class="token punctuation">(</span>pil_image<span class="token punctuation">)</span>

    # 绘制矩形框
    <span class="token keyword">for</span> color<span class="token punctuation">,</span> coords in boxes<span class="token punctuation">.</span><span class="token function">items</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
        x1<span class="token punctuation">,</span> y1<span class="token punctuation">,</span> x2<span class="token punctuation">,</span> y2 <span class="token operator">=</span> coords
        width<span class="token punctuation">,</span> height <span class="token operator">=</span> x2 <span class="token operator">-</span> x1<span class="token punctuation">,</span> y2 <span class="token operator">-</span> y1

        # 画框
        rect <span class="token operator">=</span> patches<span class="token punctuation">.</span><span class="token function">Rectangle</span><span class="token punctuation">(</span>
            <span class="token punctuation">(</span>x1<span class="token punctuation">,</span> y1<span class="token punctuation">)</span><span class="token punctuation">,</span> width<span class="token punctuation">,</span> height<span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> edgecolor<span class="token operator">=</span>color<span class="token punctuation">,</span> facecolor<span class="token operator">=</span><span class="token string">"none"</span>
        <span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span><span class="token function">add_patch</span><span class="token punctuation">(</span>rect<span class="token punctuation">)</span>

    # 去掉坐标轴
    ax<span class="token punctuation">.</span><span class="token function">axis</span><span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>


# 示例输入
boxes <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"red"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"blue"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">450</span><span class="token punctuation">,</span> <span class="token number">250</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"green"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">150</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">350</span><span class="token punctuation">,</span> <span class="token number">450</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token operator">:</span>
    <span class="token function">plot_image_with_boxes</span><span class="token punctuation">(</span><span class="token string">"1.png"</span><span class="token punctuation">,</span> boxes<span class="token punctuation">)</span>
</code></pre>
    <p>
     需要注意的是：在 Matplotlib 中，像素坐标原点 (0, 0) 默认在 图片的左上角，x 轴向右递增，y 轴向下递增。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/f351dabbabd2467282477097109b52ac.png">
      <br/>
      下面给出langChain官网的案例：
     </img>
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/c8fa68d432b3495190d69223d1bec904.png"/>
    </p>
    <pre><code class="prism language-c">LayoutParser<span class="token operator">:</span> A Uniﬁed Toolkit <span class="token keyword">for</span> DL<span class="token operator">-</span>Based DIA

<span class="token number">5</span>

Table <span class="token number">1</span><span class="token operator">:</span> Current layout detection models in the LayoutParser model zoo

Dataset Base Model1 Large Model Notes PubLayNet <span class="token punctuation">[</span><span class="token number">38</span><span class="token punctuation">]</span> PRImA <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> Newspaper <span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">]</span> TableBank <span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">]</span> HJDataset <span class="token punctuation">[</span><span class="token number">31</span><span class="token punctuation">]</span> F <span class="token operator">/</span> M M F F F <span class="token operator">/</span> M M <span class="token operator">-</span> <span class="token operator">-</span> F <span class="token operator">-</span> Layouts of modern scientiﬁc documents Layouts of scanned modern magazines and scientiﬁc reports Layouts of scanned US newspapers from the <span class="token number">20</span>th century Table region on modern scientiﬁc and business document Layouts of history Japanese documents

<span class="token number">1</span> For each dataset<span class="token punctuation">,</span> we train several models of diﬀerent sizes <span class="token keyword">for</span> diﬀerent <span class="token function">needs</span> <span class="token punctuation">(</span>the trade<span class="token operator">-</span>oﬀ between accuracy vs<span class="token punctuation">.</span> computational cost<span class="token punctuation">)</span><span class="token punctuation">.</span> For “base model” and “large model”<span class="token punctuation">,</span> we refer to using the ResNet <span class="token number">50</span> or ResNet <span class="token number">101</span> backbones <span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">,</span> respectively<span class="token punctuation">.</span> One can train models of diﬀerent architectures<span class="token punctuation">,</span> like Faster R<span class="token operator">-</span>CNN <span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">]</span> <span class="token punctuation">(</span>F<span class="token punctuation">)</span> and Mask R<span class="token operator">-</span>CNN <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">]</span> <span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">.</span> For example<span class="token punctuation">,</span> an F in the Large Model column indicates it has a Faster R<span class="token operator">-</span>CNN model trained using the ResNet <span class="token number">101</span> backbone<span class="token punctuation">.</span> The platform is maintained and a number of additions will be made to the model zoo in coming months<span class="token punctuation">.</span>

layout data structures<span class="token punctuation">,</span> which are optimized <span class="token keyword">for</span> eﬃciency and versatility<span class="token punctuation">.</span> <span class="token number">3</span><span class="token punctuation">)</span> When necessary<span class="token punctuation">,</span> users can employ existing or customized OCR models via the uniﬁed API provided in the OCR module<span class="token punctuation">.</span> <span class="token number">4</span><span class="token punctuation">)</span> LayoutParser comes with a set of utility functions <span class="token keyword">for</span> the visualization and storage of the layout data<span class="token punctuation">.</span> <span class="token number">5</span><span class="token punctuation">)</span> LayoutParser is also highly customizable<span class="token punctuation">,</span> via its integration with functions <span class="token keyword">for</span> layout data annotation and model training<span class="token punctuation">.</span> We now provide detailed descriptions <span class="token keyword">for</span> each component<span class="token punctuation">.</span>

<span class="token number">3.1</span> Layout Detection Models

In LayoutParser<span class="token punctuation">,</span> a layout model takes a document image as an input and generates a list of rectangular boxes <span class="token keyword">for</span> the target content regions<span class="token punctuation">.</span> Diﬀerent from traditional methods<span class="token punctuation">,</span> it relies on deep convolutional neural networks rather than manually curated rules to identify content regions<span class="token punctuation">.</span> It is formulated as an object detection problem and state<span class="token operator">-</span>of<span class="token operator">-</span>the<span class="token operator">-</span>art models like Faster R<span class="token operator">-</span>CNN <span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">]</span> and Mask R<span class="token operator">-</span>CNN <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">]</span> are used<span class="token punctuation">.</span> This yields prediction results of high accuracy and makes it possible to build a concise<span class="token punctuation">,</span> generalized interface <span class="token keyword">for</span> layout detection<span class="token punctuation">.</span> LayoutParser<span class="token punctuation">,</span> built upon Detectron2 <span class="token punctuation">[</span><span class="token number">35</span><span class="token punctuation">]</span><span class="token punctuation">,</span> provides a minimal API that can perform layout detection with only four lines of code in Python<span class="token operator">:</span>

<span class="token number">1</span> import layoutparser as lp <span class="token number">2</span> image <span class="token operator">=</span> cv2 <span class="token punctuation">.</span> <span class="token function">imread</span> <span class="token punctuation">(</span> <span class="token string">" image_file "</span> <span class="token punctuation">)</span> # load images <span class="token number">3</span> model <span class="token operator">=</span> lp <span class="token punctuation">.</span> De t e c tro n2 Lay outM <span class="token function">odel</span> <span class="token punctuation">(</span> <span class="token string">" lp :// PubLayNet / f as t er _ r c nn _ R _ 50 _ F P N_ 3 x / config "</span> <span class="token punctuation">)</span> <span class="token number">4</span> <span class="token number">5</span> layout <span class="token operator">=</span> model <span class="token punctuation">.</span> <span class="token function">detect</span> <span class="token punctuation">(</span> image <span class="token punctuation">)</span>

LayoutParser provides a wealth of pre<span class="token operator">-</span>trained model weights using various datasets covering diﬀerent languages<span class="token punctuation">,</span> time periods<span class="token punctuation">,</span> and document types<span class="token punctuation">.</span> Due to domain shift <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span> the prediction performance can notably drop when models are ap<span class="token operator">-</span> plied to target samples that are signiﬁcantly diﬀerent from the training dataset<span class="token punctuation">.</span> As document structures and layouts vary greatly in diﬀerent domains<span class="token punctuation">,</span> it is important to select models trained on a dataset similar to the test samples<span class="token punctuation">.</span> A semantic syntax is used <span class="token keyword">for</span> initializing the model weights in LayoutParser<span class="token punctuation">,</span> using both the dataset name and model name lp<span class="token operator">:</span><span class="token comment">//&lt;dataset-name&gt;/&lt;model-architecture-name&gt;.</span>
</code></pre>
    <p>
     尽管表格文本在文档内容中被压缩为一个字符串，但元数据包含其行和列的表示：
    </p>
    <pre><code class="prism language-c">from IPython<span class="token punctuation">.</span>display import HTML<span class="token punctuation">,</span> display

segments <span class="token operator">=</span> <span class="token punctuation">[</span>
    doc<span class="token punctuation">.</span>metadata
    <span class="token keyword">for</span> doc in docs
    <span class="token keyword">if</span> doc<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"page_number"</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">5</span> and doc<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"category"</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"Table"</span>
<span class="token punctuation">]</span>

<span class="token function">display</span><span class="token punctuation">(</span><span class="token function">HTML</span><span class="token punctuation">(</span>segments<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text_as_html"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     利用Ipython即可展示出来：
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/e3346b51f62643d89f21ae52a209cada.png"/>
    </p>
    <h5>
     <a id="_2003">
     </a>
     从特定部分提取文本
    </h5>
    <p>
     结构可能具有父子关系——例如，一个段落可能属于一个有标题的部分。如果某个部分特别重要（例如，用于索引），我们可以隔离相应的 Document 对象。
    </p>
    <p>
     下面，我们提取与文档的“结论”部分相关的所有文本：
    </p>
    <pre><code class="prism language-c"><span class="token function">render_page</span><span class="token punctuation">(</span>docs<span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> print_text<span class="token operator">=</span>False<span class="token punctuation">)</span>
</code></pre>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/bc91ba9e0da7427db82a07439e42c020.png"/>
    </p>
    <pre><code class="prism language-c">conclusion_docs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
parent_id <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>
<span class="token keyword">for</span> doc in docs<span class="token operator">:</span>
    <span class="token keyword">if</span> doc<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">"category"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"Title"</span> and <span class="token string">"Conclusion"</span> in doc<span class="token punctuation">.</span>page_content<span class="token operator">:</span>
        parent_id <span class="token operator">=</span> doc<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">"element_id"</span><span class="token punctuation">]</span>
    <span class="token keyword">if</span> doc<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"parent_id"</span><span class="token punctuation">)</span> <span class="token operator">==</span> parent_id<span class="token operator">:</span>
        conclusion_docs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>

<span class="token keyword">for</span> doc in conclusion_docs<span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>doc<span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">LayoutParser provides a comprehensive toolkit <span class="token keyword">for</span> deep learning<span class="token operator">-</span>based document image analysis<span class="token punctuation">.</span> The oﬀ<span class="token operator">-</span>the<span class="token operator">-</span>shelf library is easy to install<span class="token punctuation">,</span> and can be used to build ﬂexible and accurate pipelines <span class="token keyword">for</span> processing documents with complicated structures<span class="token punctuation">.</span> It also supports high<span class="token operator">-</span>level customization and enables easy labeling and training of DL models on unique document image datasets<span class="token punctuation">.</span> The LayoutParser community platform facilitates sharing DL models and DIA pipelines<span class="token punctuation">,</span> inviting discussion and promoting code reproducibility and reusability<span class="token punctuation">.</span> The LayoutParser team is committed to keeping the library updated continuously and bringing the most recent advances in DL<span class="token operator">-</span>based DIA<span class="token punctuation">,</span> such as multi<span class="token operator">-</span>modal document modeling <span class="token punctuation">[</span><span class="token number">37</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span> <span class="token punctuation">(</span>an upcoming priority<span class="token punctuation">)</span><span class="token punctuation">,</span> to a diverse audience of end<span class="token operator">-</span>users<span class="token punctuation">.</span>
Acknowledgements We thank the anonymous reviewers <span class="token keyword">for</span> their comments and suggestions<span class="token punctuation">.</span> This project is supported in part by NSF Grant OIA<span class="token operator">-</span><span class="token number">2033558</span> and funding from the Harvard Data Science Initiative and Harvard Catalyst<span class="token punctuation">.</span> Zejiang Shen thanks Doug Downey <span class="token keyword">for</span> suggestions<span class="token punctuation">.</span>
</code></pre>
    <h5>
     <a id="_2030">
     </a>
     从图像中提取文本
    </h5>
    <p>
     对图像运行OCR，从中提取文本：
    </p>
    <pre><code class="prism language-c"><span class="token function">render_page</span><span class="token punctuation">(</span>docs<span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/06bd09cc368a409fbfa4ad69ca4e2336.png"/>
     <br/>
     请注意，右侧图中的文本已提取并纳入Document的内容中：
    </p>
    <pre><code class="prism language-c">LayoutParser<span class="token operator">:</span> A Uniﬁed Toolkit <span class="token keyword">for</span> DL<span class="token operator">-</span>Based DIA

focuses on precision<span class="token punctuation">,</span> eﬃciency<span class="token punctuation">,</span> and robustness<span class="token punctuation">.</span> The target documents may have complicated structures<span class="token punctuation">,</span> and may require training multiple layout detection models to achieve the optimal accuracy<span class="token punctuation">.</span> Light<span class="token operator">-</span>weight pipelines are built <span class="token keyword">for</span> relatively simple documents<span class="token punctuation">,</span> with an emphasis on development ease<span class="token punctuation">,</span> speed and ﬂexibility<span class="token punctuation">.</span> Ideally one only needs to use existing resources<span class="token punctuation">,</span> and model training should be avoided<span class="token punctuation">.</span> Through two exemplar projects<span class="token punctuation">,</span> we show how practitioners in both academia and industry can easily build such pipelines using LayoutParser and extract high<span class="token operator">-</span>quality structured document data <span class="token keyword">for</span> their downstream tasks<span class="token punctuation">.</span> The source code <span class="token keyword">for</span> these projects will be publicly available in the LayoutParser community hub<span class="token punctuation">.</span>

<span class="token number">11</span>

<span class="token number">5.1</span> A Comprehensive Historical Document Digitization Pipeline

The digitization of historical documents can unlock valuable data that can shed light on many important social<span class="token punctuation">,</span> economic<span class="token punctuation">,</span> and historical questions<span class="token punctuation">.</span> Yet due to scan noises<span class="token punctuation">,</span> page wearing<span class="token punctuation">,</span> and the prevalence of complicated layout structures<span class="token punctuation">,</span> ob<span class="token operator">-</span> taining a structured representation of historical document scans is often extremely complicated<span class="token punctuation">.</span> In this example<span class="token punctuation">,</span> LayoutParser was used to develop a comprehensive pipeline<span class="token punctuation">,</span> shown in Figure <span class="token number">5</span><span class="token punctuation">,</span> to gener<span class="token operator">-</span> ate high<span class="token operator">-</span>quality structured data from historical Japanese ﬁrm ﬁnancial ta<span class="token operator">-</span> bles with complicated layouts<span class="token punctuation">.</span> The pipeline applies two layout models to identify diﬀerent levels of document structures and two customized OCR engines <span class="token keyword">for</span> optimized character recog<span class="token operator">-</span> nition accuracy<span class="token punctuation">.</span>

‘Active Learning Layout Annotate Layout Dataset <span class="token operator">|</span> <span class="token operator">+</span>—— Annotation Toolkit A4 Deep Learning Layout Layout Detection Model Training <span class="token operator">&amp;</span> Inference<span class="token punctuation">,</span> A Post<span class="token operator">-</span>processing — Handy Data Structures <span class="token operator">&amp;</span> \ Lo orajport <span class="token number">7</span> <span class="token punctuation">)</span> Al Pls <span class="token keyword">for</span> Layout Data A4 Default and Customized Text Recognition <span class="token number">0</span>CR Models ¥ Visualization <span class="token operator">&amp;</span> Export Layout Structure Visualization <span class="token operator">&amp;</span> Storage The Japanese Document Helpful LayoutParser Modules Digitization Pipeline

As shown in Figure <span class="token number">4</span> <span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">,</span> the document contains columns of text written vertically <span class="token number">15</span><span class="token punctuation">,</span> a common style in Japanese<span class="token punctuation">.</span> Due to scanning noise and archaic printing technology<span class="token punctuation">,</span> the columns can be skewed or have vari<span class="token operator">-</span> able widths<span class="token punctuation">,</span> and hence cannot be eas<span class="token operator">-</span> ily identiﬁed via rule<span class="token operator">-</span>based methods<span class="token punctuation">.</span> Within each column<span class="token punctuation">,</span> words are sepa<span class="token operator">-</span> rated by white spaces of variable size<span class="token punctuation">,</span> and the vertical positions of objects can be an indicator of their layout type<span class="token punctuation">.</span>

Fig<span class="token punctuation">.</span> <span class="token number">5</span><span class="token operator">:</span> Illustration of how LayoutParser helps with the historical document digi<span class="token operator">-</span> tization pipeline<span class="token punctuation">.</span>

<span class="token number">15</span> A document page consists of eight rows like this<span class="token punctuation">.</span> For simplicity we skip the row segmentation discussion and refer readers to the source code when available<span class="token punctuation">.</span>
</code></pre>
    <p>
     本地解析图片需要安装额外的依赖项。
    </p>
    <p>
     Poppler（PDF分析）
    </p>
    <ul>
     <li>
      Linux: apt-get install poppler-utils
     </li>
     <li>
      Mac: brew install poppler
     </li>
     <li>
      Windows: https://github.com/oschwartz10612/poppler-windows
     </li>
    </ul>
    <p>
     Tesseract（OCR）
    </p>
    <ul>
     <li>
      Linux: apt-get install tesseract-ocr
     </li>
     <li>
      Mac: brew install tesseract
     </li>
     <li>
      Windows: https://github.com/UB-Mannheim/tesseract/wiki#tesseract-installer-for-windows
     </li>
    </ul>
    <p>
     还需要安装 unstructured PDF 附加组件：
    </p>
    <pre><code class="prism language-c">pip install <span class="token operator">-</span>qU <span class="token string">"unstructured[pdf]"</span>
</code></pre>
    <p>
     我们可以以类似的方式使用 UnstructuredLoader，不需要 API 密钥和 partition_via_api 设置：
    </p>
    <pre><code class="prism language-c">loader_local <span class="token operator">=</span> <span class="token function">UnstructuredLoader</span><span class="token punctuation">(</span>
    file_path<span class="token operator">=</span>file_path<span class="token punctuation">,</span>
    strategy<span class="token operator">=</span><span class="token string">"hi_res"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
docs_local <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> doc in loader_local<span class="token punctuation">.</span><span class="token function">lazy_load</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    docs_local<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">WARNING<span class="token operator">:</span> This function will be deprecated in a future release and `unstructured` will simply use the DEFAULT_MODEL from `unstructured_inference<span class="token punctuation">.</span>model<span class="token punctuation">.</span>base` to set <span class="token keyword">default</span> model name
INFO<span class="token operator">:</span> Reading PDF <span class="token keyword">for</span> file<span class="token operator">:</span> <span class="token operator">/</span>Users<span class="token operator">/</span>chestercurme<span class="token operator">/</span>repos<span class="token operator">/</span>langchain<span class="token operator">/</span>libs<span class="token operator">/</span>community<span class="token operator">/</span>tests<span class="token operator">/</span>integration_tests<span class="token operator">/</span>examples<span class="token operator">/</span>layout<span class="token operator">-</span>parser<span class="token operator">-</span>paper<span class="token punctuation">.</span>pdf <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
INFO<span class="token operator">:</span> Detecting page elements <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
INFO<span class="token operator">:</span> Detecting page elements <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
INFO<span class="token operator">:</span> Detecting page elements <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
INFO<span class="token operator">:</span> Detecting page elements <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre>
    <h5>
     <a id="_2096">
     </a>
     多模态模型的使用
    </h5>
    <p>
     许多现代大型语言模型支持对多模态输入（例如，图像）的推理。原则上，我们可以使用任何支持多模态输入的 LangChain 聊天模型。
    </p>
    <p>
     定义一个简短的工具函数，将 PDF 页面转换为 base64 编码的图像：
    </p>
    <pre><code class="prism language-c">import base64
import io

import fitz
from PIL import Image


def <span class="token function">pdf_page_to_base64</span><span class="token punctuation">(</span>pdf_path<span class="token operator">:</span> str<span class="token punctuation">,</span> page_number<span class="token operator">:</span> <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token operator">:</span>
    pdf_document <span class="token operator">=</span> fitz<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>pdf_path<span class="token punctuation">)</span>
    page <span class="token operator">=</span> pdf_document<span class="token punctuation">.</span><span class="token function">load_page</span><span class="token punctuation">(</span>page_number <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>  # input is one<span class="token operator">-</span>indexed
    pix <span class="token operator">=</span> page<span class="token punctuation">.</span><span class="token function">get_pixmap</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token function">frombytes</span><span class="token punctuation">(</span><span class="token string">"RGB"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>pix<span class="token punctuation">.</span>width<span class="token punctuation">,</span> pix<span class="token punctuation">.</span>height<span class="token punctuation">]</span><span class="token punctuation">,</span> pix<span class="token punctuation">.</span>samples<span class="token punctuation">)</span>

    buffer <span class="token operator">=</span> io<span class="token punctuation">.</span><span class="token function">BytesIO</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    img<span class="token punctuation">.</span><span class="token function">save</span><span class="token punctuation">(</span>buffer<span class="token punctuation">,</span> format<span class="token operator">=</span><span class="token string">"PNG"</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> base64<span class="token punctuation">.</span><span class="token function">b64encode</span><span class="token punctuation">(</span>buffer<span class="token punctuation">.</span><span class="token function">getvalue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">decode</span><span class="token punctuation">(</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">from IPython<span class="token punctuation">.</span>display import Image as IPImage
from IPython<span class="token punctuation">.</span>display import display

base64_image <span class="token operator">=</span> <span class="token function">pdf_page_to_base64</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span>
<span class="token function">display</span><span class="token punctuation">(</span><span class="token function">IPImage</span><span class="token punctuation">(</span>data<span class="token operator">=</span>base64<span class="token punctuation">.</span><span class="token function">b64decode</span><span class="token punctuation">(</span>base64_image<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     然后我们可以以正常查询模型。下面我们向它询问与页面上的图表相关的问题。
    </p>
    <pre><code class="prism language-c">from langchain_openai import ChatOpenAI

llm <span class="token operator">=</span> <span class="token function">ChatOpenAI</span><span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o-mini"</span><span class="token punctuation">)</span>

from langchain_core<span class="token punctuation">.</span>messages import HumanMessage

query <span class="token operator">=</span> <span class="token string">"What is the name of the first step in the pipeline?"</span>

message <span class="token operator">=</span> <span class="token function">HumanMessage</span><span class="token punctuation">(</span>
    content<span class="token operator">=</span><span class="token punctuation">[</span>
        <span class="token punctuation">{<!-- --></span><span class="token string">"type"</span><span class="token operator">:</span> <span class="token string">"text"</span><span class="token punctuation">,</span> <span class="token string">"text"</span><span class="token operator">:</span> query<span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">{<!-- --></span>
            <span class="token string">"type"</span><span class="token operator">:</span> <span class="token string">"image_url"</span><span class="token punctuation">,</span>
            <span class="token string">"image_url"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"url"</span><span class="token operator">:</span> f<span class="token string">"data:image/jpeg;base64,{base64_image}"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
response <span class="token operator">=</span> llm<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span><span class="token punctuation">[</span>message<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">INFO<span class="token operator">:</span> HTTP Request<span class="token operator">:</span> POST https<span class="token operator">:</span><span class="token comment">//api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"</span>
``````output
The first step in the pipeline is <span class="token string">"Annotate Layout Dataset."</span>
</code></pre>
    <h3>
     <a id="_2157">
     </a>
     加载网页
    </h3>
    <p>
     LangChain 集成了一系列适合网页的解析器。
    </p>
    <ul>
     <li>
      简单快速 解析，每个网页一个 Document，其内容表示为“扁平化”字符串；
     </li>
     <li>
      高级 解析，每个页面多个 Document 对象，允许识别和遍历部分、链接、表格和其他结构。、
     </li>
    </ul>
    <p>
     对于“简单快速”解析，我们需要 langchain-community 和 beautifulsoup4 库：
    </p>
    <pre><code class="prism language-c">pip install <span class="token operator">-</span>qU langchain<span class="token operator">-</span>community beautifulsoup4
</code></pre>
    <p>
     对于高级解析，我们将使用 langchain-unstructured：
    </p>
    <pre><code class="prism language-c">pip install <span class="token operator">-</span>qU langchain<span class="token operator">-</span>unstructured
</code></pre>
    <h4>
     <a id="_2174">
     </a>
     简单快速的文本提取
    </h4>
    <p>
     在底层，它使用 beautifulsoup4：
    </p>
    <pre><code class="prism language-c">import bs4
from langchain_community<span class="token punctuation">.</span>document_loaders import WebBaseLoader

page_url <span class="token operator">=</span> <span class="token string">"https://python.langchain.com/docs/how_to/chatbots_memory/"</span>

loader <span class="token operator">=</span> <span class="token function">WebBaseLoader</span><span class="token punctuation">(</span>web_paths<span class="token operator">=</span><span class="token punctuation">[</span>page_url<span class="token punctuation">]</span><span class="token punctuation">)</span>
docs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
async <span class="token keyword">for</span> doc in loader<span class="token punctuation">.</span><span class="token function">alazy_load</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    docs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>

assert <span class="token function">len</span><span class="token punctuation">(</span>docs<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span>
doc <span class="token operator">=</span> docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token function">print</span><span class="token punctuation">(</span>f<span class="token string">"{doc.metadata}\n"</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>doc<span class="token punctuation">.</span>page_content<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">500</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">strip</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> 'https<span class="token operator">:</span><span class="token comment">//python.langchain.com/docs/how_to/chatbots_memory/', 'title': 'How to add memory to chatbots | \uf8ffü¶úÔ∏è\uf8ffüîó LangChain', 'description': 'A key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including:', 'language': 'en'}</span>

How to add memory to chatbots <span class="token operator">|</span> ü¶úÔ∏èüîó LangChain
</code></pre>
    <p>
     这基本上是页面 HTML 中文本的转储。它可能包含多余的信息，如标题和导航栏。可以通过 BeautifulSoup 指定所需的
     <code>
      &lt;div&gt;
     </code>
     类和其他参数：
    </p>
    <pre><code class="prism language-c">loader <span class="token operator">=</span> <span class="token function">WebBaseLoader</span><span class="token punctuation">(</span>
    web_paths<span class="token operator">=</span><span class="token punctuation">[</span>page_url<span class="token punctuation">]</span><span class="token punctuation">,</span>
    bs_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
        <span class="token string">"parse_only"</span><span class="token operator">:</span> bs4<span class="token punctuation">.</span><span class="token function">SoupStrainer</span><span class="token punctuation">(</span>class_<span class="token operator">=</span><span class="token string">"theme-doc-markdown markdown"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    bs_get_text_kwargs<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">"separator"</span><span class="token operator">:</span> <span class="token string">" | "</span><span class="token punctuation">,</span> <span class="token string">"strip"</span><span class="token operator">:</span> True<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

docs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
async <span class="token keyword">for</span> doc in loader<span class="token punctuation">.</span><span class="token function">alazy_load</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    docs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>

assert <span class="token function">len</span><span class="token punctuation">(</span>docs<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span>
doc <span class="token operator">=</span> docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     我们可以使用各种设置对 WebBaseLoader 进行参数化，允许指定请求头、速率限制、解析器和其他 BeautifulSoup 的关键字参数。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/7f9d41e96741425e9cf71f575fc0046c.png"/>
    </p>
    <h4>
     <a id="_2221">
     </a>
     高级解析
    </h4>
    <p>
     如果我们想对页面内容进行更细粒度的控制或处理，这种方法是合适的。加载器将文档切分为多个Document，表示页面上的不同结构。这些结构可以包括章节标题及其对应的主体文本、列表或枚举、表格等。
    </p>
    <p>
     在底层，它使用 langchain-unstructured 库。
    </p>
    <pre><code class="prism language-c">from langchain_unstructured import UnstructuredLoader

page_url <span class="token operator">=</span> <span class="token string">"https://python.langchain.com/docs/how_to/chatbots_memory/"</span>
loader <span class="token operator">=</span> <span class="token function">UnstructuredLoader</span><span class="token punctuation">(</span>web_url<span class="token operator">=</span>page_url<span class="token punctuation">)</span>

docs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
async <span class="token keyword">for</span> doc in loader<span class="token punctuation">.</span><span class="token function">alazy_load</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    docs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">INFO<span class="token operator">:</span> Note<span class="token operator">:</span> NumExpr detected <span class="token number">12</span> cores but <span class="token string">"NUMEXPR_MAX_THREADS"</span> not set<span class="token punctuation">,</span> so enforcing safe limit of <span class="token number">8.</span>
INFO<span class="token operator">:</span> NumExpr defaulting to <span class="token number">8</span> threads<span class="token punctuation">.</span>
</code></pre>
    <h5>
     <a id="_2241">
     </a>
     从特定部分提取内容
    </h5>
    <p>
     每个 Document 对象代表页面的一个元素。其元数据包含有用的信息，例如其类别：
    </p>
    <pre><code class="prism language-c"><span class="token keyword">for</span> doc in docs<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>f'<span class="token punctuation">{<!-- --></span>doc<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">"category"</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>doc<span class="token punctuation">.</span>page_content<span class="token punctuation">}</span>'<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">Title<span class="token operator">:</span> How to add memory to chatbots
NarrativeText<span class="token operator">:</span> A key feature of chatbots is their ability to use content of previous conversation turns as context<span class="token punctuation">.</span> This state management can take several forms<span class="token punctuation">,</span> including<span class="token operator">:</span>
ListItem<span class="token operator">:</span> Simply stuffing previous messages into a chat model prompt<span class="token punctuation">.</span>
ListItem<span class="token operator">:</span> The above<span class="token punctuation">,</span> but trimming old messages to reduce the amount of distracting information the model has to deal with<span class="token punctuation">.</span>
ListItem<span class="token operator">:</span> More complex modifications like synthesizing summaries <span class="token keyword">for</span> <span class="token keyword">long</span> running conversations<span class="token punctuation">.</span>
</code></pre>
    <p>
     元素之间也可能存在父子关系，一个段落可能属于一个有标题的部分，下面我们加载两个网页的“设置”部分的内容：
    </p>
    <pre><code class="prism language-c">from typing import List

from langchain_core<span class="token punctuation">.</span>documents import Document


async def <span class="token function">_get_setup_docs_from_url</span><span class="token punctuation">(</span>url<span class="token operator">:</span> str<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> List<span class="token punctuation">[</span>Document<span class="token punctuation">]</span><span class="token operator">:</span>
    loader <span class="token operator">=</span> <span class="token function">UnstructuredLoader</span><span class="token punctuation">(</span>web_url<span class="token operator">=</span>url<span class="token punctuation">)</span>

    setup_docs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    parent_id <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>
    async <span class="token keyword">for</span> doc in loader<span class="token punctuation">.</span><span class="token function">alazy_load</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token keyword">if</span> doc<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">"category"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"Title"</span> and doc<span class="token punctuation">.</span>page_content<span class="token punctuation">.</span><span class="token function">startswith</span><span class="token punctuation">(</span><span class="token string">"Setup"</span><span class="token punctuation">)</span><span class="token operator">:</span>
            parent_id <span class="token operator">=</span> doc<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">"element_id"</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> doc<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"parent_id"</span><span class="token punctuation">)</span> <span class="token operator">==</span> parent_id<span class="token operator">:</span>
            setup_docs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>

    <span class="token keyword">return</span> setup_docs


page_urls <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"https://python.langchain.com/docs/how_to/chatbots_memory/"</span><span class="token punctuation">,</span>
    <span class="token string">"https://python.langchain.com/docs/how_to/chatbots_tools/"</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
setup_docs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> url in page_urls<span class="token operator">:</span>
    page_setup_docs <span class="token operator">=</span> await <span class="token function">_get_setup_docs_from_url</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span>
    setup_docs<span class="token punctuation">.</span><span class="token function">extend</span><span class="token punctuation">(</span>page_setup_docs<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">from collections import defaultdict

setup_text <span class="token operator">=</span> <span class="token function">defaultdict</span><span class="token punctuation">(</span>str<span class="token punctuation">)</span>

<span class="token keyword">for</span> doc in setup_docs<span class="token operator">:</span>
    url <span class="token operator">=</span> doc<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">"url"</span><span class="token punctuation">]</span>
    setup_text<span class="token punctuation">[</span>url<span class="token punctuation">]</span> <span class="token operator">+=</span> f<span class="token string">"{doc.page_content}\n"</span>

<span class="token function">dict</span><span class="token punctuation">(</span>setup_text<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">{<!-- --></span>'https<span class="token operator">:</span><span class="token comment">//python.langchain.com/docs/how_to/chatbots_memory/': "You'll need to install a few packages, and have your OpenAI API key set as an environment variable named OPENAI_API_KEY:\n%pip install --upgrade --quiet langchain langchain-openai\n\n# Set env var OPENAI_API_KEY or load from a .env file:\nimport dotenv\n\ndotenv.load_dotenv()\n[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\nYou should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.[0m[33m\n[0mNote: you may need to restart the kernel to use updated packages.\n",</span>
 'https<span class="token operator">:</span><span class="token comment">//python.langchain.com/docs/how_to/chatbots_tools/': "For this guide, we'll be using a tool calling agent with a single tool for searching the web. The default will be powered by Tavily, but you can switch it out for any similar tool. The rest of this section will assume you're using Tavily.\nYou'll need to sign up for an account on the Tavily website, and install the following packages:\n%pip install --upgrade --quiet langchain-community langchain-openai tavily-python\n\n# Set env var OPENAI_API_KEY or load from a .env file:\nimport dotenv\n\ndotenv.load_dotenv()\nYou will also need your OpenAI key set as OPENAI_API_KEY and your Tavily API key set as TAVILY_API_KEY.\n"}</span>
</code></pre>
    <h5>
     <a id="_2304">
     </a>
     对页面内容进行向量搜索
    </h5>
    <p>
     一旦我们将页面内容加载到LangChain Document 对象中，就可以对数据进行索引：
    </p>
    <pre><code class="prism language-c">import getpass
import os

<span class="token keyword">if</span> <span class="token string">"OPENAI_API_KEY"</span> not in os<span class="token punctuation">.</span>environ<span class="token operator">:</span>
    os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">]</span> <span class="token operator">=</span> getpass<span class="token punctuation">.</span><span class="token function">getpass</span><span class="token punctuation">(</span><span class="token string">"OpenAI API Key:"</span><span class="token punctuation">)</span>

from langchain_core<span class="token punctuation">.</span>vectorstores import InMemoryVectorStore
from langchain_openai import OpenAIEmbeddings

vector_store <span class="token operator">=</span> InMemoryVectorStore<span class="token punctuation">.</span><span class="token function">from_documents</span><span class="token punctuation">(</span>setup_docs<span class="token punctuation">,</span> <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
retrieved_docs <span class="token operator">=</span> vector_store<span class="token punctuation">.</span><span class="token function">similarity_search</span><span class="token punctuation">(</span><span class="token string">"Install Tavily"</span><span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> doc in retrieved_docs<span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>f'Page <span class="token punctuation">{<!-- --></span>doc<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">"url"</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>doc<span class="token punctuation">.</span>page_content<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">300</span><span class="token punctuation">]</span><span class="token punctuation">}</span>\n'<span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="CSV_2321">
     </a>
     加载CSV文件
    </h3>
    <p>
     一个 逗号分隔值 (CSV) 文件是一个使用逗号分隔值的定界文本文件。文件的每一行都是一个数据记录。每个记录由一个或多个字段组成，字段之间用逗号分隔。
    </p>
    <p>
     LangChain 实现了一个 CSV 加载器，可以将 CSV 文件加载为一系列 文档 对象。CSV 文件的每一行被转换为一个文档。
    </p>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>document_loaders<span class="token punctuation">.</span>csv_loader import CSVLoader

file_path <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token string">"../../../docs/integrations/document_loaders/example_data/mlb_teams_2012.csv"</span>
<span class="token punctuation">)</span>

loader <span class="token operator">=</span> <span class="token function">CSVLoader</span><span class="token punctuation">(</span>file_path<span class="token operator">=</span>file_path<span class="token punctuation">)</span>
data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> record in data<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">page_content<span class="token operator">=</span>'Team<span class="token operator">:</span> Nationals\n<span class="token string">"Payroll (millions)"</span><span class="token operator">:</span> <span class="token number">81.34</span>\n<span class="token string">"Wins"</span><span class="token operator">:</span> <span class="token number">98</span><span class="token char">' metadata={'</span>source<span class="token char">': '</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span>docs<span class="token operator">/</span>integrations<span class="token operator">/</span>document_loaders<span class="token operator">/</span>example_data<span class="token operator">/</span>mlb_teams_2012<span class="token punctuation">.</span>csv<span class="token char">', '</span>row'<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span>'Team<span class="token operator">:</span> Reds\n<span class="token string">"Payroll (millions)"</span><span class="token operator">:</span> <span class="token number">82.20</span>\n<span class="token string">"Wins"</span><span class="token operator">:</span> <span class="token number">97</span><span class="token char">' metadata={'</span>source<span class="token char">': '</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span>docs<span class="token operator">/</span>integrations<span class="token operator">/</span>document_loaders<span class="token operator">/</span>example_data<span class="token operator">/</span>mlb_teams_2012<span class="token punctuation">.</span>csv<span class="token char">', '</span>row'<span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">}</span>
</code></pre>
    <p>
     CSVLoader 接受一个 csv_args 关键字参数，支持传递给 Python 自定义的 csv.DictReader 的参数。
    </p>
    <pre><code class="prism language-c">loader <span class="token operator">=</span> <span class="token function">CSVLoader</span><span class="token punctuation">(</span>
    file_path<span class="token operator">=</span>file_path<span class="token punctuation">,</span>
    csv_args<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
        <span class="token string">"delimiter"</span><span class="token operator">:</span> <span class="token string">","</span><span class="token punctuation">,</span>
        <span class="token string">"quotechar"</span><span class="token operator">:</span> <span class="token char">'"'</span><span class="token punctuation">,</span>
        <span class="token string">"fieldnames"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"MLB Team"</span><span class="token punctuation">,</span> <span class="token string">"Payroll in millions"</span><span class="token punctuation">,</span> <span class="token string">"Wins"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> record in data<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span>
</code></pre>
    <p>
     可以使用 CSV 的一列作为 Document 元数据中的 “source” 键，loader只会提取这一列的值，否则，将默认使用 file_path 作为source。
    </p>
    <pre><code class="prism language-c">loader <span class="token operator">=</span> <span class="token function">CSVLoader</span><span class="token punctuation">(</span>file_path<span class="token operator">=</span>file_path<span class="token punctuation">,</span> source_column<span class="token operator">=</span><span class="token string">"Team"</span><span class="token punctuation">)</span>

data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> record in data<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">page_content<span class="token operator">=</span>'Team<span class="token operator">:</span> Nationals\n<span class="token string">"Payroll (millions)"</span><span class="token operator">:</span> <span class="token number">81.34</span>\n<span class="token string">"Wins"</span><span class="token operator">:</span> <span class="token number">98</span><span class="token char">' metadata={'</span>source<span class="token char">': '</span>Nationals<span class="token char">', '</span>row'<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span>'Team<span class="token operator">:</span> Reds\n<span class="token string">"Payroll (millions)"</span><span class="token operator">:</span> <span class="token number">82.20</span>\n<span class="token string">"Wins"</span><span class="token operator">:</span> <span class="token number">97</span><span class="token char">' metadata={'</span>source<span class="token char">': '</span>Reds<span class="token char">', '</span>row'<span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">}</span>
</code></pre>
    <p>
     在直接处理 CSV 字符串时，可以使用 Python 的 tempfile。
    </p>
    <pre><code class="prism language-c">import tempfile
from io import StringIO

string_data <span class="token operator">=</span> <span class="token string">""</span>"
<span class="token string">"Team"</span><span class="token punctuation">,</span> <span class="token string">"Payroll (millions)"</span><span class="token punctuation">,</span> <span class="token string">"Wins"</span>
<span class="token string">"Nationals"</span><span class="token punctuation">,</span>     <span class="token number">81.34</span><span class="token punctuation">,</span> <span class="token number">98</span>
<span class="token string">"Reds"</span><span class="token punctuation">,</span>          <span class="token number">82.20</span><span class="token punctuation">,</span> <span class="token number">97</span>
<span class="token string">"Yankees"</span><span class="token punctuation">,</span>      <span class="token number">197.96</span><span class="token punctuation">,</span> <span class="token number">95</span>
<span class="token string">"Giants"</span><span class="token punctuation">,</span>       <span class="token number">117.62</span><span class="token punctuation">,</span> <span class="token number">94</span>
<span class="token string">""</span>"<span class="token punctuation">.</span><span class="token function">strip</span><span class="token punctuation">(</span><span class="token punctuation">)</span>


with tempfile<span class="token punctuation">.</span><span class="token function">NamedTemporaryFile</span><span class="token punctuation">(</span>delete<span class="token operator">=</span>False<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">"w+"</span><span class="token punctuation">)</span> as temp_file<span class="token operator">:</span>
    temp_file<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>string_data<span class="token punctuation">)</span>
    temp_file_path <span class="token operator">=</span> temp_file<span class="token punctuation">.</span>name

loader <span class="token operator">=</span> <span class="token function">CSVLoader</span><span class="token punctuation">(</span>file_path<span class="token operator">=</span>temp_file_path<span class="token punctuation">)</span>
loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> record in data<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">page_content<span class="token operator">=</span>'Team<span class="token operator">:</span> Nationals\n<span class="token string">"Payroll (millions)"</span><span class="token operator">:</span> <span class="token number">81.34</span>\n<span class="token string">"Wins"</span><span class="token operator">:</span> <span class="token number">98</span><span class="token char">' metadata={'</span>source<span class="token char">': '</span>Nationals<span class="token char">', '</span>row'<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span>'Team<span class="token operator">:</span> Reds\n<span class="token string">"Payroll (millions)"</span><span class="token operator">:</span> <span class="token number">82.20</span>\n<span class="token string">"Wins"</span><span class="token operator">:</span> <span class="token number">97</span><span class="token char">' metadata={'</span>source<span class="token char">': '</span>Reds<span class="token char">', '</span>row'<span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">}</span>
</code></pre>
    <h3>
     <a id="_2404">
     </a>
     从目录加载文档
    </h3>
    <p>
     LangChain 的 DirectoryLoader 实现了从磁盘读取文件到 LangChain Document 对象的功能。
    </p>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>document_loaders import DirectoryLoader
</code></pre>
    <p>
     DirectoryLoader 接受一个 loader_cls 关键字参数，默认为 UnstructuredLoader。Unstructured 支持解析多种格式，如 PDF 和 HTML。在这里我们用它来读取一个 markdown (.md) 文件。
    </p>
    <p>
     我们可以使用 glob 参数来控制加载哪些文件。请注意，这里不会加载 .rst 文件或 .html 文件。
    </p>
    <pre><code class="prism language-c">loader <span class="token operator">=</span> <span class="token function">DirectoryLoader</span><span class="token punctuation">(</span><span class="token string">"../"</span><span class="token punctuation">,</span> glob<span class="token operator">=</span><span class="token string">"**/*.md"</span><span class="token punctuation">)</span>
docs <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token function">len</span><span class="token punctuation">(</span>docs<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token number">20</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token function">print</span><span class="token punctuation">(</span>docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">Security

LangChain has a large ecosystem of integrations with various external resources like local
</code></pre>
    <p>
     默认情况下不会显示进度条。要显示进度条，需要安装 tqdm 库（例如
     <strong>
      pip install tqdm
     </strong>
     ），并将 show_progress 参数设置为 True。
    </p>
    <pre><code class="prism language-c">loader <span class="token operator">=</span> <span class="token function">DirectoryLoader</span><span class="token punctuation">(</span><span class="token string">"../"</span><span class="token punctuation">,</span> glob<span class="token operator">=</span><span class="token string">"**/*.md"</span><span class="token punctuation">,</span> show_progress<span class="token operator">=</span>True<span class="token punctuation">)</span>
docs <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     默认情况下加载在一个线程中进行。为了利用多个线程，请将 use_multithreading 标志设置为 true。
    </p>
    <pre><code class="prism language-c">loader <span class="token operator">=</span> <span class="token function">DirectoryLoader</span><span class="token punctuation">(</span><span class="token string">"../"</span><span class="token punctuation">,</span> glob<span class="token operator">=</span><span class="token string">"**/*.md"</span><span class="token punctuation">,</span> use_multithreading<span class="token operator">=</span>True<span class="token punctuation">)</span>
docs <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     默认情况下使用 UnstructuredLoader 类。要自定义加载器，需要在 loader_cls 关键字参数中指定加载器类。
    </p>
    <p>
     比如使用指明使用 TextLoader：
    </p>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>document_loaders import TextLoader

loader <span class="token operator">=</span> <span class="token function">DirectoryLoader</span><span class="token punctuation">(</span><span class="token string">"../"</span><span class="token punctuation">,</span> glob<span class="token operator">=</span><span class="token string">"**/*.md"</span><span class="token punctuation">,</span> loader_cls<span class="token operator">=</span>TextLoader<span class="token punctuation">)</span>
docs <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token function">print</span><span class="token punctuation">(</span>docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">LangChain has a large ecosystem of integrations with various external resources like loc</span></span>
</code></pre>
    <p>
     <strong>
      注意，UnstructuredLoader 解析 Markdown 头部，TextLoader 不解析。
     </strong>
    </p>
    <p>
     如果您需要加载 Python 源代码文件，请使用 PythonLoader：
    </p>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>document_loaders import PythonLoader

loader <span class="token operator">=</span> <span class="token function">DirectoryLoader</span><span class="token punctuation">(</span><span class="token string">"../../../../../"</span><span class="token punctuation">,</span> glob<span class="token operator">=</span><span class="token string">"**/*.py"</span><span class="token punctuation">,</span> loader_cls<span class="token operator">=</span>PythonLoader<span class="token punctuation">)</span>
</code></pre>
    <p>
     DirectoryLoader可以帮助管理由于文件编码差异而导致的错误。下面我们将尝试加载一组文件，其中一个文件包含非UTF8编码。
    </p>
    <pre><code class="prism language-c">path <span class="token operator">=</span> <span class="token string">"../../../../libs/langchain/tests/unit_tests/examples/"</span>

loader <span class="token operator">=</span> <span class="token function">DirectoryLoader</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> glob<span class="token operator">=</span><span class="token string">"**/*.txt"</span><span class="token punctuation">,</span> loader_cls<span class="token operator">=</span>TextLoader<span class="token punctuation">)</span>
</code></pre>
    <p>
     默认情况下，我们会引发一个错误：
    </p>
    <pre><code class="prism language-c">Error loading file <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span>libs<span class="token operator">/</span>langchain<span class="token operator">/</span>tests<span class="token operator">/</span>unit_tests<span class="token operator">/</span>examples<span class="token operator">/</span>example<span class="token operator">-</span>non<span class="token operator">-</span>utf8<span class="token punctuation">.</span>txt
</code></pre>
    <p>
     文件 example-non-utf8.txt 使用了不同的编码，因此 load() 函数失败，并提供了一个有用的消息，指示哪个文件解码失败。在 TextLoader 的默认行为下，任何文档加载失败都会导致整个加载过程失败。
    </p>
    <p>
     我们可以将参数 silent_errors 传递给 DirectoryLoader，以跳过无法加载的文件并继续加载过程。
    </p>
    <pre><code class="prism language-c">loader <span class="token operator">=</span> <span class="token function">DirectoryLoader</span><span class="token punctuation">(</span>
    path<span class="token punctuation">,</span> glob<span class="token operator">=</span><span class="token string">"**/*.txt"</span><span class="token punctuation">,</span> loader_cls<span class="token operator">=</span>TextLoader<span class="token punctuation">,</span> silent_errors<span class="token operator">=</span>True
<span class="token punctuation">)</span>
docs <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">Error loading file <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span>libs<span class="token operator">/</span>langchain<span class="token operator">/</span>tests<span class="token operator">/</span>unit_tests<span class="token operator">/</span>examples<span class="token operator">/</span>example<span class="token operator">-</span>non<span class="token operator">-</span>utf8<span class="token punctuation">.</span>txt<span class="token operator">:</span> Error loading <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span>libs<span class="token operator">/</span>langchain<span class="token operator">/</span>tests<span class="token operator">/</span>unit_tests<span class="token operator">/</span>examples<span class="token operator">/</span>example<span class="token operator">-</span>non<span class="token operator">-</span>utf8<span class="token punctuation">.</span>txt
</code></pre>
    <pre><code class="prism language-c">doc_sources <span class="token operator">=</span> <span class="token punctuation">[</span>doc<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">"source"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> doc in docs<span class="token punctuation">]</span>
doc_sources
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span>'<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span>libs<span class="token operator">/</span>langchain<span class="token operator">/</span>tests<span class="token operator">/</span>unit_tests<span class="token operator">/</span>examples<span class="token operator">/</span>example<span class="token operator">-</span>utf8<span class="token punctuation">.</span>txt'<span class="token punctuation">]</span>
</code></pre>
    <p>
     我们还可以要求 TextLoader 在失败之前自动检测文件编码，通过将 autodetect_encoding 传递给加载器类。
    </p>
    <pre><code class="prism language-c">text_loader_kwargs <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"autodetect_encoding"</span><span class="token operator">:</span> True<span class="token punctuation">}</span>
loader <span class="token operator">=</span> <span class="token function">DirectoryLoader</span><span class="token punctuation">(</span>
    path<span class="token punctuation">,</span> glob<span class="token operator">=</span><span class="token string">"**/*.txt"</span><span class="token punctuation">,</span> loader_cls<span class="token operator">=</span>TextLoader<span class="token punctuation">,</span> loader_kwargs<span class="token operator">=</span>text_loader_kwargs
<span class="token punctuation">)</span>
docs <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">doc_sources <span class="token operator">=</span> <span class="token punctuation">[</span>doc<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">"source"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> doc in docs<span class="token punctuation">]</span>
doc_sources

<span class="token punctuation">[</span>'<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span>libs<span class="token operator">/</span>langchain<span class="token operator">/</span>tests<span class="token operator">/</span>unit_tests<span class="token operator">/</span>examples<span class="token operator">/</span>example<span class="token operator">-</span>utf8<span class="token punctuation">.</span>txt'<span class="token punctuation">,</span>
 '<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span>libs<span class="token operator">/</span>langchain<span class="token operator">/</span>tests<span class="token operator">/</span>unit_tests<span class="token operator">/</span>examples<span class="token operator">/</span>example<span class="token operator">-</span>non<span class="token operator">-</span>utf8<span class="token punctuation">.</span>txt'<span class="token punctuation">]</span>
</code></pre>
    <h3>
     <a id="HTML_2520">
     </a>
     加载HTML
    </h3>
    <p>
     解析HTML文件通常需要专门的工具。langChain主要通过Unstructured和BeautifulSoup4进行解析，这些工具可以通过pip安装。
    </p>
    <pre><code class="prism language-c">pip install unstructured
</code></pre>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>document_loaders import UnstructuredHTMLLoader

file_path <span class="token operator">=</span> <span class="token string">"../../docs/integrations/document_loaders/example_data/fake-content.html"</span>

loader <span class="token operator">=</span> <span class="token function">UnstructuredHTMLLoader</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>
data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token function">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'My First Heading\n\nMy first paragraph<span class="token punctuation">.</span><span class="token char">', metadata={'</span>source<span class="token char">': '</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span>docs<span class="token operator">/</span>integrations<span class="token operator">/</span>document_loaders<span class="token operator">/</span>example_data<span class="token operator">/</span>fake<span class="token operator">-</span>content<span class="token punctuation">.</span>html'<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     我们还可以使用 BeautifulSoup4 通过 BSHTMLLoader 加载 HTML 文档。这将从 HTML 中提取文本到 page_content，并将页面标题作为 title 提取到 metadata。
    </p>
    <pre><code class="prism language-c">pip install bs4
</code></pre>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>document_loaders import BSHTMLLoader

loader <span class="token operator">=</span> <span class="token function">BSHTMLLoader</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>
data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token function">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'\nTest Title\n\n\nMy First Heading\nMy first paragraph<span class="token punctuation">.</span>\n\n\n<span class="token char">', metadata={'</span>source<span class="token char">': '</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span>docs<span class="token operator">/</span>integrations<span class="token operator">/</span>document_loaders<span class="token operator">/</span>example_data<span class="token operator">/</span>fake<span class="token operator">-</span>content<span class="token punctuation">.</span>html<span class="token char">', '</span>title<span class="token char">': '</span>Test Title'<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <h3>
     <a id="_JSON_2559">
     </a>
     加载 JSON
    </h3>
    <p>
     JSON (JavaScript 对象表示法) 是一种开放标准文件格式和数据交换格式，使用人类可读的文本来存储和传输由属性-值对和数组（或其他可序列化值）组成的数据对象。
    </p>
    <p>
     JSON Lines 是一种文件格式，其中每一行都是一个有效的 JSON 值。
    </p>
    <p>
     LangChain 实现了一个 JSONLoader 用于将 JSON 和 JSONL 数据转换为 LangChain 文档 对象。 它使用指定的 jq schema（jq python 包）来解析 JSON 文件，允许将特定字段提取到内容 和 LangChain 文档的元数据中。
    </p>
    <pre><code class="prism language-c">pip install jq
</code></pre>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>document_loaders import JSONLoader

import json
from pathlib import Path
from pprint import pprint


file_path<span class="token operator">=</span>'<span class="token punctuation">.</span><span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json'
data <span class="token operator">=</span> json<span class="token punctuation">.</span><span class="token function">loads</span><span class="token punctuation">(</span><span class="token function">Path</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">read_text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token function">pprint</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre>
    <p>
     假设我们想提取 JSON 数据中 messages 键下 content 字段的值。这可以通过下面的 JSONLoader 轻松完成。
    </p>
    <pre><code class="prism language-c">loader <span class="token operator">=</span> <span class="token function">JSONLoader</span><span class="token punctuation">(</span>
    file_path<span class="token operator">=</span>'<span class="token punctuation">.</span><span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json'<span class="token punctuation">,</span>
    jq_schema<span class="token operator">=</span><span class="token char">'.messages[].content'</span><span class="token punctuation">,</span>
    text_content<span class="token operator">=</span>False<span class="token punctuation">)</span>

data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token function">pprint</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">    <span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Bye!'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Oh no worries! Bye'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'No Im sorry it was my mistake<span class="token punctuation">,</span> the blue one is not <span class="token keyword">for</span> sale<span class="token char">', metadata={'</span>source<span class="token char">': '</span><span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'I thought you were selling the blue one<span class="token operator">!</span><span class="token char">', metadata={'</span>source<span class="token char">': '</span><span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'Im not interested in this bag<span class="token punctuation">.</span> Im interested in the blue one<span class="token operator">!</span><span class="token char">', metadata={'</span>source<span class="token char">': '</span><span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">5</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Here is $129'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">6</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">''</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">7</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Online is at least $100'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'How much do you want?'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">9</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Goodmorning! $50 is too low.'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">10</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'Hi<span class="token operator">!</span> Im interested in your bag<span class="token punctuation">.</span> Im offering $<span class="token number">50.</span> Let me know <span class="token keyword">if</span> you are interested<span class="token punctuation">.</span> Thanks<span class="token operator">!</span><span class="token char">', metadata={'</span>source<span class="token char">': '</span><span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">11</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     如果您想从 JSON Lines 文件加载文档，请传递 json_lines=True 并指定 jq_schema 以从单个 JSON 对象中提取 page_content。
    </p>
    <pre><code class="prism language-c"> <span class="token punctuation">(</span>'<span class="token punctuation">{<!-- --></span><span class="token string">"sender_name"</span><span class="token operator">:</span> <span class="token string">"User 2"</span><span class="token punctuation">,</span> <span class="token string">"timestamp_ms"</span><span class="token operator">:</span> <span class="token number">1675597571851</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token operator">:</span> <span class="token string">"Bye!"</span><span class="token punctuation">}</span>\n'
     '<span class="token punctuation">{<!-- --></span><span class="token string">"sender_name"</span><span class="token operator">:</span> <span class="token string">"User 1"</span><span class="token punctuation">,</span> <span class="token string">"timestamp_ms"</span><span class="token operator">:</span> <span class="token number">1675597435669</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token operator">:</span> "Oh no '
     <span class="token char">'worries! Bye"}\n'</span>
     '<span class="token punctuation">{<!-- --></span><span class="token string">"sender_name"</span><span class="token operator">:</span> <span class="token string">"User 2"</span><span class="token punctuation">,</span> <span class="token string">"timestamp_ms"</span><span class="token operator">:</span> <span class="token number">1675596277579</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token operator">:</span> "No Im '
     'sorry it was my mistake<span class="token punctuation">,</span> the blue one is not <span class="token keyword">for</span> sale"<span class="token punctuation">}</span>\n'<span class="token punctuation">)</span>

loader <span class="token operator">=</span> <span class="token function">JSONLoader</span><span class="token punctuation">(</span>
    file_path<span class="token operator">=</span>'<span class="token punctuation">.</span><span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat_messages<span class="token punctuation">.</span>jsonl'<span class="token punctuation">,</span>
    jq_schema<span class="token operator">=</span><span class="token char">'.content'</span><span class="token punctuation">,</span>
    text_content<span class="token operator">=</span>False<span class="token punctuation">,</span>
    json_lines<span class="token operator">=</span>True<span class="token punctuation">)</span>

data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     可以看到我们只取到了content值：
    </p>
    <pre><code class="prism language-c">    <span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Bye!'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> 'langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat_messages<span class="token punctuation">.</span>jsonl<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Oh no worries! Bye'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> 'langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat_messages<span class="token punctuation">.</span>jsonl<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'No Im sorry it was my mistake<span class="token punctuation">,</span> the blue one is not <span class="token keyword">for</span> sale<span class="token char">', metadata={'</span>source<span class="token char">': '</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat_messages<span class="token punctuation">.</span>jsonl<span class="token char">', '</span>seq_num'<span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     另一个选项是设置 jq_schema=‘.’ 并提供 content_key：
    </p>
    <pre><code class="prism language-c">loader <span class="token operator">=</span> <span class="token function">JSONLoader</span><span class="token punctuation">(</span>
    file_path<span class="token operator">=</span>'<span class="token punctuation">.</span><span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat_messages<span class="token punctuation">.</span>jsonl'<span class="token punctuation">,</span>
    jq_schema<span class="token operator">=</span><span class="token char">'.'</span><span class="token punctuation">,</span>
    content_key<span class="token operator">=</span><span class="token char">'sender_name'</span><span class="token punctuation">,</span>
    json_lines<span class="token operator">=</span>True<span class="token punctuation">)</span>

data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     要使用 jq schema 中的 content_key 从 JSON 文件加载文档，请设置 is_content_key_jq_parsable=True。 确保 content_key 兼容并可以使用 jq schema 进行解析。
    </p>
    <pre><code class="prism language-c">loader <span class="token operator">=</span> <span class="token function">JSONLoader</span><span class="token punctuation">(</span>
    file_path<span class="token operator">=</span>file_path<span class="token punctuation">,</span>
    jq_schema<span class="token operator">=</span><span class="token string">".data[]"</span><span class="token punctuation">,</span>
    content_key<span class="token operator">=</span><span class="token string">".attributes.message"</span><span class="token punctuation">,</span>
    is_content_key_jq_parsable<span class="token operator">=</span>True<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     通常，我们希望将JSON文件中可用的元数据包含到我们从内容创建的文档中。在之前的示例中，我们没有收集元数据，我们直接在模式中指定了page_content的值可以从哪里提取。
    </p>
    <pre><code class="prism language-c"><span class="token punctuation">.</span>messages<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">.</span>content
</code></pre>
    <p>
     在当前示例中，我们必须告诉加载器遍历messages字段中的记录。jq_schema必须是：
    </p>
    <pre><code class="prism language-c"><span class="token punctuation">.</span>messages<span class="token punctuation">[</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     这允许我们将记录（字典）传递给必须实现的metadata_func。metadata_func负责识别记录中哪些信息应包含在最终Document对象中存储的元数据中。
    </p>
    <p>
     此外，我们现在必须通过content_key参数在加载器中明确指定记录中提取page_content值的键。
    </p>
    <pre><code class="prism language-c">def <span class="token function">metadata_func</span><span class="token punctuation">(</span>record<span class="token operator">:</span> dict<span class="token punctuation">,</span> metadata<span class="token operator">:</span> dict<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> dict<span class="token operator">:</span>

    metadata<span class="token punctuation">[</span><span class="token string">"sender_name"</span><span class="token punctuation">]</span> <span class="token operator">=</span> record<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"sender_name"</span><span class="token punctuation">)</span>
    metadata<span class="token punctuation">[</span><span class="token string">"timestamp_ms"</span><span class="token punctuation">]</span> <span class="token operator">=</span> record<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"timestamp_ms"</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> metadata


loader <span class="token operator">=</span> <span class="token function">JSONLoader</span><span class="token punctuation">(</span>
    file_path<span class="token operator">=</span>'<span class="token punctuation">.</span><span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json'<span class="token punctuation">,</span>
    jq_schema<span class="token operator">=</span><span class="token char">'.messages[]'</span><span class="token punctuation">,</span>
    content_key<span class="token operator">=</span><span class="token string">"content"</span><span class="token punctuation">,</span>
    metadata_func<span class="token operator">=</span>metadata_func
<span class="token punctuation">)</span>

data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token function">pprint</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">    <span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Bye!'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 1, '</span>sender_name<span class="token char">': '</span>User <span class="token number">2</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675597571851</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Oh no worries! Bye'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 2, '</span>sender_name<span class="token char">': '</span>User <span class="token number">1</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675597435669</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'No Im sorry it was my mistake<span class="token punctuation">,</span> the blue one is not <span class="token keyword">for</span> sale<span class="token char">', metadata={'</span>source<span class="token char">': '</span><span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 3, '</span>sender_name<span class="token char">': '</span>User <span class="token number">2</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675596277579</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'I thought you were selling the blue one<span class="token operator">!</span><span class="token char">', metadata={'</span>source<span class="token char">': '</span><span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 4, '</span>sender_name<span class="token char">': '</span>User <span class="token number">1</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675595140251</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'Im not interested in this bag<span class="token punctuation">.</span> Im interested in the blue one<span class="token operator">!</span><span class="token char">', metadata={'</span>source<span class="token char">': '</span><span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 5, '</span>sender_name<span class="token char">': '</span>User <span class="token number">1</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675595109305</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Here is $129'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 6, '</span>sender_name<span class="token char">': '</span>User <span class="token number">2</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675595068468</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">''</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 7, '</span>sender_name<span class="token char">': '</span>User <span class="token number">2</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675595060730</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Online is at least $100'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 8, '</span>sender_name<span class="token char">': '</span>User <span class="token number">2</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675595045152</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'How much do you want?'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 9, '</span>sender_name<span class="token char">': '</span>User <span class="token number">1</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675594799696</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Goodmorning! $50 is too low.'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> '<span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 10, '</span>sender_name<span class="token char">': '</span>User <span class="token number">2</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675577876645</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'Hi<span class="token operator">!</span> Im interested in your bag<span class="token punctuation">.</span> Im offering $<span class="token number">50.</span> Let me know <span class="token keyword">if</span> you are interested<span class="token punctuation">.</span> Thanks<span class="token operator">!</span><span class="token char">', metadata={'</span>source<span class="token char">': '</span><span class="token operator">/</span>Users<span class="token operator">/</span>avsolatorio<span class="token operator">/</span>WBG<span class="token operator">/</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 11, '</span>sender_name<span class="token char">': '</span>User <span class="token number">1</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675549022673</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     如上所示，metadata_func接受由JSONLoader生成的默认元数据。这使用户能够完全控制元数据的格式。
    </p>
    <p>
     例如，默认元数据包含 source 和 seq_num 键。然而，JSON 数据中也可能包含这些键。用户可以利用 metadata_func 来重命名默认键，并使用 JSON 数据中的键。
    </p>
    <pre><code class="prism language-c"><span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Define </span><span class="token macro-name">the</span> <span class="token expression">metadata extraction function<span class="token punctuation">.</span></span></span>
def <span class="token function">metadata_func</span><span class="token punctuation">(</span>record<span class="token operator">:</span> dict<span class="token punctuation">,</span> metadata<span class="token operator">:</span> dict<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> dict<span class="token operator">:</span>

    metadata<span class="token punctuation">[</span><span class="token string">"sender_name"</span><span class="token punctuation">]</span> <span class="token operator">=</span> record<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"sender_name"</span><span class="token punctuation">)</span>
    metadata<span class="token punctuation">[</span><span class="token string">"timestamp_ms"</span><span class="token punctuation">]</span> <span class="token operator">=</span> record<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"timestamp_ms"</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token string">"source"</span> in metadata<span class="token operator">:</span>
        source <span class="token operator">=</span> metadata<span class="token punctuation">[</span><span class="token string">"source"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span>
        source <span class="token operator">=</span> source<span class="token punctuation">[</span>source<span class="token punctuation">.</span><span class="token function">index</span><span class="token punctuation">(</span><span class="token string">"langchain"</span><span class="token punctuation">)</span><span class="token operator">:</span><span class="token punctuation">]</span>
        metadata<span class="token punctuation">[</span><span class="token string">"source"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"/"</span><span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span>source<span class="token punctuation">)</span>

    <span class="token keyword">return</span> metadata


loader <span class="token operator">=</span> <span class="token function">JSONLoader</span><span class="token punctuation">(</span>
    file_path<span class="token operator">=</span>'<span class="token punctuation">.</span><span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json'<span class="token punctuation">,</span>
    jq_schema<span class="token operator">=</span><span class="token char">'.messages[]'</span><span class="token punctuation">,</span>
    content_key<span class="token operator">=</span><span class="token string">"content"</span><span class="token punctuation">,</span>
    metadata_func<span class="token operator">=</span>metadata_func
<span class="token punctuation">)</span>

data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token function">pprint</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">    <span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Bye!'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> 'langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 1, '</span>sender_name<span class="token char">': '</span>User <span class="token number">2</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675597571851</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Oh no worries! Bye'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> 'langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 2, '</span>sender_name<span class="token char">': '</span>User <span class="token number">1</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675597435669</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'No Im sorry it was my mistake<span class="token punctuation">,</span> the blue one is not <span class="token keyword">for</span> sale<span class="token char">', metadata={'</span>source<span class="token char">': '</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 3, '</span>sender_name<span class="token char">': '</span>User <span class="token number">2</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675596277579</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'I thought you were selling the blue one<span class="token operator">!</span><span class="token char">', metadata={'</span>source<span class="token char">': '</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 4, '</span>sender_name<span class="token char">': '</span>User <span class="token number">1</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675595140251</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'Im not interested in this bag<span class="token punctuation">.</span> Im interested in the blue one<span class="token operator">!</span><span class="token char">', metadata={'</span>source<span class="token char">': '</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 5, '</span>sender_name<span class="token char">': '</span>User <span class="token number">1</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675595109305</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Here is $129'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> 'langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 6, '</span>sender_name<span class="token char">': '</span>User <span class="token number">2</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675595068468</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">''</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> 'langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 7, '</span>sender_name<span class="token char">': '</span>User <span class="token number">2</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675595060730</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Online is at least $100'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> 'langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 8, '</span>sender_name<span class="token char">': '</span>User <span class="token number">2</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675595045152</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'How much do you want?'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> 'langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 9, '</span>sender_name<span class="token char">': '</span>User <span class="token number">1</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675594799696</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Goodmorning! $50 is too low.'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> 'langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 10, '</span>sender_name<span class="token char">': '</span>User <span class="token number">2</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675577876645</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'Hi<span class="token operator">!</span> Im interested in your bag<span class="token punctuation">.</span> Im offering $<span class="token number">50.</span> Let me know <span class="token keyword">if</span> you are interested<span class="token punctuation">.</span> Thanks<span class="token operator">!</span><span class="token char">', metadata={'</span>source<span class="token char">': '</span>langchain<span class="token operator">/</span>docs<span class="token operator">/</span>modules<span class="token operator">/</span>indexes<span class="token operator">/</span>document_loaders<span class="token operator">/</span>examples<span class="token operator">/</span>example_data<span class="token operator">/</span>facebook_chat<span class="token punctuation">.</span>json<span class="token char">', '</span>seq_num<span class="token char">': 11, '</span>sender_name<span class="token char">': '</span>User <span class="token number">1</span><span class="token char">', '</span>timestamp_ms'<span class="token operator">:</span> <span class="token number">1675549022673</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     下面的列表提供了用户可以使用的可能的 jq_schema 参考，以根据结构从 JSON 数据中提取内容。
    </p>
    <pre><code class="prism language-c">JSON        <span class="token operator">-&gt;</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"text"</span><span class="token operator">:</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"text"</span><span class="token operator">:</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"text"</span><span class="token operator">:</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
jq_schema   <span class="token operator">-&gt;</span> <span class="token string">".[].text"</span>

JSON        <span class="token operator">-&gt;</span> <span class="token punctuation">{<!-- --></span><span class="token string">"key"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"text"</span><span class="token operator">:</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"text"</span><span class="token operator">:</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"text"</span><span class="token operator">:</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
jq_schema   <span class="token operator">-&gt;</span> <span class="token string">".key[].text"</span>

JSON        <span class="token operator">-&gt;</span> <span class="token punctuation">[</span><span class="token string">"..."</span><span class="token punctuation">,</span> <span class="token string">"..."</span><span class="token punctuation">,</span> <span class="token string">"..."</span><span class="token punctuation">]</span>
jq_schema   <span class="token operator">-&gt;</span> <span class="token string">".[]"</span>
</code></pre>
    <h3>
     <a id="Markdown_2758">
     </a>
     加载Markdown
    </h3>
    <p>
     Markdown 是一种轻量级标记语言，用于使用纯文本编辑器创建格式化文本。LangChain 实现了一个 UnstructuredMarkdownLoader 对象，该对象需要 Unstructured 包。
    </p>
    <pre><code class="prism language-c">pip install <span class="token string">"unstructured[md]"</span> nltk
</code></pre>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>document_loaders import UnstructuredMarkdownLoader
from langchain_core<span class="token punctuation">.</span>documents import Document

markdown_path <span class="token operator">=</span> <span class="token string">"../../../README.md"</span>
loader <span class="token operator">=</span> <span class="token function">UnstructuredMarkdownLoader</span><span class="token punctuation">(</span>markdown_path<span class="token punctuation">)</span>

data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
assert <span class="token function">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span>
assert <span class="token function">isinstance</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Document<span class="token punctuation">)</span>
readme_content <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content
<span class="token function">print</span><span class="token punctuation">(</span>readme_content<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">250</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     基本用法将会把一个Markdown文件导入为一个单一文档。
    </p>
    <pre><code class="prism language-c">🦜️🔗 LangChain

⚡ Build context<span class="token operator">-</span>aware reasoning applications ⚡

Looking <span class="token keyword">for</span> the JS<span class="token operator">/</span>TS library<span class="token operator">?</span> Check out LangChain<span class="token punctuation">.</span>js<span class="token punctuation">.</span>

To help you ship LangChain apps to production faster<span class="token punctuation">,</span> check out LangSmith<span class="token punctuation">.</span> 
LangSmith is a unified developer platform <span class="token keyword">for</span> building<span class="token punctuation">,</span>
</code></pre>
    <p>
     在底层，Unstructured为不同的文本块创建不同的“元素”。默认情况下这些元素将被组合在一起，但可以通过指定mode="elements"轻松保持这种分离。
    </p>
    <pre><code class="prism language-c">loader <span class="token operator">=</span> <span class="token function">UnstructuredMarkdownLoader</span><span class="token punctuation">(</span>markdown_path<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">"elements"</span><span class="token punctuation">)</span>

data <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>f<span class="token string">"Number of documents: {len(data)}\n"</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> document in data<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>f<span class="token string">"{document}\n"</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">Number of documents<span class="token operator">:</span> <span class="token number">66</span>

page_content<span class="token operator">=</span><span class="token char">'🦜️🔗 LangChain'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'../../../README.md'</span><span class="token punctuation">,</span> <span class="token char">'category_depth'</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token char">'last_modified'</span><span class="token operator">:</span> <span class="token char">'2024-06-28T15:20:01'</span><span class="token punctuation">,</span> <span class="token char">'languages'</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token char">'eng'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token char">'filetype'</span><span class="token operator">:</span> <span class="token char">'text/markdown'</span><span class="token punctuation">,</span> <span class="token char">'file_directory'</span><span class="token operator">:</span> <span class="token char">'../../..'</span><span class="token punctuation">,</span> <span class="token char">'filename'</span><span class="token operator">:</span> <span class="token char">'README.md'</span><span class="token punctuation">,</span> <span class="token char">'category'</span><span class="token operator">:</span> <span class="token char">'Title'</span><span class="token punctuation">}</span>

page_content<span class="token operator">=</span>'⚡ Build context<span class="token operator">-</span>aware reasoning applications ⚡<span class="token char">' metadata={'</span>source<span class="token char">': '</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span>README<span class="token punctuation">.</span>md<span class="token char">', '</span>last_modified<span class="token char">': '</span><span class="token number">2024</span><span class="token operator">-</span><span class="token number">06</span><span class="token operator">-</span><span class="token number">28</span>T15<span class="token operator">:</span><span class="token number">20</span><span class="token operator">:</span><span class="token number">01</span><span class="token char">', '</span>languages<span class="token char">': ['</span>eng<span class="token char">'], '</span>parent_id<span class="token char">': '</span><span class="token number">200</span>b8a7d0dd03f66e4f13456566d2b3a<span class="token char">', '</span>filetype<span class="token char">': '</span>text<span class="token operator">/</span>markdown<span class="token char">', '</span>file_directory<span class="token char">': '</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token char">', '</span>filename<span class="token char">': '</span>README<span class="token punctuation">.</span>md<span class="token char">', '</span>category<span class="token char">': '</span>NarrativeText'<span class="token punctuation">}</span>
</code></pre>
    <p>
     请注意，在这种情况下，我们得到了三种不同的元素类型：
    </p>
    <pre><code class="prism language-c"><span class="token function">print</span><span class="token punctuation">(</span><span class="token function">set</span><span class="token punctuation">(</span>document<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">"category"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> document in data<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span><span class="token char">'ListItem'</span><span class="token punctuation">,</span> <span class="token char">'NarrativeText'</span><span class="token punctuation">,</span> <span class="token char">'Title'</span><span class="token punctuation">}</span>
</code></pre>
    <h3>
     <a id="_Microsoft_Office__2814">
     </a>
     加载 Microsoft Office 文件
    </h3>
    <p>
     Microsoft Office 办公软件套件包括 Microsoft Word、Microsoft Excel、Microsoft PowerPoint、Microsoft Outlook 和 Microsoft OneNote。它可用于 Microsoft Windows 和 macOS 操作系统，也可在 Android 和 iOS 上使用。
    </p>
    <p>
     <a href="https://learn.microsoft.com/zh-cn/azure/ai-services/document-intelligence/?view=doc-intel-4.0.0" rel="nofollow">
      Azure AI Document Intelligence
     </a>
     （前称 Azure Form Recognizer）是基于机器学习的 服务，能够从数字或扫描的 PDF、图像、Office 和 HTML 文件中提取文本（包括手写）、表格、文档结构（例如标题、章节标题等）和键值对。 文档智能支持 PDF、JPEG/JPG、PNG、BMP、TIFF、HEIF、DOCX、XLSX、PPTX 和 HTML。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/5baaed6177a34078baeac929d0e044a9.png"/>
    </p>
    <p>
     这个加载器可以逐页整合内容并将其转换为 LangChain 文档。默认输出格式为 markdown，可以与 MarkdownHeaderTextSplitter 轻松链式处理以进行语义文档分块。还可以使用
     <code>
      mode="single" 或 mode="page"
     </code>
     返回单页或按页分割的纯文本。
    </p>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>document_loaders import AzureAIDocumentIntelligenceLoader

file_path <span class="token operator">=</span> <span class="token string">"&lt;filepath&gt;"</span>
endpoint <span class="token operator">=</span> <span class="token string">"&lt;endpoint&gt;"</span>
key <span class="token operator">=</span> <span class="token string">"&lt;key&gt;"</span>
loader <span class="token operator">=</span> <span class="token function">AzureAIDocumentIntelligenceLoader</span><span class="token punctuation">(</span>
    api_endpoint<span class="token operator">=</span>endpoint<span class="token punctuation">,</span> api_key<span class="token operator">=</span>key<span class="token punctuation">,</span> file_path<span class="token operator">=</span>file_path<span class="token punctuation">,</span> api_model<span class="token operator">=</span><span class="token string">"prebuilt-layout"</span>
<span class="token punctuation">)</span>

documents <span class="token operator">=</span> loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="_2837">
     </a>
     创建自定义文档加载器
    </h3>
    <p>
     基于大型语言模型（LLMs）的应用程序通常涉及从数据库或文件（如PDF）中提取数据，并将其转换为LLMs可以使用的格式。在LangChain中，这通常涉及创建文档对象（Document），它封装了提取的文本（page_content）以及元数据——一个包含有关文档的详细信息的字典，例如作者的姓名或出版日期。
    </p>
    <p>
     Document对象通常被格式化为提示词，输入到LLM中，使LLM能够使用Document中的信息生成所需的响应（例如，总结文档）。 Documents可以立即使用，也可以索引到向量存储中以便将来检索和使用。
    </p>
    <p>
     文档加载的主要抽象是：
    </p>
    <table>
     <thead>
      <tr>
       <th>
        组件
       </th>
       <th>
        描述
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        Document
       </td>
       <td>
        包含
        <code>
         文本
        </code>
        和
        <code>
         元数据
        </code>
       </td>
      </tr>
      <tr>
       <td>
        BaseLoader
       </td>
       <td>
        用于将原始数据转换为
        <code>
         Documents
        </code>
       </td>
      </tr>
      <tr>
       <td>
        Blob
       </td>
       <td>
        二进制数据的表示，位于文件或内存中
       </td>
      </tr>
      <tr>
       <td>
        BaseBlobParser
       </td>
       <td>
        解析
        <code>
         Blob
        </code>
        的逻辑，以生成
        <code>
         Document
        </code>
        对象
       </td>
      </tr>
     </tbody>
    </table>
    <p>
     文档加载器可以通过从 BaseLoader 子类化来实现，后者提供了加载文档的标准接口。
    </p>
    <table>
     <thead>
      <tr>
       <th>
        方法名称
       </th>
       <th>
        说明
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        lazy_load
       </td>
       <td>
        用于
        <strong>
         懒加载
        </strong>
        文档，一次加载一个。用于生产代码。
       </td>
      </tr>
      <tr>
       <td>
        alazy_load
       </td>
       <td>
        <code>
         lazy_load
        </code>
        的异步变体
       </td>
      </tr>
      <tr>
       <td>
        load
       </td>
       <td>
        用于
        <strong>
         急加载
        </strong>
        所有文档到内存中。用于原型设计或交互式工作。
       </td>
      </tr>
      <tr>
       <td>
        aload
       </td>
       <td>
        用于
        <strong>
         急加载
        </strong>
        所有文档到内存中。用于原型设计或交互式工作。
        <strong>
         于2024-04添加到LangChain。
        </strong>
       </td>
      </tr>
     </tbody>
    </table>
    <ul>
     <li>
      load方法是一个便利方法，仅用于原型设计工作 – 它只是调用list(self.lazy_load())。
     </li>
     <li>
      alazy_load有一个默认实现，将委托给lazy_load。如果您使用异步，我们建议覆盖默认实现并提供原生异步实现。
     </li>
    </ul>
    <p>
     注意：
    </p>
    <ol>
     <li>
      实现文档加载器时不要通过lazy_load或alazy_load方法提供参数。
     </li>
     <li>
      所有配置预计通过初始化器(init)传递。这是LangChain做出的设计选择，以确保一旦实例化文档加载器，它就拥有加载文档所需的所有信息。
     </li>
    </ol>
    <p>
     让我们创建一个标准文档加载器的示例，该加载器加载一个文件并从文件中的每一行创建一个文档。
    </p>
    <pre><code class="prism language-c">from typing import AsyncIterator<span class="token punctuation">,</span> Iterator

from langchain_core<span class="token punctuation">.</span>document_loaders import BaseLoader
from langchain_core<span class="token punctuation">.</span>documents import Document


class <span class="token function">CustomDocumentLoader</span><span class="token punctuation">(</span>BaseLoader<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token string">""</span><span class="token string">"An example document loader that reads a file line by line."</span><span class="token string">""</span>

    def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> file_path<span class="token operator">:</span> str<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> None<span class="token operator">:</span>
        <span class="token string">""</span>"Initialize the loader with a file path<span class="token punctuation">.</span>

        Args<span class="token operator">:</span>
            file_path<span class="token operator">:</span> The path to the file to load<span class="token punctuation">.</span>
        <span class="token string">""</span>"
        self<span class="token punctuation">.</span>file_path <span class="token operator">=</span> file_path

    def <span class="token function">lazy_load</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> Iterator<span class="token punctuation">[</span>Document<span class="token punctuation">]</span><span class="token operator">:</span>  # <span class="token operator">&lt;</span><span class="token operator">--</span> Does not take any arguments
        <span class="token string">""</span>"A lazy loader that reads a file line by line<span class="token punctuation">.</span>

        When you're implementing lazy load methods<span class="token punctuation">,</span> you should use a generator
        to yield documents one by one<span class="token punctuation">.</span>
        <span class="token string">""</span>"
        with <span class="token function">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>file_path<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> as f<span class="token operator">:</span>
            line_number <span class="token operator">=</span> <span class="token number">0</span>
            <span class="token keyword">for</span> line in f<span class="token operator">:</span>
                yield <span class="token function">Document</span><span class="token punctuation">(</span>
                    page_content<span class="token operator">=</span>line<span class="token punctuation">,</span>
                    metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">"line_number"</span><span class="token operator">:</span> line_number<span class="token punctuation">,</span> <span class="token string">"source"</span><span class="token operator">:</span> self<span class="token punctuation">.</span>file_path<span class="token punctuation">}</span><span class="token punctuation">,</span>
                <span class="token punctuation">)</span>
                line_number <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">alazy</span><span class="token expression">_load is OPTIONAL<span class="token punctuation">.</span></span></span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">If you leave out the implementation<span class="token punctuation">,</span> a <span class="token keyword">default</span> implementation which delegates to lazy_load will be used<span class="token operator">!</span></span></span>
    async def <span class="token function">alazy_load</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-&gt;</span> AsyncIterator<span class="token punctuation">[</span>Document<span class="token punctuation">]</span><span class="token operator">:</span>  # <span class="token operator">&lt;</span><span class="token operator">--</span> Does not take any arguments
        <span class="token string">""</span><span class="token string">"An async lazy loader that reads a file line by line."</span><span class="token string">""</span>
        <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Requires aiofiles</span></span>
        <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Install with `pip install aiofiles`</span></span>
        <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">https</span><span class="token expression"><span class="token operator">:</span></span><span class="token comment">//github.com/Tinche/aiofiles</span></span>
        import aiofiles

        async with aiofiles<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>file_path<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> as f<span class="token operator">:</span>
            line_number <span class="token operator">=</span> <span class="token number">0</span>
            async <span class="token keyword">for</span> line in f<span class="token operator">:</span>
                yield <span class="token function">Document</span><span class="token punctuation">(</span>
                    page_content<span class="token operator">=</span>line<span class="token punctuation">,</span>
                    metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">"line_number"</span><span class="token operator">:</span> line_number<span class="token punctuation">,</span> <span class="token string">"source"</span><span class="token operator">:</span> self<span class="token punctuation">.</span>file_path<span class="token punctuation">}</span><span class="token punctuation">,</span>
                <span class="token punctuation">)</span>
                line_number <span class="token operator">+=</span> <span class="token number">1</span>
</code></pre>
    <p>
     测试文档加载器，
    </p>
    <pre><code class="prism language-c">with <span class="token function">open</span><span class="token punctuation">(</span><span class="token string">"./meow.txt"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> as f<span class="token operator">:</span>
    quality_content <span class="token operator">=</span> <span class="token string">"meow meow🐱 \n meow meow🐱 \n meow😻😻"</span>
    f<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>quality_content<span class="token punctuation">)</span>

loader <span class="token operator">=</span> <span class="token function">CustomDocumentLoader</span><span class="token punctuation">(</span><span class="token string">"./meow.txt"</span><span class="token punctuation">)</span>

## Test out the lazy load interface
<span class="token keyword">for</span> doc in loader<span class="token punctuation">.</span><span class="token function">lazy_load</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token function">print</span><span class="token punctuation">(</span><span class="token function">type</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token function">print</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token operator">&lt;</span>class 'langchain_core<span class="token punctuation">.</span>documents<span class="token punctuation">.</span>base<span class="token punctuation">.</span>Document'<span class="token operator">&gt;</span>
page_content<span class="token operator">=</span><span class="token char">'meow meow🐱 \n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'./meow.txt'</span><span class="token punctuation">}</span>

<span class="token operator">&lt;</span>class 'langchain_core<span class="token punctuation">.</span>documents<span class="token punctuation">.</span>base<span class="token punctuation">.</span>Document'<span class="token operator">&gt;</span>
page_content<span class="token operator">=</span><span class="token char">' meow meow🐱 \n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'./meow.txt'</span><span class="token punctuation">}</span>

<span class="token operator">&lt;</span>class 'langchain_core<span class="token punctuation">.</span>documents<span class="token punctuation">.</span>base<span class="token punctuation">.</span>Document'<span class="token operator">&gt;</span>
page_content<span class="token operator">=</span><span class="token char">' meow😻😻'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'./meow.txt'</span><span class="token punctuation">}</span>
</code></pre>
    <pre><code class="prism language-c">## Test out the async implementation
async <span class="token keyword">for</span> doc in loader<span class="token punctuation">.</span><span class="token function">alazy_load</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token function">print</span><span class="token punctuation">(</span><span class="token function">type</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token function">print</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>


<span class="token operator">&lt;</span>class 'langchain_core<span class="token punctuation">.</span>documents<span class="token punctuation">.</span>base<span class="token punctuation">.</span>Document'<span class="token operator">&gt;</span>
page_content<span class="token operator">=</span><span class="token char">'meow meow🐱 \n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'./meow.txt'</span><span class="token punctuation">}</span>

<span class="token operator">&lt;</span>class 'langchain_core<span class="token punctuation">.</span>documents<span class="token punctuation">.</span>base<span class="token punctuation">.</span>Document'<span class="token operator">&gt;</span>
page_content<span class="token operator">=</span><span class="token char">' meow meow🐱 \n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'./meow.txt'</span><span class="token punctuation">}</span>

<span class="token operator">&lt;</span>class 'langchain_core<span class="token punctuation">.</span>documents<span class="token punctuation">.</span>base<span class="token punctuation">.</span>Document'<span class="token operator">&gt;</span>
page_content<span class="token operator">=</span><span class="token char">' meow😻😻'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'./meow.txt'</span><span class="token punctuation">}</span>
</code></pre>
    <p>
     避免在生产代码中直接使用load()，因为加载所有内容到入内存中是十分危险的。
    </p>
    <pre><code class="prism language-c">loader<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'meow meow🐱 \n'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'./meow.txt'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">' meow meow🐱 \n'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'./meow.txt'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">' meow😻😻'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'./meow.txt'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     许多文档加载器涉及解析文件。这些加载器之间的区别通常源于文件的解析方式，而不是文件的加载方式。例如，
     <strong>
      您可以使用 open 来读取 PDF 或 markdown 文件的二进制内容，但您需要不同的解析逻辑将该二进制数据转换为文本。
     </strong>
    </p>
    <p>
     因此，将解析逻辑与加载逻辑解耦可能会很有帮助，这使得无论数据是如何加载的，都更容易重用给定的解析器。
    </p>
    <pre><code class="prism language-c">from langchain_core<span class="token punctuation">.</span>document_loaders import BaseBlobParser<span class="token punctuation">,</span> Blob


class <span class="token function">MyParser</span><span class="token punctuation">(</span>BaseBlobParser<span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token string">""</span><span class="token string">"A simple parser that creates a document from each line."</span><span class="token string">""</span>

    def <span class="token function">lazy_parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> blob<span class="token operator">:</span> Blob<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> Iterator<span class="token punctuation">[</span>Document<span class="token punctuation">]</span><span class="token operator">:</span>
        <span class="token string">""</span><span class="token string">"Parse a blob into a document line by line."</span><span class="token string">""</span>
        line_number <span class="token operator">=</span> <span class="token number">0</span>
        with blob<span class="token punctuation">.</span><span class="token function">as_bytes_io</span><span class="token punctuation">(</span><span class="token punctuation">)</span> as f<span class="token operator">:</span>
            <span class="token keyword">for</span> line in f<span class="token operator">:</span>
                line_number <span class="token operator">+=</span> <span class="token number">1</span>
                yield <span class="token function">Document</span><span class="token punctuation">(</span>
                    page_content<span class="token operator">=</span>line<span class="token punctuation">,</span>
                    metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">"line_number"</span><span class="token operator">:</span> line_number<span class="token punctuation">,</span> <span class="token string">"source"</span><span class="token operator">:</span> blob<span class="token punctuation">.</span>source<span class="token punctuation">}</span><span class="token punctuation">,</span>
                <span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">blob <span class="token operator">=</span> Blob<span class="token punctuation">.</span><span class="token function">from_path</span><span class="token punctuation">(</span><span class="token string">"./meow.txt"</span><span class="token punctuation">)</span>
parser <span class="token operator">=</span> <span class="token function">MyParser</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token function">list</span><span class="token punctuation">(</span>parser<span class="token punctuation">.</span><span class="token function">lazy_parse</span><span class="token punctuation">(</span>blob<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'meow meow🐱 \n'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'./meow.txt'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">' meow meow🐱 \n'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'./meow.txt'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">' meow😻😻'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'./meow.txt'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     使用 blob API 还允许直接从内存加载内容，而无需从文件中读取！
    </p>
    <pre><code class="prism language-c">blob <span class="token operator">=</span> <span class="token function">Blob</span><span class="token punctuation">(</span>data<span class="token operator">=</span>b<span class="token string">"some data from memory\nmeow"</span><span class="token punctuation">)</span>
<span class="token function">list</span><span class="token punctuation">(</span>parser<span class="token punctuation">.</span><span class="token function">lazy_parse</span><span class="token punctuation">(</span>blob<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'some data from memory\n'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> None<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'meow'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> None<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     Blob API：
    </p>
    <pre><code class="prism language-c">blob <span class="token operator">=</span> Blob<span class="token punctuation">.</span><span class="token function">from_path</span><span class="token punctuation">(</span><span class="token string">"./meow.txt"</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">"foo"</span><span class="token operator">:</span> <span class="token string">"bar"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">blob<span class="token punctuation">.</span>encoding
<span class="token char">'utf-8'</span>

blob<span class="token punctuation">.</span><span class="token function">as_bytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
b'meow meow\xf0\x9f\x90\xb1 \n meow meow\xf0\x9f\x90\xb1 \n meow\xf0\x9f\x98\xbb\xf0\x9f\x98\xbb'

blob<span class="token punctuation">.</span><span class="token function">as_string</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
'meow meow🐱 \n meow meow🐱 \n meow😻😻'

blob<span class="token punctuation">.</span><span class="token function">as_bytes_io</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">&lt;</span>contextlib<span class="token punctuation">.</span>_GeneratorContextManager at <span class="token number">0x743f34324450</span><span class="token operator">&gt;</span>

blob<span class="token punctuation">.</span>metadata
<span class="token punctuation">{<!-- --></span><span class="token char">'foo'</span><span class="token operator">:</span> <span class="token char">'bar'</span><span class="token punctuation">}</span>

blob<span class="token punctuation">.</span>source
<span class="token char">'./meow.txt'</span>
</code></pre>
    <p>
     虽然解析器封装了将二进制数据解析为文档所需的逻辑，但 blob 加载器 封装了从给定存储位置加载 blobs 所需的逻辑。
    </p>
    <p>
     目前，LangChain 仅支持 FileSystemBlobLoader。
    </p>
    <p>
     您可以使用 FileSystemBlobLoader 加载 blobs，然后使用解析器对其进行解析。
    </p>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>document_loaders<span class="token punctuation">.</span>blob_loaders import FileSystemBlobLoader

blob_loader <span class="token operator">=</span> <span class="token function">FileSystemBlobLoader</span><span class="token punctuation">(</span>path<span class="token operator">=</span><span class="token string">"."</span><span class="token punctuation">,</span> glob<span class="token operator">=</span><span class="token string">"*.mdx"</span><span class="token punctuation">,</span> show_progress<span class="token operator">=</span>True<span class="token punctuation">)</span>

parser <span class="token operator">=</span> <span class="token function">MyParser</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> blob in blob_loader<span class="token punctuation">.</span><span class="token function">yield_blobs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token keyword">for</span> doc in parser<span class="token punctuation">.</span><span class="token function">lazy_parse</span><span class="token punctuation">(</span>blob<span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token function">print</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>
        <span class="token keyword">break</span>
</code></pre>
    <pre><code class="prism language-c">  <span class="token number">0</span><span class="token operator">%</span><span class="token operator">|</span>          <span class="token operator">|</span> <span class="token number">0</span><span class="token operator">/</span><span class="token number">8</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token operator">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token operator">?</span><span class="token punctuation">,</span> <span class="token operator">?</span>it<span class="token operator">/</span>s<span class="token punctuation">]</span>

page_content<span class="token operator">=</span><span class="token char">'# Microsoft Office\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'office_file.mdx'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span><span class="token char">'# Markdown\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'markdown.mdx'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span><span class="token char">'# JSON\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'json.mdx'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span><span class="token char">'---\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'pdf.mdx'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span><span class="token char">'---\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'index.mdx'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span><span class="token char">'# File Directory\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'file_directory.mdx'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span><span class="token char">'# CSV\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'csv.mdx'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span><span class="token char">'# HTML\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'html.mdx'</span><span class="token punctuation">}</span>
</code></pre>
    <p>
     LangChain 具有一个 GenericLoader 抽象，它将 BlobLoader 与 BaseBlobParser 组合在一起。
    </p>
    <p>
     GenericLoader 旨在提供标准化的类方法，使使用现有的 BlobLoader 实现变得简单。目前，仅支持 FileSystemBlobLoader。
    </p>
    <pre><code class="prism language-c">from langchain_community<span class="token punctuation">.</span>document_loaders<span class="token punctuation">.</span>generic import GenericLoader

loader <span class="token operator">=</span> GenericLoader<span class="token punctuation">.</span><span class="token function">from_filesystem</span><span class="token punctuation">(</span>
    path<span class="token operator">=</span><span class="token string">"."</span><span class="token punctuation">,</span> glob<span class="token operator">=</span><span class="token string">"*.mdx"</span><span class="token punctuation">,</span> show_progress<span class="token operator">=</span>True<span class="token punctuation">,</span> parser<span class="token operator">=</span><span class="token function">MyParser</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token keyword">for</span> idx<span class="token punctuation">,</span> doc in <span class="token function">enumerate</span><span class="token punctuation">(</span>loader<span class="token punctuation">.</span><span class="token function">lazy_load</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token keyword">if</span> idx <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token operator">:</span>
        <span class="token function">print</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>

<span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"... output truncated for demo purposes"</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">  <span class="token number">0</span><span class="token operator">%</span><span class="token operator">|</span>          <span class="token operator">|</span> <span class="token number">0</span><span class="token operator">/</span><span class="token number">8</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token operator">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token operator">?</span><span class="token punctuation">,</span> <span class="token operator">?</span>it<span class="token operator">/</span>s<span class="token punctuation">]</span>

page_content<span class="token operator">=</span><span class="token char">'# Microsoft Office\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'office_file.mdx'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span><span class="token char">'\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'office_file.mdx'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span>'<span class="token operator">&gt;</span><span class="token punctuation">[</span>The Microsoft Office<span class="token punctuation">]</span><span class="token punctuation">(</span>https<span class="token operator">:</span><span class="token comment">//www.office.com/) suite of productivity software includes Microsoft Word, Microsoft Excel, Microsoft PowerPoint, Microsoft Outlook, and Microsoft OneNote. It is available for Microsoft Windows and macOS operating systems. It is also available on Android and iOS.\n' metadata={'line_number': 3, 'source': 'office_file.mdx'}</span>
page_content<span class="token operator">=</span><span class="token char">'\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'office_file.mdx'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span>'This covers how to load commonly used file formats including `DOCX`<span class="token punctuation">,</span> `XLSX` and `PPTX` documents into a document format that we can use downstream<span class="token punctuation">.</span>\n<span class="token char">' metadata={'</span>line_number<span class="token char">': 5, '</span>source<span class="token char">': '</span>office_file<span class="token punctuation">.</span>mdx'<span class="token punctuation">}</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> output truncated <span class="token keyword">for</span> demo purposes
</code></pre>
    <p>
     如果你真的喜欢创建类，你可以继承并创建一个类来封装逻辑。
    </p>
    <p>
     你可以从这个类继承，以使用现有的加载器加载内容。
    </p>
    <pre><code class="prism language-c">from typing import Any


class <span class="token function">MyCustomLoader</span><span class="token punctuation">(</span>GenericLoader<span class="token punctuation">)</span><span class="token operator">:</span>
    @staticmethod
    def <span class="token function">get_parser</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token operator">*</span>kwargs<span class="token operator">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> BaseBlobParser<span class="token operator">:</span>
        <span class="token string">""</span><span class="token string">"Override this method to associate a default parser with the class."</span><span class="token string">""</span>
        <span class="token keyword">return</span> <span class="token function">MyParser</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">loader <span class="token operator">=</span> MyCustomLoader<span class="token punctuation">.</span><span class="token function">from_filesystem</span><span class="token punctuation">(</span>path<span class="token operator">=</span><span class="token string">"."</span><span class="token punctuation">,</span> glob<span class="token operator">=</span><span class="token string">"*.mdx"</span><span class="token punctuation">,</span> show_progress<span class="token operator">=</span>True<span class="token punctuation">)</span>

<span class="token keyword">for</span> idx<span class="token punctuation">,</span> doc in <span class="token function">enumerate</span><span class="token punctuation">(</span>loader<span class="token punctuation">.</span><span class="token function">lazy_load</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token keyword">if</span> idx <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token operator">:</span>
        <span class="token function">print</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>

<span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"... output truncated for demo purposes"</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">  <span class="token number">0</span><span class="token operator">%</span><span class="token operator">|</span>          <span class="token operator">|</span> <span class="token number">0</span><span class="token operator">/</span><span class="token number">8</span> <span class="token punctuation">[</span><span class="token number">00</span><span class="token operator">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token operator">?</span><span class="token punctuation">,</span> <span class="token operator">?</span>it<span class="token operator">/</span>s<span class="token punctuation">]</span>

page_content<span class="token operator">=</span><span class="token char">'# Microsoft Office\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'office_file.mdx'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span><span class="token char">'\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'office_file.mdx'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span>'<span class="token operator">&gt;</span><span class="token punctuation">[</span>The Microsoft Office<span class="token punctuation">]</span><span class="token punctuation">(</span>https<span class="token operator">:</span><span class="token comment">//www.office.com/) suite of productivity software includes Microsoft Word, Microsoft Excel, Microsoft PowerPoint, Microsoft Outlook, and Microsoft OneNote. It is available for Microsoft Windows and macOS operating systems. It is also available on Android and iOS.\n' metadata={'line_number': 3, 'source': 'office_file.mdx'}</span>
page_content<span class="token operator">=</span><span class="token char">'\n'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'line_number'</span><span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token char">'source'</span><span class="token operator">:</span> <span class="token char">'office_file.mdx'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span>'This covers how to load commonly used file formats including `DOCX`<span class="token punctuation">,</span> `XLSX` and `PPTX` documents into a document format that we can use downstream<span class="token punctuation">.</span>\n<span class="token char">' metadata={'</span>line_number<span class="token char">': 5, '</span>source<span class="token char">': '</span>office_file<span class="token punctuation">.</span>mdx'<span class="token punctuation">}</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> output truncated <span class="token keyword">for</span> demo purposes
</code></pre>
    <h2>
     <a id="_3125">
     </a>
     文本分割组件
    </h2>
    <p>
     一旦加载文档，通常需要对其进行转换，使其更适应您的应用场景。最常见的需求是将一篇长文档拆分成适合模型上下文窗口的小块。LangChain 提供了多种内置的文档转换工具，方便进行拆分、合并、过滤等操作。
    </p>
    <p>
     在处理长文本时，拆分文本是必要的。虽然看似简单，但其中存在许多潜在的复杂性。理想情况下，希望将语义相关的文本片段放在一起，而“语义相关”具体指什么，则取决于文本的类型。本示例展示了几种不同的实现方式。
    </p>
    <p>
     从整体流程来看，文本分割器的工作方式如下：
    </p>
    <ol>
     <li>
      将文本拆分成较小的、具有语义意义的片段（通常是句子）。
     </li>
     <li>
      逐步合并这些小片段，直到达到设定的块大小（通过特定的度量方式确定）。
     </li>
     <li>
      一旦达到该大小，就将其作为独立文本块，并开始创建新的文本块，同时保留部分重叠，以维持块之间的上下文联系。
     </li>
    </ol>
    <p>
     因此，文本分割器可以在两个方面进行定制：
    </p>
    <ul>
     <li>
      <strong>
       文本的拆分方式
      </strong>
      ：如何划分文本片段
     </li>
     <li>
      <strong>
       块大小的衡量标准
      </strong>
      ：如何确定合适的块大小
     </li>
    </ul>
    <h3>
     <a id="_3141">
     </a>
     按字符递归分割文本
    </h3>
    <p>
     这个文本分割器是推荐用于通用文本的。它通过字符列表进行参数化。它尝试按顺序在这些字符上进行分割，直到块的大小足够小。默认列表是
     <code>
      ['\n\n', '\n', ' ', '']
     </code>
     。这会尽量保持所有段落（然后是句子，再然后是单词）在一起，因为这些通常被认为是语义上最相关的文本片段。
    </p>
    <p>
     注：
    </p>
    <ul>
     <li>
      要直接获取字符串内容，请使用 .split_text。
     </li>
     <li>
      要创建 LangChain 文档 对象（例如，用于下游任务），请使用 .create_documents。
     </li>
    </ul>
    <pre><code class="prism language-c">pip install <span class="token operator">-</span>qU langchain<span class="token operator">-</span>text<span class="token operator">-</span>splitters
</code></pre>
    <pre><code class="prism language-c">from langchain_text_splitters import RecursiveCharacterTextSplitter

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Load example document</span></span>
with <span class="token function">open</span><span class="token punctuation">(</span><span class="token string">"state_of_the_union.txt"</span><span class="token punctuation">)</span> as f<span class="token operator">:</span>
    state_of_the_union <span class="token operator">=</span> f<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

text_splitter <span class="token operator">=</span> <span class="token function">RecursiveCharacterTextSplitter</span><span class="token punctuation">(</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Set a really small chunk size<span class="token punctuation">,</span> just to show<span class="token punctuation">.</span></span></span>
    chunk_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
    chunk_overlap<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
    length_function<span class="token operator">=</span>len<span class="token punctuation">,</span>
    is_separator_regex<span class="token operator">=</span>False<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
texts <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span><span class="token function">create_documents</span><span class="token punctuation">(</span><span class="token punctuation">[</span>state_of_the_union<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>texts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>texts<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">//</span>
page_content<span class="token operator">=</span>'Madam Speaker<span class="token punctuation">,</span> Madam Vice President<span class="token punctuation">,</span> our First Lady and Second Gentleman<span class="token punctuation">.</span> Members of Congress and'
page_content<span class="token operator">=</span>'of Congress and the Cabinet<span class="token punctuation">.</span> Justices of the Supreme Court<span class="token punctuation">.</span> My fellow Americans<span class="token punctuation">.</span>'
</code></pre>
    <p>
     如果只需要切分后的文档信息，可以使用split_text：
    </p>
    <pre><code class="prism language-c">text_splitter<span class="token punctuation">.</span><span class="token function">split_text</span><span class="token punctuation">(</span>state_of_the_union<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">2</span><span class="token punctuation">]</span>

<span class="token punctuation">[</span>'Madam Speaker<span class="token punctuation">,</span> Madam Vice President<span class="token punctuation">,</span> our First Lady and Second Gentleman<span class="token punctuation">.</span> Members of Congress and'<span class="token punctuation">,</span>
 'of Congress and the Cabinet<span class="token punctuation">.</span> Justices of the Supreme Court<span class="token punctuation">.</span> My fellow Americans<span class="token punctuation">.</span>'<span class="token punctuation">]</span>
</code></pre>
    <p>
     上面为 RecursiveCharacterTextSplitter 设置的参数：
    </p>
    <ul>
     <li>
      chunk_size: 每个块的最大大小，大小由 length_function 决定。
     </li>
     <li>
      chunk_overlap: 块之间的目标重叠。重叠的块有助于减轻在块之间划分上下文时信息的丢失。
     </li>
     <li>
      length_function: 确定块大小的函数。
     </li>
     <li>
      is_separator_regex: 分隔符列表（默认为 [‘\n\n’, ‘\n’, ’ ', ‘’]）是否应被解释为正则表达式。
     </li>
    </ul>
    <p>
     某些语言的书写系统没有明显的词边界，例如中文、日文和泰文。如果使用默认的分隔符列表
     <code>
      ['\n\n', '\n', ' ', '']
     </code>
     进行文本拆分，可能会导致单词被错误地拆分到不同的块中。为了尽可能保持单词完整，可以自定义分隔符列表，并额外添加以下标点符号：
    </p>
    <ul>
     <li>
      <strong>
       句号
      </strong>
      ：包括 ASCII 句号
      <code>
       .
      </code>
      、Unicode 全角句号
      <code>
       ．
      </code>
      （常用于中文文本）以及表意全角句号
      <code>
       。
      </code>
      （用于日文和中文）。
     </li>
     <li>
      <strong>
       零宽空格
      </strong>
      ：用于泰文、缅甸文、柬埔寨文和日文，以更自然地分隔文本。
     </li>
     <li>
      <strong>
       逗号
      </strong>
      ：包括 ASCII 逗号
      <code>
       ,
      </code>
      、Unicode 全角逗号
      <code>
       ，
      </code>
      以及表意逗号
      <code>
       、
      </code>
      （常用于中文和日文）。
     </li>
    </ul>
    <pre><code class="prism language-c">text_splitter <span class="token operator">=</span> <span class="token function">RecursiveCharacterTextSplitter</span><span class="token punctuation">(</span>
    separators<span class="token operator">=</span><span class="token punctuation">[</span>
        <span class="token string">"\n\n"</span><span class="token punctuation">,</span>
        <span class="token string">"\n"</span><span class="token punctuation">,</span>
        <span class="token string">" "</span><span class="token punctuation">,</span>
        <span class="token string">"."</span><span class="token punctuation">,</span>
        <span class="token string">","</span><span class="token punctuation">,</span>
        <span class="token string">"\u200b"</span><span class="token punctuation">,</span>  # Zero<span class="token operator">-</span>width space
        <span class="token string">"\uff0c"</span><span class="token punctuation">,</span>  # Fullwidth comma
        <span class="token string">"\u3001"</span><span class="token punctuation">,</span>  # Ideographic comma
        <span class="token string">"\uff0e"</span><span class="token punctuation">,</span>  # Fullwidth full stop
        <span class="token string">"\u3002"</span><span class="token punctuation">,</span>  # Ideographic full stop
        <span class="token string">""</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Existing args</span></span>
<span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="HTML_3211">
     </a>
     按HTML分割文本
    </h3>
    <h4>
     <a id="HTML__3212">
     </a>
     按HTML 头部进行分割
    </h4>
    <p>
     <code>
      HTMLHeaderTextSplitter
     </code>
     是一种
     <strong>
      结构感知
     </strong>
     的文本分块器，它会在 HTML 元素级别拆分文本，并为与特定块
     <strong>
      相关
     </strong>
     的标题添加元数据。它可以选择逐个元素返回文本块，或者将具有相同元数据的元素合并，以达到以下目的：
    </p>
    <ol>
     <li>
      <strong>
       保持语义相关的文本尽可能分组
      </strong>
      ，避免内容被不当拆分。
     </li>
     <li>
      <strong>
       保留文档结构中的上下文信息
      </strong>
      ，充分利用 HTML 结构中的层次关系。
     </li>
    </ol>
    <p>
     该分块器可以与其他文本分割器配合使用，作为文本处理管道的一部分。
    </p>
    <p>
     在使用
     <code>
      HTMLHeaderTextSplitter
     </code>
     时，可以通过
     <code>
      headers_to_split_on
     </code>
     指定需要拆分的标题级别，如下所示：
    </p>
    <pre><code class="prism language-c">from langchain_text_splitters import HTMLSectionSplitter

html_string <span class="token operator">=</span> <span class="token string">""</span>"
<span class="token operator">&lt;</span><span class="token operator">!</span>DOCTYPE html<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>html<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>body<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>div<span class="token operator">&gt;</span>
        <span class="token operator">&lt;</span>h1<span class="token operator">&gt;</span>Foo<span class="token operator">&lt;</span><span class="token operator">/</span>h1<span class="token operator">&gt;</span>
        <span class="token operator">&lt;</span>p<span class="token operator">&gt;</span>Some intro text about Foo<span class="token punctuation">.</span><span class="token operator">&lt;</span><span class="token operator">/</span>p<span class="token operator">&gt;</span>
        <span class="token operator">&lt;</span>div<span class="token operator">&gt;</span>
            <span class="token operator">&lt;</span>h2<span class="token operator">&gt;</span>Bar main section<span class="token operator">&lt;</span><span class="token operator">/</span>h2<span class="token operator">&gt;</span>
            <span class="token operator">&lt;</span>p<span class="token operator">&gt;</span>Some intro text about Bar<span class="token punctuation">.</span><span class="token operator">&lt;</span><span class="token operator">/</span>p<span class="token operator">&gt;</span>
            <span class="token operator">&lt;</span>h3<span class="token operator">&gt;</span>Bar subsection <span class="token number">1</span><span class="token operator">&lt;</span><span class="token operator">/</span>h3<span class="token operator">&gt;</span>
            <span class="token operator">&lt;</span>p<span class="token operator">&gt;</span>Some text about the first subtopic of Bar<span class="token punctuation">.</span><span class="token operator">&lt;</span><span class="token operator">/</span>p<span class="token operator">&gt;</span>
            <span class="token operator">&lt;</span>h3<span class="token operator">&gt;</span>Bar subsection <span class="token number">2</span><span class="token operator">&lt;</span><span class="token operator">/</span>h3<span class="token operator">&gt;</span>
            <span class="token operator">&lt;</span>p<span class="token operator">&gt;</span>Some text about the second subtopic of Bar<span class="token punctuation">.</span><span class="token operator">&lt;</span><span class="token operator">/</span>p<span class="token operator">&gt;</span>
        <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">&gt;</span>
        <span class="token operator">&lt;</span>div<span class="token operator">&gt;</span>
            <span class="token operator">&lt;</span>h2<span class="token operator">&gt;</span>Baz<span class="token operator">&lt;</span><span class="token operator">/</span>h2<span class="token operator">&gt;</span>
            <span class="token operator">&lt;</span>p<span class="token operator">&gt;</span>Some text about Baz<span class="token operator">&lt;</span><span class="token operator">/</span>p<span class="token operator">&gt;</span>
        <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">&gt;</span>
        <span class="token operator">&lt;</span>br<span class="token operator">&gt;</span>
        <span class="token operator">&lt;</span>p<span class="token operator">&gt;</span>Some concluding text about Foo<span class="token operator">&lt;</span><span class="token operator">/</span>p<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>body<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>html<span class="token operator">&gt;</span>
<span class="token string">""</span>"

headers_to_split_on <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"h1"</span><span class="token punctuation">,</span> <span class="token string">"Header 1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"h2"</span><span class="token punctuation">,</span> <span class="token string">"Header 2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"h3"</span><span class="token punctuation">,</span> <span class="token string">"Header 3"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

html_splitter <span class="token operator">=</span> <span class="token function">HTMLHeaderTextSplitter</span><span class="token punctuation">(</span>headers_to_split_on<span class="token punctuation">)</span>
html_header_splits <span class="token operator">=</span> html_splitter<span class="token punctuation">.</span><span class="token function">split_text</span><span class="token punctuation">(</span>html_string<span class="token punctuation">)</span>
html_header_splits
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Foo'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'Some intro text about Foo<span class="token punctuation">.</span>  \nBar main section Bar subsection <span class="token number">1</span> Bar subsection <span class="token number">2</span><span class="token char">', metadata={'</span>Header <span class="token number">1</span><span class="token char">': '</span>Foo'<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Some intro text about Bar.'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">,</span> <span class="token char">'Header 2'</span><span class="token operator">:</span> <span class="token char">'Bar main section'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'Some text about the first subtopic of Bar<span class="token punctuation">.</span><span class="token char">', metadata={'</span>Header <span class="token number">1</span><span class="token char">': '</span>Foo<span class="token char">', '</span>Header <span class="token number">2</span><span class="token char">': '</span>Bar main section<span class="token char">', '</span>Header <span class="token number">3</span><span class="token char">': '</span>Bar subsection <span class="token number">1</span>'<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'Some text about the second subtopic of Bar<span class="token punctuation">.</span><span class="token char">', metadata={'</span>Header <span class="token number">1</span><span class="token char">': '</span>Foo<span class="token char">', '</span>Header <span class="token number">2</span><span class="token char">': '</span>Bar main section<span class="token char">', '</span>Header <span class="token number">3</span><span class="token char">': '</span>Bar subsection <span class="token number">2</span>'<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Baz'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Some text about Baz'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">,</span> <span class="token char">'Header 2'</span><span class="token operator">:</span> <span class="token char">'Baz'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Some concluding text about Foo'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     要将每个元素与其相关的标题一起返回，在实例化 HTMLHeaderTextSplitter 时指定 return_each_element=True：
    </p>
    <pre><code class="prism language-c">html_splitter <span class="token operator">=</span> <span class="token function">HTMLHeaderTextSplitter</span><span class="token punctuation">(</span>
    headers_to_split_on<span class="token punctuation">,</span>
    return_each_element<span class="token operator">=</span>True<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
html_header_splits_elements <span class="token operator">=</span> html_splitter<span class="token punctuation">.</span><span class="token function">split_text</span><span class="token punctuation">(</span>html_string<span class="token punctuation">)</span>
</code></pre>
    <p>
     与上述内容相比，元素按其标题聚合：
    </p>
    <pre><code class="prism language-c"><span class="token keyword">for</span> element in html_header_splits<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>element<span class="token punctuation">)</span>

page_content<span class="token operator">=</span><span class="token char">'Foo'</span>
page_content<span class="token operator">=</span>'Some intro text about Foo<span class="token punctuation">.</span>  \nBar main section Bar subsection <span class="token number">1</span> Bar subsection <span class="token number">2</span><span class="token char">' metadata={'</span>Header <span class="token number">1</span><span class="token char">': '</span>Foo'<span class="token punctuation">}</span>
</code></pre>
    <p>
     现在每个元素作为一个独立的 Document 返回：
    </p>
    <pre><code class="prism language-c"><span class="token keyword">for</span> element in html_header_splits_elements<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>element<span class="token punctuation">)</span>

page_content<span class="token operator">=</span><span class="token char">'Foo'</span>
page_content<span class="token operator">=</span><span class="token char">'Some intro text about Foo.'</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">}</span>
page_content<span class="token operator">=</span>'Bar main section Bar subsection <span class="token number">1</span> Bar subsection <span class="token number">2</span><span class="token char">' metadata={'</span>Header <span class="token number">1</span><span class="token char">': '</span>Foo'<span class="token punctuation">}</span>
</code></pre>
    <p>
     <strong>
      如何从 URL 或 HTML 文件中拆分？
     </strong>
    </p>
    <p>
     要直接从 URL 读取，可以将 URL 字符串传递给 split_text_from_url 方法。同样，可以将本地 HTML 文件传递给 split_text_from_file 方法。
    </p>
    <pre><code class="prism language-c">url <span class="token operator">=</span> <span class="token string">"https://plato.stanford.edu/entries/goedel/"</span>

headers_to_split_on <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"h1"</span><span class="token punctuation">,</span> <span class="token string">"Header 1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"h2"</span><span class="token punctuation">,</span> <span class="token string">"Header 2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"h3"</span><span class="token punctuation">,</span> <span class="token string">"Header 3"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"h4"</span><span class="token punctuation">,</span> <span class="token string">"Header 4"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

html_splitter <span class="token operator">=</span> <span class="token function">HTMLHeaderTextSplitter</span><span class="token punctuation">(</span>headers_to_split_on<span class="token punctuation">)</span>

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">for</span> <span class="token expression">local file use html_splitter<span class="token punctuation">.</span><span class="token function">split_text_from_file</span><span class="token punctuation">(</span><span class="token operator">&lt;</span>path_to_file<span class="token operator">&gt;</span><span class="token punctuation">)</span></span></span>
html_header_splits <span class="token operator">=</span> html_splitter<span class="token punctuation">.</span><span class="token function">split_text_from_url</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span>
</code></pre>
    <p>
     HTMLHeaderTextSplitter 根据 HTML 标题进行拆分，可以与另一个根据字符长度限制拆分的拆分器组合，例如 RecursiveCharacterTextSplitter。
    </p>
    <p>
     这可以通过第二个拆分器的 .split_documents 方法完成：
    </p>
    <pre><code class="prism language-c">from langchain_text_splitters import RecursiveCharacterTextSplitter

chunk_size <span class="token operator">=</span> <span class="token number">500</span>
chunk_overlap <span class="token operator">=</span> <span class="token number">30</span>
text_splitter <span class="token operator">=</span> <span class="token function">RecursiveCharacterTextSplitter</span><span class="token punctuation">(</span>
    chunk_size<span class="token operator">=</span>chunk_size<span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span>chunk_overlap
<span class="token punctuation">)</span>

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Split</span></span>
splits <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span><span class="token function">split_documents</span><span class="token punctuation">(</span>html_header_splits<span class="token punctuation">)</span>
splits<span class="token punctuation">[</span><span class="token number">80</span><span class="token operator">:</span><span class="token number">85</span><span class="token punctuation">]</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'We see that Gödel first tried to reduce the consistency problem <span class="token keyword">for</span> analysis to that of arithmetic<span class="token punctuation">.</span> This seemed to require a truth definition <span class="token keyword">for</span> arithmetic<span class="token punctuation">,</span> which in turn led to paradoxes<span class="token punctuation">,</span> such as the Liar <span class="token function">paradox</span> <span class="token punctuation">(</span>“This sentence is false”<span class="token punctuation">)</span> and Berry’s <span class="token function">paradox</span> <span class="token punctuation">(</span>“The least number not defined by an expression consisting of just fourteen English words”<span class="token punctuation">)</span><span class="token punctuation">.</span> Gödel then noticed that such paradoxes would not necessarily arise <span class="token keyword">if</span> truth were replaced by provability<span class="token punctuation">.</span> But this means that arithmetic truth<span class="token char">', metadata={'</span>Header <span class="token number">1</span><span class="token char">': '</span>Kurt Gödel<span class="token char">', '</span>Header <span class="token number">2</span><span class="token char">': '</span><span class="token number">2.</span> Gödel’s Mathematical Work<span class="token char">', '</span>Header <span class="token number">3</span><span class="token char">': '</span><span class="token number">2.2</span> The Incompleteness Theorems<span class="token char">', '</span>Header <span class="token number">4</span><span class="token char">': '</span><span class="token number">2.2</span><span class="token number">.1</span> The First Incompleteness Theorem'<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'means that arithmetic truth and arithmetic provability are not co<span class="token operator">-</span>extensive — whence the First Incompleteness Theorem<span class="token punctuation">.</span><span class="token char">', metadata={'</span>Header <span class="token number">1</span><span class="token char">': '</span>Kurt Gödel<span class="token char">', '</span>Header <span class="token number">2</span><span class="token char">': '</span><span class="token number">2.</span> Gödel’s Mathematical Work<span class="token char">', '</span>Header <span class="token number">3</span><span class="token char">': '</span><span class="token number">2.2</span> The Incompleteness Theorems<span class="token char">', '</span>Header <span class="token number">4</span><span class="token char">': '</span><span class="token number">2.2</span><span class="token number">.1</span> The First Incompleteness Theorem'<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'This account of Gödel’s discovery was told to Hao Wang very much after the fact<span class="token punctuation">;</span> but in Gödel’s contemporary correspondence with Bernays and Zermelo<span class="token punctuation">,</span> essentially the same description of his path to the theorems is given<span class="token punctuation">.</span> <span class="token punctuation">(</span>See Gödel <span class="token number">2003</span>a and Gödel <span class="token number">2003</span>b respectively<span class="token punctuation">.</span><span class="token punctuation">)</span> From those accounts we see that the undefinability of truth in arithmetic<span class="token punctuation">,</span> a result credited to Tarski<span class="token punctuation">,</span> was likely obtained in some form by Gödel by <span class="token number">1931.</span> But he neither publicized nor published the result<span class="token punctuation">;</span> the biases logicians<span class="token char">', metadata={'</span>Header <span class="token number">1</span><span class="token char">': '</span>Kurt Gödel<span class="token char">', '</span>Header <span class="token number">2</span><span class="token char">': '</span><span class="token number">2.</span> Gödel’s Mathematical Work<span class="token char">', '</span>Header <span class="token number">3</span><span class="token char">': '</span><span class="token number">2.2</span> The Incompleteness Theorems<span class="token char">', '</span>Header <span class="token number">4</span><span class="token char">': '</span><span class="token number">2.2</span><span class="token number">.1</span> The First Incompleteness Theorem'<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'result<span class="token punctuation">;</span> the biases logicians had expressed at the time concerning the notion of truth<span class="token punctuation">,</span> biases which came vehemently to the fore when Tarski announced his results on the undefinability of truth in formal systems <span class="token number">1935</span><span class="token punctuation">,</span> may have served as a deterrent to Gödel’s publication of that theorem<span class="token punctuation">.</span><span class="token char">', metadata={'</span>Header <span class="token number">1</span><span class="token char">': '</span>Kurt Gödel<span class="token char">', '</span>Header <span class="token number">2</span><span class="token char">': '</span><span class="token number">2.</span> Gödel’s Mathematical Work<span class="token char">', '</span>Header <span class="token number">3</span><span class="token char">': '</span><span class="token number">2.2</span> The Incompleteness Theorems<span class="token char">', '</span>Header <span class="token number">4</span><span class="token char">': '</span><span class="token number">2.2</span><span class="token number">.1</span> The First Incompleteness Theorem'<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'We now describe the proof of the two theorems<span class="token punctuation">,</span> formulating Gödel’s results in Peano arithmetic<span class="token punctuation">.</span> Gödel himself used a system related to that defined in Principia Mathematica<span class="token punctuation">,</span> but containing Peano arithmetic<span class="token punctuation">.</span> In our presentation of the First and Second Incompleteness Theorems we refer to Peano arithmetic as P<span class="token punctuation">,</span> following Gödel’s notation<span class="token punctuation">.</span><span class="token char">', metadata={'</span>Header <span class="token number">1</span><span class="token char">': '</span>Kurt Gödel<span class="token char">', '</span>Header <span class="token number">2</span><span class="token char">': '</span><span class="token number">2.</span> Gödel’s Mathematical Work<span class="token char">', '</span>Header <span class="token number">3</span><span class="token char">': '</span><span class="token number">2.2</span> The Incompleteness Theorems<span class="token char">', '</span>Header <span class="token number">4</span><span class="token char">': '</span><span class="token number">2.2</span><span class="token number">.2</span> The proof of the First Incompleteness Theorem'<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     不同的HTML文档之间可能存在相当大的结构变化，虽然
     <strong>
      HTMLHeaderTextSplitter会尝试将所有“相关”的标题附加到任何给定的块上，但有时它可能会遗漏某些标题。
     </strong>
    </p>
    <p>
     例如，该算法假设存在一个信息层次结构，其中标题总是在与其相关文本“上方”的节点上，即前兄弟、祖先及其组合。在以下新闻文章中（截至本文撰写时），文档的结构使得顶级标题的文本虽然标记为“h1”，但与我们期望它“上方”的文本元素处于不同的子树中——因此我们可以观察到“h1”元素及其相关文本未出现在块元数据中（但在适用的情况下，我们确实看到了“h2”及其相关文本）：
    </p>
    <pre><code class="prism language-c">url <span class="token operator">=</span> <span class="token string">"https://www.cnn.com/2023/09/25/weather/el-nino-winter-us-climate/index.html"</span>

headers_to_split_on <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"h1"</span><span class="token punctuation">,</span> <span class="token string">"Header 1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"h2"</span><span class="token punctuation">,</span> <span class="token string">"Header 2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

html_splitter <span class="token operator">=</span> <span class="token function">HTMLHeaderTextSplitter</span><span class="token punctuation">(</span>headers_to_split_on<span class="token punctuation">)</span>
html_header_splits <span class="token operator">=</span> html_splitter<span class="token punctuation">.</span><span class="token function">split_text_from_url</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>html_header_splits<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">500</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">No two El Niño winters are the same<span class="token punctuation">,</span> but many have temperature and precipitation trends in common<span class="token punctuation">.</span>  
Average conditions during an El Niño winter across the continental US<span class="token punctuation">.</span>  
One of the major reasons is the position of the jet stream<span class="token punctuation">,</span> which often shifts south during an El Niño winter<span class="token punctuation">.</span> This shift typically brings wetter and cooler weather to the South <span class="token keyword">while</span> the North becomes drier and warmer<span class="token punctuation">,</span> according to NOAA<span class="token punctuation">.</span>  
Because the jet stream is essentially a river of air that storms flow through<span class="token punctuation">,</span> they c
</code></pre>
    <h4>
     <a id="HTML_3367">
     </a>
     按HTML成分进行分割
    </h4>
    <p>
     与
     <code>
      HTMLHeaderTextSplitter
     </code>
     类似，
     <code>
      HTMLSectionSplitter
     </code>
     也是一种
     <strong>
      结构感知
     </strong>
     的分块器，它会在 HTML 元素级别拆分文本，并为每个与特定块
     <strong>
      相关
     </strong>
     的标题添加元数据。
    </p>
    <p>
     该分块器可以选择逐个返回文本块，或者将具有相同元数据的元素合并，以实现以下目标：
    </p>
    <ol>
     <li>
      <strong>
       保持语义相关的文本尽可能归为一组
      </strong>
      ，避免破坏上下文结构。
     </li>
     <li>
      <strong>
       保留 HTML 结构中编码的上下文信息
      </strong>
      ，以便更准确地理解文本层次。
     </li>
    </ol>
    <p>
     <strong>
      HTML 转换与 XSLT 支持
     </strong>
     <br/>
     <code>
      HTMLSectionSplitter
     </code>
     支持使用
     <code>
      xslt_path
     </code>
     指定一个 XSLT 文件的
     <strong>
      绝对路径
     </strong>
     ，用于转换 HTML 结构，以便更精准地检测文本块。
    </p>
    <p>
     默认情况下，它会使用
     <code>
      data_connection/document_transformers
     </code>
     目录下的
     <code>
      converting_to_header.xslt
     </code>
     文件，将 HTML 转换为
     <strong>
      更易于分块
     </strong>
     的格式。例如，可以根据
     <strong>
      字体大小
     </strong>
     将
     <code>
      &lt;span&gt;
     </code>
     标签转换为标题标签，使其在分块时被识别为独立的部分。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> langchain_text_splitters <span class="token keyword">import</span> HTMLSectionSplitter

html_string <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
    &lt;body&gt;
        &lt;div&gt;
            &lt;h1&gt;Foo&lt;/h1&gt;
            &lt;p&gt;Some intro text about Foo.&lt;/p&gt;
            &lt;div&gt;
                &lt;h2&gt;Bar main section&lt;/h2&gt;
                &lt;p&gt;Some intro text about Bar.&lt;/p&gt;
                &lt;h3&gt;Bar subsection 1&lt;/h3&gt;
                &lt;p&gt;Some text about the first subtopic of Bar.&lt;/p&gt;
                &lt;h3&gt;Bar subsection 2&lt;/h3&gt;
                &lt;p&gt;Some text about the second subtopic of Bar.&lt;/p&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;h2&gt;Baz&lt;/h2&gt;
                &lt;p&gt;Some text about Baz&lt;/p&gt;
            &lt;/div&gt;
            &lt;br&gt;
            &lt;p&gt;Some concluding text about Foo&lt;/p&gt;
        &lt;/div&gt;
    &lt;/body&gt;
    &lt;/html&gt;
"""</span>

headers_to_split_on <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"h1"</span><span class="token punctuation">,</span> <span class="token string">"Header 1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"h2"</span><span class="token punctuation">,</span> <span class="token string">"Header 2"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

html_splitter <span class="token operator">=</span> HTMLSectionSplitter<span class="token punctuation">(</span>headers_to_split_on<span class="token punctuation">)</span>
html_header_splits <span class="token operator">=</span> html_splitter<span class="token punctuation">.</span>split_text<span class="token punctuation">(</span>html_string<span class="token punctuation">)</span>
html_header_splits
</code></pre>
    <p>
     HTMLSectionSplitter 可以与其他文本分割器一起使用，作为分块管道的一部分。内部，当节的大小大于块的大小时，它使用 RecursiveCharacterTextSplitter。它还考虑文本的字体大小，以根据确定的字体大小阈值来判断它是否为一个节。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">from</span> langchain_text_splitters <span class="token keyword">import</span> RecursiveCharacterTextSplitter

html_string <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
    &lt;body&gt;
        &lt;div&gt;
            &lt;h1&gt;Foo&lt;/h1&gt;
            &lt;p&gt;Some intro text about Foo.&lt;/p&gt;
            &lt;div&gt;
                &lt;h2&gt;Bar main section&lt;/h2&gt;
                &lt;p&gt;Some intro text about Bar.&lt;/p&gt;
                &lt;h3&gt;Bar subsection 1&lt;/h3&gt;
                &lt;p&gt;Some text about the first subtopic of Bar.&lt;/p&gt;
                &lt;h3&gt;Bar subsection 2&lt;/h3&gt;
                &lt;p&gt;Some text about the second subtopic of Bar.&lt;/p&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;h2&gt;Baz&lt;/h2&gt;
                &lt;p&gt;Some text about Baz&lt;/p&gt;
            &lt;/div&gt;
            &lt;br&gt;
            &lt;p&gt;Some concluding text about Foo&lt;/p&gt;
        &lt;/div&gt;
    &lt;/body&gt;
    &lt;/html&gt;
"""</span>

headers_to_split_on <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"h1"</span><span class="token punctuation">,</span> <span class="token string">"Header 1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"h2"</span><span class="token punctuation">,</span> <span class="token string">"Header 2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"h3"</span><span class="token punctuation">,</span> <span class="token string">"Header 3"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"h4"</span><span class="token punctuation">,</span> <span class="token string">"Header 4"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

html_splitter <span class="token operator">=</span> HTMLSectionSplitter<span class="token punctuation">(</span>headers_to_split_on<span class="token punctuation">)</span>

html_header_splits <span class="token operator">=</span> html_splitter<span class="token punctuation">.</span>split_text<span class="token punctuation">(</span>html_string<span class="token punctuation">)</span>

chunk_size <span class="token operator">=</span> <span class="token number">500</span>
chunk_overlap <span class="token operator">=</span> <span class="token number">30</span>
text_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>
    chunk_size<span class="token operator">=</span>chunk_size<span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span>chunk_overlap
<span class="token punctuation">)</span>

<span class="token comment"># Split</span>
splits <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>html_header_splits<span class="token punctuation">)</span>
splits
</code></pre>
    <pre><code class="prism language-python"><span class="token punctuation">[</span>Document<span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token string">'Foo \n Some intro text about Foo.'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'Header 1'</span><span class="token punctuation">:</span> <span class="token string">'Foo'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 Document<span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token string">'Bar main section \n Some intro text about Bar.'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'Header 2'</span><span class="token punctuation">:</span> <span class="token string">'Bar main section'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 Document<span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token string">'Bar subsection 1 \n Some text about the first subtopic of Bar.'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'Header 3'</span><span class="token punctuation">:</span> <span class="token string">'Bar subsection 1'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 Document<span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token string">'Bar subsection 2 \n Some text about the second subtopic of Bar.'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'Header 3'</span><span class="token punctuation">:</span> <span class="token string">'Bar subsection 2'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 Document<span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token string">'Baz \n Some text about Baz \n \n \n Some concluding text about Foo'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'Header 2'</span><span class="token punctuation">:</span> <span class="token string">'Baz'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     注意：HTMLHeaderTextSplitter和HTMLSectionSplitter属于两种特殊分割器，并没有继承BaseSpliter，所以没有create_documents等方法；
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/cc57ff231fee4c6f93912fd1ce2286f3.png"/>
    </p>
    <h3>
     <a id="_3479">
     </a>
     按字符分割
    </h3>
    <p>
     这是最简单的方法。它基于给定的字符序列进行分割，默认值为"\n\n"。块长度以字符数来衡量。（要创建LangChain 文档 对象（例如，用于下游任务），请使用.create_documents。）
    </p>
    <pre><code class="prism language-c">from langchain_text_splitters import CharacterTextSplitter

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Load an example document</span></span>
with <span class="token function">open</span><span class="token punctuation">(</span><span class="token string">"state_of_the_union.txt"</span><span class="token punctuation">)</span> as f<span class="token operator">:</span>
    state_of_the_union <span class="token operator">=</span> f<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

text_splitter <span class="token operator">=</span> <span class="token function">CharacterTextSplitter</span><span class="token punctuation">(</span>
    separator<span class="token operator">=</span><span class="token string">"\n\n"</span><span class="token punctuation">,</span>
    chunk_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>
    chunk_overlap<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
    length_function<span class="token operator">=</span>len<span class="token punctuation">,</span>
    is_separator_regex<span class="token operator">=</span>False<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
texts <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span><span class="token function">create_documents</span><span class="token punctuation">(</span><span class="token punctuation">[</span>state_of_the_union<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>texts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">page_content<span class="token operator">=</span>'Madam Speaker<span class="token punctuation">,</span> Madam Vice President<span class="token punctuation">,</span> our First Lady and Second Gentleman<span class="token punctuation">.</span> Members of Congress and the Cabinet<span class="token punctuation">.</span> Justices of the Supreme Court<span class="token punctuation">.</span> My fellow Americans<span class="token punctuation">.</span>  \n\nLast year COVID<span class="token operator">-</span><span class="token number">19</span> kept us apart<span class="token punctuation">.</span> This year we are finally together again<span class="token punctuation">.</span> \n\nTonight<span class="token punctuation">,</span> we meet as Democrats Republicans and Independents<span class="token punctuation">.</span> But most importantly as Americans<span class="token punctuation">.</span> \n\nWith a duty to one another to the American people to the Constitution<span class="token punctuation">.</span> \n\nAnd with an unwavering resolve that freedom will always triumph over tyranny<span class="token punctuation">.</span> \n\nSix days ago<span class="token punctuation">,</span> Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways<span class="token punctuation">.</span> But he badly miscalculated<span class="token punctuation">.</span> \n\nHe thought he could roll into Ukraine and the world would roll over<span class="token punctuation">.</span> Instead he met a wall of strength he never imagined<span class="token punctuation">.</span> \n\nHe met the Ukrainian people<span class="token punctuation">.</span> \n\nFrom President Zelenskyy to every Ukrainian<span class="token punctuation">,</span> their fearlessness<span class="token punctuation">,</span> their courage<span class="token punctuation">,</span> their determination<span class="token punctuation">,</span> inspires the world<span class="token punctuation">.</span>'
</code></pre>
    <p>
     使用
     <code>
      .create_documents
     </code>
     将与每个文档相关的元数据传播到输出块：
    </p>
    <pre><code class="prism language-c">metadatas <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"document"</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"document"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
documents <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span><span class="token function">create_documents</span><span class="token punctuation">(</span>
    <span class="token punctuation">[</span>state_of_the_union<span class="token punctuation">,</span> state_of_the_union<span class="token punctuation">]</span><span class="token punctuation">,</span> metadatas<span class="token operator">=</span>metadatas
<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>documents<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     使用 .split_text 直接获取字符串内容：
    </p>
    <pre><code class="prism language-c">text_splitter<span class="token punctuation">.</span><span class="token function">split_text</span><span class="token punctuation">(</span>state_of_the_union<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre>
    <h3>
     <a id="_3517">
     </a>
     分割代码
    </h3>
    <p>
     递归字符文本分割器 包含用于在特定编程语言中分割文本的预构建
     <strong>
      分隔符列表
     </strong>
     。
    </p>
    <p>
     支持的语言存储在 langchain_text_splitters.Language 枚举中。它们包括：
    </p>
    <pre><code class="prism language-c"><span class="token string">"cpp"</span><span class="token punctuation">,</span>
<span class="token string">"go"</span><span class="token punctuation">,</span>
<span class="token string">"java"</span><span class="token punctuation">,</span>
<span class="token string">"kotlin"</span><span class="token punctuation">,</span>
<span class="token string">"js"</span><span class="token punctuation">,</span>
<span class="token string">"ts"</span><span class="token punctuation">,</span>
<span class="token string">"php"</span><span class="token punctuation">,</span>
<span class="token string">"proto"</span><span class="token punctuation">,</span>
<span class="token string">"python"</span><span class="token punctuation">,</span>
<span class="token string">"rst"</span><span class="token punctuation">,</span>
<span class="token string">"ruby"</span><span class="token punctuation">,</span>
<span class="token string">"rust"</span><span class="token punctuation">,</span>
<span class="token string">"scala"</span><span class="token punctuation">,</span>
<span class="token string">"swift"</span><span class="token punctuation">,</span>
<span class="token string">"markdown"</span><span class="token punctuation">,</span>
<span class="token string">"latex"</span><span class="token punctuation">,</span>
<span class="token string">"html"</span><span class="token punctuation">,</span>
<span class="token string">"sol"</span><span class="token punctuation">,</span>
<span class="token string">"csharp"</span><span class="token punctuation">,</span>
<span class="token string">"cobol"</span><span class="token punctuation">,</span>
<span class="token string">"c"</span><span class="token punctuation">,</span>
<span class="token string">"lua"</span><span class="token punctuation">,</span>
<span class="token string">"perl"</span><span class="token punctuation">,</span>
<span class="token string">"haskell"</span>
</code></pre>
    <p>
     要查看给定语言的分隔符列表，请将此枚举中的值传入
    </p>
    <pre><code class="prism language-c">RecursiveCharacterTextSplitter<span class="token punctuation">.</span>get_separators_for_language
</code></pre>
    <p>
     要实例化一个针对特定语言的分割器，请将枚举中的值传入
    </p>
    <pre><code class="prism language-c">RecursiveCharacterTextSplitter<span class="token punctuation">.</span>from_language
</code></pre>
    <p>
     可以查看给定语言使用的分隔符：
    </p>
    <pre><code class="prism language-c">from langchain_text_splitters <span class="token function">import</span> <span class="token punctuation">(</span>
    Language<span class="token punctuation">,</span>
    RecursiveCharacterTextSplitter<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
RecursiveCharacterTextSplitter<span class="token punctuation">.</span><span class="token function">get_separators_for_language</span><span class="token punctuation">(</span>Language<span class="token punctuation">.</span>PYTHON<span class="token punctuation">)</span>
</code></pre>
    <p>
     分割python：
    </p>
    <pre><code class="prism language-c">PYTHON_CODE <span class="token operator">=</span> <span class="token string">""</span>"
def <span class="token function">hello_world</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"Hello, World!"</span><span class="token punctuation">)</span>

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Call the function</span></span>
<span class="token function">hello_world</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token string">""</span>"
python_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">.</span><span class="token function">from_language</span><span class="token punctuation">(</span>
    language<span class="token operator">=</span>Language<span class="token punctuation">.</span>PYTHON<span class="token punctuation">,</span> chunk_size<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span><span class="token number">0</span>
<span class="token punctuation">)</span>
python_docs <span class="token operator">=</span> python_splitter<span class="token punctuation">.</span><span class="token function">create_documents</span><span class="token punctuation">(</span><span class="token punctuation">[</span>PYTHON_CODE<span class="token punctuation">]</span><span class="token punctuation">)</span>
python_docs

<span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'def <span class="token function">hello_world</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>\n    <span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"Hello, World!"</span><span class="token punctuation">)</span>'<span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'# Call the function\<span class="token function">nhello_world</span><span class="token punctuation">(</span><span class="token punctuation">)</span>'<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     Markdown：
    </p>
    <pre><code class="prism language-c">markdown_text <span class="token operator">=</span> <span class="token string">""</span>"
# 🦜️🔗 LangChain

⚡ Building applications with LLMs through composability ⚡

## Quick Install

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Hopefully this code block isn't split</span></span>
pip install langchain

As an open<span class="token operator">-</span>source project in a rapidly developing field<span class="token punctuation">,</span> we are extremely open to contributions<span class="token punctuation">.</span>
<span class="token string">""</span>"

md_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">.</span><span class="token function">from_language</span><span class="token punctuation">(</span>
    language<span class="token operator">=</span>Language<span class="token punctuation">.</span>MARKDOWN<span class="token punctuation">,</span> chunk_size<span class="token operator">=</span><span class="token number">60</span><span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span><span class="token number">0</span>
<span class="token punctuation">)</span>
md_docs <span class="token operator">=</span> md_splitter<span class="token punctuation">.</span><span class="token function">create_documents</span><span class="token punctuation">(</span><span class="token punctuation">[</span>markdown_text<span class="token punctuation">]</span><span class="token punctuation">)</span>
md_docs

<span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'# 🦜️🔗 LangChain'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'⚡ Building applications with LLMs through composability ⚡'<span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'## Quick Install'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token string">"# Hopefully this code block isn't split"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'pip install langchain'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'As an open<span class="token operator">-</span>source project in a rapidly developing field<span class="token punctuation">,</span> we'<span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'are extremely open to contributions<span class="token punctuation">.</span>'<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <h3>
     <a id="Markdown_3617">
     </a>
     按标题分割Markdown
    </h3>
    <p>
     markdown 文件是通过标题组织的。在特定标题组内创建块是一个直观的想法。为了解决这个挑战，我们可以使用 MarkdownHeaderTextSplitter。这将根据指定的标题集拆分 markdown 文件。
    </p>
    <pre><code class="prism language-c">from langchain_text_splitters import MarkdownHeaderTextSplitter

markdown_document <span class="token operator">=</span> <span class="token string">"# Foo\n\n    ## Bar\n\nHi this is Jim\n\nHi this is Joe\n\n ### Boo \n\n Hi this is Lance \n\n ## Baz\n\n Hi this is Molly"</span>

headers_to_split_on <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"#"</span><span class="token punctuation">,</span> <span class="token string">"Header 1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"##"</span><span class="token punctuation">,</span> <span class="token string">"Header 2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"###"</span><span class="token punctuation">,</span> <span class="token string">"Header 3"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

markdown_splitter <span class="token operator">=</span> <span class="token function">MarkdownHeaderTextSplitter</span><span class="token punctuation">(</span>headers_to_split_on<span class="token punctuation">)</span>
md_header_splits <span class="token operator">=</span> markdown_splitter<span class="token punctuation">.</span><span class="token function">split_text</span><span class="token punctuation">(</span>markdown_document<span class="token punctuation">)</span>
md_header_splits

<span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Hi this is Jim  \nHi this is Joe'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">,</span> <span class="token char">'Header 2'</span><span class="token operator">:</span> <span class="token char">'Bar'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Hi this is Lance'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">,</span> <span class="token char">'Header 2'</span><span class="token operator">:</span> <span class="token char">'Bar'</span><span class="token punctuation">,</span> <span class="token char">'Header 3'</span><span class="token operator">:</span> <span class="token char">'Boo'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Hi this is Molly'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">,</span> <span class="token char">'Header 2'</span><span class="token operator">:</span> <span class="token char">'Baz'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     默认情况下，MarkdownHeaderTextSplitter 会从输出块的内容中剥离正在拆分的标题。通过设置 strip_headers = False 可以禁用此功能。
    </p>
    <pre><code class="prism language-c">markdown_splitter <span class="token operator">=</span> <span class="token function">MarkdownHeaderTextSplitter</span><span class="token punctuation">(</span>headers_to_split_on<span class="token punctuation">,</span> strip_headers<span class="token operator">=</span>False<span class="token punctuation">)</span>
md_header_splits <span class="token operator">=</span> markdown_splitter<span class="token punctuation">.</span><span class="token function">split_text</span><span class="token punctuation">(</span>markdown_document<span class="token punctuation">)</span>
md_header_splits

<span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'# Foo  \n## Bar  \nHi this is Jim  \nHi this is Joe<span class="token char">', metadata={'</span>Header <span class="token number">1</span><span class="token char">': '</span>Foo<span class="token char">', '</span>Header <span class="token number">2</span><span class="token char">': '</span>Bar'<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'### Boo  \nHi this is Lance'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">,</span> <span class="token char">'Header 2'</span><span class="token operator">:</span> <span class="token char">'Bar'</span><span class="token punctuation">,</span> <span class="token char">'Header 3'</span><span class="token operator">:</span> <span class="token char">'Boo'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'## Baz  \nHi this is Molly'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">,</span> <span class="token char">'Header 2'</span><span class="token operator">:</span> <span class="token char">'Baz'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     默认情况下，MarkdownHeaderTextSplitter 根据 headers_to_split_on 中指定的标题聚合行。我们可以通过指定 return_each_line 来禁用此功能：
    </p>
    <pre><code class="prism language-c">markdown_splitter <span class="token operator">=</span> <span class="token function">MarkdownHeaderTextSplitter</span><span class="token punctuation">(</span>
    headers_to_split_on<span class="token punctuation">,</span>
    return_each_line<span class="token operator">=</span>True<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
md_header_splits <span class="token operator">=</span> markdown_splitter<span class="token punctuation">.</span><span class="token function">split_text</span><span class="token punctuation">(</span>markdown_document<span class="token punctuation">)</span>
md_header_splits

<span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Hi this is Jim'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">,</span> <span class="token char">'Header 2'</span><span class="token operator">:</span> <span class="token char">'Bar'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Hi this is Joe'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">,</span> <span class="token char">'Header 2'</span><span class="token operator">:</span> <span class="token char">'Bar'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Hi this is Lance'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">,</span> <span class="token char">'Header 2'</span><span class="token operator">:</span> <span class="token char">'Bar'</span><span class="token punctuation">,</span> <span class="token char">'Header 3'</span><span class="token operator">:</span> <span class="token char">'Boo'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token char">'Hi this is Molly'</span><span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token char">'Header 1'</span><span class="token operator">:</span> <span class="token char">'Foo'</span><span class="token punctuation">,</span> <span class="token char">'Header 2'</span><span class="token operator">:</span> <span class="token char">'Baz'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
    <p>
     在每个markdown组内，我们可以应用任何我们想要的文本分割器，例如RecursiveCharacterTextSplitter，它允许进一步控制块大小。
    </p>
    <pre><code class="prism language-c">markdown_document <span class="token operator">=</span> <span class="token string">"# Intro \n\n    ## History \n\n Markdown[9] is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9] \n\n Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files. \n\n ## Rise and divergence \n\n As Markdown popularity grew rapidly, many Markdown implementations appeared, driven mostly by the need for \n\n additional features such as tables, footnotes, definition lists,[note 1] and Markdown inside HTML blocks. \n\n #### Standardization \n\n From 2012, a group of people, including Jeff Atwood and John MacFarlane, launched what Atwood characterised as a standardisation effort. \n\n ## Implementations \n\n Implementations of Markdown are available for over a dozen programming languages."</span>

headers_to_split_on <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"#"</span><span class="token punctuation">,</span> <span class="token string">"Header 1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"##"</span><span class="token punctuation">,</span> <span class="token string">"Header 2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">MD splits</span></span>
markdown_splitter <span class="token operator">=</span> <span class="token function">MarkdownHeaderTextSplitter</span><span class="token punctuation">(</span>
    headers_to_split_on<span class="token operator">=</span>headers_to_split_on<span class="token punctuation">,</span> strip_headers<span class="token operator">=</span>False
<span class="token punctuation">)</span>
md_header_splits <span class="token operator">=</span> markdown_splitter<span class="token punctuation">.</span><span class="token function">split_text</span><span class="token punctuation">(</span>markdown_document<span class="token punctuation">)</span>

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Char<span class="token operator">-</span>level splits</span></span>
from langchain_text_splitters import RecursiveCharacterTextSplitter

chunk_size <span class="token operator">=</span> <span class="token number">250</span>
chunk_overlap <span class="token operator">=</span> <span class="token number">30</span>
text_splitter <span class="token operator">=</span> <span class="token function">RecursiveCharacterTextSplitter</span><span class="token punctuation">(</span>
    chunk_size<span class="token operator">=</span>chunk_size<span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span>chunk_overlap
<span class="token punctuation">)</span>

<span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Split</span></span>
splits <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span><span class="token function">split_documents</span><span class="token punctuation">(</span>md_header_splits<span class="token punctuation">)</span>
splits
</code></pre>
    <h3>
     <a id="_JSON__3694">
     </a>
     分割 JSON 数据
    </h3>
    <p>
     <code>
      JSONSplitter
     </code>
     允许在
     <strong>
      控制块大小
     </strong>
     的同时对 JSON 数据进行分割。它采用
     <strong>
      深度优先遍历
     </strong>
     的方式，构建较小的 JSON 块，并尽量保持嵌套的 JSON 结构完整。但如果 JSON 结构过大，为了符合
     <code>
      min_chunk_size
     </code>
     和
     <code>
      max_chunk_size
     </code>
     之间的限制，仍可能会对其进行拆分。
    </p>
    <p>
     <strong>
      处理逻辑
     </strong>
    </p>
    <ul>
     <li>
      <strong>
       嵌套对象
      </strong>
      ：尽可能保持完整，但如果超出块大小限制，则进行拆分。
     </li>
     <li>
      <strong>
       长字符串
      </strong>
      ：如果 JSON 值是一个
      <strong>
       非常大的字符串
      </strong>
      ，则不会自动拆分。如果需要严格控制块大小，可结合
      <strong>
       递归文本分割器
      </strong>
      进一步处理。
     </li>
     <li>
      <strong>
       列表处理
      </strong>
      （可选）：可以先将列表转换为 JSON
      <strong>
       字典
      </strong>
      ，然后再进行拆分，以更精确地控制块大小。
     </li>
    </ul>
    <p>
     <strong>
      分割规则
     </strong>
    </p>
    <ul>
     <li>
      <strong>
       如何拆分
      </strong>
      ：按
      <strong>
       JSON 值
      </strong>
      进行分割。
     </li>
     <li>
      <strong>
       如何计算块大小
      </strong>
      ：按
      <strong>
       字符数
      </strong>
      测量。
     </li>
    </ul>
    <p>
     指定 max_chunk_size 来限制块大小：
    </p>
    <pre><code class="prism language-c">from langchain_text_splitters import RecursiveJsonSplitter

splitter <span class="token operator">=</span> <span class="token function">RecursiveJsonSplitter</span><span class="token punctuation">(</span>max_chunk_size<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     要获取json块，请使用 .split_json 方法：
    </p>
    <pre><code class="prism language-c">json_chunks <span class="token operator">=</span> splitter<span class="token punctuation">.</span><span class="token function">split_json</span><span class="token punctuation">(</span>json_data<span class="token operator">=</span>json_data<span class="token punctuation">)</span>

<span class="token keyword">for</span> chunk in json_chunks<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>chunk<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">{<!-- --></span><span class="token char">'openapi'</span><span class="token operator">:</span> <span class="token char">'3.1.0'</span><span class="token punctuation">,</span> <span class="token char">'info'</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'title'</span><span class="token operator">:</span> <span class="token char">'LangSmith'</span><span class="token punctuation">,</span> <span class="token char">'version'</span><span class="token operator">:</span> <span class="token char">'0.1.0'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token char">'servers'</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token char">'url'</span><span class="token operator">:</span> <span class="token char">'https://api.smith.langchain.com'</span><span class="token punctuation">,</span> <span class="token char">'description'</span><span class="token operator">:</span> <span class="token char">'LangSmith API endpoint.'</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
<span class="token punctuation">{<!-- --></span><span class="token char">'paths'</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'/api/v1/sessions/{session_id}'</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'get'</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'tags'</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token char">'tracer-sessions'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token char">'summary'</span><span class="token operator">:</span> <span class="token char">'Read Tracer Session'</span><span class="token punctuation">,</span> <span class="token char">'description'</span><span class="token operator">:</span> <span class="token char">'Get a specific session.'</span><span class="token punctuation">,</span> <span class="token char">'operationId'</span><span class="token operator">:</span> 'read_tracer_session_api_v1_sessions__session_id__get'<span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span>
<span class="token punctuation">{<!-- --></span><span class="token char">'paths'</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'/api/v1/sessions/{session_id}'</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'get'</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'security'</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token char">'API Key'</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token char">'Tenant ID'</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token char">'Bearer Auth'</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span>
</code></pre>
    <p>
     要获取 LangChain 文档 对象，使用 .create_documents 方法：
    </p>
    <pre><code class="prism language-c"><span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">The splitter can also output documents</span></span>
docs <span class="token operator">=</span> splitter<span class="token punctuation">.</span><span class="token function">create_documents</span><span class="token punctuation">(</span>texts<span class="token operator">=</span><span class="token punctuation">[</span>json_data<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> doc in docs<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token operator">:</span>
    <span class="token function">print</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span>
</code></pre>
    <p>
     或者使用 .split_text 直接获取字符串内容：
    </p>
    <pre><code class="prism language-c">texts <span class="token operator">=</span> splitter<span class="token punctuation">.</span><span class="token function">split_text</span><span class="token punctuation">(</span>json_data<span class="token operator">=</span>json_data<span class="token punctuation">)</span>

<span class="token function">print</span><span class="token punctuation">(</span>texts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>texts<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     上文示例中的一个块大于指定的 max_chunk_size 300。查看这个较大的块，我们看到里面有一个列表对象：
    </p>
    <pre><code class="prism language-c"><span class="token punctuation">{<!-- --></span><span class="token string">"paths"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"/api/v1/sessions/{session_id}"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"get"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"parameters"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"name"</span><span class="token operator">:</span> <span class="token string">"session_id"</span><span class="token punctuation">,</span> <span class="token string">"in"</span><span class="token operator">:</span> <span class="token string">"path"</span><span class="token punctuation">,</span> <span class="token string">"required"</span><span class="token operator">:</span> true<span class="token punctuation">,</span> <span class="token string">"schema"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"type"</span><span class="token operator">:</span> <span class="token string">"string"</span><span class="token punctuation">,</span> <span class="token string">"format"</span><span class="token operator">:</span> <span class="token string">"uuid"</span><span class="token punctuation">,</span> <span class="token string">"title"</span><span class="token operator">:</span> <span class="token string">"Session Id"</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"name"</span><span class="token operator">:</span> <span class="token string">"include_stats"</span><span class="token punctuation">,</span> <span class="token string">"in"</span><span class="token operator">:</span> <span class="token string">"query"</span><span class="token punctuation">,</span> <span class="token string">"required"</span><span class="token operator">:</span> false<span class="token punctuation">,</span> <span class="token string">"schema"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"type"</span><span class="token operator">:</span> <span class="token string">"boolean"</span><span class="token punctuation">,</span> <span class="token string">"default"</span><span class="token operator">:</span> false<span class="token punctuation">,</span> <span class="token string">"title"</span><span class="token operator">:</span> <span class="token string">"Include Stats"</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"name"</span><span class="token operator">:</span> <span class="token string">"accept"</span><span class="token punctuation">,</span> <span class="token string">"in"</span><span class="token operator">:</span> <span class="token string">"header"</span><span class="token punctuation">,</span> <span class="token string">"required"</span><span class="token operator">:</span> false<span class="token punctuation">,</span> <span class="token string">"schema"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"anyOf"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"type"</span><span class="token operator">:</span> <span class="token string">"string"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"type"</span><span class="token operator">:</span> <span class="token string">"null"</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"title"</span><span class="token operator">:</span> <span class="token string">"Accept"</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span>
</code></pre>
    <p>
     默认情况下，json分割器不会分割列表。
    </p>
    <p>
     指定 convert_lists=True 来预处理json，将列表内容转换为 index:item 形式的字典，作为 key:val 对：
    </p>
    <pre><code class="prism language-c">texts <span class="token operator">=</span> splitter<span class="token punctuation">.</span><span class="token function">split_text</span><span class="token punctuation">(</span>json_data<span class="token operator">=</span>json_data<span class="token punctuation">,</span> convert_lists<span class="token operator">=</span>True<span class="token punctuation">)</span>
</code></pre>
    <p>
     列表已被转换为字典，但即使分成多个块，仍保留所有所需的上下文信息：
    </p>
    <pre><code class="prism language-c"><span class="token function">print</span><span class="token punctuation">(</span>texts<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span><span class="token string">"paths"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"/api/v1/sessions/{session_id}"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"get"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"tags"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"0"</span><span class="token operator">:</span> <span class="token string">"tracer-sessions"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token string">"summary"</span><span class="token operator">:</span> <span class="token string">"Read Tracer Session"</span><span class="token punctuation">,</span> <span class="token string">"description"</span><span class="token operator">:</span> <span class="token string">"Get a specific session."</span><span class="token punctuation">,</span> <span class="token string">"operationId"</span><span class="token operator">:</span> <span class="token string">"read_tracer_session_api_v1_sessions__session_id__get"</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span>

docs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'<span class="token punctuation">{<!-- --></span><span class="token string">"paths"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"/api/v1/sessions/{session_id}"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"get"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"tags"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"tracer-sessions"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"summary"</span><span class="token operator">:</span> <span class="token string">"Read Tracer Session"</span><span class="token punctuation">,</span> <span class="token string">"description"</span><span class="token operator">:</span> <span class="token string">"Get a specific session."</span><span class="token punctuation">,</span> <span class="token string">"operationId"</span><span class="token operator">:</span> <span class="token string">"read_tracer_session_api_v1_sessions__session_id__get"</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span>'<span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="_3765">
     </a>
     根据语义相似性分割文本
    </h3>
    <pre><code class="prism language-c">pip install <span class="token operator">--</span>quiet langchain_experimental langchain_openai
</code></pre>
    <p>
     加载示例数据：
    </p>
    <pre><code class="prism language-c"><span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">This is a <span class="token keyword">long</span> document we can split up<span class="token punctuation">.</span></span></span>
with <span class="token function">open</span><span class="token punctuation">(</span><span class="token string">"state_of_the_union.txt"</span><span class="token punctuation">)</span> as f<span class="token operator">:</span>
    state_of_the_union <span class="token operator">=</span> f<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     要实例化一个 SemanticChunker，我们必须指定一个嵌入模型。下面我们将使用 OpenAIEmbeddings。
    </p>
    <pre><code class="prism language-c">from langchain_experimental<span class="token punctuation">.</span>text_splitter import SemanticChunker
from langchain_openai<span class="token punctuation">.</span>embeddings import OpenAIEmbeddings

text_splitter <span class="token operator">=</span> <span class="token function">SemanticChunker</span><span class="token punctuation">(</span><span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     我们以通常的方式分割文本，例如，通过调用 .create_documents 来创建 LangChain 文档 对象：
    </p>
    <pre><code class="prism language-c">docs <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span><span class="token function">create_documents</span><span class="token punctuation">(</span><span class="token punctuation">[</span>state_of_the_union<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>
</code></pre>
    <p>
     这个分割器通过确定何时“断开”句子来工作。这是通过查看任何两个句子之间的嵌入差异来完成的。当该差异超过某个阈值时，它们就会被分割。
    </p>
    <p>
     有几种方法可以确定该阈值，这些方法由 breakpoint_threshold_type 关键字参数控制。
    </p>
    <p>
     默认的分割方式是基于百分位。在这种方法中，计算句子之间的所有差异，然后将任何大于 X 百分位的差异进行分割。
    </p>
    <pre><code class="prism language-c">text_splitter <span class="token operator">=</span> <span class="token function">SemanticChunker</span><span class="token punctuation">(</span>
    <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> breakpoint_threshold_type<span class="token operator">=</span><span class="token string">"percentile"</span>
<span class="token punctuation">)</span>

docs <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span><span class="token function">create_documents</span><span class="token punctuation">(</span><span class="token punctuation">[</span>state_of_the_union<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>
</code></pre>
    <p>
     标准差：在此方法中，任何大于 X 个标准差的差异都会被拆分。
    </p>
    <pre><code class="prism language-c">text_splitter <span class="token operator">=</span> <span class="token function">SemanticChunker</span><span class="token punctuation">(</span>
    <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> breakpoint_threshold_type<span class="token operator">=</span><span class="token string">"standard_deviation"</span>
<span class="token punctuation">)</span>

docs <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span><span class="token function">create_documents</span><span class="token punctuation">(</span><span class="token punctuation">[</span>state_of_the_union<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>
</code></pre>
    <p>
     四分位数：在此方法中，使用四分位距来拆分块。
    </p>
    <pre><code class="prism language-c">text_splitter <span class="token operator">=</span> <span class="token function">SemanticChunker</span><span class="token punctuation">(</span>
    <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> breakpoint_threshold_type<span class="token operator">=</span><span class="token string">"interquartile"</span>
<span class="token punctuation">)</span>

docs <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span><span class="token function">create_documents</span><span class="token punctuation">(</span><span class="token punctuation">[</span>state_of_the_union<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>
</code></pre>
    <p>
     梯度：在此方法中，使用距离的梯度与百分位法一起拆分块。 当块之间高度相关或特定于某个领域（例如法律或医学）时，此方法非常有用。其思想是对梯度数组应用异常检测，以便分布变得更宽，从而更容易识别高度语义数据中的边界。
    </p>
    <pre><code class="prism language-c">text_splitter <span class="token operator">=</span> <span class="token function">SemanticChunker</span><span class="token punctuation">(</span>
    <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> breakpoint_threshold_type<span class="token operator">=</span><span class="token string">"gradient"</span>
<span class="token punctuation">)</span>

docs <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span><span class="token function">create_documents</span><span class="token punctuation">(</span><span class="token punctuation">[</span>state_of_the_union<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>
</code></pre>
    <p>
     语义分割的思路来源于大佬的笔记：
     <a href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb">
      https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb
     </a>
    </p>
    <p>
     可以看到，大佬的笔记中记录了5种等级的文本分割方法：
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/e3fb069029334a7fb2357fd62d156378.png"/>
    </p>
    <h2>
     <a id="_3840">
     </a>
     嵌入模型/向量存储
    </h2>
    <p>
     嵌入模型创建文本片段的向量表示。
    </p>
    <p>
     可以将向量视为一个数字数组，
     <strong>
      它捕捉了文本的语义含义
     </strong>
     。 通过这种方式表示文本，您可以执行数学运算，从而进行诸如搜索其他在意义上最相似的文本等操作。 这些自然语言搜索能力支撑着许多类型的上下文检索， 在这里，我们为大型语言模型提供其有效响应查询所需的相关数据。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/708f7ed5ed684932b3fdf44dd7f80676.png"/>
     <br/>
     Embeddings类是一个用于与文本嵌入模型接口的类。存在许多不同的嵌入大模型供应商（OpenAI、Cohere、Hugging Face等）和本地模型，此类旨在为它们提供标准接口。
    </p>
    <p>
     LangChain中的基础嵌入类提供了两种方法：一种用于嵌入文档，另一种用于嵌入查询。前者接受多个文本作为输入，而后者接受单个文本。将这两者作为两个单独的方法的原因是某些嵌入大模型供应商对文档（待搜索的内容）和查询（搜索查询本身）有不同的嵌入方法。（
     <strong>
      存储和搜索非结构化数据的最常见方法之一是将其嵌入并存储生成的嵌入向量， 然后在查询时嵌入非结构化查询并检索与嵌入查询 ‘最相似’ 的嵌入向量。 向量存储负责为您存储嵌入数据并执行向量搜索。大多数向量存储还可以存储有关嵌入向量的元数据，并支持在相似性搜索之前对该元数据进行过滤， 让您对返回的文档有更多控制。
     </strong>
     ）
    </p>
    <h3>
     <a id="_3850">
     </a>
     文本嵌入模型
    </h3>
    <p>
     Embeddings 类是一个用于与文本嵌入模型接口的类。有很多嵌入大模型供应商（OpenAI、Cohere、Hugging Face 等） - 这个类旨在为它们提供一个标准接口。
    </p>
    <p>
     嵌入会创建一段文本的向量表示。这是有用的，因为这意味着我们可以在向量空间中思考文本，并进行语义搜索，寻找在向量空间中最相似的文本片段。
    </p>
    <p>
     LangChain 中的基础 Embeddings 类提供了两个方法：一个用于嵌入文档，一个用于嵌入查询。前者，.embed_documents，接受多个文本作为输入，而后者，.embed_query，接受单个文本。将这两个方法分开是因为某些嵌入大模型供应商对文档（待搜索的内容）和查询（搜索查询本身）有不同的嵌入方法。 .embed_query 将返回一个浮点数列表，而 .embed_documents 返回一个浮点数列表的列表（
     <strong>
      向量
     </strong>
     ）。
    </p>
    <p>
     对于openai合作伙伴包：
    </p>
    <pre><code class="prism language-c">pip install langchain<span class="token operator">-</span>openai
</code></pre>
    <p>
     对于Hugging Face合作伙伴包：
    </p>
    <pre><code class="prism language-c">pip install langchain<span class="token operator">-</span>huggingface
</code></pre>
    <p>
     访问openai API需要一个API密钥，一旦我们有了密钥，我们将通过运行将其设置为环境变量：
    </p>
    <pre><code class="prism language-c">export OPENAI_API_KEY<span class="token operator">=</span><span class="token string">"..."</span>
</code></pre>
    <p>
     如果您不想设置环境变量，可以在初始化OpenAI LLM类时通过api_key命名参数直接传递密钥：
    </p>
    <pre><code class="prism language-c">from langchain_openai import OpenAIEmbeddings

embeddings_model <span class="token operator">=</span> <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span>api_key<span class="token operator">=</span><span class="token string">"..."</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     本地模型也可以在没有任何参数的情况下进行初始化：
    </p>
    <pre><code class="prism language-c">from langchain_openai import OpenAIEmbeddings

embeddings_model <span class="token operator">=</span> <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     也可以从Hugging Face Hub加载任何emb模型。
    </p>
    <pre><code class="prism language-c">from langchain_huggingface import HuggingFaceEmbeddings

embeddings_model <span class="token operator">=</span> <span class="token function">HuggingFaceEmbeddings</span><span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"sentence-transformers/all-mpnet-base-v2"</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     嵌入文本列表：使用 .embed_documents 嵌入字符串列表，返回嵌入列表：
    </p>
    <pre><code class="prism language-c">embeddings <span class="token operator">=</span> embeddings_model<span class="token punctuation">.</span><span class="token function">embed_documents</span><span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
        <span class="token string">"Hi there!"</span><span class="token punctuation">,</span>
        <span class="token string">"Oh, hello!"</span><span class="token punctuation">,</span>
        <span class="token string">"What's your name?"</span><span class="token punctuation">,</span>
        <span class="token string">"My friends call me World"</span><span class="token punctuation">,</span>
        <span class="token string">"Hello World!"</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span>
<span class="token function">len</span><span class="token punctuation">(</span>embeddings<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">len</span><span class="token punctuation">(</span>embeddings<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1536</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     嵌入单个查询：使用 .embed_query 嵌入单个文本（例如，用于与其他嵌入文本进行比较）
    </p>
    <pre><code class="prism language-c">embedded_query <span class="token operator">=</span> embeddings_model<span class="token punctuation">.</span><span class="token function">embed_query</span><span class="token punctuation">(</span><span class="token string">"What was the name mentioned in the conversation?"</span><span class="token punctuation">)</span>
embedded_query<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">5</span><span class="token punctuation">]</span>
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token number">0.0053587136790156364</span><span class="token punctuation">,</span>
 <span class="token operator">-</span><span class="token number">0.0004999046213924885</span><span class="token punctuation">,</span>
 <span class="token number">0.038883671164512634</span><span class="token punctuation">,</span>
 <span class="token operator">-</span><span class="token number">0.003001077566295862</span><span class="token punctuation">,</span>
 <span class="token operator">-</span><span class="token number">0.00900818221271038</span><span class="token punctuation">]</span>
</code></pre>
    <h3>
     <a id="_3925">
     </a>
     缓存嵌入结果
    </h3>
    <p>
     为了避免重复计算，嵌入结果可以
     <strong>
      存储
     </strong>
     或
     <strong>
      临时缓存
     </strong>
     。
    </p>
    <p>
     <strong>
      使用
      <code>
       CacheBackedEmbeddings
      </code>
      进行嵌入缓存
     </strong>
     <br/>
     <code>
      CacheBackedEmbeddings
     </code>
     作为一个
     <strong>
      封装器
     </strong>
     ，可以在
     <strong>
      键值存储
     </strong>
     中缓存嵌入结果。它通过
     <strong>
      对文本进行哈希处理
     </strong>
     生成唯一键，并将计算后的嵌入存入缓存，以加速后续查询。
    </p>
    <p>
     <strong>
      初始化
      <code>
       CacheBackedEmbeddings
      </code>
     </strong>
     <br/>
     推荐使用
     <code>
      from_bytes_store
     </code>
     方法进行初始化，主要参数如下：
    </p>
    <ul>
     <li>
      <strong>
       <code>
        underlying_embedder
       </code>
      </strong>
      ：实际用于计算嵌入的模型。
     </li>
     <li>
      <strong>
       <code>
        document_embedding_cache
       </code>
      </strong>
      ：用于存储文档嵌入的
      <strong>
       ByteStore
      </strong>
      （字节存储）。
     </li>
     <li>
      <strong>
       <code>
        batch_size
       </code>
      </strong>
      （可选，默认为
      <code>
       None
      </code>
      ）：控制
      <strong>
       批量处理的文档数量
      </strong>
      ，减少存储更新频率。
     </li>
     <li>
      <strong>
       <code>
        namespace
       </code>
      </strong>
      （可选，默认为
      <code>
       ""
      </code>
      ）：
      <strong>
       命名空间
      </strong>
      ，用于区分不同的缓存，避免
      <strong>
       不同模型对相同文本的嵌入发生冲突
      </strong>
      。建议设置为嵌入模型的名称。
     </li>
     <li>
      <strong>
       <code>
        query_embedding_cache
       </code>
      </strong>
      （可选，默认为
      <code>
       None
      </code>
      或
      <strong>
       不缓存
      </strong>
      ）：
      <ul>
       <li>
        可提供一个
        <strong>
         ByteStore
        </strong>
        以缓存查询嵌入。
       </li>
       <li>
        也可以设为
        <code>
         True
        </code>
        ，直接复用
        <code>
         document_embedding_cache
        </code>
        作为查询缓存。
       </li>
      </ul>
     </li>
    </ul>
    <p>
     <strong>
      注意事项
     </strong>
     <br/>
     ✅
     <strong>
      建议设置
      <code>
       namespace
      </code>
     </strong>
     ，以免不同模型嵌入相同文本时出现缓存冲突。
     <br/>
     ✅
     <strong>
      默认情况下，不缓存查询嵌入
     </strong>
     。如果需要缓存查询结果，需要
     <strong>
      显式设置
      <code>
       query_embedding_cache
      </code>
     </strong>
     。
    </p>
    <pre><code class="prism language-c">from langchain<span class="token punctuation">.</span>embeddings import CacheBackedEmbeddings
</code></pre>
    <p>
     首先，让我们看一个使用本地文件系统存储嵌入并使用FAISS向量存储进行检索的示例。（FAISS 是 Facebook 推出的向量搜索库，里面提供了高性能的向量搜索工具。）
    </p>
    <pre><code class="prism language-c">pip install <span class="token operator">--</span>upgrade <span class="token operator">--</span>quiet  langchain<span class="token operator">-</span>openai faiss<span class="token operator">-</span>cpu
</code></pre>
    <pre><code class="prism language-c">from langchain<span class="token punctuation">.</span>embeddings import CacheBackedEmbeddings
from langchain<span class="token punctuation">.</span>storage import LocalFileStore
from langchain_community<span class="token punctuation">.</span>document_loaders import TextLoader
from langchain_community<span class="token punctuation">.</span>vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter

underlying_embeddings <span class="token operator">=</span> <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

store <span class="token operator">=</span> <span class="token function">LocalFileStore</span><span class="token punctuation">(</span><span class="token string">"./cache/"</span><span class="token punctuation">)</span>

cached_embedder <span class="token operator">=</span> CacheBackedEmbeddings<span class="token punctuation">.</span><span class="token function">from_bytes_store</span><span class="token punctuation">(</span>
    underlying_embeddings<span class="token punctuation">,</span> store<span class="token punctuation">,</span> namespace<span class="token operator">=</span>underlying_embeddings<span class="token punctuation">.</span>model
<span class="token punctuation">)</span>
</code></pre>
    <p>
     在嵌入之前缓存是空的：
    </p>
    <pre><code class="prism language-c"><span class="token function">list</span><span class="token punctuation">(</span>store<span class="token punctuation">.</span><span class="token function">yield_keys</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     加载文档，将其拆分为块，嵌入每个块并将其加载到向量存储中。
    </p>
    <pre><code class="prism language-c">raw_documents <span class="token operator">=</span> <span class="token function">TextLoader</span><span class="token punctuation">(</span><span class="token string">"state_of_the_union.txt"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
text_splitter <span class="token operator">=</span> <span class="token function">CharacterTextSplitter</span><span class="token punctuation">(</span>chunk_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
documents <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span><span class="token function">split_documents</span><span class="token punctuation">(</span>raw_documents<span class="token punctuation">)</span>
</code></pre>
    <p>
     创建向量存储：
    </p>
    <pre><code class="prism language-c">db <span class="token operator">=</span> FAISS<span class="token punctuation">.</span><span class="token function">from_documents</span><span class="token punctuation">(</span>documents<span class="token punctuation">,</span> cached_embedder<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">CPU times<span class="token operator">:</span> user <span class="token number">218</span> ms<span class="token punctuation">,</span> sys<span class="token operator">:</span> <span class="token number">29.7</span> ms<span class="token punctuation">,</span> total<span class="token operator">:</span> <span class="token number">248</span> ms
Wall time<span class="token operator">:</span> <span class="token number">1.02</span> s
</code></pre>
    <p>
     如果我们尝试再次创建向量存储，它会快得多，因为不需要重新计算任何嵌入。
    </p>
    <pre><code class="prism language-c">db2 <span class="token operator">=</span> FAISS<span class="token punctuation">.</span><span class="token function">from_documents</span><span class="token punctuation">(</span>documents<span class="token punctuation">,</span> cached_embedder<span class="token punctuation">)</span>
</code></pre>
    <pre><code class="prism language-c">CPU times<span class="token operator">:</span> user <span class="token number">15.7</span> ms<span class="token punctuation">,</span> sys<span class="token operator">:</span> <span class="token number">2.22</span> ms<span class="token punctuation">,</span> total<span class="token operator">:</span> <span class="token number">18</span> ms
Wall time<span class="token operator">:</span> <span class="token number">17.2</span> ms
</code></pre>
    <p>
     这里是一些创建的嵌入：
    </p>
    <pre><code class="prism language-c"><span class="token function">list</span><span class="token punctuation">(</span>store<span class="token punctuation">.</span><span class="token function">yield_keys</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">5</span><span class="token punctuation">]</span>

<span class="token punctuation">[</span>'text<span class="token operator">-</span>embedding<span class="token operator">-</span>ada<span class="token operator">-</span><span class="token number">00217</span>a6727d<span class="token operator">-</span><span class="token number">8916</span><span class="token operator">-</span><span class="token number">54</span>eb<span class="token operator">-</span>b196<span class="token operator">-</span>ec9c9d6ca472'<span class="token punctuation">,</span>
 'text<span class="token operator">-</span>embedding<span class="token operator">-</span>ada<span class="token operator">-</span><span class="token number">0025f</span>c0d904<span class="token operator">-</span>bd80<span class="token operator">-</span><span class="token number">52</span>da<span class="token operator">-</span><span class="token number">95</span>c9<span class="token operator">-</span><span class="token number">441015</span>bfb438'<span class="token punctuation">,</span>
 'text<span class="token operator">-</span>embedding<span class="token operator">-</span>ada<span class="token operator">-</span><span class="token number">002e4</span>ad20ef<span class="token operator">-</span>dfaa<span class="token operator">-</span><span class="token number">5916</span><span class="token operator">-</span><span class="token number">9459</span><span class="token operator">-</span>f90c6d8e8159'<span class="token punctuation">,</span>
 'text<span class="token operator">-</span>embedding<span class="token operator">-</span>ada<span class="token operator">-</span><span class="token number">002</span>ed199159<span class="token operator">-</span>c1cd<span class="token operator">-</span><span class="token number">5597</span><span class="token operator">-</span><span class="token number">9757</span><span class="token operator">-</span>f80498e8f17b'<span class="token punctuation">,</span>
 'text<span class="token operator">-</span>embedding<span class="token operator">-</span>ada<span class="token operator">-</span><span class="token number">0021297</span>d37a<span class="token operator">-</span><span class="token number">2</span>bc1<span class="token operator">-</span><span class="token number">5e19</span><span class="token operator">-</span>bf13<span class="token operator">-</span><span class="token number">6</span>c950f075062'<span class="token punctuation">]</span>
</code></pre>
    <p>
     为了使用不同的 ByteStore，只需在创建 CacheBackedEmbeddings 时使用它。下面，我们创建一个等效的缓存嵌入对象，但使用非持久的 InMemoryByteStore：
    </p>
    <pre><code class="prism language-c">from langchain<span class="token punctuation">.</span>embeddings import CacheBackedEmbeddings
from langchain<span class="token punctuation">.</span>storage import InMemoryByteStore

store <span class="token operator">=</span> <span class="token function">InMemoryByteStore</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

cached_embedder <span class="token operator">=</span> CacheBackedEmbeddings<span class="token punctuation">.</span><span class="token function">from_bytes_store</span><span class="token punctuation">(</span>
    underlying_embeddings<span class="token punctuation">,</span> store<span class="token punctuation">,</span> namespace<span class="token operator">=</span>underlying_embeddings<span class="token punctuation">.</span>model
<span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="_4028">
     </a>
     创建和查询向量存储
    </h3>
    <p>
     上文讲述了文本向量化以及缓存的使用，但缓存是为了加速已有的向量运算的，而不是存储向量的！
    </p>
    <p>
     存储和搜索非结构化数据的最常见方法之一是将其嵌入并存储生成的嵌入向量， 然后在查询时嵌入非结构化查询并检索与嵌入查询“最相似”的嵌入向量。 向量存储负责存储嵌入数据并执行向量搜索。
    </p>
    <table>
     <thead>
      <tr>
       <th>
        Vectorstore
       </th>
       <th>
        Delete by ID
       </th>
       <th>
        Filtering
       </th>
       <th>
        Search by Vector
       </th>
       <th>
        Search with score
       </th>
       <th>
        Async
       </th>
       <th>
        Passes Standard Tests
       </th>
       <th>
        Multi Tenancy
       </th>
       <th>
        IDs in add Documents
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>
        <a href="astradb" rel="nofollow">
         AstraDBVectorStore
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        <a href="chroma" rel="nofollow">
         Chroma
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        <a href="clickhouse" rel="nofollow">
         Clickhouse
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        <a href="couchbase" rel="nofollow">
         CouchbaseVectorStore
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        <a href="databricks_vector_search" rel="nofollow">
         DatabricksVectorSearch
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        <a href="elasticsearch" rel="nofollow">
         ElasticsearchStore
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        <a href="faiss" rel="nofollow">
         FAISS
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        <a href="https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html" rel="nofollow">
         InMemoryVectorStore
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        <a href="milvus" rel="nofollow">
         Milvus
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        <a href="mongodb_atlas" rel="nofollow">
         MongoDBAtlasVectorSearch
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        <a href="pgvector" rel="nofollow">
         PGVector
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        <a href="pinecone" rel="nofollow">
         PineconeVectorStore
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        <a href="qdrant" rel="nofollow">
         QdrantVectorStore
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
      <tr>
       <td>
        <a href="redis" rel="nofollow">
         Redis
        </a>
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ✅
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
       <td>
        ❌
       </td>
      </tr>
     </tbody>
    </table>
    <p>
     使用向量存储的关键部分是创建要放入其中的向量， 通常通过嵌入创建。
    </p>
    <p>
     有许多优秀的向量存储选项，以下是一些免费的、开源的，并且完全在本地机器上运行的选项。（其中FAISS, Chroma非常轻量级，轻量到和sqllite一样）
    </p>
    <p>
     以chroma为例：
    </p>
    <pre><code class="prism language-c">pip install langchain<span class="token operator">-</span>chroma
</code></pre>
    <pre><code class="prism language-c">from langchain_chroma import Chroma

db <span class="token operator">=</span> FAISS<span class="token punctuation">.</span><span class="token function">from_documents</span><span class="token punctuation">(</span>documents<span class="token punctuation">,</span> <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
或
db <span class="token operator">=</span> Chroma<span class="token punctuation">.</span><span class="token function">from_documents</span><span class="token punctuation">(</span>documents<span class="token punctuation">,</span> <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     所有向量存储都暴露了 similarity_search 方法。 这将接收传入的文档，创建它们的嵌入，然后找到所有具有最相似嵌入的文档。
    </p>
    <pre><code class="prism language-c">query <span class="token operator">=</span> <span class="token string">"What did the president say about Ketanji Brown Jackson"</span>
docs <span class="token operator">=</span> db<span class="token punctuation">.</span><span class="token function">similarity_search</span><span class="token punctuation">(</span>query<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>
</code></pre>
    <p>
     也可以使用 similarity_search_by_vector 搜索与给定嵌入向量相似的文档，该方法接受嵌入向量作为参数，而不是字符串。
    </p>
    <pre><code class="prism language-c">embedding_vector <span class="token operator">=</span> <span class="token function">OpenAIEmbeddings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">embed_query</span><span class="token punctuation">(</span>query<span class="token punctuation">)</span>
docs <span class="token operator">=</span> db<span class="token punctuation">.</span><span class="token function">similarity_search_by_vector</span><span class="token punctuation">(</span>embedding_vector<span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span>docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>
</code></pre>
    <p>
     向量存储通常作为一个单独的服务运行，需要一些IO操作，因此它们可能会被异步调用。LangChain支持在向量存储上进行异步操作。所有方法都可以使用其异步对应方法调用。
    </p>
    <pre><code class="prism language-c">docs <span class="token operator">=</span> await db<span class="token punctuation">.</span><span class="token function">asimilarity_search</span><span class="token punctuation">(</span>query<span class="token punctuation">)</span>
docs
</code></pre>
    <pre><code class="prism language-c"><span class="token punctuation">[</span><span class="token function">Document</span><span class="token punctuation">(</span>page_content<span class="token operator">=</span>'Tonight<span class="token punctuation">.</span> I call<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre>
    <p>
     很多github的示例服务很多都是基于python的fastapi构建的，新版本的flask也支持asyncio，而django就有点太笨重了。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f47656e6572616c5f7a792f:61727469636c652f64657461696c732f313435363030393530" class_="artid" style="display:none">
 </p>
</div>


