---
layout: post
title: "ollama-API-本地调用"
date: 2025-03-14 23:09:28 +0800
description: "前提条件，ollama 已经启动了模型，查看 ollama 中的 model 名称。使用 openai 调用。"
keywords: "ollama API 本地调用"
categories: ['大模型平台', 'Llm']
tags: ['开发语言', 'Python']
artid: "146269170"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146269170
    alt: "ollama-API-本地调用"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146269170
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146269170
cover: https://bing.ee123.net/img/rand?artid=146269170
image: https://bing.ee123.net/img/rand?artid=146269170
img: https://bing.ee123.net/img/rand?artid=146269170
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     ollama API 本地调用
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="ollama_API__0">
     </a>
     ollama API 本地调用
    </h3>
    <ul>
     <li>
      <p>
       前提条件，ollama 已经启动了模型，查看 ollama 中的 model 名称
      </p>
      <pre><code class="prism language-python">ollama <span class="token builtin">list</span>
</code></pre>
      <p>
       <img alt="image-20250314230724978" src="https://i-blog.csdnimg.cn/img_convert/ae3a01cbb90d01d0a16007b07cd8e38c.png"/>
      </p>
     </li>
     <li>
      <p>
       使用 openai 调用
      </p>
      <pre><code class="prism language-python"><span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI
<span class="token keyword">import</span> openai

openai<span class="token punctuation">.</span>api_key <span class="token operator">=</span> <span class="token string">'ollama'</span>
openai<span class="token punctuation">.</span>base_url <span class="token operator">=</span> <span class="token string">'http://localhost:11434/v1/'</span>

<span class="token keyword">def</span> <span class="token function">get_completion</span><span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"qwq"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>api_key<span class="token operator">=</span>openai<span class="token punctuation">.</span>api_key<span class="token punctuation">,</span>
                    base_url<span class="token operator">=</span>openai<span class="token punctuation">.</span>base_url
                    <span class="token punctuation">)</span>
    messages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span><span class="token punctuation">]</span>
    response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
        model<span class="token operator">=</span>model<span class="token punctuation">,</span>
        messages<span class="token operator">=</span>messages<span class="token punctuation">,</span>
        stream<span class="token operator">=</span><span class="token boolean">False</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content
  
prompt <span class="token operator">=</span> <span class="token string">'你好，请介绍下你自己'</span>
model <span class="token operator">=</span> <span class="token string">"qwq"</span>
get_completion<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">)</span>
</code></pre>
      <p>
       <img alt="image-20250314230516157" src="https://i-blog.csdnimg.cn/img_convert/6d59e646d8dfe07d7e7f0d4b6f8ec421.png"/>
      </p>
      <h3>
       <a id="_fastapi_38">
       </a>
       可以使用 fastapi将后端服务暴露出来
      </h3>
     </li>
    </ul>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f68626b79626b7a772f:61727469636c652f64657461696c732f313436323639313730" class_="artid" style="display:none">
 </p>
</div>


