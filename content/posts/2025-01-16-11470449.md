---
arturl_encode: "68747470:733a2f2f626c6f672e6373646e2e6e65742f7a6f6c616c6164:2f61727469636c652f64657461696c732f3131343730343439"
layout: post
title: "Hadoop系统完全分布式集群搭建方法"
date: 2025-01-16 23:01:32 +08:00
description: "Hadoop系统分布式集群搭建方法 1. linux操作系统安装在每个节点上安装Linux操作系统（"
keywords: "如何搭建hadoop完全分布式集群"
categories: ['Hadoop']
tags: ['集群', '搭建方法', '完全分布式', 'Hadoop']
artid: "11470449"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=11470449
    alt: "Hadoop系统完全分布式集群搭建方法"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=11470449
featuredImagePreview: https://bing.ee123.net/img/rand?artid=11470449
---

# Hadoop系统完全分布式集群搭建方法

**Hadoop
系统分布式集群搭建方法**

记得以前学习hadoop时，互联网上有不少有关Hadoop环境搭建的方法，但很多语焉不详，步骤不清晰。下面是本人亲自搭建hadoop完全分布式系统环境的笔记，沉落硬盘已久，闲来无事，现整理后发到博客上，和博友共勉，希望对hadoop初学者有所帮助，欣喜不已！

**1. linux
操作系统安装**

在每个节点上安装
Linux
操作系统（
Centos6.3
），安装时为各机器分别命名为
Master
，
slave1
、
slave2
…。令主机名为
Master
的作为主节点，主机名为
slave1
、
slave2
…作为从节点。

如果是在已经安装好系统的集群中配置
hadoop
环境，且各机器的主机名命名无规律，这时最好按照下述方法修改主机名。

**1.1
编辑各个机器的主机名：（将主从节点的主机名分别命名为
Master
，
slave1
、
slave2…
）**

**[root@Centos ~]# vi /etc/hostname**

**[root@Centos ~]# vi /etc/sysconfig/network**

**注：如有必要，主从节点都需要修改，这样改的目的是容易规划集群中的机器。**

**1.2
为所有主从节点设置静态
IP
（为所有机器配置好静态
IP
）**

**1.2.1
修改网卡配置，编辑：
vi /etc/sysconfig/network-scripts/ifcfg-eth0**

**1.2.2
修改网关配置，编辑：
vi /etc/sysconfig/network**

**1.2.3
修改
DNS
配置，编辑：
vi /etc/resolv.conf**

**1.2.4
重启网络服务，

执行命令：
service network restart**

**2.
安装
SSH
并配置免密码
SSH
访问机制（重要）**

如果安装
RHELS 6.0 ,
确保软件安装时把
SSH
选上；如果安装
Linux
时没有安装
SSH
，则需要另行安装
SSH
。

![](https://img-blog.csdn.net/20130909100930953?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvem9sYWxhZA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

**配置为可以免密码登录主节点和从节点
:**

首先查看在“当前用户”文件夹下是否存在
**.ssh**
文件夹（注意
ssh
前面有“
**.**
”，这是一个隐藏文件夹）。输入命令查看此文件夹是否存在。
**一般来说，安装
SSH
时会自动在当前用户下创建这个隐藏文件夹，如果没有，可以手创建一个。）**

下面的配置我是在主节点
**Master**
的
**hadoop**
用户下进行的：

[hadoop@
**Master**
~]
**# ls –a**

**发现
.ssh
文件夹已经存在。**

接下来输入命令（注意下面命令中不是双引号，是两个单引号）：

**执行：**

**[**
hadoop
**@Master ~]# ssh-keygen -t  rsa**

Generating public/private rsa key pair.

Enter file in which to save the key (/home/hadoop/.ssh/id_rsa):

&

按回车默认路径


&

Created directory '/home/ hadoop /.ssh'.  &
创建
/ hadoop /.ssh
目录
&

Enter passphrase (empty for no passphrase):

Enter same passphrase again:

Your identification has been saved in/home / hadoop /.ssh/id_rsa.

Your public key has been saved in/home / hadoop /.ssh/id_rsa.pub.

The key fingerprint is:

c6:7e:57:59:0a:2d:85:49:23:cc:c4:58:ff:db:5b:38 root@master

**通过以上命令将在
/home/ hadoop /.ssh/
目录下生成
id_rsa
私钥和
id_rsa.pub
公钥**
。

进入
/ hadoop /.ssh
目录在
namenode
节点下做如下配置：

**[hadoop @Master.ssh]# cat id_rsa.pub > authorized_keys**

至此，主节点配置完毕，可通过
ssh
本机
IP
测试是否需要密码登录。

**操作如图所示：说明配置无密码登录成功！**

![](https://img-blog.csdn.net/20130909101045328?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvem9sYWxhZA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

**然后配置从节点，将
authorized_keys
文件复制到所有从节点上：**

**[hadoop@Master
.ssh
]$ scp authorized_keys
[**
**从节点主机名或


IP]:/home/hadoop/.ssh**

**至此免密码登录各节点已配置完毕，可通过
ssh
各节点
IP
测试是否需要密码登录。**

**3.
安装
Java
（首先使用
[root@ Master ~]

#arch
命令查看机器属于
32
位还是
64
位机）**

（
1
）查看系统默认安装的
JDK
，命令：
java -version

**（
2
）**
下载和安装自己的
Jdk
，将
jdk
安装在
**/usr/java**
目录下。

**root**
用户登陆，新建目录
**mkdir  /usr/java**
，然后将
JDK
安装包
jdk-6u13-linux-i586.bin

复制到目录
**/usr/java**

下
，
进入该目录，执行安装命令“
**./ jdk-6u13-linux-i586.bin**

”，安装完成后将在目录下生成


jdk

的安装文件夹
**/jdk1.6.0_13**

。

**（
3
）删除默认安装的
jdk**

查看
jdk
的版本号：
rpm -qa|grep  jdk
卸载：
yum -y remove

**4.
创建专门的
hadoop
用户（令
hadoop
集群中的所有机器都是在
hadoop
用户下工作！）**

创建用户组：
hadoop
，然后在此用户组下创建
hadoop
用户。可在安装系统的时候创建，也可以在安装好之后用如下命令创建：

**[root@ Master ~]# groupadd  hadoop**

**[root@ Master ~]# useradd -g hadoop  -d /home/hadoop  hadoop**

“hadoop”
是所创建的用户名
, -d
指明
“ hadoop”
用户的
home
目录是
/home/hadoop
）

**[root@ Master ~]# passwd hadoop**
[
给用户
hadoop
设置口令
]

1).
在真实集群分布模式下，要求集群中所有节点使用相同的用户名，
**这是
hadoop
的基本要求。**
比如，可以使用“
hadoop”
作为所有节点上统一的用户名。

2).
并且要求在所有节点上安装的
hadoop
系统具有完全一致的目录结构。

**5.
在主节点上解压安装
Hadoop**

—

到
Hadoop
官网下载
hadoop-1.0.1.tar.gz
（本人使用的是此版本！）

—

建立安装目录

**[hadoop@ Master ~] $mkdir ~/hadoop_installs**

—

**把
hadoop-1.0.1.tar.gz
放在这里，然后解压：**

**[hadoop@ Master hadoop_installs]$ tar –zxvf hadoop-1.0.1.tar.gz**

解压安装完毕，可得
hadoop
的安装
**根目录**
为：
/home/hadoop/hadoop_installs/hadoop-1.0.1

**注：这个过程仅需在主节点上完成，然后安装好的


Hadoop

系统在完成后续配置后可被复制到所有从节点

。**

**6.
配置环境变量
(
每个节点都必须做）**

—

进入到“
***hadoop***
*”*
用户下
[root@Master ~]# su –
*hadoop*
[
注意中间的
”-”
不要丢
]

**[
*hadoop*
@ Master ~]$
vi
~/.bash_profile**

（此修改方式仅对


hadoop

用户生效）

注：
[
*root*
@ Master ~]#
**vi
/etc/profile**
**这种修改方式是对本机所有用户生效！**

设置如下环境变量：

export  JAVA_HOME=/usr/java/jdk1.6.0_13

export  JRE_HOME=/usr/java /jdk1.6.0_13/jre

export  CLASSPATH=
**.:**
$JAVA_HOME/lib
**:**
$JAVA_HOME/jre/lib

export  PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH

export  HADOOP_HOME=/home/hadoop/hadoop_installs/hadoop-1.0.1

export  PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin

在
vi
编辑器增加以上内容后保存退出，并执行以下命令使配置生效！

#chmod  +x  /etc/profile
；增加执行权限

#source  /etc/profile
；使配置生效！

配置完毕后，在命令行中输入：
**java -version**
，如出现下列信息说明
java
环境安装成功。

java version "1.6.0_13"

Java(TM) SE Runtime Environment (build 1.6.0_13-b03)

Java HotSpot(TM) Server VM (build 16.3-b01, mixed mode)

**7.
在主节点上修改
hadoop
配置文件**

Hadoop
的配置文件存放在
hadoop
安装目录下的
conf
目录中，主要有以下几个配置文件要修改：

—

conf/hadoop-env.sh
：
Hadoop
环境变量设置

—

conf/core-site.xml
：主要完成
NameNode
的
IP
和端口设置

—

conf/hdfs-site.xml
：主要完成
HDFS
的数据块副本等参数设置

—

conf/mapred-site.xml
：主要完成
JobTracker IP
和端口设置

—

conf/masters
：完成
master
节点
IP
设置

**进入
/home/hadoop/hadoop_install/hadoop-1.0.1/conf
，配置
Hadoop
配置文件**

**7.1
配置
hadoop-env.sh
文件**

**打开文件命令：**

vi hadoop-env.sh

添加
# set java environment

export JAVA_HOME=/usr/java/jdk1.6.0_13

编辑后保存退出。

**7.2
配置
core-site.xml**

**[hadoop@Master conf]$ vi core-site.xml**

<?xml version="1.0"?>

<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

<property>

<name>fs.default.name</name>

<value>hdfs://Master:9000
**/**
</value>

**//**
注：
Master
为主节点主机名，
9000
后面的“
**/

”**
不能少

</property>

<property>

<name>hadoop.tmp.dir</name>

<value>/tmp</value>

</property>

</configuration>

**说明：**


hadoop

分布式文件系统的两个重要的目录结构，一个是


namenode

上名字空间的存放地方，一个是


datanode

数据块的存放地方，还有一些其他的文件存放地方，这些存放地方都是基于


hadoop.tmp.dir

目录的，比如


namenode

的名字空间存放地方就是


${hadoop.tmp.dir}/dfs/name, datanode

数据块的存放地方就是


${hadoop.tmp.dir}/dfs/data

，所以设置好


hadoop.tmp.dir

目录后，其他的重要目录都是在这个目录下面，这是一个根目录。在此设置的是

**/tmp**

,

当然这个目录必须是存在的。

**7.3
配置
hdfs-site.xml**

**[hadoop@Master conf]**
$ vi  hdfs-site.xml

<?xml version="1.0"?>

<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

<property>

<name>dfs.replication</name>

<value>3</value>

</property>

</configuration>

**7.4
配置
mapred-site.xml**

**[hadoop@Master conf]$ vi mapred-site.xml**

<?xml version="1.0"?>

<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

<property>

<name>mapred.job.tracker</name>

<value>Master:9001</value>

</property>

</configuration>

**7.5
配置
masters
文件和
slaves
文件**

**[hadoop@Master conf]$ vi masters
修改为主节点的主机名**

**[hadoop@Master conf]$ vi slaves
列出所有从节点的主机名**

注：这个过程仅需在
**主节点**
上进行，然后将随着主机上安装好的


Hadoop

目录一起复制到所有从节点

**8.
复制
Hadoop
系统到所有从节点**

将在主节点安装好的
Hadoop
系统目录复制到每一个从节点上：

**[hadoop@ Master ~]**
$ scp -r /home/hadoop/hadoop-installs [
从节点主机名或
IP]:/home/hadoop/

这样可以避免对每一个从节点重复进行


Hadoop

系统安装。

**9.
在
NameNode
和
DataNode
节点上分别进行“主机名和
IP
解析”配置**

修改每台机器的
**/etc/hosts**
设置：

—

若为
NameNode
，则需要在
hosts
文件中添加集群中所有节点的
IP
地址机器对应的主机名。示例：

![](https://img-blog.csdn.net/20130909101145750?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvem9sYWxhZA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

—

若为
DataNode
，则只需要在文件中添加本机和
NameNode
的
IP
地址及对应的主机名。

**10.
格式化

NameNode**

—

执行
Hadoop
的
bin
文件夹中的格式化命令：

[hadoop@ Master ~]$ hadoop namenode -format

如果格式化成功，会返回一堆有关
NameNode
的启动信息，其中会有一句“
…. has been successfully formatted.”

**11.
启动
HDFS
和
MapReduce**

—

执行以下命令启动
HDFS
和
MapReduce

[hadoop@ Master ~]$ start-all.sh

—

用
JPS
命令检查一下是否正常启动：

[hadoop@ Master ~]$ jps

显示以下各进程信息则说明
HDFS
和
MapReduce
都已正常启动：

4706 JobTracker

4582 SecondaryNameNode

4278 NameNode

4413 DataNode

4853 TaskTracker

4889 Jps

**12
查看集群状态**

**命令方式：
[hadoop@Master bin]$ hadoop dfsadmin –report**

**浏览器方式：在
WEB
页面下查看
Hadoop
工作情况**

输入部署
Hadoop
服务器的
**IP
：
http://IP:50070
；
[http://IP:50030](http://ip:50030/)

.**

**13.
运行测试**

—

在
Linux
文件系统下（如
/home/hadoop /test)
创建两个文本数据文件
:

file1.txt
：
hello hadoop hello world

file2.txt
：
goodbye hadoop

—

**在

hdfs

分布式文件系统**

创建目录

input

：

**[hadoop@ Master ~]$ hadoop fs -mkdir input**

—

**离开
hodoop
的安全模式：**

**[hadoop@Master ~]$ hadoop dfsadmin –safemode leave**

—

**将文件复制到
HDFS
文件系统中的
input
文件夹下**
：
(
下面命令二选一使用
)

**[hadoop@Master ~]$ hadoop  dfs  –copyFromLocal   ~/test/\*   input**

**[hadoop@Master ~]$

hadoop
fs  –put  ~/test/\*  input**

—

运行
hadoop
安装包中自带的
WorldCount
程序进行测试：

**[hadoop@Master ~]$**
hadoop jar hadoop-1.0.1-examples.jar  wordcount  input  output

注：其中
output
只能由程序创建，
**HDFS
文件系统中**
不能事先存在
.

—

**在

查看执行结果

:**

**[hadoop@Master ~]

hadoop dfs -cat output/\***

**14.
停止
HDFS
和
MapReduce**

—

执行以下命令启动
HDFS
和
MapReduce

**[hadoop@ Master ~]$ stop-all.sh**