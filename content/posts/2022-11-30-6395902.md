---
arturl_encode: "68747470:733a2f2f626c6f672e6373646e2e6e65742f6c697573697975:6e2f61727469636c652f64657461696c732f36333935393032"
layout: post
title: "音视频同步解决方案"
date: 2022-11-30 19:05:27 +0800
description: "　一、音视频同步问题概述： 音视频同步问题是可视对讲中的重点需要解决的问题之一，也是一直以来被模拟门"
keywords: "qt 音视频文件同步播放"
categories: ['多媒体']
tags: ['网络', '编程', 'Windows', 'Signal', 'Linux', 'H']
artid: "6395902"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=6395902
    alt: "音视频同步解决方案"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=6395902
featuredImagePreview: https://bing.ee123.net/img/rand?artid=6395902
---

# 音视频同步解决方案

一、音视频同步问题概述： 音视频同步问题是可视对讲中的重点需要解决的问题之一，也是一直以来被模拟门禁产品厂商攻击的一个弱点，因为模拟可视对讲产品都采用专线传输，不存在这个 问题。解决同步问题的方法有很多种，其中时间戳是最成熟最完美也是最复杂的解决办法，可以解决任何多媒体领域的音视频同步问题;其原理是选择一个参考时 间，在生成数据流时依据参考时间上的时间给每个数据块都打上时间戳;在播放时，读取数据块上的时间戳，同时参考当前时钟上的时间来安排播放，让快于这个参 考时间的包等待，丢弃慢于这个参考时间的包。 在基于时间戳的同步机制中，仅仅对不同步的数据进行处理是不完备的，还需要反馈机制，如基于Windows平台的DirectShow就提供这样一个反馈 机制，它的质量控制(Quality Control)可以将播放的状态反馈给源，让源端加快或者放慢数据流的速度。

在多媒体文件采集，播放及对同步的要求都非常严格，如果从多媒体文件中分离出音视频数据的数据不同步，音视频的时间差则会越来越大，这是无法忍受的，所以在多媒体文件中，不但要求有同步机制，还要求有反馈机制。

二、数字可视对讲中的音视频同步方案

在数字可视对讲中，可以考虑的音视频同步方案有两种：一是发送端解决;二是接收端解决。

发送端解决方法比较简单，具体措施是在发送端先将一段时间内采集到音视频数据打包。比如采集到一帧视频图像，将这帧图像与采集这帧视频的时间内 采集到的视频数据打成一个包，接收端接收到这个包之后解包分别播放就可以了。发送端解决的控制方法比较简单，但是在高清要求清晰度比较高的情况下就不是很 理想，清晰度高，意味着每个音视频包数据量就大，能保证同步，却难以保证连续。我们在同一个线程中按照先后顺序发送PCM音频和H.264视频，测试结果 表明这种方法确实存在连续问题。

接收端解决方案绕不开的问题是时间戳，接收端根据接收到的音视频数据的时间戳安排播放。时间戳需要一个参考时间，而采集过程中视频的时间是不定的，数字
[**摄像头**](http://www.b2b888.com/sell/list-203.html)
采集图像的帧率是一个平均值，不宜用来做参考时间，所以只能用音频时间作为参考时间。

三、声卡编程和声卡驱动的时间机制

门禁可视对讲中音频是双向的。本文的门禁可视对讲方案中，音频的采用PCM(Pulse Code Modulation——脉码调制录音)采集，在网络中传送的也是原始数据，之所以没有对音频数据进行编码处理是基于以下原因：一是S3C6410没有提 供对音频的硬编解码，如果使用软件实现编解码，在有限的系统资源条件下难以实现;二是音频数据量较小：采用8000采样率和量化位数为8位的电话语音标 准，一秒的音频数据是8K字节，只相当于视频1帧数据的两倍，这对普遍拥有百兆网卡的局域网来说，数据量很小。实验的结果表明，这种简单的处理方式被证明 是有效的。

Linux操作系统下音频接口有/dev/dsp,/dev/audio,/dev/Mixer三种。前两种的属性基本相同，DSP是数字信号 处理器(Digital Signal Processor)的简称，是用于数字采样(sampling)和数字录音(recording)的设备文件，它对于Linux下的音频编程来讲非常重 要。向该设备写数据即意味着激活声卡上的D/A转换器进行放音，而向该设备读数据则意味着激活声卡上的A/D转换器进行录音。目前许多声卡都提供有多个数 字采样设备。/dev/audio属性与dsp类似，但更多的用于sun的工作站中，为兼容性考虑，应用中一般使用/dev/dsp作为音频接口。 mixer为混音器，也是声卡设备中相当重要的一部分，它的作用是将多个信号组合或者叠加到一起，但对应用程序来说，这些都无需考虑，但可以通过这个接口 调节声卡播放时声音的大小等参数。

无论是Linux下还是Windows下，声卡的编程接口都是由声卡驱动提供的，而驱动都是会考虑到时间机制的，其表现形式就是当声卡驱动没有 装好时，使用播放器播放多媒体文件时声音以极快的速度过去了，但是声卡驱动装好之后就很正常了，本文的音视频同步解决方案即以此为基础。

四、基于音频时间机制的音视频同步解决方案

与文件形式的多媒体不同的是，可视对讲中音视频流的源端是永远同步的。所以一种简单的解决方案是发送端启用独立的音频和视频线程，进行音视频采 集，采集后只管往外发送数据，接收端接到数据就分别解码播放，从表面看，这种采用无同步机制多线程解决方案是可行的，但是忽略了一个问题，即音频数据包和 视频数据包的大小。包的大小会影响网络传输的速度。这种差别在网络条件好的情况下显示不出来，一旦遇到网络拥塞或者其他情况就会变得很明显。

根据对音频采集和处理的叙述，我们知道，音频的采集是有时间机制的。比如采样率是8000，采样位数是8，我们就可以算出采8K字节的数据所用 的时间是1s，这样音频就可以按照自己的速度播放;而摄像头每秒采集的帧数是相对固定的，如OV9650采集速度为平均每秒30帧，这样即可以算出 1/30秒(约为0.03333，具体精度可以根据要求决定)刷新一帧图片，这种方式中只要保证源端音频视频的采集是同步的就可以，而门禁对讲过程中，这 种同步是原生的。其实现流程如下图所示：

![](https://i-blog.csdnimg.cn/blog_migrate/8b77f783984f11d8f1c6b2ca68ca5ed4.jpeg)

发送端分别用线程采集音视频数据，采集的同时根据RTP协议的规定分别将这些数据打上时间戳，然后通过RTP底层协议(如UDP)发送出去。

接收端接收到音频数据，直接交给声卡播放，当前播放的音频包的时间戳时间传送给视频线程;接收到视频帧，则将其时间戳时间与当前播放的音频时间 戳进行比较，若未达到参考时间，则解码播放;若达到参考时间，则说明该视频帧滞后，丢弃该视频帧，接收下一个视频帧，循环往复，直到线程接收到结束命令停 止;以上述音频采样率和采样位数为例，视频参考时间的计算方法为(以C语言格式的?号表达式表示)：

音频时间戳时间 +1/30> 视频时间戳时间+丢弃：播放;

在编程实现时，采集端和播放端的音频和视频可采用独立的线程，并利用Qt的信号槽机制实现音视频线程时间戳的传递，此处不再赘述。