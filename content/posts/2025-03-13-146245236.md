---
arturl_encode: "68747470733a2f:2f626c6f672e6373646e2e6e65742f534b5f53747564696f2f:61727469636c652f64657461696c732f313436323435323336"
layout: post
title: "卷积神经网络CNN的主要架构"
date: 2025-03-13 23:57:26 +0800
description: "卷积神经网络（CNN）不断演进，以提升深度、计算效率和适应性。早期架构奠定基础，随后引入更深层次网络、残差连接和轻量化设计，以提高性能并减少计算成本。近年来，研究重点转向自动优化 CNN 结构，如 EfficientNet 和 RegNet，以及结合 Transformer 设计优化 CNN，如 ConvNeXt。尽管 Transformer 逐渐崛起，CNN 仍在计算机视觉任务中占据重要地位，并持续优化以适应不同应用场景。"
keywords: "卷积神经网络（CNN）的主要架构"
categories: ['人工智能']
tags: ['神经网络', '深度学习', '机器学习', '人工智能', 'Cnn']
artid: "146245236"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146245236
    alt: "卷积神经网络CNN的主要架构"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146245236
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146245236
cover: https://bing.ee123.net/img/rand?artid=146245236
image: https://bing.ee123.net/img/rand?artid=146245236
img: https://bing.ee123.net/img/rand?artid=146245236
---

# 卷积神经网络（CNN）的主要架构

卷积神经网络（CNN, Convolutional Neural Networks）是深度学习中最重要的模型之一，广泛应用于
**计算机视觉**
、
**目标检测**
、
**语义分割**
等任务。自 LeNet 诞生以来，CNN 结构经历了多个重要发展阶段，出现了许多
**经典架构**
，包括 AlexNet、VGG、GoogLeNet（Inception）、ResNet、DenseNet、MobileNet 等。

本文将详细介绍 CNN 的主要架构及其核心思想，帮助大家深入理解 CNN 发展历程及各架构的特点。

---

### **1. LeNet-5（1998）—— 卷积神经网络的奠基者**

**提出者**
：Yann LeCun
  
**贡献**
：

* 提出了 CNN 的基本框架（卷积层 + 池化层 + 全连接层）。
* 率先应用 CNN 处理手写数字识别（MNIST 数据集）。
* 采用
  **Sigmoid/Tanh**
  作为激活函数。

**结构：**

* 输入：

  32
  ×
  32
  32 \times 32





  32



  ×





  32
  灰度图像（MNIST 手写数字）。
* **C1**
  ：卷积层（6 个

  5
  ×
  5
  5 \times 5





  5



  ×





  5
  过滤器）
* **S2**
  ：池化层（平均池化）
* **C3**
  ：卷积层（16 个

  5
  ×
  5
  5 \times 5





  5



  ×





  5
  过滤器）
* **S4**
  ：池化层（平均池化）
* **C5**
  ：全连接层
* **F6**
  ：全连接层（输出 10 类）

**特点：**

* 是
  **第一个真正意义上的 CNN**
  。
* 采用
  **权重共享**
  ，大幅减少参数量。
* 由于计算机硬件限制，仅适用于简单任务（MNIST）。

---

### **2. AlexNet（2012）—— 深度学习的复兴**

**提出者**
：Alex Krizhevsky, Geoffrey Hinton
  
**贡献**
：

* 在 ImageNet 竞赛中
  **首次**
  击败传统方法（SIFT + SVM），引发
  **深度学习热潮**
  。
* 采用
  **ReLU 激活函数**
  ，解决梯度消失问题。
* 通过
  **Dropout**
  进行正则化，减少过拟合。
* 使用
  **GPU 计算**
  ，显著提高训练速度。

**结构：**

* **输入**
  ：

  224
  ×
  224
  224 \times 224





  224



  ×





  224
  RGB 图像
* **C1**
  ：卷积层（96 个

  11
  ×
  11
  11 \times 11





  11



  ×





  11
  过滤器，步长 4）
* **P2**
  ：最大池化（

  3
  ×
  3
  3 \times 3





  3



  ×





  3
  ，步长 2）
* **C3**
  ：卷积层（256 个

  5
  ×
  5
  5 \times 5





  5



  ×





  5
  过滤器）
* **P4**
  ：最大池化
* **C5, C6, C7**
  ：三个卷积层
* **P8**
  ：最大池化
* **F9, F10**
  ：两个全连接层（4096 维）
* **F11**
  ：Softmax 进行分类

**特点：**

* **加深网络层数（8 层）**
  ，但仍然较浅。
* **引入 ReLU**
  ，加速训练并提高收敛速度。
* **采用 GPU 训练**
  ，比 CPU 速度快 10 倍以上。

---

### **3. VGG（2014）—— 简单但深度**

**提出者**
：Oxford VGG 团队
  
**贡献**
：

* 采用
  **小卷积核（

  3
  ×
  3
  3 \times 3





  3



  ×





  3
  ）**
  ，用多个小卷积堆叠代替大卷积，减少参数量同时保持感受野。
* **层次更深（VGG-16、VGG-19）**
  ，最高可达 19 层。

**结构（VGG-16）：**

* **输入**
  ：

  224
  ×
  224
  224 \times 224





  224



  ×





  224
  RGB 图像
* **C1-C2**
  ：

  3
  ×
  3
  3 \times 3





  3



  ×





  3
  卷积（64 个通道）
* **P1**
  ：最大池化
* **C3-C4**
  ：

  3
  ×
  3
  3 \times 3





  3



  ×





  3
  卷积（128 个通道）
* **P2**
  ：最大池化
* **C5-C7**
  ：

  3
  ×
  3
  3 \times 3





  3



  ×





  3
  卷积（256 个通道）
* **P3**
  ：最大池化
* **C8-C13**
  ：

  3
  ×
  3
  3 \times 3





  3



  ×





  3
  卷积（512 个通道）
* **P4**
  ：最大池化
* **全连接层**
  ：4096 + 4096 + 1000（分类）

**特点：**

* **全部使用

  3
  ×
  3
  3 \times 3





  3



  ×





  3
  卷积**
  ，网络结构更规则。
* **参数量巨大**
  （VGG-16 有 1.38 亿个参数）。
* 计算量大，推理速度慢，适合迁移学习（如 ImageNet 预训练）。

---

### **4. GoogLeNet（2014）—— Inception 结构**

**提出者**
：Google
  
**贡献**
：

* 提出
  **Inception 模块**
  ，采用不同尺寸的卷积核并行计算，提高特征表达能力。
* 通过
  **1×1 卷积进行降维**
  ，减少计算量。

**结构（Inception v1）：**

* **输入**
  ：

  224
  ×
  224
  224 \times 224





  224



  ×





  224
  RGB 图像
* **C1**
  ：

  7
  ×
  7
  7 \times 7





  7



  ×





  7
  卷积
* **P1**
  ：池化
* **C2-C3**
  ：

  3
  ×
  3
  3 \times 3





  3



  ×





  3
  卷积
* **多个 Inception 模块**
* **全连接层（Softmax 分类）**

**特点：**

* **并行多尺度特征提取**
  ，增强模型能力。
* **参数量减少**
  ，比 VGG 更轻量化。
* 发展出多个版本（Inception v2, v3, v4, Xception）。

---

### **5. ResNet（2015）—— 解决深度退化问题**

**提出者**
：Kaiming He, Microsoft Research
  
**贡献**
：

* 提出
  **残差学习（Residual Learning）**
  ，通过
  **跳跃连接（Shortcut Connection）**
  解决梯度消失问题，使 CNN 深度突破 100 层。
* ResNet-50, ResNet-101, ResNet-152 等版本成为主流。

**残差块（Residual Block）：**
  




y
=
F
(
x
)
+
x
y = F(x) + x





y



=





F

(

x

)



+





x
  
其中：

* F
  (
  x
  )
  F(x)





  F

  (

  x

  )
  由两层卷积组成。
* **跳跃连接**
  让梯度更容易传播，避免梯度消失。

**特点：**

* **可训练超深网络（152 层以上）**
  ，突破 CNN 训练极限。
* **性能卓越**
  ，在 ImageNet 竞赛中夺冠。
* 后续衍生出
  **ResNeXt、WideResNet 等变体**
  。

---

### **6. MobileNet（2017）—— 轻量级 CNN**

**提出者**
：Google
  
**贡献**
：

* 采用
  **深度可分离卷积（Depthwise Separable Convolution）**
  ，减少计算量和参数量，使 CNN 可用于移动端。
* 可用于实时应用，如手机端人脸识别。

**结构：**

* **标准卷积**
  替换为
  **深度可分离卷积**
* **1×1 卷积降维**
  ，减少参数量
* 提供 MobileNetV1, V2, V3 版本，逐步优化

**特点：**

* **计算量减少**
  90% 以上，适合移动设备。
* **轻量级**
  ，适用于嵌入式 AI 任务（如自动驾驶）。

---

### **7. EfficientNet（2019）—— 自动搜索优化 CNN**

**提出者**
：Google Brain
  
**贡献**
：

* 提出了
  **复合缩放（Compound Scaling）**
  方法，统一调整 CNN 的
  **深度、宽度和分辨率**
  ，提高计算效率。
* 采用
  **MobileNetV2**
  的深度可分离卷积和
  **Swish 激活函数**
  ，减少计算量。
* 在 ImageNet 上比 ResNet、DenseNet 等模型更高效。

**结构：**

* 使用
  **MBConv**
  （MobileNetV2 提出的 Inverted Residual Block）。
* 通过
  **神经架构搜索（NAS）**
  自动优化 CNN 结构。

**特点：**

* **参数更少，性能更强**
  （EfficientNet-B7 在 ImageNet 上超越 ResNet152）。
* **可扩展**
  ：EfficientNet-B0 到 B7 提供不同计算复杂度的版本。

---

### **8. RegNet（2020）—— 通过规则生成 CNN**

**提出者**
：Facebook AI
  
**贡献**
：

* 通过系统化搜索找到最佳的 CNN 设计规则，而非单独优化某个模型。
* 提出了
  **可预测的 CNN 结构**
  ，在计算资源受限的情况下仍然保持高性能。

**特点：**

* **比 ResNet 更高效**
  ，在 ImageNet 上实现更优性能。
* **提供多个变体**
  （RegNetX, RegNetY），可适应不同计算需求。

---

### **9. ConvNeXt（2022）—— CNN 重新对标 Transformer**

**提出者**
：Facebook AI
  
**贡献**
：

* 受 Vision Transformer（ViT） 启发，对 CNN 进行结构优化，使其在 ImageNet 上与 ViT 竞争。
* 通过简化 ResNet 设计，提升 CNN 在现代硬件上的性能。

**特点：**

* **改进的残差结构**
  （ResNet 变体）。
* **大核卷积（7×7）**
  提升感受野。
* **层归一化（LayerNorm）**
  替代 BatchNorm，提高训练稳定性。

---

### **CNN 的未来趋势**

虽然近年来
**Vision Transformer（ViT）**
和
**MLP 结构**
（如 MLP-Mixer）取得了较大突破，但 CNN 仍然是计算机视觉领域的核心方法。未来 CNN 可能会：

1. **与 Transformer 结合**
   （如 Swin Transformer + CNN）。
2. **进一步优化轻量级架构**
   （如 MobileNetV3, EfficientNetLite）。
3. **增强可解释性**
   ，提升透明度和泛化能力。

---

### **总结**

| 架构 | 主要特点 | 适用场景 |
| --- | --- | --- |
| **LeNet (1998)** | CNN 基础框架 | 早期图像识别 |
| **AlexNet (2012)** | ReLU + Dropout | 图像分类 |
| **VGG (2014)** | 深层 CNN，3×3 卷积 | 迁移学习 |
| **GoogLeNet (2014)** | Inception 模块 | 多尺度特征提取 |
| **ResNet (2015)** | 残差学习，超深网络 | 高精度任务 |
| **MobileNet (2017)** | 轻量级 CNN | 移动端 AI |
| **EfficientNet (2019)** | 复合缩放 + NAS | 高效图像分类 |
| **RegNet (2020)** | 规则生成 CNN | 灵活架构优化 |
| **ConvNeXt (2022)** | CNN 对标 Transformer | 现代计算机视觉 |

虽然 Transformer 逐渐成为主流，但 CNN 仍然有广泛应用，并在不断进化！
  
如果你对某个架构感兴趣，可以深入研究它的论文或实现！