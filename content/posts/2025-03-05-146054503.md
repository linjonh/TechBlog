---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f36343039313930302f:61727469636c652f64657461696c732f313436303534353033"
layout: post
title: "文献分享-ConstBERT固定数目向量编码文档"
date: 2025-03-05 22:15:04 +0800
description: "ECIR'25"
keywords: "文献分享: ConstBERT固定数目向量编码文档"
categories: ['文献阅读笔记']
tags: ['自然语言处理', '机器学习', '数据库', 'Nlp']
artid: "146054503"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146054503
    alt: "文献分享-ConstBERT固定数目向量编码文档"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146054503
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146054503
cover: https://bing.ee123.net/img/rand?artid=146054503
image: https://bing.ee123.net/img/rand?artid=146054503
img: https://bing.ee123.net/img/rand?artid=146054503
---

# 文献分享: ConstBERT固定数目向量编码文档

😂图放这了，大道至简的

idea
\text{idea}






idea
不愧是

ECIR
\text{ECIR}






ECIR

![image-20250305212409686](https://i-blog.csdnimg.cn/direct/d2ca3bae2f6f41e8a39675ed1527bd77.png)

👉
[原论文](https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/ECIR25b.pdf)

## 1.   ConstBERT \textbf{1. ConstBERT} 1. ConstBERT 的原理

> 1️⃣模型的改进点：相较于
>
> ColBERT
> \text{ColBERT}
>
>
>
>
>
>
> ColBERT
> 为每个
>
> Token
> \text{Token}
>
>
>
>
>
>
> Token
> 生成一个向量，
>
> ConstBERT
> \text{ConstBERT}
>
>
>
>
>
>
> ConstBERT
> 只为段落生成固定
>
> C
> C
>
>
>
>
>
> C
> 个向量
>
> 1. 嵌入阶段：为查询
>
>    Q
>    Q
>
>
>
>
>
>    Q
>    和段落
>
>    P
>    P
>
>
>
>
>
>    P
>    的每个
>
>    Token
>    \text{Token}
>
>
>
>
>
>
>    Token
>    都生成一个
>
>    d
>    d
>
>
>
>
>
>    d
>    维向量，是为
>
>    {
>    q
>    1
>    ,
>    …
>    ,
>    q
>    N
>    }
>    \{q\_{1},\ldots,q\_{N}\}
>
>
>
>
>
>    {
>
>
>    q
>
>
>
>
>
>
>
>
>
>
>    1
>
>    ​
>
>
>    ,
>
>
>
>    …
>
>
>
>    ,
>
>
>
>
>    q
>
>
>
>
>
>
>
>
>
>
>    N
>
>    ​
>
>
>    }
>    和
>
>    {
>    p
>    1
>    ,
>    …
>    ,
>    p
>    M
>    }
>    \{p\_{1},\ldots,p\_{M}\}
>
>
>
>
>
>    {
>
>
>    p
>
>
>
>
>
>
>
>
>
>
>    1
>
>    ​
>
>
>    ,
>
>
>
>    …
>
>
>
>    ,
>
>
>
>
>    p
>
>
>
>
>
>
>
>
>
>
>    M
>
>    ​
>
>
>    }
> 2. 线性变换：拼接所有段落单向量为
>
>    [
>    p
>    1
>    ,
>    ⋯
>     
>    ,
>    p
>    M
>    ]
>    ∈
>    R
>    d
>    M
>    \left[p\_{1},\cdots,p\_{M}\right]\text{∈}\mathbb{R}^{dM}
>
>
>
>
>
>
>    [
>
>
>    p
>
>
>
>
>
>
>
>
>
>
>    1
>
>    ​
>
>
>    ,
>
>
>
>    ⋯
>
>
>
>
>
>    ,
>
>
>
>
>    p
>
>
>
>
>
>
>
>
>
>
>    M
>
>    ​
>
>
>    ]
>
>
>
>
>    ∈
>
>
>    R
>
>
>
>
>
>
>
>
>
>
>    d
>
>    M
>    ，进行
>
>    W
>    ∈
>    R
>    M
>    k
>    ×
>    C
>    k
>    \mathbf{W}\text{∈}\mathbb{R}^{Mk\text{×}Ck}
>
>
>
>
>
>    W
>
>
>    ∈
>
>
>    R
>
>
>
>
>
>
>
>
>
>
>    M
>
>    k
>
>
>    ×
>
>    C
>
>    k
>    投影得
>
>    [
>    δ
>    1
>    ,
>    ⋯
>     
>    ,
>    δ
>    C
>    ]
>    =
>    W
>    T
>    [
>    p
>    1
>    ,
>    ⋯
>     
>    ,
>    p
>    M
>    ]
>    ∈
>    R
>    d
>    C
>    \left[\delta\_{1},\cdots, \delta\_{C}\right]\text{=}\mathbf{W}^{T}\left[p\_{1},\cdots,p\_{M}\right]\text{∈}\mathbb{R}^{dC}
>
>
>
>
>
>
>    [
>
>
>    δ
>
>
>
>
>
>
>
>
>
>
>    1
>
>    ​
>
>
>    ,
>
>
>
>    ⋯
>
>
>
>
>
>    ,
>
>
>
>
>    δ
>
>
>
>
>
>
>
>
>
>
>    C
>
>    ​
>
>
>    ]
>
>
>
>
>    =
>
>
>    W
>
>
>
>
>
>
>
>
>
>
>    T
>
>
>
>
>    [
>
>
>    p
>
>
>
>
>
>
>
>
>
>
>    1
>
>    ​
>
>
>    ,
>
>
>
>    ⋯
>
>
>
>
>
>    ,
>
>
>
>
>    p
>
>
>
>
>
>
>
>
>
>
>    M
>
>    ​
>
>
>    ]
>
>
>
>
>    ∈
>
>
>    R
>
>
>
>
>
>
>
>
>
>
>    d
>
>    C
> 3. 后期交互：同
>
>    ColBERT
>    \text{ColBERT}
>
>
>
>
>
>
>    ColBERT
>    ，为每个
>
>    q
>    i
>    q\_i
>
>
>
>
>
>
>    q
>
>
>
>
>
>
>
>
>
>    i
>
>    ​
>
>    找到与其内积最大的
>
>    MaxSim
>    (
>    q
>    i
>    ,
>    δ
>    )
>    =
>    δ
>    p
>    i
>    \text{MaxSim}(q\_i,\delta)\text{=}\delta\_{p\_i}
>
>
>
>
>
>
>    MaxSim
>
>    (
>
>
>    q
>
>
>
>
>
>
>
>
>
>    i
>
>    ​
>
>
>    ,
>
>
>
>    δ
>
>    )
>
>
>    =
>
>
>    δ
>
>
>
>
>
>
>
>
>
>
>
>    p
>
>
>
>
>
>
>
>
>
>    i
>
>    ​
>
>
>    ​
>
>    ，最后将所有
>
>    MaxSim
>    \text{MaxSim}
>
>
>
>
>
>
>    MaxSim
>    相加得到相似度评分
>
> 2️⃣改进的动机：为何非要固定数目的段落向量
>
> 1. 存储效率上：设定
>
>    C
>    <
>    M
>    C\text{<}M
>
>
>
>
>
>    C
>
>
>    <
>
>    M
>    后，能降低段落嵌入所占的空间
> 2. 计算效率上：设定
>
>    C
>    <
>    M
>    C\text{<}M
>
>
>
>
>
>    C
>
>
>    <
>
>    M
>    后，将原有
>
>    O
>    (
>    M
>    N
>    )
>    O(MN)
>
>
>
>
>
>    O
>
>    (
>
>    MN
>
>    )
>    的查询复杂度降为了
>
>    O
>    (
>    C
>    N
>    )
>    O(CN)
>
>
>
>
>
>    O
>
>    (
>
>    CN
>
>    )
> 3. 系统级优化：使得内存对齐，规避了变长文档表示导致内存碎片化，从而降低了
>
>    Cache Miss
>    \text{Cache Miss}
>
>
>
>
>
>
>    Cache Miss

## 2.   ConstBERT \textbf{2. ConstBERT} 2. ConstBERT 的实验结果

> 1️⃣效果：当
>
> C
> =
> 32
> C\text{=}32
>
>
>
>
>
> C
>
>
> =
>
> 32
> 时，在
>
> MsMarco/BEIR
> \text{MsMarco/BEIR}
>
>
>
>
>
>
> MsMarco/BEIR
> 等数据集上，查询效果与
>
> ColBERT
> \text{ColBERT}
>
>
>
>
>
>
> ColBERT
> 相当(用
>
> MRR@10/nDCG@10
> \text{MRR@10/nDCG@10}
>
>
>
>
>
>
> MRR@10/nDCG@10
> 衡量)
>
> 2️⃣效率：相比
>
> ColBERT
> \text{ColBERT}
>
>
>
>
>
>
> ColBERT
> 对段落的存储空间需求减少了一半多，端到端检索响应速度也显著加快