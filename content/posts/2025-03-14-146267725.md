---
arturl_encode: "68747470733a2f2f:626c6f672e6373646e2e6e65742f6368656e6779713131362f:61727469636c652f64657461696c732f313436323637373235"
layout: post
title: "Stable-Diffusion-Models"
date: 2025-03-14 21:48:32 +08:00
description: "Stable Diffusion Models"
keywords: "Stable Diffusion Models"
categories: ['Vision', 'Model', 'Large']
tags: ['Stable', 'Models', 'Diffusion']
artid: "146267725"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146267725
    alt: "Stable-Diffusion-Models"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146267725
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146267725
cover: https://bing.ee123.net/img/rand?artid=146267725
image: https://bing.ee123.net/img/rand?artid=146267725
img: https://bing.ee123.net/img/rand?artid=146267725
---

# Stable Diffusion Models

We recommend you use Stable Diffusion with
[Hugging Face Diffusers library](https://github.com/huggingface/diffusers)
. You can also use the original
[CompVis code](https://github.com/compvis/stable-diffusion)
.

## 1. CompVis Stable Diffusion

**CompVis Stable Diffusion**
  
<https://github.com/compvis/stable-diffusion>

Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input.

* CompVis/stable-diffusion-v-1-1-original

<https://huggingface.co/CompVis/stable-diffusion-v-1-1-original>

* CompVis/stable-diffusion-v-1-2-original

<https://huggingface.co/CompVis/stable-diffusion-v-1-2-original>

* CompVis/stable-diffusion-v-1-3-original

<https://huggingface.co/CompVis/stable-diffusion-v-1-3-original>

* CompVis/stable-diffusion-v-1-4-original

<https://huggingface.co/CompVis/stable-diffusion-v-1-4-original>

## 2. Hugging Face Diffusers

**Hugging Face Diffusers**
  
<https://github.com/huggingface/diffusers>

Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input.

* CompVis/stable-diffusion-v1-1

<https://huggingface.co/CompVis/stable-diffusion-v1-1>

* CompVis/stable-diffusion-v1-2

<https://huggingface.co/CompVis/stable-diffusion-v1-2>

* CompVis/stable-diffusion-v1-3

<https://huggingface.co/CompVis/stable-diffusion-v1-3>

* CompVis/stable-diffusion-v1-4

<https://huggingface.co/CompVis/stable-diffusion-v1-4>

## 3. Contrastive Language-Image Pre-Training (CLIP)

* openai/clip-vit-large-patch14

<https://huggingface.co/openai/clip-vit-large-patch14>

* CLIP

<https://github.com/openai/CLIP>

CLIP (Contrastive Language-Image Pre-Training) is a neural network trained on a variety of (image, text) pairs.

## References

[1] Yongqiang Cheng,
<https://yongqiang.blog.csdn.net/>