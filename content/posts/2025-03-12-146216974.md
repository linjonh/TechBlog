---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f34303832313236302f:61727469636c652f64657461696c732f313436323136393734"
layout: post
title: "AI-Agent系列四-Agent架构认知"
date: 2025-03-12 22:57:18 +08:00
description: "ReAct，一种提示工程框架，为语言模型提供了一种思维过程策略，以推理并采取行动响应用户查询，无论是否有上下文示例。Agents可以利用上述推理技术之一，或许多其他技术，为给定的用户请求选择下一步最佳行动。它概括了链式思维提示，并允许模型探索各种思维链，作为语言模型通用问题解决的中间步骤。ii. 例如，行动可以是[Flights, Search, Code, None]之一，其中前三个代表模型可以选择的一个已知工具，最后一个代表“无工具选择”agent的认知架构中有三个基本组件： 模型，工具和编排层。"
keywords: "AI Agent系列(四) -Agent架构认知"
categories: ['人工智能']
tags: ['架构', '智能化', '人工智能', 'Agent']
artid: "146216974"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146216974
    alt: "AI-Agent系列四-Agent架构认知"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146216974
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146216974
cover: https://bing.ee123.net/img/rand?artid=146216974
image: https://bing.ee123.net/img/rand?artid=146216974
img: https://bing.ee123.net/img/rand?artid=146216974
---

# AI Agent系列(四) -Agent架构认知

---

## 一、 Agent的三大基本组件

agent的认知架构中有三个基本组件： 模型，工具和编排层。

1. 模型
     
   在agent的范围内，模型指的是将用作agent过程集中决策者的语言模型（LM）。agent使用的模型可以是一个或多个任何大小（小/大）的LM。
     
   需要注意的是，模型通常不会使用agent的特定配置设置（即工具选择、编排/推理设置）进行训练。然而，通过提供展示agent能力的示例，包括agent在各种上下文中使用特定工具或推理步骤的实例，可以进一步优化模型以适应agent的任务。
2. 工具
     
   工具是为了弥补基础模型在文本和图像生成方面表现出色，但无法与外部世界互动限制。
     
   工具使agent能够与外部数据和服务互动，从而解锁比底层模型单独所能实现的更广泛的行动。通过工具，agent可以访问和处理现实世界的信息。这使它们能够支持更专业的系统，如检索增强生成（RAG），这显著扩展了agent的能力，超越了基础模型单独所能实现的范围。
3. 编排层
     
   编排层描述了一个循环过程，该过程管理agent如何接收信息、执行一些内部推理，并使用该推理来通知其下一步行动或决策。这个循环通常需要持续到agent达到其目标或停止点。
     
   编排层可以是简单的计算和决策规则，也可能包含链式逻辑、涉及额外的机器学习算法或实现其他概率推理技术。
     
   ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e5b6776dde064315b5a8455d93fdd3e5.jpeg)

## 二、 Agent的运行

agent可以使用认知架构通过迭代处理信息、做出明智决策并根据之前的输出细化下一步行动来实现其最终目标。在agent认知架构的核心是编排层，负责维护记忆、状态、推理和计划。它利用快速发展的提示工程领域及相关框架来指导推理和计划。
  
提示工程框架和任务规划的最流行的框架和推理技术包括如下三个：

* ReAct，一种提示工程框架，为语言模型提供了一种思维过程策略，以推理并采取行动响应用户查询，无论是否有上下文示例。ReAct提示已显示出优于多个SOTA基线，并提高了LLM的人类互操作性和可信度。
* Chain-of-Thought (CoT)，一种提示工程框架，通过中间步骤实现推理能力。CoT有多种子技术，包括自一致性、主动提示和多模态CoT，每种技术根据具体应用具有不同的优缺点。
* Tree-of-Thoughts(ToT)，一种提示工程框架，非常适合探索或战略前瞻任务。它概括了链式思维提示，并允许模型探索各种思维链，作为语言模型通用问题解决的中间步骤。

Agents可以利用上述推理技术之一，或许多其他技术，为给定的用户请求选择下一步最佳行动。例如使用ReAct框架来为用户查询选择正确行动和工具的agent，其事件序列可能如下：

1. 用户向agent发送查询
2. agent开始ReAct序列
3. agent向模型提供提示，要求其生成下一个ReAct步骤及其相应的输出：

a. 问题：来自用户查询的输入问题，随提示提供

b. 思考：模型关于下一步该做什么的思考

c. 行动：模型关于下一步采取什么行动的决定

i. 这里可以选择工具

ii. 例如，行动可以是[Flights, Search, Code, None]之一，其中前三个代表模型可以选择的一个已知工具，最后一个代表“无工具选择”

d. 行动输入：模型关于向工具提供什么输入的决定（如果有）

e. 观察：行动/行动输入序列的结果

i. 这个思考/行动/行动输入/观察可以根据需要重复N次

f. 最终答案：模型提供给原始用户查询的最终答案

4. ReAct循环结束，并向用户提供最终答案
     
   ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c7f53d198d2146e9ba39de12496ededb.jpeg)
     
   如上图所示，模型、工具和编排层的agent配置共同作用，根据用户的原始查询提供基于事实的简明响应。