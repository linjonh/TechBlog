---
layout: post
title: "PyTorch-系列教程使用CNN实现图像分类"
date: 2025-03-12 21:22:20 +0800
description: "通过PyTorch和卷积神经网络，你可以有效地处理图像分类任务。借助PyTorch的灵活性，可以根据特定的数据集和应用程序构建、训练和微调模型。示例代码仅为理论过程，实际项目中还有大量优化空间。"
keywords: "PyTorch 系列教程：使用CNN实现图像分类"
categories: ['人工智能', 'Python']
tags: ['分类', 'Pytorch', 'Cnn']
artid: "146215409"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146215409
    alt: "PyTorch-系列教程使用CNN实现图像分类"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146215409
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146215409
cover: https://bing.ee123.net/img/rand?artid=146215409
image: https://bing.ee123.net/img/rand?artid=146215409
img: https://bing.ee123.net/img/rand?artid=146215409
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     PyTorch 系列教程：使用CNN实现图像分类
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <blockquote>
     <p>
      图像分类是计算机视觉领域的一项基本任务，也是深度学习技术的一个常见应用。近年来，卷积神经网络（cnn）和PyTorch库的结合由于其易用性和鲁棒性已经成为执行图像分类的流行选择。
     </p>
    </blockquote>
    <h3>
     <a id="cnn_4">
     </a>
     理解卷积神经网络（cnn）
    </h3>
    <p>
     卷积神经网络是一类深度神经网络，对分析视觉图像特别有效。他们利用多层构建一个可以直接从图像中识别模式的模型。这些模型对于图像识别和分类等任务特别有用，因为它们不需要手动提取特征。
    </p>
    <h4>
     <a id="cnn_8">
     </a>
     cnn的关键组成部分
    </h4>
    <ul>
     <li>
      卷积层：这些层对输入应用卷积操作，将结果传递给下一层。每个过滤器（或核）可以捕获不同的特征，如边缘、角或其他模式。
     </li>
     <li>
      池化层：这些层减少了表示的空间大小，以减少参数的数量并加快计算速度。池化层简化了后续层的处理。
     </li>
     <li>
      完全连接层：在这些层中，神经元与前一层的所有激活具有完全连接，就像传统的神经网络一样。它们有助于对前一层识别的对象进行分类。
      <br/>
      <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/direct/244bdc5121c741348312ab6f50037f9a.png"/>
     </li>
    </ul>
    <h3>
     <a id="PyTorch_15">
     </a>
     使用PyTorch进行图像分类
    </h3>
    <p>
     PyTorch是开源的深度学习库，提供了极大的灵活性和多功能性。研究人员和从业人员广泛使用它来轻松有效地实现尖端的机器学习模型。
    </p>
    <h4>
     <a id="PyTorch_19">
     </a>
     设置PyTorch
    </h4>
    <p>
     首先，确保在开发环境中安装了PyTorch。你可以通过pip安装它：
    </p>
    <pre><code>pip install torch torchvision
</code></pre>
    <h4>
     <a id="PyTorchCNN_27">
     </a>
     用PyTorch创建简单的CNN示例
    </h4>
    <p>
     下面是如何定义简单的CNN来使用PyTorch对图像进行分类的示例。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token comment"># 定义CNN模型（修复了变量引用问题）</span>
<span class="token keyword">class</span> <span class="token class-name">SimpleCNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SimpleCNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>      <span class="token comment"># 第一个卷积层：3输入通道，6输出通道，5x5卷积核</span>
        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment"># 最大池化层：2x2窗口，步长2</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>     <span class="token comment"># 第二个卷积层：6输入通道，16输出通道，5x5卷积核</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span><span class="token comment"># 全连接层1：400输入 -&gt; 120输出</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>      <span class="token comment"># 全连接层2：120输入 -&gt; 84输出</span>
        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>       <span class="token comment"># 输出层：84输入 -&gt; 10类 logits</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 输入形状：[batch_size, 3, 32, 32]</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># -&gt; [batch, 6, 14, 14]（池化后尺寸减半）</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># -&gt; [batch, 16, 5, 5] </span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">)</span>            <span class="token comment"># 展平为一维向量：16 * 5 * 5=400</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>             <span class="token comment"># -&gt; [batch, 120]</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>             <span class="token comment"># -&gt; [batch, 84]</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                     <span class="token comment"># -&gt; [batch, 10]（未应用softmax，配合CrossEntropyLoss使用）</span>
        <span class="token keyword">return</span> x
</code></pre>
    <p>
     这个特殊的网络接受一个输入图像，通过两组卷积和池化层，然后是三个完全连接的层。根据数据集的复杂性和大小调整网络的架构和超参数。
    </p>
    <p>
     <strong>
      模型定义
     </strong>
     ：
    </p>
    <ul>
     <li>
      <code>
       SimpleCNN
      </code>
      继承自
      <code>
       nn.Module
      </code>
     </li>
     <li>
      使用两个卷积层提取特征，三个全连接层进行分类
     </li>
     <li>
      最终输出未应用 softmax，而是直接输出 logits（与
      <code>
       CrossEntropyLoss
      </code>
      配合使用）
     </li>
    </ul>
    <h4>
     <a id="_66">
     </a>
     训练网络
    </h4>
    <p>
     对于训练，你需要一个数据集。PyTorch通过torchvision包提供了用于数据加载和预处理的实用程序。
    </p>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token comment"># 初始化模型、损失函数和优化器</span>
net <span class="token operator">=</span> SimpleCNN<span class="token punctuation">(</span><span class="token punctuation">)</span>               <span class="token comment"># 实例化模型</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 使用交叉熵损失函数（自动处理softmax）</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                            lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span>      <span class="token comment"># 学习率</span>
                            momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>   <span class="token comment"># 动量参数</span>

<span class="token comment"># 数据预处理和加载</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          
    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  

<span class="token comment"># 加载CIFAR-10训练集</span>
trainset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>
    root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># 自动下载数据集</span>
    transform<span class="token operator">=</span>transform
<span class="token punctuation">)</span>

trainloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> 
                     batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>   <span class="token comment"># 每个batch包含4张图像</span>
                     shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 打乱数据顺序</span>
</code></pre>
    <p>
     <strong>
      模型配置
     </strong>
     ：
    </p>
    <ul>
     <li>
      <strong>
       损失函数
      </strong>
      ：
      <code>
       CrossEntropyLoss
      </code>
      （自动包含 softmax 和 log_softmax）
     </li>
     <li>
      <strong>
       优化器
      </strong>
      ：SGD with momentum，学习率 0.001
     </li>
    </ul>
    <p>
     <strong>
      数据加载
     </strong>
     ：
    </p>
    <ul>
     <li>
      <p>
       使用
       <code>
        torchvision.datasets.CIFAR10
       </code>
       加载数据集
      </p>
     </li>
     <li>
      <p>
       <strong>
        batch_size
       </strong>
       ：4（根据 GPU 内存调整，CIFAR-10 建议 batch size ≥ 32）
      </p>
     </li>
     <li>
      <p>
       <code>
        transforms.Compose
       </code>
       定义数据预处理流程：
      </p>
      <ul>
       <li>
        <code>
         ToTensor()
        </code>
        ：将图像转换为 PyTorch Tensor
       </li>
       <li>
        <code>
         Normalize()
        </code>
        ：标准化图像像素值到 [-1, 1]
       </li>
      </ul>
     </li>
    </ul>
    <p>
     加载数据后，训练过程包括通过数据集进行多次迭代，使用反向传播和合适的损失函数：
    </p>
    <pre><code class="prism language-python"><span class="token comment"># 训练循环</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 进行2个epoch的训练</span>
    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>trainloader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data
        
        <span class="token comment"># 前向传播</span>
        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        
        <span class="token comment"># 反向传播和优化</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># 清空梯度</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>         <span class="token comment"># 计算梯度</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment"># 更新参数</span>
        
        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment"># 每2000个batch打印一次</span>
        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">1999</span><span class="token punctuation">:</span>
            avg_loss <span class="token operator">=</span> running_loss <span class="token operator">/</span> <span class="token number">2000</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch [</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token number">2</span><span class="token punctuation">}</span></span><span class="token string">], Batch [</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/2000], Loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>avg_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
            running_loss <span class="token operator">=</span> <span class="token number">0.0</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练完成！"</span><span class="token punctuation">)</span>
</code></pre>
    <p>
     <strong>
      训练循环
     </strong>
     ：
    </p>
    <ul>
     <li>
      <strong>
       epoch
      </strong>
      ：完整遍历数据集一次
     </li>
     <li>
      <strong>
       batch
      </strong>
      ：数据加载器中的一个批次
     </li>
     <li>
      <strong>
       梯度清零
      </strong>
      ：每次反向传播前需要清空梯度
     </li>
     <li>
      <strong>
       损失计算
      </strong>
      ：
      <code>
       outputs
      </code>
      的形状为
      <code>
       [batch_size, 10]
      </code>
      ，
      <code>
       labels
      </code>
      为整数标签
     </li>
    </ul>
    <h3>
     <a id="_149">
     </a>
     完整代码
    </h3>
    <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token comment"># 定义CNN模型（修复了变量引用问题）</span>
<span class="token keyword">class</span> <span class="token class-name">SimpleCNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SimpleCNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>      <span class="token comment"># 第一个卷积层：3输入通道，6输出通道，5x5卷积核</span>
        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment"># 最大池化层：2x2窗口，步长2</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>     <span class="token comment"># 第二个卷积层：6输入通道，16输出通道，5x5卷积核</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span><span class="token comment"># 全连接层1：400输入 -&gt; 120输出</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>      <span class="token comment"># 全连接层2：120输入 -&gt; 84输出</span>
        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>       <span class="token comment"># 输出层：84输入 -&gt; 10类 logits</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 输入形状：[batch_size, 3, 32, 32]</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># -&gt; [batch, 6, 14, 14]（池化后尺寸减半）</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># -&gt; [batch, 16, 5, 5] </span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">)</span>            <span class="token comment"># 展平为一维向量：16 * 5 * 5=400</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>             <span class="token comment"># -&gt; [batch, 120]</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>             <span class="token comment"># -&gt; [batch, 84]</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                     <span class="token comment"># -&gt; [batch, 10]（未应用softmax，配合CrossEntropyLoss使用）</span>
        <span class="token keyword">return</span> x

<span class="token comment"># 初始化模型、损失函数和优化器</span>
net <span class="token operator">=</span> SimpleCNN<span class="token punctuation">(</span><span class="token punctuation">)</span>               <span class="token comment"># 实例化模型</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 使用交叉熵损失函数（自动处理softmax）</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                            lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span>      <span class="token comment"># 学习率</span>
                            momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>   <span class="token comment"># 动量参数</span>

<span class="token comment"># 数据预处理和加载</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            
    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 加载CIFAR-10训练集</span>
trainset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>
    root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># 自动下载数据集</span>
    transform<span class="token operator">=</span>transform
<span class="token punctuation">)</span>
trainloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> 
                         batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>   <span class="token comment"># 每个batch包含4张图像</span>
                         shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 打乱数据顺序</span>

<span class="token comment"># 训练循环</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 进行2个epoch的训练</span>
    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>trainloader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data
        
        <span class="token comment"># 前向传播</span>
        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        
        <span class="token comment"># 反向传播和优化</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment"># 清空梯度</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>         <span class="token comment"># 计算梯度</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment"># 更新参数</span>
        
        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment"># 每2000个batch打印一次</span>
        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">1999</span><span class="token punctuation">:</span>
            avg_loss <span class="token operator">=</span> running_loss <span class="token operator">/</span> <span class="token number">2000</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch [</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token number">2</span><span class="token punctuation">}</span></span><span class="token string">], Batch [</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/2000], Loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>avg_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
            running_loss <span class="token operator">=</span> <span class="token number">0.0</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练完成！"</span><span class="token punctuation">)</span>
</code></pre>
    <h3>
     <a id="_231">
     </a>
     最后总结
    </h3>
    <p>
     通过PyTorch和卷积神经网络，你可以有效地处理图像分类任务。借助PyTorch的灵活性，可以根据特定的数据集和应用程序构建、训练和微调模型。示例代码仅为理论过程，实际项目中还有大量优化空间。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f6e65776561737473756e2f:61727469636c652f64657461696c732f313436323135343039" class_="artid" style="display:none">
 </p>
</div>


