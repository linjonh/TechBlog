---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f6c69616e7a68616e67383631:2f61727469636c652f64657461696c732f3832303134343630"
layout: post
title: "javacv实现上传视频后自动保存封面缩略图视频第一帧"
date: 2018-08-24 11:30:36 +08:00
description: "首先，使用场景：现在视频网站展示列表都是用img标签展示的，动图用的是gif，但是我们上传视频时并没"
keywords: "java vue 视频上传 封面"
categories: ['后端问题']
tags: ['Java', 'Java', 'Java']
artid: "82014460"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=82014460
    alt: "javacv实现上传视频后自动保存封面缩略图视频第一帧"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=82014460
featuredImagePreview: https://bing.ee123.net/img/rand?artid=82014460
---

# javacv实现上传视频后自动保存封面缩略图（视频第一帧）

首先，使用场景：

现在视频网站展示列表都是用img标签展示的，动图用的是gif，但是我们上传视频时并没有视屏封面，就这需要上传到服务器时自动成功封面并保存

JavaCV 是一款开源的视觉处理库，基于GPLv2协议，对各种常用计算机视觉库封装后的一组jar包，封装了OpenCV、libdc1394、OpenKinect、videoInput和ARToolKitPlus等计算机视觉编程人员常用库的接口。

此方法的好处是不需要再服务器上安装插件，直接代码中就可以实现视频截取。

我们需要截取视频第一帧，主要用到了ffmpeg和opencv。

我用到的maven的目前最新javacv版本，1.4.2，它应该支持jdk1.7及以上，我项目用的还是jdk1.7.

#### 1.引入maven依赖

#### 坑：

```
<dependency>
      <groupId>org.bytedeco</groupId>
      <artifactId>javacv-platform</artifactId>
      <version>1.4.2</version>
</dependency>
```

网上有说用0.8版本的，但用maven打包编译时总是报错，所以索性用最高版本

本来maven直接引用这段会自动下载依赖包，但是全部下载下载我看有500多兆，因为它包括了android,linux，macosx等。一个截取封面功能要给项目增加五百多兆内存这是不能容忍的。

我的服务器是windows 64系统的，所以我只需要windows-x86\_64需要的jar包

所以我精简了一下pom依赖

```
<!-- https://mvnrepository.com/artifact/org.bytedeco/javacv -->
<dependency>
    <groupId>org.bytedeco</groupId>
    <artifactId>javacv</artifactId>
    <version>1.4.2</version>
    <exclusions>
        <exclusion>
            <groupId>org.bytedeco.javacpp-presets</groupId>
            <artifactId>*</artifactId>
        </exclusion>
    </exclusions>
</dependency>
<dependency>
    <groupId>org.bytedeco.javacpp-presets</groupId>
    <artifactId>opencv</artifactId>
    <version>3.4.2-1.4.2</version>
</dependency>
<dependency>
    <groupId>org.bytedeco.javacpp-presets</groupId>
    <artifactId>opencv</artifactId>
    <version>3.4.2-1.4.2</version>
    <classifier>windows-x86_64</classifier>
</dependency>
<!-- https://mvnrepository.com/artifact/org.bytedeco.javacpp-presets/ffmpeg -->
<dependency>
    <groupId>org.bytedeco.javacpp-presets</groupId>
    <artifactId>ffmpeg</artifactId>
    <version>4.0.1-1.4.2</version>
</dependency>
<dependency>
    <groupId>org.bytedeco.javacpp-presets</groupId>
    <artifactId>ffmpeg</artifactId>
    <version>4.0.1-1.4.2</version>
    <classifier>windows-x86_64</classifier>
</dependency>
```

这样我只用了ffmpeg和opencv，占用内存成功缩小到几十兆。

其他平台需要用可以在classifier里面修改成对应的

```
<javacpp.platform.android-arm>android-arm</javacpp.platform.android-arm>
    <javacpp.platform.android-arm64>android-arm64</javacpp.platform.android-arm64>
    <javacpp.platform.android-x86>android-x86</javacpp.platform.android-x86>
    <javacpp.platform.android-x86_64>android-x86_64</javacpp.platform.android-x86_64>
    <javacpp.platform.ios-arm>ios-arm</javacpp.platform.ios-arm>
    <javacpp.platform.ios-arm64>ios-arm64</javacpp.platform.ios-arm64>
    <javacpp.platform.ios-x86>ios-x86</javacpp.platform.ios-x86>
    <javacpp.platform.ios-x86_64>ios-x86_64</javacpp.platform.ios-x86_64>
    <javacpp.platform.linux-armhf>linux-armhf</javacpp.platform.linux-armhf>
    <javacpp.platform.linux-arm64>linux-arm64</javacpp.platform.linux-arm64>
    <javacpp.platform.linux-ppc64le>linux-ppc64le</javacpp.platform.linux-ppc64le>
    <javacpp.platform.linux-x86>linux-x86</javacpp.platform.linux-x86>
    <javacpp.platform.linux-x86_64>linux-x86_64</javacpp.platform.linux-x86_64>
    <javacpp.platform.macosx-x86_64>macosx-x86_64</javacpp.platform.macosx-x86_64>
    <javacpp.platform.windows-x86>windows-x86</javacpp.platform.windows-x86>
    <javacpp.platform.windows-x86_64>windows-x86_64</javacpp.platform.windows-x86_64>
```

至此引入jar结束。

#### 2.java代码实现

引入jar包

```
import org.bytedeco.javacv.FFmpegFrameGrabber;
import org.bytedeco.javacv.Frame;
import org.bytedeco.javacv.Java2DFrameConverter;
import javax.imageio.ImageIO;
import javax.servlet.http.HttpServletRequest;
import java.awt.*;
import java.awt.image.BufferedImage;
import java.io.File;
import java.io.IOException;
```

保存视频的方法

```
@RequestMapping(value = "uploadVideoFiles", method = RequestMethod.POST, produces = "application/json;charset=utf-8")
@ResponseBody
public String uploadVideoFiles(
        @RequestParam(value = "file") MultipartFile[] files,  //这样接收文件
        String classId,
        HttpServletRequest request
) {
    try {
        Map<String,Object> params=new HashMap<String, Object>();
        //视频路径
        String path="/resource/videos/";
        //缩略图
        String framefile="/resource/frames/";
        //根路径
        String basePath=request.getSession().getServletContext().getRealPath("/");
        int userId=((TSystemUser)request.getSession().getAttribute("USER")).getUserId();
        params.put("classId",classId);
        params.put("attachmentType","VIDEO");
        params.put("userId",userId);
        for (MultipartFile file : files) {    //循环保存文件
            Map<String,String> name=uploadFile(path,file, request);
            params.put("attachmentUrl",path+name.get("saveName"));
            params.put("attachmentName",name.get("fileName"));
            String thumbpath=framefile+name.get("saveName").substring(0,name.get("saveName").length()-4)+".jpg";
            params.put("attachmentThumbnail",thumbpath);
            //调用保存缩略图方法
            this.fetchFrame(basePath+path+name.get("saveName"),basePath+thumbpath);
            //保存入库
            attachmentService.saveFile(params);
            // attachmentService.saveImg(path);
        }
        // 返回前台
        return JSON.toJSONString("success");

    } catch (Exception e) {
        e.printStackTrace();
        return JSON.toJSONString("fail");
    }

}


public Map<String,String> uploadFile(String path,MultipartFile file, HttpServletRequest request) throws IOException {
    Map<String,String> result=new HashMap<String,String>();
    //文件原名
    String fileName = file.getOriginalFilename();
    String basePath=request.getSession().getServletContext().getRealPath("/");
    path=basePath+path;            //设置文件保存路径
    //File tempFile = new File(path, new Date().getTime() + String.valueOf(fileName));
    //文件类型
    String fileType = fileName.substring(fileName.lastIndexOf(".") + 1, fileName.length()).toLowerCase();
    //保存的文件名
    String saveName=String.valueOf((new Date()).getTime()).substring(8)+(int)((Math.random()*999+1))+'.'+fileType;

    File tempFile = new File(path, String.valueOf(saveName));
    if (!tempFile.getParentFile().exists()) {    //创建文件夹
        tempFile.getParentFile().mkdir();
    }
    if (!tempFile.exists()) {
        tempFile.createNewFile();
    }
    file.transferTo(tempFile);
    result.put("fileName",fileName);
    result.put("saveName",saveName);
    return result;
}
```

截取缩略图的方法

```
//参数：视频路径和缩略图保存路径
public static void fetchFrame(String videofile, String framefile)
        throws Exception {
    long start = System.currentTimeMillis();
    File targetFile = new File(framefile);
    FFmpegFrameGrabber ff = new FFmpegFrameGrabber(videofile);
    ff.start();
    int length = ff.getLengthInFrames();
    int i = 0;
    Frame f = null;
    while (i < length) {
        // 去掉前5帧，避免出现全黑的图片，依自己情况而定
        f = ff.grabImage();
        if ((i > 5) && (f.image != null)) {
            break;
        }
        i++;
    }
    ImageIO.write(FrameToBufferedImage(f), "jpg", targetFile);
    //ff.flush();
    ff.stop();
    System.out.println(System.currentTimeMillis() - start);
}

public static BufferedImage FrameToBufferedImage(Frame frame) {
    //创建BufferedImage对象
    Java2DFrameConverter converter = new Java2DFrameConverter();
    BufferedImage bufferedImage = converter.getBufferedImage(frame);
    return bufferedImage;
}
```

![](https://i-blog.csdnimg.cn/blog_migrate/6c57e3cc368edaebbca09781e3bd70ea.png)

至此，一个视频文件上传后成功生成视频的缩略图

还有很多其他问题，日后再来总结