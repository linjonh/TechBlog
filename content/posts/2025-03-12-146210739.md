---
arturl_encode: "68747470733a2f2f626c6f:672e6373646e2e6e65742f323430315f38343837333731352f:61727469636c652f64657461696c732f313436323130373339"
layout: post
title: "人工智能实现神经网络实例"
date: 2025-03-12 17:46:01 +08:00
description: "定义超参数定义数据预处理函数并加载数据"
keywords: "[人工智能]实现神经网络实例"
categories: ['未分类']
tags: ['神经网络', '深度学习', '人工智能']
artid: "146210739"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146210739
    alt: "人工智能实现神经网络实例"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146210739
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146210739
cover: https://bing.ee123.net/img/rand?artid=146210739
image: https://bing.ee123.net/img/rand?artid=146210739
img: https://bing.ee123.net/img/rand?artid=146210739
---

# [人工智能]实现神经网络实例

![](https://i-blog.csdnimg.cn/direct/5ca93d2f4e664eb58b0dd46fc3038d9c.png)

![](https://i-blog.csdnimg.cn/direct/bd6794cf8109475f9707b08b0beea7f4.png)

1. import numpy as np：导入 NumPy 库，用于数值计算。
2. 导入 PyTorch 相关库：
   * import torch：导入 PyTorch 库，深度学习框架核心库。
   * from torchvision.datasets import mnist：从torchvision.datasets中导入 MNIST 数据集类，用于下载和加载 MNIST 数据。
   * import torchvision：导入torchvision库，提供了计算机视觉相关的数据集、模型和转换函数等。
   * import torchvision.transforms as transforms：导入数据转换模块，用于对数据进行预处理。
   * from torch.utils.data import DataLoader：导入数据加载器类，方便按批次加载数据。
   * import torch.nn.functional as F：导入 PyTorch 的函数式接口，包含常用的激活函数、损失函数等。
   * import torch.optim as optim：导入优化器模块，用于训练模型时更新参数。
   * import torch.nn as nn：导入神经网络模块，用于构建神经网络模型。
   * from torch.utils.tensorboard import SummaryWriter：导入SummaryWriter类，用于记录训练过程中的数据，方便在 TensorBoard 中可视化。

**定义超参数**

1. train\_batch\_size = 64：定义训练数据的批次大小为 64，即每次训练使用 64 个样本。
2. test\_batch\_size = 128：定义测试数据的批次大小为 128。
3. learning\_rate = 0.01：设置学习率为 0.01，控制模型参数更新的步长。
4. num\_epochs = 20：定义训练的轮数为 20，即整个训练数据集将被遍历 20 次。

**定义数据预处理函数并加载数据**

1. **定义预处理函数**
   ：
   * transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]) 使用transforms.Compose组合多个数据转换操作。transforms.ToTensor()将数据转换为 PyTorch 的张量格式，transforms.Normalize([0.5], [0.5])对数据进行归一化处理，使数据的均值为 0，标准差为 0.5。
2. **下载并加载数据**
   ：
   * train\_dataset = mnist.MNIST('../data/', train=True, transform=transform, download=True) 下载并加载训练数据集，数据存储在../data/目录下，设置train=True表示加载训练集，应用定义的预处理函数transform，如果数据不存在则自动下载。
   * test\_dataset = mnist.MNIST('../data/', train=False, transform=transform) 加载测试数据集，train=False表示加载测试集，同样应用预处理函数。
3. **创建数据加载器**
   ：
   * train\_loader = DataLoader(train\_dataset, batch\_size=train\_batch\_size, shuffle=True) 创建训练数据加载器，按照定义的训练批次大小train\_batch\_size加载数据，shuffle=True表示在每个 epoch 开始时打乱数据顺序。
   * test\_loader = DataLoader(test\_dataset, batch\_size=test\_batch\_size, shuffle=False) 创建测试数据加载器，按照测试批次大小test\_batch\_size加载数据，测试数据一般不需要打乱顺序，所以shuffle=False。

![](https://i-blog.csdnimg.cn/direct/341f10706d9145c4b75f85d1642d606a.png)

1. examples = enumerate(test\_loader)：使用enumerate函数对测试数据加载器test\_loader进行包装，使其在迭代时可以同时返回索引和数据。
2. batch\_idx, (example\_data, example\_targets) = next(examples)：通过next函数从examples中获取第一个批次的数据，batch\_idx是批次索引，example\_data是该批次的图像数据，example\_targets是对应的真实标签。
3. example\_data.shape 和 Out[10]: torch.Size([128, 1, 28, 28])：查看第一个批次图像数据的形状，结果表明该批次有 128 个样本，每个样本是 1 通道、大小为 28x28 的图像。

![](https://i-blog.csdnimg.cn/direct/21ffa44632f54c02acdec70cf8507543.png)

1. **导入库并设置**
   ：
   * import matplotlib.pyplot as plt：导入matplotlib库的pyplot模块，用于绘制图像和可视化数据。
   * %matplotlib inline：这是 Jupyter Notebook 中的魔法命令，用于在 Notebook 中直接显示绘制的图像，而不是弹出新窗口。
2. **获取测试数据**
   ：
   * examples = enumerate(test\_loader)：对测试数据加载器test\_loader进行枚举，方便获取每个批次的索引和数据。
   * batch\_idx, (example\_data, example\_targets) = next(examples)：获取测试数据的第一个批次，example\_data包含图像数据，example\_targets包含对应的真实标签。
3. **绘制图像**
   ：
   * fig = plt.figure()：创建一个新的图形对象。
   * for i in range(6)：循环 6 次，用于展示 6 张手写数字图像。
   * plt.subplot(2,3,i+1)：创建一个 2 行 3 列的子图布局，并指定当前绘制的子图位置。
   * plt.tight\_layout()：自动调整子图间距，使图像布局更美观。
   * plt.imshow(example\_data[i][0], cmap='gray', interpolation='none')：显示第i个样本的图像，cmap='gray'表示以灰度模式显示图像，interpolation='none'表示不进行插值处理。
   * plt.title('Ground Truth: {}'.format(example\_targets[i]))：设置图像的标题为该样本的真实标签。
   * plt.xticks([]) 和 plt.yticks([])：隐藏图像的横纵坐标轴刻度。

![](https://i-blog.csdnimg.cn/direct/3af09300e0d94890b3d17bbfb274c755.png)

1. **定义网络类**
   ：class Net(nn.Module) 定义了一个名为Net的类，继承自nn.Module，这是 PyTorch 中所有神经网络模型的基类。
2. **\_\_init\_\_方法**
   ：
   * super(Net, self).\_\_init\_\_()：调用父类的构造函数进行初始化。
   * self.flatten = nn.Flatten()：定义一个Flatten层，用于将输入的多维图像数据展平为一维向量，方便后续全连接层处理。
   * self.layer1 = nn.Sequential(nn.Linear(in\_dim, n\_hidden\_1),nn.BatchNorm1d(n\_hidden\_1))：使用nn.Sequential将一个线性层nn.Linear和一个批归一化层nn.BatchNorm1d组合在一起，构成网络的第一层。线性层将输入维度in\_dim映射到隐藏层维度n\_hidden\_1 ，批归一化层用于加速训练并提高模型的稳定性。
   * self.layer2 = nn.Sequential(nn.Linear(n\_hidden\_1, n\_hidden\_2),nn.BatchNorm1d(n\_hidden\_2))：同理，构成网络的第二层，将维度从n\_hidden\_1映射到n\_hidden\_2。
   * self.out = nn.Linear(n\_hidden\_2, out\_dim)：定义输出层，将第二层隐藏层的输出维度映射到输出维度out\_dim，用于分类任务输出类别概率。
3. **forward方法**
   ：
   * x=self.flatten(x)：对输入x进行展平操作。
   * x = F.relu(self.layer1(x))：将展平后的数据通过第一层，并使用 ReLU 激活函数增加模型的非线性。
   * x = F.relu(self.layer2(x))：通过第二层并再次使用 ReLU 激活函数。
   * x = F.softmax(self.out(x),dim=1)：将第二层的输出通过输出层，再使用 Softmax 激活函数将输出转换为概率分布，dim=1指定按行计算，即对每个样本的各个类别输出计算概率。

![](https://i-blog.csdnimg.cn/direct/326b45583dae48bfb09d4620a699982f.png)

1. **外层循环**
   ：for epoch in range(num\_epochs) 遍历训练的轮数，num\_epochs是之前定义的超参数，即整个训练数据集将被重复训练的次数。
2. **设置训练模式和初始化训练损失**
   ：
   * model.train()：将模型设置为训练模式，此时像BatchNorm和Dropout等层会采用相应的训练行为。
   * train\_loss = 0：初始化当前轮次的训练损失为 0。
3. **动态修改学习率**
   ：
   * if epoch%5 == 0: 当训练轮数是 5 的倍数时，执行以下操作。
   * optimizer.param\_groups[0]['lr']\*=0.9 将优化器的学习率乘以 0.9，实现动态调整学习率，随着训练进行逐渐减小学习率，有助于模型更好地收敛。
   * print('学习率:{:.6f}'.format(optimizer.param\_groups[0]['lr'])) 打印当前调整后的学习率。
4. **内层循环**
   ：for img, label in train\_loader: 遍历训练数据加载器，每次获取一个批次的图像数据img和对应的标签label。
   * **数据移动到设备**
     ：img = img.to(device) 和 label = label.to(device) 将图像和标签数据移动到指定的设备（GPU 或 CPU）上。
   * **正向传播**
     ：out = model(img) 将图像数据传入模型进行前向传播，得到模型的输出out。
   * **计算损失**
     ：loss = criterion(out, label) 使用定义的损失函数criterion（交叉熵损失函数）计算模型输出和真实标签之间的损失值。
   * **反向传播和参数更新**
     ：
     + optimizer.zero\_grad() 在反向传播前将优化器中所有参数的梯度清零，避免梯度累加。
     + loss.backward() 执行反向传播，计算损失值对模型所有可学习参数的梯度。
     + optimizer.step() 根据计算得到的梯度更新模型的参数。
   * **记录损失**
     ：
     + train\_loss += loss.item() 累计当前批次的损失值到当前轮次的总损失中。
     + writer.add\_scalar('train-loss', train\_loss/len(train\_loader), epoch) 将当前轮次的平均损失记录到SummaryWriter中，train\_loss/len(train\_loader)计算平均损失，epoch为当前轮次。
   * **计算分类准确率**
     ：
     + \_, pred = out.max(1) 从模型输出out中获取每个样本预测概率最高的类别索引pred。
     + num\_correct = (pred == label).sum().item() 计算预测正确的样本数量。
     + acc = num\_correct / img.shape[0] 计算当前批次的分类准确率。

![](https://i-blog.csdnimg.cn/direct/1fd3a0cdafa54822be02673fd8fa2443.png)

1. **初始化评估指标**
   ：
   * eval\_loss = 0：初始化测试集上的损失为 0。
   * eval\_acc = 0：初始化测试集上的准确率为 0。
2. **设置模型为评估模式**
   ：model.eval() 将模型设置为评估模式，此时像BatchNorm和Dropout等层会采用与训练模式不同的行为，以确保评估结果的准确性。
3. **遍历测试数据**
   ：
   * for img, label in test\_loader: 循环遍历测试数据加载器test\_loader，每次获取一个批次的图像数据img和标签label。
   * **数据处理和移动**
     ：
     + img = img.to(device) 和 label = label.to(device) 将图像和标签数据移动到指定设备上。
     + img = img.view(img.size(0), -1) 将图像数据展平，以适应模型输入要求（这里假设模型输入需要一维向量形式）。
   * **正向传播和计算损失**
     ：
     + out = model(img) 将图像数据传入模型进行前向传播，得到模型的输出out。
     + loss = criterion(out, label) 使用交叉熵损失函数计算模型输出和真实标签之间的损失值。
   * **记录评估损失**
     ：eval\_loss += loss.item() 累计当前批次的损失值到测试集的总损失中。
   * **计算评估准确率**
     ：
     + \_, pred = out.max(1) 从模型输出out中获取每个样本预测概率最高的类别索引pred。
     + num\_correct = (pred == label).sum().item() 计算预测正确的样本数量。
     + acc = num\_correct / img.shape[0] 计算当前批次的准确率。
     + eval\_acc += acc 累计当前批次的准确率。
4. **记录评估结果**
   ：
   * eval\_losses.append(eval\_loss / len(test\_loader)) 将测试集的平均损失添加到eval\_losses列表中。
   * eval\_accs.append(eval\_acc / len(test\_loader)) 将测试集的平均准确率添加到eval\_accs列表中。

![](https://i-blog.csdnimg.cn/direct/2ca3125eb8e74e0782b0d085e0fb0399.png)

1. plt.title('train loss')：设置绘制图形的标题为 “train loss”，用于表明该图展示的是训练损失相关内容。
2. plt.plot(np.arange(len(losses)), losses)：使用plot函数绘制折线图。np.arange(len(losses))生成一个从 0 到losses列表长度减 1 的数组，作为横坐标，表示训练的轮次；losses列表存储了每一轮训练的平均损失值，作为纵坐标。这样就将训练轮次和对应的损失值进行了可视化展示。
3. plt.legend(['Train Loss'], loc='upper right')：为图形添加图例，图例内容为 “Train Loss”，并将其放置在图形的右上角（loc='upper right'），方便读者识别曲线代表的含义。