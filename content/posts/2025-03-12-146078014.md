---
arturl_encode: "68747470733a2f2f62:6c6f672e6373646e2e6e65742f67757975656c696e3132332f:61727469636c652f64657461696c732f313436303738303134"
layout: post
title: "LinuxUbuntu-server-24.02-上搭建-ollama-dify"
date: 2025-03-12 20:00:00 +08:00
description: "本文为通过ollama，docker在一台没有显卡的裸金属服务，系统为Ubuntu server24.02系统上部署的DeepSeek + dify 聊天机器人。"
keywords: "Linux：Ubuntu server 24.02 上搭建 ollama + dify"
categories: ['工作杂谈']
tags: ['运维', 'Ubuntu', 'Linux']
artid: "146078014"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146078014
    alt: "LinuxUbuntu-server-24.02-上搭建-ollama-dify"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146078014
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146078014
cover: https://bing.ee123.net/img/rand?artid=146078014
image: https://bing.ee123.net/img/rand?artid=146078014
img: https://bing.ee123.net/img/rand?artid=146078014
---

# Linux：Ubuntu server 24.02 上搭建 ollama + dify

### 一、安装Ubuntu

具体的安装过程可以参见此链接：
[链接：Ubuntu Server 20.04详细安装教程](https://www.cnblogs.com/huizhipeng/p/18089881)
，这里主要记录一下过程中遇到的问题。

1. 安装时subnet如何填写
     
   ![网络配置](https://i-blog.csdnimg.cn/direct/4d2a8f1258244f6abe4ff7184655881d.jpeg)
     
   在Ubuntu中subnet填写255.255.255.0是错误的，其格式为 xx.xx.xx.xx/yy ，需要自己转化为 YAML格式。以下来自AI的换算

> ​理解子网掩码与CIDR的转换
>   
> 子网掩码255.255.255.0对应的二进制形式为11111111.11111111.11111111.00000000，其中连续“1”的个数为24位，因此CIDR表示为/24。
>   
> ​在YAML配置中，子网掩码需与IP地址结合使用，例如192.168.1.10/24，其中/24即为255.255.255.0的CIDR形式。

2. 在安装系统后，查看到空间并没有使用完。

```bash
root@cikkodai:/# df -h
Filesystem                         Size  Used Avail Use% Mounted on
tmpfs                              3.2G  1.4M  3.2G   1% /run
efivarfs                           304K  235K   65K  79% /sys/firmware/efi/efivars
/dev/mapper/ubuntu--vg-ubuntu--lv   98G   11G   83G  12% /
tmpfs                               16G     0   16G   0% /dev/shm
tmpfs                              5.0M     0  5.0M   0% /run/lock
/dev/sda2                          2.0G   99M  1.7G   6% /boot
/dev/sda1                          1.1G  6.2M  1.1G   1% /boot/efi
tmpfs                              3.2G   12K  3.2G   1% /run/user/1000
root@cikkodai:/# fdisk -l
Disk /dev/sda: 931.51 GiB, 1000204886016 bytes, 1953525168 sectors
Disk model: TOSHIBA DT01ACA1
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
Disklabel type: gpt
Disk identifier: AFF48690-0B2E-4235-91E1-9FF035B5A186

Device       Start        End    Sectors   Size Type
/dev/sda1     2048    2203647    2201600     1G EFI System
/dev/sda2  2203648    6397951    4194304     2G Linux filesystem
/dev/sda3  6397952 1953521663 1947123712 928.5G Linux filesystem


Disk /dev/mapper/ubuntu--vg-ubuntu--lv: 100 GiB, 107374182400 bytes, 209715200 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
root@cikkodai:/# lsblk
NAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS
sda                         8:0    0 931.5G  0 disk
├─sda1                      8:1    0     1G  0 part /boot/efi
├─sda2                      8:2    0     2G  0 part /boot
└─sda3                      8:3    0 928.5G  0 part
  └─ubuntu--vg-ubuntu--lv 252:0    0   100G  0 lvm  /
sr0                        11:0    1  1024M  0 rom
root@cikkodai:/# df -lhT
Filesystem                        Type      Size  Used Avail Use% Mounted on
tmpfs                             tmpfs     3.2G  1.4M  3.2G   1% /run
efivarfs                          efivarfs  304K  235K   65K  79% /sys/firmware/efi/efivars
/dev/mapper/ubuntu--vg-ubuntu--lv ext4       98G   11G   83G  12% /
tmpfs                             tmpfs      16G     0   16G   0% /dev/shm
tmpfs                             tmpfs     5.0M     0  5.0M   0% /run/lock
/dev/sda2                         ext4      2.0G   99M  1.7G   6% /boot
/dev/sda1                         vfat      1.1G  6.2M  1.1G   1% /boot/efi
tmpfs                             tmpfs     3.2G   12K  3.2G   1% /run/user/1000
root@cikkodai:/# lsblk
NAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS
sda                         8:0    0 931.5G  0 disk
├─sda1                      8:1    0     1G  0 part /boot/efi
├─sda2                      8:2    0     2G  0 part /boot
└─sda3                      8:3    0 928.5G  0 part
  └─ubuntu--vg-ubuntu--lv 252:0    0   100G  0 lvm  /
sr0                        11:0    1  1024M  0 rom
root@cikkodai:/# vgdisplay
  --- Volume group ---
  VG Name               ubuntu-vg
  System ID
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  2
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                1
  Open LV               1
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               <928.46 GiB
  PE Size               4.00 MiB
  Total PE              237685
  Alloc PE / Size       25600 / 100.00 GiB
  Free  PE / Size       212085 / <828.46 GiB
  VG UUID               rJHPa1-vjcK-2hm4-O2DV-0VtA-gVtS-6bXJSD

root@cikkodai:/# vgdisplay -v
  --- Volume group ---
  VG Name               ubuntu-vg
  System ID
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  2
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                1
  Open LV               1
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               <928.46 GiB
  PE Size               4.00 MiB
  Total PE              237685
  Alloc PE / Size       25600 / 100.00 GiB
  Free  PE / Size       212085 / <828.46 GiB
  VG UUID               rJHPa1-vjcK-2hm4-O2DV-0VtA-gVtS-6bXJSD

  --- Logical volume ---
  LV Path                /dev/ubuntu-vg/ubuntu-lv
  LV Name                ubuntu-lv
  VG Name                ubuntu-vg
  LV UUID                CSRJ1I-rwE0-sIHl-p4HH-yzxL-GqLX-qukS9t
  LV Write Access        read/write
  LV Creation host, time ubuntu-server, 2025-03-06 10:31:39 +0000
  LV Status              available
  # open                 1
  LV Size                100.00 GiB
  Current LE             25600
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     256
  Block device           252:0

  --- Physical volumes ---
  PV Name               /dev/sda3
  PV UUID               QtprZ3-uT6s-7Pkg-Sl5g-TfNL-FoLK-fvbdBg
  PV Status             allocatable
  Total PE / Free PE    237685 / 212085

root@cikkodai:/# lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description:    Ubuntu 24.04.2 LTS
Release:        24.04
Codename:       noble
root@cikkodai:/#

```

以下磁盘的分配来至AI（
[链接：Ubuntu 24.04.2 服务器存储分配方案（针对 Ollama 和 AnythingLLM）](https://yuanbao.tencent.com/bot/app/share/chat/047059874a01deefc5428bf972b60520)
），其问法为：“以下服务器，如果分配存储，能合理 Ollama ， AnythingLLM：”

**Ubuntu 24.04.2 服务器存储分配方案（针对 Ollama 和 AnythingLLM）​**
  
根据你的磁盘信息（sda 总容量 931.5GB，当前仅分配 100GB 给根目录），建议按以下方案分配存储：

1、
**存储现状分析**

1. ​可用空间分布
     
   • ​LVM 剩余空间：卷组 ubuntu-vg 中未分配的物理扩展区（PE）约 ​828.46GB，可通过 LVM 扩展逻辑卷。
     
   • ​根目录占用：当前根目录 / 使用 12%（11GB），剩余 83GB，适合部署核心系统组件。
     
   • ​磁盘分区：sda3 已全部加入 LVM，无需额外格式化。
2. ​
   **关键限制**
     
   • ​Ollama 需求：模型文件通常较大（7B 模型约 4GB，70B 模型可达 100GB+），需预留充足空间 。
     
   • ​AnythingLLM 需求：工作区数据、文档索引和本地模型存储需独立分区 。

**2、存储分配建议 ​**

1. 扩展 LVM 逻辑卷
     
   利用 ubuntu-vg 的剩余空间创建两个专用逻辑卷：

```bash
# 创建 Ollama 模型存储卷（500GB）
sudo lvcreate -L 500G -n ollama-data ubuntu-vg

# 创建 AnythingLLM 数据存储卷（300GB）
sudo lvcreate -L 300G -n anythingllm-data ubuntu-vg

```

2. 格式化并挂载

```bash
# 格式化逻辑卷为 ext4（推荐兼容性）
sudo mkfs.ext4 /dev/ubuntu-vg/ollama-data
sudo mkfs.ext4 /dev/ubuntu-vg/anythingllm-data

# 创建挂载点
sudo mkdir /mnt/ollama_models /mnt/anythingllm_storage

# 写入 /etc/fstab 实现持久化
echo "/dev/ubuntu-vg/ollama-data /mnt/ollama_models ext4 defaults 0 2" | sudo tee -a /etc/fstab
echo "/dev/ubuntu-vg/anythingllm-data /mnt/anythingllm_storage ext4 defaults 0 2" | sudo tee -a /etc/fstab

# 立即挂载
sudo mount -a

```

**3、验证与维护**

1. 验证挂载

```bash
df -hT | grep -E 'ollama|anythingllm'
# 应显示 /mnt/ollama_models 和 /mnt/anythingllm_storage 的容量

```

### 二、 安装 ollama

检查系统版本，下载对应ollama压缩包，输出为 “amd64”，当下载
[链接：ollama-linux-amd64.tgz](https://github.com/ollama/ollama/releases)
版本。

```bash
dpkg --print-architecture

```

输出：

```bash

root@cikkodai:/mnt/ollama_models# dpkg --print-architecture
amd64

```

2. 将压缩包拷贝至服务器端并解压，解压至 /usr目录。拷贝可以通过搭建局域网服务器，远程工具，命令等。

```bash
sudo tar -C /usr -xzf ollama-linux-amd64.tgz

```

3.快速定位 ollama 可执行文件及其相关文件的存储路径

```bash
whereis ollama

```

输出：

```bash
root@cikkodai:/mnt# whereis ollama
ollama: /usr/bin/ollama /usr/lib/ollama

```

需要记住 /usr/lib/ollama 路径，此路径在配置文件中会使用。

4. 修改ollama配置文件，如果没有可以自行新建。

```bash
vim /etc/systemd/system/ollama.service

```

```bash
[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=/usr/bin/ollama serve
User=root
Group=root
Restart=always
RestartSec=3
Environment="OLLAMA_MODELS=/mnt/ollama_models"
Environment="OLLAMA_ORIGINS=*"
Environment="OLLAMA_HOST=0.0.0.0"

[Install]
WantedBy=default.target


```

5.重载配，启动ollama并设置自启和查看状态

```bash
sudo systemctl daemon-reload
sudo systemctl start ollama
sudo systemctl enable ollama
sudo systemctl status ollama


```

输出：

```bash
root@cikkodai:/etc/systemd/system# sudo systemctl status ollama
● ollama.service - Ollama Service
     Loaded: loaded (/etc/systemd/system/ollama.service; enabled; preset: enabled)
     Active: active (running) since Mon 2025-03-10 20:14:38 CST; 18s ago
   Main PID: 777696 (ollama)
      Tasks: 9 (limit: 38027)
     Memory: 9.6M (peak: 10.3M)
        CPU: 15ms
     CGroup: /system.slice/ollama.service
             └─777696 /usr/bin/ollama serve

Mar 10 20:14:38 cikkodai ollama[777696]: Couldn't find '/root/.ollama/id_ed25519'. Generating new private key.
Mar 10 20:14:38 cikkodai ollama[777696]: Your new public key is:
Mar 10 20:14:38 cikkodai ollama[777696]: ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIHTnlbSex1dGPSUm7nDxoyZAeGDFNLDgWM2AybCBN4e7
Mar 10 20:14:38 cikkodai ollama[777696]: 2025/03/10 20:14:38 routes.go:1215: INFO server config env="map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE>
Mar 10 20:14:38 cikkodai ollama[777696]: time=2025-03-10T20:14:38.679+08:00 level=INFO source=images.go:432 msg="total blobs: 0"`在这里插入代码片`
Mar 10 20:14:38 cikkodai ollama[777696]: time=2025-03-10T20:14:38.679+08:00 level=INFO source=images.go:439 msg="total unused blobs removed: 0"
Mar 10 20:14:38 cikkodai ollama[777696]: time=2025-03-10T20:14:38.679+08:00 level=INFO source=routes.go:1277 msg="Listening on 0.0.0.0:11434 (version 0.5.13)"
Mar 10 20:14:38 cikkodai ollama[777696]: time=2025-03-10T20:14:38.679+08:00 level=INFO source=gpu.go:217 msg="looking for compatible GPUs"
Mar 10 20:14:38 cikkodai ollama[777696]: time=2025-03-10T20:14:38.681+08:00 level=INFO source=gpu.go:377 msg="no compatible GPUs were discovered"
Mar 10 20:14:38 cikkodai ollama[777696]: time=2025-03-10T20:14:38.681+08:00 level=INFO source=types.go:130 msg="inference compute" id=0 library=cpu variant="">



```

6.启用大模型，主要就是查看浏览器地址

```bash
ollama serve

```

输出：

```bash
root@cikkodai:/etc/systemd/system# ollama serve
Error: listen tcp 127.0.0.1:11434: bind: address already in use

```

在浏览器输入 IP:11434，如显示 ‘‘Ollama is running’’ 表述部署成功。

### 三、DeepSeek模型安装

不用魔法上网，也能快速通过ollama下载模型（
[链接：deepseek-r1:7b](https://ollama.com/library/deepseek-r1:7b)
）。在末尾 出现Send 部分就可以开始输入信息，使用对话功能。

```bash
root@cikkodai:/etc/systemd/system# ollama run deepseek-r1:7b
pulling manifest
pulling 96c415656d37... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████▏ 4.7 GB
pulling 369ca498f347... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████▏  387 B
pulling 6e4c38e1172f... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████▏ 1.1 KB
pulling f4d24e9138dd... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████▏  148 B
pulling 40fb844194b2... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████▏  487 B
verifying sha256 digest
writing manifest
success
>>> Send a message (/? for help)


```

通过在对话框输入 /bye 或则 采用快捷键 ctrl +D 退出对话框

```bash
>>> /bye
root@cikkodai:/etc/systemd/system#


```

想要进入模型，先查看有哪些模型，然后运行对应模型即可

```bash
root@cikkodai:/etc/systemd/system# ollama list
NAME              ID              SIZE      MODIFIED
deepseek-r1:7b    0a8c26691023    4.7 GB    16 minutes ago
root@cikkodai:/etc/systemd/system# ollama run deepseek-r1:7b
>>> Send a message (/? for help)


```

这里推荐将 nomic-embed-text 向量模型（
[链接：nomic-embed-text](https://ollama.com/library/nomic-embed-text:latest)
）一起部署一下，理论值可以提供更好的知识库管理。

```bash
ollama pull nomic-embed-text:latest

```

输出：

```bash
root@cikkodai:/opt/frp# ollama pull nomic-embed-text:latest
pulling manifest
pulling 970aa74c0a90... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████▏ 274 MB
pulling c71d239df917... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████▏  11 KB
pulling ce4a164fc046... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████▏   17 B
pulling 31df23ea7daa... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████▏  420 B
verifying sha256 digest
writing manifest
success
root@cikkodai:/opt/frp#


```

查看安装了那些模型

```bash
root@cikkodai:/opt/frp# ollama ls
NAME                       ID              SIZE      MODIFIED
nomic-embed-text:latest    0a109f422b47    274 MB    15 seconds ago
deepseek-r1:7b             0a8c26691023    4.7 GB    8 hours ago
root@cikkodai:/opt/frp#


```

### 四、安装docker

安装此主要用于跑 dify，安装操作可查看此
[链接 ：Ollama + DeepSeek + Dify 打造企业级知识库的“超级大脑”](https://mp.weixin.qq.com/s/HJHMPQlXmhtZy7MsDywdhA)
。注意：1.Ubuntu在安装系统时本身提供勾选页面，是否安装docker等工具，如果之前安装了需要先卸载干净，2. docker部分下载需要魔法上网，可以用
[链接：毫秒镜像](https://1ms.run/)
作为镜像。

检查Docker服务状态

```bash
sudo systemctl status docker  # 显示服务状态，包括是否激活、运行日志等

```

查看Docker版本信息

```bash
docker --version    # 显示客户端版本
docker info         # 显示详细运行时信息（包括镜像数、容器数、存储驱动等）

```

​查看运行中的容器

```bash
docker ps        # 仅显示活动容器

```

查看所有容器（包括已停止的）​

```bash
docker ps -a     # 显示完整容器列表及状态（如Exited状态）

```

查看镜像列表

```bash
docker images    # 显示本地已下载的镜像

```

Docker 下载文件的默认存储位置及空间使用查看

Linux 系统

* 核心数据目录：/var/lib/docker，包含镜像（images）、容器（containers）、卷（volumes）、日志（logs）等数据 。
* 日志文件路径：/var/lib/docker/containers/<容器ID>/<容器ID>-json.log

已用空间 → sudo du -sh /var
  
​剩余空间 → df -h /var
  
子目录分析 → sudo du -h /var --max-depth=1 | sort -h

```bash
root@cikkodai:/etc/systemd/system# sudo du -sh /var
1.1G    /var
root@cikkodai:/etc/systemd/system# df -h /var
Filesystem                         Size  Used Avail Use% Mounted on
/dev/mapper/ubuntu--vg-ubuntu--lv   98G   15G   79G  16% /
root@cikkodai:/etc/systemd/system# sudo du -h /var --max-depth=1 | sort -h
4.0K    /var/crash
4.0K    /var/local
4.0K    /var/mail
4.0K    /var/opt
4.0K    /var/snap
16K     /var/spool
60K     /var/tmp
1.2M    /var/backups
67M     /var/log
253M    /var/cache
755M    /var/lib
1.1G    /var
root@cikkodai:/etc/systemd/system#


```

以下为安装 Portainer 图像化面板工具

1. 修改Docker镜像源

```bash
sudo tee /etc/docker/daemon.json << EOF
{
  "registry-mirrors": [
    "https://docker.1ms.run"
  ]
}
EOF

```

```bash
systemctl daemon-reload
systemctl restart docker

```

2. 手动拉取镜像

```bash
docker pull portainer/portainer:latest

```

3. 重新运行Portainer容器

```bash
docker run -d -p 9000:9000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer

```

4. 浏览器输入 IP:9000 即可进入Portainer管理界面。注意防火墙是否打开。

### 五、安装dify

具体的安装步骤可以参考官方文档

1. [链接：Docker Compose 部署](https://docs.dify.ai/zh-hans/getting-started/install-self-hosted/docker-compose)
2. [链接：接入 Ollama 部署的本地模型](https://docs.dify.ai/zh-hans/development/models-integration/ollama)

可能比较关心dify相关文件保存在什么位置，会不会把磁盘撑爆，例如：此处单独创建一个 anythingllm_storage 文件夹。不用担心，这些默认存在在dify的相对路径目录中，也可以自己重新配置，以下是配置文件中的关键存储路径。来自于AI
[链接：dify的知识默认存放在什么位置](https://yuanbao.tencent.com/bot/app/share/chat/aaa6e2ac2afdd847b4bcf17f579f2f41)
。

```bash
volumes:
  - ./volumes/app/storage:/app/api/storage  # 宿主机路径:容器内路径
  - 
# Weaviate 示例
volumes:
  - ./volumes/weaviate:/var/lib/weaviate  # 向量数据存储路径

volumes:
  - ./volumes/db/data:/var/lib/postgresql/data  # 数据库文件

volumes:
  - ./volumes/redis/data:/data  # 缓存数据

```

注意：dify添加ollama模型完成后，刷新页面才会显示。 进一步配置模型时，deepseek模型添加时选择LLM，nomic-embed-text模型添加时选择TxT embedding。

在模型设置完成后，就可以创建知识，创建机器人了，具体操作可见此（
[链接：最新AI落地指南，Dify+DeepSeek搭建本地知识库实现智能客服，直接嵌入官网太香了，降本利器，老板狂赞](https://mp.weixin.qq.com/s?__biz=MzkxNTg1MDk4MQ==&mid=2247485057&idx=1&sn=2b72ec5b7a897f8b894751740fdcd777&chksm=c0580fe0d0ccffa5eb236117ae00b26a0886ddef5266c20d8ca865bb19c4a44c2ad2115df86d#rd)
）

本次遇到一个问题，在创建LLM大模型时，一直不能保存成功，虽然最后莫名其妙就又能保存了。但记录一下了解到的新知识，在docker容器中存在不能直接访问到宿主机网络，特别是宿主机为裸金属，可验证可达性。来至AI（
[链接：dify创建ollama 模型时，保存不生效。其模型明确为正确名称，ollama地址可通过其他设备浏览器访问](https://yuanbao.tencent.com/bot/app/share/chat/585f4cf3747bb1f0e9a0d9d066bb639a)
）。

1. 验证 Ollama 服务可达性，若输出包含 0.0.0.0:11434 则正常；若为 127.0.0.1:11434，需设置环境变量：

```bash
root@cikkodai:/mnt/anythingllm_storage/dify/docker# netstat -tuln | grep :11434
tcp        0      0 0.0.0.0:11434           0.0.0.0:*               LISTEN

```

2. 进入目标容器

```bash
docker exec -it docker-api-1 /bin/bash

```

3. 在 Dify 容器内执行连通性检查：

```bash
ping -c 4 host.docker.internal

```

4. 正常退出（容器停止）​输入exit 或者 ctrl+D，更多参见AI（
   [链接：Ubuntu 退出 Docker 容器的具体方法](https://yuanbao.tencent.com/bot/app/share/chat/c4336e2196ac8c163718d763d3381bb1)
   ）

```bash
exit

```

### 六、frp网络穿透Linux客户端安装

具体安装查看此（
[链接：内网穿透工具frp安装使用](https://blog.csdn.net/guyuelin123/article/details/135102852)
），这里记录以下Linux系统上部署frpc客户端。

1. 下载相应版本 frpc文件包，并解压。
2. 修改frpc.toml，注意修改为自己frps服务端相应数据

```bash
root@cikkodai:/opt/frp# cat frpc.toml
#token需要与服务端的token一致---无需改动
auth.method = "xxx"
auth.token = "xxx"
#服务端的公网ip---不用改动
serverAddr = "xx.xx.xx.xx"
serverPort = 8001

#http端口配置
[[proxies]]
#名称 需要唯一
name = "ai-xx-tcp"
#类型tcp
type = "tcp"
#本地服务http：ip和端口。此处修改为本地对应的ip和端口
localIP = "127.0.0.1"
localPort = 80
#比如此处是8100，那外网访问服务端公网ip:8003则会被转发访问本配置10.131.19.2:8080端口
remotePort = 8412
root@cikkodai:/opt/frp#


```

修改后验证配置是否正确

```bash
root@cikkodai:/opt/frp# ./frpc verify -c  ./frpc.toml
frpc: the configuration file ./frpc.toml syntax is ok
root@cikkodai:/opt/frp# 

```

如果未能执行成功，提示权限不足，则先修改权限

```bash
root@cikkodai:/opt/frp# ./frpc verify -c  ./frpc.toml
-bash: ./frpc: Permission denied
root@cikkodai:/opt/frp# chmod +x frpc
root@cikkodai:/opt/frp# 

```

3. 在/etc/systemd/system/创建配置frpc.service配置文件

```bash
sudo nano /etc/systemd/system/frpc.service

```

创建成功后，写入以下内容，注意修改为自己的路径

```bash
[Unit]
Description=Frp Server Service
After=network.target

[Service]
Type=simple
Restart=on-failure
RestartSec=5s
ExecStart=/opt/frp/frpc -c /opt/frp/frpc.toml
User=root
WorkingDirectory=/opt/frp

[Install]
WantedBy=multi-user.target


```

4. 设置权限并启用服务

```bash
sudo chmod 644 /etc/systemd/system/frpc.service
sudo systemctl daemon-reload        # 重载服务配置
sudo systemctl enable frpc          # 开机自启
sudo systemctl start frpc           # 立即启动

```

```bash
root@cikkodai:/opt/frp# sudo systemctl daemon-reload
root@cikkodai:/opt/frp# sudo systemctl enable frpc
Created symlink /etc/systemd/system/multi-user.target.wants/frpc.service → /etc/systemd/system/frpc.service.
root@cikkodai:/opt/frp# sudo systemctl start frpc
root@cikkodai:/opt/frp# sudo systemctl status frpc
● frpc.service - Frp Server Service
     Loaded: loaded (/etc/systemd/system/frpc.service; enabled; preset: enabled)
     Active: active (running) since Tue 2025-03-11 17:35:35 CST; 9s ago
   Main PID: 1573710 (frpc)
      Tasks: 6 (limit: 38027)
     Memory: 2.2M (peak: 2.6M)
        CPU: 4ms
     CGroup: /system.slice/frpc.service
             └─1573710 /opt/frp/frpc -c /opt/frp/frpc.toml

Mar 11 17:35:35 cikkodai systemd[1]: Started frpc.service - Frp Server Service.
Mar 11 17:35:35 cikkodai frpc[1573710]: 2025-03-11 17:35:35.099 [I] [sub/root.go:142] start frpc service for config file [/opt/frp/frpc.toml]
Mar 11 17:35:35 cikkodai frpc[1573710]: 2025-03-11 17:35:35.099 [I] [client/service.go:294] try to connect to server...
Mar 11 17:35:35 cikkodai frpc[1573710]: 2025-03-11 17:35:35.145 [I] [client/service.go:286] [31bb2ffcbaac1489] login to server success, get run id [31bb2ffcba>
Mar 11 17:35:35 cikkodai frpc[1573710]: 2025-03-11 17:35:35.145 [I] [proxy/proxy_manager.go:173] [31bb2ffcbaac1489] proxy added: [ai-cikkod-tcp]
Mar 11 17:35:35 cikkodai frpc[1573710]: 2025-03-11 17:35:35.160 [I] [client/control.go:168] [31bb2ffcbaac1489] [ai-cikkod-tcp] start proxy success

root@cikkodai:/opt/frp# 

```