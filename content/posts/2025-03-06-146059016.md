---
layout: post
title: "win11编译llama_cpp_python-cuda128-RTX304050版本"
date: 2025-03-06 10:15:49 +0800
description: "win11编译llama_cpp cuda128 RTX30/40/50版本"
keywords: "win11编译llama_cpp_python cuda128 RTX30/40/50版本"
categories: ['未分类']
tags: ['Windows', 'Python', 'Llama', 'Cuda']
artid: "146059016"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146059016
    alt: "win11编译llama_cpp_python-cuda128-RTX304050版本"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146059016
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146059016
cover: https://bing.ee123.net/img/rand?artid=146059016
image: https://bing.ee123.net/img/rand?artid=146059016
img: https://bing.ee123.net/img/rand?artid=146059016
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     win11编译llama_cpp_python cuda128 RTX30/40/50版本
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     Geforce 50xx系显卡最低支持cuda128，llama_cpp_python官方源只有cpu版本，没有cuda版本，所以自己基于0.3.5版本源码编译一个RTX 30xx/40xx/50xx版本。
    </p>
    <h2>
     1. 前置条件
    </h2>
    <p>
     1. 访问
     <a href="https://developer.download.nvidia.cn/compute/cuda/12.8.0/local_installers/cuda_12.8.0_571.96_windows.exe" rel="nofollow" title="https://developer.download.nvidia.cn/compute/cuda/12.8.0/local_installers/cuda_12.8.0_571.96_windows.exe">
      https://developer.download.nvidia.cn/compute/cuda/12.8.0/local_installers/cuda_12.8.0_571.96_windows.exe
     </a>
     安装cuda12.8 toolkit， 安装完成后在命令行输入“nvcc -V”确认如下信息：
    </p>
    <pre><code class="language-bash">Cuda compilation tools, release 12.8, V12.8.61</code></pre>
    <p>
     2. 使用visual studio installer 安装visual studio 2022，工作负荷选择【使用c++的桌面开发】,安装完成后将“
     <em>
      VC\Tools\MSVC\&lt;版本号&gt;\bin\Hostx64\x64
     </em>
     ”对1应的路径加入
     <a href="https://so.csdn.net/so/search?q=%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F&amp;spm=1001.2101.3001.7020" title="环境变量">
      环境变量
     </a>
     ；
     <img alt="" src="https://i-blog.csdnimg.cn/direct/00c732764e75440ab9bd738870c92e10.png"/>
    </p>
    <p>
     3. 访问
     <a href="https://github.com/abetlen/llama-cpp-python/archive/refs/tags/v0.3.5-metal.tar.gz" title="https://github.com/abetlen/llama-cpp-python/archive/refs/tags/v0.3.5-metal.tar.gz">
      https://github.com/abetlen/llama-cpp-python/archive/refs/tags/v0.3.5-metal.tar.gz
     </a>
     下载源码（
     <a class="link-info" href="http://​https://raw.gitcode.com/gh_mirrors/ll/llama-cpp-python/archive/refs/heads/main.zip​" rel="nofollow" title="国内镜像">
      国内镜像
     </a>
     ），下载后解压； 访问
     <a href="https://github.com/ggml-org/llama.cpp/archive/refs/tags/b4831.tar.gz" title="https://github.com/ggml-org/llama.cpp/archive/refs/tags/b4831.tar.gz">
      https://github.com/ggml-org/llama.cpp/archive/refs/tags/b4831.tar.gz
     </a>
     下载源码（
     <a class="link-info" href="https://raw.gitcode.com/gh_mirrors/ll/llama.cpp/archive/refs/heads/master.zip" rel="nofollow" title="国内镜像">
      国内镜像
     </a>
     ），下载后解压到 “
     <em>
      llama_cpp_python\vendor\llama.cpp”
     </em>
     ；
    </p>
    <p>
     4. 访问
     <a href="https://github.com/conda-forge/miniforge/releases/download/24.11.3-0/Miniforge3-Windows-x86_64.exe" title="https://github.com/conda-forge/miniforge/releases/download/24.11.3-0/Miniforge3-Windows-x86_64.exe">
      https://github.com/conda-forge/miniforge/releases/download/24.11.3-0/Miniforge3-Windows-x86_64.exe
     </a>
     安装miniforge；
    </p>
    <p>
    </p>
    <h2>
     2. 编译
    </h2>
    <div>
     <pre><code class="language-bash">conda create llama_build
conda activate llama_build
conda install ccahce
pip install build wheel

set CMAKE_ARGS=-DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES=86;89;120

cd C:\llama_cpp_python
python -m build --wheel</code></pre>
    </div>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f613436323533333538372f:61727469636c652f64657461696c732f313436303539303136" class_="artid" style="display:none">
 </p>
</div>


