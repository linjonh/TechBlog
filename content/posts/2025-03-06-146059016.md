---
layout: post
title: "win11编译llama_cpp_python-cuda128-RTX304050版本"
date: 2025-03-06 10:15:49 +0800
description: "win11编译llama_cpp cuda128 RTX30/40/50版本"
keywords: "win11编译llama_cpp_python cuda128 RTX30/40/50版本"
categories: ['未分类']
tags: ['Windows', 'Python', 'Llama', 'Cuda']
artid: "146059016"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146059016
    alt: "win11编译llama_cpp_python-cuda128-RTX304050版本"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146059016
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146059016
cover: https://bing.ee123.net/img/rand?artid=146059016
image: https://bing.ee123.net/img/rand?artid=146059016
img: https://bing.ee123.net/img/rand?artid=146059016
---

# win11编译llama_cpp_python cuda128 RTX30/40/50版本

Geforce
50xx系显卡最低支持cuda128，llama_cpp_python官方源只有cpu版本，没有cuda版本，所以自己基于0.3.5版本源码编译一个RTX
30xx/40xx/50xx版本。

## 1\. 前置条件

1\.
访问<https://developer.download.nvidia.cn/compute/cuda/12.8.0/local_installers/cuda_12.8.0_571.96_windows.exe>安装cuda12.8
toolkit， 安装完成后在命令行输入“nvcc -V”确认如下信息：

    
    
    Cuda compilation tools, release 12.8, V12.8.61

2\. 使用visual studio installer 安装visual studio 2022，工作负荷选择【使用c++的桌面开发】,安装完成后将“
_VC\Tools\MSVC\
<版本号>\bin\Hostx64\x64_”对1应的路径加入[环境变量](https://so.csdn.net/so/search?q=%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F&spm=1001.2101.3001.7020
"环境变量")；![](https://i-blog.csdnimg.cn/direct/00c732764e75440ab9bd738870c92e10.png)

3\. 访问<https://github.com/abetlen/llama-cpp-
python/archive/refs/tags/v0.3.5-metal.tar.gz>下载源码（[国内镜像](http://​https://raw.gitcode.com/gh_mirrors/ll/llama-
cpp-python/archive/refs/heads/main.zip​ "国内镜像")），下载后解压； 访问
<https://github.com/ggml-
org/llama.cpp/archive/refs/tags/b4831.tar.gz>下载源码（[国内镜像](https://raw.gitcode.com/gh_mirrors/ll/llama.cpp/archive/refs/heads/master.zip
"国内镜像")），下载后解压到 “ _llama_cpp_python\vendor\llama.cpp”_ ；

4\. 访问<https://github.com/conda-
forge/miniforge/releases/download/24.11.3-0/Miniforge3-Windows-x86_64.exe>安装miniforge；

## 2\. 编译

    
    
    conda create llama_build
    conda activate llama_build
    conda install ccahce
    pip install build wheel
    
    set CMAKE_ARGS=-DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES=86;89;120
    
    cd C:\llama_cpp_python
    python -m build --wheel



