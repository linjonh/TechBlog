---
layout: post
title: "DeepSeek-linux服务器CentOS部署命令笔记"
date: 2025-03-14 15:50:43 +0800
description: "Linux（CentOS）+FinalShell+Ollama+远程访问，本地部署deepseek自备CentOS服务器，并且已经使用FinalShell连接到服务器。"
keywords: "DeepSeek linux服务器（CentOS）部署命令笔记"
categories: ['Llm', 'Linux']
tags: ['本地部署', 'Linux', 'Deepseek', 'Centos']
artid: "146258626"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146258626
    alt: "DeepSeek-linux服务器CentOS部署命令笔记"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146258626
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146258626
cover: https://bing.ee123.net/img/rand?artid=146258626
image: https://bing.ee123.net/img/rand?artid=146258626
img: https://bing.ee123.net/img/rand?artid=146258626
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     DeepSeek linux服务器（CentOS）部署命令笔记
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     Linux（CentOS）+FinalShell+Ollama+远程访问，本地部署deepseek
    </p>
    <p>
    </p>
    <p>
     自备CentOS服务器，并且已经使用FinalShell连接到服务器
    </p>
    <p>
    </p>
    <h2>
     一、准备工作
    </h2>
    <h3>
     1.更新服务器
    </h3>
    <pre><code class="hljs">apt-get update-y</code></pre>
    <h3>
     2.下载Ollama
    </h3>
    <pre><code class="hljs">curl -fsSL https://ollama.com/install.sh  | sh</code></pre>
    <h3>
     3.测试ollama是否安装完成
    </h3>
    <pre><code class="hljs">ollama</code></pre>
    <h3>
     4.按照正常的命令下载Ollama模型。根据个人服务器硬件配置
    </h3>
    <pre><code class="hljs">ollama run deepseek-r1:14b</code></pre>
    <p>
    </p>
    <h2>
     二、放行端口
    </h2>
    <pre><code class="hljs">#放行端口
ufw allow 11434

#查看端口状态
ufw status</code></pre>
    <p>
    </p>
    <h2>
     三、设置环境变量：
    </h2>
    <h3>
     1.编辑ollama.service
    </h3>
    <pre><code class="hljs">vim /etc/systemd/system/ollama.service</code></pre>
    <h3>
     2.在[Service]部分，Environment下面添加：
    </h3>
    <pre><code class="hljs">Environment="OLLAMA_HOST=0.0.0.0"
Environment="OLLAMA_ORIGINS=*"
</code></pre>
    <p>
     <img alt="" height="655" src="https://i-blog.csdnimg.cn/direct/0110c685f3744e8c921e8c82b022bec6.png" width="1192"/>
    </p>
    <p>
     使用箭头移动光标到Environment下方，
    </p>
    <p>
     键盘[i]键，进入编辑模式（左下角显示INSERT代表进入编辑模式）
    </p>
    <p>
     输入以上两个配置
    </p>
    <p>
     按[ESC]键，退出编辑模式
    </p>
    <p>
     输入:wq保存并退出
    </p>
    <p>
    </p>
    <h3>
     3.重新加载systemd并重启Ollama
    </h3>
    <pre><code class="hljs">systemctl deamon-reload
systemctl restart ollama</code></pre>
    <p>
    </p>
    <h2>
     查看Ollama运行状态
    </h2>
    <pre><code class="hljs">systemctl status ollama
按【q】退出</code></pre>
    <p>
    </p>
    <h2>
     查看显存占用状态
    </h2>
    <pre><code class="hljs">#英伟达
nvidia-smi

#其他软件
apt-get install nvtop -y
nvtop</code></pre>
    <p>
    </p>
    <h2>
     四、使用Ollama
    </h2>
    <p>
     使用PageAssist、ChatBox、CherryStudio、AnythingLLM等方式连接即可
    </p>
    <p>
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f753031313634333436332f:61727469636c652f64657461696c732f313436323538363236" class_="artid" style="display:none">
 </p>
</div>


