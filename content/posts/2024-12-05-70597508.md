---
arturl_encode: "68747470733a2f2f:626c6f672e6373646e2e6e65742f4269786977656e5f6c6975:2f61727469636c652f64657461696c732f3730353937353038"
layout: post
title: "Android-WebRTC-音视频开发总结四-webrtc传输模块"
date: 2024-12-05 18:35:17 +08:00
description: "音视频数据采集->编码->发送->接收->解码->播放。编码、解码、以及会用到加密、解密、回声消除等"
keywords: "webrtc推送模块开发"
categories: ['Webrtc']
tags: ['无标签']
artid: "70597508"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=70597508
    alt: "Android-WebRTC-音视频开发总结四-webrtc传输模块"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=70597508
featuredImagePreview: https://bing.ee123.net/img/rand?artid=70597508
---

# Android WebRTC 音视频开发总结（四）-- webrtc传输模块

在介绍WebRTC通讯之前我们先来看一个P2P视频聊天包括的主要过程，转载请说明出处（博客园RTC.Blacker）：

音视频数据采集->编码->发送->接收->解码->播放。

编码、解码、以及会用到加密、解密、回声消除等针对不同系统处理方式都一样，与平台无关，

但像Socket通信涉及到的数据发送、接收不同平台则有不同的处理方式，

如Socket模型，windows里面用的是WSASocket，

Linux下用的则是socket，所以他通过模版模式来创建不同类型，

下面主要是介绍WebRTC自带的一个传输模块，实际应用中您可以根据自己的需求注册不同的传输模块。

![](http://images.cnitblog.com/i/77236/201403/270932437026700.png)

其中:udp_socket_wrapper.h主要负责Socket相关操作，如Socket创建、启动、端口绑定、停止。

udp_socket2_windows.h主要负责windows平台上的Socket相关操作，与之对应的就是linux平台上的udp_socket_posix.h

udp_transport.h主要负责包的发送和接收，如果你想实现自己的数据包收发逻辑，可重写该类，如他里面的LoopBack方式就是通过重写该模块来实现的。

对客户端调用来说主要就是做四件事情：

1、设置音视频远端地址和端口（包括远端音视频的RTP、RTCP端口和本地接收音视频的RTP、RTCP端口）。

2、启动音视频数据的发送。

3、启动音视频数据的接收。

4、启动音视频数据的播放。

具体代码结构如下：

![复制代码](https://i-blog.csdnimg.cn/blog_migrate/69c5a8ac3fa60e0848d784a6dd461da6.gif)

```
1 public void start() {
2         this.setRemoteIp(WebRTCClient.str_remote_ip);WebRTCClient.str_to);
3         if (audioEnabled) {
4             startVoE();
5         }
6         if (receiveVideo || sendVideo) {
7             startViE();
8         }
9     }
```

![复制代码](https://i-blog.csdnimg.cn/blog_migrate/69c5a8ac3fa60e0848d784a6dd461da6.gif)

![复制代码](https://i-blog.csdnimg.cn/blog_migrate/69c5a8ac3fa60e0848d784a6dd461da6.gif)

```
1 public void startVoE() {
2         check(!voeRunning, "VoE already started");
3         check(voe.startListen(audioChannel) == 0, "Failed StartListen");
4         check(voe.startPlayout(audioChannel) == 0, "VoE start playout failed");
5         check(voe.startSend(audioChannel) == 0, "VoE start send failed");
6         voeRunning = true;
7     }
```

![复制代码](https://i-blog.csdnimg.cn/blog_migrate/69c5a8ac3fa60e0848d784a6dd461da6.gif)

![复制代码](https://i-blog.csdnimg.cn/blog_migrate/69c5a8ac3fa60e0848d784a6dd461da6.gif)

```
 1 public void startViE() {
 2         check(!vieRunning, "ViE already started");
 3 
 4         if (receiveVideo) {
 5             if (viewSelection == context.getResources().getInteger(R.integer.openGl)) {
 6                 svRemote = ViERenderer.CreateRenderer(context, true);
 7             } else if (viewSelection == context.getResources().getInteger(R.integer.surfaceView)) {
 8                 svRemote = ViERenderer.CreateRenderer(context, false);
 9             } else {
10                 externalCodec = new MediaCodecVideoDecoder(context);
11                 svRemote = externalCodec.getView();
12             }
13             if (externalCodec != null) {
14                 check(vie.registerExternalReceiveCodec(videoChannel, VCM_VP8_PAYLOAD_TYPE,
15                         externalCodec, true) == 0, "Failed to register external decoder");
16             } else {
17                 check(vie.addRenderer(videoChannel, svRemote, 0, 0, 0, 1, 1) == 0,
18                         "Failed AddRenderer");
19                 check(vie.startRender(videoChannel) == 0, "Failed StartRender");
20             }
21             check(vie.startReceive(videoChannel) == 0, "Failed StartReceive");
22         }
23         if (sendVideo) {
24             startCamera();
25             check(vie.startSend(videoChannel) == 0, "Failed StartSend");
26         }
27         vieRunning = true;
28     }
```

![复制代码](https://i-blog.csdnimg.cn/blog_migrate/69c5a8ac3fa60e0848d784a6dd461da6.gif)

希望查看这个调用过程能是您大概明白流媒体数据的发送过程，为后面自定能够以传输模块打下基础。

请思考：WebRTC里面如何操作音视频设备？如打开扬声器，启动摄像头，后面会揭晓答案，请关注。