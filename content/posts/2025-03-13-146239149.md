---
layout: post
title: "上下文学习思维链COTPrompt工程"
date: 2025-03-13 23:12:17 +0800
description: "上下文学习&思维链COT&Prompt工程"
keywords: "上下文学习&思维链COT&Prompt工程"
categories: ['未分类']
tags: ['提示词Prompt', '思维链Cot', '上下文学习Context']
artid: "146239149"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146239149
    alt: "上下文学习思维链COTPrompt工程"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146239149
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146239149
cover: https://bing.ee123.net/img/rand?artid=146239149
image: https://bing.ee123.net/img/rand?artid=146239149
img: https://bing.ee123.net/img/rand?artid=146239149
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     上下文学习&amp;思维链COT&amp;Prompt工程
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     一、上下文学习
    </h2>
    <p>
     上下文学习强调在学习过程中考虑问题所处的上下文环境。
    </p>
    <h3>
     1.1 上下文学习的分类
    </h3>
    <ul>
     <li>
      零样本（Zero-Shot）上下文学习
     </li>
     <li>
      单样本（One-Shot）上下文学习
     </li>
     <li>
      少样本（Few-Shot）上下文学习
     </li>
    </ul>
    <h3>
     1.2 示例选择方法
    </h3>
    <p>
     两个主要依据是
     <strong>
      相似性和多样性
     </strong>
     。
    </p>
    <ul>
     <li>
      直接检索：然后选取排名靠前的K个示例。
     </li>
     <li>
      聚类检索：把所有示例划分为K个簇，从每个簇中选取最为相似的示例，获取K个示例。
     </li>
     <li>
      迭代检索：下一个示例的选择依赖于当前的问题和已选择的示例。
     </li>
    </ul>
    <h3>
     1.3 性能影响因素
    </h3>
    <ul>
     <li>
      预训练数据：领域丰富度、任务多样性、训练数据的分布
     </li>
     <li>
      预训练规模：模型参数规模
     </li>
     <li>
      演示示例：示例的数量和顺序
     </li>
    </ul>
    <hr/>
    <h2>
     二、思维链
    </h2>
    <h3>
     2.1 两种任务类型
    </h3>
    <p>
     （1）System-1任务
    </p>
    <ul>
     <li>
      依靠
      <strong>
       直觉和经验
      </strong>
      进行瞬间判断。
     </li>
     <li>
      随着规模（参数量、训练数据、算力）变大，模型性能显著提升。
     </li>
    </ul>
    <p>
     （2）System-2任务
    </p>
    <ul>
     <li>
      运用
      <strong>
       逻辑分析、计算和有意识
      </strong>
      的思考来解决。
     </li>
     <li>
      模型会出现“Flat Scaling Curves”现象——即模型规模增长未带来预期性能提升。
     </li>
    </ul>
    <h3>
     2.2 思维链的定义
    </h3>
    <p>
     在提示中
     <strong>
      嵌入一系列中间推理步骤
     </strong>
     ，引导大模型模拟人类解决问题时的思考过程，以
     <strong>
      提升模型处理System-2任务的能力
     </strong>
     。
    </p>
    <h3>
     2.3 思维链的分类
    </h3>
    <p>
     在标准COT方法上，出现了许多扩展方法，这些方法按照其推理方式的不同，可以归纳为三种模式：
     <strong>
      按部就班、三思而行、集思广益
     </strong>
     。
    </p>
    <p>
     <img alt="" height="323" src="https://i-blog.csdnimg.cn/direct/a81b741c69734951be90f319d1488c4f.png" width="1092"/>
    </p>
    <p>
     <strong>
      <span style="color:#ff9900">
       按部就班模式
      </span>
     </strong>
    </p>
    <p>
     强调
     <strong>
      逻辑的连贯性和步骤的顺序性
     </strong>
     。
    </p>
    <p>
     代表方法：
    </p>
    <ul>
     <li>
      COT：
      <strong>
       手工构造（
      </strong>
      费时费力
      <strong>
       ）
      </strong>
      例子，作为示例放入Prompt，引导模型一步一步推理。
     </li>
     <li>
      Zero-Shot COT：
      <strong>
       无需手工标注，只需提供简单的提示
      </strong>
      ，如“Let's think step by step”，引导模型自行生成一条推理链。
     </li>
    </ul>
    <blockquote>
     <p>
      <span style="color:#956fe7">
       <strong>
        魔法咒语：Let's think step by step.
       </strong>
      </span>
     </p>
    </blockquote>
    <ul>
     <li>
      Auto COT：
      <strong>
       聚类算法
      </strong>
      自动筛选相关样本，
      <strong>
       Zero-Shot
      </strong>
      生成思维链内容作为示例，引导大语言模型生成针对用户问题的推理链和答案。
     </li>
    </ul>
    <p>
     <img alt="" height="282" src="https://i-blog.csdnimg.cn/direct/7dbcf0ddd1b94f6983ae8bef0eaf8e80.png" width="1086"/>
    </p>
    <p>
     不足：
    </p>
    <ul>
     <li>
      局部：在思维过程中不会探索不同的后续内容，即树的分支。
     </li>
     <li>
      全局：顺序链式输出，不存在回溯的过程。
     </li>
    </ul>
    <p>
     <strong>
      <span style="color:#ff9900">
       三思后行模式
      </span>
     </strong>
    </p>
    <p>
     强调
     <strong>
      审慎和灵活
     </strong>
     。
    </p>
    <p>
     代表方法：
    </p>
    <ul>
     <li>
      Tree of Thoughts（TOT）：将推理过程构造为一棵
      <strong>
       思维树
      </strong>
      ，允许模型在不确定时进行
      <strong>
       回溯
      </strong>
      和
      <strong>
       重新选择
      </strong>
      。TOT从
      <strong>
       拆解、衍生、评估、搜索
      </strong>
      四个角度构造思维树。
     </li>
    </ul>
    <p>
     <img alt="" height="334" src="https://i-blog.csdnimg.cn/direct/7557945f30dd45ffb42079ae5ee1fab5.png" width="1089"/>
    </p>
    <ul>
     <li>
      Graph of Thoughts（GOT）
     </li>
    </ul>
    <p>
     <span style="color:#ff9900">
      <strong>
       集思广益模式
      </strong>
     </span>
    </p>
    <p>
     强调
     <strong>
      观点和方法的多样性。
     </strong>
    </p>
    <p>
     代表方法：
    </p>
    <ul>
     <li>
      Self-Consistency：引入
      <strong>
       多样性的推理路径
      </strong>
      ，从中提取并选择
      <strong>
       最一致的答案。
      </strong>
     </li>
    </ul>
    <p>
     <img alt="" height="238" src="https://i-blog.csdnimg.cn/direct/fcd1a51a9b61485d9b6f71afe63a54b5.png" width="1086"/>
    </p>
    <ul>
     <li>
      Universal Self-Consistency：利用
      <strong>
       LLMs自身选择最一致答案
      </strong>
      ，支持更多种任务，无需答案提取过程。
     </li>
    </ul>
    <p>
     <img alt="" height="356" src="https://i-blog.csdnimg.cn/direct/9820a4266ed444168336c2179502c2d9.png" width="1183"/>
    </p>
    <hr/>
    <h2>
     三、Prompt工程
    </h2>
    <p>
     <img alt="" height="441" src="https://i-blog.csdnimg.cn/direct/7246889d311a4aef92a54c9f05906c93.png" width="1284"/>
    </p>
    <h3>
     3.1 Prompt规范
    </h3>
    <p>
     编写规范的Prompt是与大语言模型进行有效沟通的基础。一个标准规范的Prompt通常由
     <strong>
      任务说明、上下文、问题、输出格式
     </strong>
     这几个部分中的一个或几个来组成。
    </p>
    <h3>
     3.2 Prompt技巧
    </h3>
    <ul>
     <li>
      复杂问题拆解
     </li>
     <li>
      追问
     </li>
     <li>
      适时使用COT
     </li>
     <li>
      善用心理暗示：角色扮演or情景代入
     </li>
    </ul>
    <p>
     <img alt="" height="420" src="https://i-blog.csdnimg.cn/direct/3624da3eb5d64276ac15d5e2955448ec.png" width="1029"/>
    </p>
    <h3>
     3.3 Prompt工程应用
    </h3>
    <p>
     可以通过精心设计的Prompt激活大语言模型的内在潜力，而不需要对模型进行微调。Prompt已经在
     <strong>
      垂域任务、数据增强、智能代理
     </strong>
     等多个领域发挥出卓越性能。
    </p>
    <p>
     （1）自然语言接口
    </p>
    <ul>
     <li>
      Text to SQL
     </li>
     <li>
      代码生成
     </li>
    </ul>
    <p>
     （2）大模型支撑的数据合成
    </p>
    <ul>
     <li>
      Self-Instruct
     </li>
    </ul>
    <p>
     （3）大模型增强的搜索引擎
    </p>
    <p>
     （4）大模型赋能智能体
    </p>
    <p>
     经典的智能体通常由大语言模型和四大模块组成，分别是：配置模块（Profile）、记忆模块（Memory）、计划模块（Planning）、行动模块（Action）。
    </p>
    <blockquote>
     <p>
      单智能体仅包含一个智能体，交互相对简单，适用于简单任务。Prompt设计主要用于引导模型执行特定任务，且围绕单个上下文。
     </p>
     <p>
      多智能体包含多个智能体，每个智能体都设定有角色和任务，交互复杂度高。他们协调、合作、竞争，以实现共同或各自目标。
     </p>
    </blockquote>
    <p>
     （5）大模型驱动的具身智能
    </p>
    <p>
     大语言模型是AGI的智慧引擎，机器人是大语言模型走向真实世界的物理载体。
    </p>
    <hr/>
    <h2>
     四、参考
    </h2>
    <p>
     bilibili：浙江大学-大模型原理与技术
    </p>
    <p>
    </p>
    <p>
    </p>
    <p>
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f37323830383837392f:61727469636c652f64657461696c732f313436323339313439" class_="artid" style="display:none">
 </p>
</div>


