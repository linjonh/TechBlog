---
layout: post
title: "Ubuntu通过Ollama部署deepseek和千问"
date: 2025-03-10 14:08:56 +0800
description: "本地服务器是Ubuntu20.04，输入命令uname -a即可查看部署方式有多样，点击访问官网可复制命令直接粘贴下载，但是过程比较慢，所以我推荐下面这种方式从github上下载ollama的tar包进行解压，如图。"
keywords: "Ubuntu通过Ollama部署deepseek和千问"
categories: ['未分类']
tags: ['Ubuntu', 'Linux']
artid: "146152697"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146152697
    alt: "Ubuntu通过Ollama部署deepseek和千问"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146152697
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146152697
cover: https://bing.ee123.net/img/rand?artid=146152697
image: https://bing.ee123.net/img/rand?artid=146152697
img: https://bing.ee123.net/img/rand?artid=146152697
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Ubuntu通过Ollama部署deepseek和千问
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     一、准备文件
    </h2>
    <p>
     本地服务器是Ubuntu20.04，输入命令uname -a即可查看
    </p>
    <p>
     <img alt="" height="52" src="https://i-blog.csdnimg.cn/direct/a55b4a5e4d7d4b5580d977098728dafd.png" width="1064"/>
    </p>
    <p>
     部署方式有多样，点击
     <a href="https://ollama.com/" rel="nofollow" title="Ollama">
      Ollama
     </a>
     访问官网
    </p>
    <p>
     <img alt="" height="1239" src="https://i-blog.csdnimg.cn/direct/f7328a4423ce4117af74f40c5790afc5.png" width="2560"/>
    </p>
    <p>
     可复制命令直接粘贴下载，但是过程比较慢，所以我推荐下面这种方式
    </p>
    <p>
     从github
     <a href="https://github.com/ollama/ollama/releases/" title="Releases · ollama/ollama · GitHub">
      Releases · ollama/ollama · GitHub
     </a>
     上下载ollama的tar包进行解压，如图
    </p>
    <p>
     <img alt="" height="1239" src="https://i-blog.csdnimg.cn/direct/c2ee3c089c374ab68d354cf8f7eedbf1.png" width="2560"/>
    </p>
    <h2>
     二、安装Ollama
    </h2>
    <p>
     如果系统是x86_64的就选择amd64,下载完成后传到服务器上面进行解压，输入命令
    </p>
    <pre><code class="language-bash">sudo tar -zxf ollama-linux-amd64.tgz -C /usr/local</code></pre>
    <p>
     然后进行赋权
    </p>
    <pre><code class="language-bash">sudo chmod +x /usr/local/bin/ollama </code></pre>
    <p>
     添加ollama用户
    </p>
    <pre><code class="language-bash">sudo useradd -r -s /bin/false -m -d /usr/share/ollama ollama</code></pre>
    <p>
     创建service文件（方便后面启动服务）
    </p>
    <pre><code class="language-bash">sudo vim /etc/systemd/system/ollama.service</code></pre>
    <p>
     service文件内容如下
    </p>
    <pre><code class="language-bash">[Unit]
Description=Ollama Service
After=network-online.target
[Service]
Environment="OLLAMA_HOST=0.0.0.0"
ExecStart=/usr/local/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
[Install]
WantedBy=default.target</code></pre>
    <p>
     加载守护进程
    </p>
    <pre><code class="language-bash">sudo systemctl daemon-reload</code></pre>
    <p>
     启用
    </p>
    <pre><code class="language-bash">sudo systemctl enable ollama</code></pre>
    <p>
     验证
    </p>
    <pre><code class="language-bash">ollama -v</code></pre>
    <p class="img-center">
     <img alt="" height="74" src="https://i-blog.csdnimg.cn/direct/6b0ad4a55ead4e1eb9f62e7e0988ec37.png" width="469"/>
    </p>
    <h2>
     三、下载模型
    </h2>
    <h3>
     1、deepseek
    </h3>
    <p>
     Ollama官网搜索deepseek r1
    </p>
    <p>
     <img alt="" height="916" src="https://i-blog.csdnimg.cn/direct/44d2f6f93475418fba3c821bf396795a.png" width="1763"/>
    </p>
    <p>
     或者输入命令下载你想要的模型
    </p>
    <pre><code class="language-bash">ollama pull deepseek-r1:7b
 
ollama pull deepseek-r1:8b
 
ollama pull deepseek-r1:14b
 
ollama pull deepseek-r1:32b
 
ollama pull deepseek-r1:70b
 
ollama pull deepseek-r1:671b</code></pre>
    <p>
     等待下载，如果到后面下载慢的话ctrl +c结束然后在继续下载速度就会变快
    </p>
    <p>
     <img alt="" height="194" src="https://i-blog.csdnimg.cn/direct/834ec2b42ff1495391291f2957ed062b.png" width="1602"/>
    </p>
    <p>
     输入命令
    </p>
    <pre><code class="language-bash">ollama run deepseek-r1:7b</code></pre>
    <p>
     开始对话
    </p>
    <p>
     <img alt="" height="302" src="https://i-blog.csdnimg.cn/direct/b27423b5065749889b8107031c9441b9.png" width="1220"/>
    </p>
    <h3>
     2、千问
    </h3>
    <p>
     输入命令
    </p>
    <pre><code class="language-bash">ollama run qwen:7b</code></pre>
    <p>
     等待下载
    </p>
    <p>
     <img alt="" height="214" src="https://i-blog.csdnimg.cn/direct/a525a8093749410489618216008fee85.png" width="1493"/>
    </p>
    <p>
     开始对话
    </p>
    <p>
     <img alt="" height="369" src="https://i-blog.csdnimg.cn/direct/5e120e2838a44cd2b7a229baa829ce42.png" width="1194"/>
    </p>
    <h2>
     四、暴露11434端口服务
    </h2>
    <p>
     因为Ollama的11434端口默认是127.0.0.1:11434其它的电脑通过服务器IP去访问是不通的，有两个解决方案
    </p>
    <p>
     1、在启动时设置为0.0.0.0启动
    </p>
    <p>
    </p>
    <pre><code class="language-bash">set OLLAMA_HOST=0.0.0.0 &amp;&amp; ollama serve</code></pre>
    <p>
     2、修改service文件，增加环境为0.0.0.0在上述已经增加过了
    </p>
    <p>
     <img alt="" height="339" src="https://i-blog.csdnimg.cn/direct/8d464bc4b6614117884399b199863ce7.png" width="833"/>
    </p>
    <p>
     修改配置文件需要重新加载守护进程然后重启服务（daemon-reload）
    </p>
    <p>
     验证
    </p>
    <p>
     <img alt="" height="210" src="https://i-blog.csdnimg.cn/direct/28e44ee0b1dc46419f0131f62471b1b4.png" width="964"/>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f:672e6373646e2e6e65742f6a69616e676c6f7665686f6e672f:61727469636c652f64657461696c732f313436313532363937" class_="artid" style="display:none">
 </p>
</div>


