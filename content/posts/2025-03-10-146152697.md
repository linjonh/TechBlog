---
arturl_encode: "68747470733a2f2f626c6f:672e6373646e2e6e65742f6a69616e676c6f7665686f6e672f:61727469636c652f64657461696c732f313436313532363937"
layout: post
title: "Ubuntu通过Ollama部署deepseek和千问"
date: 2025-03-10 14:08:56 +08:00
description: "本地服务器是Ubuntu20.04，输入命令uname -a即可查看部署方式有多样，点击访问官网可复制命令直接粘贴下载，但是过程比较慢，所以我推荐下面这种方式从github上下载ollama的tar包进行解压，如图。"
keywords: "Ubuntu通过Ollama部署deepseek和千问"
categories: ['未分类']
tags: ['Ubuntu', 'Linux']
artid: "146152697"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=146152697
    alt: "Ubuntu通过Ollama部署deepseek和千问"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=146152697
featuredImagePreview: https://bing.ee123.net/img/rand?artid=146152697
cover: https://bing.ee123.net/img/rand?artid=146152697
image: https://bing.ee123.net/img/rand?artid=146152697
img: https://bing.ee123.net/img/rand?artid=146152697
---

# Ubuntu通过Ollama部署deepseek和千问

## 一、准备文件

本地服务器是Ubuntu20.04，输入命令uname -a即可查看

![](https://i-blog.csdnimg.cn/direct/a55b4a5e4d7d4b5580d977098728dafd.png)

部署方式有多样，点击
[Ollama](https://ollama.com/ "Ollama")
访问官网

![](https://i-blog.csdnimg.cn/direct/f7328a4423ce4117af74f40c5790afc5.png)

可复制命令直接粘贴下载，但是过程比较慢，所以我推荐下面这种方式

从github
[Releases · ollama/ollama · GitHub](https://github.com/ollama/ollama/releases/ "Releases · ollama/ollama · GitHub")
上下载ollama的tar包进行解压，如图

![](https://i-blog.csdnimg.cn/direct/c2ee3c089c374ab68d354cf8f7eedbf1.png)

## 二、安装Ollama

如果系统是x86_64的就选择amd64,下载完成后传到服务器上面进行解压，输入命令

```bash
sudo tar -zxf ollama-linux-amd64.tgz -C /usr/local
```

然后进行赋权

```bash
sudo chmod +x /usr/local/bin/ollama 
```

添加ollama用户

```bash
sudo useradd -r -s /bin/false -m -d /usr/share/ollama ollama
```

创建service文件（方便后面启动服务）

```bash
sudo vim /etc/systemd/system/ollama.service
```

service文件内容如下

```bash
[Unit]
Description=Ollama Service
After=network-online.target
[Service]
Environment="OLLAMA_HOST=0.0.0.0"
ExecStart=/usr/local/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
[Install]
WantedBy=default.target
```

加载守护进程

```bash
sudo systemctl daemon-reload
```

启用

```bash
sudo systemctl enable ollama
```

验证

```bash
ollama -v
```

![](https://i-blog.csdnimg.cn/direct/6b0ad4a55ead4e1eb9f62e7e0988ec37.png)

## 三、下载模型

### 1、deepseek

Ollama官网搜索deepseek r1

![](https://i-blog.csdnimg.cn/direct/44d2f6f93475418fba3c821bf396795a.png)

或者输入命令下载你想要的模型

```bash
ollama pull deepseek-r1:7b
 
ollama pull deepseek-r1:8b
 
ollama pull deepseek-r1:14b
 
ollama pull deepseek-r1:32b
 
ollama pull deepseek-r1:70b
 
ollama pull deepseek-r1:671b
```

等待下载，如果到后面下载慢的话ctrl +c结束然后在继续下载速度就会变快

![](https://i-blog.csdnimg.cn/direct/834ec2b42ff1495391291f2957ed062b.png)

输入命令

```bash
ollama run deepseek-r1:7b
```

开始对话

![](https://i-blog.csdnimg.cn/direct/b27423b5065749889b8107031c9441b9.png)

### 2、千问

输入命令

```bash
ollama run qwen:7b
```

等待下载

![](https://i-blog.csdnimg.cn/direct/a525a8093749410489618216008fee85.png)

开始对话

![](https://i-blog.csdnimg.cn/direct/5e120e2838a44cd2b7a229baa829ce42.png)

## 四、暴露11434端口服务

因为Ollama的11434端口默认是127.0.0.1:11434其它的电脑通过服务器IP去访问是不通的，有两个解决方案

1、在启动时设置为0.0.0.0启动

```bash
set OLLAMA_HOST=0.0.0.0 && ollama serve
```

2、修改service文件，增加环境为0.0.0.0在上述已经增加过了

![](https://i-blog.csdnimg.cn/direct/8d464bc4b6614117884399b199863ce7.png)

修改配置文件需要重新加载守护进程然后重启服务（daemon-reload）

验证

![](https://i-blog.csdnimg.cn/direct/28e44ee0b1dc46419f0131f62471b1b4.png)