---
arturl_encode: "68747470733a2f2f626c6f:672e6373646e2e6e65742f323430315f38343539313734362f:61727469636c652f64657461696c732f313338383235393830"
layout: post
title: "2024年大数据最新关于Hadoop生态圈相关组件的介绍3,2024年最新小白看完都会了"
date: 2024-05-14 00:44:52 +08:00
description: "冷备”、温备和热备是备份和恢复策略中常见的术语，_12台机器"
keywords: "12台机器搭建的haoop生态圈能存多少的数据"
categories: ['程序员']
tags: ['面试', '学习', '大数据']
artid: "138825980"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=138825980
    alt: "2024年大数据最新关于Hadoop生态圈相关组件的介绍3,2024年最新小白看完都会了"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=138825980
featuredImagePreview: https://bing.ee123.net/img/rand?artid=138825980
---

# 2024年大数据最新关于Hadoop生态圈相关组件的介绍(3)，2024年最新小白看完都会了

![img](https://i-blog.csdnimg.cn/blog_migrate/01a052ff5d799e4097628b28b12f055f.png)
  
![img](https://i-blog.csdnimg.cn/blog_migrate/0a8e1639bacdb5ee6fdbade25e8ca596.png)

**网上学习资料一大堆，但如果学到的知识不成体系，遇到问题时只是浅尝辄止，不再深入研究，那么很难做到真正的技术提升。**

**[需要这份系统化资料的朋友，可以戳这里获取](https://bbs.csdn.net/topics/618545628)**

**一个人可以走的很快，但一群人才能走的更远！不论你是正从事IT行业的老鸟或是对IT行业感兴趣的新人，都欢迎加入我们的的圈子（技术交流、学习资源、职场吐槽、大厂内推、面试辅导），让我们一起学习成长！**

##### **伪分布式模式**

（1）Hadoop安装在一台计算机上，需要修改相应的配置文件，用一台计算机模拟多台主机的集群。

（2）需要启动HDFS和YARN，是相互独立的Java进程。

（3）MapReduce运行处理数据时是每个作业一个独立进程，输入输出使用分布式文件系统。

（4）用来进行学习和开发测试Hadoop程序的执行是否正确。

##### **完全分布式模式**

（1）在多台计算机上安装JDK和Hadoop，组成相互连通的集群，需要修改相应的配置文件。

（2）Hadoop的守护进程运行在由多台主机搭建的集群上。

真正的生产环境。

#### **Hadoop 优点**

（1）扩容能力强：Hadoop是在可用的计算机集群间分配数据并完成计算任务，这些集群可以方便地扩展到数以千计的节点。

（2）成本低：通过普通廉价的计算机组成服务器集群来分发以及处理数据，相比使用大型机乃至超级计算机成本低很多。

（3）高效率：通过并发数据，Hadoop可以在节点之间动态并行处理数据，使得处理速度非常快。

（4）高可靠性：能自动维护数据的多份复制，并且在任务失败后能自动地重新部署计算任务。

#### **Hadoop的核心组件——HDFS**

##### **HDFS 定义**

HDFS(Hadoop Distributed File System)，它是一个文件系统，用于存储文件，通过目录树来定位文件;其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。适合一次写入，多次读出的场景，不支持文件修改，可以过来做数据分析。

##### **优点：**

（1）容错性高：主要有多个副本

（2）适合处理大数据：数据规模 可达到 PB级别，文件量能够处理百万这个量级

（3）可构建在廉价机器上

##### **缺点：**

（1）数据访问有延时，做不到毫秒级别的

（2）大量小文件不能高效存储，NameNode会占用大量内存

（3） 可追加写入，不可随机修改，不支持并发写入（不支持多线程写入）

HDFS架构图

![](https://i-blog.csdnimg.cn/blog_migrate/e3865b29e3f2c1510aee0a50c8c9f70e.png)

#### **相关组件的介绍**

##### **NameNode**

**名称节点，HDFS的管理者。**

**（1）管理HDFS的名字空间，维护管理所有文件的元数据。**

**（2）管理DataNode上的数据块，决定文件数据块存储到哪个DataNode。**

**（3）处理客户端的读写请求。**

**（4）按用户确定的副本策略管理HDFS中数据的副本**

##### **DataNode（数据节点）**

**负责存储数据。**

**（1）存储实际的数据块，每个HDFS数据块默认大小为128MB，存储在本地文件系统的单独文件中。**

**（2）处理客户端的读写请求，执行数据块的读和写。**

**（3）向 NameNode 定期汇报数据块信息，并定时向 NameNode 发送心跳信号保持联系。**

##### **FSImage和edits文件**

**（1）FSImage文件存储文件的元数据，HDFS运行时会将该文件加载到内存中。**

**（2）edits文件记录对文件的写操作（修改）。**

**（3）写文件操作只会对内存中的元数据进行修改，不会对FSImage文件进行修改。**

##### **SecondaryNameNode**

**用于合并元数据文件FSImage。**

**（1）将NameNode上的FSImage和edits文件复制到本地，并将两者合并生成新的FSImage文件，再将新的FSImage文件复制回NameNode。**

**（2）不是NameNode的备份，但可以帮助恢复NameNode，因为其上保存了大部分的元数据信息。**

**SecondaryNameNode，用于合并元数据文件FSImage。**

**（1）将NameNode上的FSImage和edits文件复制到本地，并将两者合并生成新的FSImage文件，再将新的FSImage文件复制回NameNode。**

**（2）不是NameNode的备份，但可以帮助恢复NameNode，因为其上保存了大部分的元数据信息。**

##### **Client**

**就是客户端。**

**(1）文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传;**

**(2)与 NameNode 交互，获取文件的位置信息;**

**(3)与 DataNode 交互，读取或者写入数据;**

**(4) Client提供一些命令来管理 HDFS，比如 NaneNode 格式化;**

**(5) Client可以通过一些命令来访问 HDFS，比如对 HDFS 增删查改操作;**

#### **HDFS - 优缺点**

##### **优点：**

**（1）适合处理大数据：HDFS能够处理TB级甚至PB级的数据，文件数量也可达百万以上。**

**（2）高容错性：自动保存数据的多个副本，当某一副本丢失，可以自动重备。**

**（3）低成本运行：HDFS可以运行在廉价的商用计算机上。通过多副本机制提高可靠性。**

##### 缺点：

**（1）不适合处理低延时的数据访问。**

**（2）不适合处理大量的小文件：小文件太多会消耗NameNode的内存。同时小文件的寻址时间超过读取时间，也违背了HDFS的设计目标。**

**（3）不支持并发写入和文件随机修改：HDFS的文件同时只能有一个用户进行写操作，也仅支持文件的数据追加。**

### **二、MapReduce的特点及运行架构**

MapReduce是一种用于处理大规模数据集的编程模型和处理框架，最初由Google开发，在后来由Apache Hadoop项目采用，并被广泛应用于分布式计算环境中。它的主要特点和运行架构如下：

#### **MapReduce的特点：**

1. **简单易用**
   ：MapReduce模型提供了简单的抽象，使得开发人员可以专注于编写处理数据的逻辑，而不必关注底层的并行和分布式处理细节。
2. **分布式处理：**
   MapReduce适用于大规模数据集的并行处理。它将输入数据分割成小块，并在多个计算节点上进行并行处理，以加速数据处理过程。
3. **容错性：**
   MapReduce具有高度的容错性，能够处理计算节点故障。当一个节点失败时，MapReduce会重新调度任务到其他节点上，确保整个作业的完成。
4. **可扩展性：**
   可以通过简单地添加更多的计算节点来扩展MapReduce系统的处理能力，使其适应不断增长的数据规模。
5. **简化编程模型：**
   MapReduce采用了一种简单而灵活的编程模型，将数据处理任务分解为两个主要阶段：Map阶段和Reduce阶段，简化了大规模数据处理的复杂性。
6. **自动数据分片：**
   MapReduce会自动将输入数据切分为小的数据块，并分配给不同的计算节点进行处理，使得处理任务能够更加均衡地分布在整个集群中。
7. **并行化处理**
   ：MapReduce将
   **任务**
   分解为独立的Map和Reduce阶段，并行处理输入数据集的不同部分，从而有效利用了集群中的计算资源。
8. **适用于各种类型的计算任务**
   ：MapReduce模型适用于各种类型的数据处理任务，包括数据清洗、数据转换、数据分析等。

#### **MapReduce的运行架构：**

1. JobTracker和TaskTracker： 在Hadoop中，MapReduce作业通常由一个主节点（JobTracker）和多个工作节点（TaskTracker）组成。JobTracker负责作业的调度和任务分配，而TaskTracker则在各个计算节点上执行具体的任务。
2. Map阶段： 输入数据被切分为多个数据块，然后通过一系列的Map任务并行处理。每个Map任务对输入数据执行用户定义的映射函数，生成一组中间键值对（Intermediate key-value pairs）。
3. 分区和排序： 中间键值对被分区为一组，并在每个分区内进行排序。这一过程的目的是将相同键的所有值都聚集在一起，以便更有效地进行Reduce操作。
4. Shuffle阶段： 在Shuffle阶段，Map的输出被重新分配到Reduce任务。这一阶段包括数据的排序、分区和传输，确保相同键的所有值被发送到相同的Reduce任务。
5. Reduce阶段： Reduce任务按照键对相应的值进行聚合和处理。用户定义的Reduce函数被应用于每个键的所有值，生成最终的输出。
6. 持久化和输出： Reduce任务的输出被写入HDFS（Hadoop分布式文件系统）或其他指定的存储系统，作为MapReduce作业的最终结果。

总体而言，MapReduce通过将大规模数据处理任务分解为独立的Map和Reduce阶段，并允许这些阶段在分布式环境中并行运行，实现了高效的大规模数据处理。

### **三、spark的特点与MapReduc的区别**

#### **spark的特点**

##### **快速：**

1. Spark 使用内存计算，能够在内存中高效地处理数据，大大提高了计算速度。相比于传统的基于磁盘的计算框架，如 Hadoop MapReduce，Spark 能够将中间结果保存在内存中，避免了频繁的磁盘读写操作，因此速度更快。
2. Spark 还引入了基于弹性分布式数据集（RDD）的计算模型，它将数据分片存储在集群的多个节点上，并能够在节点间并行执行操作，进一步提高了处理速度。

##### **易用：**

1. Spark 提供了丰富的高级 API 和易于使用的编程接口，包括 Scala、Java、Python 和 R 等语言的 API，以及 DataFrame 和 Dataset API。这些 API 使得开发者可以以更简洁、更直观的方式编写复杂的数据处理和分析任务，而无需深入了解底层的并行计算原理。
2. Spark 的交互式 shell 和可视化工具（如 Spark UI）也使得开发者可以方便地调试和优化代码，提高了开发效率。

##### **通用：**

1. Spark 不仅支持批处理任务，还能够处理流式数据、交互式查询、机器学习和图计算等多种工作负载。无论是对实时数据处理、数据挖掘还是机器学习等应用场景，Spark 都能够提供强大的支持。
2. Spark 还提供了丰富的库和扩展，如 Spark SQL、MLlib、GraphX 和 Spark Streaming 等，使得开发者可以方便地构建各种复杂的数据处理和分析应用。

##### **随处运行：**

1. Spark 可以在各种不同的环境中运行，包括本地机器、集群、云平台和容器化环境等。它支持多种资源管理器，如独立模式、YARN、Mesos 和 Kubernetes，因此可以轻松地部署和运行在各种不同的计算平台上。
2. Spark 还支持跨平台的部署，使得开发者可以在不同的环境中无缝切换，提高了灵活性和可扩展性。

##### **代码简洁：**

1. Spark 提供了简洁、优雅的编程模型和 API，使得开发者可以用更少的代码实现复杂的数据处理和分析任务。例如，使用 DataFrame API 可以方便地进行数据操作和转换，而无需手动编写复杂的 Map 和 Reduce 函数。
2. Spark 还支持函数式编程范式，如 map、filter、reduce 等操作，这些函数式编程的特性使得代码更易读、更易维护，并且能够有效地利用并行计算的优势。

#### 与MapReduced的区别

1. **快速**
   ：

   * **Spark**
     ：Spark 的内存计算和高效的调度机制使其处理速度比 MapReduce 快得多。通过将数据保留在内存中进行计算，Spark 避免了 MapReduce 中频繁的磁盘读写操作，从而显著提高了性能。
   * **MapReduce**
     ：相对而言，MapReduce 更依赖于磁盘 I/O，每个计算步骤都需要将数据写入磁盘，这会增加处理时间。
2. **易用**
   ：

   * **Spark**
     ：Spark 提供了丰富的高级 API 和开发工具，如 Spark SQL、DataFrame API 和 MLlib，使得开发者能够以更简单的方式编写复杂的数据处理和机器学习任务。
   * **MapReduce**
     ：MapReduce 的编程模型相对较为简单，但是需要编写大量的冗长的代码来完成相同的任务，因此相对而言稍显复杂。
3. **通用**
   ：

   * **Spark**
     ：Spark 不仅支持批处理任务，还支持流式处理、交互式查询、机器学习和图计算等多种工作负载，使其在各种场景下都能发挥作用。
   * **MapReduce**
     ：MapReduce 主要专注于批处理任务，虽然也可以通过一些扩展实现其他功能，但不如 Spark 的通用性强。
4. **随处运行**
   ：

   * **Spark**
     ：Spark 可以在各种环境中运行，包括独立模式、Hadoop YARN、Apache Mesos、Kubernetes 等，甚至可以在云平台上运行，如 AWS、Azure 和 Google Cloud。
   * **MapReduce**
     ：MapReduce 主要运行在 Hadoop 生态系统中，依赖于 Hadoop 的资源管理器和文件系统，相对而言不太灵活。
5. **代码简洁**
   ：

   * **Spark**
     ：Spark 提供了简洁的 API 和函数式编程模型，使得开发者可以用更少的代码实现相同的功能，同时提高了代码的可读性和维护性。
   * **MapReduce**
     ：MapReduce 的编程模型相对底层，需要编写大量的冗长的代码，不太容易理解和维护。

#### 四、熟练掌握Linux操作命令并演示说明

![](https://i-blog.csdnimg.cn/blog_migrate/6908e2757d64e5acb465b68a83aa3249.jpeg)

![](https://i-blog.csdnimg.cn/blog_migrate/fe80c6ee9025837136a7221d5b04cc48.jpeg)
![](https://i-blog.csdnimg.cn/blog_migrate/61ca4df398e70e2056fb2e3b11870e1c.jpeg)
![](https://i-blog.csdnimg.cn/blog_migrate/f06e17355d7861ae8b8a1ff97439fbc7.jpeg)
![](https://i-blog.csdnimg.cn/blog_migrate/9de52c36715b2a5943635c27ccde9968.jpeg)

![](https://i-blog.csdnimg.cn/blog_migrate/6809e4a94c0e8f980f31193b50596104.jpeg)
![](https://i-blog.csdnimg.cn/blog_migrate/69983ccc6a8eca37585d469cd2dbc9af.jpeg)
![](https://i-blog.csdnimg.cn/blog_migrate/8c3eef74a5e3ac6c9aaf60af4c9849f9.jpeg)
![](https://i-blog.csdnimg.cn/blog_migrate/8da1878cb8bae8a7fb2df219a92b5163.jpeg)
![](https://i-blog.csdnimg.cn/blog_migrate/6508196b65b05e82952ee6d568e803b7.jpeg)

### 五、冷备 温备 热备的介绍

“冷备”、"温备"和"热备"是备份和恢复策略中常见的术语，它们描述了在不同情况下备份数据的状态以及备份过程的准备程度。这些术语主要用于描述系统或数据的备份和恢复策略。

1. #### **冷备** （Cold Backup）：

   * 冷备是指在备份数据之前，系统或者数据服务已经停止运行的情况下进行备份。这意味着备份数据是静态的，没有正在写入或修改的数据。冷备通常需要停机时间，因为备份操作会中断系统或服务的正常运行。
   * 冷备通常用于对静态数据进行备份，或者在非工作时间进行备份，以最大程度地减少对系统性能的影响。
2. #### **温备** （Warm Backup）：

   * 温备是指备份数据时，系统或数据服务仍然处于运行状态，但备份操作会暂停数据的写入。这意味着备份数据是静态的，但是系统仍然可以读取数据。在温备状态下，系统可能会受到轻微的影响，因为写入操作暂时被暂停。
   * 温备通常用于对需要保持一定可用性的系统进行备份，因为它可以在备份过程中保持读取数据的能力，但是写入操作会受到一定的限制。
3. #### **热备** （Hot Backup）：

   * 热备是指备份数据时，系统或数据服务仍然处于完全运行状态，备份操作不会中断数据的写入或修改。这意味着备份数据是动态的，包含了系统正在进行的所有写入和修改操作。
   * 热备是最为灵活和实时的备份方式，但同时也是最复杂和资源密集的方式，因为备份操作必须与实时的系统交互，确保备份数据的一致性和完整性。

总的来说，冷备、温备和热备是备份策略中的不同选择，其选择取决于对系统可用性、备份时间窗口以及备份数据的一致性要求等方面的考虑。

### 六、 **数据类型**

大数据是一个广泛的概念，涵盖了处理和分析大规模数据集的方法和技术。在大数据领域，数据可以分为结构化数据、半结构化数据和非结构化数据等几种类型。以下是大数据中常见的数据类型：

1. #### **结构化数据（Structured Data）:**

   * 结构化数据是按照预定义的数据模型组织的数据，通常存储在关系型数据库中。

![img](https://i-blog.csdnimg.cn/blog_migrate/29f8809604bad012d6afa1122bcb1a9b.png)
  
![img](https://i-blog.csdnimg.cn/blog_migrate/5a6eb0d1e282833307daae3c92e906e7.png)

**网上学习资料一大堆，但如果学到的知识不成体系，遇到问题时只是浅尝辄止，不再深入研究，那么很难做到真正的技术提升。**

**[需要这份系统化资料的朋友，可以戳这里获取](https://bbs.csdn.net/topics/618545628)**

**一个人可以走的很快，但一群人才能走的更远！不论你是正从事IT行业的老鸟或是对IT行业感兴趣的新人，都欢迎加入我们的的圈子（技术交流、学习资源、职场吐槽、大厂内推、面试辅导），让我们一起学习成长！**

ata）😗*

```
* 结构化数据是按照预定义的数据模型组织的数据，通常存储在关系型数据库中。

```

[外链图片转存中…(img-O3PbqTdO-1715618669810)]
  
[外链图片转存中…(img-MujsFa1l-1715618669810)]

**网上学习资料一大堆，但如果学到的知识不成体系，遇到问题时只是浅尝辄止，不再深入研究，那么很难做到真正的技术提升。**

**[需要这份系统化资料的朋友，可以戳这里获取](https://bbs.csdn.net/topics/618545628)**

**一个人可以走的很快，但一群人才能走的更远！不论你是正从事IT行业的老鸟或是对IT行业感兴趣的新人，都欢迎加入我们的的圈子（技术交流、学习资源、职场吐槽、大厂内推、面试辅导），让我们一起学习成长！**