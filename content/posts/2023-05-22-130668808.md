---
layout: post
title: "智能文档处理黑科技,拥抱更高效的数字世界"
date: 2023-05-22 08:51:07 +0800
description: "文档图像智能分析与处理》高峰论坛围绕文档图像处理及OCR领域的前沿技术展开“头脑风暴”，共同交流文档"
keywords: "智能文档处理"
categories: ['前沿资讯']
tags: ['计算机视觉', '科技', '机器学习', '人工智能']
artid: "130668808"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=130668808
    alt: "智能文档处理黑科技,拥抱更高效的数字世界"
render_with_liquid: false
featuredImage: https://bing.ee123.net/img/rand?artid=130668808
featuredImagePreview: https://bing.ee123.net/img/rand?artid=130668808
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     智能文档处理黑科技，拥抱更高效的数字世界
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-tomorrow-night-eighties" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
    </p>
    <div class="toc">
     <h4>
      目录
     </h4>
     <ul>
      <li>
       <a href="#0__2" rel="nofollow">
        0 写在前面
       </a>
      </li>
      <li>
       <a href="#1__10" rel="nofollow">
        1 为何要关注智慧文档？
       </a>
      </li>
      <li>
       <a href="#2__30" rel="nofollow">
        2 图像弯曲矫正
       </a>
      </li>
      <li>
       <a href="#3__63" rel="nofollow">
        3 手写板反光擦除
       </a>
      </li>
      <li>
       <a href="#4__85" rel="nofollow">
        4 版面元素检测
       </a>
      </li>
      <li>
       <a href="#5__99" rel="nofollow">
        5 文档篡改检测
       </a>
      </li>
      <li>
       <a href="#_121" rel="nofollow">
        总结
       </a>
      </li>
     </ul>
    </div>
    <p>
    </p>
    <h2>
     <a id="0__2">
     </a>
     0 写在前面
    </h2>
    <p>
     近期，中国图象图形学学会文档图像分析与识别专业委员会与上海合合信息科技有限公司联合打造了
     <font color="#f00">
      <strong>
       《文档图像智能分析与处理》
      </strong>
     </font>
     高峰论坛。论坛特别邀请了来自中科院自动化研究所、北京大学、中科大的学术专家与华为等知名企业的研究者们，围绕文档图像处理及OCR领域的前沿技术展开“头脑风暴”，共同交流文档图像分析与处理的前沿学术进展、在典型行业的规模化应用情况，并探讨未来技术及产业发展趋势。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/552f175afe23a532620c9a71cce163b5.png#pic_center" width="650"/>
    </p>
    <p>
     很荣幸听了这次论坛，使我对文档智能识别技术有了更加深入的了解，也让我认识到了其中涵盖的技术在实际应用中的巨大潜力和挑战
    </p>
    <h2>
     <a id="1__10">
     </a>
     1 为何要关注智慧文档？
    </h2>
    <p>
     随着信息技术的发展和应用场景的不断扩大，人们需要处理和利用大量的文档信息。而传统的手动处理方法效率低下，无法满足现代生活和工作的需求。
     <strong>
      文档图像智能分析与处理
     </strong>
     就是一个重要且极具挑战性的研究问题，智能文档识别技术基于人工智能和机器学习等技术，可以自动识别文档中的各种信息，如文字、图像、表格、条码等，然后将其分类、归档、摘要、提取等处理。
    </p>
    <p>
     文档图像智能分析与处理技术被广泛应用在人们生活的方方面面，比如银行票据的自动分析处理、快递运单的自动识别、教科书的分析与识别、古籍文稿的分析与理解、数字档案、数字图书馆等等，极大地提高了信息的检索、处理、传播速率。总之，文档图像分析与识别技术的出现和发展极大地方便了人们的生活，也极大地促进了我们的社会向智能化、数字化、信息化发展。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/c2ef8cb2a785d0d10c093f81e19bf64a.png#pic_center" width="650"/>
    </p>
    <p>
     文档图像智能分析与处理的难点在于文档的多样性和复杂性：文档类型和格式繁多，包括报告、合同、发票、证明、证件等等。不同类型的文档有不同的格式和布局，难以用统一的方法处理。而且智能文档处理受到图像质量、文字字体、文字大小、文字颜色等噪声因素的影响，容易出现误识别。此外，还有图像质量不一、文档获取繁琐等诸多问题。
    </p>
    <p>
     针对这些问题及其背后的技术，合合信息的丁凯博士进行了深入的探讨和分析，相信对这个领域感兴趣的同学一定有所收获！
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/3f796c876c7ffda37a514b36f1986366.png#pic_center" width="650"/>
    </p>
    <h2>
     <a id="2__30">
     </a>
     2 图像弯曲矫正
    </h2>
    <p>
     现代神经科学表明，哺乳动物大脑的初级视觉皮层的主要工作就是进行图像的字典表示，因为视觉是人类最重要的感觉——据不完全统计，至少80%以上的外界信息由视觉获得。然而，计算机获取图像的过程相当于用二维平面对三维客观世界进行降维表示，其中降低的维度称为深度，就像我们无法理解四维、五维等高维空间意义，二维平面图像因为维度丢失，导致图像处理的困难。
    </p>
    <p>
     因为相机硬件不符合理论上透视相机模型针孔无限小的假设，所以真实图像会产生明显的径向失真——场景中的线条在图像中显示为曲线。径向畸变(Radial Distortion)有两种类型：筒体畸变(Barrel Distortion)与枕形失真(Pincushion Distortion)。此外由于相机组装过程中，透镜不能和成像面严格平行，会引入切向畸变(Tangential Distortion)，再加上视觉文档图像的拍摄视角一般不垂直于文档平面，产生文档图像的变形和扭曲。例如比较厚重的书籍在展开后其书脊两侧文字区会出现向内弯曲的情况。由此可见，扭曲文档的形变情况要比平面文档要复杂，对其分析和矫正的难度也比平面文档图像要高。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/b3a42ae32350974f090ba3e92a9e101e.png#pic_center" width="650"/>
    </p>
    <p>
     在高峰论坛上，合合信息介绍了几种技术路线：
    </p>
    <ul>
     <li>
      基于文本行线拟合和坐标变换方法(2003~2015)
     </li>
     <li>
      基于文本行线坐标变换的优化方法(2015~2019)
     </li>
     <li>
      基于偏移场学习的方法(2019~2022)
     </li>
    </ul>
    <p>
     对于基本拟合、变换或优化等传统方法，存在一些缺陷，例如：在扭曲比较严重的文本区域还可能会定位错误、在复杂的版面或包含有图像的文档中识别精度下降等。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/319e488247362c9d20ac14a61c73e54e.png#pic_center" width="650"/>
    </p>
    <p>
     近年来，合合信息采用的基于偏移场的学习方法大大改善了上述缺陷。那么什么是偏移场呢？广义来说，图像的灰度不均匀性通常称为
     <font color="#4a86e8">
      <strong>
       偏移场
      </strong>
     </font>
     。灰度不均匀性的存在会影响图像后续的分析应用，许多图像处理方法都是建立在图像是均匀的基础之上的，这已然成为智能文档处理中的关键环节。
    </p>
    <p>
     国内外学者对偏移场弯曲矫正也展开了大量的研究。Guillemaud等人提出了参数化的EM算法主要是使用一组多项式基函数的线性组合来模拟偏移场，用以保证偏移场的光滑性。Pham等人提出了RFCM(Robust Fuzzy C-mean)算法，将对偏移场的估计值引入到模糊 C 均值聚类算法(FCM) 模型中,可以对存在偏移场的图像进行聚类分割，随之而来的是繁琐的计算。由此，Ahmed 等人提出了BCFCM算法，可以兼顾对偏移场的矫正和噪声的抑制，但是该算法受图像轮廓不同的影响较大，使得估计出的偏移场不平滑，同时该算法对图像中零梯度问题处理效果很差。Likar等人在偏移场矫正过程中引入了最小信息熵方法，得到了不错的偏移场矫正效果，但是该方法却不能很好的解决寻找曲面最优解的问题。基于此，Salvado等人提出了局部熵最小化策略LEM 取得了较好的改进结果，但是LEM算法对初始化参数的要求较高。
    </p>
    <p>
     合合信息采用的则是一种端到端结构的偏移场矫正方法，方法主要分为两个阶段：首先使用U-Net架构对输入图像进行分割，获得文本区域的掩模；接着将掩模输入到另一个U-Net网络中，该网络使用
     <font color="#4a86e8">
      <strong>
       自注意力机制(self-attention)
      </strong>
     </font>
     和
     <font color="#4a86e8">
      <strong>
       残差连接(residual connections)
      </strong>
     </font>
     对文档图像进行矫正。
    </p>
    <p>
     在第一阶段，U-Net网络首先将输入图像进行编码，然后将编码的特征图像进行解码，生成相同大小的输出掩模。在该过程中，U-Net通过
     <font color="#4a86e8">
      <strong>
       跳跃连接(skip connections)
      </strong>
     </font>
     和上采样操作保留输入图像的高层次特征，从而获得更加准确的掩模。
    </p>
    <p>
     在第二阶段，使用了另一个U-Net网络对输入图像进行矫正。该网络首先对输入图像进行特征提取，然后通过自注意力机制加强了特征图像中的相关性，从而更好地捕获了文档图像的全局和局部信息。接着，网络使用残差连接对输入特征和输出特征进行合并，从而得到矫正后的文档图像。
    </p>
    <p>
     合合信息采用的技术相比于其他方法，能够更好地处理文档图像中的扭曲和旋转等问题，且实现了很好的商业化效果。
    </p>
    <h2>
     <a id="3__63">
     </a>
     3 手写板反光擦除
    </h2>
    <p>
     随着各式各样的数码产品与数字仪器的快速普及，数字图像已经成人们生活
     <br/>
     中所接触的最重要的信息载体之一。但是，图像的质量受到各种各样的外部因素的影响，例如反光干扰。用户通常希望通过消除图像中的反射来提取出清晰的背景图像，因此将反射图像和背景图像进行分离的图像去反光任务是计算机视觉领域的活跃研究方向。
    </p>
    <p>
     图像去反光问题是不适定的，导致基于先验的方法去反光效果非常糟糕。普遍的基于先验的方法或多或少存在这样的问题，在面对实际中的反光图像时，泛化效果比较差。最近，深度卷积网络 (CNN) 在诸如图像识别、图像生成等计算机视觉任务取得了巨大的成功。同样的，在图像去任务上，深度卷积网络的强大表征能力同样表现出了不错的效果。合合信息正是采用基于学习的算法实现手写板反光擦除。
    </p>
    <p>
     具体来说，这个算法的原理是使用背景提取网络和文字提取网络来分离原始图像中的反光区域和文字区域，然后再将这些区域进行重组以实现图像去反光的效果。如下图所示
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/767775adf2ebd9929c0b8b56753f6efe.png#pic_center" width="650"/>
    </p>
    <p>
     原图像首先使用背景提取网络来检测图像中的背景区域。这可以通过对图像进行像素级别的分割来实现，其中像素被分类为属于背景或前景。在这个过程中，反光区域通常会被识别为前景区域。在训练时，背景提取网络会使用一组标注好的图像作为训练集，通过反向传播算法来更新网络中的权重参数，从而最小化损失函数。在测试时，网络会将输入图像作为网络的输入，经过前向传播计算得到每个像素点属于背景或前景的概率，然后根据概率阈值进行二值化处理，从而得到图像的分割结果。
    </p>
    <p>
     接下来，算法使用文字提取网络来检测图像中的文字区域。这可以通过使用一些先进的文字识别技术，如OCR来实现。在这个过程中，文字区域通常会被准确地识别出来，并被排除在反光区域之外。最后，算法将背景区域和非文字区域重组成一张新的图像，从而去除反光效果。这个过程通常涉及到一些图像处理技术，如图像融合和修补，以确保新图像的视觉效果与原始图像相似。
    </p>
    <p>
     真实样例的效果如下，可以看出反光擦除的效果很明显
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/310dde6adb42938d59b6af3292067524.png#pic_center" width="650"/>
    </p>
    <h2>
     <a id="4__85">
     </a>
     4 版面元素检测
    </h2>
    <p>
     文档版面分析即对文档图像按照不同的语义功能及区域类别进行分割和识别，分割出文本区、表格区、公式区、图形区等区域，并判断各区域所属的类别。区域分类是版面分析中的一个重要组成部分，它可以通过机器学习或深度学习的方法来识别出相应的特征区域。例如Bukhari通过对连通域进行分析，提取出一些简单的特征，再根据这些简单的特征产生具有更好表达能力的特征向量，最后由多层感知机将连通域分类，实现对复杂文档不同区域的分类。Konya和Paaß 采取最小生成树的方法，通过大量的文档来提取特征并构造出相应的特征向量，来对分类器进行训练，以完成文档版面分析任务。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/572b714cc93a6a12f22240f480cb407d.png#pic_center" width="650"/>
    </p>
    <p>
     版面元素检测也可以理解为一个图像语义分割问题。目前主流的语义分割方法是采用特征图先缩小后恢复的方法，如 U-Net、DeconvNet等语义分割网络先通过对图像的卷积和池化操作得到低分辨率的特征图，再通过上采样或反卷积将特征图恢复到高分辨率。但是这种方法存在一个缺点就是图像从高分辨率到低分辨率的过程中会损失信息，为了解决这个问题，2019年提出的HRNet（High Resolution Network）可以使图像在一个分支上始终保持高分辨率的同时，并行地对特征图进行下采样产生低分辨特征图，各个分辨率分别一个分支，然后各个分支不同分辨率特征图之间不断地进行特征融合来产生强大的高分辨率表示，从而使最终得到的特征图具有丰富的上下文信息，进一步提高了网络的分割准确率。
    </p>
    <p>
     目前，合合信息提供了关于版面检测、还原的系统级解决方案：涉及文字检测识别，版面元素检测识别，图层分离，排版布局等一系列深度学习模型，并需要通过合理的方式糅合各个模块，搭配文档渲染，最终生成可供用户编辑修改的Word/Excel文档，具有非常巨大的应用价值。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/3f4afa1b75dcbff74d0e01eb1f27a5c7.png#pic_center" width="650"/>
    </p>
    <h2>
     <a id="5__99">
     </a>
     5 文档篡改检测
    </h2>
    <p>
     <font color="#4a86e8">
      <strong>
       篡改文本检测(TTD，tampered text detection)
      </strong>
     </font>
     作为多媒体信息安全领域的一个新兴研究方向，是指通过对文本图像中纹理特征的分析，捕捉真实文本和篡改文本之间的纹理差异性，以确定文本图像中文字区域的真伪性。常见的应用场景有：谣言检测流水、合同造假识别、欺诈图像识别、学历造假检测、保单PS检测等。
    </p>
    <p>
     篡改文本检测任务有两个主要挑战。
    </p>
    <ul>
     <li>
      局部纹理差异性捕捉困难。篡改文本与真实文本仅存在局部纹理差异；
     </li>
     <li>
      真实和篡改文本检测精度平衡困难。
     </li>
    </ul>
    <p>
     相较传统的文本检测任务，篡改文本检测任务需要进一步区分篡改和真实文本。由于真实和篡改文本分类难度不一致，训练过程中网络无法平衡两类的学习过程，导致在测试过程中两类检测精度差异较大。上述挑战极大地限制了篡改文本检测方法的性能。因此，如何准确地捕捉局部纹理差异性，同时平衡篡改和真实类别学习难度，是目前篡改文本检测研究的重要方向。
    </p>
    <p>
     合合信息采用的是现在大火的Transformer结构。
     <font color="#4a86e8">
      <strong>
       Transformer
      </strong>
     </font>
     又是什么呢？它是一种用于自然语言处理、计算机视觉或其他
     <font color="#4a86e8">
      <strong>
       序列到序列（sequence-to-sequence）
      </strong>
     </font>
     任务的神经网络架构。
    </p>
    <p>
     Transformer
     <font color="#4a86e8">
      <strong>
       基于注意力机制（Attention Mechanism）
      </strong>
     </font>
     构建，其核心思想是在序列中进行全局信息的交互和捕捉，而不是像以往的
     <font color="#4a86e8">
      <strong>
       循环神经网络（RNN）
      </strong>
     </font>
     一样在序列中逐个位置处理信息。Transformer通过多个
     <font color="#4a86e8">
      <strong>
       自注意力层（Self-Attention Layer）
      </strong>
     </font>
     进行信息的交互和表示，而每个自注意力层包含了注意力机制的三个部分：查询（query）、键（key）和值（value）。现在流行的GPT
     <font color="#4a86e8">
      <strong>
       (Generative Pre-trained Transformer)
      </strong>
     </font>
     系列模型正是一种基于Transformer的语言模型。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/b19aaad04eeccfc6c9067dfaf10245b6.png#pic_center" width="650"/>
    </p>
    <center>
     图源网络，侵删
     <p>
     </p>
    </center>
    <p>
     具体来说，对于一个输入序列，Transformer将其转换为多个
     <font color="#4a86e8">
      <strong>
       词向量（word embeddings）
      </strong>
     </font>
     ，然后通过自注意力层进行特征提取。在自注意力层中，查询向量通过与所有键向量的相似度计算来计算注意力分数，这些分数用于加权求和值向量，最终得到每个位置的输出向量。然后，这些输出向量被馈送到下一个自注意力层或全连接层进行后续处理。
    </p>
    <p>
     相比于传统的序列模型，Transformer的优点在于可以并行处理输入序列，从而加速模型的训练和推断。此外，Transformer还能够有效地处理长序列，因为它可以在不受时间限制的情况下一次性处理整个序列，而不需要像RNN那样进行逐个位置的处理。
    </p>
    <h2>
     <a id="_121">
     </a>
     总结
    </h2>
    <p>
     介绍了这么多黑科技之后，想必大家对智能文档处理领域有了一定了解。合合信息的智能文字识别应用开发宗旨就是为了让世界更高效！合合信息深耕人工智能17年，全球累计用户下载量23亿，享有国内外发明专利113项，在顶级AI竞赛获得15项世界冠军，提供行业智能解决方案30个。合合信息提供了深受全球用户喜爱的效率工具，例如C端的名片全能王、扫描全能王等。相信合合信息在模式识别、深度学习、图像处理、自然语言处理等领域的深耕厚积薄发，用技术方案惠及更多的人。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a2f2f626c:6f672e6373646e2e6e65742f46524947494457494e5445522f:61727469636c652f64657461696c732f313330363638383038" class_="artid" style="display:none">
 </p>
</div>


