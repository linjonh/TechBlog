---
layout: post
title: "如何设计一个秒杀系统"
date: 2025-01-21 21:03:49 +0800
description: "本文作为许令波老师“如何设计一个秒杀系统？”这一课程的学习记录。同时也记录下今年项目中的一些原因导致"
keywords: "如何设计一个秒杀系统？"
categories: ['']
tags: ['高并发设计', '秒杀设计', '抢购']
artid: "85198469"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=85198469
    alt: "如何设计一个秒杀系统"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     如何设计一个秒杀系统？
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atelier-sulphurpool-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <blockquote>
     <p>
      本文作为许令波老师《如何设计一个秒杀系统》这一课程的学习记录。
      <br/>
      同时也记录下今年项目中的一些原因导致秒杀、抢购服务器宕机
     </p>
    </blockquote>
    <h3>
     秒杀系统的关键点
    </h3>
    秒杀系统其实主要解决2个问题，一个是并发读，一个是并发写。整体概况为“稳、准、快”
    <ul>
     <li>
      <strong>
       高性能。
      </strong>
      秒杀涉及大量的并发读和并发写，因此支持高并发访问这点非常关键。本文将从设计数据的动静分离方案、热点的发现与隔离、请求的削峰与分层过滤、服务端的极致优化这 4 个方面重点介绍。
     </li>
     <li>
      <strong>
       一致性。
      </strong>
      秒杀中商品减库存的实现方式同样关键。可想而知，有限数量的商品在同一时刻被很多倍的请求同时来减库存，减库存又分为“拍下减库存”“付款减库存”以及预扣等几种，在大并发更新的过程中都要保证数据的准确性，其难度可想而知。
     </li>
     <li>
      <strong>
       高可用。
      </strong>
      虽然介绍了很多极致的优化思路，但现实中总难免出现一些我们考虑不到的情况，所以要保证系统的高可用和正确性，我们还要设计一个 PlanB 来兜底，以便在最坏情况发生时仍然能够从容应对。
     </li>
    </ul>
    <h3>
     1.设计秒杀系统时应该注意的5个架构原则
    </h3>
    <p>
     <mark>
      总结来说就是“4 要 1 不要”
     </mark>
    </p>
    <ul>
     <li>
      <p>
       <strong>
        数据要尽量少。
       </strong>
       所谓“数据要尽量少”，请求的数据包括请求包体和返回包体，字段精简。不管是请求数据还是返回数据都需要服务器做处理，而服务器在写网络时通常都要做压缩和字符编码，这些都非常消耗 CPU，所以减少传输的数据量可以显著减少 CPU 的使用。数据库也容易成为一个瓶颈，所以和数据库打交道越少越好，数据越简单、越小则越好。
      </p>
     </li>
     <li>
      <p>
       <strong>
        请求数要尽量少。
       </strong>
       这里的请求数包括了页面依赖的 CSS/JavaScript、图片、加载这些文件都需要建立连接要做三次握手，另外，如果不同请求的域名不一样的话，还涉及这些域名的 DNS 解析，可能会耗时更久。所以，减少请求数可以显著减少以上这些因素导致的资源消耗。
      </p>
     </li>
     <li>
      <p>
       <strong>
        路径要尽量短。
       </strong>
       所谓“路径”，就是用户发出请求到返回数据这个过程中，需求经过的中间的节点数。所以缩短请求路径不仅可以增加可用性，同样可以有效提升性能（减少中间节点可以减少数据的序列化与反序列化），并减少延时（可以减少网络传输耗时）。
       <mark>
        要缩短访问路径有一种办法，就是多个相互强依赖的应用合并部署在一起，把远程过程调用（RPC）变成 JVM 内部之间的方法调用，也就是同一个服务同一个web容器
       </mark>
       。
       <font color="#FF0000">
        <strong>
         这里把应用合并部署在一起，是和分布式微服务并不是矛盾的，只是要从中取舍
        </strong>
       </font>
      </p>
     </li>
     <li>
      <p>
       <strong>
        依赖要尽量少。
       </strong>
       所谓依赖，指的是要完成一次用户请求必须依赖的系统或者服务，这里的依赖指的是强依赖。比如说你要展示秒杀页面，而这个页面必须强依赖商品信息、用户信息，还有其他如优惠券、成交列表等这些对秒杀不是非要不可的信息（弱依赖），这些弱依赖在紧急情况下就可以去掉。防止强依赖被弱依赖拖垮，比如优惠券服务无法提供优惠券列表，导致拖垮支付服务是不行的
      </p>
     </li>
     <li>
      <p>
       <strong>
        不要有单点。
       </strong>
       单点是系统架构的大忌，单点意味着没有备份，风险不可控，设计分布式系统最重要的原则就是“消除单点”。避免单点关键点是避免将服务的状态和机器绑定，即服务无状态化，这样服务就可以在机器中随意移动。
      </p>
     </li>
    </ul>
    <h3>
     2.如何做好动静分离
    </h3>
    <ul>
     <li>
      <strong>
       URL 唯一化。
      </strong>
      商品详情系统天然地就可以做到 URL 唯一化，每个商品都由 ID 来标识，那么
      <a href="http://item.xxx.com/item.htm?id=xxxx" rel="nofollow">
       http://item.xxx.com/item.htm?id=xxxx
      </a>
      就可以作为唯一的 URL 标识。就
      <mark>
       以 URL 作为缓存的 Key
      </mark>
      。
     </li>
     <li>
      <strong>
       分离浏览者相关的因素。
      </strong>
      浏览者相关的因素包括是否已登录，以及登录身份等，这些相关因素我们可以单独拆分出来，通过动态请求来获取。
     </li>
     <li>
      <strong>
       分离时间因素。
      </strong>
      服务端输出的时间也通过动态请求获取。
     </li>
     <li>
      <strong>
       异步化地域因素。
      </strong>
      详情页面上与地域相关的因素做成异步方式获取，当然你也可以通过动态请求方式获取，只是这里通过异步获取更合适。
     </li>
     <li>
      <strong>
       去掉 Cookie。
      </strong>
      去掉 Cookie 并不是用户端收到的页面就不含 Cookie 了，而是说，在缓存的静态数据中不含有 Cookie。
      <br/>
      <mark>
       分离出动态内容之后，如何组织这些内容页就变得非常关键了。这里将这些信息 JSON 化（用 JSON 格式组织这些数据），以方便前端获取。
      </mark>
     </li>
    </ul>
    <p>
     前面我们介绍里用缓存的方式来处理静态数据。而
     <strong>
      动态内容的处理通常有两种方案：ESI（Edge Side Includes）方案和 CSI（Client Side Include）方案。
     </strong>
    </p>
    <p>
     ESI 方案（或者 SSI）：即在 Web 代理服务器上做动态内容请求，并将请求插入到静态页面中，当用户拿到页面时已经是一个完整的页面了。这种方式对服务端性能有些影响，但是用户体验较好。
     <br/>
     CSI 方案。即单独发起一个异步 JavaScript 请求，以向服务端获取动态内容。这种方式服务端性能更佳，但是用户端页面可能会延时，体验稍差。
    </p>
    <p>
     <mark>
      动静分离的几种架构方案
     </mark>
     <br/>
     前面我们通过改造把静态数据和动态数据做了分离，那么如何在系统架构上进一步对这些动态和静态数据重新组合，再完整地输出给用户根据架构上的复杂度，有 3 种方案可选：
    </p>
    <ul>
     <li>
      <p>
       <strong>
        实体机单机部署
       </strong>
       <br/>
       虚拟机改为实体机，增大 Cache 容量，采用了一致性 Hash 分组的方式来提升命中率，将 Cache 分成若干组，是希望能达到命中率和访问热点的平衡。Hash 分组越少，缓存的命中率肯定就会越高，但短板是也会使单个商品集中在一个分组中，容易导致 Cache 被击穿。
       <mark>
        没有网络瓶颈，而且能使用大内存；既能提升命中率，又能减少 Gzip 压缩；优势很明显，但是一定程度上也造成了 CPU 的浪费，因为单个的 Java 进程很难用完整个实体机的 CPU。
       </mark>
      </p>
     </li>
     <li>
      <p>
       <strong>
        统一 Cache 层
       </strong>
       <br/>
       单独一个 Cache 层，减少应用接入时使用 Cache 的成本。统一 Cache 的方案易于维护，
       <mark>
        可以共享内存，最大化利用内存，不同系统之间的内存可以动态切换，从而能够有效应对各种攻击
       </mark>
       。但是也带来了其他一些问题，比如缓存更加集中，导致：
       <font color="#FF0000">
        <strong>
         Cache 层内部交换网络成为瓶颈；缓存服务器的网卡也会是瓶颈；机器少风险较大，挂掉一台就会影响很大一部分缓存数据
        </strong>
       </font>
       。要解决上面这些问题，可以
       <mark>
        再对 Cache 做 Hash 分组，即一组 Cache 缓存的内容相同，这样能够避免热点数据过度集中导致新的瓶颈产生
       </mark>
       。
      </p>
     </li>
     <li>
      <p>
       <strong>
        上 CDN
       </strong>
       <br/>
       在将整个系统做动静分离后，我们自然会想到更进一步的方案，就是将 Cache 进一步前移到 CDN 上，因为 CDN
       <mark>
        离用户最近，效果会更好
       </mark>
       。有以下几个问题需要解决。
       <br/>
       <mark>
        靠近访问量比较集中的地区；离主站相对较远；节点到主站间的网络比较好，而且稳定；节点容量比较大，不会占用其他 CDN 太多的资源。
       </mark>
       <font color="#FF0000">
        <strong>
         节点不要太多。
        </strong>
       </font>
       <br/>
       除此之外，CDN 化部署方案还有以下几个特点：
       <br/>
       把整个页面缓存在用户浏览器中；
       <br/>
       如果强制刷新整个页面，也会请求 CDN；
       <br/>
       实际有效请求，只是用户对“刷新抢宝”按钮的点击。
       <br/>
       这样就把 90% 的静态数据缓存在了用户端或者 CDN 上，当真正秒杀时，用户只需要点击特殊的“刷新抢宝”按钮，而不需要刷新整个页面。这样，系统只是向服务端请求很少的有效数据，而不需要重复请求大量的静态数据。
      </p>
     </li>
    </ul>
    <h3>
     3.如何有针对性的处理好系统的“热点数据”
    </h3>
    <ul>
     <li>
      <p>
       <strong>
        为什么要关注热点
       </strong>
       <br/>
       <font color="#FF0000">
        <strong>
         2/8原则
        </strong>
       </font>
       <br/>
       数据的访问存在热点，20%的数据占用80%的访问流量，这20%数据就是热点数据
      </p>
     </li>
     <li>
      <p>
       <strong>
        什么是“热点”
       </strong>
       <br/>
       热点分为热点操作和热点数据。所谓“热点操作”，例如大量的刷新页面、大量的添加购物车、双十一零点大量的下单等都属于此类操作。对系统来说，这些操作可以抽象为“读请求”和“写请求”，这两种热点请求的处理方式大相径庭，读请求的优化空间要大一些，而写请求的瓶颈一般都在存储层，优化的思路就是根据 CAP 理论做平衡，这个内容在“减库存”中再详细介绍。
      </p>
      <p>
       而“热点数据”比较好理解，那就是用户的热点请求对应的数据。而热点数据又分为“静态热点数据”和“动态热点数据”。
      </p>
      <p>
       所谓“静态热点数据”，就是能够提前预测的热点数据。例如通过大数据分析来提前发现热点商品，比如我们分析历史成交记录、用户的购物车记录，来发现哪些商品可能更热门、更好卖，这些都是可以提前分析出来的热点。
      </p>
      <p>
       所谓“动态热点数据”，就是不能被提前预测到的，系统在运行过程中临时产生的热点。例如，卖家在抖音上做了广告，然后商品一下就火了，导致它在短时间内被大量购买。
      </p>
     </li>
     <li>
      <p>
       <strong>
        发现热点数据
       </strong>
       <br/>
       前面介绍了如何对单个秒杀商品的页面数据进行动静分离，以便针对性地对静态数据做优化处理，那么另外一个关键的问题来了：如何发现这些秒杀商品，或者更准确地说，如何发现热点商品呢？
      </p>
      <p>
       <mark>
        发现静态热点数据
       </mark>
       <br/>
       静态热点数据可以通过商业手段，例如强制让卖家通过报名参加的方式提前把热点商品筛选出来、或者对买家每天访问的商品进行大数据计算，然后统计出 TOP N 的商品，我们可以认为这些 TOP N 的商品就是热点商品。
      </p>
      <p>
       <mark>
        发现动态热点数据
       </mark>
       <br/>
       构建一个异步的系统，它可以收集交易链路上各个环节中的中间件产品的热点 Key，如 Nginx、缓存、RPC 服务框架等这些中间件（一些中间件产品本身已经有热点统计模块）。
       <br/>
       建立一个热点上报和可以按照需求订阅的热点服务的下发规范，主要目的是通过交易链路上各个系统（包括详情、购物车、交易、优惠、库存、物流等）访问的时间差，把上游已经发现的热点透传给下游系统，提前做好保护。比如，对于大促高峰期，详情系统是最早知道的，在统一接入层上 Nginx 模块统计的热点 URL。
       <br/>
       将上游系统收集的热点数据发送到热点服务台，然后下游系统（如交易系统）就会知道哪些商品会被频繁调用，然后做热点保护。
      </p>
     </li>
     <li>
      <p>
       <strong>
        处理热点数据
       </strong>
       <br/>
       <mark>
        处理热点数据通常有几种思路：一是优化，二是限制，三是隔离。
       </mark>
       <br/>
       <mark>
        优化
       </mark>
       。优化热点数据最有效的办法就是缓存热点数据，如果热点数据做了动静分离，那么可以长期缓存静态数据。但是，缓存热点数据更多的是“临时”缓存，即不管是静态数据还是动态数据，都用一个队列短暂地缓存数秒钟，由于队列长度有限，可以采用 LRU 淘汰算法替换。
      </p>
      <p>
       <mark>
        限制
       </mark>
       。限制更多的是一种保护机制，限制的办法也有很多，例如对被访问商品的 ID 做一致性 Hash，然后根据 Hash 做分桶，每个分桶设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点商品占用太多的服务器资源，而使其他请求始终得不到服务器的处理资源。
      </p>
      <p>
       <mark>
        隔离
       </mark>
       。秒杀系统设计的第一个原则就是将这种热点数据隔离出来，不要让 1% 的请求影响到另外的 99%，隔离出来后也更方便对这 1% 的请求做针对性的优化。
       <br/>
       具体到“秒杀”业务，我们可以在以下几个层次实现隔离。
      </p>
     </li>
    </ul>
    <p>
     <strong>
      业务隔离。
     </strong>
     把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就有了已知热点，因此可以提前做好预热。
     <br/>
     <strong>
      系统隔离。
     </strong>
     系统隔离更多的是运行时的隔离，可以通过分组部署的方式和另外 99% 分开。秒杀可以申请单独的域名，目的也是让请求落到不同的集群中。
     <br/>
     <strong>
      数据隔离。
     </strong>
     秒杀所调用的数据大部分都是热点数据，比如会启用单独的 Cache 集群或者 MySQL 数据库来放热点数据，目的也是不想 0.01% 的数据有机会影响 99.99% 数据。
    </p>
    <h3>
     4.流量削峰应该怎么做
    </h3>
    <p>
     为什么要削峰
     <br/>
     为什么要削峰呢？或者说峰值会带来哪些坏处？
    </p>
    <p>
     我们知道服务器的处理资源是恒定的，你用或者不用它的处理能力都是一样的，所以出现峰值的话，很容易导致忙到处理不过来，闲的时候却又没有什么要处理。但是由于要保证服务质量，我们的很多处理资源只能按照忙的时候来预估，而这会导致资源的一个浪费。
    </p>
    <p>
     这就好比因为存在早高峰和晚高峰的问题，所以有了错峰限行的解决方案。
     <font color="#FF0000">
      <strong>
       削峰的存在，一是可以让服务端处理变得更加平稳，二是可以节省服务器的资源成本
      </strong>
     </font>
     。针对秒杀这一场景，
     <mark>
      削峰
     </mark>
     从
     <mark>
      本质上
     </mark>
     来说
     <mark>
      就是更多地延缓用户请求的发出，以便减少和过滤掉一些无效请求
     </mark>
     ，它遵从“请求数要尽量少”的原则。
    </p>
    <p>
     今天，我就来介绍一下流量削峰的一些操作思路：
     <mark>
      排队、答题、分层过滤。这几种方式都是无损
     </mark>
     （即不会损失用户的发出请求）的实现方案，当然还有些有损的实现方案，包括我们后面要介绍的关于稳定性的一些办法，比如限流和机器负载保护等一些强制措施也能达到削峰保护的目的，当然这都是不得已的一些措施，因此就不归类到这里了。
    </p>
    <ul>
     <li>
      <p>
       排队
       <br/>
       <mark>
        用消息队列来缓冲瞬时流量，把同步的直接调用转换成异步的间接推送
       </mark>
      </p>
     </li>
     <li>
      <p>
       答题
       <br/>
       这主要是为了增加购买的复杂度，从而达到两个目的。
      </p>
      <ul>
       <li>
        第一个目的是防止秒杀器作弊。
       </li>
       <li>
        第二个目的其实就是延缓请求，起到对请求流量进行削峰的作用，从而让系统能够更好地支持瞬时的流量高峰。
       </li>
      </ul>
     </li>
     <li>
      <p>
       分层过滤
       <br/>
       前面介绍的排队和答题要么是少发请求，要么对发出来的请求进行缓冲，而针对秒杀场景还有一种方法，就是对请求进行分层过滤，从而过滤掉一些无效的请求。分层过滤其实就是采用“漏斗”式设计来处理请求的，如下图所示。
      </p>
      <p>
       分层过滤的核心思想是：在不同的层次尽可能地过滤掉无效请求，让“漏斗”最末端的才是有效请求。而要达到这种效果，我们就必须对数据做分层的校验。
      </p>
     </li>
    </ul>
    <p>
     其中，
     <mark>
      队列缓冲方式更加通用
     </mark>
     ，它适用于内部上下游系统之间调用请求不平缓的场景，由于内部系统的服务质量要求不能随意丢弃请求，所以使用消息队列能起到很好的削峰和缓冲作用。
    </p>
    <p>
     而
     <mark>
      答题更适用于秒杀或者营销活动等应用场景
     </mark>
     ，在请求发起端就控制发起请求的速度，因为越到后面无效请求也会越多，所以配合后面介绍的分层拦截的方式，可以更进一步减少无效请求对系统资源的消耗。
    </p>
    <p>
     <mark>
      分层过滤非常适合交易性的写请求，比如减库存或者拼车这种场景
     </mark>
     ，在读的时候需要知道还有没有库存或者是否还有剩余空座位。但是由于库存和座位又是不停变化的，所以读的数据是否一定要非常准确呢？其实不一定，你可以放一些请求过去，然后在真正减的时候再做强一致性保证，这样既过滤一些请求又解决了强一致性读的瓶颈。
    </p>
    <p>
     不过，在削峰的处理方式上除了采用技术手段，其实还可以采用业务手段来达到一定效果，例如在零点开启大促的时候采用发放优惠券、发起抽奖活动等方式，将一部分流量分散到其他地方，这样也能起到缓冲流量的作用。
     <br/>
     <mark>
      就像12306分时段发放各个热点城市的票
     </mark>
    </p>
    <h3>
     5.影响性能的因素有哪些？又该如何提高？
    </h3>
    <ul>
     <li>
      <p>
       “
       <strong>
        性能”是什么？
       </strong>
       <br/>
       服务设备不同对性能的定义也是不一样的，例如 CPU 主要看主频、磁盘主要看 IOPS（Input/Output Operations Per Second，即每秒进行读写操作的次数）。而系统服务端性能，一般用 QPS（Query Per Second，每秒请求数）来衡量，还有一个影响和 QPS 也息息相关，那就是响应时间（Response Time，RT），它可以理解为服务器处理响应的耗时。
      </p>
      <p>
       但是你可能想到响应时间总有一个极限，不可能无限下降，所以又出现了另外一个维度，即通过多线程，来处理请求。这样理论上就变成了“总 QPS =（1000ms / 响应时间）× 线程数量”，这样性能就和两个因素相关了，一个是一次响应的服务端耗时，一个是处理请求的线程数。
      </p>
      <p>
       对于大部分的 Web 系统而言，响应时间一般都是由 CPU 执行时间和线程等待时间（比如 RPC、IO 等待、Sleep、Wait 等）组成，即服务器在处理一个请求时，一部分是 CPU 本身在做运算，还有一部分是在各种等待。
      </p>
      <p>
       其实，
       <mark>
        真正对性能有影响的是 CPU 的执行时间。这也很好理解，因为 CPU 的执行真正消耗了服务器的资源。经过实际的测试，如果减少 CPU 一半的执行时间，就可以增加一倍的 QPS。也就是说，我们应该致力于减少 CPU 的执行时间。
       </mark>
      </p>
      <p>
       其次，我们再来看看线程数对 QPS 的影响。
      </p>
      <p>
       单看“总 QPS”的计算公式，你会觉得线程数越多 QPS 也就会越高，但这会一直正确吗？显然不是，
       <mark>
        线程数不是越多越好，因为线程本身也消耗资源，也受到其他因素的制约。例如，线程越多系统的线程切换成本就会越高，而且每个线程也都会耗费一定内存。
       </mark>
      </p>
      <p>
       那么，设置什么样的线程数最合理呢？其实很多多线程的场景都有一个默认配置，即“线程数 = 2 * CPU 核数 + 1”。除去这个配置，还有一个根据最佳实践得出来的公式：
      </p>
     </li>
    </ul>
    <p>
     <mark>
      当然，最好的办法是通过性能测试来发现最佳的线程数。
     </mark>
    </p>
    <p>
     换句话说，要提升性能我们就要减少 CPU 的执行时间，另外就是要设置一个合理的并发线程数，通过这两方面来显著提升服务器的性能。
    </p>
    <ul>
     <li>
      <p>
       <strong>
        如何发现瓶颈
       </strong>
       <br/>
       就服务器而言，会出现瓶颈的地方有很多，例如 CPU、内存、磁盘以及网络等都可能会导致瓶颈。此外，不同的系统对瓶颈的关注度也不一样，例如对缓存系统而言，制约它的是内存，而对存储型系统来说 I/O 更容易是瓶颈。
       <mark>
        当 QPS 达到极限时，你的服务器的 CPU 使用率是不是超过了 95%，如果没有超过，那么表示 CPU 还有提升的空间，要么是有锁限制，要么是有过多的本地 I/O 等待发生。
       </mark>
      </p>
      <p>
       那么，如何发现 CPU 的瓶颈呢？其实有很多 CPU 诊断工具可以发现 CPU 的消耗，
       <mark>
        最常用的就是 JProfiler 和 Yourkit 这两个工具，它们可以列出整个请求中每个函数的 CPU 执行时间，可以发现哪个函数消耗的 CPU 时间最多
       </mark>
       ，以便你有针对性地做优化。
      </p>
     </li>
     <li>
      <p>
       <font color="#FF0000">
        <strong>
         真实项目中遇到的问题
        </strong>
       </font>
       <br/>
       <strong>
        场景：
       </strong>
       一个基于小程序的商城，在只有3台服务器集群的情况下。面对业务方突然的大促销。服务器直接瘫痪，下面是按照顺序遇到的问题。
      </p>
      <p>
       <font color="#FF0000">
        <strong>
         问题1：
        </strong>
       </font>
       服务器集群数量不够。
      </p>
      <p>
       <font color="#FF0000">
        <strong>
         问题2：
        </strong>
       </font>
       首页有三个请求，而且请求查询商品列表都是 select * from ，导致很多冗余数据。违背了上文说的四要一不要中的“数据要尽量少”，“请求要尽量少”原则。通过精简业务代码返回数据，把因为带宽不够的因素去掉了。
      </p>
      <p>
       <font color="#FF0000">
        <strong>
         问题3：
        </strong>
       </font>
       首页接口中存在直接访问数据库的代码，导致数据库连接不够，通过把商品列表redis缓存，图片走CDN，库存采用单独的key，返回之前组装对象，解决了访问数据库造成数据库崩溃。
      </p>
      <p>
       <font color="#FF0000">
        <strong>
         问题4：
        </strong>
       </font>
       首页大量使用缓存，造成redis连接数不够，而云服务RDS产品费用太高，改用云主机自己安装redis，组建10台redis集群。采用key的ASCII取模，均衡到对于的redis服务器
      </p>
      <p>
       <font color="#FF0000">
        <strong>
         问题5：
        </strong>
       </font>
       因为上述连接数的问题出现，优化了一波tomcat、mysql、nginx、redis等中间件的最大连接数，JVM性能调优等。
      </p>
      <p>
       <mark>
        <strong>
         以上问题以及解决方式只是抛砖引玉，有问题敬请指出
        </strong>
       </mark>
      </p>
     </li>
    </ul>
    <h3>
     6.秒杀过程中“减库存”设计的核心逻辑
    </h3>
    <p>
     说到秒杀那么库存扣减便是难题之一了。
     <mark>
      不要超卖，这是大前提。
     </mark>
     <br/>
     <mark>
      减库存有哪几种方式
     </mark>
    </p>
    <ul>
     <li>
      <strong>
       下单减库存。
      </strong>
      即当买家下单后，在商品的总库存中减去买家购买数量。下单减库存是最简单的减库存方式，也是控制最精确的一种，下单时直接通过数据库的事务机制控制商品库存，这样一定不会出现超卖的情况。但是你要知道，有些人下完单可能并不会付款。
     </li>
     <li>
      <strong>
       付款减库存。
      </strong>
      即买家下单后，并不立即减库存，而是等到有用户付款后才真正减库存，否则库存一直保留给其他买家。但因为付款时才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况，因为可能商品已经被其他人买走了。
     </li>
     <li>
      <strong>
       预扣库存。
      </strong>
      这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如 10 分钟），超过这个时间，库存将会自动释放，释放后其他买家就可以继续购买。在买家付款前，系统会校验该订单的库存是否还有保留：如果没有保留，则再次尝试预扣；如果库存不足（也就是预扣失败）则不允许继续付款；如果预扣成功，则完成付款并实际地减去库存。
     </li>
    </ul>
    <p>
     <mark>
      下面就探讨下这几种方式的利弊
     </mark>
     <br/>
     <strong>
      下单扣减库存
     </strong>
     当卖家参加某个活动时，如果有竞争对手恶意下单将该卖家的商品全部下单，导致因为售罄，后面再取消订单。导致活动错过了商品的黄金售卖时间
    </p>
    <p>
     <strong>
      付款减库存
     </strong>
     可以解决上面恶意下单的问题。但是又会导致另外一个问题：库存超卖。假如有 100 件商品，就可能出现 300 人下单成功的情况，因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况，这尤其会发生在做活动的热门商品上。这样一来，就会导致很多买家下单成功但是付不了款，
     <mark>
      买家的购物体验自然比较差
     </mark>
     。
    </p>
    <p>
     <mark>
      大型秒杀中如何减库存？
     </mark>
     <br/>
     目前来看，
     <strong>
      业务系统中最常见的就是预扣库存方案
     </strong>
     ，像你在买机票、买电影票时，下单后一般都有个“有效付款时间”，超过这个时间订单自动释放，这都是典型的预扣库存方案。
    </p>
    <p>
     <mark>
      由于参加秒杀的商品，一般都是“抢到就是赚到”，所以成功下单后却不付款的情况比较少，再加上卖家对秒杀商品的库存有严格限制，所以秒杀商品采用“下单减库存”更加合理。另外，理论上由于“下单减库存”比“预扣库存”以及涉及第三方支付的“付款减库存”在逻辑上更为简单，所以性能上更占优势。
     </mark>
    </p>
    <p>
     “下单减库存”在数据一致性上，主要就是保证大并发请求时库存数据不能为负数，也就是要保证数据库中的库存字段值不能为负数，一般我们有多种解决方案：
    </p>
    <ul>
     <li>
      一种是在应用程序中通过事务来判断，即保证减后库存不能为负数，否则就回滚；
     </li>
     <li>
      另一种办法是直接设置数据库的字段数据为无符号整数，这样减后库存字段值小于零时会直接执行 SQL 语句来报错；
     </li>
     <li>
      再有一种就是使用 CASE WHEN 判断语句，例如这样的 SQL 语句：，如果update返回0说明没有更新。说明库存为0
     </li>
    </ul>
    <pre><code class="prism language-sql"><span class="token keyword">UPDATE</span> item <span class="token keyword">SET</span> inventory <span class="token operator">=</span> <span class="token keyword">CASE</span> <span class="token keyword">WHEN</span> inventory <span class="token operator">&gt;=</span> xxx <span class="token keyword">THEN</span> inventory<span class="token operator">-</span>xxx <span class="token keyword">ELSE</span> inventory <span class="token keyword">END</span>
</code></pre>
    <p>
     <mark>
      秒杀减库存的极致优化
     </mark>
    </p>
    <p>
     秒杀商品和普通商品的减库存还是有些差异的，例如商品数量比较少，交易时间段也比较短，因此这里有一个大胆的假设，即能否把秒杀商品减库存直接放到缓存系统中实现，也就是直接在缓存中减库存或者在一个带有持久化功能的缓存系统（如 Redis）中完成呢？
    </p>
    <p>
     如果你的秒杀商品的减库存逻辑非常单一，比如没有复杂的 SKU 库存和总库存这种联动关系的话，我觉得完全可以。但是如果有比较复杂的减库存逻辑，或者需要使用事务，你还是必须在数据库中完成减库存。
    </p>
    <h3>
     7.如何设计兜底方案？
    </h3>
    在大流量的迅猛冲击下，不管什么系统都曾经或多或少发生过宕机的情况。当一个系统面临持续的大流量时，它其实很难单靠自身调整来恢复状态，你必须等待流量自然下降或者人为地把流量切走才行，这无疑会严重影响用户的购物体验。所以我们需要需要“反脆弱”。也就是设计一个 Plan B 方案来兜底，这样在最坏情况发生时我们仍然能够从容应对。今天，我们就来看下兜底方案设计的一些具体思路。
    <p>
     高可用建设应该从哪里着手
     <br/>
     说到系统的高可用建设，它其实是一个系统工程，需要考虑到系统建设的各个阶段，也就是说它其实贯穿了系统建设的整个生命周期，如下图所示：
     <br/>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/e6813d9f36ffa107c65f172077e79fbe.png"/>
    </p>
    <p>
     接下来，我们分别看一下。
    </p>
    <ul>
     <li>
      <strong>
       架构阶段
      </strong>
      ：架构阶段主要考虑系统的可扩展性和容错性，避免单点
     </li>
     <li>
      <strong>
       编码阶段
      </strong>
      ：编码保证代码的健壮性，例如涉及远程调用问题时，要设置合理的超时退出机制，防止被其他系统拖垮，也要对调用的返回结果集有预期，防止返回的结果超出程序处理范围，最常见的做法就是对错误异常进行捕获，对无法预料的错误要有默认处理结果。
     </li>
     <li>
      <strong>
       测试阶段
      </strong>
      ：测试主要是保证测试用例的覆盖度，保证最坏情况发生时，我们也有相应的处理流程。
     </li>
     <li>
      <strong>
       发布阶段
      </strong>
      ：发布时也有一些地方需要注意，因为发布时最容易出现错误，因此要有紧急的回滚机制。
     </li>
     <li>
      <strong>
       运行阶段
      </strong>
      ：运行时是系统的常态，系统大部分时间都会处于运行态，运行态最重要的是对系统的监控要准确及时，发现问题能够准确报警并且报警数据要准确详细，以便于排查问题。
     </li>
     <li>
      <strong>
       故障发生
      </strong>
      ：故障发生时首先最重要的就是及时止损，例如由于程序问题导致商品价格错误，那就要及时下架商品或者关闭购买链接，防止造成重大资产损失。然后就是要能够及时恢复服务，并定位原因解决问题。
      <br/>
      为什么系统的高可用建设要放到整个生命周期中全面考虑？因为我们在每个环节中都可能犯错，而有些环节犯的错，你在后面是无法弥补的。例如在架构阶段，你没有消除单点问题，那么系统上线后，遇到突发流量把单点给挂了，你就只能干瞪眼，有时候想加机器都加不进去。所以高可用建设是一个系统工程，必须在每个环节都做好。
     </li>
    </ul>
    <p>
     <mark>
      那么针对秒杀系统在遇到大流量时，应该从哪些方面来保障系统的稳定运行，所以更多的是看如何针对运行阶段进行处理，这就引出了接下来的内容：降级、限流和拒绝服务。
     </mark>
    </p>
    <ul>
     <li>
      <p>
       <mark>
        降级
       </mark>
       <br/>
       所谓“降级”，就是当系统的容量达到一定程度时，限制或者关闭系统的某些非核心功能，从而把有限的资源保留给更核心的业务。它是一个有目的、有计划的执行过程，所以对降级我们一般需要有一套预案来配合执行。如果我们把它系统化，就可以通过预案系统和开关系统来实现降级。
      </p>
      <p>
       降级方案可以这样设计：当秒杀流量达到 5w/s 时，把成交记录的获取从展示 20 条降级到只展示 5 条。“从 20 改到 5”这个操作由一个开关来实现，也就是设置一个能够从开关系统动态获取的系统参数。
      </p>
     </li>
     <li>
      <p>
       <mark>
        限流
       </mark>
       <br/>
       如果说降级是牺牲了一部分次要的功能和用户的体验效果，那么限流就是更极端的一种保护措施了。限流就是当系统容量达到瓶颈时，我们需要通过限制一部分流量来保护系统，并做到既可以人工执行开关，也支持自动化保护的措施。
      </p>
     </li>
    </ul>
    <p>
     在限流的实现手段上来讲，基于 QPS 和线程数的限流应用最多，最大 QPS 很容易通过压测提前获取，例如我们的系统最高支持 1w QPS 时，可以设置 8000 来进行限流保护。线程数限流在客户端比较有效，例如在远程调用时我们设置连接池的线程数，超出这个并发线程请求，就将线程进行排队或者直接超时丢弃。
    </p>
    <p>
     限流无疑会影响用户的正常请求，所以必然会导致一部分用户请求失败，因此在系统处理这种异常时一定要设置超时时间，防止因被限流的请求不能 fast fail（快速失败）而拖垮系统。
    </p>
    <ul>
     <li>
      <mark>
       拒绝服务
      </mark>
      <br/>
      如果限流还不能解决问题，最后一招就是直接拒绝服务了。
     </li>
    </ul>
    <p>
     当系统负载达到一定阈值时，例如 CPU 使用率达到 90% 或者系统 load 值达到 2*CPU 核数时，系统直接拒绝所有请求，这种方式是最暴力但也最有效的系统保护方式。例如秒杀系统，我们在如下几个环节设计过载保护：
    </p>
    <p>
     在最前端的 Nginx 上设置过载保护，当机器负载达到某个值时直接拒绝 HTTP 请求并返回 503 错误码，在 Java 层同样也可以设计过载保护。
    </p>
    <p>
     拒绝服务可以说是一种不得已的兜底方案，用以防止最坏情况发生，防止因把服务器压跨而长时间彻底无法提供服务。像这种系统过载保护虽然在过载时无法提供服务，但是系统仍然可以运作，当负载下降时又很容易恢复，所以每个系统和每个环节都应该设置这个兜底方案，对系统做最坏情况下的保护。
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="6874747073:3a2f2f626c6f672e6373646e2e6e65742f6c696272615f7473:2f61727469636c652f64657461696c732f3835313938343639" class_="artid" style="display:none">
 </p>
</div>


