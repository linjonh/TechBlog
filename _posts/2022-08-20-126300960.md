---
layout: post
title: 2022-08-20-手动写一个搜索引擎超详细
date: 2022-08-20 19:56:28 +0800
categories: [JavaWeb]
tags: [数据库,java,开发语言,mybatis,spring]
image:
  path: https://img-blog.csdnimg.cn/7cdb03241d1041168ddfcf0482d2f5c4.png?x-oss-process=image/resize,m_fixed,h_150
  alt: 手动写一个搜索引擎超详细
artid: 126300960
render_with_liquid: false
---
<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     手动写一个搜索引擎（超详细）
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h2>
     一、项目背景
    </h2>
    <p>
     搜索引擎是现代设备中被广泛利用的一种系统软件，诸如百度、谷歌、搜索、bing等，或者抖音、快手、b站、小红书，甚至软件应用市场，Windows（操作系统）中的各类提供搜索功能的背后都有搜索引擎的影子。
    </p>
    <h2>
     二、使用技术
    </h2>
    <p>
     <strong>
      Spring + SpringMVC + Mybatis
     </strong>
    </p>
    <p>
     Spring 负责提供：IoC、AOP
    </p>
    <p>
     SpringMVC 负责提供：Web 业务处理
    </p>
    <p>
     Mybatis 负责提供：方便 SQL 处理
    </p>
    <h2>
     三、项目功能
    </h2>
    <p>
     根据用户检索的内容，把检索到的相关信息展现给用户。
    </p>
    <h2>
     四、整体逻辑图
    </h2>
    <p>
     <img alt="" height="426" src="https://i-blog.csdnimg.cn/blog_migrate/250d99ccf8570b14b62d84686b414969.png" width="1093"/>
    </p>
    <h2>
     五、具体实现
    </h2>
    <h3>
     1.基本流程（用户角度）：
    </h3>
    <p>
     用户输入搜索词（一个词或者多个词），在已有文档中，找到文档包含这些词的所有文档信息，再给出搜索后的列表。
    </p>
    <h3>
     2.设计
    </h3>
    <h4>
     （1）初步想法（不可行）
    </h4>
    <p>
     首先，我们可以分析到，这实际上就是需要一个文档表，里面记录他的 id、标题、内容。然后在数据库中查找：
     <strong>
      select * from 文档表 where 标题 like '%搜索词%' or 内容 like '%搜索词%'
     </strong>
    </p>
    <p>
     但我们不使用这种方式（SQL），因为上述 SQL 的查找性能非常差。
    </p>
    <p>
     文档个数记为 m，文档的平均长度（标题 + 内容）记为 n。O(m*n)。
    </p>
    <p>
     现实中，m 非常大（几百亿篇文档），所以从性能上这个方案不可行。
    </p>
    <h4>
     （2）可实行的方法
    </h4>
    <p>
     <span style="color:#fe2c24;">
      <strong>
       使用倒排索引（inverted index）
      </strong>
     </span>
    </p>
    <p>
     倒排索引的大概结构：key-value 形式。key：词，value：词出现在哪些文档中。
    </p>
    <p>
     ①提前构造好倒排索引，倒排索引中有 id、单词、这个单词对应的文章编号、这个单词的权重。
    </p>
    <p>
     ②当我们比如说去搜索 “list” 这个单词的时候，根据倒排索引，我们可以找到这个单词出现在哪些文档中，根据文档的编号，取出对应的文档内容。
    </p>
    <p>
     ③我们再维护一个正排索引，这里面有 docid（文章的编号）、文章标题、文章的 URL、文章的内容
    </p>
    <p>
     ④当我们根据倒排索引搜索到单词对应的文章id时，比如只取前 20 篇文章，那我们就只需要进行 20 次正排索引查找即可。
    </p>
    <p>
     <strong>
      补充：
     </strong>
     文档是什么文档不重要，可以是 html、pdf、图片、视频等等。
    </p>
    <p>
     我们经常用到的搜索引擎（百度、搜狗），他背后的数据获取一般使用爬虫自动在互联网上搜集信息，将所有内容爬成文档下来，然后进行检索和排序等操作。
    </p>
    <p>
     <span style="color:#fe2c24;">
      <strong>
       我们这个项目只针对 JDK API 文档库中的 html 做搜索
      </strong>
     </span>
    </p>
    <h4>
     （3）构建两大模块
    </h4>
    <p>
     <img alt="" height="650" src="https://i-blog.csdnimg.cn/blog_migrate/d870f03b9cda6917053b21b4cc759cd6.png" width="1012"/>
    </p>
    <h3>
     3.构建索引模块
    </h3>
    <p>
     不需要使用 web 功能，只需要执行一次
    </p>
    <p>
     我们写一个 Indexer 类（indexer/command/Indexer），这是：构建索引的模块，是整个程序的逻辑入口。
     <strong>
      @Slf4j ——添加 Spring 日志的使用           @Component —— 注册成 Spring 的 bean
     </strong>
    </p>
    <p>
     <img alt="" height="130" src="https://i-blog.csdnimg.cn/blog_migrate/40f40925d900fb38c2d52be388011b4a.png" width="525"/>
    </p>
    <p>
     我们让这个类实现 CommandLineRunner 接口。
    </p>
    <pre><code class="language-java">@Component 
public class Indexer implements CommandLineRunner {
    @Override
    public void run(String... args) throws Exception {
        log.info("这里的整个程序的逻辑入口");
    }
}
</code></pre>
    <blockquote>
     <h4>
      <em>
       <strong>
        <span style="color:#0d0016;">
         <span style="background-color:#ffd900;">
          知识补充：
         </span>
        </span>
       </strong>
      </em>
     </h4>
     <h4>
      <strong>
       CommandLineRunner 接口：
      </strong>
     </h4>
     <p>
      Spring boot的
      <code>
       CommandLineRunner
      </code>
      接口主要用于实现在应用初始化后，去执行一段代码块逻辑，这段初始化代码在整个应用生命周期内只会执行一次。
     </p>
     <p>
      使用
      <code>
       CommandLineRunner
      </code>
      接口和@Component注解一起使用
     </p>
     <h4 id="1324930649">
      为什么要使用CommandLineRunner接口
     </h4>
     <ul>
      <li>
       实现在应用启动后，去执行相关代码逻辑，且只会执行一次；
      </li>
      <li>
       spring batch批量处理框架依赖这些执行器去触发执行任务；
      </li>
      <li>
       我们可以在run()方法里使用任何依赖，因为它们已经初始化好了；
      </li>
     </ul>
    </blockquote>
    <h3>
     构造索引的大概步骤：
    </h3>
    <h4>
     <strong>
      1.扫描文档目录下的所有文档：目录遍历的过程 FileScanner
     </strong>
    </h4>
    <p>
     <img alt="" height="73" src="https://i-blog.csdnimg.cn/blog_migrate/6693b2ec62f91a7297d5228780fc6b91.png" width="473"/>
    </p>
    <hr/>
    <pre><code class="language-java">// 1. 扫描出来所有的 html 文件
        log.debug("开始扫描目录，找出所有的 html 文件。{}", properties.getDocRootPath());
        List&lt;File&gt; htmlFileList = fileScanner.scanFile(properties.getDocRootPath(), file -&gt; {
            return file.isFile() &amp;&amp; file.getName().endsWith(".html");
        });
        log.debug("扫描目录结束，一共得到 {} 个文件。", htmlFileList.size());</code></pre>
    <p>
     我们把这个类注册成 Spring bean —— @Service
    </p>
    <blockquote>
     <h4>
      <em>
       <strong>
        <span style="color:#0d0016;">
         <span style="background-color:#ffd900;">
          知识补充：
         </span>
        </span>
       </strong>
      </em>
     </h4>
     <p>
      1、@Service注解 是标注在实现类上的，因为 @Service 是把 spring 容器中的
      <code>
       bean
      </code>
      进行实例化，也就是等同于
      <code>
       new
      </code>
      操作，只有实现类是可以进行
      <code>
       new
      </code>
      实例化的，而接口则不能，所以是加在实现类上的。
     </p>
     <p>
      2、要说明@Service注解 的使用，就得说一下我们经常在 spring 配置文件applicationContext.xml中看到如下图中的配置：
     </p>
     <pre><code>&lt;!-- 采用扫描 + 注解的方式进行开发 可以提高开发效率，后期维护变的困难了，可读性变差了 --&gt;
&lt;context:component-scan base-package="com.study.persistent" /&gt;</code></pre>
     <p>
      在applicationContext.xml配置文件中加上这一行以后，将自动扫描指定路径下的包，如果一个类带了 @Service注解，将自动注册到 Spring容器，不需要再在applicationContext.xml配置文件中定义 bean 了，类似的还包括 @Component、@Repository、@Controller。
     </p>
    </blockquote>
    <h4>
     具体在
     <strong>
      indexer.util.FileScanner
     </strong>
     中完成。
    </h4>
    <ul>
     <li>
      <span style="color:#4da8ee;">
       <strong>
        以 rootPath 作为根目录，开始进行文件的扫描，把所有符合条件的 File 对象，作为结果，以 List 形式返回
       </strong>
      </span>
      <span style="color:#fe2c24;">
       <strong>
        （把这个过程想象成一棵树）
       </strong>
      </span>
     </li>
     <li>
      <span style="color:#4da8ee;">
       <strong>
        针对目录树进行遍历，深度优先 or 广度优先即可，确保每个文件都没遍历到即可，我们这里采用深度优先遍历，使用递归完成
       </strong>
      </span>
     </li>
    </ul>
    <p>
     1. 先通过目录，得到该目录下的孩子文件有哪些
    </p>
    <pre><code class="language-java">File[] files = directoryFile.listFiles();</code></pre>
    <p>
     2. 遍历每个文件，检查是否符合条件
    </p>
    <pre><code class="language-java">for (File file : files) {
            // 通过 filter.accept(file) 的返回值，判断是否符合条件
            if (filter.accept(file)) {
                // 说明符合条件，需要把该文件加入到结果 List 中
                resultList.add(file);
            }
        }</code></pre>
    <p>
     3. 遍历每个文件，针对是目录的情况，继续深度优先遍历（递归）
    </p>
    <pre><code class="language-java">for (File file : files) {
            if (file.isDirectory()) {
                traversal(file, filter, resultList);
            }
        }</code></pre>
    <p>
    </p>
    <h4>
     <strong>
      2.针对每一篇文档进行分析、处理
     </strong>
    </h4>
    <p>
     得到文档的 标题（这里就把他的文件名作为标题）、最终访问的 URL（实际上是一个相对路径）、文档下的内容（IO 读操作）
    </p>
    <p>
     标题：
     <img alt="" height="65" src="https://i-blog.csdnimg.cn/blog_migrate/3ff4939a4f2577845e70dad82f8a1c9a.png" width="471"/>
    </p>
    <p>
     URL：
     <img alt="" height="55" src="https://i-blog.csdnimg.cn/blog_migrate/3c044de5ea5efc77114aedcb2e95fd5f.png" width="499"/>
    </p>
    <p>
     <img alt="" height="171" src="https://i-blog.csdnimg.cn/blog_migrate/241f46a235e8faeb4da1fda7532cbac5.png" width="536"/>
    </p>
    <p>
     进行分词后才能得到倒排索引中保存的key，也就是你想要搜索的词。
    </p>
    <p>
     这个分词引入第三方库来做NLP
    </p>
    <hr/>
    <pre><code class="language-java">// 2. 针对每个 html 文件，得到其 标题、URL、正文信息，把这些信息封装成一个对象（文档 Document）
        File rootFile = new File(properties.getDocRootPath());
        List&lt;Document&gt; documentList = htmlFileList.stream()
                .parallel()         // 【注意】由于我们使用了 Stream 用法，所以，可以通过添加 .parallel()，使得整个操作变成并行，利用多核增加运行速度
                .map(file -&gt; new Document(file, properties.getUrlPrefix(), rootFile))
                .collect(Collectors.toList());
        log.debug("构建文档完毕，一共 {} 篇文档", documentList.size());</code></pre>
    <h4>
     具体在
     <strong>
      indexer.model.Document
     </strong>
     中完成
    </h4>
    <ul>
     <li>
      <span style="color:#4da8ee;">
       <strong>
        扫描出来所有的 html 文件（需要依赖FileScanner 对象，构造方法注入的方式，让 Spring 容器，注入 FileScanner 对象进来）
       </strong>
      </span>
     </li>
    </ul>
    <p>
     这里最好，把要扫描的文件路径放在配置文件（src/main/resources/application.yml）中，这样有利于以后修改会更方便
    </p>
    <pre><code class="language-java">List&lt;File&gt; htmlFileList = fileScanner.scanFile(properties.getDocRootPath(), file -&gt; {
            return file.isFile() &amp;&amp; file.getName().endsWith(".html");
        });</code></pre>
    <pre><code>searcher:
  indexer:
    doc-root-path: E:\java程序\docs\api
    url-prefix: https://docs.oracle.com/javase/8/docs/api/</code></pre>
    <p>
     之后用 properties 的方式来读取
    </p>
    <pre><code class="language-java">package com.lingqi.searcher.indexer.properties;

import lombok.*;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.stereotype.Component;

@Component  // 是注册到 Spring 的一个 bean
@ConfigurationProperties("searcher.indexer")
@Data // = @Getter + @Setter + @ToString + @EqualsAndHashCode
public class IndexerProperties {
    // 对应 application.yml 配置下的 searcher.indexer.doc-root-path
    private String docRootPath;
}
</code></pre>
    <ul>
     <li>
      <span style="color:#4da8ee;">
       <strong>
        针对每个 html 文件，得到其 标题、URL、正文信息，把这些信息封装成一个对象（文档 Document——model/Document)
       </strong>
      </span>
     </li>
    </ul>
    <p>
     <strong>
      标题
     </strong>
     ：从文件名中，将 .html 后缀去掉，剩余的看作标题
    </p>
    <pre><code class="language-java">    private String parseTitle(File file) {
        // 从文件名中，将 .html 后缀去掉，剩余的看作标题
        String name = file.getName();
        String suffix = ".html";
        return name.substring(0, name.length() - suffix.length());
    }</code></pre>
    <p>
     <strong>
      URL
     </strong>
     ：需要得到一个相对路径，file 相对于 rootFile 的相对路径 。
    </p>
    <blockquote>
     <p>
      比如：rootFile 是 E:\java程序\docs\api 。
     </p>
     <p>
      file 是 E:\java程序\docs\api\javax\sql\DataSource.html
     </p>
     <p>
      则相对路径就是：javax\sql\DataSource.html
     </p>
    </blockquote>
    <p>
     把所有反斜杠(\) 变成正斜杠(/)
    </p>
    <p>
     最终得到 java/sql/DataSource.html
    </p>
    <p>
     <strong>
      正文信息
     </strong>
     ：
    </p>
    <p>
     随便打开一篇文档：
    </p>
    <p>
     <img alt="" height="261" src="https://i-blog.csdnimg.cn/blog_migrate/f0235931e886156d53bdc497c6f2aeb7.png" width="495"/>
    </p>
    <blockquote>
     <p>
      我们需要做的是：
     </p>
     <p>
      1.&lt;script...&gt; ... &lt;/sprict&gt;  这是我们不要的
     </p>
     <p>
      2.所有标签都不要：&lt;p&gt;Hello&lt;/p&gt;&lt;p&gt;World&lt;/p&gt; 我们要的只是 Hello World
     </p>
     <p>
      3.所有的换行符替换成' '（空格）
     </p>
     <p>
      我们只保留纯文本内容，用来做分词
     </p>
    </blockquote>
    <p>
     因此使用正则表达式完成上述工作
    </p>
    <blockquote>
     <h4>
      <em>
       <strong>
        <span style="color:#0d0016;">
         <span style="background-color:#ffd900;">
          知识补充：
         </span>
        </span>
       </strong>
      </em>
     </h4>
     <p>
      <span style="color:#0d0016;">
       正则表达式
      </span>
     </p>
     <p>
      " . " 匹配 任意 字符，匹配多少个需要根据后续字符来判断，默认就是一个
     </p>
     <p>
      <img alt="" height="97" src="https://i-blog.csdnimg.cn/blog_migrate/b6b694375900c3f2abc05742c66ebbe9.png" width="413"/>
     </p>
     <p>
      " /s " 匹配任意空格，包括" "，"\t"，"\r\n"，"\r"，"\n"
     </p>
     <p>
      " /d " 匹配任意数字（只有一位）0-9
     </p>
     <p>
      " a+ " 匹配 "a"，出现的次数 &gt;= 1次
     </p>
     <p>
      " a* " 匹配 "a"，出现的次数 &gt;= 0次
     </p>
     <p>
      " .+ " 匹配任意字符，出现次数 &gt;= 1 次
     </p>
     <p>
      " .* " 匹配任意字符，出现次数 &gt;= 0 次
     </p>
     <p>
      " ? " 可选的
     </p>
    </blockquote>
    <p>
     先把文章一行一行全部读取到 StringBuilder 中，再把 StringBuilder 中不需要的那些内容进行删除或者替换
    </p>
    <pre><code class="language-java">return contentBuilder.toString()
         // 首先去掉 &lt;script ...&gt;...&lt;/script&gt;
         .replaceAll("&lt;script.*?&gt;.*?&lt;/script&gt;", " ")
         // 去掉标签
         .replaceAll("&lt;.*?&gt;", " ")
         // 把最后多出来的空格删除掉
         .replaceAll("\\s+", " ")
         .trim();</code></pre>
    <p>
    </p>
    <h4>
     3.进行正排索引的保存
    </h4>
    <p>
     拿到分词后，我们就知道每一篇文档的 标题、URL、内容、标题和内容的每个词
    </p>
    <p>
     利用上述信息就可以构建索引了。正排索引、倒排索引
    </p>
    <hr/>
    <p>
     正排索引有1W条数据，倒排索引有600W条。如果一条一条插入，需要循环600W次才可以插入完成。但我们可以设置成一次插入1000条数据，这样只需要循环6000次就可以了。
    </p>
    <p>
     因此我们只需要两张表存在数据库中：
    </p>
    <p>
     正排索引表（docid-pk、title、url、content）整体数量级不大，只有1W条，但是每一条比较大（content大）——批量插入的时候，每次记录不用太多（每次插入 10 条）
    </p>
    <p>
     倒排索引（id-pk、word、docid、weight）整体数量级较大，有600W条，每一条的记录比较小——批量插入的时候，每次记录多插入一些（每次插入 1W条）
    </p>
    <p>
     我们docid的生成方式利用 MySQL 的表中的自增机制作为docid
    </p>
    <blockquote>
     <p>
      <em>
       <strong>
        <span style="background-color:#ffd900;">
         MySQL 批量插入语法：
        </span>
       </strong>
      </em>
     </p>
     <p>
      insert into forward_indexs(title,url,content) values
     </p>
     <p>
      ('1','2','3'),
     </p>
     <p>
      ('4','5','6'),
     </p>
     <p>
      ('7','8','9')；
     </p>
    </blockquote>
    <blockquote>
     <p>
      既然需要批量插入，我就要用到
      <strong>
       <em>
        <span style="background-color:#ffd900;">
         mybatis
        </span>
       </em>
      </strong>
      的动态SQL特性
     </p>
     <p>
      <img alt="" height="310" src="https://i-blog.csdnimg.cn/blog_migrate/4860aaadf3237d6043d925946e5ccedb.png" width="795"/>
     </p>
     <p>
      遍历 collection="list"，其中，下标保存在 index （index=“index”），其中遍历时的每一项保存在item（item=“item”）
     </p>
    </blockquote>
    <p>
     写sql的：
    </p>
    <pre><code class="language-java">@Repository // 注册 Spring bean
@Mapper     // 是一个 Mybatis 管理的 Mapper
public interface IndexDatabaseMapper {
    // 正排
    void batchInsertForwardIndexes(@Param("list") List&lt;Document&gt; documentList);

    //倒排
    void batchInsertInvertedIndexes(@Param("list") List&lt;InvertedRecord&gt; recordList);
}</code></pre>
    <p>
     准备一个xml
     <img alt="" height="98" src="https://i-blog.csdnimg.cn/blog_migrate/b7c80e956db9977d614c7d49b3c6ff7f.png" width="523"/>
    </p>
    <pre><code class="language-XML">&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
&lt;!DOCTYPE mapper
        PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
        "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;
&lt;mapper namespace="com.lingqi.searcher.indexer.mapper.IndexDatabaseMapper"&gt;
</code></pre>
    <p>
     在配置文件中也加入。在 Spring 的配置文件中，指定 mybatis 查找 mapper xml 文件的路径
    </p>
    <p>
     classpath：代表从 src/main/resources 下进行查找（这实际上是错误的理解，暂且可以这么简单理解关系不大）
    </p>
    <p>
     <img alt="" height="161" src="https://i-blog.csdnimg.cn/blog_migrate/fa48e03b51f8d54433cd105833f8f28c.png" width="1200"/>
    </p>
    <p>
     index-mapper.xml文件中设置的
    </p>
    <p>
     &lt;mapper namespace="com.lingqi.searcher.indexer.mapper.IndexDatabaseMapper"&gt;
    </p>
    <p>
     实际上对应的就是 我们用于写sql 的类 IndexDatabaseMapper。
    </p>
    <p>
     因为我们这里实际上就是一个插入，所以是 insert 语句，因此我们在index-mapper.xml中写入insert语句
    </p>
    <p>
     <img alt="" height="484" src="https://i-blog.csdnimg.cn/blog_migrate/7058c6412a740173a0db34695fd22430.png" width="1006"/>
    </p>
    <p>
     <span style="color:#fe2c24;">
      <strong>
       sql语句（写在index-mapper.xml中）：
      </strong>
     </span>
    </p>
    <p>
     <img alt="" height="220" src="https://i-blog.csdnimg.cn/blog_migrate/c6d6eaeca9d110735f8fac6aefa87c06.png" width="920"/>
    </p>
    <p>
     最终的到的 sql 就是拼接好的sql。
    </p>
    <pre><code class="language-XML">&lt;insert id="batchInsertForwardIndexes" useGeneratedKeys="true" keyProperty="docId" keyColumn="docid"&gt;
        insert into forward_indexes (title, url, content) values
        &lt;!-- 一共有多少条记录，得根据用户传入的参数来决定，所以这里采用动态 SQL 特性 --&gt;
        &lt;foreach collection="list" item="doc" separator=", "&gt;
            (#{doc.title}, #{doc.url}, #{doc.content})
        &lt;/foreach&gt;
&lt;/insert&gt;</code></pre>
    <p>
     <img alt="" height="287" src="https://i-blog.csdnimg.cn/blog_migrate/c15e33b92ec82ea004fe9c4b0dc53722.png" width="946"/>
    </p>
    <p>
     我们在 indexer/core/IndexManager 中完成插入
    </p>
    <ul>
     <li>
      <span style="color:#4da8ee;">
       <strong>
        批量生成、保存正排索引
       </strong>
      </span>
     </li>
    </ul>
    <pre><code class="language-java"> indexManager.saveForwardIndexesConcurrent(documentList);</code></pre>
    <p>
     <span style="color:#ff9900;">
      <strong>
       单线程版本：
      </strong>
     </span>
    </p>
    <p>
     1. 批量插入时，每次插入多少条记录（由于每条记录比较大，所以这里使用 10 条就够了）
    </p>
    <pre><code class="language-java">int batchSize = 10;</code></pre>
    <p>
     2. 一共需要执行多少次 SQL？ 向上取整(documentList.size() / batchSize)
    </p>
    <pre><code class="language-java">int listSize = documentList.size();
int times = (int) Math.ceil(1.0 * listSize / batchSize);    // ceil(天花板): 向上取整</code></pre>
    <p>
     3. 开始分批次插入
    </p>
    <pre><code class="language-java">for (int i = 0; i &lt; listSize; i += batchSize) {
    // 从 documentList 中截取这批要插入的 文档列表（使用 List.subList(int from, int to)
    int from = i;
    int to = Integer.min(from + batchSize, listSize);

    List&lt;Document&gt; subList = documentList.subList(from, to);

    // 针对这个 subList 做批量插入
    mapper.batchInsertForwardIndexes(subList);
}</code></pre>
    <p>
     <span style="color:#ff9900;">
      <strong>
       多线程版本：
      </strong>
     </span>
    </p>
    <p>
     前面两步和单线程版本相同，在第三步循环插入中，把他们放到任务中去执行
    </p>
    <p>
     我们需要一个线程池，定义在 indexer/config/AppConfig 中：
    </p>
    <pre><code class="language-java">@Configuration
public class AppConfig {
    @Bean
    public ExecutorService executorService() {
        ThreadPoolExecutor executor = new ThreadPoolExecutor(
                8, 20, 30, TimeUnit.SECONDS,
                new ArrayBlockingQueue&lt;&gt;(5000),
                (Runnable task) -&gt; {
                    Thread thread = new Thread(task);
                    thread.setName("批量插入线程");
                    return thread;
                },
                new ThreadPoolExecutor.AbortPolicy()
        );

        return executor;
    }
}</code></pre>
    <pre><code class="language-java">@Timing("构建 + 保存正排索引 —— 多线程版本")
@SneakyThrows
public void saveForwardIndexesConcurrent(List&lt;Document&gt; documentList) {
    // 1. 批量插入时，每次插入多少条记录（由于每条记录比较大，所以这里使用 10 条就够了）
    int batchSize = 10;
    // 2. 一共需要执行多少次 SQL？   向上取整(documentList.size() / batchSize)
    int listSize = documentList.size();
    int times = (int) Math.ceil(1.0 * listSize / batchSize);    // ceil(天花板): 向上取整
    log.debug("一共需要 {} 批任务。", times);

    CountDownLatch latch = new CountDownLatch(times);   // 统计每个线程的完全情况，初始值是 times(一共多少批)

    // 3. 开始分批次插入
    for (int i = 0; i &lt; listSize; i += batchSize) {
        // 从 documentList 中截取这批要插入的 文档列表（使用 List.subList(int from, int to)
        int from = i;
        int to = Integer.min(from + batchSize, listSize);

        Runnable task = () -&gt; { // 内部类 / lambda 表达式里如果用到了外部变量，外部变量必须的 final（或者隐式 final 的变量）
            List&lt;Document&gt; subList = documentList.subList(from, to);

            // 针对这个 subList 做批量插入
            mapper.batchInsertForwardIndexes(subList);

            latch.countDown();      //  每次任务完成之后，countDown()，让 latch 的个数减一
        };

        executorService.submit(task);   // 主线程只负责把一批批的任务提交到线程池，具体的插入工作，由线程池中的线程完成
    }

    // 4. 循环结束，只意味着主线程把任务提交完成了，但任务有没有做完是不知道的
    // 主线程等在 latch 上，只到 latch 的个数变成 0，也就是所有任务都已经执行完了
    latch.await();
}</code></pre>
    <p>
    </p>
    <h4>
     4.倒排索引的生成和保存
    </h4>
    <p>
     <strong>
      针对文档进行分词，并且分别计算每个词的权重
     </strong>
    </p>
    <p>
     在倒排索引中，我们需要进行分词、处理词的权重问题，这里我们统一放到 Document 类中处理
    </p>
    <p>
     <span style="color:#4da8ee;">
      <strong>
       对于每个 Document 进行分词处理，需要第三方库的支持
      </strong>
     </span>
    </p>
    <p>
     在pom.xml 中添加依赖，它支持中文和英文分词
    </p>
    <pre><code class="language-XML">&lt;dependency&gt;
    &lt;groupId&gt;org.ansj&lt;/groupId&gt;
    &lt;artifactId&gt;ansj_seg&lt;/artifactId&gt;
    &lt;version&gt;5.1.6&lt;/version&gt;
&lt;/dependency&gt;</code></pre>
    <p>
     用法示例：
    </p>
    <pre><code class="language-java">public void Ansj() {
		Result result = ToAnalysis.parse("我爱北京天安门，天安门上太阳升。");
		List&lt;Term&gt; termList = result.getTerms();
		for (Term term : termList) {
			System.out.print(term.getName() + ", ");
			System.out.print(term.getNatureStr() + ", ");
			System.out.println(term.getRealName());
		}
	}</code></pre>
    <p>
     <img alt="" height="209" src="https://i-blog.csdnimg.cn/blog_migrate/2af06da93d5f6c0c668947e178679540.png" width="374"/>
    </p>
    <p>
    </p>
    <p>
     <span style="color:#4da8ee;">
      <strong>
       权重的设计
      </strong>
     </span>
    </p>
    <p>
     比如说用户要查找 “list” 这个单词，找到了好几篇文档都含有 “list”  ，那么哪篇文章显示在前，哪篇在后？
    </p>
    <blockquote>
     <p>
      <strong>
       第一种
      </strong>
      ：按照 docid 从小到大去显示：1，2，13，25，27，34，67，....
     </p>
     <p>
      <strong>
       第二种
      </strong>
      ：按照匹配程度去显示：比如说：13号的 list 在标题出现了10次，在正文出现了 100 次；1号的 list 在标题出现了1次，在正文出现了 1次。那么13号文档更匹配，所以排名要在1号的前面。
     </p>
     <p>
      <strong>
       第三种
      </strong>
      ：更加智能的计算：根据用户的点击数、点击频率、文档的更新频率、作者的维权程度、文档来源的权威程度等信息更精准的计算。
     </p>
     <p>
      <strong>
       第四种
      </strong>
      ：谁给的钱多，谁靠前。
     </p>
     <p>
      <span style="color:#fe2c24;">
       <strong>
        我们这里采用的是第二种方法。
       </strong>
      </span>
     </p>
    </blockquote>
    <p>
     所以，我们针对每个单词 ---&gt; 每篇文档，都伴随一个 weight（权重），根据这个权重去排序（d倒序）
    </p>
    <p>
     权重的计算：
     <strong>
      10 * 单词出现在标题的次数 + 1 * 单词出现在正文中的次数。
     </strong>
    </p>
    <hr/>
    <p>
     这里我们使用map 来维护，key就是某个词，value就是该词对应的权重
    </p>
    <ul>
     <li>
      <span style="color:#4da8ee;">
       <strong>
        标题 | 分词
       </strong>
      </span>
     </li>
    </ul>
    <pre><code class="language-java">List&lt;String&gt; wordInTitle = ToAnalysis.parse(title)  //对title进行分词
    .getTerms()   
    .stream()
    .parallel()
    .map(Term::getName)   
    .filter(s -&gt; !ignoredWordSet.contains(s))
    .collect(Collectors.toList());</code></pre>
    <ul>
     <li>
      <strong>
       <span style="color:#4da8ee;">
        标题 | 出现次数
       </span>
      </strong>
     </li>
    </ul>
    <pre><code class="language-java">Map&lt;String, Integer&gt; titleWordCount = new HashMap&lt;&gt;();
for (String word : wordInTitle) {
    int count = titleWordCount.getOrDefault(word, 0);
    titleWordCount.put(word, count + 1);
}</code></pre>
    <ul>
     <li>
      <span style="color:#4da8ee;">
       <strong>
        正文 | 分词
       </strong>
      </span>
     </li>
    </ul>
    <pre><code class="language-java">List&lt;String&gt; wordInContent = ToAnalysis.parse(content)
    .getTerms()
    .stream()
    .parallel()
    .map(Term::getName)
    .collect(Collectors.toList());</code></pre>
    <ul>
     <li>
      <span style="color:#4da8ee;">
       <strong>
        正文 | 出现次数
       </strong>
      </span>
     </li>
    </ul>
    <pre><code class="language-java"> Map&lt;String, Integer&gt; contentWordCount = new HashMap&lt;&gt;();
for (String word : wordInContent) {
    int count = contentWordCount.getOrDefault(word, 0);
    contentWordCount.put(word, count + 1);
}</code></pre>
    <ul>
     <li>
      <strong>
       <span style="color:#4da8ee;">
        计算权重值
       </span>
      </strong>
     </li>
    </ul>
    <p>
     <span style="color:#0d0016;">
      用map，某个词对应的权重是多少
     </span>
    </p>
    <pre><code class="language-java">Map&lt;String, Integer&gt; wordToWeight = new HashMap&lt;&gt;();</code></pre>
    <p>
     1. 先计算出有哪些词，不重复
    </p>
    <p>
     就是使用set ，把所有的标题中的词初始化就都放入，然后再把所有正文的词也放入，set 中的元素是不能重复的。
    </p>
    <p>
     2.遍历set中的元素，看这个词在标题中出现多少次，在正文中出现多少次，最后计算权重：
    </p>
    <p>
     10 * 单词出现在标题的次数 + 1 * 单词出现在正文中的次数。
    </p>
    <p>
     3.最后把该词和他的权重放到map中，最后返回这个map即可。
    </p>
    <hr/>
    <p>
     上述准备工作处理完成之后，我们开始进行倒排索引的生成和保护（在IndexManager类中）
    </p>
    <p>
     1.定义一个类 ，里面的对象用来映射 inverted_indexes 表中的一条记录
    </p>
    <pre><code class="language-java">// 这个对象映射 inverted_indexes 表中的一条记录（我们不关心表中的 id，就不写 id 了）
@Data
public class InvertedRecord {
    private String word;
    private int docId;
    private int weight;

    public InvertedRecord(String word, int docId, int weight) {
        this.word = word;
        this.docId = docId;
        this.weight = weight;
    }
}</code></pre>
    <p>
     2.执行 sql 在index-mapper.xml 中
    </p>
    <pre><code class="language-XML">&lt;!-- 不关心自增 id --&gt;
    &lt;insert id="batchInsertInvertedIndexes"&gt;
        insert into inverted_indexes (word, docid, weight) values
        &lt;foreach collection="list" item="record" separator=", "&gt;
            (#{record.word}, #{record.docId}, #{record.weight})
        &lt;/foreach&gt;
    &lt;/insert&gt;</code></pre>
    <p>
     <strong>
      <span style="color:#ff9900;">
       单线程版本：
      </span>
     </strong>
    </p>
    <p>
     3.设置 批量插入时，最多 10000 条
    </p>
    <pre><code class="language-java">int batchSize = 10000;</code></pre>
    <p>
     4.准备一个List （recordList），里面是  InvertedRecord 类型的，然后根据分词不断向里面放入，放够10000条了就插入一次。（也就是本批次要插入的数据）
    </p>
    <p>
     5.遍历document 文件，调用 document.segWordAndCalcWeight() 方法，拿到分词结果。
    </p>
    <p>
     6.遍历每个单词，得到单词和权重，再得到他的docid。构建出这三个后把他们放入recordList中。
    </p>
    <p>
     7.如果 recordList.size() == batchSize，说明够一次插入了，够10000条了，就进行插入，插入完成之后清空 recordList。然后就会重新循环再走。
    </p>
    <p>
     8. recordList 还剩一些，之前放进来，但还不够 batchSize 个的，所以最后再批量插入一次。执行完成之后就可以认为是所有插入都完成了。
    </p>
    <p>
     <strong>
      <span style="color:#ff9900;">
       多线程版本：
      </span>
     </strong>
    </p>
    <p>
     一次插入10000条，一次处理50篇文档
    </p>
    <pre><code class="language-java">int batchSize = 10000;  // 批量插入时，最多 10000 条
int groupSize = 50;</code></pre>
    <p>
     提前把线程一批一批分好，分好之后交给线程去提交。
    </p>
    <pre><code class="language-java">    static class InvertedInsertTask implements Runnable {
        private final CountDownLatch latch;
        private final int batchSize;
        private final List&lt;Document&gt; documentList;
        private final IndexDatabaseMapper mapper;

        InvertedInsertTask(CountDownLatch latch, int batchSize, List&lt;Document&gt; documentList, IndexDatabaseMapper mapper) {
            this.latch = latch;
            this.batchSize = batchSize;
            this.documentList = documentList;
            this.mapper = mapper;
        }

        @Override
        public void run() {
            List&lt;InvertedRecord&gt; recordList = new ArrayList&lt;&gt;();    // 放这批要插入的数据

            for (Document document : documentList) {
                Map&lt;String, Integer&gt; wordToWeight = document.segWordAndCalcWeight();
                for (Map.Entry&lt;String, Integer&gt; entry : wordToWeight.entrySet()) {
                    String word = entry.getKey();
                    int docId = document.getDocId();
                    int weight = entry.getValue();

                    InvertedRecord record = new InvertedRecord(word, docId, weight);

                    recordList.add(record);

                    // 如果 recordList.size() == batchSize，说明够一次插入了
                    if (recordList.size() == batchSize) {
                        mapper.batchInsertInvertedIndexes(recordList);  // 批量插入
                        recordList.clear();                             // 清空 list，视为让 list.size() = 0
                    }
                }
            }

            // recordList 还剩一些，之前放进来，但还不够 batchSize 个的，所以最后再批量插入一次
            mapper.batchInsertInvertedIndexes(recordList);  // 批量插入
            recordList.clear();

            latch.countDown();
        }
    }

    @Timing("构建 + 保存倒排索引 —— 多线程版本")
    @SneakyThrows
    public void saveInvertedIndexesConcurrent(List&lt;Document&gt; documentList) {
        int batchSize = 10000;  // 批量插入时，最多 10000 条
        int groupSize = 50;
        int listSize = documentList.size();
        int times = (int) Math.ceil(listSize * 1.0 / groupSize);
        CountDownLatch latch = new CountDownLatch(times);

        for (int i = 0; i &lt; listSize; i += groupSize) {
            int from = i;
            int to = Integer.min(from + groupSize, listSize);
            List&lt;Document&gt; subList = documentList.subList(from, to);
            Runnable task = new InvertedInsertTask(latch, batchSize, subList, mapper);
            executorService.submit(task);
        }

        latch.await();
    }</code></pre>
    <p>
    </p>
    <h3>
     4.搜索模块
    </h3>
    <p>
     依赖索引构建完成之后才能进行，需要 web 功能
    </p>
    <p>
     使用SpringMVC 实现了Web服务
    </p>
    <hr/>
    <h4>
     <span style="color:#e6b223;">
      只针对一个词进行搜索
     </span>
    </h4>
    <blockquote>
     <p>
      select docid,weight from inverted_indexes where word = 'list' order by weight desc;
     </p>
     <p>
      select * from forward_indexes where docid in (...);  这样排出来是无序的
     </p>
     <p>
      需要根据 weight 重新再进行一次排序
     </p>
     <p>
      把上述合并成一条联表 SQL
     </p>
    </blockquote>
    <blockquote>
     <p>
      select ii.docid,title,url,content,from inverted_indexes ii
     </p>
     <p>
      join forward_indexes fi on ii.docid = fi.docid
     </p>
     <p>
      where word = 'list'
     </p>
     <p>
      order by weight desc;   这样排完之后是有序的
     </p>
    </blockquote>
    <p>
     前端传过来这个词，根据词 去 倒排索引 + 正排索引中搜索，得到文档列表（可以做分页）
    </p>
    <p>
     <img alt="" height="123" src="https://i-blog.csdnimg.cn/blog_migrate/f0541c73e233c8fd76827f1cece045f0.png" width="849"/>
    </p>
    <p>
     查询很慢，只是一个词就需要1.8秒，如果搜索的多了，时间更久，没有人愿意等待这么久
    </p>
    <p>
     这里我们使用
     <strong>
      向表中新建索引
     </strong>
     来解决这个问题（针对 word 列去建索引）
    </p>
    <p>
     建索引的过程，就是把 word 列作为 key，docid 作为 value，新建一棵搜索树（B+树）
    </p>
    <p>
     从 key 查找 value，则时间复杂度变成O(log(n)) 21次 远远小于O(n) 200W 次
    </p>
    <p>
     建索引的速度很慢，而且会导致数据插入很慢，所以，在表中的数据已经插入完成的情况下，再添加索引
    </p>
    <p>
     给 word 和 weight 都添加索引，先用word 查，查完之后利用 weight 我们可以利用索引直接进行排序。
    </p>
    <p>
     <img alt="" height="264" src="https://i-blog.csdnimg.cn/blog_migrate/c7466fe38fa27cc089f09f6d0415caa8.png" width="584"/>
    </p>
    <p>
     建立索引之后，查询只需要0.2秒
    </p>
    <p>
     <img alt="" height="55" src="https://i-blog.csdnimg.cn/blog_migrate/eaba511e3fa54c0de397d005a4bca8d4.png" width="937"/>
    </p>
    <p>
     搜索树的 key：索引中的字段 word + weight（复合索引）
    </p>
    <p>
     左边是word，右边weight
    </p>
    <p>
     左边可以比较大小：索引的命中规则遵守靠左原则，select ... from 表 where word = ' ... ' 可以用上索引
    </p>
    <p>
     随后按weight 进行排序，因为 key 里就有 weight ，所以 key 本身就是按照 weight 排序好的（搜索树的有序原则）
    </p>
    <blockquote>
     <ol>
      <li>
       不加索引的情况下查询慢（因为排序 和 查询都没有用到索引）。
      </li>
      <li>
       针对 word 加索引，性能有所提升（查询使用了索引，排序没有用，相对快，但还不够快）。
      </li>
      <li>
       针对word 和 weight ，使用索引，性能明显提升（查询和排序都使用了索引，非常快）
      </li>
     </ol>
    </blockquote>
    <hr/>
    <p>
     1.动态资源 /web， qurty=... 必须填的 page=...选填，但必须是数字
    </p>
    <p>
     写一个Controller ，叫做 SearchController ，通过 @Controller 注解修饰，代表这是一个控制器。实现  @GetMapping("/web")，查询的url 是 /web。里面 return "search";最后会渲染 search.html 这个模板
    </p>
    <blockquote>
     <h4>
      <em>
       <strong>
        <span style="color:#0d0016;">
         <span style="background-color:#ffd900;">
          @GetMapping 注解
         </span>
        </span>
       </strong>
      </em>
     </h4>
     <p>
      @GetMapping是一个组合注解，等价于@RequestMapping (method = RequestMethod.GET)，它
      <strong>
       将HTTP Get请求映射到特定的处理方法上
      </strong>
      。
     </p>
    </blockquote>
    <p>
     2.之后就需要进行查询，定义一个 Document 类 模板，其中需要 title、url、content。
    </p>
    <p>
     3.这些东西需要根据数据库去查，因此我们需要一个接口——SearchMapper，用@Repository @Mapper 这两个注解来修饰。里面返回的是一组 Document 类型的 list
    </p>
    <pre><code class="language-java">@Repository
@Mapper
public interface SearchMapper {
    List&lt;Document&gt; query(
            @Param("word") String word,
            @Param("limit") int limit,
            @Param("offset") int offset);

    List&lt;DocumentWightWeight&gt; queryWithWeight(
            @Param("word") String word,
            @Param("limit") int limit,
            @Param("offset") int offset
    );
}</code></pre>
    <blockquote>
     <h4>
      <strong>
       <em>
        <span style="background-color:#ffd900;">
         @param 注解
        </span>
       </em>
      </strong>
     </h4>
     <p>
      @param 标签
      <strong>
       提供了对某个函数的参数的各项说明
      </strong>
      ，包括参数名、参数数据类型、描述等。
     </p>
     <p>
      @param 标签要求您指定要描述参数的名称。
     </p>
     <p>
      您还可以包含参数的数据类型，使用大括号括起来，和参数的描述。
     </p>
     <p>
      参数类型可以是一个内置的JavaScript类型，如 string 或 Object ，或是你代码中另一个标识符的 JSDoc namepath（名称路径） 。
     </p>
     <p>
      如果你已经在这namepath（名称路径）上为标识符添加了描述，JSDoc会自动链接到该标识符的文档。
     </p>
    </blockquote>
    <p>
     配置文件：
    </p>
    <pre><code>spring:
  main:
    log-startup-info: false
    banner-mode: off
  datasource:
    url: jdbc:mysql://127.0.0.1:3306/searcher_refactor?characterEncoding=utf8&amp;useSSL=false&amp;serverTimezone=Asia/Shanghai
    username: root
    password: 123456

mybatis:
  mapper-locations: classpath:mapper/search-mapper.xml

logging:
  level:
    com.lingqi.searcher.web: debug</code></pre>
    <p>
     具体的查询语句，这里使用 mybatis ，在 search-mapper.xml 语句中写具体的查询语句
    </p>
    <pre><code class="language-XML">&lt;!-- #{...} 会添加引号上去; ${...} 不会添加引号 --&gt;
    &lt;select id="query" resultMap="DocumentResultMap"&gt;
        select ii.docid, title, url, content
        from inverted_indexes ii
        join forward_indexes fi
            on ii.docid = fi.docid
        where word = #{word}
        order by weight desc
        limit ${limit}
        offset ${offset}
    &lt;/select&gt;</code></pre>
    <p>
     4. 在  SearchController 中写具体步骤
    </p>
    <ul>
     <li>
      得到查询的词是哪个词（query）参数的合法性检查 + 处理
     </li>
    </ul>
    <pre><code class="language-java">if (query == null) {
    log.debug("query 为 null，重定向到首页");
    return "redirect:/";
}

query = query.trim().toLowerCase();
if (query.isEmpty()) {
    log.debug("query 为空字符串，重定向到首页");
    return "redirect:/";
}</code></pre>
    <ul>
     <li>
      分词
     </li>
    </ul>
    <pre><code class="language-java">List&lt;String&gt; queryList = ToAnalysis.parse(query)
    .getTerms()
    .stream()
    .map(Term::getName)
    .collect(Collectors.toList());
</code></pre>
    <ul>
     <li>
      如果分词后，queryList  为空，也就是分词后一个词都没有，那么证明没有找到这个词，让他重定向到首页
     </li>
     <li>
      处理分页的问题 （得到page，计算出limit + offset）
     </li>
    </ul>
    <pre><code class="language-java">int limit = 20;
int offset = 0;
int page = 1;

if (pageString != null) {
    pageString = pageString.trim();
    try {
        page = Integer.parseInt(pageString);
        if (page &lt;= 0) {
            page = 1;
        }

        limit = page * 20;
     } catch (NumberFormatException ignored) {}
}</code></pre>
    <ul>
     <li>
      执行SQL进行查询
     </li>
     <li>
      将数据添加到 model 中，是为了在 渲染模板的时候用到（这里使用了SpringMVC的模板渲染技术（ViewResover），这里具体使用的是 Thymeleaf）
     </li>
     <li>
      Model 添加渲染需要的数据：query、docList、page
     </li>
    </ul>
    <pre><code class="language-java">model.addAttribute("query", query);
model.addAttribute("docList", documentList);
model.addAttribute("page", page);</code></pre>
    <ul>
     <li>
      指定使用哪个模板来进行渲染 return "search" 对应 resources/templates/search.html
     </li>
    </ul>
    <p>
     5.搜索出来之后，展示基本内容部分
    </p>
    <p>
     首先我们可以拿到这个文本的内容，我们可以前面截取120 个字，后面截取120 个字。
    </p>
    <pre><code class="language-java">public Document build(List&lt;String&gt; queryList, Document doc) {
        // 找到 content 中包含关键字的位置
        // query = "list"
        // content = "..... hello list go come do ...."
        // desc = "hello &lt;i&gt;list&lt;/i&gt; go com..."

        String content = doc.getContent().toLowerCase();
        String word = "";
        int i = -1;
        for (String query : queryList) {
            i = content.indexOf(query);
            if (i != -1) {
                word = query;
                break;
            }
        }
        if (i == -1) {
            // 这里中情况如果出现了，说明咱的倒排索引建立的有问题
            log.error("docId = {} 中不包含 {}", doc.getDocId(), queryList);
            throw new RuntimeException();
        }

        // 前面截 120 个字，后边截 120 个字
        int from = i - 120;
        if (from &lt; 0) {
            // 说明前面不够 120 个字了
            from = 0;
        }

        int to = i + 120;
        if (to &gt; content.length()) {
            // 说明后面不够 120 个字了
            to = content.length();
        }

        String desc = content.substring(from, to);

        // 这里添加i标签，可以使这个单词高亮显示
        desc = desc.replace(word, "&lt;i&gt;" + word + "&lt;/i&gt;");

        doc.setDesc(desc);

        return doc;
    }</code></pre>
    <hr/>
    <h4>
     <strong>
      <span style="color:#e6b223;">
       针对多个词进行搜索
      </span>
     </strong>
    </h4>
    <p>
     和单词搜索的区别就是 权重值需要重新计算
    </p>
    <p>
     <img alt="" height="202" src="https://i-blog.csdnimg.cn/blog_migrate/c9367899f4b794851c17a4d69531562f.png" width="616"/>
    </p>
    <p>
     多次中，就需要有一个权重值聚合的问题
    </p>
    <p>
     docid 相同的，weight=sum（w1,w2,w3）
    </p>
    <p>
     docid=1  weight = 13 + 7 + 1
    </p>
    <p>
     docid=2  weight = 22
    </p>
    <p>
     把实际业务抽象成如下的简单题：给定3个有序数组（按照权重从大到排序），最终结果的权重（sum=w1+w2+w3|docid相同），给出第 x 到第 y 个元素
    </p>
    <blockquote>
     <p>
      假如需要【0，20），必须把 每个【0，20）找出，聚合权重，重新排序，算出结果中的【0，20）
     </p>
     <p>
      假如需要【20，40），必须把 每个【0，40）找出，聚合权重，重新排序，算出结果中的【20，40）
     </p>
     <p>
      假如需要【40，60），必须把 每个【0，60）找出，聚合权重，重新排序，算出结果中的【40，60）
     </p>
    </blockquote>
    <p>
     如果数据量太大，这种找法是不可能的，内存空间可能不足，时间效率也很低
    </p>
    <p>
     因此实际中我们会舍弃他的准确性，比如说某次考试，前1000名学生，各自的排名多少是非常重要的，不能出错。后1000名同学，排名略有错误，其实也不重要。实际上上就是
     <span style="color:#fe2c24;">
      <strong>
       牺牲正确性来换取性能。
      </strong>
     </span>
    </p>
    <p>
     结果必须重新计算，所以没办法使用MySQL帮我们排序了
    </p>
    <ul>
     <li>
      首先我们先对所有的词进行查找，查找出来先放到 totalList 中
     </li>
    </ul>
    <pre><code class="language-java">List&lt;DocumentWightWeight&gt; totalList = new ArrayList&lt;&gt;();
for (String s : queryList) {
    List&lt;DocumentWightWeight&gt; documentList = mapper.queryWithWeight(s, limit, offset);
    totalList.addAll(documentList);
}</code></pre>
    <ul>
     <li>
      针对所有文档列表，做权重聚合工作
     </li>
    </ul>
    <p>
     维护:docId -&gt; document 的 map
    </p>
    <p>
     1.我们遍历 totalList 针对每一个docid 我们往里面放。遇到重复的，不断累加。
    </p>
    <p>
     <img alt="" height="381" src="https://i-blog.csdnimg.cn/blog_migrate/5708e1efa00b1da711bec8943b442164.png" width="300"/>
    </p>
    <p>
     2.此时我们就有了每个单词对应的权重了，这放在 documentMap 中，我们需要对这个权重进行一个排序，首要要拿到这些权重，放在 Collection 中
    </p>
    <p>
     3.但 Collection 没有排序这个概念（只有线性结构才有排序的概念），所以我们需要一个 List
    </p>
    <p>
     4. 按照 weight 的从大到小排序
    </p>
    <pre><code class="language-java">Collections.sort(list, (item1, item2) -&gt; {
    return item2.weight - item1.weight;
});</code></pre>
    <p>
     5. 从 list 中把分页区间取出来
    </p>
    <pre><code class="language-java">int from = (page - 1) * 20;
int to = from + 20;
     
List&lt;DocumentWightWeight&gt; subList = list.subList(from, to);
List&lt;Document&gt; documentList = subList.stream()
    .map(DocumentWightWeight::toDocument)
    .collect(Collectors.toList());</code></pre>
    <p>
     具体的查询语句，这里使用 mybatis ，在 search-mapper.xml 语句中写具体的查询语句：
    </p>
    <p>
    </p>
    <pre><code class="language-XML">    &lt;select id="queryWithWeight" resultMap="DocumentWithWeightResultMap"&gt;
        select ii.docid, title, url, content, weight
        from inverted_indexes ii
        join forward_indexes fi
        on ii.docid = fi.docid
        where word = #{word}
        order by weight desc
        limit ${limit}
        offset ${offset}
    &lt;/select&gt;</code></pre>
    <hr/>
    <p>
     完整代码：
    </p>
    <p>
     构造索引：
     <a href="https://gitee.com/hlingqi/search-engines" rel="nofollow" title="搜索引擎_构建索引模块: 写一个搜索引擎的项目">
      搜索引擎_构建索引模块: 写一个搜索引擎的项目
     </a>
    </p>
    <p>
     搜索模块：
     <a href="https://gitee.com/hlingqi/search-engine-search-module" rel="nofollow" title="https://gitee.com/hlingqi/search-engine-search-module">
      https://gitee.com/hlingqi/search-engine-search-module
     </a>
    </p>
    <p>
     项目测试：
     <a href="https://blog.csdn.net/weixin_61567666/article/details/126350202" title="[测试] 搜索引擎的相关测试_我要敲代码6400的博客-CSDN博客">
      [测试] 搜索引擎的相关测试_我要敲代码6400的博客-CSDN博客
     </a>
    </p>
   </div>
  </div>
 </article>
</div>


<p class="artid" style="display:none">68747470733a2f2f626c6f672e:6373646e2e6e65742f77656978696e5f36313536373636362f:61727469636c652f64657461696c732f313236333030393630</p>
