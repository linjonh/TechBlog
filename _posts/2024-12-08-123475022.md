---
layout: post
title: "android-音视频录制"
date: 2024-12-08 17:30:25 +0800
description: "文章浏览阅读5.4k次。android 音视频录制_安卓开发 audiorecord不能录制视频声音"
keywords: "离屏渲染,FBO,MediaMuxer"
categories: ['音视频']
tags: ['音视频']
artid: "123475022"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=123475022
    alt: "android-音视频录制"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     android 音视频录制
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     所用到的东西，
    </p>
    <p>
     FBO：离屏渲染，得到视频数据，这里用FBO是为了以后扩展特效预留；
    </p>
    <p>
     MediaMuxer：封装音视频输出成MP4
    </p>
    <p>
     AudioRecord：录制音频；
    </p>
    <p>
     MediaCode:编解码，把音频编码成AAC ，把视频编码成AVC也就是H264
    </p>
    <p>
    </p>
    <p>
     整个流程图如下：
    </p>
    <p>
     <img alt="" height="131" src="https://i-blog.csdnimg.cn/blog_migrate/83438a5ca0c135a5cd2dec68b39f71eb.png" width="703"/>
    </p>
    <p>
    </p>
    <h4>
     视频流程：
    </h4>
    <p>
     自定义GLSurfaceView,因为GLSurfaceView继承SurfaceView 把一些GL的东西做了，不用再做，
    </p>
    <p>
     然后把SurfaceTexture给Camera,
    </p>
    <pre>mCamera.setPreviewTexture(surfaceTexture); </pre>
    <p>
     这个是离屏渲染，OpenGL 不能直接拿到相机的数据，通过绑定纹理的方式去预览，拿到每帧渲染数据；通过Renderer onDrawFrame接口回调，这个时候就进行预览绘制，和录制的离屏绘制，然后把离屏绘制的纹理id给录制类进行处理；
    </p>
    <pre>// 这个是手动刷新毎帧
mSurfaceTexture.updateTexImage();
// 预览相机的处理
mSurfaceTexture.getTransformMatrix(mtx);
mCameraFilter.setMatrix(mtx);
int textureId = mCameraFilter.onDrawFrame(mTextureID[0]);
// 绘制
mScreenFilter.onDrawFrame(textureId);</pre>
    <p>
     然后再去单独处理录制的，
    </p>
    <p>
     录制的我使用Android自带的OpenGL es,所以需要EGL；然后通过MedicCodec 去缓冲区拿数据并编码，这里需要在同一线程，
    </p>
    <pre>/**
 * 4.配置EGL 环境
 */
HandlerThread handlerThread = new HandlerThread("MyMediaRecorder");
handlerThread.start();
Looper looper = handlerThread.getLooper();
mHandler = new Handler(looper);
mHandler.post(new Runnable() {
    @Override
    public void run() {
        mEGL = new MyEGL(mEGLContext, mInputSurface, mContext, mWidth, mHeight);
        mMediaCodec.start();
        isStart = true;
    }
});</pre>
    <pre>/**
 * 录制 真正执行编码的函数
 *
 * @param textureId
 * @param timestamp 时间戳
 */
public void encodeFrame(final int textureId, final long timestamp) {
    if (!isStart) {
        return;
    }
    if (mHandler != null) {
        mHandler.post(new Runnable() {
            @Override
            public void run() {
                if (mEGL != null) {
                    mEGL.draw(textureId, timestamp);
                }
                getEncodeedData(false);
            }
        });
    }
}</pre>
    <p>
     视频编码后的数据放到Mp4RecorderCalbackRenderer里的队列中，然后让MediaMuxer去封装，为什么要放队列？因为还有音频需要一起处理；
    </p>
    <p>
    </p>
    <h4>
     音频处理：
    </h4>
    <p>
     使用AudioRecord 录音然后循环取数据，
    </p>
    <pre>while (mIsRecording){
    int len = mAudioRecord.read(mBuffer,0,mBuffer.length);
    if (len&gt;0){
        if (mAacEncoder== null){
            return;
        }
        mAacEncoder.queueData(mBuffer);
    }
}</pre>
    <p>
     然后编码给Mp4RecorderCalbackRenderer 队列中，然后让MediaMuxer封装；
    </p>
    <p>
     MediaMuxer是使用时间戳来同步音视频；
    </p>
    <p>
     详细的代码：
     <a href="https://gitee.com/amszhang/Seven" rel="nofollow" title="Seven: Android音视频">
      Seven: Android音视频
     </a>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f32353930393435332f:61727469636c652f64657461696c732f313233343735303232" class_="artid" style="display:none">
 </p>
</div>


