---
layout: post
title: "音视频同步原理解析音频编码和解码原理"
date: 2024-11-29 17:28:50 +0800
description: "视频流中的DTS／PTS到底是什么?DTS（解码时间戳）和PTS（显示时间戳）分别是解码器进行解码和"
keywords: "杜比dts解码芯片工作原理"
categories: ['音视频编解码技术', '流媒体技术']
tags: ['无标签']
artid: "70882515"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=70882515
    alt: "音视频同步原理解析音频编码和解码原理"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     音视频同步原理解析；音频编码和解码原理
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <h4 style='font-family:Helvetica,"Tahoma, Arial",sans-serif; font-weight:400; line-height:1.5em; color:rgb(85,85,85); margin:0px 0px 5px; font-size:16px; padding:0px'>
     视频流中的DTS／PTS到底是什么?
    </h4>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     DTS（解码时间戳）和PTS（显示时间戳）分别是解码器进行解码和显示帧时相对于SCR（系统参考）的时间戳。SCR可以理解为解码器应该开始从磁盘读取数据时的时间。
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     mpeg文件中的每一个包都有一个SCR时间戳并且这个时间戳就是读取这个数据包时的系统时间。通常情况下，解码器会在它开始读取mpeg流时启动系统时钟（系统时钟的初始值是第一个数据包的SCR值，通常为0但也可以不从0开始）。
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     DTS 时间戳决定了解码器在SCR时间等于DTS时间时进行解码，PTS时间戳也是类似的。通常，DTS/PTS时间戳指示的是晚于音视频包中的SCR的一个时 间。例如，如果一个视频数据包的SCR是100ms（意味着此包是播放100ms以后从磁盘中读取的），那么DTS/PTS值就差不多是200 /280ms，表明当SCR到200ms时这个视频数据应该被解码并在80ms以后被显示出来（视频数据在一个buffer中一直保存到开始解码）下 溢通常发生在设置的视频数据流相关mux率太高。
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     如果mux率是1000000bits/sec（意味着解码器要以1000000bits/sec的速率 读取文件），可是视频速率是2000000bits/sec（意味着需要以2000000bits/sec的速率显示视频数据），从磁盘中读取视频数据时 速度不够快以至于1秒钟内不能够读取足够的视频数据。这种情况下DTS/PTS时间戳就会指示视频在从硬盘中读出来之前进行解码或显示（DTS/PTS时间戳就要比包含它们的数据包中的SCR时间要早了）。
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     如今依靠解码器，这基本已经不是什么问题了（尽管MPEG文件因为应该没有下溢而并不完全符合MPEG标准）。一些解码器（很多著名的基于PC的播放器）尽可能快的读取文件以便显示视频，可以的话直接忽略SCR。
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     注意在你提供的列表中，平均的视频流速率为～3Mbps（3000000bits/sec）但是它的峰值达到了14Mbps（相当大，DVD限制在 9.8Mbps内）。这意味着mux率需要调整足够大以处理14Mbps的部分， bbMPEG计算出来的mux率有时候太低而导致下溢。
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     你计划让视频流速率这么高么？这已经超过了DVD的说明了，而且很可能在大多数独立播放其中都不能播放。如果你不是这么计划，我会从1增加mquant的值并且在视频设置中将最大码流设置为9Mbps以保持一个小一点的码流。
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     如果你确实想让视频码率那么高，你需要增大mux率。从提供的列表可以得出bbMPEG使用14706800bits/sec或者1838350bytes /sec的mux率（总数据速率为：1838350bytes/sec（14706800bits/sec）行）。你在强制mux率字段设置的值应该是以 bytes/sec为单位并被50整除。所以我会从36767（1838350/50）开始，一直增加直到不会再出现下溢错误为止。
    </div>
    <h4 style='font-family:Helvetica,"Tahoma, Arial",sans-serif; font-weight:400; line-height:1.5em; color:rgb(85,85,85); margin:0px 0px 5px; font-size:16px; padding:0px'>
     音视频同步原理[ffmpeg]
    </h4>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     ffmpeg对视频文件进行解码的大致流程：
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     1. 注册所有容器格式和CODEC: av_register_all()
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     2. 打开文件: av_open_input_file()
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     3. 从文件中提取流信息: av_find_stream_info()
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     4. 穷举所有的流，查找其中种类为CODEC_TYPE_VIDEO
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     5. 查找对应的解码器: avcodec_find_decoder()
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     6. 打开编解码器: avcodec_open()
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     7. 为解码帧分配内存: avcodec_alloc_frame()
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     8. 不停地从码流中提取中帧数据: av_read_frame()
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     9. 判断帧的类型，对于视频帧调用: avcodec_decode_video()
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     10. 解码完后，释放解码器: avcodec_close()
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     11. 关闭输入文件:av_close_input_file()
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     output_example.c 中AV同步的代码如下(我的代码有些修改)，这个实现相当简单，不过挺说明问题。
    </div>
    <h4 style='font-family:Helvetica,"Tahoma, Arial",sans-serif; font-weight:400; line-height:1.5em; color:rgb(85,85,85); margin:0px 0px 5px; font-size:16px; padding:0px'>
     音视频同步-时间戳
    </h4>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     媒体内容在播放时，最令人头痛的就是音视频不同步。从技术上来说，解决音视频同步问题的最佳方案就是时间戳：首先选择一个参考时钟（要求参考时钟上的时间是线性递增的）；生成数据流时依据参考时钟上的时间给每个数据块都打上时间戳（一般包括开始时间和结束时间）；在播放时，读取数据块上的时间戳，同时参考当前参考时钟上的时间来安排播放（如果数据块的开始时间大于当前参考时钟上的时间，则不急于播放该数据块，直到参考时钟达到数据块的开始时间；如果数据块的开始时间小于当前参考时钟上的时间，则“尽快”播放这块数据或者索性将这块数据“丢弃”，以使播放进度追上参考时钟）。
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     可见，避免音视频不同步现象有两个关键——一是在生成数据流时要打上正确的时间戳。如果数据块上打的时间戳本身就有问题，那么播放时再怎么调整也于事无补。假如，视频流内容是从0s开始的，假设10s时有人开始说话，要求配上音频流，那么音频流的起始时间应该是10s，如果时间戳从0s或其它时间开始打，则这个混合的音视频流在时间同步上本身就出了问题。打时间戳时，视频流和音频流都是参考参考时钟的时间，而数据流之间不会发生参考关系；也就是说，视频流和音频流是通过一个中立的第三方（也就是参考时钟）来实现同步的。第二个关键的地方，就是在播放时基于时间戳对数据流的控制，也就是对数据块早到或晚到采取不同的处理方法。图2.8中，参考时钟时间在0-10s内播放视频流内容过程中，即使收到了音频流数据块也不能立即播放它，而必须等到参考时钟的时间达到10s之后才可以，否则就会引起音视频不同步问题。
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     基于时间戳的播放过程中，仅仅对早到的或晚到的数据块进行等待或快速处理，有时候是不够的。如果想要更加主动并且有效地调节播放性能，需要引入一个反馈机制，也就是要将当前数据流速度太快或太慢的状态反馈给“源”，让源去放慢或加快数据流的速度。熟悉DirectShow的读者一定知道，DirectShow中的质量控制（Quality Control）就是这么一个反馈机制。DirectShow对于音视频同步的解决方案是相当出色的。但WMF SDK在播放时只负责将ASF数据流读出并解码，而并不负责音视频内容的最终呈现，所以它也缺少这样的一个反馈机制。
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     音视频同步通讯SDK源码包分享：
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     Android：http://down.51cto.com/data/711001
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     Windows：http://down.51cto.com/data/715497
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     Linux：http://download.csdn.net/detail/weixiaowenrou/5169796
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     IOS：http://down.51cto.com/data/715486
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     WEB：http://down.51cto.com/data/710983
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     <a href="http://6352513.blog.51cto.com/6342513/1180742" rel="nofollow noopener noreferrer" style="background:transparent; color:rgb(43,145,232); text-decoration:none" target="_blank">
      http://6352513.blog.51cto.com/6342513/1180742
     </a>
     <br style=""/>
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     <br style=""/>
    </div>
    <div style='margin:0px; padding:0px; line-height:1.5em; font-family:"Microsoft Yahei"; font-size:14px; color:rgb(85,85,85)'>
     <h2 style="margin:0px 0px 10px; font-size:24px; font-family:微软雅黑,宋体,Arial; font-weight:400; line-height:36px; color:rgb(34,34,34); padding:0px; background:none">
      音频编码和解码原理
     </h2>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       <a href="http://www.elecfans.com/soft/72/2010/2010071279927.html" rel="nofollow noopener noreferrer" style="background:transparent; color:rgb(0,66,118); text-decoration:none" target="_blank">
        音频编码
       </a>
       和解码原理
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       每张CD光盘重放双声道立体声信号可达74分钟。VCD视盘机要同时重放声音和图像，图像信号数据需要压缩，其伴音信号数据也要压缩，否则伴音信号难于存储到VCD光盘中。
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       <span style="">
        一、伴音压缩
        <a href="http://www.elecfans.com/soft/72/2009/2009091947413.html" rel="nofollow noopener noreferrer" style="background:transparent; color:rgb(0,66,118); text-decoration:none" target="_blank">
         编码原理
        </a>
       </span>
       <br style=""/>
       伴音信号的结构较图像信号简单一些。伴音信号的压缩方法与图像信号压缩技术有相似性，也要从伴音信号中剔除冗余信息。人耳朵对音频信号的听觉灵敏度有其其规律性，对于不同频段或不同声压级的伴音有其特殊的敏感特性。在伴音数据压缩过程中，主要应用了听觉阈值及掩蔽效应等听觉心理特性。
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       <span style="">
        1、阈值和掩蔽效应
       </span>
       <br style=""/>
       (1) 阈值特性
       <br style=""/>
       人耳朵对不同频率的声音具有不同的听觉灵敏度，对低频段(例如100Hz以下)和超高频段(例如16KHZ以上)的听觉灵敏度较低，而在1K－5KHZ的中音频段时，听觉灵敏度明显提高。通常，将这种现象称为人耳的阈值特性。若将这种听觉特性用曲线表示出来，就称为人耳的阈值特性曲线，阈值特性曲线反映该特性的数值界限。将曲线界限以下的声音舍弃掉，对人耳的实际听音效果没有影响，这些声音属于冗余信息。
       <br style=""/>
       在伴音压缩编码过程中，应当将阈值曲线以上的可听频段的声音信号保留住，它是可听频段的主要成分，而那些听觉不灵敏的频段信号不易被察觉。应当保留强大的信号，忽略舍弃弱小的信号。经过这样处理的声音，人耳在听觉上几乎察觉不到其失真。在实际伴音压缩编码过程中，也要对不同频段的声音数据进行量化处理。可对人耳不敏感频段采用较粗的量化步长进行量化，可舍弃一些次要信息；而对人耳敏感频段则采用较细小的量化步长，使用较多的码位来传送。
       <br style=""/>
       (2)掩蔽效应
       <br style=""/>
       掩蔽效应是人耳的另一个重要生理特征。如果在一段较窄的频段上存在两种声音信号，当一个强度大于另一个时，则人耳的听觉阈值将提高，人耳朵可以听到大音量的声音信号，而其附近频率小音量的声音信号却听不到，好像是小音量信号被大音量信号掩蔽掉了。由于其它声音信号存在而听不到本声音存在的现象，称为掩蔽效应。
       <br style=""/>
       根据人耳的掩蔽特性，可将大音量附近的小音量信号舍弃掉，对实际听音效果不会发生影响。既使保留这些小音量信号，人耳也听不到它们的存在，它属于伴音信号中的冗余信息。舍弃掉这些信号，可以进一步压缩伴音数据总量。
       <br style=""/>
       经仔细观察，掩蔽效应分为两大类，一类是同时掩蔽效应，另一类是短时掩蔽效应。其中，同时掩蔽效应是指同时存在一个弱信号和一个强信号，两者频率接近，强信号将提高弱信号的听阈值，将弱信号的听阈值提高到一定程度时，可使人耳听不到弱信号。例如，同时出现A、B两声，若A声的听觉阈值为50dB，由于存在另一个不同频率的B声，将使A声的阈值提高到64～68dB，例如取68dB，那么数值(68～50)dB=18dB，该值称为掩蔽量。将强大的B声称为掩蔽声，而较弱的A声称为被掩蔽声。上述掩蔽现象说明，若仅有A声时，其声压级50dB以上的声音可以传送出去，而50dB以下的声音将听不到；若同时出现B声，B声具有同时掩蔽效应，使得A声在声压级68dB以下的声音也听不到了，即50～68dB之间的A声人耳也听不到了，这些声音不必传送，即使传送也听不到，只须传送声压级68dB以上的声音。总之，为了提高一个声音的阈值，可以同时设置另一个声音，使用这种办法可以压缩掉一部分声音数据。在周围十分安静的环境下，人耳可以听到声压级很低的各种频率声音，但对低频声和高频声的掩蔽阈值较高，即听觉不灵敏。经研究还发现，掩蔽声越强，掩蔽作用越强；当掩蔽声与被掩蔽声的频率相差越小，掩蔽效果越明显，两者频率相等时，掩蔽效果最佳；低频声(设为B)可有效地掩蔽高频声(设为A)，而高频声(设为B)几乎不能掩蔽低频声(设为A)。因而输入信号时，在受掩蔽的频带内加入更大的噪声时，人耳也感觉不到与原始信号有所区别。上述的同时掩蔽效应，又称为频域掩蔽效应，它主要反映在频域方面对掩蔽作用的影响。在声音压缩编码中，更多地使用单频声音的掩蔽效应。
       <br style=""/>
       如果A声和B声不同时出现，也可发生掩蔽作用，称它为短时掩蔽效应。短时掩蔽又可分为两种类型，作用仍可持续一段时间，即后向掩蔽和前向掩蔽。后向掩蔽是指掩蔽声B消失后，其掩蔽作用仍可持续一段时间，一般可达0.5～2秒。掩蔽机理是人耳的存储效应所致。而前向掩蔽是指被掩蔽声A出现一段时间后出现掩蔽声B，只要A、B声音隔不太大(一般在0.05～0.2秒以内)，B也可对A起掩蔽作用。掩蔽机理是A声尚未被人耳感知接受时，强大的B声已来临所致。在实践中，后向掩蔽有较高的应用价值。短时掩蔽效应具有很强的时域结构特性，故又称为时域掩蔽效应。在声音压缩编码中，应兼顾好人耳的频域和时域两种掩蔽效应。
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       <span style="">
        2、子带编码原理
       </span>
       <br style=""/>
       (1)子带编码和解码过程
       <br style=""/>
       所谓子带编码技术，是将原始信号由时间域转变为频率域，然后将其分割为若干个子频带，并对其分别进行数字编码的技术。它是利用带通滤波器(BPF)组把原始信号分割为若干(例如m个)子频带(简称子带)。
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       <img alt="图2.3.1子带编码示意图 http://www.elecfans.com" border="0" height="371" src="https://i-blog.csdnimg.cn/blog_migrate/f2128ffaf5618a775ed3007978eb8206.jpeg" style="border:0px; vertical-align:middle; max-width:100%; width:350px; height:371px" width="350"/>
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       在接收端实现发送端的逆过程。输入子带编码数据流，将各子带信号分别送到相应的数字解码电路(共m个)进行数字解调，经过诸路低通滤波器(m路)，并重新解调，可把各子带频域恢复为当初原始信号的分布状态。最后，将各路子带输出信号送到同步相加器，经过相加恢复为原始信号，该恢复的信号与原始信号十分相似。
       <br style=""/>
       (2)子带编码的应用
       <br style=""/>
       子带编码技术具有突出的优点。首先，声音频谱各频率分量的幅度值各不相同，若对不同子带分配以合适的比例系数，可以更合理地分别控制各子带的量化电平数目和相应的重建误差，使码率更精确地与各子带的信号源特性相匹配。通常，在低频基音附近，采用较大的比特数目来表示取样值，而在高频段则可分配以较小的编码比特。其次，通过合理分配不同子带的比特数，可控制总的重建误差频谱形状，通过与声学心理模型相结合，可将噪声频谱按人耳主观噪声感知特性来形成。于是，利用人耳听觉掩蔽效应可节省大量比特数。
       <br style=""/>
       在采用子带编码时，利用了听觉的掩蔽效应进行处理。它对一些子带信号予以删除或大量减少比特数目，可明显压缩传输数据总量。比如，不存在信号频率分量的子带，被噪声掩蔽的信号频率的子带，被邻近强信号掩蔽的信号频率分量子带等，都可进行删除处理。另外，全系统的传输信息量与信号的频带范围、动态范围等均有关系，而动态范围则决定于量化比特数，若对信号引入合理的比特数，可使不同子带内按需要给以不同的比特数，也可压缩其信息量。
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       二、MPEG-1音频编码方框图
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       <span style="">
        1、MPEG-1音频编码的依据
       </span>
       <br style=""/>
       MPEG-1音频压缩编码标准采用了心理学算法。利用感知模型删去那些听觉不灵敏的声音数据，而使重建的声音质量无明显下降。它采用子带编码技术，根据心理声学模型取得不同子带的听觉掩蔽阈值；对各子带的取样值进行动态量化。它根据不同频段上大音量信号所引起的小音量信号掩蔽阈值的变化规律，对不同频段给以不同的量化步长，以便保留主要信号，而舍弃对听觉效果影响很小的成分，经过数据压缩，可取得合理的比特流，将原来大约1.5Mbit/s的声音传输码率减少到0.3Mbit/s，即压缩率可达到1/5。
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       <span style="">
        2、编码流程
        <br style=""/>
       </span>
       图2.3.2是基于MUSICAM(掩蔽模式通用子带编码和多路复用)的MPEG-1音频压缩编码方框图。输入信号是经过取样的二进制PCM数字音频信号，取样频率可以取44.1KHz、48KHz或32KHz，该音频数码信号的码值与原来采样信号的幅度、频率成正比。
       <br style=""/>
       <img alt="图2.3.2 MPEG-1音频编码方框图 http://www.elecfans.com" border="0" height="193" src="https://i-blog.csdnimg.cn/blog_migrate/ea6ab8a2c98546a23fbc0581d86a07ef.jpeg" style="border:0px; vertical-align:middle; max-width:100%; width:528px; height:193px" width="528"/>
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       数字音频信号首先进入数字滤波器组，它被分成等带宽的32个子频带，可由数字滤波器输出32个子带数据信号。这种处理方法与图像编码信号进行DCT变换的作用相似，但不是像图像信号那样分为64种余弦频率信息，这里仅分成32个子带，即将音频数据流改为32种频率的组合。声音的分解力低于图像，这种处理方法是可行的。然后，对32个子带的伴音数据进行再量化，以便再压缩数据量。对于各个子频带的量化步长不相同，量化步长是根据人耳的听觉阈值和掩蔽效应而确定的。经过量化处理的已压缩数据，保留了伴音信息的主体部分，而舍弃了听觉效果影响较小的伴音信息。
       <br style=""/>
       进入编码系统的输入信号，分流部分信号送到并列的1024点快速傅利叶变换器(FFT)进行变换，它检测输入信号每一个瞬间取样点在主频谱分量频域的分布的强度，经变换的信号送到心理声学模型控制单元。根据听觉心理声学测量统计结果，可以归纳出一个心理声学控制对照表格，并按照此表格制成控制单元，而单元电路可以集中地反映出人耳的阈值特性和掩蔽特性。
       <br style=""/>
       经过量化的32个子频带数据已经被压缩，还要加上比例因子、位分配信息等辅助信息，共同加到1位流格式化单元，编码成为两个层次的伴音编码信号。它既含有32个子频带的伴音数码，又带有这些数码所对应的位分配数据和不同频带数据的强弱比例因子。待将来数据解码时，可根据各子频带的数据恢复声音信号，以及压缩时码位分配和强弱比例情况，在进行反量化时，参照压缩时的程序进行还原。
       <br style=""/>
       可见，伴音的压缩编码和图像处理一样，也要经过变换、量化、码位压缩等处理过程，它运用了许多数学模型和心理听觉测量的统计数据，对32个子频带和各个层次信号的处理也各有不相同的取样速率。实际的心理听觉模型和适时处理控制过程十分复杂。这些算法细节都已按硬件方式被固化在解码芯片中，这些内容不能再改变。
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       <span style="">
        3、伴音与图像的同步
        <br style=""/>
       </span>
       图像和声音信号的压缩方法有许多不同，图像数据量又远远大于声音数据量，两者传送的数据码率大不相同。每传送14～15个视频数据包才传送1个音频数据包，而播放声音和图像的内容又必须作到良好同步，否则将无法保证视听统一的效果。
       <br style=""/>
       为了作到声图同步，MPEG-1采用了独立的系统时钟(简称为STC)作为编码的参照基准，并将图像和声音的数据分为许多播放单元。例如，将图像分为若干帧，将声音分为若干段落。在数据编码时，在每个播放单元前面加置一个展示时标(PTS)，或者加置一个解码时标(DTS)。当这些时标出现时，表示前一个播放单元已经结束，一个新的图像和声音播放单元立即开始。在播放相互对应的同一图像单元和声音单元时，可实现互相同步。
       <br style=""/>
       为了使整个系统在时钟在编码和重放时，声图有共同的时钟基准，又引入系统参考时钟SCR的概念。系统参考时钟是一个实时时钟，其数值代表声图的实际播放时间，用它作为参照基准，以保证声图信号的传输时间保持一致。实时时钟SCR必须与生活中的真实时间一致，要求它的准确度很高，否则可能发生声音和图像都播快或播慢的现象。为了使SCR时间基准稳定、准确，MPEG-1采用了系统时钟频率SCF，以它作为定时信息的参照基础。SCF系统时钟的频率是90KHz，频率误差为90KHz±4.5KHz。声图信号以SCF为统一的基准，其它定时信号SCR、PTS、DTS也是以它为基础。
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       三、其它MPEG标准的音频编码器
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       <span style="">
        1、MPEG-2音频编码方框图
        <br style=""/>
       </span>
       <a href="http://www.elecfans.com/soft/161/2009/2009112855903.html" rel="nofollow noopener noreferrer" style="background:transparent; color:rgb(0,66,118); text-decoration:none" target="_blank">
        MPEG-1
       </a>
       是处理双声道立体声信号，而MPEG-2是处理5声道（或7声道）环绕立体声信号，它的重放效果更加逼真。
       <br style=""/>
       图2.3.3是MPEG-2音频编码方框图。它输入互相独立的5声道音频信号，有前置左、右主声道(L、R)，前置中央声道(C)，还有后置左、右环绕声道(LS、RS)。各声源经过模－数转化后，首先进入子带滤波器，每一声道都要分割为32个子频带，各子带的带宽均为750Hz。为了兼容MPEG-1、普通双声道立体声和环绕模拟立体声等编码方式，原来按MPEG-1编码的立体声道能够扩展为多声道，应当包括所有5声道的信息，为此设置了矩阵变换电路。该电路可生成兼容的传统立体声信号LO、RO，还有经过“加重”的左、中、右、左环绕、右环绕声音信号(共5路)。对5路环绕立体声信号进行“加重”处理的原因：当计算兼容的立体声信号(LO、RO)时，为了防止过载,已在编码前对所有信号进行了衰减，经加重处理可以去失真；另外，矩阵转变中也包含了衰减因子和类似相移的处理。
       <br style=""/>
       编码器原始信号是5路，输入通道是5个，经过矩阵转化处理后产生了7种声音信号。应当设置通道选择电路，它能够根据需要，对7路信号进行合理的选择处理。该处理过程决定于解矩阵的过程，以及传输通道的分配信息；合理的通道选择，有利于减弱人为噪声加工而引起的噪声干扰。此外，还设置了多声道预测计算电路，用于减少各通道间冗余度。在进行多声道预测时，在传输通道内的兼容信号LO、RO，可由MPEG-1数据计算出来。根据人耳生理声学基
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <a href="https://i-blog.csdnimg.cn/blog_migrate/40c29328872b5c3258dd67f152312b04.jpeg" rel="nofollow noopener noreferrer" style="background:transparent; color:rgb(0,66,118); text-decoration:none" target="_blank">
       <img alt="图2.3.3  MPEG-2音频编码方框图" border="0" height="312" src="https://i-blog.csdnimg.cn/blog_migrate/40c29328872b5c3258dd67f152312b04.jpeg" style="border:0px; vertical-align:middle; max-width:100%; width:529px; height:312px" width="529"/>
      </a>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       础，后级设置了动态串话电路，可在给定比特的情况下提高声音质量，或在要求声音质量的前提下降低比特率。但设置该电路增加了MPEG-2解码器的复杂程度。
       <br style=""/>
       经过编码器产生了多种信息，主要有编码取样值，比例因子，比特分配数据，动态串话模式，多声道预测信息，通道预测选择信号等，诸信息传递给复接成帧模块电路，最后以MPEG-2比特流形式输出压缩编码信号。
       <br style=""/>
       MPEG-2解码器基本上是编码器的逆过程，其电路结构简单一些，运算量小一些。解码器的解码转换矩阵可输出5路信号，再经过32分频子带滤波器处理，可输出LS、L、C、R、RS信号；另外，经过量化、SCF和子带滤波器处理后，还可以取得前置立体声LO、RO，共计可输出7路音频信号。
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       <span style="">
        2、MPEG-4音频解码
       </span>
       <br style=""/>
       <a href="http://www.elecfans.com/soft/study/digital/2009/2009081040468.html" rel="nofollow noopener noreferrer" style="background:transparent; color:rgb(0,66,118); text-decoration:none" target="_blank">
        MPEG-4
       </a>
       音频编码和MPEG-4视频编码一样，具有许多特点和功能，例如可分级性，有限时间音频流，音频变化/时间尺度变化，可编辑性，延迟性等。它具优越的交互性能和高压缩比。它不仅利用分级方法可对语言和音乐进行编辑，也能解决合成语言和音乐问题，它将成为多媒体世界的一个主要格式，将成为“全能”的系统。
       <br style=""/>
       通过MPEG-4音频编码，可以存储、传送多种音频内容。它具有高质量的音频信号(单声道、立体声和多通道)。它采用低码率编码，而声音重放质量很高。它可以传送宽带语言信号(例如7KHz宽的语音)，也可传送窄带宽语言信号(例如长途电话)。可以传输、制作可理解的各种语音信号。可以合成语言，例如进行音素或其它记号为基础的文本转换；也可以合成音频，例如支持音乐描述语言。
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       <span style="">
        四、杜比AC-3技术
        <br style=""/>
       </span>
       1、什么是杜比AC-3
       <br style=""/>
       在杜比定向逻辑环绕声技术的基础上，于1990年杜比公司与日本先锋公司合作，采用先进的数位压缩技术，推出新颖的全数字化杜比数码环绕声系统。它可使多声道信号有更多的信息被压缩到双声道中去，并将这种系统称为AC-3。AC是英语“音频感觉编码系统”的缩写词。AC-3技术首先应用到电影院，后来又进入普通家庭。
       <br style=""/>
       杜比AC-3系统设置完全独立的6个声道，即全频带的左、中、右、左环绕和右环绕声道，再加上一个超重低音声道。由于这样声道的结构，AC-3系统又称为5.1声道。
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       <span style="">
        <span style="">
         2、杜比AC-3的基本原理
        </span>
        <br style=""/>
        (1)应用听觉掩蔽效应开发出自适应编码系统
        <br style=""/>
        AC-3技术的理论基础，也是利用心理声学中的听觉阈值和掩蔽效应，但具体技术上与MPEG标准又有所不同。
        <br style=""/>
        对音频信号进行数据处理时，都要进行数据压缩，将没有用途或用途不大的数据信息忽略掉。为此，可以应用听觉阈值和掩蔽规律，省略掉那些多余的数据信息。杜比公司除运用上述声学原理外，还运用了它拥有的杜比降噪技术，开发出数码化的“自适应编码”系统。这是一种极具选择性和抑制噪声能力的自适应编码体系。杜比公司依据音响心理学的基本原理，在未输入音乐信号时，保持宁静状态；当输入音乐信号时，对复杂的音频信号进行分析和分解，用较强信号掩蔽噪声，删除听觉界限以外，或由于频率相近而音量小的信号，经过这种处理方法，可以大大减少需要处理的数据信息。人耳的听觉范围是20Hz－20KHz，在如此宽阔的频带范围内，人耳对不同频率的听觉灵敏度具有极大的差异。杜比AC-3根据这个特性，将各声道的音响频道划分为许多大小不等的狭窄频带，各个子频带与人耳临界频带的宽度相接近，保留有效的音频，将不同的噪声频率紧跟每个声道信号进行编码，即编码噪声只能存在于编码音频信号的频带内。这样能够更陡峭地滤除掉编码噪声，将频带内多余信号和无音频信号的编码噪声降低或除掉，而将有用的音频信号保留下来。AC-3系统精确地运用了掩蔽效应和“公用位元群”的设计方法，使数据压缩效率大大提高，且具有很高水平的音质。该系统的比特率是根据个别频谱的需要，或者音源的动态状况，再分配到每个窄频段，它设计了内置的听觉掩盖程序，可让编码器改变其频率灵敏度和时间分解力，以确保有充足的比特被采用，掩盖掉噪声，而良好地记录音乐信号。
        <br style=""/>
        为了高效地利用有限的信息传输介质(光盘、胶片等)，它在压缩音频信号时与其它压缩系统一样，利用人耳的听觉特性，根据当时的具体情况，将某些声道的系数合并(这些声道系数反映了那个频带的能量大小)，以便提高压缩率。并不是所有声道都能进行这种合并。编码器可根据各声道的信息特征自动决定和调整，只有相似的声道才能混合在一起，若压缩比不要求很高时也不必合并。一般情况下，合并的起始频率越高，音质就越好，但要求数据传输速率也越高。当取样频率为48KHz时，合并的起始频率应为3.42MHz；若取样频率为44.1KHz时，起始频率应为3.14MHz。若硬件和软件搭配适当，AC-3的音质可达到或接近CD唱片的水平。
        <br style=""/>
        (2)杜比AC-3解码器简易方框图
        <br style=""/>
        AC-3解码器输入信号是一组频谱信号，它是由时域信号PCM数据经过时－频变换而得到。该频谱数据流分为指数部和尾数部两部分，指数部分采用差分方式进行编码，编码后的指数代表了整个信号的频谱，可作为频谱包络的参数。其尾数部分按照比特分配的结果进行量化。于是，量化尾数和频谱包络形成了AC-3码流的主要信息，连同其它辅助信号(例如比特分配等)构成了AC-3比特流。
        <br style=""/>
        图2.3.4是AC-3系统的解码方框图，它是AC-3编码的逆过程。AC-3比特流首先进入缓冲级，然后以帧为处理单元进行误码纠错，经纠错处理后对比特流中的固定数据(指数数据、匹配系数、模式符号等)解码，使数据比特流恢复为原来的比特分配。
        <br style=""/>
       </span>
       <img alt="图2.3.4  AC-3解码器方框图" border="0" src="https://i-blog.csdnimg.cn/blog_migrate/08ca782480a8b610f07cd09134960dc1.jpeg" style="border:0px; vertical-align:middle; max-width:100%"/>
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       然后，数据信号分为两路。其中一路，将比特流恢复为原来的比特分配之后，确定尾数部量化的大小，再对比特流中的可变数据解码；再接着恢复高频成分，为反频率变换做好准备。最后，将指数部数据和尾数部数据汇合，变换为固定小数点数据，再对它进行频率变换，以获得时间轴数据。已经恢复为时域的数据信号需进行窗处理，进行重叠加算，即可得到5.1环绕声道的输出信号。
      </span>
     </p>
     <p style="margin-top:0px; margin-bottom:20px; padding-top:0px; padding-bottom:0px; line-height:25px; font-family:宋体,arial">
      <span style="font-family:Verdana">
       <span style="">
        3、杜比AC-3的特点
        <br style=""/>
       </span>
       (1)配置5.1声道
       <br style=""/>
       将输入的音频信号解码后，可以输出5.1声道信号，其中有3个前置声道(L、C、R)，还有2个后置环绕声道(LS、RS)，它们互相独立，频响宽度都是全声频域，即20Hz－20KHz(±0.5dB)及3Hz－20.3KHz(-3dB)，各频道的频响十分宽阔。目前，广泛应用于音响系统的杜比定向逻辑环绕声系统，无法和杜比AC-3频带宽度相比。还有，杜比定向逻辑环绕声系统实为4声道系统，即前置左、中、右和后置环绕声，它的环绕声实为单声道环绕声，两个后置环绕声道重放共同的声音信号，两声道采取并联甚至串联方式；其环绕声的频响被限制在100Hz－7KHz范围内；另外，它没有设置独立的超低音声道，它是由前置左、右声道分离出20Hz－120Hz的超重低音，来重放具有震撼效果的超重低音。AC-3系统配置了独立的超低声道，其频响为20Hz－120HZ(±0.5dB)及3Hz－121Hz(-3dB)，要求超低音箱的音量比其它各声道大10dB，具有更加震撼的低效果。
       <br style=""/>
       (2)各声道全数字化且互相独立
       <br style=""/>
       AC-3各声道互相独立地携带不同信号，是全数字化音频信号。取样频率是32、44.1或48KHz，数据传输量每声道为32kb/s－640kb/s，在5.1声道模式下取典型值384kb/s，在双声道模式下典型值为192kb/s。经过数字处理后，5个主声道的频率压缩在20Hz－20KHz范围内。
       <br style=""/>
       (3)可将5.1声道压缩输出
       <br style=""/>
       由于AC-3的“比特流”内对每种节目方式(单声道、立体声、环绕声等)都有一个“指导信号”，能使AC-3自动地为使用者指出节目方式。它可把5.1声道信号压缩为双声道，以供给录制常规VHS录像带，或作为杜比环绕声的输入节目源，以便与它兼容，它甚至可将5.1声道信号压缩为单声道输出。总之，AC-3可输出5.1声道杜比环绕声、混合4声道杜比环绕声、双声道立体声及单声道。将5.1声道数据压缩后所占频带较窄，例如可在LD影碟机的FM调制的右声道所占用的频带宽度内，编入AC-3数据编码，输出AC-3的RF信号，它的中心频率取在2.88MHz，可由LD原先的模拟输出右声道取出频率为2.88MHz的AC-3编码信号。于是，在原有一个模拟声道内就能够容纳5.1声道的全部内容。
       <br style=""/>
       (4)经过声音时间校准使音效极为理想
       <br style=""/>
       杜比AC-3将所有声道通过“时间校准”技术，使每个扬声器的声音好像与聆听者的距离相同，以产生更好的音响效果，其环绕声效果不仅是前、后、左、右的声源定位鲜明，上下的音场也清晰可辨。
      </span>
     </p>
    </div>
   </div>
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f776569797565666569:2f61727469636c652f64657461696c732f3730383832353135" class_="artid" style="display:none">
 </p>
</div>


