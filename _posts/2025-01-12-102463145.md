---
layout: post
title: "大数据运维的工作职责"
date: 2025-01-12 11:49:08 +0800
description: "一.集群管理  大数据需要分布式系统，也就是集群：Hadoop，Hbase，Spark，Kafka，"
keywords: "大数据运维的日常工作有哪些内容"
categories: ["未分类"]
tags: ["无标签"]
artid: "102463145"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=102463145
  alt: "大数据运维的工作职责"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     大数据运维的工作职责
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     一.集群管理
     <br/>
     大数据需要分布式系统，也就是集群：Hadoop，Hbase，Spark，Kafka，Redis等大数据生态圈组建。
    </p>
    <p>
     二.故障处理
     <br/>
     1&gt;.商用硬件使用故障是常态。
     <br/>
     2&gt;.区分故障等级，优先处理影响实时性业务的故障。
    </p>
    <p>
     三.变更管理
     <br/>
     1&gt;.以可控的方式，高效的完成变更工作；
     <br/>
     2&gt;.包括配置管理和发布管理；
    </p>
    <p>
     四.容量管理
     <br/>
     1&gt;.存储空间，允许链接数等都是容量概念；
     <br/>
     2&gt;.在多租户环境下，容量管理尤其重要；
    </p>
    <p>
     五.性能调优
     <br/>
     1&gt;.不同组建的性能概念不一样，如kafka注重吞吐量，Hbase注重实用性可用性;
     <br/>
     2&gt;.需要对组建有深刻的理解
    </p>
    <p>
     六.架构优化
     <br/>
     1&gt;.优化大数据平台架构，支持平台能力和产品的不断迭代;
     <br/>
     2&gt;.类似架构师的工作；
     <br/>
     复制代码
     <br/>
    </p>
    <p>
     三.大数据运维所需的能力
    </p>
    <p>
     复制代码
     <br/>
     一.DevOps
     <br/>
     DevOps(英文Development和Operations的组合)是一组过程，方法和系统的统称，用于促进开发（应用程序/软件工程），技术运营和质量保障（QA）部门之间的沟通，写作与整合。
     <br/>
     二.硬件，OS，网络，安全的基础知识
     <br/>
     大数据平台和组建设计范围广，各种都需要懂一点，这些知识出问题的时候不可能问人，因为别人也有自己的工作要做。
    </p>
    <p>
     三.脚本语言能力
     <br/>
     Shell,SQL(DDL),Python.Java（加分）
    </p>
    <p>
     四.大数据各个组件知识
     <br/>
     设计思想。使用范围，底层架构，常用命令，常用配置或参数，常见问题处理方法。
    </p>
    <p>
     五.工具能力
     <br/>
     Zabbix，Open Falcon，Ganglia，ELK等，企业自研工具。我推荐使用集群自带的工具。
    </p>
    <p>
     六.Trouble shooting能力
     <br/>
     搜索能力（搜索引擎，stackoverflow等），java能力（异常堆栈要看得懂，最好能看懂源码），英文阅读能力。
    </p>
    <p>
     七.意识，流程
     <br/>
     良好的意识，什么能做什么不能做。同用的流程如ITIL，各企业也有自己的流程。
     <br/>
     复制代码
     <br/>
    </p>
    <p>
     四.大数据运维的主要工作
    </p>
    <p>
     复制代码
     <br/>
     一.运维三板斧
     <br/>
     三板斧可以解决90%以上的故障处理工作。
     <br/>
     1&gt;.重启
     <br/>
     重启有问题的机器或经常，使其正常工作。
     <br/>
     2&gt;.切换
     <br/>
     主备切换或主主切换，链接正常工作的节点。
     <br/>
     3&gt;.查杀
     <br/>
     查杀有问题的进程，链接等。
     <br/>
     4&gt;.三板斧的问题
     <br/>
     第一：只能处理故障处理问题，不能解决性能调优，架构优化等问题；
     <br/>
     第二：只能治标，不能治本；
     <br/>
     5&gt;..大数据运维和传统运维的不同
     <br/>
     第一：传统运维面对的底层软硬件基本稳固，大数据运维面对的是商用硬件和复杂linux版本；
     <br/>
     第二：传统运维面对的是单机架构为主，大数据运维面对复杂的分布式架构；
     <br/>
     第三：传统运维大多维护闭源商业版系统，大数据运维通常面对开源系统，文档手册匮乏，对阅读源码要求高。
     <br/>
     第四：大数据运维对自动化工具的依赖大大增加；
    </p>
    <p>
     二.Iaas层（基础设置及服务）运维工作
     <br/>
     一般中大型企业有自己的基础设施维护团队，这部分工作不会交给大数据运维来做。小公司可能需要大数据运维键值这部分工作，主要关注三个方面：
     <br/>
     1&gt;.硬件
     <br/>
     大数据系统大多使用廉价PC Server或虚拟机，硬件故障是常态，通过告警，日志，维护命令等识别故障，并支持硬件更换。
     <br/>
     2&gt;.存储
     <br/>
     大多使用PC Server挂本磁盘的存储方式，极少情况会使用SAN（存储区域网络）或NAS（网络附属存储），熟悉分区，格式化，巡检等基本操作。
     <br/>
     3&gt;.网络
     <br/>
     网络的配置变更更需要比较专业的知识，如有需要可学习CCNA，CCNP等认证课程，但网络硬件和配置出问题概率很低，主要关注丢包，延时。
    </p>
    <p>
     三.HDFS运维工作
     <br/>
     1&gt;.容量管理
     <br/>
     第一：HDFS空间我使用超过80%要警惕，如果是多租户环境，租户的配额空间也能用完；
     <br/>
     第二：熟悉hdfs，fsck，distcp等常用命令，会使用DataNode均衡器；
    </p>
    <p>
     2&gt;.进程管理
     <br/>
     第一：NameNode的进程是重点
     <br/>
     第二：熟悉dfsadmin等Ingles。怎么做NameNode高可用。
     <br/>
     3&gt;.故障管理
     <br/>
     Hadoop最常见的故障就是硬盘损坏。
     <br/>
     4&gt;.配置管理
     <br/>
     hdfs-site.xml中的参数设置。
    </p>
    <p>
     四.MapReduce运维工作
     <br/>
     1&gt;.进程管理
     <br/>
     第一：jobtracker进程故障概率比较低，有问题可以通过重启解决；
     <br/>
     第二：了解一下HA的做法；
     <br/>
     2&gt;.配置管理
     <br/>
     mapred-site.xml中的参数设置。
    </p>
    <p>
     五.Yarn运维工作
     <br/>
     1&gt;.故障管理
     <br/>
     主要是当任务异常这中止时看日志排查，通茶故障原因会集中在资源问题，权限问题中的一种。
     <br/>
     2&gt;.进程管理
     <br/>
     ResourceManager主要是学会配置HA
     <br/>
     NodeManager进程挂掉不重要，重启即可。
     <br/>
     3&gt;.配置管理
     <br/>
     yarn-site.xml中的参数设置，主要分三块配置，scheduler的，ResourceManager的，NodeManager的。
    </p>
    <p>
     六.Hive/Impala运维工作
     <br/>
     1&gt;.SQL问题排查
     <br/>
     第一：结果不对，主要原因可能是SQL错误，数据不存在，UDF错误等，需要靠经验排查
     <br/>
     第二：慢SQL，这类问题开发经常会找运维排查，有可能是劣势SQL，数据量大，也有可能是集群资源紧张；
     <br/>
     2&gt;.元数据管理
     <br/>
     Hive和Impala公用的元数据，存在关系型数据库中。
    </p>
    <p>
     七.其它组件
     <br/>
     根据组件用途，特性，关注点的不用，运维工作也各不相同，如：
     <br/>
     1&gt;.HBase关注读写性能，服务的可用性
     <br/>
     2&gt;.Kafka关注吞吐量，负载均衡，消息不丢机制
     <br/>
     3&gt;.Flume关注屯度量，故障后的快速恢复
     <br/>
     复制代码
     <br/>
    </p>
    <p>
     五.大数据运维技能概览
    </p>
    <p>
    </p>
    <p>
    </p>
    <p>
    </p>
    <p>
     六.大数据运维职业素养
    </p>
    <p>
     复制代码
     <br/>
     1&gt;.人品
     <br/>
     2&gt;.严谨
     <br/>
     3&gt;.细心
     <br/>
     4&gt;.心态
     <br/>
     5&gt;.熟悉操作系统
     <br/>
     6&gt;.熟悉业务(开发)
     <br/>
     7&gt;.熟悉行业
     <br/>
     8&gt;.喜欢大数据生态圈
     <br/>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f68616f7869616f79616e2f:61727469636c652f64657461696c732f313032343633313435" class_="artid" style="display:none">
 </p>
</div>
