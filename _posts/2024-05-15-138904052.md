---
layout: post
title: "Google-IO-2024有关AI的一切已公布TodayAI"
date: 2024-05-15 12:40:27 +0800
description: "​2024年谷歌I/O大会圆满落幕，谷歌在会上发布了一系列更新，涵盖从最新的人工智能技术到Andro"
keywords: "谷歌2024 io汇总"
categories: ['Todayai']
tags: ['人工智能', 'I', 'Google']
artid: "138904052"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=138904052
    alt: "Google-IO-2024有关AI的一切已公布TodayAI"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Google I/O 2024：有关AI的一切已公布｜TodayAI
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
    </p>
    <p class="img-center">
     <a href="https://todayai.com.cn/wp-content/uploads/2024/05/IO-8.png" rel="nofollow">
      <img alt="Google I/O 2024：有关AI的一切已公布｜TodayAI" height="834" src="https://i-blog.csdnimg.cn/blog_migrate/c5e72ac55072dfe72d734c13f1b78111.png" width="1200"/>
     </a>
    </p>
    <p>
     2024年谷歌I/O大会圆满落幕，谷歌在会上发布了一系列更新，涵盖从最新的人工智能技术到Android系统的多项改进。此次大会特别关注于谷歌的
     <a href="https://todayai.com.cn/article/tag/gemini" rel="nofollow" title="Gemini">
      Gemini
     </a>
     人工智能模型，并详细介绍了这些模型如何被融入到Workspace、
     <a href="https://todayai.com.cn/article/tag/chrome" rel="nofollow" title="Chrome">
      Chrome
     </a>
     等多个应用程序中，展示了谷歌在智能技术领域的最新进展。
    </p>
    <p>
    </p>
    <p>
     <strong>
      一、视频搜索新功能：利用AI技术简化问题描述与解答
     </strong>
    </p>
    <p>
     谷歌在本次开发者大会上宣布，用户现在可以通过上传视频到谷歌镜（Google Lens）来搜索网络。这项新功能使得描述问题比使用关键词搜索更直观、更简单。谷歌镜是谷歌的视觉搜索工具，此前仅支持静态图像搜索，而现在新增了视频及音频搜索功能，用户可以直接通过视频询问问题。
    </p>
    <p>
     谷歌设想，用户可以使用这一功能来询问关于汽车故障的问题，或是获取某个产品的更多信息。这也是人工智能（AI）技术被进一步融入谷歌产品的又一例证。视频作为一种多模态输入，在当前谷歌的多模态搜索技术中占据重要位置。与静态图像相比，视频可以提供更丰富的信息，用户无需重复精确描述问题，只需对准汽车或其他目标，简单发问，如“这个部件为何悬挂在底部”，谷歌即可全面理解并回答问题。
    </p>
    <p>
     谷歌搜索部门负责人莉兹·里德（Liz Reid）表示，尽管搜索结果仍呈现为常规的谷歌搜索结果，使用视频搜索的目的在于加速搜索过程，使得用户向谷歌表达需求变得更加简单。“有时候，视频中的动作是关键所在，不仅仅是与一张静态图像对话，而是试图描述正在发生的事情。”她以洗碗机故障为例，指出视频可以直观显示哪些指示灯在闪烁及其频率，这对于用关键词描述来说可能相当复杂。
    </p>
    <p>
     谷歌镜是谷歌搜索未来发展的关键部分，特别是其与谷歌AI计划的紧密联系。谷歌一直在寻找新的搜索方式，不仅为了简化搜索过程，还为了给用户带来新的搜索理由。里德说：“如果我在与你对话，假设你知道一切，我会怎样向你提问？”在这种情况下，发送一个视频似乎是一个相当正常、直接的做法。随着谷歌继续完善其核心产品的工作方式，使其更像是一个无所不知的好友，而不仅仅是一个计算机，这似乎是谷歌的最终目标。
    </p>
    <p>
    </p>
    <p>
     <strong>
      二、谷歌照片的新助手：“询问照片”
     </strong>
    </p>
    <p>
    </p>
    <p class="img-center">
     <a href="https://todayai.com.cn/wp-content/uploads/2024/05/IO-2.png" rel="nofollow">
      <img alt="Google I/O 2024：有关AI的一切已公布｜TodayAI" height="646" src="https://i-blog.csdnimg.cn/blog_migrate/82ecc8463e1d0a6c69b950c9344e5b9a.png" width="1178"/>
     </a>
    </p>
    <p>
     谷歌首席执行官桑达尔·皮查伊在大会上演示了即将推出的“询问照片”功能。这一新功能将在今年夏天正式上线，旨在提升谷歌照片服务的智能搜索能力。谷歌照片已具备令人印象深刻的搜索功能，但通过使用GeminiAI技术，谷歌希望将这些功能提升到一个全新的水平。
    </p>
    <p>
     在大会主题演讲中，皮查伊演示了“询问照片”的操作流程。例如，他询问应用“我的车牌号是什么？”目前，搜索车牌号需要用户浏览许多不同汽车的照片。然而，借助“询问照片”，谷歌照片能够根据地点、汽车出现在照片中的频次及其他数据，智能地识别出目标车辆，并返回实际的车牌号码及相应的验证图片。
    </p>
    <p>
     皮查伊还展示了“询问照片”在深度搜索记忆方面的应用，他命令应用“展示露西亚的游泳进步情况。”随后，GeminiAI技术汇总了多年来孩子游泳课的照片，展示了成长历程。
    </p>
    <p>
     皮查伊表示，“询问照片”功能预计将在今年夏天向谷歌照片用户推出，并将不断增加更多功能。他指出，自从约九年前推出以来，谷歌照片目前每天接收大约60亿次的照片和视频上传，这一数字充分证明了该服务对数百万用户的重要性。
    </p>
    <p>
    </p>
    <p>
     <strong>
      三、更快的AI模型：Gemini 1.5 Flash
     </strong>
    </p>
    <p>
     Gemini 1.5 Flash承诺在保持与Gemini Pro同等强大的处理能力的同时，实现更快的处理速度。该模型专为那些需要快速响应的任务设计，如实时客户服务和快速图像生成，而其兄弟模型Gemini 1.5 Pro则更适合处理不依赖快速回答的复杂任务，如阅读并总结研究论文。
    </p>
    <p>
     谷歌实验室副总裁乔什·伍德沃德在谷歌I/O大会前的媒体简报会上表示，尽管谷歌推出了更大的AI模型Gemini Ultra，但开发者社区的兴趣主要集中在Pro版和Flash版模型上。目前，Gemini 1.5 Flash已对公众开放预览，而Gemini 1.5 Pro也将很快在谷歌AI工作室中提供。
    </p>
    <p>
     两款模型都支持多模态处理，能够同时处理文本、图片和视频。此外，这两个模型的上下文窗口——即模型一次处理信息的数量——达到了100万个Token，这比GPT-4的128,000个Token要大得多。还将通过等候名单提供私人预览，其中包括对两种模型进行的实验性200万Token上下文窗口测试。
    </p>
    <p>
     Gemini 1.5 Pro将很快登陆AI工作室，并将在谷歌工作空间中提供，使人们能够利用这一AI模型在Gmail中总结电子邮件或分析PDF文件。此外，订阅了“Gemini Advanced”的付费用户将能够使用35种语言的Gemini 1.5 Pro，进行翻译或撰写提示。
    </p>
    <p>
     这两款模型将通过谷歌AI工作室和GeminiAPI在包括欧盟、英国和瑞士在内的200多个国家提供。
    </p>
    <p>
    </p>
    <p>
     <strong>
      四、
     </strong>
     <strong>
      轻量级AI助手Gemini Nano集成进Chrome浏览器
     </strong>
    </p>
    <p>
     在本次大会上，谷歌宣布其正在将Gemini AI集成到桌面版Chrome浏览器中。即将推出的Chrome 126将利用Gemini Nano来支持设备上的人工智能特性，如文本生成。
    </p>
    <p>
     Gemini Nano是谷歌去年首次在Pixel 8 Pro中引入的轻量级大语言模型，随后也应用于Pixel 8。为了在Chrome中使用Gemini Nano，谷歌表示对模型进行了调整，并优化了浏览器以“快速加载模型”。
    </p>
    <p>
     这一集成将使用户能够直接在Chrome内部生成产品评论、社交媒体帖子和其他简短内容。微软去年同样将其AI助手Copilot添加到了Edge浏览器，允许用户提问并总结屏幕上的信息。与在Chrome中运行的Gemini Nano不同，Edge中的Copilot不在本地设备上运行。
    </p>
    <p>
     谷歌还宣布将在Chrome DevTools中提供Gemini功能，开发者使用这些工具来调试和调优他们的应用。Gemini能够为错误信息提供解释，并就如何解决编程问题提供建议。
    </p>
    <p>
    </p>
    <p>
     <strong>
      五、Project Astra：未来的人工智能通用助理
     </strong>
    </p>
    <p>
     在本次
     <a href="https://todayai.com.cn/article/tag/google-i-o" rel="nofollow" title="Google I/O">
      Google I/O
     </a>
     上，谷歌DeepMind的负责人兼谷歌人工智能项目领导者德米斯·哈萨比斯展示了一项名为Project Astra的雄心勃勃的新计划。哈萨比斯长期以来一直梦想打造一款全方位的通用助理，而Project Astra正是向这一目标迈出的重要一步。这款实时多模态AI助理能够感知周围世界，识别物体及其位置，并回答问题或协助完成几乎任何任务。
    </p>
    <p>
     哈萨比斯在会上放映的演示视频令人印象深刻。视频中，一位在谷歌伦敦办公室的Astra用户询问系统识别扬声器的某个部件，找回丢失的眼镜，审查代码等，所有这些都几乎能够实时完成，并且交互方式极其自然。哈萨比斯承诺，这段演示视频是真实的，未经任何篡改或处理。他形容这款助理像是“星际迷航”中的通讯器或电影《她》中的声音，是一种始终在旁边，随叫随到的帮手。
    </p>
    <p>
    </p>
    <p>
     <strong>
      六、新型生成AI视频模型
      <a href="https://todayai.com.cn/article/tag/veo" rel="nofollow" title="Veo">
       Veo
      </a>
      ，全面挑战Sora
     </strong>
    </p>
    <p>
     大会上宣布了一款名为Veo的新型生成AI视频模型。谷歌表示，Veo能够根据文本、图片和视频提示生成“高质量”的1080p分辨率视频，视频长度超过一分钟，且支持多种视觉和电影风格。
    </p>
    <p>
     据谷歌的新闻稿称，Veo拥有“先进的自然语言理解能力”，使得该模型能理解包括“时间流逝”或“航拍风景”在内的电影术语。用户可以通过文本、图像或视频提示来指导期望的输出，谷歌称生成的视频“更加一致和连贯”，展现出人物、动物和物体在镜头中的更真实动作。
    </p>
    <p>
     谷歌DeepMind的CEO德米斯·哈萨比斯在周一的媒体预览中表示，视频结果可以通过额外的提示进行精细调整，谷歌还在探索使Veo能够生成故事板和更长场景的额外功能。虽然许多人都希望尝试Veo，但大多数人可能还需要等待一段时间。谷歌表示，它正在邀请部分电影制作人和创作者试验该模型，以确定如何最好地支持创意工作者，并将基于这些合作来确保“创作者在谷歌AI技术的发展中有发言权”。
    </p>
    <p>
     Veo的部分功能将在未来几周内对“选定的创作者”在VideoFX中进行私人预览。此外，谷歌还计划将其部分功能未来加入YouTube Shorts。
    </p>
    <p>
     这是谷歌在过去几年中推出的多个视频生成模型中的一个，从Phenaki和Imagen Video（生成的视频片段往往粗糙、扭曲）到今年一月展示的Lumiere模型。Lumiere在Sora被公布之前是我们见过的最令人印象深刻的模型之一，而谷歌表示Veo在理解视频内容、模拟现实物理、渲染高清输出等方面更为出色。
    </p>
    <p>
    </p>
    <p>
     <strong>
      七、
     </strong>
     <strong>
      <a href="https://todayai.com.cn/article/tag/synthid" rel="nofollow" title="SynthID">
       SynthID
      </a>
      水印：识别AI生成的文本和视频内容
     </strong>
    </p>
    <p>
     大会上，谷歌宣布新的SynthID水印系统，扩展其AI内容水印和检测技术到两种新的媒体格式。升级后的SynthID水印系统能够标记数字生成的视频以及AI生成的文本。
    </p>
    <p>
     当AI被用于恶意目的时，对AI生成内容进行水印标记将变得越来越重要。AI已被用于传播政治错误信息、声称某人说了他们未曾说过的话，以及创建非自愿性内容。
    </p>
    <p>
     SynthID最初于去年八月公布，起初是作为一个工具来印记AI图像，人眼无法直观识别这些水印——但系统能够检测到。这种方法与其他如C2PA等正在开发的水印协议标准不同，后者通过添加加密元数据到AI生成的内容中。
    </p>
    <p>
     谷歌还启用了SynthID，将不可听见的水印注入使用DeepMind的Lyria模型制作的AI生成音乐中。SynthID只是多个正在开发中的AI安全措施之一，这些安全措施旨在防止技术被滥用，拜登政府也正在指导联邦机构围绕这些措施建立指导方针。
    </p>
    <p>
    </p>
    <p>
     <strong>
      八、Gemini AI全新的语音对话模式
     </strong>
    </p>
    <p>
    </p>
    <p class="img-center">
     <a href="https://todayai.com.cn/wp-content/uploads/2024/05/IO-5.png" rel="nofollow">
      <img alt="Google I/O 2024：有关AI的一切已公布｜TodayAI" height="740" src="https://i-blog.csdnimg.cn/blog_migrate/8a1c501a39b795a83355e423fa0609f3.png" width="1182"/>
     </a>
    </p>
    <p>
     谷歌的Gemini AI助手将为Gemini Advanced订阅者推出全新的语音聊天功能，名为Gemini Live，计划在今年内上线。这一功能将支持与聊天机器人进行双向语音对话，具备智能助手功能和视觉识别能力——类似于OpenAI目前正在为ChatGPT开发的功能。
    </p>
    <p>
     Gemini Live将适应用户的语音模式，并提供比传统基于文本的回答更简洁、更符合会话习惯的响应。该功能将提供10种语音选项，并能利用智能手机摄像头实时查看和解释视频内容。
    </p>
    <p>
     此外，Gemini Live还具备多模态AI功能，这些功能是在今天的I/O开发者大会上展示的。在演示视频中，Gemini被要求通过手机摄像头宣布它看到的“发出声音的物体”。当桌子上的扬声器出现在视野中时，Gemini报告说：“我看到一个扬声器”，并在进一步提示后正确识别了扬声器的高音喇叭部分。
    </p>
    <p>
     用户还可以使用Gemini Live执行数字助手任务，比如使用从音乐会传单上获取的信息更新个人日历。谷歌表示，该功能还能搜索用户的Gmail账户，收集旅行计划信息，如航班行程，或查询酒店附近的餐厅信息等。
    </p>
    <p>
     Gemini Live功能显然旨在实现与OpenAI昨天刚宣布的GPT-4o相似的功能。该聊天机器人模型也能进行自然的来回对话，并可以在对话中被打断，就像Gemini Live一样。与Gemini相似，GPT-4o的功能也将逐步推出；ChatGPT Plus订阅者将在未来几周内首先测试新的语音模式的早期Alpha版本。
    </p>
    <p>
    </p>
    <p>
     <strong>
      九、“环形搜索”（Circle to Search）：助力数学作业解题
     </strong>
    </p>
    <p>
    </p>
    <p class="img-center">
     <a href="https://todayai.com.cn/wp-content/uploads/2024/05/IO-6.png" rel="nofollow">
      <img alt="Google I/O 2024：有关AI的一切已公布｜TodayAI" height="778" src="https://i-blog.csdnimg.cn/blog_migrate/99f12e0655499f33caa60657a83721bd.png" width="1132"/>
     </a>
    </p>
    <p>
     谷歌正在通过其新的LearnLM人工智能模型，增强Android上的“环形搜索”功能。这一功能允许用户在Android手机屏幕上用手指圈选内容，即可进行搜索。现在，它还可以生成解决学校数学和物理问题的指导。
    </p>
    <p>
     学生们可以在Android手机或平板上使用“环形搜索”来获得关于数学文字题目的人工智能帮助。该功能将帮助学生理解问题并列出解题所需的步骤，但据谷歌表示，它不会直接完成作业，而是帮助学生探索如何解题。
    </p>
    <p>
     随着像ChatGPT这样的AI工具在教育领域的使用成为热门话题，人们对学生如何利用这些工具快速完成作业表示担忧。然而，谷歌明确将这一功能定位为支持教育的工具，这可能会缓解关于AI为学生完成所有作业的担忧。
    </p>
    <p>
     今年晚些时候，“环形搜索”还将增加解决涉及公式、图表、图形等复杂数学方程的能力。谷歌正在利用其为学习而特别调整的新AI模型LearnLM，使这些新的“环形搜索”功能得以实现。
    </p>
    <p>
    </p>
    <p>
     <strong>
      十、“AI概览”（AI Overviews）：改变搜索方式
     </strong>
    </p>
    <p>
    </p>
    <p class="img-center">
     <a href="https://todayai.com.cn/wp-content/uploads/2024/05/IO-7.png" rel="nofollow">
      <img alt="Google I/O 2024：有关AI的一切已公布｜TodayAI" height="1052" src="https://i-blog.csdnimg.cn/blog_migrate/b5e8ed3728ad2fad2dbcbd495857493f.png" width="1200"/>
     </a>
    </p>
    <p>
     谷歌已经开始在美国推出名为“AI概览”的功能，旨在通过链接提供对查询问题的一般性解答和更多信息。这一功能此前被称为搜索生成体验（SGE），并将很快在全球范围内推广。不久后，数十亿谷歌用户将在许多搜索结果的顶部看到由AI生成的摘要。这只是人工智能改变搜索方式的开始。
    </p>
    <p>
    </p>
    <p>
     <strong>
      十一、为Android推出AI驱动的诈骗电话检测功能
     </strong>
    </p>
    <p>
     谷歌正在开发新的保护措施，以帮助Android用户防范电话诈骗。在本次I/O开发者大会上，谷歌宣布正在测试一项新的来电监控功能，该功能将警告用户如果与之通话的人可能在尝试诈骗，并鼓励用户结束这类通话。
    </p>
    <p>
     谷歌表示，这一功能利用了Gemini Nano——公司为Android设备设计的Gemini大型语言模型的简化版，该模型可以在本地和离线环境下运行。该功能将检测欺诈性语言和通常与诈骗相关的其他对话模式。用户将在这些红旗信号出现时，接收到实时警报。
    </p>
    <p>
     可能触发这些警报的例子包括来自自称“银行代表”的电话，这些代表会提出真实银行不太可能提出的要求，如索要个人信息包括密码或银行卡PIN码、要求通过礼品卡支付，或紧急要求用户将钱转账给他们。谷歌表示，这些新的保护措施完全在设备上进行，因此由Gemini Nano监控的对话将保持私密。
    </p>
    <p>
     谷歌尚未宣布这一诈骗检测功能何时可用，但表示用户需要选择加入才能使用此功能，并将在“今年晚些时候”分享更多信息。
    </p>
    <p>
     尽管经过多年的宣传活动和提供如何避免诈骗的指导后，诈骗电话对一些人来说可能很容易被识别，但总是存在被骗的风险。去年十月，全球反诈骗联盟的一份报告发现，在过去的12个月里，全球有四分之一的人因诈骗或身份盗窃而损失了金钱，期间损失超过1万亿美元。
    </p>
    <p>
    </p>
    <p>
     <strong>
      十二、Gemini将更加懂得你的屏幕
     </strong>
    </p>
    <p>
    </p>
    <p class="img-center">
     <a href="https://todayai.com.cn/wp-content/uploads/2024/05/IO-4.png" rel="nofollow">
      <img alt="Google I/O 2024：有关AI的一切已公布｜TodayAI" height="792" src="https://i-blog.csdnimg.cn/blog_migrate/45a4d68408f2e2e077662d51625a7802.png" width="1150"/>
     </a>
    </p>
    <p>
     谷歌正在对其Android设备上的Gemini AI进行一次关键更新，此举旨在充分利用和理解用户屏幕上显示的内容。通过这一更新，Gemini将能够更有效地协助用户解析日常生活中的数据信息，如视频和PDF文件。
    </p>
    <p>
     用户若将Gemini设置为Android手机的默认助手，它不仅可以对网页或截图进行总结和回答问题，即将到来的更新还将使它能够识别屏幕上的视频内容，并引导用户就视频内容提出问题。此外，Gemini将使用视频中的自动字幕功能来寻找答案，这种方法比以往更直接有效。
    </p>
    <p>
     对于PDF文件，更新后的Gemini同样能提供帮助，但这一功能将限于Gemini Advanced的付费用户。这是因为该功能需要处理整个PDF文件，而这一处理能力是Gemini Advanced的长内容窗口所支持的。一旦Gemini处理了PDF文件，它就能够就相关主题提供专业的解答和指导，比如解读用户的家电使用手册或是地方回收规则。Gemini Advanced是Google One AI Premium计划的一部分，该计划每月收费20美元。
    </p>
    <p>
     此外，这次更新还包括了一个便捷的新功能，即用户很快能够将Gemini生成的图片直接拖放到他们正在编辑的文档或电子邮件中，而无需在不同应用程序间切换。
    </p>
    <p>
     这种改进使得Gemini不再是一个需要特别访问的功能，而是与系统其他部分无缝整合的一部分。此外，这次更新也展示了谷歌对于实现情境感知搜索长达十年的努力——这一理念最早出现在Google Now中。随着Gemini的最新功能，用户可以更自然地与其互动，比如在厨房准备晚餐时询问食谱等。
    </p>
    <p>
     谷歌计划在未来几个月内向数亿台设备推送这些Gemini的更新，并继续开发更多基于情境的特性，进一步提升用户体验。这标志着谷歌在智能助手领域迈出的重要一步，旨在使日常技术应用更加智能和亲切。
    </p>
    <p>
    </p>
    <p>
     <strong>
      十三、
     </strong>
     <strong>
      将Gemini 1.5 Pro变成用户的个人助理
     </strong>
    </p>
    <p>
     谷歌宣布，其最新的主流语言模型Gemini 1.5 Pro即将集成到Docs、Sheets、Slides、Drive和Gmail的侧边栏中。当这一更新下月向付费订阅者推出时，它将转变为一个更通用的助理，能够从用户的Drive中获取任何内容信息，无论用户身处何地。
    </p>
    <p>
     此外，这一智能助理还将能够执行多种任务，例如根据用户正在查看的文档中的信息撰写电子邮件，或在用户浏览电子邮件时提醒他们稍后进行回复。目前，一些早期测试者已经可以访问这些功能，但谷歌表示，下个月将向所有付费的Gemini订阅者推出这一功能。
    </p>
    <p>
    </p>
    <p>
     <strong>
      十四、
     </strong>
     <strong>
      个性化AI聊天机器人功能“Gems”
     </strong>
    </p>
    <p>
     谷歌正在为其Gemini AI引入一系列新功能，其中最引人注目的是一项名为“Gems”的个性化选项，该功能允许用户根据自己的需求创建具有不同个性的Gemini助手版本。
    </p>
    <p>
     通过Gems功能，用户可以创建具有特定特征和能力的聊天机器人，帮助完成特定任务，这有点类似于Character.AI服务，后者允许用户与虚拟化的流行人物、名人甚至是虚构的心理医生对话。谷歌表示，你可以将Gemini变成你的健身伙伴、厨师助手、编程搭档、创意写作向导，或是你能想到的任何角色。Gems的功能与OpenAI的GPT Store类似，后者允许用户定制自己的ChatGPT聊天机器人。
    </p>
    <p>
     设置一个Gems非常简单，你只需告诉Gemini要执行什么任务以及如何响应。例如，你可以指定它为你的跑步教练，提供每日跑步计划，并保持积极和激励的语气回应。之后，只需一键，Gemini就会根据你的描述创建一个Gems。这项功能将“很快”向Gemini Advanced订阅者开放。
    </p>
    <p>
    </p>
    <p style="text-align:center;">
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/cd95297a790e3f7709506ed8f245f0dc.png"/>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f706f6e64657261692f:61727469636c652f64657461696c732f313338393034303532" class_="artid" style="display:none">
 </p>
</div>


