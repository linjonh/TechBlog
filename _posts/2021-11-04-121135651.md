---
layout: post
title: "基于大数据平台的毕业设计"
date: 2021-11-04 10:01:39 +0800
description: "文章浏览阅读2.2w次，点赞62次，前言最近有很多人问我，大数据专业有什么好的毕设项目，也有直接问我"
keywords: "大数据毕设"
categories: ['大数据']
tags: ['毕业设计', '大数据', 'Spark', 'Data', 'Big']
artid: "121135651"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=121135651
    alt: "基于大数据平台的毕业设计"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     基于大数据平台的毕业设计
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3>
     <a id="_0">
     </a>
     前言
    </h3>
    <p>
     <strong>
      文末有大数据毕设交流群二维码，二维码过期可通过公众号添加博主VX，备注来意。
     </strong>
    </p>
    <p>
     2022年最新大数据毕设文章：
     <br/>
     <a href="https://blog.csdn.net/CatchLight/article/details/127510129">
      基于大数据平台的毕业设计01：基于Docker的HDP集群搭建
     </a>
    </p>
    <p>
     2024年最新大数据毕设文章：
     <br/>
     <a href="https://blog.csdn.net/CatchLight/article/details/137511575">
      大数据毕设的“万能公式”
     </a>
    </p>
    <h3>
     <a id="_11">
     </a>
     前言
    </h3>
    <p>
     在大数据流数据实时开发中，常用的技术就是SparkStreaming和Flink。在初学实时处理技术时，总是围绕着
     <em>
      处理数据的实时性
     </em>
     ，来对不同技术做一个比较。
    </p>
    <p>
     但是在实际应用开发场景中，很多时候都需要Window（窗口）操作，这就相当于数据在窗口”形成的过程“中不处理数据，当窗口形成之后，才会触发窗口计算。所以，这时候的实时处理就变成了基于窗口的微批处理。
    </p>
    <h3>
     <a id="_16">
     </a>
     关于窗口
    </h3>
    <p>
     在Spark中是基于RDD（Resilient Distributed Dataset）计算的，RDD是一个数据的集合，所以说SparkStreaming本身就是基于微批计算的，在构造SparkContext时设置批次间隔，最小值为50毫秒。这里的批次，就可以理解为窗口
    </p>
    <p>
     当达到批次设定的时间时，Spark就会开始执行开发基于RDD实现的计算逻辑，所以，SparkStreaming是自带”窗口“的，而且计算逻辑是基于RDD实现的。
    </p>
    <p>
     Flink中的数据计算是以事件为驱动的，这里的事件是指数据流中的单个数据元素，所以在Flink中每个事件都可以触发相应的处理逻辑，而不是按照固定的时间间隔进行处理。所以说，在Flink中如果想实现窗口处理，就必须使用窗口函数来实现。
    </p>
    <p>
     什么场景下会用到窗口计算？
    </p>
    <p>
     例如数据的一分钟去重（reduceByKey)，计数（count）、关联（join）等操作，就需要用到窗口计算。今天就先看看如何玩转SparkStreaming的窗口操作。
    </p>
    <h3>
     <a id="SparkStreaming_28">
     </a>
     SparkStreaming窗口计算
    </h3>
    <p>
     上面SparkStreaming就是自带时间窗口的，一个批次中的RDD就代表着一个窗口，对RDD的计算就是窗口计算，所以SparkStreaming没有提供普通窗口的算子。
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/3499b5a87e439706226088e16fc7874f.png"/>
    </p>
    <p>
     如图，RDD中数据的获取时间time 0 to 1就是一个时间窗口，数据间隔就是设置的
     <em>
      批次间隔
     </em>
     。既然SparkStreaming都有了RDD这个”时间窗口“了，那还有什么窗口好讲的？
    </p>
    <p>
     在RDD计算中，一个窗口通常只能计算一个RDD的数据，当本批次RDD计算完之后，默认就会被回收，然后再拉取下一个时间批次的数据生成RDD进行计算。当我们需要对多个RDD即多个时间窗口进行计算时，就必须要借助
     <em>
      滑动窗口
     </em>
     的算子来实现。
    </p>
    <h4>
     <a id="_38">
     </a>
     滑动窗口
    </h4>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/9c9f7c6353b9e463833f7c54f11ad40d.png"/>
    </p>
    <p>
     什么是滑块
    </p>
    <p>
     最近有很多人问我，大数据专业有什么好的毕设项目，我就简单的回复了一下。也有直接问我要源码的…
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/ef4b358c876602d7ba7daa2566b43452.png"/>
    </p>
    <p>
     所以就抽空写一写自己毕业设计的一个思路，大数据是我实习自学的，这个思路是我当初自己想的，就当做一份参考吧。
    </p>
    <p>
     在我毕业那年，同学们毕业设计大多都是以Java语言开发的各种管理系统、xx商城为主，包括我刚开始的想法也是这样的。这也是计算机专业很常见的毕业设计选题。
    </p>
    <p>
     这种选择的好处就是简单，网上模板多。动手能力强的同学，直接去github上拉下来源码，稍微修改一下，一个毕业设计项目就完成了。动手能力弱的同学，也可以使用钞能力低成本完成。
    </p>
    <p>
     至于缺点嘛，就是这类毕设太常见了，除非UI设计和思路特别出彩，让老师眼前一亮。要不然见多识广的老师，就会带着一颗毫无波澜的内心，用空洞的眼神看完你的演示，机械般的给你打下一个及格分。
    </p>
    <p>
     当然，对于大部分同学的内心想法就是：
     <em>
      能过就行
     </em>
     。也有的同学担心，自己的毕设项目和其他同学的重合度很高，老师可能会问一些细节（稀奇古怪）的问题。所以，
     <strong>
      毕设最好还是自己做，就算找的模板，也要把技术和架构搞清楚
     </strong>
     。
    </p>
    <p>
     同时，想要做一个与众不同的毕设，在技术上也一定要“花里胡哨”。
    </p>
    <h3>
     <a id="_66">
     </a>
     大数据毕设思路
    </h3>
    <p>
     大数据方向的毕设，归根结底还是基于大数据平台进行构思。对于管理系统、商城这种项目毕设来说，我们面向的是编程语言，而大数据主要还是还是面向平台。就像你一说大数据，别人接着就说，
     <em>
      大数据…就是那个Hadoop吗？
     </em>
    </p>
    <p>
     是的。虽然这个回答很片面，但是对于大数据毕设来说，就是基于Hadoop来发散延伸。
    </p>
    <p>
     我学的不是大数据专业，也曾有成为一名优©秀(V)的Java开发的梦想。后来，17年实习阴差阳错就接触到大数据，并开始自学大数据，所以在18年毕业的时候，就基于大数据完成了毕业设计。这里就简单说一下当初我的毕业设计流程。
    </p>
    <ol>
     <li>
      在虚拟机搭建Hadoop、Hive、Kafka、Spark集群
     </li>
     <li>
      使用Java（建议Python）采集了163w数据放入MySQL
     </li>
     <li>
      用Flume将mysql中的数据实时写入到了Kafka中
     </li>
     <li>
      Scala开发sparkstreaming程序，读取kafka数据进行处理，然后写入Kafka
     </li>
     <li>
      使用Flume将kafka数据写入到了HDFS，然后加载到hive进行hsql分析
     </li>
     <li>
      使用Springboot和Vue，开发数据管理系统，对数据进行查询和图形化展示，对接了echarts和百度地图。
     </li>
    </ol>
    <p>
     就很简单，很简单。大家可以在上面的思路上进行扩展。下面就展开说一下具体步骤。
    </p>
    <h3>
     <a id="_83">
     </a>
     大数据毕设实践
    </h3>
    <p>
     关于下文中提到的一些大数据概念，可以参考之前写的一篇大数据的文章。
    </p>
    <h4>
     <a id="0__87">
     </a>
     0. 数据准备
    </h4>
    <p>
     大数据，大数据，数据肯定是大的无边无际。那多大才算大？自从18年负责一天1w亿条数据的接入、存储、处理工作之后，我就飘了~ 经常同事告诉我说，要接入一个大数据量的文件接口，我问他多少，他说一天一百亿条，我一般会轻飘飘地说一句，一百亿，算多吗 ~~~
    </p>
    <p>
     其实，对于毕业设计来说，数据量并不需要那么大，
     <em>
      数据在大数据平台中的流转，以此来模拟大数据中的ETL和实时处理，从而体现数据的价值。
     </em>
     那么，数据从哪里获取呢？
    </p>
    <p>
     方法1，我们可以写一个程序来生成一些测试数据，但是这样的话，数据重合度太高，很难体现出数据分析价值。那么就采用方法二，
     <em>
      开发爬虫进行采集网上的数据
     </em>
     。
    </p>
    <p>
     当时我用Java开发了一个爬虫，采集了163w条POI位置数据，存到了MySQL中，完成了数据的准备工作。爬虫的开发还是推荐用Python，17年我还不会Python，后来18年开始学习Python，后来又做了很多爬虫开发工作，再后来写了爬虫系列由浅入深的学习文章，大家也可以参考一下。
    </p>
    <h4>
     <a id="1__97">
     </a>
     1. 大数据平台搭建
    </h4>
    <p>
     欲抬手摘星望月，必先平地起高楼。
    </p>
    <p>
     上面也说了，大数据还是围绕着平台来搞。当时我在笔记本上搭建了三台centos系统的虚拟机，主要用来搭建下面的集群。
    </p>
    <p>
     在集群搭建之前，需要完成下列操作系统和环境的配置。
    </p>
    <ol>
     <li>
      安装JDK、Scala
     </li>
     <li>
      三台虚拟机之间进行互信操作
     </li>
     <li>
      安装mysql数据，作为hive的元数据库
     </li>
    </ol>
    <h5>
     <a id="Hadoop___109">
     </a>
     Hadoop - 基础核心
    </h5>
    <p>
     Hadoop集群作为大数据基础建设，同时也是大数据核心。其HDFS提供了分布式存储，Yarn提供了计算资源。
    </p>
    <p>
     如果是毕设的话，可以选择
     <strong>
      一主两从
     </strong>
     的架构，即一个NameNode和两个DataNode的架构。如果想要玩的花一点，就选择HA高可用架构，即两主两从，这里就需要四台虚拟机。
    </p>
    <p>
     关于HA，就是两个NameNode，但是一个NN处于工作状态（active），一个NN处于待命状态（standby）。你可以kill掉active的NN，然后让standby的NN接管集群。
    </p>
    <p>
     关于HA，在大数据是随处可见的。在Hadoop生态中,集群中的多NN和多DN是HA，HDFS的副本机制也是HA，这一块在论文中还是能体现不少东西的。
    </p>
    <p>
     下面就是Hadoop集群的NN和DN的基本信息。
    </p>
    <p>
     <img alt="NameNode" src="https://i-blog.csdnimg.cn/blog_migrate/563ae36d01f6d776a2c0fc26d670b7bf.png"/>
    </p>
    <p>
     <img alt="DataNode" src="https://i-blog.csdnimg.cn/blog_migrate/6c71e5d9163f2dcd7b66aa823c1608e1.png"/>
    </p>
    <h5>
     <a id="Hive___125">
     </a>
     Hive - 离线分析
    </h5>
    <p>
     Hive在我的毕设中的角色就是一个数据分析的工具，主要表述的是大数据ETL中L阶段，以及大数据平台的离线分析部分。
    </p>
    <p>
     Hive是一个数据仓库，关于它的作用就是对HDFS上的数据进行离线分析，虽然它不是数据库，但是大家可以把它当做数据库来用。这里其他基础的概念就不多介绍了。
    </p>
    <p>
     时至今日，也有很多hive的平替产品，例如号称比hive快800倍的clickhouse，以及druid，但是在应用场景方面和hive还是有一定出入的，有兴趣的可以去了解一下。
    </p>
    <p>
     大数据在数仓方面，有很多值得玩的平台架构和一些基本概念，ETL描述的就是基于数据仓库进行的数据处理过程。
    </p>
    <h5>
     <a id="SparkKafka___135">
     </a>
     Spark、Kafka - 实时计算
    </h5>
    <p>
     现在提到实时计算，可能大家首先会想到flink。的确，flink在开源实时领域方面绝对算是TOP了。18年的时候，实时处理还是SparkStreaming应用的比较广泛。所以当时我安装的是Spark集群，来模拟的实时计算。
    </p>
    <p>
     其实Spark/flink集群都是可以不搭建的，在Spark集群上运行程序属于standlone模式，如果使用yarn模式只需要有客户端就可以了。Spark程序运行在yarn上，能对cpu和内存进行资源隔离，而且不需要要单独维护一个Spark集群。
    </p>
    <p>
     而作为实时处理配套，Kafka和Rabbitmq之间我还是倾向于Kafka。在Kafka搭建之前，先搭建zookeeper集群，zk是kafka的依赖组件，用来记录一些元数据。
    </p>
    <p>
     下图命令操作就是消费写入Kafka的数据。
    </p>
    <p>
     <img alt="Kafka" src="https://i-blog.csdnimg.cn/blog_migrate/c76e6ac843c6fd6c1653d1714fda993e.png"/>
    </p>
    <p>
     我们要做的就是将数据库/数据仓库中的离线数据，转换为数据流（Data Stream），作为生产者实时写入到Kafka中。
    </p>
    <p>
     我们开发的Spark/flink程序作为消费者实时读取Kafka中的数据，实时处理并数据计算结果。如下图，为SparkStreaming的程序监控页面。
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/6e647b7fb635fc8d190d6b80c948fba0.png"/>
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/261c047a2ee0e5faae1c476681c85ac3.png"/>
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/af943ab8487cf7a12c5c6d77d8ca0e24.png"/>
    </p>
    <p>
     SparkStreming程序，可以使用Java、Scala、Python开发，但是选择Scala比较好一些。一是Scala的语法结构更贴合流式处理,二是源码都是Scala写的。
    </p>
    <h5>
     <a id="Flume___160">
     </a>
     Flume - 数据交换神器
    </h5>
    <p>
     当初刚接触Flume的时候，真的没玩明白，云里雾里的。后来深入研究了一下之后，数据在oracle、MySQL、Kafka、HDFS以及其他存储平台上，就可以进行同步。不过MySQL和oracle需要自己定义Source和Sink。
    </p>
    <p>
     Flume的简单之处在于配置化。当初我将数据从MySql抽取到Kafka，部分配置如下。
    </p>
    <p>
     <img alt="Flume" src="https://i-blog.csdnimg.cn/blog_migrate/526bd1567ad94f1f07cd74fdc966f279.png"/>
    </p>
    <p>
     顺带一提，在大数据量的情况下，Flume很多参数还是需要调的。当初我将1W亿/天的数据从Kafka落地到HDFS的时候，写了几千行的配置，调了很多参数。
    </p>
    <h4>
     <a id="3__170">
     </a>
     3. 数据展示
    </h4>
    <p>
     最后就是前台的数据展示了，使用了Springboot和Vue做了一个POI数据管理系统。主要实现分类查询和POI搜索标点地图展示功能。
    </p>
    <p>
     但是这个系统，我只找到了登录页面和地图搜索标点的截图了…
    </p>
    <p>
     <img alt="登录页面" src="https://i-blog.csdnimg.cn/blog_migrate/643dc525197747f79bee0d2a075e00f6.png"/>
    </p>
    <p>
     <img alt="地图" src="https://i-blog.csdnimg.cn/blog_migrate/0b3026a7221f27f07372aaac662c914a.png"/>
    </p>
    <p>
     数据管理系统发挥的空间还是挺多的，比如页面样式的优化，再比如前台可以使用Node + Vue，后端使用Springboot来实现前后端分离架构。
    </p>
    <h3>
     <a id="_182">
     </a>
     结语
    </h3>
    <p>
     主要是给大家提供一个大数据平台毕业设计的基本思路，很多细节的地方还可以优化。我们也不难发现，这里的大数据集群都是独立安装的，我们同样可以使用Ambari进行统一的安装、管理、启动、状态监控。
    </p>
    <p>
     最近也是在研究Ambari，前几周刚花了一个星期，完成了Ambari2.7.5的编译安装工作。后期的目标是
     <strong>
      配合docker在一台机器上完成大数据集群的搭建工作
     </strong>
     ，当然这里主要是玩，构建测试环境，性能啥的就不要考虑了哈。
    </p>
    <p>
     忙完这一阵，完成Scrapy系列文章，就开始着手准备大数据平台系列文章的编写。期待下一次相遇。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/7707dffddbe672d12db7891a6e7158ae.jpeg#pic_center"/>
     <br/>
     <img alt="感谢每一次相遇" src="https://i-blog.csdnimg.cn/blog_migrate/75a3827211716e2e0ba2ca3a5505eaae.png"/>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f43617463684c696768742f:61727469636c652f64657461696c732f313231313335363531" class_="artid" style="display:none">
 </p>
</div>


