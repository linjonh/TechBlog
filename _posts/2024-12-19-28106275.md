---
layout: post
title: "RTPRTCP音视频同步"
date: 2024-12-19 00:34:24 +0800
description: "文章浏览阅读3.8k次。2.1  RTCP控制参数由于音视频流作为不同的RTP会话传送，它们在RTP"
keywords: "frevideo"
categories: ['LinuxOS']
tags: ['视频流', '视频', '多媒体', 'rtp', 'linux']
artid: "28106275"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=28106275
    alt: "RTPRTCP音视频同步"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     RTP/RTCP音视频同步
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     Blog From
     <a href="http://blog.csdn.net/kof98765/article/details/17733701" rel="noopener noreferrer" target="_blank">
      http://blog.csdn.net/kof98765/article/details/17733701
     </a>
    </p>
    <p>
     <a href="http://hongdow.com/rtp%E3%80%81rtcp%E5%8F%8A%E5%AA%92%E4%BD%93%E6%B5%81%E5%90%8C%E6%AD%A5.html" rel="nofollow noopener noreferrer" target="_blank">
      http://hongdow.com/rtp%E3%80%81rtcp%E5%8F%8A%E5%AA%92%E4%BD%93%E6%B5%81%E5%90%8C%E6%AD%A5.html
     </a>
     <br/>
    </p>
    <p>
     RTCP控制参数
    </p>
    由于音视频流作为不同的RTP会话传送，它们在RTP层无直接关联。尽管由一个数据源发出的不同的流具有不同的同步源标识(SSRC)，为能进行流同步，RTCP要求发送方给接收方传送一个唯一的标识数据源的规范名(canonical name)，应用层藉此关联音视频流，以便实现同步。
    <br/>
    RTP/ RTCP中有时间戳（相对和绝对）和序列号等信息，可以利用它实现基于时间戳的多媒体流同步。使用相对时间戳和序列号实现流内同步；使用相对和绝对时间戳的对应关系实现流间同步。获得相对与绝对时间戳的算法如下：
    <br/>
    <pre><code class="language-cpp">while ((pack = GetNextPacket()) != NULL)
         {
              if(srcdat-&gt;SR_HasInfo() &amp;&amp; srcdat-&gt;SR_GetRTPTimestamp() != app-&gt;mvideortcprtp)  
                   {  
                            app-&gt;mvideortcprtp = srcdat-&gt;SR_GetRTPTimestamp();
                            app-&gt;mvideortcpntp = srcdat-&gt;SR_GetNTPTimestamp().GetMSW();
                            srcdat-&gt;FlushPackets();  
                   }
                   DeletePacket(pack);
}
 </code></pre>
    音视频流间同步实现
    <br/>
    发送端在发送音视频数据时，同时也会发送SR包，这样可以使接收方能够正确使音视频同步播放。具体实现方法是在接收方每次接收数据包后，再遍历一次数据源，获取所有源端的SS_RTPTime与SS_NTPTime这两则数据，通过获取音频端与视频端的数据，可以利用下面的公式进行计算。
    <br/>
    表 2.1    变量描述表
    <br/>
    <pre><code class="language-html">   类型                    RTP数据               NTP数据               RTP时戳频率
   音频                 Audio_SRRTPTime       Audio_SRNTPTime             Audio_Fre
   视频                 Video_SRRTPTime       Video_SRNTPTime             Video_Fre</code></pre>
    <p>
     从SR包中可以读出音频与视频的RTP与NTP数据，而需要计算的是时戳频率，利用下述公式：
    </p>
    <pre><code class="language-cpp">                      Audio_Fre=( AudioSRRTPtime2- AudioSRRTPtime1)/( AudioSRNTPtime2- AudioSRNTPtime1)     
                      Video_Fre=( VideoSRRTPtime2- VideoSRRTPtime1)/( VideoSRNTPtime2- Video SRNTPtime1)</code></pre>
    然后计算视频RTP的时间，即：
    <br/>
    <p>
    </p>
    <pre><code class="language-cpp">                      Video_RTPTime=Video_SRRTPTime + (Audio_SRNTP-Video_SRNTP)×Video_Fre</code></pre>
    <p>
    </p>
    最后即可计算出Video_TRUERTP时间，将其与从RTP包中读出的时间进行比较，就可以进行同步播放了。
    <br/>
    <pre><code class="language-cpp">                      (Video_TRUERTP-Video_RTPTime)/Video_Fre=(Audio_TRUERTP-Audio_SRRTPTime)/Audio_Fre</code></pre>
    <p>
     下面采用临时缓冲区的方法来同步音视频。因为要保证音频优先正常传输，所以本系统以音频为主轴，视频为辅轴。
    </p>
    <p>
     以最大延迟时间为缓冲区大小，存放M个音频帧数据。当接收端获得M个音频帧后开始播放音频，每次获得视频帧时，就计算出当前视频应当播放RTP时间与现有RTP时间进行比对，如若在120ms以内，迅速播放；延迟120ms以上，则扔掉，然后比对下一帧；还在120ms以内，放入视频缓冲区内进行储存，如果视频缓冲区的大小超过了最大临时缓冲区的数值，依旧开始播放。
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f:2f626c6f672e6373646e2e6e65742f69616d62657374303037:2f61727469636c652f64657461696c732f3238313036323735" class_="artid" style="display:none">
 </p>
</div>


