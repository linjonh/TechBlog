---
layout: post
title: "Python用requests库爬取网页内容,返回为为空的解决办法"
date: 2024-12-09 11:13:33 +0800
description: "首先介紹一下我們用360搜索派取城市排名前20。我们爬取的网址：https://baike.so.c"
keywords: "python中的request到目标网址为什么返回未登录的页面"
categories: ['学习', 'Python']
tags: ['网络爬虫', 'Requests', 'Python', 'Bs']
artid: "95223267"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=95223267
    alt: "Python用requests库爬取网页内容,返回为为空的解决办法"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     Python用requests库爬取网页内容，返回为‘’（为空）的解决办法。
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     首先介紹一下我們用360搜索派取城市排名前20。
     <br/>
     我们爬取的网址：
     <a href="https://baike.so.com/doc/24368318-25185095.html" rel="nofollow">
      https://baike.so.com/doc/24368318-25185095.html
     </a>
    </p>
    <p>
     我们要爬取的内容：
     <img alt="爬取的内容" src="https://i-blog.csdnimg.cn/blog_migrate/31f99f7ba7e09d177a92a15133e89534.png">
      <br/>
      html字段：
      <br/>
      <img alt="源代码" src="https://i-blog.csdnimg.cn/blog_migrate/840e58392524613e18570454951cf685.png">
       <br/>
       robots协议：
       <br/>
       <img alt="360搜索的robots协议" src="https://i-blog.csdnimg.cn/blog_migrate/8cf12618b142d7092c5505b02e63fbfb.png">
        <br/>
        现在我们开始用python IDLE 爬取
        <br/>
        <img alt="爬取得到的是‘’空返回" src="https://i-blog.csdnimg.cn/blog_migrate/30fdeff4d9cfe14a3e27bb7acc3719cf.png"/>
       </img>
      </img>
     </img>
    </p>
    <pre><code>import requests
r = requests.get("https://baike.so.com/doc/24368318-25185095.html")
r.status_code
r.text
</code></pre>
    <p>
     结果分析，我们可以成功访问到该网页，但是得不到网页的结果。被360搜索识别，我们将headers修改。转自：链接: [link(
     <a href="https://blog.csdn.net/SL_World/article/details/84893957">
      https://blog.csdn.net/SL_World/article/details/84893957
     </a>
     )
    </p>
    <p>
     <img alt="修改headers后得到成功的返回" src="https://i-blog.csdnimg.cn/blog_migrate/3f6b580436d9a0245d38bb7e48d49f2d.png">
      <br/>
      输出有个小插曲，网页内容很多，我是想将前500个字符输出，第一次格式错了
     </img>
    </p>
    <pre><code>import requests
headers = {
    'Cookie':'OCSSID=4df0bjva6j7ejussu8al3eqo03',
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                 '(KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36',
}
r = requests.get("https://baike.so.com/doc/24368318-25185095.html"， headers = headers)
r.status_code
r.text
</code></pre>
    <p>
     接着我们对需要的内容进行爬取，用(.find)方法找到我们内容位置，用(.children)下行遍历的方法对内容进行爬取，用(isinstance)方法对内容进行筛选：
    </p>
    <pre><code>import requests
from bs4 import BeautifulSoup
import bs4
headers = {
    'Cookie':'OCSSID=4df0bjva6j7ejussu8al3eqo03',
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                 '(KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36',
}
r = requests.get("https://baike.so.com/doc/24368318-25185095.html",  headers = headers)
r.status_code
r.encoding = r.apparent_encoding
soup = BeautifulSoup(r.text, "html.parser")
for tr in soup.find('tbody').children:
	if isinstance(tr, bs4.element.Tag):
		tds = tr('td')
		print([tds[0].string, tds[1].string, tds[2].string])
</code></pre>
    <p>
     得到结果如下：
     <br/>
     <img alt="输出结果" src="https://i-blog.csdnimg.cn/blog_migrate/977bac7b071eceadfa5787a31413a3be.png">
      <br/>
      修改输出的数目，我们用Clist列表来存取所有城市的排名，将前20个输出代码如下：
     </img>
    </p>
    <pre><code>import requests
from bs4 import BeautifulSoup
import bs4
Clist = list()  #存所有城市的列表
headers = {
    'Cookie':'OCSSID=4df0bjva6j7ejussu8al3eqo03',
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                 '(KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36',
}
r = requests.get("https://baike.so.com/doc/24368318-25185095.html", headers = headers)
r.encoding = r.apparent_encoding #将html的编码解码为utf-8格式
soup = BeautifulSoup(r.text, "html.parser") #重新排版
for tr in soup.find('tbody').children:     #将tbody标签的子列全部读取
	if isinstance(tr, bs4.element.Tag):    #筛选tb列表，将有内容的筛选出啦
	    tds = tr('td')
	    Clist.append([tds[0].string, tds[1].string, tds[2].string])
for i in range(21):
    print(Clist[i])
</code></pre>
    <p>
     最终结果：
     <br/>
     <img alt="最终的结果" src="https://i-blog.csdnimg.cn/blog_migrate/c250fbe550579c8ab546826035b2748a.png">
      <br/>
      第一次写博客，如果错的地方希望您能指出。互相学习！！！
     </img>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f71715f3338373936363336:2f61727469636c652f64657461696c732f3935323233323637" class_="artid" style="display:none">
 </p>
</div>


