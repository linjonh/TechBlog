---
layout: post
title: "开源超闭源通义千问Qwen2发布即爆火,网友GPT-4o危"
date: 2024-06-08 13:37:10 +0800
description: "文章浏览阅读1.8k次，点赞21次，收藏13次。鱼羊 发自 凹非寺量子位 | 公众号 QbitAI开"
keywords: "qwen2"
categories: ['未分类']
tags: ['无标签']
artid: "139553947"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=139553947
    alt: "开源超闭源通义千问Qwen2发布即爆火,网友GPT-4o危"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     开源超闭源！通义千问Qwen2发布即爆火，网友：GPT-4o危
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <div id="js_content">
     <h6>
      鱼羊 发自 凹非寺
      <br/>
      量子位 | 公众号 QbitAI
     </h6>
     <p style="text-align:left;">
      开源大模型全球格局，一夜再变。
     </p>
     <p style="text-align:left;">
      这不，全新开源大模型亮相，性能
      <strong>
       全面超越
      </strong>
      开源标杆Llama 3。王座易主了。不是“媲美”、不是“追上”，是全面超越。发布两小时，直接冲上HggingFace开源大模型榜单第一。
     </p>
     <p style="text-align:left;">
      这就是最新一代开源大模型
      <strong>
       Qwen2
      </strong>
      ，来自通义千问，来自阿里巴巴。
     </p>
     <p style="text-align:center;">
      <img alt="058ec90630bd0de2872e599b882d78bb.jpeg" src="https://i-blog.csdnimg.cn/blog_migrate/8300599ba3739953080efedd7051dbdc.jpeg"/>
     </p>
     <p style="text-align:left;">
      在十几项国际权威测评中，Qwen2-72B得分均胜过Llama3-70B，尤其在HumanEval、MATH等测试代码和数学能力的基准中表现突出。
     </p>
     <p>
      <img alt="3acc034465b09e49fa270c409f4a3dce.png" src="https://i-blog.csdnimg.cn/blog_migrate/d12d375613508a73a988af79394c7942.png"/>
     </p>
     <p style="text-align:left;">
      不仅如此，作为国产大模型，Qwen2-72B也“毕其功于一役”，超过了国内一众闭源大模型：
     </p>
     <p style="text-align:left;">
      Qwen2-72B相比于自家前代模型Qwen1.5-110B实现了整体性能的代际提升，而在上海AI Lab推出的OpenCompass大模型测评榜单上，Qwen1.5-110B已经超过了文心4、Moonshot-v1-8K等一众国内闭源模型。随着Qwen2-72B的问世，这一领先优势还在扩大。
     </p>
     <p style="text-align:center;">
      <img alt="31f52deb3bbba808c19d5477a52db128.png" src="https://i-blog.csdnimg.cn/blog_migrate/312fdd3e251c3f6718905bf085c03a18.png"/>
     </p>
     <p style="text-align:left;">
      有网友便感慨说：这还只是刚开始。开源模型很可能在未来几个月，就能击败GPT-4o为代表的闭源模型。
     </p>
     <p style="text-align:center;">
      <img alt="d5c5e09437660d0e3186f68e7c623d25.png" src="https://i-blog.csdnimg.cn/blog_migrate/8c2423b1b406689b649da857f32bb806.png"/>
     </p>
     <p style="text-align:left;">
      Qwen2的发布，可以说是一石激起千层浪。
     </p>
     <p style="text-align:left;">
      上线仅1天，下载量已经超过3万次。
     </p>
     <p style="text-align:left;">
      网友们还发现，除了72B和指令调优版本，这次同步开源的Qwen2-0.5B、Qwen2-1.5B、Qwen2-7B、Qwen2-57B-A14B，开源许可都换成了Apache 2.0——
     </p>
     <p style="text-align:left;">
      就是说可以
      <strong>
       更加自由地商用
      </strong>
      。这是Llama 3系列都没做到的。
     </p>
     <p style="text-align:center;">
      <img alt="b1390aff141c92e707d7169de11e1410.png" src="https://i-blog.csdnimg.cn/blog_migrate/ccfa020ef2ba53423cb25365174a7ac6.png"/>
     </p>
     <p style="text-align:left;">
      在AI大模型领域，时间和速度都不同了。
     </p>
     <p style="text-align:left;">
      因为距离阿里推出Qwen1.5-110B模型刷新SOTA，全球开源大模型形成双雄格局，才刚过去1个月时间。
     </p>
     <p style="text-align:left;">
      而现在，Qwen2独领风骚，全球开源第一，国产大模型第一——连不开源的大模型都超越了。
     </p>
     <h3>
      Qwen2挑战高考数学真题
     </h3>
     <p style="text-align:left;">
      还是先来整体梳理一下Qwen2的基本情况。
     </p>
     <p style="text-align:left;">
      根据官方技术博客介绍，Qwen2的特点和相比Qwen1.5的主要升级包括：
     </p>
     <ul>
      <li>
       <p>
        发布5个尺寸的预训练和指令微调模型，包括Qwen2-0.5B、Qwen2-1.5B、Qwen2-7B、Qwen2-57B-A14B以及Qwen2-72B。其中Qwen2-57B-A14B是一个MoE模型。
       </p>
      </li>
      <li>
       <p>
        在中文英语的基础上，对27种语言进行了增强。有阿拉伯语开发者表示，Qwen已经成为4亿阿拉伯语用户喜欢的大模型，稳居阿拉伯语开源模型榜单第一。
       </p>
      </li>
     </ul>
     <p style="text-align:center;">
      <img alt="9c22b8a5a465eb37a4de2b8b1fb726f6.jpeg" src="https://i-blog.csdnimg.cn/blog_migrate/e3883cede979bee387b2e89a9f21cb0b.jpeg"/>
     </p>
     <ul>
      <li>
       <p>
        在MMLU、GPQA、HumanEval、GSM8K、BBH、MT-Bench、Arena Hard、LiveCodeBench等国际权威测评中，Qwen2-72B斩获十几项世界第一，超过Llama 3。
       </p>
      </li>
      <li>
       <p>
        代码和数学能力显著提升。
       </p>
      </li>
      <li>
       <p>
        增大了上下文长度支持，最长实现128K tokens上下文长度支持（Qwen2-7B-Instruct和Qwen2-72B-Instruct）。
       </p>
      </li>
     </ul>
     <p style="text-align:left;">
      纸面数据上，Qwen2在开源大模型中已经达成全球最强，那么实际表现又会如何？
     </p>
     <p style="text-align:left;">
      我们用新鲜出炉的高考数学真题上手实测了一波。
     </p>
     <p style="text-align:left;">
      先来个简单题：
     </p>
     <blockquote>
      <p>
       已知集合A={x|-5＜x^3&lt;5}，B={-3,-1,0,2,3}，则A∩B=()
      </p>
     </blockquote>
     <p style="text-align:center;">
      <img alt="dafd72f9b4a8ab6d4b2bdcee397d860c.png" src="https://i-blog.csdnimg.cn/blog_migrate/3c4ca487e8d5d19bb63a2e4204914505.png"/>
     </p>
     <p style="text-align:left;">
      左边是Qwen2-72B-Instruct，右边是Llama-3-70B-Instruct。除了Llama 3原版的老问题不咋支持中文外，两边的答案都是正确的。
     </p>
     <p style="text-align:left;">
      那么就稍微上点难度：
     </p>
     <blockquote>
      <p>
       当x∈[0, 2π]时，曲线y=sinx与y=2sin(3x-π/6)的交点个数为？
      </p>
     </blockquote>
     <p style="text-align:center;">
      <img alt="8ee0bfff0af1c8dc59d7336c09d048f6.png" src="https://i-blog.csdnimg.cn/blog_migrate/fbbdb9167840851646a57f2b9d467f81.png"/>
     </p>
     <p style="text-align:left;">
      Qwen2-72B-Instruct依然没有被难住，一通计算后给出正确答案：交点个数为6个。
     </p>
     <p style="text-align:left;">
      而Llama-3-70B-Instruct则计算错误，扣5分。
     </p>
     <p style="text-align:left;">
      Qwen2在数学能力方面，已经到了高考考场接受真题检验的水平。
     </p>
     <p style="text-align:center;">
      <img alt="6b2a6603b8349c6f2a2dd5144a2a0cb9.gif" src="https://i-blog.csdnimg.cn/blog_migrate/f9e560822fe4e59089ec9975a91165b9.gif"/>
     </p>
     <p style="text-align:left;">
      通义千问此番升级，官方和评测数据还突出了代码能力的提升，我们也有LeetCode中等难度真题浅测了一下：
     </p>
     <blockquote>
      <p>
       给你一个按照非递减顺序排列的整数数组nums，和一个目标值target。请你找出给定目标值在数组中的开始位置和结束位置。如果数组中不存在目标值 target，返回 [-1, -1]。你必须设计并实现时间复杂度为 O(log n) 的算法解决此问题。
      </p>
     </blockquote>
     <p style="text-align:center;">
      <img alt="bd43df4c34b906eea962fbae975d2152.png" src="https://i-blog.csdnimg.cn/blog_migrate/daa90edf00e53b1a5aa7ba57c938d4d5.png"/>
     </p>
     <p style="text-align:left;">
      Qwen2-72B-Instruct给出的python实现如下：
     </p>
     <pre class="has"><code class="language-go">def searchRange(nums, target):def binary_search_left(nums, target):
        left, right = 0, len(nums)while left &lt; right:
            mid = (left + right) // 2if nums[mid] &lt; target:
                left = mid + 1else:
                right = midreturn left
def binary_search_right(nums, target):
        left, right = 0, len(nums)while left &lt; right:
            mid = (left + right) // 2if nums[mid] &lt;= target:
                left = mid + 1else:
                right = midreturn left
    left, right = binary_search_left(nums, target), binary_search_right(nums, target)return [left, right - 1] if left &lt;= right - 1 and nums[left] == target and nums[right - 1] == target else [-1, -1]</code></pre>
     <p style="text-align:left;">
      一开始没有定义Solution类导致报错，不过直接把报错信息反馈给Qwen2，它自己就能完成debug：
     </p>
     <p style="text-align:center;">
      <img alt="6e26d71da826ec86b76bf6196887a44c.png" src="https://i-blog.csdnimg.cn/blog_migrate/f80fdb7807b1add61c4089271a3da03f.png"/>
      <br/>
     </p>
     <p style="text-align:left;">
      顺利通过测试。
     </p>
     <p style="text-align:center;">
      <img alt="59c8f42709a512f5f9ddbd5287d01b10.png" src="https://i-blog.csdnimg.cn/blog_migrate/97b4e3cdeaebe464d8d7d46f4b03f1d2.png"/>
     </p>
     <h3>
      全尺寸模型标配GQA
     </h3>
     <p style="text-align:left;">
      这波实测，你给通义千问打几分？
     </p>
     <p style="text-align:left;">
      值得关注的是，这次阿里官方的技术博客中，还透露出了不少
      <strong>
       Qwen变强的技术细节
      </strong>
      。
     </p>
     <p style="text-align:left;">
      首先，是
      <strong>
       GQA（Grouped Query Attention）
      </strong>
      的全面加持。
     </p>
     <p style="text-align:center;">
      <img alt="398f3726512c3e2699ed710e08323baa.png" src="https://i-blog.csdnimg.cn/blog_migrate/8212e6dffe0cac08bd3db5faf503b4f3.png"/>
     </p>
     <p style="text-align:left;">
      GQA，即分组查询注意力机制，主要思想将输入序列划分成若干个组，在组内和组间分别应用注意力机制，以更好地捕捉序列内的局部和全局依赖关系。
     </p>
     <p style="text-align:left;">
      GQA能够有效降低计算复杂度，同时很容易实现并行化从而提高计算效率。
     </p>
     <p style="text-align:left;">
      在Qwen1.5系列中，只有32B和110B模型使用了GQA。而Qwen2则全系列用上了这一注意力机制。也就是说，无论是高端玩家还是爱好者入门，这回都能在Qwen2各个尺寸模型中体验到GQA带来的推理加速和显存占用降低的优势。
     </p>
     <p style="text-align:left;">
      另外，针对小模型（0.5B和1.5B），由于embedding参数量较大，研发团队使用了tie embedding的方法让输入和输出层共享参数，以增加非embedding参数的占比。
     </p>
     <p style="text-align:left;">
      其次，在上下文长度方面，Qwen2系列中所有Instruct模型，均在32K上下文长度上进行训练，并通过YARN或Dual Chunk Attention等技术扩展至更长的上下文长度。
     </p>
     <p style="text-align:left;">
      其中，Qwen2-7B-Instruct和Qwen2-72B-Instruct支持128K上下文。72B版本的最长上下文长度可以达到131072个token。
     </p>
     <p style="text-align:left;">
      Qwen2-57B-A14B-Instruct能处理64K上下文，其余两个较小的模型（0.5B和1.5B）则支持32K的上下文长度。
     </p>
     <p style="text-align:left;">
      大海捞针的实验结果如下。可以看到，Qwen2-72B-Instruct在处理128K上下文长度内的信息抽取任务时，表现称得上完美。
     </p>
     <p style="text-align:center;">
      <img alt="d4d88040173f8554fe55860cad38b5ad.png" src="https://i-blog.csdnimg.cn/blog_migrate/1481cd18ec22c811f696ede076389b94.png"/>
     </p>
     <p style="text-align:left;">
      除此之外，在数据方面，Qwen2继续探索Scaling Law的路线。
     </p>
     <p style="text-align:left;">
      比如数学能力的提升，就是研究团队给模型喂了大规模高质量数学数据的结果。
     </p>
     <p style="text-align:left;">
      在多语言能力方面，研究团队也针对性地在训练数据中增加了27种语言相关的高质量数据。
     </p>
     <p style="text-align:center;">
      <img alt="e38c481f411ce7341b902936e4993b0d.png" src="https://i-blog.csdnimg.cn/blog_migrate/66229c60e92d0bce292319a5bfddca0b.png"/>
     </p>
     <p style="text-align:left;">
      博客还透露，接下来，通义千问研究团队还将继续探索模型及数据的Scaling Law，还会把Qwen2扩展为多模态模型。
     </p>
     <h3>
      重新认识中国开源大模型
     </h3>
     <p style="text-align:left;">
      更强的性能、更开放的态度，Qwen2刚一发布，堪称好评如潮。
     </p>
     <p style="text-align:center;">
      <img alt="6c645caa1f40c80bdb1454c7225087b2.png" src="https://i-blog.csdnimg.cn/blog_migrate/c5ef4e98b67a9e16e0eaec452e60ccdc.png"/>
     </p>
     <p style="text-align:left;">
      而在此前，生态方面，Qwen系列下载量已突破1600万次。海内外开源社区也已经出现了超过1500款基于Qwen二次开发的模型和应用。
     </p>
     <p style="text-align:left;">
      已经有开发者感受到了：
      <strong>
       在开源路线上，现在中国大模型正在成为引领者
      </strong>
      。
     </p>
     <p style="text-align:center;">
      <img alt="392fa61574eb953fc10c70cafd6ff306.png" src="https://i-blog.csdnimg.cn/blog_migrate/10798580aa22e5eaacbf85dd02276008.png"/>
     </p>
     <p style="text-align:left;">
      Qwen2的最新成绩单，至少印证了两个事实。
     </p>
     <p style="text-align:left;">
      其一，中国开源大模型，从性能到生态，都已具备跟美国最强开源大模型Llama 3全面对垒的硬实力。
     </p>
     <p style="text-align:left;">
      其二，如图灵奖得主Yann LeCun所预言，开源大模型已经走在了超越闭源模型的道路上，拐点已现。
     </p>
     <p style="text-align:left;">
      事实上，这也是包括阿里在内，开源大模型玩家的明牌——
     </p>
     <p style="text-align:left;">
      大模型的持续优化和进步，一方面依赖于强大的AI研发能力、领先的基础设施能力，也就是人工智能和云的强强联合。
     </p>
     <p style="text-align:left;">
      以阿里为例，作为中国云厂商份额第一，依托于强大的云计算能力，能为AI训练、AI应用提供稳定高效的AI基础服务体系，同时在人工智能方面有长期的积累。
     </p>
     <p style="text-align:left;">
      另一方面也需要来自外界的不断反馈和技术推动。
     </p>
     <p style="text-align:left;">
      开源社区的技术反哺，从Qwen2上线第一天，GitHub上的Issues数量就可见一斑。
     </p>
     <p style="text-align:center;">
      <img alt="bd5d4879b7c2af786e1c1119f589efd5.png" src="https://i-blog.csdnimg.cn/blog_migrate/dffd9b1e970ca178edf470d4221270bc.png"/>
     </p>
     <p style="text-align:left;">
      在技术领域，开源就是我为人人、人人为我，是全球科技互联网繁荣发展至今最核心的精神要素。
     </p>
     <p style="text-align:left;">
      不论任何一个时代，不管哪种新兴技术浪潮，没有程序员、工程师不以开源感到骄傲，甚至快乐。
     </p>
     <p style="text-align:left;">
      阿里高级算法专家、开源负责人林俊旸，曾对外分享过通义千问进展飞快的“秘籍”：
     </p>
     <p style="text-align:left;">
      <strong>
       快乐。
      </strong>
     </p>
     <p style="text-align:left;">
      因为面向全球开发者服务，面向其他开发者交流，给别人带去实实在在的帮助，这样通义千问大模型的打造者们快乐又兴奋，关注着每一个开发者的反馈，激动于全新意想不到的落地应用。
     </p>
     <p style="text-align:left;">
      这也是科技互联网世界曾经快速发展的核心原因，黄金时代，开源才是约定俗成的，不开源反而要遭受质疑。
     </p>
     <p style="text-align:left;">
      然而时移世易，在大模型时代，由于研发成本、商业模式和竞争多方面的原因，闭源的光芒一度掩盖了开源，Close成了宠儿。
     </p>
     <p style="text-align:left;">
      所以Meta的Llama也好，阿里通义千问的Qwen也好，复兴传统，重新证明科技互联网领域不变的精神和内核。
     </p>
     <p style="text-align:left;">
      这种精神和内核，在通义千问这里，也拥有不言自明的可持续飞轮。
     </p>
     <p style="text-align:left;">
      阿里巴巴董事长蔡崇信已经对外分享了思考，在全球云计算和AI的第一梯队中，有领先的云业务又有自研大模型能力的，仅谷歌和阿里两家。其他有云服务的微软、亚马逊，都是合作接入大模型；其他自研大模型的OpenAI、Meta，没有领先的云服务。
     </p>
     <p style="text-align:left;">
      全球唯二，中国唯一。
     </p>
     <p style="text-align:left;">
      而在开源生态的推动中，技术迭代会更快，云计算的服务延伸会越广，技术模型和商业模式，飞轮闭环，循环迭代，在固有基础设施的基础上垒起新的基础设施，形成稳固持续的竞争力。
     </p>
     <p style="text-align:left;">
      但开源大模型，最大的价值和意义依然回归开发者，只有足够强大的开源大模型，AI for All、AI无处不在才不会成为纸上空谈。
     </p>
     <p style="text-align:left;">
      所以通义千问Qwen2，此时此刻，登顶的是全球开源性能最高峰，引领的是开源对闭源的超越阶段，象征着中国大模型在新AI时代中的竞争力。
     </p>
     <p style="text-align:left;">
      但更值得期待的价值是通过开源大模型，让天下没有难开发的AI应用、让天下没有难落地的AI方案。完整兑现AI价值，让新一轮AI复兴，持续繁荣，真正改变经济和社会。
     </p>
     <p style="text-align:left;">
      参考链接：
     </p>
     <p style="text-align:left;">
      https://qwenlm.github.io/zh/blog/qwen2/
     </p>
     <p style="text-align:center;">
      —
      <strong>
       完
      </strong>
      —
     </p>
     <p style="text-align:center;">
      <strong>
       点这里👇关注我，记得标星哦～
      </strong>
     </p>
    </div>
   </div>
  </div>
 </article>
 <p alt="68747470:733a2f2f626c6f672e6373646e2e6e65742f5162697441492f:61727469636c652f64657461696c732f313339353533393437" class_="artid" style="display:none">
 </p>
</div>


