---
layout: post
title: "ffmpeg合并复用音频和视频文件,组成mp4"
date: 2024-12-20 04:51:46 +0800
description: "ffmpeg合并（复用）音频和视频文件，组成mp4。程序如下：/*合并音频和视频,形成音视频*/ex"
keywords: "基于ffmpeg6.0的视频重编码音频复用"
categories: ['Ffmpeg']
tags: ['Ffmpeg']
artid: "120433213"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=120433213
    alt: "ffmpeg合并复用音频和视频文件,组成mp4"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     ffmpeg合并（复用）音频和视频文件，组成mp4
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     ffmpeg合并（复用）音频和视频文件，组成mp4。程序如下：
    </p>
    <pre><code class="language-cpp">/*
合并音频和视频,形成音视频
*/

extern "C"
{
#include "libavutil/avutil.h"
#include "libavformat/avformat.h"
#include "libavformat/avio.h"
#include "libavcodec/avcodec.h"
}


#pragma warning(disable:4996)


int main()
{
	//
	const char *srcMedia1 = "out/t2Video.h264";
	const char *srcMedia2 = "out/T2audio.aac";
	const char *destMedia = "out/T2.mp4";
	char errors[200] = { 0 };
	AVFormatContext *inFormatContext1 = NULL;
	AVFormatContext *inFormatContext2 = NULL;
	AVFormatContext *outFormatContext = NULL;

	//输入上下文1-视频
	int ret = 0;
	av_log_set_level(AV_LOG_INFO);
	av_register_all();
	ret = avformat_open_input(&amp;inFormatContext1, srcMedia1, NULL, NULL);
	if (ret != 0)
	{
		av_strerror(ret, errors, 200);
		av_log(NULL, AV_LOG_WARNING, "error, ret=%d, msg=%s\n", ret, errors);
		return -1;
	}
	avformat_find_stream_info(inFormatContext1, NULL);
	av_dump_format(inFormatContext1, -1, srcMedia1, 0);
	//输入上下文1-音频
	ret = avformat_open_input(&amp;inFormatContext2, srcMedia2, NULL, NULL);
	avformat_find_stream_info(inFormatContext2, NULL);
	av_dump_format(inFormatContext2, -1, srcMedia2, 0);
	//输出上下文
	avformat_alloc_output_context2(&amp;outFormatContext, NULL, NULL, destMedia);
	AVOutputFormat *outFormat = outFormatContext-&gt;oformat;
	int stream1 = 0;
	AVStream *inStream1 = NULL;
	//复制流信息
	if(inFormatContext1-&gt;nb_streams &gt; 0)
	{
		stream1 = 1;
		inStream1 = inFormatContext1-&gt;streams[0];
		AVStream *outStream = avformat_new_stream(outFormatContext, NULL);
		avcodec_parameters_copy(outStream-&gt;codecpar, inStream1-&gt;codecpar);
		outStream-&gt;codecpar-&gt;codec_tag = 0;
	}
	int stream2 = 0;
	AVStream *inStream2 = NULL;
	if (inFormatContext2-&gt;nb_streams &gt; 0)
	{
		stream2 = 1;
		inStream2 = inFormatContext2-&gt;streams[0];
		AVStream *outStream = avformat_new_stream(outFormatContext, NULL);
		avcodec_parameters_copy(outStream-&gt;codecpar, inStream2-&gt;codecpar);
		outStream-&gt;codecpar-&gt;codec_tag = 0;
	}
	av_dump_format(outFormatContext, -1, destMedia, 1);
	//打开文件
	avio_open(&amp;outFormatContext-&gt;pb, destMedia, AVIO_FLAG_WRITE);
	avformat_write_header(outFormatContext, NULL);
	int64_t curPts1 = 0;
	int64_t curPts2 = 0;
	
	AVPacket avPacket;
	av_init_packet(&amp;avPacket);
	//输入流时间基
	AVRational inStream1time = inStream1-&gt;time_base;
	AVRational inStream2time = inStream2-&gt;time_base;
	int frameIndex = 0;
	//交替写入音频和视频数据
	while (stream1 || stream2)
	{
		if (stream1 &amp;&amp; (!stream2 || av_compare_ts(curPts1, inStream1time, curPts2, inStream2time) &lt;= 0))
		{
			ret = av_read_frame(inFormatContext1, &amp;avPacket);
			if (ret &lt; 0)
			{
				stream1 = 0;
				continue;
			}
			//raw h264无pts,手动添加
			if (avPacket.pts == AV_NOPTS_VALUE)
			{
				AVRational timeBase = inStream1time;
				int64_t calcDuration = AV_TIME_BASE / av_q2d(inStream1-&gt;r_frame_rate);
				avPacket.pts = (double)(frameIndex*calcDuration) / (av_q2d(timeBase)*AV_TIME_BASE);
				avPacket.dts = avPacket.pts;
				avPacket.duration = (double)calcDuration / (av_q2d(timeBase)*AV_TIME_BASE);
				frameIndex++;
			}
			curPts1 = avPacket.pts;
			AVStream *outStream = outFormatContext-&gt;streams[0];
			avPacket.pts = av_rescale_q_rnd(avPacket.pts, inStream1time, outStream-&gt;time_base, AVRounding(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
			avPacket.dts = avPacket.pts;
			avPacket.duration = av_rescale_q(avPacket.duration, inStream1time, outStream-&gt;time_base);
			avPacket.pos = -1;
			avPacket.stream_index = 0;
			//av_log(NULL, AV_LOG_INFO, "xxxxxxxxx%d, dts=%lld, pts=%lld, duration=%lld\n", frameIndex, avPacket.dts, avPacket.pts, avPacket.duration);
			stream1 = !av_interleaved_write_frame(outFormatContext, &amp;avPacket);
		}
		else if (stream2)
		{
			ret = av_read_frame(inFormatContext2, &amp;avPacket);
			if (ret &lt; 0)
			{
				stream2 = 0;
				continue;
			}
			//raw aac无pts,手动添加
			if (avPacket.pts == AV_NOPTS_VALUE)
			{
				AVRational timeBase = inStream2time;
				int64_t calcDuration = AV_TIME_BASE / av_q2d(inStream2-&gt;r_frame_rate);
				avPacket.pts = (double)(frameIndex*calcDuration) / (av_q2d(timeBase)*AV_TIME_BASE);
				avPacket.dts = avPacket.pts;
				avPacket.duration = (double)calcDuration / (av_q2d(timeBase)*AV_TIME_BASE);
				frameIndex++;
			}
			curPts2 = avPacket.pts;
			AVStream *outStream = outFormatContext-&gt;streams[1];
			avPacket.pts = av_rescale_q_rnd(avPacket.pts, inStream2time, outStream-&gt;time_base, AVRounding(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
			avPacket.dts = avPacket.pts;
			avPacket.duration = av_rescale_q(avPacket.duration, inStream2time, outStream-&gt;time_base);
			avPacket.pos = -1;
			avPacket.stream_index = 1;
			av_log(NULL, AV_LOG_INFO, "xxxxxxxxx%d, size:%5d, dts=%lld, pts=%lld, duration=%lld\n", frameIndex, avPacket.size, avPacket.dts, avPacket.pts, avPacket.duration);
			stream2 = !av_interleaved_write_frame(outFormatContext, &amp;avPacket);
		}
		av_packet_unref(&amp;avPacket);
	}
	ret = av_write_trailer(outFormatContext);
	if (ret != 0)
	{
		av_strerror(ret, errors, 200);
		av_log(NULL, AV_LOG_WARNING, "av_write_trailer error: ret=%d, msg=%s\n", ret, errors);
	}

	//释放资源
	avformat_close_input(&amp;inFormatContext1);
	avformat_close_input(&amp;inFormatContext2);
	avio_close(outFormatContext-&gt;pb);

	return 0;
}</code></pre>
    <p>
     <strong>
      相关链接：
     </strong>
     <a href="https://blog.csdn.net/leixiaohua1020/article/details/39802913" title="最简单的基于FFmpeg的封装格式处理：视音频复用器（muxer）_雷霄骅(leixiaohua1020)的专栏-CSDN博客_muxer">
      最简单的基于FFmpeg的封装格式处理：视音频复用器（muxer）_雷霄骅(leixiaohua1020)的专栏-CSDN博客_muxer
     </a>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f717569657462786a2f:61727469636c652f64657461696c732f313230343333323133" class_="artid" style="display:none">
 </p>
</div>


