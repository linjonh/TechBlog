---
layout: post
title: "科大讯飞首发开源大模型星火开源-13B-深度适配昇思MindSpore-AI框架"
date: 2025-01-08 16:40:14 +0800
description: ""
keywords: "科大讯飞大模型架构"
categories: ['']
tags: ['人工智能']
artid: "136070530"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=136070530
    alt: "科大讯飞首发开源大模型星火开源-13B-深度适配昇思MindSpore-AI框架"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     科大讯飞首发开源大模型“星火开源-13B” 深度适配昇思MindSpore AI框架
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     1月30日，科大讯飞举行星火认知大模型V3.5升级发布会。发布会上依托昇思MindSpore AI框架打造的讯飞星火开源大模型“星火开源-13B”正式发布，开源模型场景应用效果领先，目前已在Gitee的MindFormers代码仓开源，用户可在昇思MindSpore开源社区线上体验。
    </p>
    <p>
    </p>
    <p>
     开源代码仓：https://gitee.com/mindspore/mindformers/tree/r1.0/research/iflytekspark开源社区体验：https://xihe.mindspore.cn/modelzoo/iflytek/introduce
    </p>
    <p>
    </p>
    <p class="img-center">
     <img alt="image.png" height="723" src="https://i-blog.csdnimg.cn/blog_migrate/7eba509ea37b0b4d3e6a9072a0ca3c48.png" width="1080"/>
    </p>
    <p>
     <strong>
      <strong>
       <strong>
        1、
       </strong>
      </strong>
     </strong>
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          <strong>
           <strong>
            公开评测榜单名列前茅，应用效果显著领先
           </strong>
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
    </p>
    <p>
    </p>
    <p class="img-center">
     <img alt="image.png" height="300" src="https://i-blog.csdnimg.cn/blog_migrate/9764a0de72c3b01300e817e927ddde32.png" width="1080"/>
    </p>
    <p>
     星火开源-13B在多项知名公开评测任务中名列前茅，在文本生成、语言理解、文本改写、行业问答、机器翻译等企业典型场景中，通过对学习辅助、语言理解等领域的深入研究和优化，大幅提升了其实用性，在处理复杂的自然语言任务时更加得心应手，确保了其在面对多样化和专业化的应用场景时能够保持高效和准确，效果显著优于其他同等尺寸的开源模型。为各行各业提供了一种性价比高的解决方案。
    </p>
    <p>
    </p>
    <p class="img-center">
     <img alt="image.png" height="500" src="https://i-blog.csdnimg.cn/blog_migrate/d5e03271d14565eca304f17ce6ec49ce.png" width="1080"/>
    </p>
    <p>
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          2、
         </strong>
        </strong>
       </strong>
       <strong>
        <strong>
         <strong>
          <strong>
           <strong>
            <strong>
             <strong>
              <strong>
               <strong>
                利用MindSpore Transformers套件适配优化，同步上线昇思MindSpore开源社区
               </strong>
              </strong>
             </strong>
            </strong>
           </strong>
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
    </p>
    <p>
    </p>
    <p>
     在星火开源-13B训练过程中，开发团队利用昇思MindSpore AI框架将训练效率提升了40%。此外，科大讯飞及昇思MindSpore研发团队通过昇思MindSpore Transformers大模型套件提供的分布式自动并行能力，实现训练策略的匹配，节省大量开发投入与策略调试时间，训练完成后可调用套件提供的一站式微调算法进行模型快速调优，从而实现开发效率大幅提升，目前已在相应代码仓及昇思社区上线，欢迎大家在线体验。
    </p>
    <p>
    </p>
    <p>
    </p>
    <p>
     <strong>
      附录：
     </strong>
    </p>
    <p>
    </p>
    <p>
     Mindformers仓库地址: https://gitee.com/mindspore/mindformers/tree/r1.0/research/iflytekspark
    </p>
    <p>
     昇思MindSpore开源社区：https://xihe.mindspore.cn/modelzoo/iflytek/introduce启智社区：https://openi.pcl.ac.cn/iflytek/iFlytekSpark-13BGitee地址：https://gitee.com/iflytekopensource/iFlytekSpark-13B
    </p>
    <p>
     社群二维码：
    </p>
    <p>
    </p>
    <p class="img-center">
     <img alt="image.png" height="913" src="https://i-blog.csdnimg.cn/blog_migrate/98ef690aa6b4321a69b612ebc3965202.png" width="513"/>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c:6f672e6373646e2e6e65742f4b656e6a695f5368696e6a692f:61727469636c652f64657461696c732f313336303730353330" class_="artid" style="display:none">
 </p>
</div>


