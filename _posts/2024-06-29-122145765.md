---
layout: post
title: "音视频7安卓硬编音视频数据推送到rtmp服务器"
date: 2024-06-29 03:38:48 +0800
description: "音视频开发路线：Android 音视频开发入门指南_Jhuster的专栏的技术博客_51CTO博客_"
keywords: "音视频系统的对接推送"
categories: ['音视频', '安卓']
tags: ['音视频', 'Flutter', 'Android']
artid: "122145765"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=122145765
    alt: "音视频7安卓硬编音视频数据推送到rtmp服务器"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     音视频7——安卓硬编音视频数据推送到rtmp服务器
    </h1>
   </div>
   <div class="ai-article-tag" id="ai-article-tag">
    <div class="ai-article-tag-box">
     <p class="ai-article-tag-item-active">
      <img alt="" class="item-target" src="https://img-home.csdnimg.cn/images/20240715101418.png"/>
     </p>
     <a class="ai-article-tag-item" data-report-click='{"spm":"3001.10231","extra":{"searchword":"Android开发"}}' data-report-query="spm=1001.2101.3001.10231" data-report-view='{"spm":"3001.10231","extra":{"searchword":"Android开发"}}' href="https://so.csdn.net/so/search/s.do?q=Android%E5%BC%80%E5%8F%91&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">
      <span>
       Android开发
      </span>
     </a>
     <a class="ai-article-tag-item" data-report-click='{"spm":"3001.10231","extra":{"searchword":"音视频直播"}}' data-report-query="spm=1001.2101.3001.10231" data-report-view='{"spm":"3001.10231","extra":{"searchword":"音视频直播"}}' href="https://so.csdn.net/so/search/s.do?q=%E9%9F%B3%E8%A7%86%E9%A2%91%E7%9B%B4%E6%92%AD&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">
      <span>
       音视频直播
      </span>
     </a>
     <a class="ai-article-tag-item" data-report-click='{"spm":"3001.10231","extra":{"searchword":"RTMP协议"}}' data-report-query="spm=1001.2101.3001.10231" data-report-view='{"spm":"3001.10231","extra":{"searchword":"RTMP协议"}}' href="https://so.csdn.net/so/search/s.do?q=RTMP%E5%8D%8F%E8%AE%AE&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">
      <span>
       RTMP协议
      </span>
     </a>
     <a class="ai-article-tag-item" data-report-click='{"spm":"3001.10231","extra":{"searchword":"MediaCodec"}}' data-report-query="spm=1001.2101.3001.10231" data-report-view='{"spm":"3001.10231","extra":{"searchword":"MediaCodec"}}' href="https://so.csdn.net/so/search/s.do?q=MediaCodec&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">
      <span>
       MediaCodec
      </span>
     </a>
     <a class="ai-article-tag-item" data-report-click='{"spm":"3001.10231","extra":{"searchword":"服务器配置"}}' data-report-query="spm=1001.2101.3001.10231" data-report-view='{"spm":"3001.10231","extra":{"searchword":"服务器配置"}}' href="https://so.csdn.net/so/search/s.do?q=%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">
      <span>
       服务器配置
      </span>
     </a>
    </div>
    <span class="ai-article-tag-text">
     关键词由CSDN通过智能技术生成
    </span>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     音视频开发路线：
    </p>
    <p>
     <a href="https://blog.51cto.com/ticktick/1956269" rel="nofollow" title="Android 音视频开发入门指南_Jhuster的专栏的技术博客_51CTO博客_android 音视频开发入门">
      Android 音视频开发入门指南_Jhuster的专栏的技术博客_51CTO博客_android 音视频开发入门
     </a>
    </p>
    <p>
     demo地址：
    </p>
    <p>
     <a href="https://github.com/wygsqsj/videoPath/blob/master/app/src/main/java/com/wish/videopath/demo8/Demo8Activity.java" title="videoPath/Demo8Activity.java at master · wygsqsj/videoPath · GitHub">
      videoPath/Demo8Activity.java at master · wygsqsj/videoPath · GitHub
     </a>
    </p>
    <h2>
     一.RTMP使用流程
    </h2>
    <p>
     rtmp协议的api调用顺序如下：
    </p>
    <p>
     <img alt="" height="532" src="https://i-blog.csdnimg.cn/blog_migrate/6599e9a04f131b90b85ffb485f35f227.png" width="404"/>
    </p>
    <p>
    </p>
    <h2>
     二.初始化RTMP，连接服务器
    </h2>
    <p>
     有两种构建rtmp服务器的方式我们使用的b站的服务器，要使用b站的服务器，你得认证一下，审核还需要大概1天得时间，除此之外，我们还可以自己构建rtmp服务器，你可以花几十块钱买个阿里云之类的云服务器，预装一个Linux系统，rtmp服务器一般是安装在linux上，他需要配合ngix等代理框架来实现，不想自己配置的话就去申请个B站直播，我是windows电脑，然后在自己电脑上跑了一个Ubuntu虚拟机，把RTMP服务器跑在了虚拟机中，具体的配置可以参考：
    </p>
    <p>
     <a href="https://blog.csdn.net/kangear/article/details/83019640" title="Ubuntu 16.04简易安装Nginx-rtmp-module_Android/Linux的专栏-CSDN博客">
      Ubuntu 16.04简易安装Nginx-rtmp-module_Android/Linux的专栏-CSDN博客
     </a>
    </p>
    <p>
     由于对Linux系统的不熟悉，在安装中可能遇到各种各样的问题，我有的时候也是会在一个地方卡住，然后就得各种查资料，例如Vim编辑文本，我当时第一次接触时搞了好久才知道这个vim原来是用来在命令框中直接编辑文档的，如果碰到了问题卡住了，可以不用钻牛角尖，放置一会，也可以留言，我如果看到了也会看一块研究一下，博主也是一个在爬坡的开发，如果可能的话希望可以帮到你。
    </p>
    <p>
    </p>
    <p>
     下面我们把rtmp服务器初始化，此处为了后面对视频的sps等数据保存，我们定义了一个结构体来保存RTMP和sps、pps等数据
    </p>
    <pre><code>//用于保存sps pps 结构体
typedef struct {
    RTMP *rtmp;
    int8_t *sps;//sps数组
    int8_t *pps;//pps数组
    int16_t sps_len;//sps数组长度
    int16_t pps_len;//pps数组长度
} Live;</code></pre>
    <p>
     初始化rtmp服务器，然后对rtmp进行配置，然后链接我们java层传入的rtmp地址,如果我们的rtmp服务器配置正常且开启之后RTMP_ConnectStream函数将会返回成功
    </p>
    <pre><code>extern "C"
JNIEXPORT jboolean JNICALL
Java_com_example_rtmpdemo_mediacodec_ScreenLive_connect(JNIEnv *env, jobject thiz, jstring url_) {
    //链接rtmp服务器
    int ret = 0;
    const char *url = env-&gt;GetStringUTFChars(url_, 0);
    //不断重试，链接服务器
    do {
        //初始化live数据
        live = (Live *) malloc(sizeof(Live));
        //清空live数据
        memset(live, 0, sizeof(Live));
        //初始化RTMP,申请内存
        live-&gt;rtmp = RTMP_Alloc();
        RTMP_Init(live-&gt;rtmp);
        //设置超时时间
        live-&gt;rtmp-&gt;Link.timeout = 10;
        LOGI("connect %s", url);
        //设置地址
        if (!(ret = RTMP_SetupURL(live-&gt;rtmp, (char *) url))) break;
        //设置输出模式
        RTMP_EnableWrite(live-&gt;rtmp);
        LOGI("connect Connect");
        //连接
        if (!(ret = RTMP_Connect(live-&gt;rtmp, 0))) break;
        LOGI("connect ConnectStream");
        //连接流
        if (!(ret = RTMP_ConnectStream(live-&gt;rtmp, 0))) break;
        LOGI("connect 成功");
    } while (0);

    //连接失败，释放内存
    if (!ret &amp;&amp; live) {
        free(live);
        live = nullptr;
    }

    env-&gt;ReleaseStringUTFChars(url_, url);
    return ret;
}</code></pre>
    <h2>
     三.发送数据到rtmp服务器
    </h2>
    <p>
     java层我们通过Camera2来获取视频数据，AudioRecord来进行录音，再通过MediaCodec实现编码，cameara2的api调用比较繁琐，可以去我的github项目中查看具体的使用方法，总之就是把采集到视频数剧转换成nv12，使用MediaCodec来将yuv数据编码成h264码流，然后把h264数据通过jni方法传递到我们的Native层，现在我们来看一下Native中收到了数据后的操作：
    </p>
    <pre><code>//发送数据到rtmp服务器端
extern "C"
JNIEXPORT jboolean JNICALL
Java_com_example_rtmpdemo2_mediacodec_ScreenLive_sendData(JNIEnv *env, jobject thiz,
                                                          jbyteArray data_, jint len,
                                                          jlong tms, jint type) {
    // 确保不会取出空的 RTMP 数据包
    if (!data_) {
        return 0;
    }
    int ret;
    int8_t *data = env-&gt;GetByteArrayElements(data_, NULL);

    if (type == 1) {//视频
        LOGI("开始发送视频 %d", len);
        ret = sendVideo(data, len, tms);
    } else {//音频
        LOGI("开始发送音频 %d", len);
        ret = sendAudio(data, len, tms, type);
    }

    env-&gt;ReleaseByteArrayElements(data_, data, 0);
    return ret;
}
</code></pre>
    <p>
     收到视频数据后，需要判断是否是sps、pps数据，如果是，把他们缓存到结构体中，后续的I帧进入时我们再把sps、pps添加到头部，因为直播中任意时刻进入的用户想播放必须先解析sps/pps这些配置数据才行
    </p>
    <pre><code>/**
 *发送帧数据到rtmp服务器
 *把pps和sps缓存下来，放在每一个I帧前面，
 */
int sendVideo(int8_t *buf, int len, long tms) {
    int ret = 0;
    //当前时sps,缓存sps、pps 到全局变量
    if (buf[4] == 0x67) {
        //判断live是否缓存过，liv缓存过不再进行缓存
        if (live &amp;&amp; (!live-&gt;sps || !live-&gt;pps)) {
            saveSPSPPS(buf, len, live);
        }
        return ret;
    }

    //I帧，关键帧,非关键帧直接推送帧数据
    if (buf[4] == 0x65) {
        LOGI("找到关键帧,先发送sps数据 %d", len);
        //先推送sps、pps
        RTMPPacket *SPpacket = createSPSPPSPacket(live);
        sendPacket(SPpacket);
    }
    //推送帧数据
    RTMPPacket *packet = createVideoPacket(buf, len, tms, live);
    ret = sendPacket(packet);
    return ret;
}
</code></pre>
    <p>
     RTMP协议发送的是RTMPPacket数据包，其中sps和pps的数据包为：
    </p>
    <pre><code>/**
 * 创建sps和pps的RTMPPacket
 */
RTMPPacket *createSPSPPSPacket(Live *live) {
    //sps、pps的packet
    int body_size = 16 + live-&gt;sps_len + live-&gt;pps_len;
    LOGI("创建sps Packet ,body_size:%d", body_size);
    RTMPPacket *packet = (RTMPPacket *) malloc(sizeof(RTMPPacket));
    //初始化packet数据,申请数组
    RTMPPacket_Alloc(packet, body_size);
    int i = 0;
    //固定协议字节标识
    packet-&gt;m_body[i++] = 0x17;
    packet-&gt;m_body[i++] = 0x00;
    packet-&gt;m_body[i++] = 0x00;
    packet-&gt;m_body[i++] = 0x00;
    packet-&gt;m_body[i++] = 0x00;
    packet-&gt;m_body[i++] = 0x01;
    //sps配置信息
    packet-&gt;m_body[i++] = live-&gt;sps[1];
    packet-&gt;m_body[i++] = live-&gt;sps[2];
    packet-&gt;m_body[i++] = live-&gt;sps[3];
    //固定
    packet-&gt;m_body[i++] = 0xFF;
    packet-&gt;m_body[i++] = 0xE1;
    //两个字节存储sps长度
    packet-&gt;m_body[i++] = (live-&gt;sps_len &gt;&gt; 8) &amp; 0xFF;
    packet-&gt;m_body[i++] = (live-&gt;sps_len) &amp; 0xFF;
    //sps内容写入
    memcpy(&amp;packet-&gt;m_body[i], live-&gt;sps, live-&gt;sps_len);
    i += live-&gt;sps_len;

    //pps开始写入
    packet-&gt;m_body[i++] = 0x01;
    //pps长度
    packet-&gt;m_body[i++] = (live-&gt;pps_len &gt;&gt; 8) &amp; 0xFF;
    packet-&gt;m_body[i++] = (live-&gt;pps_len) &amp; 0xFF;
    memcpy(&amp;packet-&gt;m_body[i], live-&gt;pps, live-&gt;pps_len);

    //设置视频类型
    packet-&gt;m_packetType = RTMP_PACKET_TYPE_VIDEO;
    packet-&gt;m_nBodySize = body_size;
    //通道值，音视频不能相同
    packet-&gt;m_nChannel = 0x04;
    packet-&gt;m_nTimeStamp = 0;
    packet-&gt;m_hasAbsTimestamp = 0;
    packet-&gt;m_headerType = RTMP_PACKET_SIZE_LARGE;
    packet-&gt;m_nInfoField2 = live-&gt;rtmp-&gt;m_stream_id;
    return packet;
}</code></pre>
    <p>
     普通帧数据的构建方式，注意就是I帧和非I帧，RTMPPacket的起始字节是不同的
    </p>
    <pre><code>/**
 * 创建帧内数据的RTMPPacket,I帧和非关键帧都在此合成RTMPPacket
 */
RTMPPacket *createVideoPacket(int8_t *buf, int len, long tms, Live *live) {
    buf += 4;
    len -= 4;
    RTMPPacket *packet = (RTMPPacket *) malloc(sizeof(RTMPPacket));
    int body_size = len + 9;
    LOGI("创建帧数据 Packet ,body_size:%d", body_size);
    //初始化内部body数组
    RTMPPacket_Alloc(packet, body_size);

    packet-&gt;m_body[0] = 0x27;//非关键帧
    if (buf[0] == 0x65) {//关键帧
        packet-&gt;m_body[0] = 0x17;
    }
    //固定
    packet-&gt;m_body[1] = 0x01;
    packet-&gt;m_body[2] = 0x00;
    packet-&gt;m_body[3] = 0x00;
    packet-&gt;m_body[4] = 0x00;
    //帧长度，4个字节存储
    packet-&gt;m_body[5] = (len &gt;&gt; 24) &amp; 0xFF;
    packet-&gt;m_body[6] = (len &gt;&gt; 16) &amp; 0xFF;
    packet-&gt;m_body[7] = (len &gt;&gt; 8) &amp; 0xFF;
    packet-&gt;m_body[8] = (len) &amp; 0xFF;
    //copy帧数据
    memcpy(&amp;packet-&gt;m_body[9], buf, len);

    //设置视频类型
    packet-&gt;m_packetType = RTMP_PACKET_TYPE_VIDEO;
    packet-&gt;m_nBodySize = body_size;
    //通道值，音视频不能相同
    packet-&gt;m_nChannel = 0x04;
    packet-&gt;m_nTimeStamp = tms;
    packet-&gt;m_hasAbsTimestamp = 0;
    packet-&gt;m_headerType = RTMP_PACKET_SIZE_LARGE;
    packet-&gt;m_nInfoField2 = live-&gt;rtmp-&gt;m_stream_id;
    return packet;
}</code></pre>
    <p>
     发送代码，这样我们就把视频数据发送出去了
    </p>
    <pre><code>//将rtmp包发送出去
int sendPacket(RTMPPacket *packet) {
    int r = RTMP_SendPacket(live-&gt;rtmp, packet, 0);
    RTMPPacket_Free(packet);
    free(packet);
    LOGI("发送packet: %d ", r);
    return r;
}</code></pre>
    <h2>
     四.发送音频数据到服务器
    </h2>
    <p>
     音频使用AudioRecord来进行录音，同样使用MediaCodec来将pcm原始音频数据编码成AAC格式的数据推送给服务器，具体的代码前期也有写过，具体查看一下demo代码，需要注意的点是rtmp协议在发送音频数据之前要先发一个固定音频格式头：0x12, 0x08
    </p>
    <p>
     java层在编码开始前先发送音频头：
    </p>
    <pre><code>        //发送音频头
        RTMPPacket rtmpPacket = new RTMPPacket();
        byte[] audioHeadInfo = {0x12, 0x08};
        rtmpPacket.setBuffer(audioHeadInfo);
        rtmpPacket.setType(AUDIO_HEAD_TYPE);
        screenLive.addPacket(rtmpPacket);</code></pre>
    <p>
     native中根据java层传递的type进行判断，音频头的RTMPPacket数据第二个字节为为0x00,普通的音频为0x01
    </p>
    <pre><code>//创建audio包
RTMPPacket *createAudioPacket(int8_t *buf, int len, long tms, int type, Live *live) {
    int body_size = len + 2;
    RTMPPacket *packet = (RTMPPacket *) malloc(sizeof(RTMPPacket));
    RTMPPacket_Alloc(packet, body_size);
    packet-&gt;m_body[0] = 0xAF;
    if (type == 2) {//音频头
        packet-&gt;m_body[1] = 0x00;
    } else {//正常数据
        packet-&gt;m_body[1] = 0x01;
    }
    memcpy(&amp;packet-&gt;m_body[2], buf, len);
    //设置音频类型
    packet-&gt;m_packetType = RTMP_PACKET_TYPE_AUDIO;
    packet-&gt;m_nBodySize = body_size;
    //通道值，音视频不能相同
    packet-&gt;m_nChannel = 0x05;
    packet-&gt;m_nTimeStamp = tms;
    packet-&gt;m_hasAbsTimestamp = 0;
    packet-&gt;m_headerType = RTMP_PACKET_SIZE_LARGE;
    packet-&gt;m_nInfoField2 = live-&gt;rtmp-&gt;m_stream_id;
    return packet;
}</code></pre>
    <p>
     整体的调用流程我们已经写完了，具体的代码细节可以去github中看一下
    </p>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="6874747073:3a2f2f626c6f672e6373646e2e6e65742f7779677371736a2f:61727469636c652f64657461696c732f313232313435373635" class_="artid" style="display:none">
 </p>
</div>


