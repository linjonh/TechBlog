---
layout: post
title: DeepSeek本地部署详细指南
date: 2025-02-01 15:54:42 +0800
categories: ['本地部署']
tags: ['本地部署', '大模型', 'Deepseek']
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=145413005
    alt: DeepSeek本地部署详细指南
artid: 145413005
render_with_liquid: false
---
<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     DeepSeek本地部署详细指南
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h2>
     <a id="DeepSeek_0">
     </a>
     DeepSeek本地部署详细指南
    </h2>
    <p>
     随着人工智能技术的飞速发展，本地部署大模型的需求也日益增加。DeepSeek作为一款开源且性能强大的大语言模型，提供了灵活的本地部署方案，让用户能够在本地环境中高效运行模型，同时保护数据隐私。以下是详细的DeepSeek本地部署流程。
    </p>
    <h3>
     <a id="_4">
     </a>
     一、环境准备
    </h3>
    <h4>
     <a id="_6">
     </a>
     （一）硬件需求
    </h4>
    <ul>
     <li>
      <strong>
       最低配置
      </strong>
      ：CPU（支持AVX2指令集）+ 16GB内存 + 30GB存储。
     </li>
     <li>
      <strong>
       推荐配置
      </strong>
      ：NVIDIA GPU（RTX 3090或更高）+ 32GB内存 + 50GB存储。
     </li>
    </ul>
    <h4>
     <a id="_10">
     </a>
     （二）软件依赖
    </h4>
    <ul>
     <li>
      <strong>
       操作系统
      </strong>
      ：Windows、macOS或Linux。
     </li>
     <li>
      <strong>
       Docker
      </strong>
      ：如果使用Open Web UI，需要安装Docker。
     </li>
    </ul>
    <h3>
     <a id="Ollama_14">
     </a>
     二、安装Ollama
    </h3>
    <p>
     Ollama是一个开源工具，用于在本地轻松运行和部署大型语言模型。以下是安装Ollama的步骤：
    </p>
    <ol>
     <li>
      <strong>
       访问Ollama官网
      </strong>
      ：前往Ollama官网，点击“Download”按钮。
     </li>
     <li>
      <strong>
       下载安装包
      </strong>
      ：根据你的操作系统选择对应的安装包。下载完成后，直接双击安装文件并按照提示完成安装。
     </li>
     <li>
      <strong>
       验证安装
      </strong>
      ：安装完成后，在终端输入以下命令，检查Ollama版本：
      <pre><code class="prism language-bash">ollama <span class="token parameter variable">--version</span>
</code></pre>
      如果输出版本号（例如
      <code>
       ollama version is 0.5.6
      </code>
      ），则说明安装成功。
     </li>
    </ol>
    <h3>
     <a id="DeepSeek_26">
     </a>
     三、下载并部署DeepSeek模型
    </h3>
    <p>
     Ollama支持多种DeepSeek模型版本，用户可以根据硬件配置选择合适的模型。以下是部署步骤：
    </p>
    <h4>
     <a id="_30">
     </a>
     选择模型版本：
    </h4>
    <ul>
     <li>
      <strong>
       入门级
      </strong>
      ：1.5B版本，适合初步测试。
     </li>
     <li>
      <strong>
       中端
      </strong>
      ：7B或8B版本，适合大多数消费级GPU。
     </li>
     <li>
      <strong>
       高性能
      </strong>
      ：14B、32B或70B版本，适合高端GPU。
     </li>
    </ul>
    <h4>
     <a id="_35">
     </a>
     下载模型：
    </h4>
    <p>
     打开终端，输入以下命令下载并运行DeepSeek模型。例如，下载7B版本的命令为：
    </p>
    <pre><code class="prism language-bash">ollama run deepseek-r1:7b
</code></pre>
    <p>
     如果需要下载其他版本，可以参考以下命令：
    </p>
    <pre><code class="prism language-bash">ollama run deepseek-r1:8b  <span class="token comment"># 8B版本</span>
ollama run deepseek-r1:14b <span class="token comment"># 14B版本</span>
ollama run deepseek-r1:32b <span class="token comment"># 32B版本</span>
</code></pre>
    <h4>
     <a id="Ollama_47">
     </a>
     启动Ollama服务：
    </h4>
    <p>
     在终端运行以下命令启动Ollama服务：
    </p>
    <pre><code class="prism language-bash">ollama serve
</code></pre>
    <p>
     服务启动后，可以通过访问
     <a href="http://localhost:11434" rel="nofollow">
      http://localhost:11434
     </a>
     来与模型进行交互。
    </p>
    <h3>
     <a id="Open_Web_UI_54">
     </a>
     四、使用Open Web UI（可选）
    </h3>
    <p>
     为了更直观地与DeepSeek模型进行交互，可以使用Open Web UI。以下是安装和使用步骤：
    </p>
    <ol>
     <li>
      <strong>
       安装Docker
      </strong>
      ：确保你的机器上已安装Docker。
     </li>
     <li>
      <strong>
       运行Open Web UI
      </strong>
      ：
      <br/>
      在终端运行以下命令安装并启动Open Web UI：
     </li>
    </ol>
    <pre><code class="prism language-bash"><span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">-p</span> <span class="token number">3000</span>:8080 <span class="token punctuation">\</span>
  --add-host<span class="token operator">=</span>host.docker.internal:host-gateway <span class="token punctuation">\</span>
  <span class="token parameter variable">-v</span> open-webui:/app/backend/data <span class="token punctuation">\</span>
  <span class="token parameter variable">--name</span> open-webui <span class="token punctuation">\</span>
  <span class="token parameter variable">--restart</span> always <span class="token punctuation">\</span>
  ghcr.io/open-webui/open-webui:main
</code></pre>
    <p>
     安装完成后，访问
     <a href="http://localhost:3000" rel="nofollow">
      http://localhost:3000
     </a>
     ，选择deepseek-r1:latest模型即可开始使用。
    </p>
    <h3>
     <a id="_71">
     </a>
     五、性能优化与资源管理
    </h3>
    <ul>
     <li>
      <strong>
       资源分配
      </strong>
      ：根据硬件配置选择合适的模型版本。较小的模型（如1.5B到14B）在标准硬件上表现良好，而较大的模型（如32B和70B）需要更强大的GPU支持。
     </li>
     <li>
      <strong>
       内存管理
      </strong>
      ：确保系统有足够的内存和存储空间，以避免运行时出现资源不足的问题。
     </li>
    </ul>
    <h3>
     <a id="_76">
     </a>
     六、常见问题及解决方法
    </h3>
    <ul>
     <li>
      <strong>
       模型下载超时
      </strong>
      ：如果在下载模型时出现超时问题，可以尝试重新运行下载命令。
     </li>
     <li>
      <strong>
       服务启动失败
      </strong>
      ：确保Ollama服务已正确安装并启动。如果服务启动失败，可以尝试重启Ollama服务。
     </li>
    </ul>
    <h3>
     <a id="_81">
     </a>
     七、总结
    </h3>
    <p>
     通过上述步骤，你可以在本地成功部署DeepSeek模型，并通过Ollama或Open Web UI与模型进行交互。本地部署不仅能够保护数据隐私，还能根据需求灵活调整模型参数，满足不同场景下的使用需求。如果你在部署过程中遇到任何问题，可以在评论区留言，我们将一起解决。
    </p>
    <p>
     希望这篇教程能帮助你顺利部署DeepSeek模型，开启高效开发的新旅程！
    </p>
    <pre><code></code></pre>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
</div>


