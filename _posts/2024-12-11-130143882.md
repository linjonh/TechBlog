---
layout: post
title: "AIGC时代的多模态知识工程思考与展望"
date: 2024-12-11 07:00:00 +0800
description: "内容简介：ChatGPT的火爆出圈使得AI生成（AIGC）技术受到了全社会前所未有的广泛关注。此消彼"
keywords: "AIGC时代的多模态知识工程思考与展望"
categories: ["未分类"]
tags: ["人工智能", "Aigc"]
artid: "130143882"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=130143882
  alt: "AIGC时代的多模态知识工程思考与展望"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     AIGC时代的多模态知识工程思考与展望
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <div id="js_content">
     <h4>
     </h4>
     <p>
      <strong>
       内容简介：
      </strong>
      ChatGPT的火爆出圈使得AI生成（AIGC）技术受到了全社会前所未有的广泛关注。此消彼长之下，传统的知识工程遭受了诸多质疑。在多模态智能领域，AIGC的能力不断提升，多模态知识工程工作应该何去何从？是否仍有价值？在本次分享中，讲者将探讨当前AIGC技术耀眼“光芒”背后的“暗面”，思考与展望AIGC时代的多模态知识工程研究。
     </p>
     <p>
      来自：知识工场
     </p>
     <p>
      <strong>
       <strong>
        <strong>
         <strong>
          <strong>
           进NLP群—&gt;
          </strong>
          <strong>
           <a href="" rel="nofollow">
            加入NLP交流群
           </a>
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </p>
     <h4>
      <img alt="1e8a4c6b94685816d8b6f12a8b117f76.jpeg" src="https://i-blog.csdnimg.cn/blog_migrate/401dfc5ea08de86c5c5249c01eadd57e.jpeg">
       <br/>
      </img>
     </h4>
     <p>
      关于AIGC时代的多模态知识工程思考与展望，我们将从以下六个方面展开介绍：
     </p>
     <p>
      第一部分，我们回顾一下AIGC技术的发展历程和它带来的划时代影响力；
     </p>
     <p>
      第二部分，我们对AIGC技术的不足（阿克琉斯之踵）之处进行分析与总结；
     </p>
     <p>
      第三部分，我们将介绍多模态认知智能的框架和两种实现路径，并进行对比分析；
     </p>
     第四~六部分，我们会展望当前AIGC大模型和MMKG多模态图谱间如何竞与合。
     <p>
      <strong>
       01
      </strong>
     </p>
     <p>
      <strong>
       AIGC时代：未来已来
      </strong>
     </p>
     <p style="text-align:center;">
      <img alt="42df06e7af3c982049c8543e71efdabb.png" src="https://i-blog.csdnimg.cn/blog_migrate/d872bd54e9b382a9fc9063b22ee01eb6.png">
       <br/>
      </img>
     </p>
     <p>
      随着人工智能总体阶段的发展，生成式人工智能技术（AIGC）也在不断迭代。从20世纪50年代到90年代中期，是AIGC的早期萌芽阶段，这一时期受限于技术水平，AIGC仅限于小范围实验。这一时期的AIGC典型事件包括：1950年，艾伦·图灵提出的著名的“图灵测试”，给出判断机器是否具有“智能”的方法；1966年，世界上第一款可人机对话机器人“Eliza”的问世；以及在80年代中期IBM公司创造的语音控制打字机“Tangora”的出现。
     </p>
     <p>
      而从20世纪90年代到21世纪10年代中期，AIGC处于沉淀积累阶段，这一阶段的AIGC技术从实验性向实用性转变，但仍因受限于算法瓶颈，无法直接进行内容生成。这一阶段的AIGC典型事件则包括2007年世界上第一部完全由人工智能创作的小说《1 the road》的问世；以及2012年微软开发的全自动同声传译系统的出现，它能够将英文语音自动翻译成中文语音。
     </p>
     <p>
      自21世纪10年代中期至今，是AIGC快速发展的阶段，得益于深度学习算法不断迭代，人工智能生成内容百花齐放。2014年，Goodfellow提出的生成对抗网络GAN用于生成图像；2019年，英伟达发布StyleGAN模型可以自动生成高质量图片；2019年DeepMind发布DVD-GAN用于生成连续性视频，直到2022年，OpenAI发布ChatGPT模型生成流畅的自然语言文本。
     </p>
     <p>
      可以说，ChatGPT的爆红出圈宣告了AIGC时代的到来。
     </p>
     <p>
      <img alt="4d67478e14d79501e5fe082a858ac616.png" src="https://i-blog.csdnimg.cn/blog_migrate/e64a6f82d5d01f16c5d0353b33e5094b.png">
       <br/>
      </img>
     </p>
     <p>
      现在的AIGC技术可以生成的内容包括文本、图像、音频和视频等。如今，已经有很多强大的算法被发明出来，如用于图像生成的Stable Diffusion算法。此外，还有很多走在技术前沿的创业公司不断推动AIGC技术的应用落地，如Jasper AI的AI写作软件和midjourney的AI绘画工具的发明都在解放着人类的内容创作生产力。这些共同促进了一个万物皆可AI生成的AIGC时代。
     </p>
     <p>
      右图是一张来自互联网的趣味图片——机器人一家三口在人类博物馆中观赏人类的最后一篇推文“GPT-5也没啥了不起的”——表达了创作者对当今AIGC技术飞速发展的隐隐担忧。
     </p>
     <p>
      <img alt="cd433c043b4a98945acc45fd570b17f9.png" src="https://i-blog.csdnimg.cn/blog_migrate/f53c460ca0ca83f31038e116b4f171a0.png">
       <br/>
      </img>
     </p>
     <p>
      那么，我们首先看一下多模态大模型的分类与发展脉络。如上图所示，多模态大模型发展非常迅速，我们可以将多模态大模型简单分为多模态统一大模型和多模态文图生成大模型，前者用于统一的多模态生成和理解，后者特指具备强大的多模态文到图生成能力的大模型。
     </p>
     <p>
      <img alt="479b50c768a8c2c8bac841e9ba17bfff.png" src="https://i-blog.csdnimg.cn/blog_migrate/e4bed3001bde17dd267e157036df71bd.png"/>
     </p>
     <p>
      当前，文图生成大模型已经可以生成逼真、高清以及风格化的意境图像。
     </p>
     <p>
      <img alt="2cf1fa4de58f1fe56aca6f08fcd9e6d5.png" src="https://i-blog.csdnimg.cn/blog_migrate/f44a984ce23b1c8a0e8af978b543fcf3.png"/>
     </p>
     <p>
      还有一些文图生成大模型，如斯坦福大学提出的ControlNet，其生成能力更加精致、可控。它不仅可以生成各类质地细腻、细节精致的图片，也可以通过简笔画来对图像生成进行操控。
     </p>
     <p>
      <img alt="42db1dba3100ce5b47c52dbedd869fdb.png" src="https://i-blog.csdnimg.cn/blog_migrate/ae4c85798208b049c89550a19e347774.png"/>
     </p>
     <p>
      AIGC大模型生成的视频在某种程度上也可谓自然流畅、栩栩如生。
     </p>
     <p>
      <img alt="71e72449e0bd88130e0fc5aac72e616e.png" src="https://i-blog.csdnimg.cn/blog_migrate/f17c018c4aa8d1b5432023eb58c35fab.png"/>
     </p>
     <p>
      我们还看到Google发布的PaLM-E模型，展现了多模态AIGC大模型驱动的具身智能的情景。这个具备5620亿参数的具身多模态大模型，可以将真实世界的传感器信号与文本输入相结合，建立语言和感知的链接，可以用自然语言操控机器人完成操作规划、视觉问答等任务。
     </p>
     <p>
      <img alt="49010efe8f5293aaafa80c145825090c.png" src="https://i-blog.csdnimg.cn/blog_migrate/3e935f4addfa7da2bd8b005935318ebf.png"/>
      <br/>
     </p>
     <p>
      AIGC的惊艳效果不禁让很多人对符号主义（知识工程）的研究产生了疑问。Rich Sutton在著名文章《苦涩的教训》中提出，唯一导致AI进步的因素是更多的数据和更有效的计算。而DeepMind的研究主任Nando de Freitas也宣称，“AI现在完全取决于规模，AI领域更难的挑战已经解决了，游戏结束了！”。我们也看到，在大多数领域，大模型已经（暂时）战胜了精心设计的知识工程。然而，AI的流派之争真的结束了吗？
     </p>
     <p>
      <strong>
       02
      </strong>
     </p>
     <p>
      <strong>
       AIGC的阿克
      </strong>
      <strong>
       琉斯之踵
      </strong>
     </p>
     <p>
      第二部分，让我们来看一下当前AIGC大模型实际存在的一些问题。
      <br/>
     </p>
     <p>
      <img alt="e2002fb95e32f789a1a2eec8e94916ca.png" src="https://i-blog.csdnimg.cn/blog_migrate/731c4bb55d596d914159d3874a8efc78.png"/>
     </p>
     <p>
      尽管今天的ChatGPT（包括GPT-4）很强大，它的诸多问题仍旧难以忽视：
     </p>
     <p>
      第一、强语言弱知识的问题，ChatGPT无法理解用户查询中的知识性错误，它具备强大的语言能力，但知识能力仍旧较弱；
     </p>
     <p>
      第二、实时信息自更新慢，新旧知识难以区分，目前ChatGPT的知识还停留在2021年，而每一次信息更新都需要成本高昂的重新训练；
     </p>
     <p>
      第三、其逻辑推理能力并不可靠，应该说尚不具备复杂数学逻辑推理与专业逻辑推理能力；
     </p>
     <p>
      第四、由于缺乏领域知识，它也无法真正为领域类问题提供专业靠谱的答案。
     </p>
     <p>
      <img alt="132e4d9c5170c8137837f8551efdf74c.png" src="https://i-blog.csdnimg.cn/blog_migrate/63e17def46fe7c2ddaffc78bf2a92bf4.png"/>
      <br/>
     </p>
     <p>
      当前的多模态大模型的跨模态生成能力也尚不完善。上图是我们用文图生成大模型Stable Diffusion生成的一些案例。具体来说，当前的文图生成存在组合泛化、属性泄露、方位理解混乱、语义理解错误等问题。因此，尽管我们看到AIGC跨模态生成的视觉效果惊艳，但往往存在较大的模态间信息不对称问题。
     </p>
     <p>
      <img alt="36e717fb2e6527fb09fc14ea03cd082f.png" src="https://i-blog.csdnimg.cn/blog_migrate/8fe5a759a15644967a589e624af231cb.png"/>
     </p>
     <p>
      此外，当前多模态大模型的多模态理解能力也存在问题。上图是来自BLIP2进行视觉问答任务的错误样例。我们看到：
     </p>
     <p>
      1）模型由于缺乏事实知识，无法知晓球拍上的“w”图案是品牌“Wilson”的logo，因而错误回答成“nike”；
     </p>
     <p>
      2）模型由于欠缺逻辑推理能力，不理解图像场景和问题的逻辑关系，因而回答错误；
     </p>
     <p>
      3）模型由于常识储备不足，对某个具体场景（冲浪）下的意图理解犯了常识性错误。
     </p>
     <p>
      <img alt="cbe7d14237aa89836bb8885e9508a7cf.png" src="https://i-blog.csdnimg.cn/blog_migrate/15adc584eef426035c8301c8ccf683f5.png"/>
      <br/>
     </p>
     <p>
      让我们再来看一下Google的具身多模态大模型PaLM-E，虽然依赖如此大规模的参数实现了初步的机器人操控，但其demo视频中所展示的空间范围、物品种类、规划和操作任务的复杂度等都非常有限。我们可以想象，如果要在真实世界的复杂场景中达到实用级别，PaLM-E的参数规模是否还需要增大百倍、千倍甚至万倍？如果一味用海量参数存储所有知识，那么智慧涌现的代价是否过于昂贵？
     </p>
     <p>
      <img alt="9793f6152186f6dc05fd181bf0ac45d8.png" src="https://i-blog.csdnimg.cn/blog_migrate/2d3555a825129d318f40087d81f73f99.png"/>
      <br/>
     </p>
     <p>
      至此，我们对多模态大模型做个简单的小结。首先，多模态大模型的本质是“用语言解释视觉，用视觉完善语言”。换句话说，我们要将文本中的语言符号知识，与视觉中的可视化信息建立统计关联。所谓“用语言解释视觉”，就是将语言中蕴含的符号知识体系和逻辑推理能力延伸至对视觉内容的理解；而所谓“用视觉完善语言”，是指丰富的视觉信息可以成为符号知识体系和逻辑推理能力的重要完善和补充。
     </p>
     <p>
      我们知道，多模态大模型能发挥重大作用的
      <strong>
       重要前提
      </strong>
      是：
     </p>
     <p>
      1）具有海量高质量图文配对数据；
     </p>
     <p>
      2）文字富含事实知识和常识；
     </p>
     <p>
      3）其逻辑推理过程可显式化被学习。
     </p>
     <p>
      而我们所面临的
      <strong>
       现实情况
      </strong>
      却是：
     </p>
     <p>
      1）数据量大但质量差，信息不对称；
     </p>
     <p>
      2）纯文字中的知识与常识也不完备；
     </p>
     <p>
      3）其逻辑推理是隐性难以学习的。
     </p>
     <p>
      正因为这些理想与现实间的差距，导致了前面提到的多模态大模型的种种问题与不足。综上，我们认为，统计大模型始终难以较低成本，全面、准确地掌握人类知识、常识和逻辑推理能力。
     </p>
     <p>
      <strong>
       03
      </strong>
     </p>
     <p>
      <strong>
       多模态认知智能
      </strong>
     </p>
     <p>
      第三部分，我们引出多模态认知智能，其研究旨在解决前一部分提到的问题。
     </p>
     <p>
      <img alt="f5c32c47e0d5275013ff363a01774ebd.png" src="https://i-blog.csdnimg.cn/blog_migrate/9cc5fc80104fdecad4d054bef1f5deda.png"/>
     </p>
     <p>
      上图是我们提出的一个多模态认知智能的研究框架。总的来说，多模态认知智能主要研究基于多模态数据的知识获取、表示、推理与应用。在多模态知识获取层面，我们从语料中通过抽取、生成、群智等方法获取知识或者从语言模型中萃取知识。在多模态知识表示层面，可以使用多模态图谱、常识图谱、语言模型、大规模知识网络等方法进行知识表示。基于多模态知识表示，可以进一步支撑多模态理解、推理和元认知等能力，从而赋能诸如跨模态搜索、推荐、问答、生成等多模态知识的应用。
     </p>
     <p>
      <img alt="f06329615539c9bd2aac267c86d02242.png" src="https://i-blog.csdnimg.cn/blog_migrate/e92a84b784ec2aada20ffe27a26e2ee0.png"/>
      <br/>
     </p>
     <p>
      多模态认知智能目前有两种实现路径。一种是
      <strong>
       多
      </strong>
      <strong>
       模态大模型
      </strong>
      ，其代表了联结主义和经验主义的思想，从海量预训练数据中学习概率关联，是简单而鲁棒的，它属于统计学习范畴，具备端到端、干预少和“数”尽其用的优势，其劣势在于难以学习到从因到果、从主到次、从整体到部分、从概括到具体、从现象到本质、从具体到一般等逻辑关系。
     </p>
     <p>
      另一种实现路径是
      <strong>
       多模态知识工程
      </strong>
      ，其代表了符号主义的思想，从精选数据和专家知识中学习符号关联，是精细而脆弱的，它往往通过专家系统和知识图谱实现，具备易推理、可控、可干预、可解释的优点，但是它的劣势主要在于将数据转换成符号知识的过程往往伴随着巨大的信息损失，而其中隐性知识等难以表达的知识往往是信息损失的主体。
     </p>
     <p>
      结合多模态大模型和多模态知识工程的优劣势分析，我们认为：在AIGC大模型时代，多模态知识工程依然不可或缺。
     </p>
     <p>
      <img alt="42b72a26b71ce4ded2a8e027023d14f1.png" src="https://i-blog.csdnimg.cn/blog_migrate/35cfc0c273a3a20283149296b1d5c23b.png"/>
      <br/>
     </p>
     <p>
      当前，多模态知识工程的主要形式之一是
      <strong>
       多模态知识图谱（MMKG）
      </strong>
      。多模态知识图谱是在传统知识图谱的基础上，增加多种模态数据以丰富符号知识表达的方法，其多模态数据包括但不限于图像、视频、语言、代码等。多模态知识图谱可以将符号接地到具象的视觉等模态对象上，实现跨模态语义对齐。
     </p>
     <p>
      <img alt="9f4e4b3c415897091724d90ded581dc8.png" src="https://i-blog.csdnimg.cn/blog_migrate/b329ac4bcb9a8a054b6d40e4fa084230.png"/>
     </p>
     <p>
      目前多模知识图谱的主流形式有两种。
     </p>
     <p>
      一种是
      <strong>
       A-MMKG
      </strong>
      ，其中多模态数据仅作为文字符号实体的关联属性存在；
     </p>
     <p>
      另一种是
      <strong>
       N-MMKG
      </strong>
      ，其中多模态数据也可作为图谱中的实体存在，可与现有实体发生广泛关联。
     </p>
     <p>
      <img alt="ff789a6562e86510ef175fbab722e814.png" src="https://i-blog.csdnimg.cn/blog_migrate/ca1f765ae5e056cadc53b0947f05e9a6.png"/>
     </p>
     <p>
      至此，我们进一步分析AIGC多模态大模型和大规模多模态知识图谱各自的优缺点。
     </p>
     <p>
      <strong>
       多模态大模型的优点是：
      </strong>
     </p>
     <p>
      1）关联推理能力强：可以学习掌握大量跨模态知识模式，隐空间的关联推理能力强，具有很强的泛化能力；
     </p>
     <p>
      2）多任务通吃：一套大模型处理各类跨模态任务；
     </p>
     <p>
      3）人工成本低：不依赖人工schema设计与数据标注；
     </p>
     <p>
      4）适配能力强：可通过调优训练或prompt对话等方式来适配新的领域和任务。
     </p>
     <p>
      <strong>
       而其不足之处在于：
      </strong>
     </p>
     <p>
      1）可靠程度低：所生成的内容可靠性堪忧，存在误差累积、隐私泄露等问题，无法胜任高精度严肃场景需求；
     </p>
     <p>
      2）知识推理弱：没有真正掌握数据背后的知识，缺乏知识推理能力，更无因果推理能力；
     </p>
     <p>
      3）可解释性弱：虽有CoT加持，但可解释性仍然不足；
     </p>
     <p>
      4）训练成本高：需要消耗大量计算资源和时间来进行训练，需要强大的计算设备和高效的算法。
     </p>
     <p>
      <strong>
       而与之对应的，
      </strong>
      <strong>
       多模态知识图谱的优点是：
      </strong>
     </p>
     <p>
      1）专业可信度高：其结构和关系清晰，易于理解和解释，可为人类决策提供参考，通常为某个具体应用场景构建，可提供更精准和针对性的知识支持；
     </p>
     <p>
      2）可解释性好：以结构化形式表示知识 ，知识的可访问性、可重用性、可解释性好，对人类友好；
     </p>
     <p>
      3）可扩展性强：知识图谱的内容可以随着应用场景的需要进行不断扩展和更新，可以不断完善和改进。
     </p>
     <p>
      <strong>
       而多模态知识图谱的缺点在于：
      </strong>
     </p>
     <p>
      1）推理能力弱：只能表示已有的知识和关系，对于未知或不确定的领域难以进行有效的知识建模和推理；
     </p>
     <p>
      2）人工成本高：其构建需要依赖于人工或半自动的方式进行知识抽取和建模，难以实现完全自动化；
     </p>
     <p>
      3）架构调整难：其基本schema架构通常是静态的，不易根据新的数据或场景进行修改和调整。
     </p>
     <p>
      由上分析可见：多模态大模型的优点常常是多模态知识图谱的不足，而多模态大模型的不足又往往是多模态知识图谱的优势。因此，我们认为：当前阶段，大模型与知识图谱仍应继续保持竞合关系，互相帮助，互为补充。
     </p>
     <p>
      <strong>
       04
      </strong>
     </p>
     <p>
      <strong>
       AIGC for MMKG
      </strong>
     </p>
     <p>
      第四部分，我们思考与展望一下AIGC大模型如何辅助MMKG的构建与应用。
     </p>
     <p>
      <img alt="f30e6fa67671c2d9e1dc0399d37c8aa2.png" src="https://i-blog.csdnimg.cn/blog_migrate/f0924a6cc80938f5919292ee0c90a124.png"/>
     </p>
     <p>
      <strong>
       第一，AIGC大模型为知识获取降本增效。
      </strong>
     </p>
     <p>
      （1）通过知识诱导（萃取），可以快速获取大量知识或常识。例如，我们可以从语言大模型中诱导语言知识和关系知识；我们也可以从多模态大模型中诱导跨模态对齐知识和视觉常识知识。
      <br/>
     </p>
     <p>
      <img alt="5d18098ea36a5f32f5d7372b1974e839.png" src="https://i-blog.csdnimg.cn/blog_migrate/2ebbf7f62b0a978868815f45300da638.png"/>
     </p>
     <p>
      （2）AIGC大模型的出现使得零样本、少样本、开放知识抽取成为可能。例如，我们可以利用ChatGPT对话大模型的理解和生成能力，从给定文本中抽取三元组知识；我们也可以利用多模态AIGC大模型的跨模态生成和理解能力，从给定图文数据中抽取多模态知识。
     </p>
     <p>
      <img alt="04d93c48166419fb44e73be7b8aa49c4.png" src="https://i-blog.csdnimg.cn/blog_migrate/88664f26f1ef0217a4fa1e6f7f5ba9f0.png"/>
     </p>
     <p>
      （3）AIGC大模型可以显著增强垂域多模态知识获取能力。GPT-4、ChatPDF模型等已经显示了强大的领域知识抽取能力，如基于多模态文档的知识抽取。
     </p>
     <p>
      <img alt="15b24fbf53874921a8ca64414e57d59b.png" src="https://i-blog.csdnimg.cn/blog_migrate/ed833fc4feedda6502fab03c5e2f02d7.png"/>
     </p>
     <p>
      <strong>
       第二，AIGC大模型助图谱设计一臂之力。
      </strong>
     </p>
     <p>
      大模型在部分领域上拥有领域常识知识，可以辅助完成schema的半自动化设计。在多模态场景中，也有一些尝试，例如可以用多模态AIGC大模型生成cms领域的schema。
      <br/>
     </p>
     <p>
      <img alt="c4e2e9a145683184421b18ae364635b2.png" src="https://i-blog.csdnimg.cn/blog_migrate/f1aab3844871b8e56595f7d1e679500c.png"/>
     </p>
     <p>
      <strong>
       第三，AIGC大模型为知识推理保驾护航。
      </strong>
     </p>
     <p>
      基于大模型的跨模态生成与推理能力，可以辅助完成KG表示学习、图谱补全等任务。
     </p>
     <p>
      <img alt="9917e2438af094b3cdfb5fc571b7713f.png" src="https://i-blog.csdnimg.cn/blog_migrate/6fdcd9dc86e5a7e28c486d597a439eb6.png"/>
     </p>
     <p>
      <strong>
       第四，AIGC大模型为知识融合扫清障碍。
      </strong>
     </p>
     <p>
      利用大模型的泛化能力和海量知识，可以辅助完成多模态知识图谱融合。利于对于两个MMKG的对齐，多模态AIGC大模型在两者之间可以生成实体知识或语义层面的特征，辅助完成实体对齐。
     </p>
     <p>
      <img alt="78ae4890f197e1e6b189ab729c3a6954.png" src="https://i-blog.csdnimg.cn/blog_migrate/55df884d06859fa0426e4fb157eae799.png"/>
     </p>
     <p>
      <strong>
       第五，AIGC大模型为
      </strong>
      <strong>
       知识更新舔砖加瓦。
      </strong>
     </p>
     <p>
      基于大模型的常识知识和通用抽取能力可以辅助MMKG进行知识更新。可以利用多模态AIGC大模型从新事实中辅助抽取新知识；当新知识抽取完成后，可以借助多模态AIGC大模型辅助更新多模态知识图谱。此外，还可以借助多模态AIGC大模型辅助过期事实检测，从而将过期知识从知识图谱中删除。
     </p>
     <p>
      <img alt="612ccbae26fdd10f30a6d29f7d4aa4e6.png" src="https://i-blog.csdnimg.cn/blog_migrate/24cea02e956ce718d636e17ef2099e10.png"/>
     </p>
     <p>
      <strong>
       第六，AIGC大模型为知识问答锦上添花。
      </strong>
     </p>
     <p>
      利用大模型的语言理解能力和解析能力，可以帮助更好的构建多模态知识问答系统。在ChatGPT的知识问答评测结果显示其在很多问题类型上效果显著，且跨语言低资源情况下具有碾压级效果，但是其数值类问题效果不及SOTA。因此，使用AIGC大模型助力MM-KGQA和K-VQA等任务，可以提升问题解析能力，强化知识推理能力，提供外部知识辅助等。
     </p>
     <p>
      <strong>
       05
      </strong>
     </p>
     <p>
      <strong>
       MMKG for AIGC
      </strong>
     </p>
     <p>
      第五部分，我们总结与展望一下MMKG如何助力AIGC大模型的提升与完善。
      <br/>
     </p>
     <p>
      <img alt="5c8d4a0abeba0072d760ba68d17a9088.png" src="https://i-blog.csdnimg.cn/blog_migrate/dd816c796fc84addda8f2cf48e9da202.png"/>
     </p>
     <p>
      <strong>
       第一，MMKG参与AIGC大模型的生成能力评估
      </strong>
      <strong>
       。
      </strong>
     </p>
     <p>
      基于多模态知识图谱中的知识构建测试集，可对大模型的生成能力进行各方面评估。例如利用各类百科知识图谱进行事实性检验评估，也可以利用各类MMKG构建测试集进行符号推理能力评估、视觉常识推理能力评估、非语言推理能力评估等。
     </p>
     <p>
      <img alt="69082a15fedb0776b405d8071defcaa8.png" src="https://i-blog.csdnimg.cn/blog_migrate/258f5af06ba41c37cd9ebac17c2f066d.png"/>
     </p>
     <p>
      <strong>
       第二，MMKG引导AIGC大模型的可控约束生成。
      </strong>
     </p>
     <p>
      已有工作在文本AIGC模型中引入指定约束（如包含/避免某主题）进行可控生成。可以展望未来会出现多模态知识引导大模型约束生成的工作。比如对于图像生成，可通过将文本链接到多模态知识图谱的具体实体，提供实体图像信息，帮助正确生成实体对应图像；对于文本生成，通过链接到多模态知识图谱的具体实体，提供实体关系属性和实体图像等实体画像信息，帮助正确生成符合实体性质和特点的文本。
     </p>
     <p>
      <img alt="19849873309866b94d13720d1882b9a0.png" src="https://i-blog.csdnimg.cn/blog_migrate/a38982a3ebb2eda8a49abdb0da67c275.png"/>
     </p>
     <p>
      <strong>
       第三，MMKG帮助AIGC大模型进行知识编辑。
      </strong>
     </p>
     <p>
      目前已有在文本大模型上的知识编辑的相关工作。可以预见，未来也会出现利用多模态知识图谱来对多模态大模型进行知识编辑的研究工作。
     </p>
     <p>
      <img alt="d49dc279608d18050339663536ae2601.png" src="https://i-blog.csdnimg.cn/blog_migrate/ec8fa7c0bb9aa6c0c770df52a6d4d324.png"/>
     </p>
     <p>
      <strong>
       第四，MMKG辅助AIGC大模型的领域（任务）适配。
      </strong>
     </p>
     <p>
      用多模态知识图谱做领域知识微调可以将大模型的能力适配到领域任务。例如，在电商领域跨模态检索场景，常常存在语义不匹配的问题。这种情况下，大模型如何低成本、高效率地解决该领域的具体问题是其应用落地的关键。我们与阿里合作的这篇工作提出了通过微调大模型，加上多模态知识辅助的方式，实现了大模型的轻量级领域适配。
     </p>
     <p>
      <strong>
       06
      </strong>
     </p>
     <p>
      <strong>
       AIGC+MMKG
      </strong>
     </p>
     <p>
      第六部分，我们展望一下AIGC大模型和MMKG如何进一步合作。
     </p>
     <p>
      <img alt="e2d5a3fd855b4728f2f78facaf7a5ff5.png" src="https://i-blog.csdnimg.cn/blog_migrate/725c7189c7ce0f81717a3ca22875e41a.png"/>
     </p>
     <p>
      我们认为，走向通用人工智能需要AIGC大模型和MMKG携手并进。在未来，基于知识工程和统计模型的语言认知和多模态感知将会相互结合，并且借助MMKG和AIGC大模型，共同走向多模态认知的发展道路上。从视觉感知和语言认知到多模态认知，从连接主义和符号主义到神经符号主义，通用人工智能必将是一条融合之路。
     </p>
     <p>
      <img alt="d39eb8a568b2bacecbc15d8281b59451.png" src="https://i-blog.csdnimg.cn/blog_migrate/5b4d9b7a7e49e3b1462a8605e04b2d90.png"/>
     </p>
     <p>
      <strong>
       AIGC和MMKG的第一种融合方式是注入知识以增强预训练大模型
      </strong>
      <strong>
       。
      </strong>
      目前知识增强的预训练语言模型已有多种路径实现。在多模态知识增强预训练的方向上，也有工作将场景图知识融入视觉语言预训练模型的预训练过程中以增强跨模态语言理解能力。未来还有很多方式方法来将MMKG中的知识以更多方式融入到大模型当中。
     </p>
     <p>
      <img alt="387e0da15fd42c94ddd17e0e901f1bc0.png" src="https://i-blog.csdnimg.cn/blog_migrate/37cebc4c88546a704caaeb0736549837.png"/>
     </p>
     <p>
      <strong>
       AIGC和MMKG的第二种融合方式是基于知识检索增强的多模态生成
      </strong>
      <strong>
       。
      </strong>
      例如，给定文本提示，访问外部多模态知识库以检索相关图文对，将其用作生成图像的参考。
     </p>
     <p>
      <img alt="e39ec664873dc542ba8b2316a63ce902.png" src="https://i-blog.csdnimg.cn/blog_migrate/08a42b19492d15e5ae38f4133d7e9619.png"/>
     </p>
     <p>
      <strong>
       AIGC和MMKG的第三种融合方式是因果知识增强的多模态生成
      </strong>
      <strong>
       。
      </strong>
      已有工作利用因果图谱中的因果关系和图推理能力，辅助大模型的因果决策，通过在因果图谱上的检索、推理和融合将因果信息融入大模型推理中。可以展望，未来因果知识也可被用在对多模态大模型的理解与生成能力优化上。
     </p>
     <p>
      <img alt="8833bcbd74057d40325bd7376d871998.png" src="https://i-blog.csdnimg.cn/blog_migrate/fc97ac9dd88baba81e5893a93fe93624.png"/>
     </p>
     <p>
      <strong>
       AIGC和MMKG的第四种融合方式是个性化知识接入的多模态生成
      </strong>
      <strong>
       。
      </strong>
      在未来，或许每个个体或企业都会拥有AI私有化助手，那么如何管理个性化多模态知识，诸如个人画像知识图谱、企业画像知识图谱、价值观知识图谱、自媒体知识图谱等，将这些知识以一种可插拔式的方式接入AIGC大模型中，提高大模型的个性化生成能力将是非常值得探索的方向。
     </p>
     <p>
      <img alt="6dda3ffc881fbc9eb23173729cb99f66.png" src="https://i-blog.csdnimg.cn/blog_migrate/dae10a0823b1500079d422571b4423d5.png"/>
     </p>
     <p>
      实际上，Microsoft 365 Copilot就可以看作是知识库与大模型良好协作的一款划时代产品。借助Microsoft Graph（可以看做是一种知识库）与AIGC大模型的协作融合，助力Word、PowerPoint、Excel的生产力大提升。
     </p>
     <p>
      <img alt="dedbd45f0083ddcf8df769d0c2e6cb1f.png" src="https://i-blog.csdnimg.cn/blog_migrate/2546e84bf3f041a9211e29f1ef64d879.png"/>
     </p>
     <p>
      <strong>
       此外，在行业落地层面，AIGC大模型和MMKG的融合更具价值
      </strong>
      <strong>
       。
      </strong>
      由于利用海量通用语料和通用知识训练的通用大模型与行业应用场景之间依然存在鸿沟，因此需要进行行业数据挖掘和行业特色知识获取来进一步训练更加实用的行业大模型。
     </p>
     <p>
      <img alt="c3e3a0930f6bfb69d6fa41c47e1eb4ff.png" src="https://i-blog.csdnimg.cn/blog_migrate/7b1b524407eda0f7e729a3b67a365e58.png"/>
     </p>
     <p>
      基于上述原因，行业落地往往需要多层次的模型，并有效与知识库和外部工具进行配合，才能真正解决好行业问题。通用多模态预训练生成大模型、行业领域预训练模型、任务小模型以及行业知识库、外部工具将构成一个模型共同体，协作解决行业复杂问题。
     </p>
     <p>
      <strong>
       07
      </strong>
     </p>
     <p>
      <strong>
       总  结
      </strong>
     </p>
     <p>
      <img alt="f40e181e08b235049fb2b2949b1ccd97.png" src="https://i-blog.csdnimg.cn/blog_migrate/c49d485deda771dce44064dd12732797.png"/>
     </p>
     <p>
      最后总结一下本次分享的主要观点。首先，AIGC技术的发展必将加速迈向通用人工智能的步伐。但是仅凭AIGC技术无法真正实现通用人工智能。在多模态领域，MMKG的构建与应用仍具重要价值。我们认为，AIGC和MMKG应该相互借力，我们分别从AIGC用于MMKG、MMKG用于AIGC、MMKG和AIGC如何融合三方面给出了二者竞合方式的探索和展望。未来，符号知识和统计模型的竞合方式有待进一步深入探索。
     </p>
     <p>
      （在此感谢辅助完成分享PPT材料的课题组同学们，包括陈石松、朱祥茹、王续武、查志伟、王小丹、赵一聪、邹健。演讲稿的文字记录与整理由查志伟同学完成。）
     </p>
     <p>
      <strong>
       分享人简介
      </strong>
      <br/>
     </p>
     <p>
      <img alt="344718029c87e240df8d41df44eaee1b.png" src="https://i-blog.csdnimg.cn/blog_migrate/4df745d02e5ade2d83dc0ec1085a6efa.png"/>
     </p>
     <p>
      李直旭，复旦大学研究员、博士生导师，上海市数据科学重点实验室主任助理，复旦大学知识工场实验室执行副主任，曾兼任科大讯飞苏州研究院副院长，博士毕业于澳大利亚昆士兰大学。主要研究方向为认知智能与知识工程、多模态知识图谱、大数据分析与挖掘等。在领域主流期刊和国际会议上发表论文150余篇，主持十余项国家和省部级科研项目。
     </p>
     <p>
      <img alt="c5024f62730b8ad25e63523688b3cd0b.gif" src="https://i-blog.csdnimg.cn/blog_migrate/0f4ee7c2e70ca2e56d5b1a627c29a7a3.gif"/>
     </p>
     <hr/>
     <p>
      <strong>
       <strong>
        <strong>
        </strong>
        <strong>
         <strong>
          <strong>
           进NLP群—&gt;
          </strong>
          <strong>
           <a href="" rel="nofollow">
            加入NLP交流群
           </a>
           (备注nips/emnlp/nlpcc进入对应投稿群)
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </p>
     <p>
      加入星球，你将获得：
     </p>
     <p>
      1.
      <strong>
       每日更新
      </strong>
      <strong>
       3-5篇
      </strong>
      <strong>
       论文速读
      </strong>
     </p>
     <p>
      2.
      <strong>
       最新入门和进阶学习资料
      </strong>
     </p>
     <p>
      3.
      <strong>
       每日
      </strong>
      <strong>
       1-3个
      </strong>
      <strong>
       AI岗位招聘信息
      </strong>
     </p>
     <p>
      <img alt="6b62adbd796004565130ac15931eff54.png" src="https://i-blog.csdnimg.cn/blog_migrate/3ccac5b1dd14151d6b05cfd07a261eb1.png"/>
     </p>
    </div>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f32373539303237372f:61727469636c652f64657461696c732f313330313433383832" class_="artid" style="display:none">
 </p>
</div>
