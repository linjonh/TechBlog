---
layout: post
title: "一文彻底搞懂多模态-多模态学习"
date: 2025-01-10 14:00:33 +0800
description: "跨模态对齐直接建立不同模态之间的对应关系，包括无监督对齐和监督对齐。注意力对齐。_多模态学习"
keywords: "多模态学习"
categories: ['']
tags: ['深度学习', '学习', '大数据', '人工智能', 'Caffe', 'Ai']
artid: "142531751"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=142531751
    alt: "一文彻底搞懂多模态-多模态学习"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     一文彻底搞懂多模态 - 多模态学习
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/bbf3453dfc913c7c9d9ca3c80584c814.jpeg"/>
    </p>
    <p>
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          MultiModal
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
    </p>
    <p>
     <strong>
      多模态学习（Multimodal Learning）是一种利用来自不同感官或交互方式的数据进行学习的方法，这些数据模态可能包括文本、图像、音频、视频等。
      <strong>
       多模态学习
      </strong>
      通过融合
      <strong>
       <strong>
        多种数据模态来训练模型
       </strong>
      </strong>
      ，从而提高模型的感知与理解能力，实现跨模态的信息交互与融合。
     </strong>
    </p>
    <p>
     <strong>
      接下来
     </strong>
     分三部分：
     <strong>
      <em>
       <strong>
        模态表示
       </strong>
       、多模态融合
      </em>
      __
     </strong>
     <em>
      、跨模态对齐，
     </em>
     <strong>
      一起来总结下多模型的核心：多模态学习
     </strong>
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/f98cb40bafa7c7093c1077f055a8f70f.png"/>
    </p>
    <p>
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          <strong>
           MultiModal
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
    </p>
    <p>
     <strong>
      一、模态表示
     </strong>
    </p>
    <p>
     <strong>
      <strong>
       什么是
       <strong>
        模态表示
       </strong>
       （Modal
       <strong>
        Representation
       </strong>
       ）？
       <strong>
        <strong>
         <strong>
          模态表示是将不同感官或交互方式的数据（如文本、图像、声音等）转换为
         </strong>
        </strong>
        计算机可理解和处理的形式
       </strong>
      </strong>
      ，以便进行后续的计算、分析和融合。
     </strong>
    </p>
    <ul>
     <li>
      <p>
       文本模态的表示：文本模态的表示方法有多种，如独热表示、低维空间表示（如通过神经网络模型学习得到的转换矩阵将单词或字映射到语义空间中）、词袋表示及其衍生出的n-grams词袋表示等。
       <strong>
        目前，主流的文本表示方法是预训练文本模型，如BERT。
       </strong>
      </p>
     </li>
     <li>
      <p>
       视觉模态的表示：视觉模态分为图像模态和视频模态。图像模态的表示主要通过卷积神经网络（CNN）实现，如LeNet-5、AlexNet、VGG、GoogLeNet、ResNet等。
       <strong>
        视频模态的表示则结合了图像的空间属性和时间属性，通常由CNN和循环神经网络（RNN）或长短时记忆网络（LSTM）等模型共同处理。
       </strong>
      </p>
     </li>
     <li>
      <p>
       声音模态的表示：声音模态的表示通常涉及
       <strong>
        音频信号的预处理、特征提取和表示学习
       </strong>
       等步骤，常用的模型包括深度神经网络（DNN）、卷积神经网络（CNN）和循环神经网络（RNN）等。
      </p>
     </li>
    </ul>
    <p>
     <strong>
      表征学习（Representation Learning）旨在从原始数据中自动提取有效特征，
      <strong>
       <strong>
        形成计算机可理解的模态表示
       </strong>
      </strong>
      ，以保留关键信息并促进跨模态交互与融合。
     </strong>
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/f677a473d654eb81e1b4a4a1b3fe4813.jpeg"/>
    </p>
    <p>
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          表征学习
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
    </p>
    <p>
     <strong>
      表征学习（Representation Learning） ≈ 向量化（Embedding）-- 架构师带你玩转AI
     </strong>
    </p>
    <p>
     <strong>
      <strong>
       什么是
       <strong>
        多模态联合表示
       </strong>
       （Joint Representation）
      </strong>
     </strong>
     ？
     <strong>
      多模态联合表示是一种将多个模态（如文本、图像、声音等）的信息共同映射到
     </strong>
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          一个统一的多模态向量空间
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
     <strong>
      中的表示方法。
     </strong>
    </p>
    <p>
     <strong>
      <strong>
       <strong>
        多模态联合表示通过
       </strong>
      </strong>
     </strong>
     <strong>
      <strong>
       <strong>
        神经网络、概率图模型
       </strong>
      </strong>
     </strong>
     将来自不同模态的数据进行融合，生成一个包含多个模态信息的统一表示。
     <strong>
      <strong>
       <strong>
        这个表示不仅保留了每个模态的关键信息，还能够在不同模态之间建立联系
       </strong>
      </strong>
      ，从而支持跨模态的任务，如多模态情感分析、视听语音识别等。
     </strong>
    </p>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/0df66e18a88670b0187b91b9f4f1ec84.png"/>
    </p>
    <p>
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          <strong>
           多模态表示
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
    </p>
    <p>
     <strong>
      什么是多模态协同表示（Coordinated Representation）？
      <strong>
       <strong>
        <strong>
         <strong>
          多模态
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
     <strong>
      协同表示是一种将
     </strong>
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          多个模态的信息分别映射到各自的表示空间
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
     ，但映射后的向量或表示之间
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          <strong>
           需要满足一定的相关性或约束条件的方法
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
     。这种方法的核心在于
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          <strong>
           确保不同模态之间的信息在协同空间内能够相互协作，共同优化模型的性能
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
     。
    </p>
    <p>
     <strong>
      <img alt="" src="https://img-blog.csdnimg.cn/img_convert/44bd42fb4ffd117135fe56437304af59.png"/>
     </strong>
    </p>
    <p>
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          <strong>
           多模态表示
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
    </p>
    <p>
     <strong>
      二、多模态融合
     </strong>
    </p>
    <p>
     <strong>
      <strong>
       什么是
       <strong>
        多模态融合
       </strong>
      </strong>
     </strong>
     （Multi
     <strong>
      <strong>
       Modal Fusion
      </strong>
     </strong>
     ）
     <strong>
      ？多模态融合
     </strong>
     能够充分利用不同模态之间的互补性，
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          <strong>
           它将抽取自不同模态的信息整合成一个稳定的多模态表征
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
     。
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          <strong>
           从数据处理的层次角度将多模态融合分为
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
     数据级融合、特征级融合和目标级融合。
    </p>
    <p>
     <strong>
      <strong>
       <img alt="" src="https://img-blog.csdnimg.cn/img_convert/1889bfaaa7013b58c72e92d4ec40c60d.jpeg"/>
      </strong>
     </strong>
    </p>
    <p>
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          <strong>
           多模态融合
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
    </p>
    <ol>
     <li>
      数据级融合（Data-Level Fusion）：
     </li>
    </ol>
    <ul>
     <li>
      <p>
       数据级融合，也称为像素级融合或原始数据融合，是在最底层的数据级别上进行融合。
       <strong>
        这种融合方式通常发生在数据预处理阶段，即将来自不同模态的原始数据直接合并或叠加在一起，形成一个新的数据集。
       </strong>
      </p>
     </li>
     <li>
      <p>
       应用场景：适用于那些原始数据之间具有高度相关性和互补性的情况，如图像和深度图的融合。
      </p>
     </li>
    </ul>
    <ol start="3">
     <li>
      特征级融合（Feature-Level Fusion）：
     </li>
    </ol>
    <ul>
     <li>
      <p>
       特征级融合是在特征提取之后、决策之前进行的融合。
       <strong>
        不同模态的数据首先被分别处理，提取出各自的特征表示，然后将这些特征表示在某一特征层上进行融合。
       </strong>
      </p>
     </li>
     <li>
      <p>
       应用场景：广泛应用于图像分类、语音识别、情感分析等多模态任务中。
      </p>
     </li>
    </ul>
    <ol start="5">
     <li>
      目标级融合（Decision-Level Fusion）：
     </li>
    </ol>
    <ul>
     <li>
      <p>
       目标级融合，也称为决策级融合或后期融合，是在各个单模态模型分别做出决策之后进行的融合。
       <strong>
        每个模态的模型首先独立地处理数据并给出自己的预测结果（如分类标签、回归值等），然后将这些预测结果进行整合以得到最终的决策结果。
       </strong>
      </p>
     </li>
     <li>
      <p>
       应用场景：适用于那些需要综合考虑多个独立模型预测结果的场景，如多传感器数据融合、多专家意见综合等。
      </p>
     </li>
    </ul>
    <h5>
     <a id="httpsimgblogcsdnimgcnimg_convertd57ac38ea5e99bbf9491863a132f1910jpeg_79">
     </a>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/d57ac38ea5e99bbf9491863a132f1910.jpeg"/>
    </h5>
    <p>
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          多模态融合
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
    </p>
    <p>
     <strong>
      三、跨模态对齐
     </strong>
    </p>
    <h5>
     <a id="MultiModalAlignment_85">
     </a>
     什么是跨模态对齐（MultiModalAlignment）？跨模态对齐是通过各种技术手段，实现不同模态数据（如图像、文本、音频等）在特征、语义或表示层面上的匹配与对应。跨模态对齐主要分为两大类：显式对齐和隐式对齐。
    </h5>
    <p>
     <strong>
      <img alt="" src="https://img-blog.csdnimg.cn/img_convert/2b6dda1d1eca1dd3f242e00f0ede90a3.png"/>
     </strong>
    </p>
    <p>
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          <strong>
           跨模态对齐
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
    </p>
    <h5>
     <a id="Explicit_Alignment_91">
     </a>
     什么是显示对齐（Explicit Alignment）？
     <strong>
      直接建立不同模态之间的对应关系，包括无监督对齐和监督对齐。
     </strong>
    </h5>
    <ol>
     <li>
      <h5>
       <a id="_93">
       </a>
       无监督对齐：利用数据本身的统计特性或结构信息，无需额外标签，自动发现不同模态间的对应关系。
      </h5>
     </li>
    </ol>
    <ul>
     <li>
      <p>
       <strong>
        CCA（典型相关分析
       </strong>
       ）：通过最大化两组变量之间的相关性来发现它们之间的线性关系，常用于图像和文本的无监督对齐。
      </p>
     </li>
     <li>
      <p>
       自编码器：通过编码-解码结构学习数据的低维表示，有时结合循环一致性损失（Cycle Consistency Loss）来实现无监督的图像-文本对齐。
      </p>
     </li>
    </ul>
    <ol start="3">
     <li>
      <h5>
       <a id="_101">
       </a>
       <strong>
        监督对齐
       </strong>
       ：利用额外的标签或监督信息指导对齐过程，确保对齐的准确性。
      </h5>
     </li>
    </ol>
    <ul>
     <li>
      <p>
       多模态嵌入模型：如DeViSE（Deep Visual-Semantic Embeddings），通过最大化图像和对应文本标签在嵌入空间中的相似度来实现监督对齐。
      </p>
     </li>
     <li>
      <p>
       多任务学习模型：同时学习图像分类和文本生成任务，利用共享层或联合损失函数来促进图像和文本之间的监督对齐。
      </p>
     </li>
    </ul>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/fcacf464f1ddaccf93fc957f084dcc6a.jpeg"/>
    </p>
    <p>
     <strong>
      <strong>
       <strong>
        <strong>
         <strong>
          <strong>
           显式对齐
          </strong>
         </strong>
        </strong>
       </strong>
      </strong>
     </strong>
    </p>
    <h5>
     <a id="Implicit_Alignment_113">
     </a>
     什么是隐式对齐（Implicit Alignment）？不直接建立对应关系，而是通过模型内部机制隐式地实现跨模态的对齐。这包括注意力对齐和语义对齐。
    </h5>
    <ol>
     <li>
      <h5>
       <a id="_115">
       </a>
       <strong>
        注意力对齐
       </strong>
       ：通过注意力机制动态地生成不同模态之间的权重向量，实现跨模态信息的加权融合和对齐。
      </h5>
     </li>
    </ol>
    <ul>
     <li>
      <p>
       Transformer模型：在跨模态任务中（如图像描述生成），利用自注意力机制和编码器-解码器结构，自动学习图像和文本之间的注意力分布，实现隐式对齐。
      </p>
     </li>
     <li>
      <p>
       BERT-based模型：在问答系统或文本-图像检索中，结合BERT的预训练表示和注意力机制，隐式地对齐文本查询和图像内容。
      </p>
     </li>
    </ul>
    <ol start="3">
     <li>
      <h5>
       <a id="_123">
       </a>
       <strong>
        语义对齐
       </strong>
       ：在语义层面上实现不同模态之间的对齐，需要深入理解数据的潜在语义联系。
      </h5>
     </li>
    </ol>
    <ul>
     <li>
      <p>
       图神经网络（GNN）：在构建图像和文本之间的语义图时，利用GNN学习节点（模态数据）之间的语义关系，实现隐式的语义对齐。
      </p>
     </li>
     <li>
      <p>
       预训练语言模型与视觉模型结合：如CLIP（Contrastive Language-Image Pre-training），通过对比学习在大量图像-文本对上训练，使模型学习到图像和文本在语义层面上的对应关系，实现高效的隐式语义对齐。
      </p>
     </li>
    </ul>
    <p>
     <img alt="" src="https://img-blog.csdnimg.cn/img_convert/7ab7b78ad60ca745ef6e73796c3ac56f.png"/>
    </p>
    <h3>
     <a id="_AI__133">
     </a>
     如何学习大模型 AI ？
    </h3>
    <p>
     由于新岗位的生产效率，要优于被取代岗位的生产效率，所以实际上整个社会的生产效率是提升的。
    </p>
    <p>
     但是具体到个人，只能说是：
    </p>
    <p>
     <strong>
      “最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。
     </strong>
    </p>
    <p>
     这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。
    </p>
    <p>
     我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。
    </p>
    <p>
     我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/direct/80dfd54ec491457faa956c46afad1163.png#pic_center"/>
    </p>
    <h3>
     <a id="10_151">
     </a>
     第一阶段（10天）：初阶应用
    </h3>
    <p>
     该阶段让大家对大模型 AI有一个最前沿的认识，对大模型 AI 的理解超过 95% 的人，可以在相关讨论时发表高级、不跟风、又接地气的见解，别人只会和 AI 聊天，而你能调教 AI，并能用代码将大模型和业务衔接。
    </p>
    <ul>
     <li>
      大模型 AI 能干什么？
     </li>
     <li>
      大模型是怎样获得「智能」的？
     </li>
     <li>
      用好 AI 的核心心法
     </li>
     <li>
      大模型应用业务架构
     </li>
     <li>
      大模型应用技术架构
     </li>
     <li>
      代码示例：向 GPT-3.5 灌入新知识
     </li>
     <li>
      提示工程的意义和核心思想
     </li>
     <li>
      Prompt 典型构成
     </li>
     <li>
      指令调优方法论
     </li>
     <li>
      思维链和思维树
     </li>
     <li>
      Prompt 攻击和防范
     </li>
     <li>
      …
     </li>
    </ul>
    <h3>
     <a id="30_172">
     </a>
     第二阶段（30天）：高阶应用
    </h3>
    <p>
     该阶段我们正式进入大模型 AI 进阶实战学习，学会构造私有知识库，扩展 AI 的能力。快速开发一个完整的基于 agent 对话机器人。掌握功能最强的大模型开发框架，抓住最新的技术进展，适合 Python 和 JavaScript 程序员。
    </p>
    <ul>
     <li>
      为什么要做 RAG
     </li>
     <li>
      搭建一个简单的 ChatPDF
     </li>
     <li>
      检索的基础概念
     </li>
     <li>
      什么是向量表示（Embeddings）
     </li>
     <li>
      向量数据库与向量检索
     </li>
     <li>
      基于向量检索的 RAG
     </li>
     <li>
      搭建 RAG 系统的扩展知识
     </li>
     <li>
      混合检索与 RAG-Fusion 简介
     </li>
     <li>
      向量模型本地部署
     </li>
     <li>
      …
     </li>
    </ul>
    <h3>
     <a id="30_188">
     </a>
     第三阶段（30天）：模型训练
    </h3>
    <p>
     恭喜你，如果学到这里，你基本可以找到一份大模型 AI相关的工作，自己也能训练 GPT 了！通过微调，训练自己的垂直大模型，能独立训练开源多模态大模型，掌握更多技术方案。
    </p>
    <p>
     到此为止，大概2个月的时间。你已经成为了一名“AI小子”。那么你还想往下探索吗？
    </p>
    <ul>
     <li>
      为什么要做 RAG
     </li>
     <li>
      什么是模型
     </li>
     <li>
      什么是模型训练
     </li>
     <li>
      求解器 &amp; 损失函数简介
     </li>
     <li>
      小实验2：手写一个简单的神经网络并训练它
     </li>
     <li>
      什么是训练/预训练/微调/轻量化微调
     </li>
     <li>
      Transformer结构简介
     </li>
     <li>
      轻量化微调
     </li>
     <li>
      实验数据集的构建
     </li>
     <li>
      …
     </li>
    </ul>
    <h3>
     <a id="20_206">
     </a>
     第四阶段（20天）：商业闭环
    </h3>
    <p>
     对全球大模型从性能、吞吐量、成本等方面有一定的认知，可以在云端和本地等多种环境下部署大模型，找到适合自己的项目/创业方向，做一名被 AI 武装的产品经理。
    </p>
    <ul>
     <li>
      硬件选型
     </li>
     <li>
      带你了解全球大模型
     </li>
     <li>
      使用国产大模型服务
     </li>
     <li>
      搭建 OpenAI 代理
     </li>
     <li>
      热身：基于阿里云 PAI 部署 Stable Diffusion
     </li>
     <li>
      在本地计算机运行大模型
     </li>
     <li>
      大模型的私有化部署
     </li>
     <li>
      基于 vLLM 部署大模型
     </li>
     <li>
      案例：如何优雅地在阿里云私有部署开源大模型
     </li>
     <li>
      部署一套开源 LLM 项目
     </li>
     <li>
      内容安全
     </li>
     <li>
      互联网信息服务算法备案
     </li>
     <li>
      …
     </li>
    </ul>
    <p>
     学习是一个过程，只要学习就会有挑战。天道酬勤，你越努力，就会成为越优秀的自己。
    </p>
    <p>
     如果你能在15天内完成所有的任务，那你堪称天才。然而，如果你能完成 60-70% 的内容，你就已经开始具备成为一名大模型 AI 的正确特征了。
    </p>
    <h6>
     <a id="httpsblogcsdnnetJavachichiarticledetails122513096spm1001201430015501httpsblogcsdnnetm0_57081622articledetails122378123spm1001201430015501_AI_CSDNCSDN100_230">
     </a>
     <a href="https://blog.csdn.net/Javachichi/article/details/122513096?spm=1001.2014.3001.5501">
     </a>
     <a href="https://blog.csdn.net/m0_57081622/article/details/122378123?spm=1001.2014.3001.5501">
     </a>
     这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【
     <code>
      保证100%免费
     </code>
     】
    </h6>
    <p>
     <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/direct/16d23a5ac75941ee874df3df7f04dfb4.png#pic_center"/>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f35393136343532302f:61727469636c652f64657461696c732f313432353331373531" class_="artid" style="display:none">
 </p>
</div>


