---
layout: post
title: "什么是人工智能的嵌入Embedding一文吃透人工智能的嵌入Embedding"
date: 2025-01-23 11:09:45 +0800
description: "该阶段让大家对大模型 AI有一个最前沿的认识，对大模型 AI 的理解超过 95% 的人，可以在相关讨"
keywords: "embiding人工智能"
categories: ['']
tags: ['自然语言处理', '程序人生', '人工智能', '产品经理', 'Llm', 'Embedding']
artid: "144546026"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=144546026
    alt: "什么是人工智能的嵌入Embedding一文吃透人工智能的嵌入Embedding"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     什么是人工智能的嵌入（Embedding）？一文吃透人工智能的嵌入（Embedding）
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <p>
    </p>
    <div class="toc">
     <h4>
      目录
     </h4>
     <ul>
      <li>
       <ul>
        <li>
         <a href="#1_Embedding_33" rel="nofollow">
          1\. Embedding往往包含语义关系
         </a>
        </li>
        <li>
         <a href="#2__45" rel="nofollow">
          2\. 举个通俗的例子来说明
         </a>
        </li>
        <li>
         <ul>
          <li>
           <a href="#21_Embedding__48" rel="nofollow">
            2.1 Embedding 像是一种“翻译器”：
           </a>
          </li>
          <li>
           <a href="#22_Embedding__60" rel="nofollow">
            2.2 Embedding 像地图上的“坐标”：
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a href="#_AI__68" rel="nofollow">
          如何学习大模型 AI ？
         </a>
        </li>
        <li>
         <a href="#10_90" rel="nofollow">
          第一阶段（10天）：初阶应用
         </a>
        </li>
        <li>
         <a href="#30_111" rel="nofollow">
          第二阶段（30天）：高阶应用
         </a>
        </li>
        <li>
         <a href="#30_127" rel="nofollow">
          第三阶段（30天）：模型训练
         </a>
        </li>
        <li>
         <a href="#20_146" rel="nofollow">
          第四阶段（20天）：商业闭环
         </a>
        </li>
        <li>
         <ul>
          <li>
           <ul>
            <li>
             <ul>
              <li>
               <a href="#_AI_CSDNCSDN100_171" rel="nofollow">
                这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【`保证100%免费`】
               </a>
              </li>
             </ul>
            </li>
           </ul>
          </li>
         </ul>
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <p>
    </p>
    <p>
     <strong>
      Embedding
     </strong>
     是一种机器学习概念，用于将数据映射到高维空间，将语义相似的数据放在一起。Embedding模型通常是 BERT 或其他 Transformer 系列中的深度神经网络，可以用一系列称为
     <strong>
      向量(vectors)的数字
     </strong>
     有效地表示
     <strong>
      文本、图像和其他数据类型的语义
     </strong>
     。这些模型的一个主要特点是，向量之间在高维空间中的数学距离可以表示原始文本或图像语义的相似性。这一特性开启了许多信息检索应用，如谷歌和必应等网络搜索引擎、电子商务网站上的产品搜索和推荐，以及最近流行的生成式人工智能中的检索增强生成（RAG）范式。
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/direct/223af409f8594c7ba5e61553cffe3bf8.png"/>
    </p>
    <p>
     Embedding 有两大类，每一类都能产生不同类型的向量：
    </p>
    <ul>
     <li>
      <p>
       <strong>
        密集嵌入
       </strong>
       ：大多数嵌入模型将信息表示为数百到数千维的浮点向量。由于
       <strong>
        大多数维度的值都不为零
       </strong>
       ，因此输出的向量被称为 "密集 "向量。例如，流行的开源嵌入模型 BAAI/bge-base-en-v1.5 输出的向量为 768 个浮点数（768 维浮点向量）。
      </p>
     </li>
     <li>
      <p>
       <strong>
        稀疏嵌入
       </strong>
       ：相比之下，稀疏嵌入的输出向量
       <strong>
        大部分维数为零
       </strong>
       ，即 "稀疏 "向量。这些向量通常具有更高的维度（数万或更多），这是由标记词汇量的大小决定的。稀疏向量可由深度神经网络或文本语料库统计分析生成。由于稀疏嵌入向量具有可解释性和更好的域外泛化能力，越来越多的开发人员采用稀疏嵌入向量作为高密度嵌入向量的补充。
      </p>
     </li>
    </ul>
    <blockquote>
     <p>
      如向量数据库Milvus，专为向量数据管理、存储和检索而设计。通过整合主流的嵌入(embedding )和重排 (reranking)模型，可以轻松地将原始文本转换为可搜索的向量，或使用强大的模型对结果进行重排，从而获得更准确的 RAG 结果
     </p>
    </blockquote>
    <p>
     对于 AI 或机器学习算法来说，原始数据如文字、视频、图片等，这些数据并没有相似性或距离的概念。例如“手机”与“苹果”，对于现代人来说，会知道“苹果”在语义上会联想到“手机”，
     <strong>
      Embedding
     </strong>
     在这当中加入了距离来表达它们之间的
     <strong>
      关联性
     </strong>
     ，距离越近相关性越高。这使得数据维度大幅减少，而且节省了很多存储空间。
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/direct/42794307cc3b41fdafbea13163076a0e.png"/>
    </p>
    <h3>
     <a id="1_Embedding_33">
     </a>
     1. Embedding往往包含语义关系
    </h3>
    <p>
     Embedding能捕捉词与词之间的语义关系。相似词的向量通常在空间中接近，并能区分同义词（如“big”和“large”），还能捕捉更复杂的语义关系：
    </p>
    <ul>
     <li>
      <p>
       <strong>
        “king” - “man” + “woman” ≈ “queen”
       </strong>
      </p>
     </li>
     <li>
      <p>
       king去掉man的语义，再加上woman的语义，就和queen的语义相近
      </p>
     </li>
    </ul>
    <p>
     像 BERT 或 GPT 这样的模型会根据上下文调整词的向量。例如，“bank” 在“河岸”和“银行”中的向量会不同。“bank” 在“river bank”和“money bank”中的表示是不同的。
    </p>
    <h3>
     <a id="2__45">
     </a>
     2. 举个通俗的例子来说明
    </h3>
    <h4>
     <a id="21_Embedding__48">
     </a>
     2.1 Embedding 像是一种“翻译器”：
    </h4>
    <ul>
     <li>
      <p>
       它把复杂的事物（比如单词、句子、图片）转化成“机器能理解的数字”。
      </p>
     </li>
     <li>
      <p>
       但这些数字不仅仅是随便的编码，而是带有
       <strong>
        意义
       </strong>
       的，比如让相似的东西靠得更近。
      </p>
     </li>
    </ul>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/direct/fab69ecf5bd84472ae36dbaaf8ab0dc1.png"/>
    </p>
    <h4>
     <a id="22_Embedding__60">
     </a>
     2.2 Embedding 像地图上的“坐标”：
    </h4>
    <ul>
     <li>
      <p>
       想象有一个巨大的地图，每个单词、句子或图片都被标记成一个点。
      </p>
     </li>
     <li>
      <p>
       Embedding 会把
       <strong>
        相似的内容
       </strong>
       放在地图上靠得更近，比如“猫”和“狗”会靠近，而“猫”和“汽车”距离较远。
      </p>
     </li>
     <li>
      <p>
       通过 Embedding，我们可以用数字坐标（如 [2.3, 4.1]）来表示这些东西的位置，机器就能用数学方法分析它们的关系了。
      </p>
     </li>
    </ul>
    <h3>
     <a id="_AI__68">
     </a>
     如何学习大模型 AI ？
    </h3>
    <p>
     由于新岗位的生产效率，要优于被取代岗位的生产效率，所以实际上整个社会的生产效率是提升的。
    </p>
    <p>
     但是具体到个人，只能说是：
    </p>
    <p>
     <strong>
      “最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。
     </strong>
    </p>
    <p>
     这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。
    </p>
    <p>
     我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。
    </p>
    <p>
     我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。
    </p>
    <p>
     <strong>
      这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【
      <code>
       保证100%免费
      </code>
      】
     </strong>
    </p>
    <p>
     <img alt="https://img-blog.csdnimg.cn/img_convert/05840567e2912bcdcdda7b15cba33d93.jpeg" src="https://i-blog.csdnimg.cn/direct/8860f19e62134f058ae4494199266f1f.png"/>
    </p>
    <p>
     <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/direct/80dfd54ec491457faa956c46afad1163.png#pic_center"/>
    </p>
    <h3>
     <a id="10_90">
     </a>
     第一阶段（10天）：初阶应用
    </h3>
    <p>
     该阶段让大家对大模型 AI有一个最前沿的认识，对大模型 AI 的理解超过 95% 的人，可以在相关讨论时发表高级、不跟风、又接地气的见解，别人只会和 AI 聊天，而你能调教 AI，并能用代码将大模型和业务衔接。
    </p>
    <ul>
     <li>
      大模型 AI 能干什么？
     </li>
     <li>
      大模型是怎样获得「智能」的？
     </li>
     <li>
      用好 AI 的核心心法
     </li>
     <li>
      大模型应用业务架构
     </li>
     <li>
      大模型应用技术架构
     </li>
     <li>
      代码示例：向 GPT-3.5 灌入新知识
     </li>
     <li>
      提示工程的意义和核心思想
     </li>
     <li>
      Prompt 典型构成
     </li>
     <li>
      指令调优方法论
     </li>
     <li>
      思维链和思维树
     </li>
     <li>
      Prompt 攻击和防范
     </li>
     <li>
      …
     </li>
    </ul>
    <h3>
     <a id="30_111">
     </a>
     第二阶段（30天）：高阶应用
    </h3>
    <p>
     该阶段我们正式进入大模型 AI 进阶实战学习，学会构造私有知识库，扩展 AI 的能力。快速开发一个完整的基于 agent 对话机器人。掌握功能最强的大模型开发框架，抓住最新的技术进展，适合 Python 和 JavaScript 程序员。
    </p>
    <ul>
     <li>
      为什么要做 RAG
     </li>
     <li>
      搭建一个简单的 ChatPDF
     </li>
     <li>
      检索的基础概念
     </li>
     <li>
      什么是向量表示（Embeddings）
     </li>
     <li>
      向量数据库与向量检索
     </li>
     <li>
      基于向量检索的 RAG
     </li>
     <li>
      搭建 RAG 系统的扩展知识
     </li>
     <li>
      混合检索与 RAG-Fusion 简介
     </li>
     <li>
      向量模型本地部署
     </li>
     <li>
      …
     </li>
    </ul>
    <h3>
     <a id="30_127">
     </a>
     第三阶段（30天）：模型训练
    </h3>
    <p>
     恭喜你，如果学到这里，你基本可以找到一份大模型 AI相关的工作，自己也能训练 GPT 了！通过微调，训练自己的垂直大模型，能独立训练开源多模态大模型，掌握更多技术方案。
    </p>
    <p>
     到此为止，大概2个月的时间。你已经成为了一名“AI小子”。那么你还想往下探索吗？
    </p>
    <ul>
     <li>
      为什么要做 RAG
     </li>
     <li>
      什么是模型
     </li>
     <li>
      什么是模型训练
     </li>
     <li>
      求解器 &amp; 损失函数简介
     </li>
     <li>
      小实验2：手写一个简单的神经网络并训练它
     </li>
     <li>
      什么是训练/预训练/微调/轻量化微调
     </li>
     <li>
      Transformer结构简介
     </li>
     <li>
      轻量化微调
     </li>
     <li>
      实验数据集的构建
     </li>
     <li>
      …
     </li>
    </ul>
    <h3>
     <a id="20_146">
     </a>
     第四阶段（20天）：商业闭环
    </h3>
    <p>
     对全球大模型从性能、吞吐量、成本等方面有一定的认知，可以在云端和本地等多种环境下部署大模型，找到适合自己的项目/创业方向，做一名被 AI 武装的产品经理。
    </p>
    <ul>
     <li>
      硬件选型
     </li>
     <li>
      带你了解全球大模型
     </li>
     <li>
      使用国产大模型服务
     </li>
     <li>
      搭建 OpenAI 代理
     </li>
     <li>
      热身：基于阿里云 PAI 部署 Stable Diffusion
     </li>
     <li>
      在本地计算机运行大模型
     </li>
     <li>
      大模型的私有化部署
     </li>
     <li>
      基于 vLLM 部署大模型
     </li>
     <li>
      案例：如何优雅地在阿里云私有部署开源大模型
     </li>
     <li>
      部署一套开源 LLM 项目
     </li>
     <li>
      内容安全
     </li>
     <li>
      互联网信息服务算法备案
     </li>
     <li>
      …
     </li>
    </ul>
    <p>
     学习是一个过程，只要学习就会有挑战。天道酬勤，你越努力，就会成为越优秀的自己。
    </p>
    <p>
     如果你能在15天内完成所有的任务，那你堪称天才。然而，如果你能完成 60-70% 的内容，你就已经开始具备成为一名大模型 AI 的正确特征了。
    </p>
    <h6>
     <a id="_AI_CSDNCSDN100_171">
     </a>
     这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【
     <code>
      保证100%免费
     </code>
     】
    </h6>
    <p>
     <img alt="https://img-blog.csdnimg.cn/img_convert/05840567e2912bcdcdda7b15cba33d93.jpeg" src="https://i-blog.csdnimg.cn/direct/8860f19e62134f058ae4494199266f1f.png"/>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f6d305f35373038313632322f:61727469636c652f64657461696c732f313434353436303236" class_="artid" style="display:none">
 </p>
</div>


