---
layout: post
title: "融云技术分享基于WebRTC的实时音视频首帧显示时间优化实践"
date: 2025-01-11 16:15:13 +0800
description: "本文由融云技术团队原创投稿，作者是融云WebRTC高级工程师苏道，转载请注明出处。1、引言在一个典型"
keywords: "android webrtc发送端每帧时间"
categories: ['']
tags: ['音频编码解码', '视频处理', 'Android']
artid: "108858906"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=108858906
    alt: "融云技术分享基于WebRTC的实时音视频首帧显示时间优化实践"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     融云技术分享：基于WebRTC的实时音视频首帧显示时间优化实践
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     本文由融云技术团队原创投稿，作者是融云WebRTC高级工程师苏道，转载请注明出处。
    </p>
    <h2>
     1、引言
    </h2>
    <p>
     在一个典型的IM应用里，使用实时音视频聊天功能时，视频首帧的显示，是一项很重要的用户体验指标。
    </p>
    <p>
     本文主要通过对WebRTC接收端的音视频处理过程分析，来了解和优化视频首帧的显示时间，并进行了总结和分享。
    </p>
    <p>
     （本文同步发布于：
     <a href="http://www.52im.net/thread-3169-1-1.html" rel="nofollow">
      http://www.52im.net/thread-3169-1-1.html
     </a>
     ）
    </p>
    <h2>
     2、什么是WebRTC？
    </h2>
    <p>
     对于没接触过实时音视频技术的人来说，总是看到别人在提WebRTC，那WebRTC是什么？我们有必要简单介绍一下。
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/766779e816bfcd92073a3335a01e3292.png"/>
    </p>
    <p>
     说到 WebRTC，我们不得不提到 Gobal IP Solutions，简称 GIPS。这是一家 1990 年成立于瑞典斯德哥尔摩的 VoIP 软件开发商，提供了可以说是世界上最好的语音引擎。相关介绍详见《
     <a href="http://www.52im.net/thread-227-1-1.html" rel="nofollow">
      访谈WebRTC标准之父：WebRTC的过去、现在和未来
     </a>
     》。
    </p>
    <p>
     Skype、腾讯 QQ、WebEx、Vidyo 等都使用了它的音频处理引擎，包含了受专利保护的回声消除算法，适应网络抖动和丢包的低延迟算法，以及先进的音频编解码器。
    </p>
    <p>
     Google 在 Gtalk 中也使用了 GIPS 的授权。Google 在 2011 年以6820万美元收购了 GIPS，并将其源代码开源，加上在 2010 年收购的 On2 获取到的 VPx 系列视频编解码器（详见《
     <a href="http://www.52im.net/thread-274-1-1.html" rel="nofollow">
      即时通讯音视频开发（十七）：视频编码H.264、VP8的前世今生
     </a>
     》），WebRTC 开源项目应运而生，即 GIPS 音视频引擎 + 替换掉 H.264 的 VPx 视频编解码器。
    </p>
    <p>
     在此之后，Google 又将在 Gtalk 中用于 P2P 打洞的开源项目 libjingle 融合进了 WebRTC。目前 WebRTC 提供了包括 Web、iOS、Android、Mac、Windows、Linux 在内的所有平台支持。
    </p>
    <p>
     （以上介绍，引用自《
     <a href="http://www.52im.net/thread-1631-1-1.html" rel="nofollow">
      了不起的WebRTC：生态日趋完善，或将实时音视频技术白菜化
     </a>
     》）
    </p>
    <p>
     虽然WebRTC的目标是实现跨平台的Web端实时音视频通讯，但因为核心层代码的Native、高品质和内聚性，开发者很容易进行除Web平台外的移殖和应用。目前为止，WebRTC几乎是是业界能免费得到的唯一高品质实时音视频通讯技术。
    </p>
    <h2>
     3、流程介绍
    </h2>
    <p>
     <strong>
      一个典型的实时音视频处理流程大概是这样：
     </strong>
    </p>
    <ul>
     <li>
      1）发送端采集音视频数据，通过编码器生成帧数据；
     </li>
     <li>
      2）这数据被打包成 RTP 包，通过 ICE 通道发送到接收端；
     </li>
     <li>
      3）接收端接收 RTP 包，取出 RTP payload，完成组帧的操作；
     </li>
     <li>
      4）之后音视频解码器解码帧数据，生成视频图像或音频 PCM 数据。
     </li>
    </ul>
    <p>
     <strong>
      如下图所示：
     </strong>
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/e1be6726adfe1e05780d6298da4a7116.png"/>
    </p>
    <p>
     本文所涉及的参数调整，谈论的部分位于上图中的第 4 步。
    </p>
    <p>
     因为是接收端，所以会收到对方的 Offer 请求。先设置 SetRemoteDescription 再 SetLocalDescription。
    </p>
    <p>
     <strong>
      如下图蓝色部分：
     </strong>
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/2f5a25dc372fe1b516e5bde179a57a10.png"/>
    </p>
    <h2>
     4、参数调整
    </h2>
    <h4>
     4.1 视频参数调整
    </h4>
    <p>
     当收到 Signal 线程 SetRemoteDescription 后，会在 Worker 线程中创建 VideoReceiveStream 对象。具体流程为 SetRemoteDescription -&gt; VideoChannel::SetRemoteContent_w 创建 WebRtcVideoReceiveStream。
    </p>
    <p>
     WebRtcVideoReceiveStream 包含了一个 VideoReceiveStream 类型 stream_ 对象， 通过 webrtc::VideoReceiveStream* Call::CreateVideoReceiveStream 创建。
    </p>
    <p>
     创建后立即启动 VideoReceiveStream 工作，即调用 Start() 方法。
    </p>
    <p>
     此时 VideoReceiveStream 包含一个 RtpVideoStreamReceiver 对象准备开始处理 video RTP 包。
    </p>
    <p>
     接收方创建 createAnswer 后通过 setLocalDescription 设置 local descritpion。
    </p>
    <p>
     对应会在 Worker 线程中 setLocalContent_w 方法中根据 SDP 设置 channel 的接收参数，最终会调用到 WebRtcVideoReceiveStream::SetRecvParameters。
    </p>
    <p>
     <strong>
      WebRtcVideoReceiveStream::SetRecvParameters 实现如下：
     </strong>
    </p>
    <blockquote>
     <p>
      void WebRtcVideoChannel::WebRtcVideoReceiveStream::SetRecvParameters(
     </p>
     <p>
      const ChangedRecvParameters&amp; params) {
      <!-- -->
     </p>
     <p>
      bool video_needs_recreation = false;
     </p>
     <p>
      bool flexfec_needs_recreation = false;
     </p>
     <p>
      if(params.codec_settings) {
      <!-- -->
     </p>
     <p>
      ConfigureCodecs(*params.codec_settings);
     </p>
     <p>
      video_needs_recreation = true;
     </p>
     <p>
      }
     </p>
     <p>
      if(params.rtp_header_extensions) {
      <!-- -->
     </p>
     <p>
      config_.rtp.extensions = *params.rtp_header_extensions;
     </p>
     <p>
      flexfec_config_.rtp_header_extensions = *params.rtp_header_extensions;
     </p>
     <p>
      video_needs_recreation = true;
     </p>
     <p>
      flexfec_needs_recreation = true;
     </p>
     <p>
      }
     </p>
     <p>
      if(params.flexfec_payload_type) {
      <!-- -->
     </p>
     <p>
      ConfigureFlexfecCodec(*params.flexfec_payload_type);
     </p>
     <p>
      flexfec_needs_recreation = true;
     </p>
     <p>
      }
     </p>
     <p>
      if(flexfec_needs_recreation) {
      <!-- -->
     </p>
     <p>
      RTC_LOG(LS_INFO) &lt;&lt; "MaybeRecreateWebRtcFlexfecStream (recv) because of "
     </p>
     <p>
      "SetRecvParameters";
     </p>
     <p>
      MaybeRecreateWebRtcFlexfecStream();
     </p>
     <p>
      }
     </p>
     <p>
      if(video_needs_recreation) {
      <!-- -->
     </p>
     <p>
      RTC_LOG(LS_INFO)
     </p>
     <p>
      &lt;&lt; "RecreateWebRtcVideoStream (recv) because of SetRecvParameters";
     </p>
     <p>
      RecreateWebRtcVideoStream();
     </p>
     <p>
      }
     </p>
     <p>
      }
     </p>
    </blockquote>
    <p>
     根据上面 SetRecvParameters 代码，如果 codec_settings 不为空、rtp_header_extensions 不为空、flexfec_payload_type 不为空都会重启 VideoReceiveStream。
    </p>
    <p>
     video_needs_recreation 表示是否要重启 VideoReceiveStream。
    </p>
    <p>
     <strong>
      重启过程为：
     </strong>
     把先前创建的释放掉，然后重建新的 VideoReceiveStream。
    </p>
    <p>
     以 codec_settings 为例：初始 video codec 支持 H264 和 VP8。若对端只支持 H264，协商后的 codec 仅支持 H264。SetRecvParameters 中的 codec_settings 为 H264 不空。其实前后 VideoReceiveStream 的都有 H264 codec，没有必要重建 VideoReceiveStream。可以通过配置本地支持的 video codec 初始列表和 rtp extensions，从而生成的 local SDP 和 remote SDP 中影响接收参数部分调整一致，并且判断 codec_settings 是否相等。 如果不相等再 video_needs_recreation 为 true。
    </p>
    <p>
     这样设置就会使 SetRecvParameters 避免触发重启 VideoReceiveStream 逻辑。
    </p>
    <p>
     在 debug 模式下，修改后，验证没有 “RecreateWebRtcVideoStream (recv) because of SetRecvParameters” 的打印, 即可证明没有 VideoReceiveStream 重启。
    </p>
    <h4>
     4.2 音频参数调整
    </h4>
    <p>
     和上面的视频调整类似，音频也会有因为 rtp extensions 不一致导致重新创建 AudioReceiveStream，也是释放先前的 AudioReceiveStream，再重新创建 AudioReceiveStream。
    </p>
    <p>
     <strong>
      参考代码:
     </strong>
    </p>
    <blockquote>
     <p>
      bool WebRtcVoiceMediaChannel::SetRecvParameters(
     </p>
     <p>
      const AudioRecvParameters&amp; params) {
      <!-- -->
     </p>
     <p>
      TRACE_EVENT0("webrtc", "WebRtcVoiceMediaChannel::SetRecvParameters");
     </p>
     <p>
      RTC_DCHECK(worker_thread_checker_.CalledOnValidThread());
     </p>
     <p>
      RTC_LOG(LS_INFO) &lt;&lt; "WebRtcVoiceMediaChannel::SetRecvParameters: "
     </p>
     <p>
      &lt;&lt; params.ToString();
     </p>
     <p>
      // TODO(pthatcher): Refactor this to be more clean now that we have
     </p>
     <p>
      // all the information at once.
     </p>
     <p>
     </p>
     <p>
      if(!SetRecvCodecs(params.codecs)) {
      <!-- -->
     </p>
     <p>
      return false;
     </p>
     <p>
      }
     </p>
     <p>
     </p>
     <p>
      if(!ValidateRtpExtensions(params.extensions)) {
      <!-- -->
     </p>
     <p>
      return false;
     </p>
     <p>
      }
     </p>
     <p>
      std::vector&lt;webrtc::RtpExtension&gt; filtered_extensions = FilterRtpExtensions(
     </p>
     <p>
      params.extensions, webrtc::RtpExtension::IsSupportedForAudio, false);
     </p>
     <p>
      if(recv_rtp_extensions_ != filtered_extensions) {
      <!-- -->
     </p>
     <p>
      recv_rtp_extensions_.swap(filtered_extensions);
     </p>
     <p>
      for(auto&amp; it : recv_streams_) {
      <!-- -->
     </p>
     <p>
      it.second-&gt;SetRtpExtensionsAndRecreateStream(recv_rtp_extensions_);
     </p>
     <p>
      }
     </p>
     <p>
      }
     </p>
     <p>
      return true;
     </p>
     <p>
      }
     </p>
    </blockquote>
    <p>
     AudioReceiveStream 的构造方法会启动音频设备，即调用 AudioDeviceModule 的 StartPlayout。
    </p>
    <p>
     AudioReceiveStream 的析构方法会停止音频设备，即调用 AudioDeviceModule 的 StopPlayout。
    </p>
    <p>
     因此重启 AudioReceiveStream 会触发多次 StartPlayout/StopPlayout。
    </p>
    <p>
     经测试，这些不必要的操作会导致进入视频会议的房间时，播放的音频有一小段间断的情况。
    </p>
    <p>
     <strong>
      解决方法：
     </strong>
     同样是通过配置本地支持的 audio codec 初始列表和 rtp extensions，从而生成的 local SDP 和 remote SDP 中影响接收参数部分调整一致，避免 AudioReceiveStream 重启逻辑。
    </p>
    <p>
     另外 audio codec 多为 WebRTC 内部实现，去掉一些不用的 Audio Codec，可以减小 WebRTC 对应的库文件。
    </p>
    <h4>
     4.3 音视频相互影响
    </h4>
    <p>
     <strong>
      WebRTC 内部有三个非常重要的线程：
     </strong>
    </p>
    <ul>
     <li>
      1）woker 线程；
     </li>
     <li>
      2）signal 线程；
     </li>
     <li>
      3）network 线程。
     </li>
    </ul>
    <p>
     调用 PeerConnection 的 API 的调用会由 signal 线程进入到 worker 线程。
    </p>
    <p>
     worker 线程内完成媒体数据的处理，network 线程处理网络相关的事务，channel.h 文件中有说明，以 _w 结尾的方法为 worker 线程的方法，signal 线程的到 worker 线程的调用是同步操作。
    </p>
    <p>
     如下面代码中的 InvokerOnWorker 是同步操作，setLocalContent_w 和 setRemoteContent_w 是 worker 线程中的方法。
    </p>
    <blockquote>
     <p>
      bool BaseChannel::SetLocalContent(const MediaContentDescription* content,
     </p>
     <p>
      SdpType type,
     </p>
     <p>
      std::string* error_desc) {
      <!-- -->
     </p>
     <p>
      TRACE_EVENT0("webrtc", "BaseChannel::SetLocalContent");
     </p>
     <p>
      returnI nvokeOnWorker&lt;bool&gt;(
     </p>
     <p>
      RTC_FROM_HERE,
     </p>
     <p>
      Bind(&amp;BaseChannel::SetLocalContent_w, this, content, type, error_desc));
     </p>
     <p>
      }
     </p>
     <p>
     </p>
     <p>
      bool BaseChannel::SetRemoteContent(const MediaContentDescription* content,
     </p>
     <p>
      SdpType type,
     </p>
     <p>
      std::string* error_desc) {
      <!-- -->
     </p>
     <p>
      TRACE_EVENT0("webrtc", "BaseChannel::SetRemoteContent");
     </p>
     <p>
      return InvokeOnWorker&lt;bool&gt;(
     </p>
     <p>
      RTC_FROM_HERE,
     </p>
     <p>
      Bind(&amp;BaseChannel::SetRemoteContent_w, this, content, type, error_desc));
     </p>
     <p>
      }
     </p>
    </blockquote>
    <p>
     setLocalDescription 和 setRemoteDescription 中的 SDP 信息都会通过 PeerConnection 的 PushdownMediaDescription 方法依次下发给 audio/video RtpTransceiver 设置 SDP 信息。
    </p>
    <p>
     <strong>
      举例：
     </strong>
     执行 audio 的 SetRemoteContent_w 执行很长（比如音频 AudioDeviceModule 的 InitPlayout 执行耗时）, 会影响后面的 video SetRemoteContent_w 的设置时间。
    </p>
    <p>
     <strong>
      PushdownMediaDescription 代码：
     </strong>
    </p>
    <blockquote>
     <p>
      RTCError PeerConnection::PushdownMediaDescription(
     </p>
     <p>
      SdpType type,
     </p>
     <p>
      cricket::ContentSource source) {
      <!-- -->
     </p>
     <p>
      const SessionDescriptionInterface* sdesc =
     </p>
     <p>
      (source == cricket::CS_LOCAL ? local_description()
     </p>
     <p>
      : remote_description());
     </p>
     <p>
      RTC_DCHECK(sdesc);
     </p>
     <p>
     </p>
     <p>
      // Push down the new SDP media section for each audio/video transceiver.
     </p>
     <p>
      for(const auto&amp; transceiver : transceivers_) {
      <!-- -->
     </p>
     <p>
      const ContentInfo* content_info =
     </p>
     <p>
      FindMediaSectionForTransceiver(transceiver, sdesc);
     </p>
     <p>
      cricket::ChannelInterface* channel = transceiver-&gt;internal()-&gt;channel();
     </p>
     <p>
      if(!channel || !content_info || content_info-&gt;rejected) {
      <!-- -->
     </p>
     <p>
      continue;
     </p>
     <p>
      }
     </p>
     <p>
      const MediaContentDescription* content_desc =
     </p>
     <p>
      content_info-&gt;media_description();
     </p>
     <p>
      if(!content_desc) {
      <!-- -->
     </p>
     <p>
      continue;
     </p>
     <p>
      }
     </p>
     <p>
      std::string error;
     </p>
     <p>
      bool success = (source == cricket::CS_LOCAL)
     </p>
     <p>
      ? channel-&gt;SetLocalContent(content_desc, type, &amp;error)
     </p>
     <p>
      : channel-&gt;SetRemoteContent(content_desc, type, &amp;error);
     </p>
     <p>
      if(!success) {
      <!-- -->
     </p>
     <p>
      LOG_AND_RETURN_ERROR(RTCErrorType::INVALID_PARAMETER, error);
     </p>
     <p>
      }
     </p>
     <p>
      }
     </p>
     <p>
      ...
     </p>
     <p>
      }
     </p>
    </blockquote>
    <h2>
     5、其他影响首帧显示的问题
    </h2>
    <h4>
     5.1 Android图像宽高16字节对齐
    </h4>
    <p>
     AndroidVideoDecoder 是 WebRTC Android 平台上的视频硬解类。AndroidVideoDecoder 利用
     <a href="http://docs.52im.net/extend/docs/api/android-50/reference/android/media/MediaCodec.html" rel="nofollow">
      MediaCodec
     </a>
     API 完成对硬件解码器的调用。
    </p>
    <p>
     <strong>
      <a href="http://docs.52im.net/extend/docs/api/android-50/reference/android/media/MediaCodec.html" rel="nofollow">
       MediaCodec
      </a>
      有已下解码相关的 API：
     </strong>
    </p>
    <ul>
     <li>
      1）dequeueInputBuffer：若大于 0，则是返回填充编码数据的缓冲区的索引，该操作为同步操作；
     </li>
     <li>
      2）getInputBuffer：填充编码数据的 ByteBuffer 数组，结合 dequeueInputBuffer 返回值，可获取一个可填充编码数据的 ByteBuffer；
     </li>
     <li>
      3）queueInputBuffer：应用将编码数据拷贝到 ByteBuffer 后，通过该方法告知 MediaCodec 已经填写的编码数据的缓冲区索引；
     </li>
     <li>
      4）dequeueOutputBuffer：若大于 0，则是返回填充解码数据的缓冲区的索引，该操作为同步操作；
     </li>
     <li>
      5）getOutputBuffer：填充解码数据的 ByteBuffer 数组，结合 dequeueOutputBuffer 返回值，可获取一个可填充解码数据的 ByteBuffer；
     </li>
     <li>
      6）releaseOutputBuffer：告诉编码器数据处理完成，释放 ByteBuffer 数据。
     </li>
    </ul>
    <p>
     在实践当中发现，发送端发送的视频宽高需要 16 字节对齐，因为在某些 Android 手机上解码器需要 16 字节对齐。
    </p>
    <p>
     <strong>
      大致的原理就是：
     </strong>
     Android 上视频解码先是把待解码的数据通过 queueInputBuffer 给到 MediaCodec。然后通过 dequeueOutputBuffer 反复查看是否有解完的视频帧。若非 16 字节对齐，dequeueOutputBuffer 会有一次MediaCodec.INFO_OUTPUT_BUFFERS_CHANGED。而不是一上来就能成功解码一帧。
    </p>
    <p>
     <strong>
      经测试发现：
     </strong>
     帧宽高非 16 字节对齐会比 16 字节对齐的慢 100 ms 左右。
    </p>
    <h4>
     5.2 服务器需转发关键帧请求
    </h4>
    <p>
     iOS 移动设备上，WebRTC App应用进入后台后，视频解码由 VTDecompressionSessionDecodeFrame 返回 kVTInvalidSessionErr，表示解码session 无效。从而会触发观看端的关键帧请求给服务器。
    </p>
    <p>
     这里要求服务器必须转发接收端发来的关键帧请求给发送端。若服务器没有转发关键帧给发送端，接收端就会长时间没有可以渲染的图像，从而出现黑屏问题。
    </p>
    <p>
     这种情况下只能等待发送端自己生成关键帧，发送个接收端，从而使黑屏的接收端恢复正常。
    </p>
    <h4>
     5.3 WebRTC内部的一些丢弃数据逻辑举例
    </h4>
    <p>
     Webrtc从接受报数据到、给到解码器之间的过程中也会有很多验证数据的正确性。
    </p>
    <p>
     <strong>
      <em>
       举例1：
      </em>
     </strong>
    </p>
    <p>
     PacketBuffer 中记录着当前缓存的最小的序号 first_seq_num_（这个值也是会被更新的）。 当 PacketBuffer 中 InsertPacket 时候，如果即将要插入的 packet 的序号 seq_num 小于 first_seq_num，这个 packet 会被丢弃掉。如果因此持续丢弃 packet，就会有视频不显示或卡顿的情况。
    </p>
    <p>
     <strong>
      <em>
       举例2：
      </em>
     </strong>
    </p>
    <p>
     正常情况下 FrameBuffer 中帧的 picture id，时间戳都是一直正增长的。
    </p>
    <p>
     <strong>
      如果 FrameBuffer 收到 picture_id 比最后解码帧的 picture id 小时，分两种情况：
     </strong>
    </p>
    <ul>
     <li>
      1）时间戳比最后解码帧的时间戳大，且是关键帧，就会保存下来。
     </li>
     <li>
      2）除情况 1 之外的帧都会丢弃掉。
     </li>
    </ul>
    <p>
     <strong>
      代码如下:
     </strong>
    </p>
    <blockquote>
     <p>
      auto last_decoded_frame = decoded_frames_history_.GetLastDecodedFrameId();
     </p>
     <p>
      auto last_decoded_frame_timestamp =
     </p>
     <p>
      decoded_frames_history_.GetLastDecodedFrameTimestamp();
     </p>
     <p>
      if(last_decoded_frame &amp;&amp; id &lt;= *last_decoded_frame) {
      <!-- -->
     </p>
     <p>
      if(AheadOf(frame-&gt;Timestamp(), *last_decoded_frame_timestamp) &amp;&amp;
     </p>
     <p>
      frame-&gt;is_keyframe()) {
      <!-- -->
     </p>
     <p>
      // If this frame has a newer timestamp but an earlier picture id then we
     </p>
     <p>
      // assume there has been a jump in the picture id due to some encoder
     </p>
     <p>
      // reconfiguration or some other reason. Even though this is not according
     </p>
     <p>
      // to spec we can still continue to decode from this frame if it is a
     </p>
     <p>
      // keyframe.
     </p>
     <p>
      RTC_LOG(LS_WARNING)
     </p>
     <p>
      &lt;&lt; "A jump in picture id was detected, clearing buffer.";
     </p>
     <p>
      ClearFramesAndHistory();
     </p>
     <p>
      last_continuous_picture_id = -1;
     </p>
     <p>
      } else{
      <!-- -->
     </p>
     <p>
      RTC_LOG(LS_WARNING) &lt;&lt; "Frame with (picture_id:spatial_id) ("
     </p>
     <p>
      &lt;&lt; id.picture_id &lt;&lt; ":"
     </p>
     <p>
      &lt;&lt; static_cast&lt;int&gt;(id.spatial_layer)
     </p>
     <p>
      &lt;&lt; ") inserted after frame ("
     </p>
     <p>
      &lt;&lt; last_decoded_frame-&gt;picture_id &lt;&lt; ":"
     </p>
     <p>
      &lt;&lt; static_cast&lt;int&gt;(last_decoded_frame-&gt;spatial_layer)
     </p>
     <p>
      &lt;&lt; ") was handed off for decoding, dropping frame.";
     </p>
     <p>
      return last_continuous_picture_id;
     </p>
     <p>
      }
     </p>
     <p>
      }
     </p>
    </blockquote>
    <p>
     因此为了能让收到了流顺利播放，发送端和中转的服务端需要确保视频帧的 picture_id, 时间戳正确性。
    </p>
    <p>
     WebRTC 还有其他很多丢帧逻辑，若网络正常且有持续有接收数据，但是视频卡顿或黑屏无显示，多为流本身的问题。
    </p>
    <h2>
     6、本文小结
    </h2>
    <p>
     本文通过分析 WebRTC 音视频接收端的处理逻辑，列举了一些可以优化首帧显示的点，比如通过调整 local SDP 和 remote SDP 中与影响接收端处理的相关部分，从而避免 Audio/Video ReceiveStream 的重启。
    </p>
    <p>
     另外列举了 Android 解码器对视频宽高的要求、服务端对关键帧请求处理、以及 WebRTC 代码内部的一些丢帧逻辑等多个方面对视频显示的影响。 这些点都提高了融云 SDK 视频首帧的显示时间，改善了用户体验。
    </p>
    <p>
     因个人水平有限，文章内容或许存在一定的局限性，欢迎回复进行讨论。
    </p>
    <h2>
     附录1：融云分享的其它文章
    </h2>
    <blockquote>
     <p>
      《
      <a href="http://www.52im.net/thread-2744-1-1.html" rel="nofollow">
       融云技术分享：融云安卓端IM产品的网络链路保活技术实践
      </a>
      》
     </p>
     <p>
      《
      <a href="http://www.52im.net/thread-2747-1-1.html" rel="nofollow">
       IM消息ID技术专题(三)：解密融云IM产品的聊天消息ID生成策略
      </a>
      》
     </p>
     <p>
      《
      <a href="http://www.52im.net/thread-3169-1-1.html" rel="nofollow">
       融云技术分享：基于WebRTC的实时音视频首帧显示时间优化实践
      </a>
      》（* 本文）
     </p>
     <p>
      《
      <a href="http://www.52im.net/thread-2703-1-1.html" rel="nofollow">
       即时通讯云融云CTO的创业经验分享：技术创业，你真的准备好了？
      </a>
      》
     </p>
    </blockquote>
    <h2 id="14">
     附录2：更多实时音视频相关技术文章
    </h2>
    <blockquote>
     <p>
      [1] 开源实时音视频技术WebRTC的文章：
      <br/>
      《
      <a href="http://www.52im.net/article-126-1.html" rel="nofollow">
       开源实时音视频技术WebRTC的现状
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-225-1-1.html" rel="nofollow">
       简述开源实时音视频技术WebRTC的优缺点
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-227-1-1.html" rel="nofollow">
       访谈WebRTC标准之父：WebRTC的过去、现在和未来
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-265-1-1.html" rel="nofollow">
       良心分享：WebRTC 零基础开发者教程（中文）[附件下载]
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-284-1-1.html" rel="nofollow">
       WebRTC实时音视频技术的整体架构介绍
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-356-1-1.html" rel="nofollow">
       新手入门：到底什么是WebRTC服务器，以及它是如何联接通话的？
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-442-1-1.html" rel="nofollow">
       WebRTC实时音视频技术基础：基本架构和协议栈
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-475-1-1.html" rel="nofollow">
       浅谈开发实时视频直播平台的技术要点
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-488-1-1.html" rel="nofollow">
       [观点] WebRTC应该选择H.264视频编码的四大理由
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-510-1-1.html" rel="nofollow">
       基于开源WebRTC开发实时音视频靠谱吗？第3方SDK有哪些？
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-589-1-1.html" rel="nofollow">
       开源实时音视频技术WebRTC中RTP/RTCP数据传输协议的应用
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-763-1-1.html" rel="nofollow">
       简述实时音视频聊天中端到端加密（E2EE）的工作原理
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1034-1-1.html" rel="nofollow">
       实时通信RTC技术栈之：视频编解码
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1125-1-1.html" rel="nofollow">
       开源实时音视频技术WebRTC在Windows下的简明编译教程
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1282-1-1.html" rel="nofollow">
       网页端实时音视频技术WebRTC：看起来很美，但离生产应用还有多少坑要填？
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1631-1-1.html" rel="nofollow">
       了不起的WebRTC：生态日趋完善，或将实时音视频技术白菜化
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1988-1-1.html" rel="nofollow">
       腾讯技术分享：微信小程序音视频与WebRTC互通的技术思路和实践
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-3169-1-1.html" rel="nofollow">
       融云技术分享：基于WebRTC的实时音视频首帧显示时间优化实践
      </a>
      》
      <br/>
      &gt;&gt;
      <a href="http://www.52im.net/forum.php?mod=collection&amp;action=view&amp;ctid=5" rel="nofollow">
       更多同类文章 ……
      </a>
      <br/>
      <br/>
      [2] 实时音视频开发的其它精华资料：
      <br/>
      《
      <a href="http://www.52im.net/thread-228-1-1.html" rel="nofollow">
       即时通讯音视频开发（一）：视频编解码之理论概述
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-229-1-1.html" rel="nofollow">
       即时通讯音视频开发（二）：视频编解码之数字视频介绍
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-232-1-1.html" rel="nofollow">
       即时通讯音视频开发（三）：视频编解码之编码基础
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-235-1-1.html" rel="nofollow">
       即时通讯音视频开发（四）：视频编解码之预测技术介绍
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-237-1-1.html" rel="nofollow">
       即时通讯音视频开发（五）：认识主流视频编码技术H.264
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-241-1-1.html" rel="nofollow">
       即时通讯音视频开发（六）：如何开始音频编解码技术的学习
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-242-1-1.html" rel="nofollow">
       即时通讯音视频开发（七）：音频基础及编码原理入门
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-243-1-1.html" rel="nofollow">
       即时通讯音视频开发（八）：常见的实时语音通讯编码标准
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-247-1-1.html" rel="nofollow">
       即时通讯音视频开发（九）：实时语音通讯的回音及回音消除概述
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-250-1-1.html" rel="nofollow">
       即时通讯音视频开发（十）：实时语音通讯的回音消除技术详解
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-251-1-1.html" rel="nofollow">
       即时通讯音视频开发（十一）：实时语音通讯丢包补偿技术详解
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-253-1-1.html" rel="nofollow">
       即时通讯音视频开发（十二）：多人实时音视频聊天架构探讨
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-266-1-1.html" rel="nofollow">
       即时通讯音视频开发（十三）：实时视频编码H.264的特点与优势
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-267-1-1.html" rel="nofollow">
       即时通讯音视频开发（十四）：实时音视频数据传输协议介绍
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-269-1-1.html" rel="nofollow">
       即时通讯音视频开发（十五）：聊聊P2P与实时音视频的应用情况
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-270-1-1.html" rel="nofollow">
       即时通讯音视频开发（十六）：移动端实时音视频开发的几个建议
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-274-1-1.html" rel="nofollow">
       即时通讯音视频开发（十七）：视频编码H.264、VP8的前世今生
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-2230-1-1.html" rel="nofollow">
       即时通讯音视频开发（十八）：详解音频编解码的原理、演进和应用选型
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-2840-1-1.html" rel="nofollow">
       即时通讯音视频开发（十九）：零基础，史上最通俗视频编码技术入门
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-825-1-1.html" rel="nofollow">
       实时语音聊天中的音频处理与编码压缩技术简述
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-678-1-1.html" rel="nofollow">
       网易视频云技术分享：音频处理与压缩技术快速入门
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-590-1-1.html" rel="nofollow">
       学习RFC3550：RTP/RTCP实时传输协议基础知识
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-273-1-1.html" rel="nofollow">
       基于RTMP数据传输协议的实时流媒体技术研究（论文全文）
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-399-1-1.html" rel="nofollow">
       声网架构师谈实时音视频云的实现难点(视频采访)
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-475-1-1.html" rel="nofollow">
       浅谈开发实时视频直播平台的技术要点
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-507-1-1.html" rel="nofollow">
       还在靠“喂喂喂”测试实时语音通话质量？本文教你科学的评测方法！
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-528-1-1.html" rel="nofollow">
       实现延迟低于500毫秒的1080P实时音视频直播的实践分享
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-530-1-1.html" rel="nofollow">
       移动端实时视频直播技术实践：如何做到实时秒开、流畅不卡
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-535-1-1.html" rel="nofollow">
       如何用最简单的方法测试你的实时音视频方案
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-541-1-1.html" rel="nofollow">
       技术揭秘：支持百万级粉丝互动的Facebook实时视频直播
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-763-1-1.html" rel="nofollow">
       简述实时音视频聊天中端到端加密（E2EE）的工作原理
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-853-1-1.html" rel="nofollow">
       移动端实时音视频直播技术详解（一）：开篇
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-955-1-1.html" rel="nofollow">
       移动端实时音视频直播技术详解（二）：采集
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-960-1-1.html" rel="nofollow">
       移动端实时音视频直播技术详解（三）：处理
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-965-1-1.html" rel="nofollow">
       移动端实时音视频直播技术详解（四）：编码和封装
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-967-1-1.html" rel="nofollow">
       移动端实时音视频直播技术详解（五）：推流和传输
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-972-1-1.html" rel="nofollow">
       移动端实时音视频直播技术详解（六）：延迟优化
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-875-1-1.html" rel="nofollow">
       理论联系实际：实现一个简单地基于HTML5的实时视频直播
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-939-1-1.html" rel="nofollow">
       IM实时音视频聊天时的回声消除技术详解
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-953-1-1.html" rel="nofollow">
       浅谈实时音视频直播中直接影响用户体验的几项关键技术指标
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1008-1-1.html" rel="nofollow">
       如何优化传输机制来实现实时音视频的超低延迟？
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1033-1-1.html" rel="nofollow">
       首次披露：快手是如何做到百万观众同场看直播仍能秒开且不卡顿的？
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1154-1-1.html" rel="nofollow">
       Android直播入门实践：动手搭建一套简单的直播系统
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1254-1-1.html" rel="nofollow">
       网易云信实时视频直播在TCP数据传输层的一些优化思路
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1281-1-1.html" rel="nofollow">
       实时音视频聊天技术分享：面向不可靠网络的抗丢包编解码器
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1289-1-1.html" rel="nofollow">
       P2P技术如何将实时视频直播带宽降低75%？
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1201-1-1.html" rel="nofollow">
       专访微信视频技术负责人：微信实时视频聊天技术的演进
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1308-1-1.html" rel="nofollow">
       腾讯音视频实验室：使用AI黑科技实现超低码率的高清实时视频聊天
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1311-1-1.html" rel="nofollow">
       微信团队分享：微信每日亿次实时音视频聊天背后的技术解密
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1369-1-1.html" rel="nofollow">
       近期大热的实时直播答题系统的实现思路与技术难点分享
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1395-1-1.html" rel="nofollow">
       福利贴：最全实时音视频开发要用到的开源工程汇总
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1406-1-1.html" rel="nofollow">
       七牛云技术分享：使用QUIC协议实现实时视频直播0卡顿！
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1465-1-1.html" rel="nofollow">
       实时音视频聊天中超低延迟架构的思考与技术实践
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1553-1-1.html" rel="nofollow">
       理解实时音视频聊天中的延时问题一篇就够
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1564-1-1.html" rel="nofollow">
       实时视频直播客户端技术盘点：Native、HTML5、WebRTC、微信小程序
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1620-1-1.html" rel="nofollow">
       写给小白的实时音视频技术入门提纲
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1746-1-1.html" rel="nofollow">
       微信多媒体团队访谈：音视频开发的学习、微信的音视频技术和挑战等
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1799-1-1.html" rel="nofollow">
       腾讯技术分享：微信小程序音视频技术背后的故事
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1828-1-1.html" rel="nofollow">
       微信多媒体团队梁俊斌访谈：聊一聊我所了解的音视频技术
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1843-1-1.html" rel="nofollow">
       新浪微博技术分享：微博短视频服务的优化实践之路
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1904-1-1.html" rel="nofollow">
       实时音频的混音在视频直播应用中的技术原理和实践总结
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1915-1-1.html" rel="nofollow">
       以网游服务端的网络接入层设计为例，理解实时通信的技术挑战
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-1988-1-1.html" rel="nofollow">
       腾讯技术分享：微信小程序音视频与WebRTC互通的技术思路和实践
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-2022-1-1.html" rel="nofollow">
       新浪微博技术分享：微博实时直播答题的百万高并发架构实践
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-2087-1-1.html" rel="nofollow">
       技术干货：实时视频直播首屏耗时400ms内的优化实践
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-3028-1-1.html" rel="nofollow">
       爱奇艺技术分享：轻松诙谐，讲解视频编解码技术的过去、现在和将来
      </a>
      》
      <br/>
      《
      <a href="http://www.52im.net/thread-3079-1-1.html" rel="nofollow">
       零基础入门：实时音视频技术基础知识全面盘点
      </a>
      》
      <br/>
      &gt;&gt;
      <a href="http://www.52im.net/forum.php?mod=collection&amp;action=view&amp;ctid=4" rel="nofollow">
       更多同类文章 ……
      </a>
     </p>
    </blockquote>
    <p>
     <strong>
      本文已同步发布于“即时通讯技术圈”公众号：
     </strong>
    </p>
    <p>
     <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/d91523df23f3a85eb597efd125597994.png"/>
    </p>
    <p>
     本文在公众号上的链接是：
     <a href="https://mp.weixin.qq.com/s/0YKtG5o_rNejUrvDGGmMrA" rel="nofollow">
      点此进入
     </a>
     ，原文链接是：
     <a href="http://www.52im.net/thread-3169-1-1.html" rel="nofollow">
      http://www.52im.net/thread-3169-1-1.html
     </a>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e637364:6e2e6e65742f68656c6c6f6a61636b6a69616e67323031312f:61727469636c652f64657461696c732f313038383538393036" class_="artid" style="display:none">
 </p>
</div>


