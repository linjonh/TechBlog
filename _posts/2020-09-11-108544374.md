---
layout: post
title: "你的大数据平台中病毒了记一次HDP生产环境中dr.who病毒并修复的过程"
date: 2020-09-11 07:00:00 +0800
description: "有些事还是经历过了才知道“小心驶得万年船”的道理啊。最近笔者帮一个客户安装HDP2.6.5版本的大数"
keywords: "你的大数据平台中病毒了！！！记一次HDP生产环境中dr.who病毒并修复的过程"
categories: ['未分类']
tags: ['运维', 'Linux', 'Java', 'Hadoop', 'Docker']
artid: "108544374"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=108544374
  alt: "你的大数据平台中病毒了记一次HDP生产环境中dr.who病毒并修复的过程"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     你的大数据平台中病毒了！！！记一次HDP生产环境中dr.who病毒并修复的过程
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <div id="js_content">
     <p>
      <img src="https://i-blog.csdnimg.cn/blog_migrate/3688b7d0679473c0f17a41e2f39d80ac.png"/>
     </p>
     <p>
      有些事还是经历过了才知道“小心驶得万年船”的道理啊。最近笔者帮一个客户安装HDP2.6.5版本的大数据平台，最重要的是，这次安装的背景是生产环境的云平台迁移，不是普通的开发阶段或者上线阶段。
      <br/>
     </p>
     <p>
      刚开始拿到系统，自然一片空白，因此有些掉以轻心了。由于是云平台且是新到位的环境，为了方便安装，便直接开了全部网络访问来安装。经过一两天的折腾（过程自不必详述，不是本文的重点），终于完成一个master节点、一个standby节点+3个datanode节点的hdp安装。由于经验不足，加上工作疏忽，忘记了提醒客户调整网络策略，于是两天后悲剧就发生了。
      <br/>
     </p>
     <p>
      最开始出现的症状是，mapreduce任务和hive任务都跑的巨慢，
      <br/>
     </p>
     <p>
      深入看看，发现有两个问题，1.是yarn的nodemanger起不来，2是yarn资源管理上出现了一些奇怪的进程，如下：
      <br/>
     </p>
     <p style="text-align: center">
      <img src="https://i-blog.csdnimg.cn/blog_migrate/721338596a7b55721438b362031f8f51.png"/>
     </p>
     <p>
      很明显，看到dr.who这么异常的用户，我们马上感觉不对劲，各种百度找原因，最后确认我们中毒了。重点关注到的是下面的文章，但是很遗憾，没用给出对应的解决方案。
      <br/>
     </p>
     <p style="text-align: center">
      <img src="https://i-blog.csdnimg.cn/blog_migrate/f7c43d610476d255262e6a53840e9cc2.png"/>
     </p>
     <p>
     </p>
     <p>
      网上找了一些资源，一开始就是蒙的，只能求助于云平台。虽然工作很久了，但是以前的Linux环境大多都是内部网络，第一次接触到Linux中毒的情况。结果云平台又是断网查杀，又是重启，可是最终还是没能解决我们的问题，唯一给出的消息就是，经过诊断，三台datanode中毒了，另外两台maser节点没问题。当时距离迁移结束尚有四五天的时间，于是在苦恼两天以后，决定重新安装datanode。云平台给的建议也是重装系统。
     </p>
     <p>
      经过一番苦战，我们把三台datanode节点下线以后，直接重置系统，全部清空。然后安装ambari-agent，让ambari-server和ambari-agent建立通信，在三个ambari-agent上初始化客户端+datanode+nodemaneger等。初始化完成以后，也遇到一个问题，这里也记录一下。需要执行hdfs hadoop  dfsadmin -safemode leave让集群离开安全模式，然后删除丢失文件的目录。重新安装以后，经过一番折腾，恢复数据和文件，终于把集群又运行起来了。
     </p>
     <p>
      然而，命运总是喜欢开玩笑。在系统稳定运行一周后，由于云平台管理人员的失误，本应针对应用服务器开放8080端口的需求误操作成对所有云平台开放8080端口，于是已经在生成环境的服务器再次出现故障，nodemanger每次一启动就down掉。联系云厂商，再次杀掉，折腾了一台以后未见任何进展。我们利用周末时间翻遍了百度、谷歌、必应的各种文章以后，仍未找到合理的解决方案。
     </p>
     <p>
      在周一即将到来、系统即将迎来大面积访问的关头，我们都做好了要再次重装datanode的准备，然而另外一位同事部署的kafka程序及spark程序不愿意再次配合修改，因此我们只能选择再推迟一天重装来解决此问题。
     </p>
     <p>
      在周日的晚上十一点多，点的外卖到了一个多小时还没吃的时候，我最后一次尝试卸载一个节点的nodemanger然后重装，在启动的时候偶然遇到错误，提示里面有dr.who的错误，让我意识了这么多次nodemanger一启动就down掉并且不报错可能跟这个病毒有关。
     </p>
     <p style="text-align: center">
      <img src="https://i-blog.csdnimg.cn/blog_migrate/c603dc36d54e69351e2b8efc4ab62386.png"/>
     </p>
     <p>
      于是我开始在网上查找相关资料。最有用的是下面这篇博文，https://www.cnblogs.com/daxiangfei/p/9198856.html，然而内容过于简单，只给了解题思路，没用给解题步骤。
     </p>
     <p style="text-align: center">
      <img src="https://i-blog.csdnimg.cn/blog_migrate/a8a55bd3d3172bef5690aa91e626d5c4.png"/>
     </p>
     <p>
      参照本文的说明，我现实在yarn用户的crontab找到系统定时任务，虽然已经注释，但是我还是手动删掉了。
     </p>
     <p style="text-align: center">
      <img src="https://i-blog.csdnimg.cn/blog_migrate/5b5652c3dd748df97c90a543cfd98d00.png"/>
     </p>
     <p>
      由于定时任务是yarn用户的，根据经验，我就开始查看yarn用户的进程，ps -ef|grep yarn，于是看到了四个很奇怪的进程，很明显，这就是所谓的挖矿程序。二话不说，我就kill掉了四个进程，然后再次启动nodemanger。在启动过程中我还不是查看yarn的用户的进程，想看看是不是有命令会杀掉nodemanger经常。
     </p>
     <p style="text-align: center">
      <img src="https://i-blog.csdnimg.cn/blog_migrate/702236845440789012ba60d551dd5ef2.png"/>
     </p>
     <p>
      结果就看到了，挖矿程序是伴随这个nodemanger启动的，这是，我有两个怀疑，第一，这个挖矿程序修改了nodemanger启动脚本，嵌入到了nodemanger启动过程中；第二，nodemanger容器中包含挖矿程序，导致nodemanger一启动就要执行挖矿任务，“不堪重负累死了”。从表面上看第一个推理比较合理，于是我认真查找挖矿进程对应的脚本并且进行各种删除，但是多次重启以后还是存在挖矿程序同步启动的情况。于是只能尝试第二种思路，第二个设想从其它博文中看到一句命令后就验证了。yarn top命令可以查看yarn正在运行的进程。
     </p>
     <p style="text-align: center">
      <img src="https://i-blog.csdnimg.cn/blog_migrate/1acc7034aa5543adf1091109bf522792.png"/>
     </p>
     <p>
      这样问题请很清晰了，大量的dr.who的挖矿程序在yarn队列中是提交状态，所以nodemanger一启动就需要开始干活，资源不足或者被挖矿程序抢占了CPU资源所以导致nodemanger启动后马上就悄悄的死掉了。认识到来这一点，我开始查询yarn的其他命令行以及怎么杀死这些任务。
      <br/>
     </p>
     <p>
      在尝试几次批量查杀后发现进程依然没有减少，于是网上百度查找yarn批量查杀进程的方法。
      <br/>
     </p>
     <p style="text-align: center">
      <img src="https://i-blog.csdnimg.cn/blog_migrate/d44762d0081695bb0fb1238402d36ac6.png"/>
     </p>
     <p>
      最后终于找到一个非常好用的命令。在我执行的时候，奇迹出现，dr.who的进程在一个一个得减少，慢慢的mapreduce就出现了，再到后来全部是mapreduce任务和hive任务。这个命令真的很神奇，杀了一堆有害进程，但是对合理的进程全部保留。
      <br/>
     </p>
     <p style="text-align: center">
      <img src="https://i-blog.csdnimg.cn/blog_migrate/6749cf9b9e2254178d991666225a87b1.png"/>
     </p>
     <h3>
      # 删除处于ACCEPTED状态的任务
      <br/>
      for i in  `yarn application  -list | grep -w  ACCEPTED | awk '{print $1}' | grep application_`; do yarn  application -kill $i; done
     </h3>
     <p>
      这是我终于看到了曙光。我在保障所有节点的yarn用户crontab里面没用定时任务以后，登录ambari开始启动nodemanger。正当我点开页面的时候，奇迹出现了，所有的nodemanger满血复活。
      <br/>
     </p>
     <p style="text-align: center">
      <img src="https://i-blog.csdnimg.cn/blog_migrate/0f32ec0f86204810598068d76943dd2e.png"/>
     </p>
     <p>
      等我重新提交任务以后，yarn平台也正是恢复正常，tez和mapreduce任务正常执行。
      <br/>
     </p>
     <p style="text-align: center">
      <img src="https://i-blog.csdnimg.cn/blog_migrate/a41abe8e8f16246e33ff77754d7eac8d.png"/>
     </p>
     <p>
      于是，在产生更严重的生产事故之前，hdp平台就这样被我修复了。经过一天的稳定运行，平台也安然无恙。至此，我修复了一次重大的生成事故。
      <br/>
     </p>
     <p>
      最后补充说一下，可能由于挖矿程序的升级，"检查/tmp和/var/tmp目录，删除java、ppc、w.conf等异常文件"这一条已经完全失效了，找不到任何对应的文件。        总结一下，远程木马通过yarn的8080端口提交了包含挖矿程序的shell脚本任务给yarn执行，yarn执行以后就产生了crontab定时任务和挖矿进程。由于木马一次性提交了大量（大概一两百个）的相同任务给yarn，所以杀死一两个并不能解决问题，只有全部杀死，才能再次启动nodemanger。
     </p>
     <p style="text-align: center">
      历史好文推荐
     </p>
     <ol>
      <li>
       <p>
        <a href="http://mp.weixin.qq.com/s?__biz=MzI4MzE4MjQxOQ%3D%3D&amp;chksm=f3903004c4e7b9127b2de3f761cfc57fd5265bc8aa6cd4908cbd13fea7d39bc70b1f347bc0d9&amp;idx=1&amp;mid=2649359416&amp;scene=21&amp;sn=42e67d8c8ce58d426e211f8f3f282145#wechat_redirect" rel="nofollow">
         从0到1搭建大数据平台之计算存储系统
        </a>
        <br/>
       </p>
      </li>
      <li>
       <p>
        <a href="http://mp.weixin.qq.com/s?__biz=MzI4MzE4MjQxOQ%3D%3D&amp;chksm=f39037d2c4e7bec4c65872248003b150013bbc9d3a9dbeba59578ef495473a7ae06daf104396&amp;idx=1&amp;mid=2649359342&amp;scene=21&amp;sn=2607bc9d074ae20ef861bd0f46f14880#wechat_redirect" rel="nofollow">
         从0到1搭建大数据平台之调度系统
        </a>
        <br/>
       </p>
      </li>
      <li>
       <p>
        <a href="http://mp.weixin.qq.com/s?__biz=MzI4MzE4MjQxOQ%3D%3D&amp;chksm=f39037eec4e7bef88473d7c8d9d99e266c81b7699c2b9865df2685f6f3f330728fdd32487132&amp;idx=1&amp;mid=2649359314&amp;scene=21&amp;sn=0650b017466e9a571cee9b03b62519e2#wechat_redirect" rel="nofollow">
         从0到1搭建大数据平台之数据采集系统
        </a>
        <br/>
       </p>
      </li>
      <li>
       <p>
        <a href="http://mp.weixin.qq.com/s?__biz=MzI4MzE4MjQxOQ%3D%3D&amp;chksm=f3903796c4e7be802317b9a9e27133099f110b3de571a3706ebcff5739c53e4d431a7505f4d9&amp;idx=1&amp;mid=2649359274&amp;scene=21&amp;sn=fa545fd207e2acf41a0c36b5d60482fe#wechat_redirect" rel="nofollow">
         如何从0到1搭建大数据平台
        </a>
        <br/>
       </p>
      </li>
     </ol>
     <p style="text-align: center">
      <img src="https://i-blog.csdnimg.cn/blog_migrate/fd825f4cc6595202dee3030c228298e0.png"/>
     </p>
    </div>
   </div>
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f57696e64795143462f:61727469636c652f64657461696c732f313038353434333734" class_="artid" style="display:none">
 </p>
</div>
