---
layout: post
title: "基于FFmpeg和Android的音视频同步播放实现"
date: 2025-01-11 23:25:44 +0800
description: "前言在以前的博文中，我们通过FFmpeg解码，并基于OpenGL ES完成了视频的渲染，也完成了基于"
keywords: "playerbufferqueue"
categories: ['Ffmpeg']
tags: ['音视频同步', '视频渲染', 'Opensl', 'Ffmpegavsync', 'Ffmpeg', 'Es']
artid: "80785764"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=80785764
    alt: "基于FFmpeg和Android的音视频同步播放实现"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     基于FFmpeg和Android的音视频同步播放实现
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h3 id="前言">
     前言
    </h3>
    <p>
     在以前的博文中，我们通过FFmpeg解码，并基于OpenGL ES完成了视频的渲染，也完成了基于OpenSL ES实现的native音频注入播放。 本文将这两部分代码进行合并，并实现音视频的同步播放。
    </p>
    <h3 id="实现需求">
     实现需求
    </h3>
    <ol>
     <li>
      基于FFmpeg实现视频解码，并通过OpenGL ES进行渲染；
     </li>
     <li>
      基于OpenSL ES进行PCM注入播放；
     </li>
     <li>
      播放时进行音视频同步；
     </li>
    </ol>
    <h3 id="关于音视频同步原理">
     关于音视频同步原理
    </h3>
    <p>
     本文不打算详细介绍音视频同步的基本原理，网上关于这部分的资源很多。简单的来说，是音视频在编码时，在音频和视频PES包中，打入时间戳信息（PTS），那么在终端解码时，由于音频解码和视频解码的速度可能不一致，如果不进行同步操作，可能声音和画面就不同步了，造成画面超前或者滞后于声音。
     <br/>
     一般来说，声音的播放时固定采样率的，所以声音的播放本身是平滑的，因此我们往往基于音频播放的基准（PTS）来进行视频同步，让视频画面的播放速度来匹配音频的解码速度。
    </p>
    <h3 id="音频同步实现">
     音频同步实现
    </h3>
    <p>
     由于参考了前述博文视频和音频播放，所以原理部分不再阐述，重点描述同步相关的代码实现。关注如下两个函数：
    </p>
    <pre class="prettyprint"><code class="hljs cs"><span class="hljs-keyword">double</span> get_audio_clock() {
    <span class="hljs-keyword">double</span> pts;
    <span class="hljs-keyword">int</span> hw_buf_size, bytes_per_sec, n;

    pts = audio_clock;

    bytes_per_sec = <span class="hljs-number">0</span>;
    n = global_context.acodec_ctx-&gt;channels * <span class="hljs-number">2</span>;
    bytes_per_sec = global_context.acodec_ctx-&gt;sample_rate * n;
    hw_buf_size = last_enqueue_buffer_size
            - (<span class="hljs-keyword">double</span>(av_gettime() - last_enqueue_buffer_time) / <span class="hljs-number">1000000.0</span>)
                    * bytes_per_sec;
    <span class="hljs-keyword">if</span> (bytes_per_sec) {
        pts -= (<span class="hljs-keyword">double</span>) hw_buf_size / bytes_per_sec;
    }

    <span class="hljs-comment">//LOGV2("get_audio_clock:pts is %ld", pts);</span>
    <span class="hljs-keyword">return</span> pts;
}
<span class="hljs-comment">// this callback ha</span>

ndler <span class="hljs-keyword">is</span> called every time a buffer finishes playing
<span class="hljs-keyword">void</span> bqPlayerCallback(SLAndroidSimpleBufferQueueItf bq, <span class="hljs-keyword">void</span> *context) {
    SLresult result;

    <span class="hljs-comment">//LOGV2("bqPlayerCallback...");</span>

    <span class="hljs-keyword">if</span> (bq != bqPlayerBufferQueue) {
        LOGV2(<span class="hljs-string">"bqPlayerCallback : not the same player object."</span>);
        <span class="hljs-keyword">return</span>;
    }

    <span class="hljs-keyword">int</span> decoded_size = audio_decode_frame(decoded_audio_buf,
            <span class="hljs-keyword">sizeof</span>(decoded_audio_buf));
    <span class="hljs-keyword">if</span> (decoded_size &gt; <span class="hljs-number">0</span>) {
        result = (*bqPlayerBufferQueue)-&gt;Enqueue(bqPlayerBufferQueue,
                decoded_audio_buf, decoded_size);
        last_enqueue_buffer_time = av_gettime();
        last_enqueue_buffer_size = decoded_size;
        <span class="hljs-comment">// the most likely other result is SL_RESULT_BUFFER_INSUFFICIENT,</span>
        <span class="hljs-comment">// which for this code example would indicate a programming error</span>
        <span class="hljs-keyword">if</span> (SL_RESULT_SUCCESS != result) {
            LOGV2(<span class="hljs-string">"bqPlayerCallback : bqPlayerBufferQueue Enqueue failure."</span>);
        }
    }
}
</code></pre>
    <p>
     我们知道bqPlayerCallback函数是注册给OpenSL ES的接口函数，当解码芯片音频数据消耗完毕时，会调用此函数，我们在这个函数里存储了两个变量，
    </p>
    <pre class="prettyprint"><code class="hljs ini"><span class="hljs-setting">last_enqueue_buffer_time = <span class="hljs-value">av_gettime();</span></span>
<span class="hljs-setting">last_enqueue_buffer_size = <span class="hljs-value">decoded_size;</span></span></code></pre>
    <p>
     其中，last_enqueue_buffer_time保存当前的系统时间，last_enqueue_buffer_size存储注入的数据大小。
     <br/>
     接下来，函数get_audio_clock（），是获取音频时钟信息的，返回单位是秒，一般是浮点数，这里重点注意如下代码段，
    </p>
    <pre class="prettyprint"><code class="hljs cs">pts = audio_clock;

    bytes_per_sec = <span class="hljs-number">0</span>;
    n = global_context.acodec_ctx-&gt;channels * <span class="hljs-number">2</span>;
    bytes_per_sec = global_context.acodec_ctx-&gt;sample_rate * n;
    hw_buf_size = last_enqueue_buffer_size
            - (<span class="hljs-keyword">double</span>(av_gettime() - last_enqueue_buffer_time) / <span class="hljs-number">1000000.0</span>)
                    * bytes_per_sec;
    <span class="hljs-keyword">if</span> (bytes_per_sec) {
        pts -= (<span class="hljs-keyword">double</span>) hw_buf_size / bytes_per_sec;
    }

    <span class="hljs-keyword">return</span> pts;</code></pre>
    <p>
     全局变量audio_clock保存的是最后一次解码音频帧的时钟（时间戳）信息，n表示每声道存储的字节数，这里是16bit格式，所以乘以2。bytes_per_sec表示每秒钟消耗的音频字节数，根据采样率和n计算得到。hw_buf_size表示芯片音频缓存区里剩余未解码的音频数据大小，这里依赖保存的变量last_enqueue_buffer_size和last_enqueue_buffer_time计算得到，很好理解，最后就可以计算得到当前的音频时钟pts并返回。
    </p>
    <h3 id="视频同步实现">
     视频同步实现
    </h3>
    <p>
     视频的同步相对复杂一点，首先建立了两个线程，一个负责解码即video_thread线程，一个负责视频渲染即picture_thread线程，解码后的视频帧（即picture）存储在一个队列中，我们定义成，
     <br/>
     VideoPicture pictq[VIDEO_PICTURE_QUEUE_SIZE];
     <br/>
     放在GlobalContext全局上下文中。
     <br/>
     视频渲染线程picture_thread中，每一帧视频渲染的时间点，是由timer_delay_ms延时时间决定的，而每一帧视频的timer_delay_ms延时时间的计算主要由如下函数计算得到，
    </p>
    <pre class="prettyprint"><code class="hljs perl">void video_refresh_timer() {
    VideoPicture <span class="hljs-variable">*vp</span>;
    double actual_delay, delay, sync_threshold, ref_clock, diff;

    <span class="hljs-keyword">if</span> (global_context.pictq_size == <span class="hljs-number">0</span>) {
        schedule_refresh(<span class="hljs-number">1</span>);
    } <span class="hljs-keyword">else</span> {
        vp = &amp;global_context.pict<span class="hljs-string">q[global_context.pictq_rindex]</span>;

        video_current_pts = vp-&gt;pts;
        global_context.video_current_pts_time = av_gettime();

        delay = vp-&gt;pts - global_context.frame_last_pts;

        <span class="hljs-keyword">if</span> (delay &lt;= <span class="hljs-number">0</span> || delay &gt;= <span class="hljs-number">1.0</span>) { <span class="hljs-regexp">//</span> 非法值判断
            delay = global_context.frame_last_delay;
        }

        global_context.frame_last_delay = delay;
        global_context.frame_last_pts = vp-&gt;pts;

        ref_clock = get_master_clock();
        diff = vp-&gt;pts - ref_clock;

        sync_threshold =
                (delay &gt; AV_SYNC_THRESHOLD) ? delay : AV_SYNC_THRESHOLD;
        <span class="hljs-keyword">if</span> (fabs(diff) &lt; AV_NOSYNC_THRESHOLD) {
            <span class="hljs-keyword">if</span> (diff &lt;= -sync_threshold) {
                <span class="hljs-regexp">//av</span>_log(NULL, AV_LOG_ERROR, <span class="hljs-string">"video_refresh_timer : skip. \n"</span>);
                LOGV(<span class="hljs-string">"video_refresh_timer : skip. \n"</span>);
                delay = <span class="hljs-number">0</span>;
            } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (diff &gt;= sync_threshold) {
                <span class="hljs-regexp">//av</span>_log(NULL, AV_LOG_ERROR, <span class="hljs-string">"video_refresh_timer : repeat. \n"</span>);
                LOGV(<span class="hljs-string">"video_refresh_timer : repeat. \n"</span>);
                delay = <span class="hljs-number">2</span> * delay;
            }
        } <span class="hljs-keyword">else</span> {
            <span class="hljs-regexp">//av</span>_log(NULL, AV_LOG_ERROR,
            <span class="hljs-regexp">//</span>      <span class="hljs-string">" video_refresh_timer : diff &gt; 10 , diff = <span class="hljs-variable">%f</span>, vp-&gt;pts = <span class="hljs-variable">%f</span> , ref_clock = <span class="hljs-variable">%f</span>\n"</span>,
            <span class="hljs-regexp">//</span>      diff, vp-&gt;pts, ref_clock);
            LOGV(
                    <span class="hljs-string">" video_refresh_timer : diff &gt; 10 , diff = <span class="hljs-variable">%f</span>, vp-&gt;pts = <span class="hljs-variable">%f</span> , ref_clock = <span class="hljs-variable">%f</span>\n"</span>,
                    diff, vp-&gt;pts, ref_clock);
        }

        global_context.frame_timer += delay;

        actual_delay = global_context.frame_timer - (av_gettime() / <span class="hljs-number">1000000.0</span>);
        <span class="hljs-keyword">if</span> (actual_delay &lt; <span class="hljs-number">0</span>.<span class="hljs-number">010</span>) {    <span class="hljs-regexp">//</span>每秒<span class="hljs-number">100</span>帧的刷新率不存在

            actual_delay = <span class="hljs-number">0</span>.<span class="hljs-number">010</span>;
        }
        schedule_refresh((<span class="hljs-keyword">int</span>) (actual_delay * <span class="hljs-number">1000</span> + <span class="hljs-number">0</span>.<span class="hljs-number">5</span>)); <span class="hljs-regexp">//add</span> <span class="hljs-number">0</span>.<span class="hljs-number">5</span> <span class="hljs-keyword">for</span> 进位
        <span class="hljs-keyword">if</span> (vp-&gt;pFrame)
            video_display(vp-&gt;pFrame);

        <span class="hljs-keyword">if</span> (++global_context.pictq_rindex &gt;= VIDEO_PICTURE_QUEUE_SIZE) {
            global_context.pictq_rindex = <span class="hljs-number">0</span>;
        }

        pthread_mutex_lock(&amp;global_context.pictq_mutex);
        global_context.pictq_size--;
        pthread_cond_signal(&amp;global_context.pictq_cond);
        pthread_mutex_unlock(&amp;global_context.pictq_mutex);
    }
}
</code></pre>
    <p>
     其中，get_master_clock（）函数获取系统时钟，我们这里一般配置成音频的解码时间戳（PTS），然后计算视频时间戳和参考时间的差值，
    </p>
    <pre class="prettyprint"><code class="hljs ini"><span class="hljs-setting">ref_clock = <span class="hljs-value">get_master_clock();</span></span>
<span class="hljs-setting">diff = <span class="hljs-value">vp-&gt;pts - ref_clock;</span></span></code></pre>
    <p>
     以下代码判断差值的大小，如果小于门限值，则不延时，也就是说要迅速播放下一帧，类似于快进，如果大于门限值，则延时加倍，也就是说要慢点播放下一帧，当然可能一帧并不能马上达到音视频之间的同步，但是可以通过多帧的累积，最终使两者同步。
    </p>
    <pre class="prettyprint"><code class="hljs ruby"><span class="hljs-keyword">if</span> (diff &lt;= -sync_threshold) {
    <span class="hljs-regexp">//av</span>_log(<span class="hljs-constant">NULL</span>, <span class="hljs-constant">AV_LOG_ERROR</span>, <span class="hljs-string">"video_refresh_timer : skip. \n"</span>);
    <span class="hljs-constant">LOGV</span>(<span class="hljs-string">"video_refresh_timer : skip. \n"</span>);
    delay = <span class="hljs-number">0</span>;
} <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (diff &gt;= sync_threshold) {
    <span class="hljs-regexp">//av</span>_log(<span class="hljs-constant">NULL</span>, <span class="hljs-constant">AV_LOG_ERROR</span>, <span class="hljs-string">"video_refresh_timer : repeat. \n"</span>);
    <span class="hljs-constant">LOGV</span>(<span class="hljs-string">"video_refresh_timer : repeat. \n"</span>);
    delay = <span class="hljs-number">2</span> * delay;
}</code></pre>
    <p>
     注意video_refresh_timer（）函数中，还有一个actual_delay变量，奇怪的是，delay变量就行了，为何还有个actual_delay变量呢？原来，我们的程序在处理视频数据或者执行时，总要消耗时间，因此实际的delay时间总是要小于上述计算得到的delay值，actual_delay的计算如下，frame_timer是记录的上一次帧显示的系统时间加上了delay的值，av_gettime（）是当前的系统时间，两者的差值刚好是下一帧图像显示的延时时间。
    </p>
    <pre class="prettyprint"><code class="hljs fix"><span class="hljs-attribute">actual_delay </span>=<span class="hljs-string"> global_context.frame_timer - (av_gettime() / 1000000.0);</span></code></pre>
    <p>
     下面函数完成一帧图像的显示，这和以前博文介绍的实现方法一致。
    </p>
    <pre class="prettyprint"><code class="hljs haskell"><span class="hljs-title">video_display</span>(vp-&gt;pFrame);</code></pre>
    <h3 id="几个时间变量">
     几个时间变量
    </h3>
    <p>
     关于代码中出现的几个关于时间的变量，分别解释如下：
    </p>
    <pre class="prettyprint"><code class="hljs haskell"><span class="hljs-title">pFrame</span>-&gt;pkt_pts
这个是码流里存储的<span class="hljs-type">PTS</span>值，就是一个计数器，相对于时基的一个计数值

<span class="hljs-title">av_q2d</span>(global_context.vstream-&gt;time_base)
把分数的时基，转成浮点数（double）型的时间基准，就是最小分辨率时间段吧

<span class="hljs-title">pFrame</span>-&gt;pkt_pts*av_q2d(global_context.vstream-&gt;time_base)
这是把码流里的<span class="hljs-type">PTS</span>计数值，转换成时间戳的形式，单位是秒（如<span class="hljs-number">0.0001</span>秒）

<span class="hljs-title">av_gettime</span>
获取当前系统时间，单位微秒us

<span class="hljs-title">vp</span>-&gt;pts = pFrame-&gt;pkt_pts*av_q2d(global_context.vstream-&gt;time_base)
当前要显示的帧的时间戳，单位是秒（如<span class="hljs-number">0.0001</span>秒），是 倍数*（<span class="hljs-number">1</span>/时基）

<span class="hljs-title">video_current_pts</span>
保留最后刷新的帧的vp-&gt;pts值

<span class="hljs-title">global_context</span>.video_current_pts_time
当前显示帧时的系统时间，单位微秒


<span class="hljs-title">global_context</span>.frame_last_pts
看起来和video_current_pts一个意思？最后刷新的帧的vp-&gt;pts值


<span class="hljs-title">global_context</span>.frame_last_delay
记录最后的延时时间，用于下次<span class="hljs-type">PTS</span>非法或者跳变时，采用上一次的值

<span class="hljs-title">global_context</span>.frame_timer
用于帧的定时器时间计算，单位微秒

<span class="hljs-title">delay</span> = vp-&gt;pts - global_context.frame_last_pts

<span class="hljs-title">get_master_clock</span>（）
返回系统的pts时间戳，是 倍数*（<span class="hljs-number">1</span>/时基）

<span class="hljs-title">delay</span> = vp-&gt;pts - global_context.frame_last_pts
两帧之间的时间戳差值

<span class="hljs-title">diff</span> = vp-&gt;pts - ref_clock
当前帧和系统时钟之间的差值

<span class="hljs-title">global_context</span>.frame_timer
应该是指每一帧视频的显示时刻，单位是秒，记住程序open媒体的时候有一个初始值</code></pre>
    <h3 id="遗留问题">
     遗留问题
    </h3>
    <ol>
     <li>
      本程序在解码avi等视频格式时，无法播出图像，应该是avcodec_decode_video2解码后的数据是分段的，并不能一次完整解出；
     </li>
     <li>
      在我的测试机器上，宏定义VIDEO_PICTURE_QUEUE_SIZE取值不同时，视频可能会出现跳帧卡顿的现象，调整到30帧时，表现最好，具体原因没有查到。
     </li>
    </ol>
    <h3 id="github源码">
     GitHub源码
    </h3>
    <p>
     请参考完整的源码路径：
     <br/>
     <a href="https://github.com/ericbars/FFmpegAVSync">
      https://github.com/ericbars/FFmpegAVSync
     </a>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470:733a2f2f626c6f672e6373646e2e6e65742f65726963626172:2f61727469636c652f64657461696c732f3830373835373634" class_="artid" style="display:none">
 </p>
</div>


