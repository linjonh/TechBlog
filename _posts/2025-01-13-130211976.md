---
layout: post
title: "时空序列全球气象预测大模型-OpenCastKit-正式开源"
date: 2025-01-13 09:58:02 +0800
description: "OpenCastKit 是幻方 AI 开源的 AI 气象大模型工具包，包含了两大气象 SOTA 模型"
keywords: "opencastkit"
categories: ['']
tags: ['深度学习', '人工智能']
artid: "130211976"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=130211976
    alt: "时空序列全球气象预测大模型-OpenCastKit-正式开源"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     【时空序列】全球气象预测大模型 OpenCastKit 正式开源
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <div id="js_content">
     <p>
      <img alt="e8f7ee70066a45d0367f0f83707b079f.jpeg" src="https://i-blog.csdnimg.cn/blog_migrate/9a1aff1c3789c9624d1909ff61ec1929.jpeg"/>
     </p>
     <p>
      OpenCastKit 是幻方 AI 开源的 AI 气象大模型工具包，包含了两大气象 SOTA 模型 FourCastNet 和 GraphCast，并提供完整参数开源。用户可以轻松得通过该大模型输出全球高分辨率的气象预测结果。
     </p>
     <p>
      <strong>
       Open
      </strong>
     </p>
     <p>
      <strong>
       CastKit
      </strong>
     </p>
     <p>
      用 AI 方法对
      <strong>
       现
      </strong>
      <strong>
       代数值天气预报
      </strong>
      （numerical weather prediction, NWP）进行改进提升近两年受到了广泛关注，如 Nvidia 发布的 FourCastNet、 DeepMind 发布的 GraphCast 和华为发布的盘古气象大模型，在与欧洲中期天气预报中心（ECMWF）的高分辨率综合预测系统（IFS）对比中都获得了不错的效果。
     </p>
     <p>
      基于此，我们最近复现整合了这些工作，并将这些成果贡献给开源社区。我们基于 FourCastNet 和 GraphCast 论文构建了一个新的全球AI气象预测项目——
      <strong>
       OpenCastKit
      </strong>
      。
     </p>
     <p>
      <img alt="c8404d7c18231b92a41ad595bffa21af.png" src="https://i-blog.csdnimg.cn/blog_migrate/afd9f7e8dafad9dc5a41b0cb2b875e6b.png"/>
     </p>
     <p style="text-align:center;">
      项目地址：https://github.com/HFAiLab/OpenCastKit
     </p>
     <p>
      这个项目提供了一个强大的、基于ERA5数据训练的开源气象模型和参数，可以生成全球高分辨率的气象预测结果。具体来说，它包含：
     </p>
     <ul>
      <li>
       <p>
        一个统一的数据处理工具，抽取ERA5数据和特征并整理成高性能训练数据格式
        <a href="" rel="nofollow">
         ffrecord
        </a>
        ；
       </p>
      </li>
      <li>
       <p>
        基于
        <a href="" rel="nofollow">
         hfai 算子
        </a>
        和
        <a href="" rel="nofollow">
         hfreduce 并行通信
        </a>
        优化的 FourCastNet 模型源码和 GraphCast 模型源码，供社区研究优化；
       </p>
      </li>
      <li>
       <p>
        基于1979年到2022年15TB的ERA5数据，在萤火高性能集群上训练的模型参数，可以进行微调，获得高精度预测结果。
       </p>
      </li>
     </ul>
     <p>
      同时，我们上线了一个每日更新的
      <strong>
       HF-Earth
      </strong>
      ，展示气象大模型输出的全球预测效果：
     </p>
     <p>
      <img alt="4971a93cee196a8c09c693790236134a.png" src="https://i-blog.csdnimg.cn/blog_migrate/12b6d5c271f53ea8d4b88cf5356c8668.png"/>
     </p>
     <p style="text-align:center;">
      Demo地址：https://www.high-flyer.cn/hf-earth/
     </p>
     <p>
      经过一段时间的测试来看，AI气象大模型对台风、极端降水等事件的预测上效果明显，在长期气候变化的分析中可以起到一定作用。希望在此开源项目的基础上，构建出更加强大的 AI 气象应用。
     </p>
     <p>
      <strong>
       数据集
      </strong>
     </p>
     <p>
      欧洲中期天气预报中心（ECMWF）提供了一个公开可用的综合数据集 ERA5，其将物理模型数据与来自世界各地的观测数据结合起来，形成一个全球完整的、一致的数据集，以小时级到天级不等，提供包括温度、风量、降水、水文、气压等多项全球气象指标数据，供各种气象预报模型学习。
     </p>
     <p style="text-align:left;">
      官方地址：https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5
     </p>
     <p>
      FourCastNet 与 GraphCast 使用了不同规模的 ERA5 数据来训练，产生的预测效果各自不同。前者仅使用了 20 个相关气象指标，包括 4 个不同位势高度下的温度、风速、相对湿度和一些近地表变量，其旨对极端天气、自然灾害进行预警；而后者使用了更加全面的数据，其包含 37 个不同位势高度下的气象指标和 5 个地表气象指标，总计 227 个指标，其旨在对气象变化进行更加全面的评估和预报。
      <br/>
     </p>
     <p>
      对此，我们将这些数据进行了归纳整理，通过
      <a href="" rel="nofollow">
       hfai.datasets
      </a>
      工具进行管理优化。原始数据通过特征处理，转化成 “
      <em>
       X
       <sub>
        t-1
       </sub>
       , X
       <sub>
        t
       </sub>
       → X
       <sub>
        t+1
       </sub>
      </em>
      ” 的模式，通过高性能训练样本格式 ffrecord 进行保存，从而可以在萤火集群中进行高效的并行训练。更多信息可以浏览 hfai 数据集仓库。
     </p>
     <p>
      <strong>
       模型构建和优化
      </strong>
     </p>
     <p>
      为了进行 0.25° 分辨率下的全球气象预测，FourCastNet 采用自适应傅里叶神经算子 AFNO，而 GraphCast 采用了图神经网络。前者计算效率高效，可以灵活且可扩展地建模跨空间和不同指标之间的依赖关系；后者通过构建节点之间的联系，更加详细捕捉如“蝴蝶效应”般的气候因子影响。前者在小 batchsize 上可以进行数据并行以加速训练，而后者球体节点之间的 message passing 参数规模更大，需要进行流水线并行（或称模型并行）的改造，以实现模型的完整训练。
     </p>
     <p>
      <img alt="2c43a0024a8cb901ef880eef894322a4.png" src="https://i-blog.csdnimg.cn/blog_migrate/3a74446c4124862f53718987c9194927.png"/>
     </p>
     <p style="text-align:center;">
      FourCastNet 模型结构
     </p>
     <p>
      <img alt="367f9663e42dbc268464b15de7b58778.png" src="https://i-blog.csdnimg.cn/blog_migrate/cdda1b4d4d90c62e75b178fb9e57633d.png"/>
     </p>
     <p style="text-align:center;">
      GraphCast 模型结构
     </p>
     <p>
      这里我们采用自研的
      <a href="" rel="nofollow">
       haiscale 高性能并行训练工具库
      </a>
      对两种模型进行复现优化。对于 FourCastNet，我们使用
      <em>
       haiscale.ddp
      </em>
      或者
      <em>
       haiscale.fsdp
      </em>
      进行数据并行优化，实验中我们采用小 batchsize 即实现了论文效果的复现；对于 GraphCast，完整参数基本无法塞入单张显卡，因此对于不同的环节，如球体中 grid 节点与 mesh 节点进行message passing，我们需要对其拆分，让其分布在不同的显卡上，通过
      <em>
       haiscale.pipeline
      </em>
      对不同环节进行串联，实现模型并行训练。具体如下：
     </p>
     <p>
      <strong>
       FourCastNet 数据并行
      </strong>
     </p>
     <p>
      FourCastNet 模型的训练包括
      <em>
       pretrian
      </em>
      、
      <em>
       finetune
      </em>
      和
      <em>
       precipitation
      </em>
      三个部分。模型采用递进式，即以
      <em>
       X
       <sub>
        t
       </sub>
      </em>
      作为输入，预测下一步
      <em>
       X
       <sub>
        t+1
       </sub>
      </em>
      。一次训练输出多步，与真值对比计算 loss。如下伪代码所示：
     </p>
     <pre class="has"><code class="language-python">from hfai.datasets import ERA5
from haiscale.ddp import DistributedDataParallel
from torch.utils.data.distributed import DistributedSampler


model = FourCastNet(args).cuda()
model = DistributedDataParallel(model)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)


data = ERA5(split='train')
sampler = DistributedSamper(data, shuffle=True)
dataloader = data.loader(args.batch_szie, sampler=sampler, num_workers=8, pin_memory=True, drop_last=True)


# training ...
for step, (xt0, xt1, xt2, pt2) in enumerate(dataloader):
    xt1_pred = model(xt0)            # pretrain
    xt2_pred = model(xt1_pred)          # finetune
    pt2_pred = model(xt2_pred, precip=True)    # preciptation


    pretrain_loss = criterion(xt1_pred, xt1)
    finttune_loss = criterion(xt2_pred, xt2)
    precip_loss = criterion(pt2_pred, pt2)
    
    # optim ...


# stop hfreduce
model.reducer.stop()</code></pre>
     <p>
      <em>
       haiscale.ddp
      </em>
      默认采用 hfreduce 进行通信优化，我们还可以使用优化算子，加入一行
      <em>
       model = hfai.nn.to_hfai(model)
      </em>
      代码进行进一步加速。在萤火集群上我们使用 96 张 A100 进行数据并行加速，耗时 16~17 个小时左右基本可以完成 FourCastNet 的整体训练。
     </p>
     <p>
      <strong>
       GraphCast 数据并行
      </strong>
     </p>
     <p>
      不同于 FourCastNet，GraphCast 只有主干模型一个，其也是采用递进式，不过以
      <em>
       X
       <sub>
        t-1
       </sub>
       , X
       <sub>
        t
       </sub>
       , T, C, G
      </em>
      作为输入，预测下一步
      <em>
       X
       <sub>
        t+1
       </sub>
      </em>
      。这里
      <em>
       T, C
      </em>
      代表了时间戳信息和地理位置信息，
      <em>
       G
      </em>
      代表所构建的球体 Graph 信息。如下伪代码所示：
     </p>
     <pre class="has"><code class="language-python">from hfai.datasets import ERA5
from haiscale.ddp import DistributedDataParallel
from haiscale.pipeline import PipeDream, make_subgroups, partition
from torch.utils.data.distributed import DistributedSampler


dist.init_process_group(...)
torch.cuda.set_device(local_rank)
rank, world_size = dist.get_rank(), dist.get_world_size()


dp_group, pp_group = make_subgroups(pp_size=pp_size)
dp_rank, dp_size = dp_group.rank(), dp_group.size()
pp_rank, pp_size = pp_group.rank(), pp_group.size()


model = GraphCast_sequentail(args)
model = partition(model, pp_group.rank(), pp_group.size(), balance=[1,1,1,1,1,1,1,1])
model = DistributedDataParallel(model.cuda(), process_group=dp_group)
model = PipeDream(model, args.chunks, process_group=pp_group)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)


data = ERA5(split='train')
sampler = DistributedSamper(data, num_replicas=dp_size, rank=dp_rank, shuffle=True)
dataloader = data.loader(args.batch_szie, sampler=sampler, num_workers=8, pin_memory=True, drop_last=True)
earth_graph = generate_graph(args)


# training ...
for step, (xt0, xt1, xt2) in enumerate(dataloader):
    loss = model.forward_backward(xt0, xt1, earth_graph, criterion=criterion, labels=(xt2,))
    
    # optim ...


# synchronize all processes
model.module.reducer.stop()
dist.barrier()</code></pre>
     <p>
      在使用
      <em>
       haiscale.pipeline
      </em>
      进行流水线并行训练时，需要我们提前将模型进行拆分，通过
      <em>
       haiscale.SequentialModel
      </em>
      进行模型的串联。同时 haiscale 提供了一个统一的 forward_backward 接口，进行样本和标签的统一输入和结果输出。在萤火集群上我们使用 256 张 A100 进行模型并行加速（单节点 8 卡做流水并行，32 节点做数据并行），耗时 3 天左右基本可以完成 GraphCast 的整体训练。
     </p>
     <p>
      关于代码的更多细节可以访问项目地址阅读源码。
     </p>
     <p>
      <strong>
       预测结果
      </strong>
     </p>
     <p>
      参照论文中的评估方式，我们采用递归输出未来多天的预测结果，与真实值对比，通过误差增长曲线来比较不同AI气象大模型的预测效果。如下图所示：
     </p>
     <p style="text-align:center;">
      <img alt="8ba76c86f9fd3640fe167fb2a86197ea.png" src="https://i-blog.csdnimg.cn/blog_migrate/33dbfe12be4321d43e4bc0956db563c4.png"/>
     </p>
     <p>
      可以看到，在进行 14 天的中期天气预报测试中，无论是GraphCast 还是 FourCastNet，递归预测导致误差随时间逐步增长。整体误差上看 GraphCast 考虑了地理时间和地理位置的因素，预测误差比 FourCastNet 要小。受此启发，我们将时间和地理信息加入 FourCastNet 进行模型训练（FourCastNet+），发现最终模型输出的预测误差几乎与 GraphCast 一致。
     </p>
     <p>
      下面我们以 2022 年 6 月 22 日开始连续输出 14 天的预测，展示 OpenCastKit 的预测效果：
     </p>
     <p>
      <img alt="5794b01a96db618fd9462c95f6652f3d.gif" src="https://i-blog.csdnimg.cn/blog_migrate/1bb4ca4c29d9a3a4758b7db6b5c17830.gif"/>
     </p>
     <p style="text-align:center;">
      FourCastNet 温度预测
     </p>
     <p>
      <img alt="d45d607ecb751e65a6a66f77d110e88c.gif" src="https://i-blog.csdnimg.cn/blog_migrate/dfc74d7f5b9b67373c350444bc38e863.gif"/>
     </p>
     <p>
      GraphCast 温度预测
     </p>
     <p>
      <img alt="605571539ea2017a8f84e6fdeeda05a2.gif" src="https://i-blog.csdnimg.cn/blog_migrate/e892a756633fa17adc242045cf81fda5.gif"/>
     </p>
     <p>
      FourCastNet 风力预测
     </p>
     <p>
      <img alt="314c330631d2010cc4a6c8c2726c51b1.gif" src="https://i-blog.csdnimg.cn/blog_migrate/9999b593022be3a40149001d14810e99.gif"/>
     </p>
     <p>
      GraphCast 风力预测
     </p>
     <p>
      <img alt="6d030ba80179aa8cf0ec10110e342d7a.gif" src="https://i-blog.csdnimg.cn/blog_migrate/2493b6c55d666f974c8492a0e8d92fbc.gif"/>
     </p>
     <p>
      真实温度
     </p>
     <p>
      <img alt="a74b52b8dbc3d57b9a5fdee929478cfd.gif" src="https://i-blog.csdnimg.cn/blog_migrate/2b9517c789a3aecf24cdf2f7f767aaf1.gif"/>
     </p>
     <p>
      真实风力
     </p>
     <p>
      可以看到 FourCastNet 和 GraphCast 都可以对风力和温度的衍变进行比较准确的预测。其中 GraphCast 相对来说更加接近真实情况，包括气象指标的细节纹理更丰富和一致，还有在6月30号开始在我国东南沿海的两次台风路径的预测。
     </p>
     <pre class="has"><code class="language-go">推荐阅读：

我的2022届互联网校招分享

我的2021总结

浅谈算法岗和开发岗的区别

互联网校招研发薪资汇总
2022届互联网求职现状，金9银10快变成铜9铁10！！

公众号：AI蜗牛车

保持谦逊、保持自律、保持进步

发送【蜗牛】获取一份《手把手AI项目》（AI蜗牛车著）
发送【1222】获取一份不错的leetcode刷题笔记

发送【AI四大名著】获取四本经典AI电子书</code></pre>
    </div>
   </div>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a2f2f62:6c6f672e6373646e2e6e65742f71715f33333433313336382f:61727469636c652f64657461696c732f313330323131393736" class_="artid" style="display:none">
 </p>
</div>


