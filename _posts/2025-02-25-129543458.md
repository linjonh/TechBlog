---
layout: post
title: "烧数亿美元耗上万颗英伟达-GPU,微软揭秘构建-ChatGPT-背后超级计算机往事-..."
date: 2025-02-25 21:26:48 +0800
description: "整理 | 苏宓出品 | CSDN（ID：CSDNnews）都说 ChatGPT 这种大模型研发是大公"
keywords: "chatgpt 通过云计算调用gpu"
categories: ['未分类']
tags: ['人工智能', 'Microsoft', 'Chatgpt']
artid: "129543458"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=129543458
  alt: "烧数亿美元耗上万颗英伟达-GPU,微软揭秘构建-ChatGPT-背后超级计算机往事-..."
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     烧数亿美元、耗上万颗英伟达 GPU，微软揭秘构建 ChatGPT 背后超级计算机往事 ！...
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <div id="js_content">
     <p style="text-align:center;">
      <img alt="4b6937c3a1a7d0b26795ccc0fe05ee0a.gif" src="https://i-blog.csdnimg.cn/blog_migrate/60cc711c8238436e9923567eaa8dfeb5.gif"/>
     </p>
     <p style="text-align:left;">
      整理 | 苏宓
      <br/>
     </p>
     <p style="text-align:left;">
      出品 | CSDN（ID：CSDNnews）
     </p>
     <p style="text-align:justify;">
      都说 ChatGPT 这种大模型研发是大公司之间的博弈，不仅仅是因为其要消耗的算力巨大，也是因为需要有强大的资金支撑。
     </p>
     <p style="text-align:justify;">
      那么，加入这场战局，究竟要花费多少钱？
      <br/>
     </p>
     <p style="text-align:justify;">
      此前，据 Techcrunch 报道，有人估算，运行 ChatGPT 的成本约为 100,000 美元每天，或每个月约耗费 300 万美元。在此之下，OpenAI 才找到了微软，寻求资助，共同探索人工智能的发展。
     </p>
     <p style="text-align:justify;">
      一直以来，这些传言并未得到准确的核实，众人只知晓 AI 大模型的运行成本非常高，却终不知道高到何种程度。
     </p>
     <p style="text-align:justify;">
      近日，微软在官方博客上连发两篇文章，分享了它对 Azure 的押注如何开启一场人工智能革命的历程，也揭晓了为 OpenAI 的 ChatGPT 提供算力构建基础设施的困难与挑战。微软透露，它将上万颗英伟达 A100 芯片连接到一起，并重新设计了服务架构，这使得 OpenAI 能够训练出越来越强大的 AI 模型，同时，也帮助自家解锁了 Bing、Edge 等工具的 AI 功能。据悉，这个项目已经花费微软数亿美元。
     </p>
     <p style="text-align:center;">
      <strong>
       <img alt="aa5debe596853e133ab64314ca4ba4ac.png" src="https://i-blog.csdnimg.cn/blog_migrate/d52977ba58e8a84a340d95e6ff0b584e.png"/>
      </strong>
     </p>
     <p style="text-align:center;">
      <strong>
       投资数亿，微软回忆与 OpenAI 合作往事
      </strong>
     </p>
     <p style="text-align:justify;">
      时间回到大约 5 年前，OpenAI 向微软提出了一个大胆的想法——它可以构建一套人工智能系统，永远改变人类与计算机之间的交互方式。
      <br/>
     </p>
     <p style="text-align:justify;">
      当时，包括微软在内，没有人知道这意味着 AI 系统可以创造出一个聊天机器人，可以写词、草拟邮件，也能根据少数的词语提示做出行程、菜单规划等等。
     </p>
     <p style="text-align:justify;">
      为了实现它，OpenAI 需要真正大规模的计算能力的支持。
     </p>
     <p style="text-align:justify;">
      但是在 OpenAI 向微软提出想法时，微软也迷茫了，甚至发出“微软能做到吗？”的疑问。
      <br/>
     </p>
     <p style="text-align:justify;">
      虽说微软过去多年以来一直在努力开发人工智能模型，使用更强大的 GPU 来处理更复杂的人工智能工作负载，也发现大模型的潜力，但在这过程中，他们也清楚的明白大型模型备受现有计算资源限制的困扰。
     </p>
     <p style="text-align:justify;">
      微软 Azure 高性能计算和人工智能产品负责人 Nidhi Chappell 对此表示："我们从研究中了解到的一件事是，模型越大，你拥有的数据越多，你能训练的时间越长，模型的准确性就越好。"
     </p>
     <p style="text-align:justify;">
      所以，想要大力推动让更大的模型训练更长的时间，这意味着你不仅需要拥有强大的基础设施，你还必须能够长期可靠地运行它。
     </p>
     <p style="text-align:justify;">
      可以说，这是 OpenAI 对 AI 模型的一次巨大尝试，也是微软对自家 Azure 服务的一次勇敢押注。
      <br/>
     </p>
     <p style="text-align:justify;">
      在 2019 年，微软和 OpenAI 开始建立了合作关系。"我们建立了一个系统架构，可以在非常大的规模下运行和可靠。这就是 ChatGPT 成为可能的原因，"微软 Azure AI 基础设施总经理 Nidhi Chappell 分享道，"这就是其中的一个模型。将会有很多很多其他的模式。"
     </p>
     <p style="text-align:justify;">
      当时，微软开发了一套新的 Azure 人工智能超级计算技术，也在 Azure 中建立超级计算资源，这些资源的设计和专用性使 OpenAI 能够训练一套日益强大的 AI 模型。
     </p>
     <p style="text-align:justify;">
      为了训练出这套模型，微软在基础设施中使用了数以千计的英伟达人工智能优化 GPU，它们被连接在一个高吞吐量、低延迟的网络中，该网络基于英伟达量子 InfiniBand 通信，用于高性能计算。
     </p>
     <p style="text-align:justify;">
      对此，促成微软和 OpenAI 合作的关键人物——负责战略合作伙伴关系的微软高级主管 Phil Waymouth 表示，OpenAI 训练其模型所需的云计算基础设施的规模是前所未有的，比业内任何人试图建立的网络 GPU 集群都要大得多。
     </p>
     <p>
      据彭博社报道，微软在该项目上已经花费了数亿美元。
     </p>
     <p>
      要问这个钱花得值不得，现在无论是微软，还是业界同行，给出的答案必然是肯定的。因为去年 11 月 ChatGPT 上线仅 5 天用户量就突破了 100 万；微软上线 ChatGPT 版本 Bing 短短一段时间后日活跃用户首次破亿；微软逐步将蕴藏着巨大的商业价值 ChatGPT 引入自家的服务线中，给亚马逊、Google 等公司也带来了巨大的压力。
     </p>
     <p style="text-align:center;">
      <strong>
       <img alt="405648a8449626bb8b1aec4249ffd897.png" src="https://i-blog.csdnimg.cn/blog_migrate/6aedf5dfe1ef68a578ee99ea53f74fe0.png"/>
      </strong>
     </p>
     <p style="text-align:center;">
      <strong>
       大规模的 AI 训练
      </strong>
     </p>
     <p style="text-align:justify;">
      当然微软押宝成功这些都是后话了，对于当时的微软而言，是一场摸着石头过河的未知探索之旅。相比现在可能看到的商业价值，那时的他们可谓是眼前一抹黑。
     </p>
     <p style="text-align:justify;">
      彼时的微软没有 OpenAI 所需要的东西，也不完全确定是否能在其 Azure 云服务中建造这么大的东西而不至于崩溃。
     </p>
     <p style="text-align:justify;">
      微软 Azure 高性能计算和人工智能产品负责人 Nidhi Chappell 称，这些突破的关键是学习如何在高吞吐量、低延迟的 InfiniBand 网络上构建、运行和维护数以万计共处一地的 GPU，并相互连接。
     </p>
     <p style="text-align:center;">
      <img alt="8b08623a8411ee15e80a4794eee3e133.png" src="https://i-blog.csdnimg.cn/blog_migrate/6c853a119672a4c63269f52033c3b431.png"/>
     </p>
     <p style="text-align:justify;">
      她解释说，这种规模甚至超过了 GPU 和网络设备供应商曾经测试过的规模。这是一个未知的领域。没有人确定硬件是否可以在这么大规模下运行，而不损坏。
     </p>
     <p style="text-align:justify;">
      为了训练一个大型语言模型，计算工作负载被划分到一个集群中的数千个 GPU 上。在这个计算的某些阶段（称之为 Allreduce），GPU 交换它们所做工作的信息。一个 InfiniBand 网络加速了这一阶段，在 GPU 开始下一块计算之前必须完成。
     </p>
     <p style="text-align:justify;">
      "由于这些工作跨越了数千个 GPU，你需要确保你有可靠的基础设施，然后也需要在后端拥有网络，这样你就可以更快地进行通信，并能够连续数周这样做"，Chappell 说道，“这不是你买了一大堆 GPU，把它们连在一起，就可以开始工作的。为了获得最佳的性能，需要有很多系统级的优化，而这是经过许多代人的经验总结出来的。”
     </p>
     <p>
      系统级优化也包括能够有效利用 GPU 和网络设备的软件。
     </p>
     <p>
      在过去的几年里，微软已经开发了这样的软件技术，提高了使用数十万亿个参数训练模型的能力，同时降低了训练和在生产中提供这些模型的资源要求和时间。
     </p>
     <p>
      “微软及其合作伙伴也一直在逐步增加 GPU 集群的容量，增加 InfiniBand 网络，并看看他们能把保持 GPU 集群运行所需的数据中心基础设施推到什么程度，包括冷却系统、不间断电源系统和备用发电机”，Waymouth 在官方博文中写道。
     </p>
     <p>
      今天，这种为大型语言模型训练而优化的 Azure 基础设施可以通过 Azure AI 超级计算能力获得，微软公司负责 AI 平台的副总裁  Eric Boyd 分享道。该资源提供了 GPU、网络硬件和虚拟化软件的组合，以提供推动下一波 AI 创新所需的计算。
     </p>
     <p style="text-align:center;">
      <strong>
       <img alt="586f939b748ce6b407e01e684f5967eb.png" src="https://i-blog.csdnimg.cn/blog_migrate/37bdcefdc295ca5777fdeb6a36017057.png"/>
      </strong>
     </p>
     <p style="text-align:center;">
      <strong>
       英伟达才是背后的赢家？
      </strong>
     </p>
     <p>
      随着基础设施的到位，微软现在正向其他人开放其硬件。为此，微软在另一篇博文中宣布加强和英伟达的合作，推出了使用英伟达 H100 和 A100 Tensor Core GPU 以及 Quantum-2 InfiniBand 网络的新虚拟机，其中最新推出的 ND H100 v5 VM，它支持按需大小不等的 8 到数千个 NVIDIA H100 GPU，这些 GPU 通过 NVIDIA Quantum-2 InfiniBand 网络互连。
     </p>
     <p>
      据微软透露，这应该允许 OpenAI 和其他依赖 Azure 的公司训练出更大、更复杂的 AI 模型。
     </p>
     <p>
      至此，也有不少人发现并调侃道，英伟达似乎成为了这场 AI 浪潮中最大的赢家。因为过去微软与 OpenAI 的合作创立的基础设施所投入的资金，大部分都进入了英伟达的口袋。
     </p>
     <p>
      话说如此，但他们也都为 AI 的发展做出了重要贡献。在 3 月 16 日，微软将分享其在人工智能方面的下一步最新进展，而英伟达也即将在 GTC 大会期间透露更多关于未来 AI 产品的信息，CSDN 也将进一步跟踪报道，敬请关注。
     </p>
     <p>
      参考：
      <br/>
     </p>
     <p style="text-align:justify;">
      https://www.bloomberg.com/news/articles/2023-03-13/microsoft-built-an-expensive-supercomputer-to-power-openai-s-chatgpt
     </p>
     <p style="text-align:justify;">
      https://azure.microsoft.com/en-us/blog/azure-previews-powerful-and-scalable-virtual-machine-to-help-customers-accelerate-ai/
     </p>
     <p style="text-align:justify;">
      https://news.microsoft.com/source/features/ai/how-microsofts-bet-on-azure-unlocked-an-ai-revolution/
     </p>
     <pre></pre>
     <p style="text-align:right;">
      <img alt="3ef20a039a52175f69bf142baaff3dad.gif" src="https://i-blog.csdnimg.cn/blog_migrate/a4f266572df12c9c6934622071d60d2c.gif"/>
     </p>
     <pre class="has"><code class="language-go">☞香港科技大学：期中报告使用 ChatGPT 可加分；爆谷歌、微软已在韩国开始裁员；美国最大加密货币银行宣布关闭|极客头条
☞硅谷银行一夜破产！ChatGPT 之父撒钱救援，马斯克有意收购？
☞各家的“ChatGPT”什么时候能取代程序员？CSDN AI编程榜发布</code></pre>
    </div>
   </div>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f6373646e6e6577732f:61727469636c652f64657461696c732f313239353433343538" class_="artid" style="display:none">
 </p>
</div>
