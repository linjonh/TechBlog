---
layout: post
title: 音视频开发-音视频同步算法
date: 2025-01-17 07:13:09 +0800
description: "目录ffplay简介为什么要做音视频同步音视频同步算
keywords: 基于播放时限的流内同步算法
categories: ['音视频']
tags: ['音视频同步', 'Ffmpeg']
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=97137998
    alt: 音视频开发-音视频同步算法
artid: 97137998
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     音视频开发---音视频同步算法
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p id="main-toc">
    </p>
    <p>
     <strong>
      目录
     </strong>
    </p>
    <p id="ffplay%E7%AE%80%E4%BB%8B-toc" style="margin-left:40px;">
     <a href="#ffplay%E7%AE%80%E4%BB%8B" rel="nofollow">
      ffplay简介
     </a>
    </p>
    <p id="%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%81%9A%E9%9F%B3%E8%A7%86%E9%A2%91%E5%90%8C%E6%AD%A5-toc" style="margin-left:40px;">
     <a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%81%9A%E9%9F%B3%E8%A7%86%E9%A2%91%E5%90%8C%E6%AD%A5" rel="nofollow">
      为什么要做音视频同步
     </a>
    </p>
    <p id="%E9%9F%B3%E8%A7%86%E9%A2%91%E5%90%8C%E6%AD%A5%E7%AE%97%E6%B3%95-toc" style="margin-left:40px;">
     <a href="#%E9%9F%B3%E8%A7%86%E9%A2%91%E5%90%8C%E6%AD%A5%E7%AE%97%E6%B3%95" rel="nofollow">
      音视频同步算法
     </a>
    </p>
    <p id="%E5%8F%82%E8%80%83-toc" style="margin-left:40px;">
     <a href="#%E5%8F%82%E8%80%83" rel="nofollow">
      参考
     </a>
    </p>
    <hr id="hr-toc"/>
    <p>
     本文是对音视频同步算法的总结，以阅读ffplay.c源码为基础，结合各位博主的分析， 逐渐深入理解同步算法原理， 并根据自身理解， 编写一套简易的视频播放器，用于验证音视频同步算法。
    </p>
    <h3 id="ffplay%E7%AE%80%E4%BB%8B">
     ffplay简介
    </h3>
    <p>
     ffplay是FFmpeg提供的开源播放器，基于FFmpeg和SDL进行视频播放， 是研究视频播放器，音视频同步算法的很好的示例。ffplay源码涉及到很多音视频的基本概念， 在基础理论缺乏的情况下分析起来并不容易，在分析ffplay源码之前，要对音视频的相关概念有所了解，关于音视频的基本知识，在网络上有很多，也可以参考我的其他文章，这些也是我在学习中的经验总结。
    </p>
    <p>
     在ffmpeg4.1.3中，ffplay源码约3700行，非常的小巧，网上关于ffplay原理分析的文章也有很多，诸如：
    </p>
    <p>
     <a href="https://blog.csdn.net/leixiaohua1020">
      雷神
     </a>
     的博客
    </p>
    <p>
     <a href="https://blog.csdn.net/lrzkd" id="uid">
      ITRonnie
     </a>
     的
     <a href="https://blog.csdn.net/lrzkd/article/details/78661841">
      ffplay系列博客
     </a>
    </p>
    <p>
     <a href="https://www.cnblogs.com/leisure_chn/p/10307089.html" rel="nofollow">
      ffplay源码分析
     </a>
    </p>
    <p>
     比较系统的介绍了ffplay，是学习ffplay很好的资料。
    </p>
    <p>
     这里不再详细的分析ffplay的源码， 仅按照自己的理解对音视频同步算法进行总结， 并基于ffplay，自己动手编写一个简易视频播放器， 对音视频同步算法进行验证。
    </p>
    <p>
    </p>
    <h3 id="%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%81%9A%E9%9F%B3%E8%A7%86%E9%A2%91%E5%90%8C%E6%AD%A5">
     为什么要做音视频同步
    </h3>
    <p>
     如果仅仅是视频按帧率播放，音频按采样率播放，二者没有同步机制，即使一开始音视频是同步的，随着时间的流逝，音视频会渐渐失去同步，并且不同步的现象会随着时间会越来越严重。这是因为：
    </p>
    <p>
     一、播放时间难以精确控制
    </p>
    <p>
     二、异常、误差会随时间累积。
    </p>
    <p>
     所以，必须要采用一定的同步策略，不断对音视频的时间差作校正，使图像显示与声音播放总体保持一致。
    </p>
    <p>
    </p>
    <h3 id="%E9%9F%B3%E8%A7%86%E9%A2%91%E5%90%8C%E6%AD%A5%E7%AE%97%E6%B3%95">
     音视频同步算法
    </h3>
    <p>
     音视频同步算法的核心在于准确计算出音频与视频播放时间的偏差， 再根据这个偏差对双方进行调整，确保双方在你追我赶的过程中保持同步。
    </p>
    <p>
     1. 音视频同步介绍
    </p>
    <p>
     视频同步到音频：即以音频为主时间轴作为同步源
    </p>
    <p>
     音频同步到视频：即以视频为主时间轴作为同步源
    </p>
    <p>
     音频和视频同步到系统时钟：即以系统时钟为主时间轴作为同步源
    </p>
    <p>
     ffplay默认采用第一种同步方式，本节主要阐述视频同步到音频方式。为什么大多播放器要采用视频同步到音频呢，因为音频的采样率是固定的，若音频稍有卡顿，都会很明显的听出来，反则视频则不如此，虽然表面上说的是25P（每秒25帧），不一定每一帧的间隔就必须精确到40ms（所以每帧间隔大约40ms，事实上，也很难做到精确的40ms），即便偶尔视频间隔延时大了点或小了点，人眼也是察觉不出来的，所以视频的帧率可以是动态的，并不是严格标准的！
    </p>
    <p>
     视频同步到音频，即以音频作为主时间轴， 尽量不去干扰音频的播放，音频采用独立的线程独自解码播放(音频播放的速度在参数设置完毕后是固定的，因此我们也很容易计算音频播放的时间),在整个过程中，根据视频与音频时间差，来决策如何改变视频的播放速度，来确保视频与音频时间差控制在一定范围内， 当偏移在-90ms（音频滞后于视频）到+20ms（音频超前视频）之间时，人感觉不到视听质量的变化，这个区域可以认为是同步区域；当偏移在-185到+90之外时，音频和视频会出现严重的不同步现象，此区域认为是不同步区域。这里我们认为偏移diff在‘±一个视频帧间隔’范围内即认为是同步的，如下图所示：
    </p>
    <p>
    </p>
    <p>
     <img alt="" class="has" height="275" src="https://i-blog.csdnimg.cn/blog_migrate/c450aa2a013096baedcb1d1f4db19004.png" width="763"/>
    </p>
    <p>
    </p>
    <p>
     2. 音视频时间偏差计算
    </p>
    <p>
     同步系统的关键就在于计算视频与音频时间偏差diff， 在ffplay.c源码中，是通过函数compute_target_delay实现的，函数源码如下：
    </p>
    <pre class="has"><code>
static double compute_target_delay(double delay, VideoState *is)
{
    double sync_threshold, diff = 0;

    /* update delay to follow master synchronisation source */
    if (get_master_sync_type(is) != AV_SYNC_VIDEO_MASTER) {
        /* if video is slave, we try to correct big delays by
           duplicating or deleting a frame */
        diff = get_clock(&amp;is-&gt;vidclk) - get_master_clock(is);

        /* skip or repeat frame. We take into account the
           delay to compute the threshold. I still don't know
           if it is the best guess */
        sync_threshold = FFMAX(AV_SYNC_THRESHOLD_MIN, FFMIN(AV_SYNC_THRESHOLD_MAX, delay));
        if (!isnan(diff) &amp;&amp; fabs(diff) &lt; is-&gt;max_frame_duration) {
            if (diff &lt;= -sync_threshold)
                delay = FFMAX(0, delay + diff);
            else if (diff &gt;= sync_threshold &amp;&amp; delay &gt; AV_SYNC_FRAMEDUP_THRESHOLD)
                delay = delay + diff;
            else if (diff &gt;= sync_threshold)
                delay = 2 * delay;
        }
    }

    av_log(NULL, AV_LOG_TRACE, "video: delay=%0.3f A-V=%f\n",
            delay, -diff);

    return delay;
}
</code></pre>
    <p>
     根据自身的理解，结合实际测试，得出diff的计算方法：
    </p>
    <p>
     <img alt="" class="has" height="445" src="https://i-blog.csdnimg.cn/blog_migrate/cef29afaa47935f1493734478a3981dd.png" width="712"/>
    </p>
    <p>
     当前视频帧pts：frame-&gt;pts * av_q2d(video_st-&gt;time_base)
    </p>
    <p>
     当前视频帧至今流逝的时间： 代表当前视频帧从开始显示到现在的时间， 在ffplay中函数get_clock(&amp;is-&gt;vidclk)给出了具体实现，在本次实验中， 通过nowtime - last_showtime来表示流逝的时间， 由于我们是在视频显示后立即计算diff， 这个流逝的时间几乎可以忽略不计，可以使用0表示。
    </p>
    <p>
     音频帧播放时间 = 音频长度/采样率
    </p>
    <p>
     当前音频帧播放完毕时间= 当前音频帧的pts + 当前音频帧长度 / 采样率
    </p>
    <p>
     = af-&gt;pts + (double) af-&gt;frame-&gt;nb_samples / af-&gt;frame-&gt;sample_rate;
    </p>
    <p>
     （在计算音频帧长度时需要考虑采样率， 通道数， 样本格式）
    </p>
    <p>
     音频缓冲区中未播放数据的时间： 在ffplay.c中，采用如下公式来获取：
    </p>
    <pre class="has"><code>set_clock_at(&amp;is-&gt;audclk, is-&gt;audio_clock - (double)(2 * is-&gt;audio_hw_buf_size + is-&gt;audio_write_buf_size) / is-&gt;audio_tgt.bytes_per_sec, is-&gt;audio_clock_serial, audio_callback_time / 1000000.0);</code></pre>
    <p>
     缓冲区数据总长度=SDL的A，B缓冲区总长度  +  当前音频帧尚未拷贝到SDL缓冲区的剩余长度aduio_write_buf_size
    </p>
    <p>
     到这里，我们就可以计算得到音视频的播放时间偏差diff， 结合上面的偏差图，我们很容易判断出是视频落后于音频，还是音频落后于视频。
    </p>
    <p>
    </p>
    <p>
     3. 量化视频播放的时间延时
    </p>
    <p>
     通过第2步我们已经计算出音视频的时间偏差， 接下来我们就要根据这个偏差来量化视频延时的时间， 来控制下一个视频帧显示的时间。
    </p>
    <p>
     我们参考ffplay.c中的代码片段：
    </p>
    <pre class="has"><code>            last_duration = vp_duration(is, lastvp, vp);
            delay = compute_target_delay(last_duration, is);

            time= av_gettime_relative()/1000000.0;
            if (time &lt; is-&gt;frame_timer + delay) {
                *remaining_time = FFMIN(is-&gt;frame_timer + delay - time, *remaining_time);
                goto display;
            }

            is-&gt;frame_timer += delay;
            if (delay &gt; 0 &amp;&amp; time - is-&gt;frame_timer &gt; AV_SYNC_THRESHOLD_MAX)
                is-&gt;frame_timer = time;
</code></pre>
    <p>
     remaining_time为下一帧播放的延时时间， ffplay.c借助frame_timer += delay来记录当前视频累计播放的时间。
    </p>
    <p>
     frame_timer + delay - av_gettime_relative()/1000000.0 ：代表下一视频帧需要延时的时间，这里需要减去当前时间，是为了得到定时器或delay的时间。
    </p>
    <p>
     另外， 我们约定任意两个视频帧的间隔至少为10ms,所以才有了：
    </p>
    <p>
     *remaining_time = FFMIN(is-&gt;frame_timer + delay - time, *remaining_time);
    </p>
    <p>
    </p>
    <p>
     4. 编写简易的视频播放器
    </p>
    <p>
     ffplay.c中的同步算法对于初学者而言理解起来还是有些难度的， 结合自身对ffplay.c源码的阅读，以及音视频同步算法的理解， 对上述同步代码进行精简， 亦能达到音视频同步的效果代码片段如下。
    </p>
    <pre class="has"><code>        if( pm-&gt;av_sync_type == AV_SYNC_AUDIO_MASTER){// 
            master_clock = get_master_clock(pm);
            diff = vp-&gt;pts - master_clock;
            printf("vps:%lf, audioclock:%lf, diff:%lf\n", vp-&gt;pts, master_clock, diff);
            sync_threshold = (delay &gt; AV_SYNC_THRESHOLD)?delay:AV_SYNC_THRESHOLD;
  
            if( diff &lt;= -sync_threshold){
                delay = 0;
            }else if( diff &gt;= sync_threshold){
                delay *= 2;
            }
            
        }</code></pre>
    <p>
     我们直接根据diff的值来决策下一帧要延时的时间。
    </p>
    <p>
     学习期间编写的一个视频播放器，用于研究音视频同步算法，
     <a href="https://download.csdn.net/download/u011734326/11449397">
      完整代码下载
     </a>
    </p>
    <p>
    </p>
    <h3 id="%E5%8F%82%E8%80%83">
     参考
    </h3>
    <p>
     <a href="https://www.cnblogs.com/my_life/articles/6842155.html" rel="nofollow">
      https://www.cnblogs.com/my_life/articles/6842155.html
     </a>
    </p>
    <p>
     ffplay播放器音视频同步原理：
     <a href="https://blog.csdn.net/lrzkd/article/details/78661841">
      https://blog.csdn.net/lrzkd/article/details/78661841
     </a>
    </p>
    <p>
     ffplay：
     <a href="https://juejin.im/user/5cac7dc26fb9a06885399b1c/posts" rel="nofollow">
      https://juejin.im/user/5cac7dc26fb9a06885399b1c/posts
     </a>
    </p>
    <p>
     <a href="https://www.cnblogs.com/leisure_chn/p/10307089.html" rel="nofollow">
      ffplay.c 音视频同步
     </a>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f:2f626c6f672e6373646e2e6e65742f75303131373334333236:2f61727469636c652f64657461696c732f3937313337393938" class_="artid" style="display:none">
 </p>
</div>


