---
layout: post
title: "直击云栖,阿里云再甩王炸模型到云基础设施全面升级"
date: 2025-02-25 22:42:10 +0800
description: "编辑 | 宋慧出品 | CSDN（ID：CSDNnews）过去两年，从生成式 AI 火爆出圈到 AI"
keywords: "阿里 gpu故障预测"
categories: ["未分类"]
tags: ["阿里云", "云计算"]
artid: "142427655"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=142427655
  alt: "直击云栖,阿里云再甩王炸模型到云基础设施全面升级"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     直击云栖，阿里云再甩王炸：模型到云基础设施全面升级
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <div id="js_content">
     <p style="text-align:center;">
      <img alt="bd49f450671f50f2fac85fc7673f85e2.gif" src="https://img-blog.csdnimg.cn/img_convert/bd49f450671f50f2fac85fc7673f85e2.gif"/>
     </p>
     <p style="text-align:left;">
      编辑 | 宋慧
     </p>
     <p style="text-align:left;">
      出品 | CSDN（ID：CSDNnews）
     </p>
     <p style="text-align:justify;">
      过去两年，从生成式 AI 火爆出圈到 AI 大模型在各行业落地应用，CSDN 看到，大模型正在掀起一场智能化革命，带来计算、开发、交互三大范式全面升级和转换，本次 AI 技术浪潮，可能进一步让我们迎来科技变革周期，而且比移动与云计算变革更加剧烈。这与 IT 云化、全行业数字化之后 AI 引发的云计算第三次浪潮不谋而合。
     </p>
     <p style="text-align:justify;">
      重要的趋势之下，全球科技巨头纷纷加码 AI 大模型技术投入，在今天的 2024 云栖大会上，阿里云通义旗舰模型 Qwen-Max 全方位升级，性能接近 GPT-4o；通义千问推出新一代开源模型 Qwen2.5，Qwen2.5 全系列涵盖多个尺寸的大语言模型、多模态模型、数学模型和代码模型，每个尺寸都有基础版本、指令跟随版本、量化版本，总计上架 100 多个模型，刷新业界纪录。
     </p>
     <p style="text-align:justify;">
      除了自研模型的全面开源开放，今年云栖大会更重磅的是阿里云全栈“All in”AI 基础设施，全面重构了面向 AI 的服务器、弹性计算、网络、存储等全栈技术体系，钻研探索 AI 基础设施的新标准。这一重要技术风向，可以说是一改 AI 系统就要“堆资源、堆硬件”，“搞 AI 就是装备竞赛”的 IT 传统思路，而是从计算存储网络这些云技术底层核心架构的创新，挖掘算力潜力和效率，这可能才是系统性、结构化去满足巨量算力需求的新思路。
     </p>
     <p style="text-align:center;">
      <img alt="06f3adc650d428598b3b7ee1cb28f39a.png" src="https://img-blog.csdnimg.cn/img_convert/06f3adc650d428598b3b7ee1cb28f39a.png"/>
     </p>
     <p style="text-align:center;">
      <strong>
       面向 AI 的计算、存储、网络
      </strong>
     </p>
     <p style="text-align:center;">
      <strong>
       软硬一体、全面重构！
      </strong>
     </p>
     <p style="text-align:justify;">
      我们看到，AI 计算范式正在从图灵、冯·诺伊曼计算范式转为神经网络计算范式，以 GPU 为主的 AI 算力是目前 AI 系统计算的核心。今年云栖大会，阿里云从自研磐久 AI Infra 服务器、云基础设施处理器 CIPU，GPU 容器算力，自研 HPN7.0 高性能网络，自研智算 CPFS 文件存储系统，AI 大模型工程平台 PAI，全链路提升 AI 系统性能。
     </p>
     <p style="text-align:center;">
      <img alt="657e01538bd043cbfcc316b741941223.jpeg" src="https://img-blog.csdnimg.cn/img_convert/657e01538bd043cbfcc316b741941223.jpeg"/>
     </p>
     <p style="text-align:center;">
      2024 云栖大会现场展示阿里云自研、高密度、高性能 AI 基础设施
     </p>
     <p style="text-align:justify;">
      <strong>
       一、自研高密度磐久 AI Infra 服务器，性能再升级
      </strong>
     </p>
     <p style="text-align:justify;">
      阿里云自研 AI 服务器磐久系列，推出针对 AI 深度优化版本 G 系列（现场展示了磐久 AI Infra1.0、2.0 服务器），可以支持国内外多种 GPU 与异构芯片、单机可实现 16 颗 GPU 高速 Scale up 互连，支持最高 1.5TB 共享显存，提供最高 3.2Tbps 的 Scale-Out 网络带宽。除了硬件规格升级，磐久面向高性能计算的可靠性设计，采用超钛金电源实现能效超 97%，基于 AI 算法的 GPU 故障预测准确率达 92%。另外，阿里云自研云基础设施处理器 CIPU2.0 全面打通阿里云 AI Infra，通过 VPC、eRDMA 提供高性能虚拟网络能力，并全量接入 EBS、EED、CPFS、DFS 等高性能 AI 存储能力；通过存储和网络数据 E2E 加密、统一 TPM 硬件可信根等技术确保数据全生命周期安全。通过软硬一体协同优化，CIPU2.0 最终可以实现 400Gbps 的高吞吐硬件数据加速架构，将整机稳定性提升 20%。
     </p>
     <p style="text-align:justify;">
      <strong>
       二、阿里云 ACS 首推 GPU 容器算力，容器化使用 GPU 算力
      </strong>
     </p>
     <p style="text-align:justify;">
      除了高密度 AI 服务器硬件升级，在 2023 年 Gartner 容器管理魔力象限进入领导者象限的阿里云，在今天会上宣布容器计算服务 ACS 重磅升级，以 0.5vCPU、1GiB 步长递进，实现更柔性的秒级自动热变配；每分钟可弹至 10000 个 pod，并推出按天承诺消费的节省计划，综合算力成本最高可降 55%。面向 AI，ACS 首次推出 GPU 容器算力，用户可以容器化去使用 GPU 算力，通过拓扑感知调度，实现计算亲和度和性能的提升；容器服务 ACK 再升级，大模型应用冷启动延迟降低 85%，容器网络吞吐增加 30%，弹性扩容效率提升 25%，并可提供 15000 个超大规模节点支持。
     </p>
     <p style="text-align:justify;">
      <strong>
       三、自研高性能网络 HPN 7.0，AI 网络全新架构
      </strong>
     </p>
     <p style="text-align:justify;">
      在网络层面，针对需要高带宽的 AI 推理在传统数据中心三层网络架构中遭遇负载不均衡的问题，今年云栖大会阿里云推出自研高性能网络 HPN 7.0。HPN 网络系统论文于 2024 年收录顶会 SIGCOMM，成为首篇智算架构论文，HPN 7.0 设计了“双上联+多轨+双平面”的网络架构，被认为是
      <strong>
       继谷歌 Jupiter 经典网络之后的 AI 网络架构新范式。
      </strong>
      以 HPN 7.0 构建的高性能、高稳定 AIinfra 网络，支持 3.2TRDMA 网络带宽，模型训练性能端到端提升 10%，集合通信性能提升十余倍。除了 HPN，阿里云还提出端网融合的可预期网络技术体系、率先实践 RDMA 低延时网络，阿里巴巴还曾获评权威机构 AMiner 全球十大最具影响力的网络研究机构。
     </p>
     <p style="text-align:justify;">
      <strong>
       四、并行文件存储 CPFS，端到端全链路 AI 极致存储能力
      </strong>
     </p>
     <p style="text-align:justify;">
      面对 AI 海量数据存储管理挑战，阿里云存储服务全面升级，AI 训练场景通过采用对象存储服务（OSS）作为统一的数据湖底座，并结合文件存储 CPFS 数据流动，通过冷热数据分离进行生命周期管理，实现端到端全链路性能提升，数据吞吐 20TB/s，为 AI 智算提供指数级扩展存储能力；另外阿里云 Tablestore 表格存储的向量检索技术，推出了 OSS 索引服务-语义检索，适用于大规模多模态数据集的管理。
     </p>
     <p style="text-align:justify;">
      <img alt="dd019a1493638ca9e2864f140b12c459.jpeg" src="https://img-blog.csdnimg.cn/img_convert/dd019a1493638ca9e2864f140b12c459.jpeg"/>
     </p>
     <p style="text-align:justify;">
      计算存储网络之上，还有数据/算力/AI 资产管理、开发、训练、推理的大模型工程化平台 PAI，通过针对 AI 各层全栈优化的 AI Infra，阿里云灵骏集群提供高效的一体化 AI 算力，万卡规模性能线性度超过 96%，并行存储吞吐 20TB/s，万卡规模下网络带宽利用率超过 99%，可支持单集群十万卡级别 AI 算力规模。技术创新也得到了行业权威认可，Gartner 最近刚刚发布了针对 AI 大模型和全流程服务的 2024 年全球云 AI 开发者服务魔力象限，阿里云成为唯一进入挑战者象限的中国厂商。
     </p>
     <p style="text-align:center;">
      <img alt="98ea561e4713e216955e2e703d4b990d.png" src="https://img-blog.csdnimg.cn/img_convert/98ea561e4713e216955e2e703d4b990d.png"/>
     </p>
     <p style="text-align:center;">
      <strong>
       Qwen-Max、Qwen2.5，
      </strong>
     </p>
     <p style="text-align:center;">
      <strong>
       自研模型全面开放开源，
      </strong>
     </p>
     <p style="text-align:center;">
      <strong>
       发布专业视频生成模型
      </strong>
     </p>
     <p style="text-align:justify;">
      大会现场，通义大模型迎来了年度重磅发布。首先是通义旗舰模型 Qwen-Max 全方位升级，性能接近 GPT-4o。通义官网和通义 APP 的后台模型均已切换为 Qwen-Max，继续免费为所有用户提供服务。用户也可通过阿里云百炼平台调用 Qwen-Max 的 API。
     </p>
     <p style="text-align:center;">
      <img alt="2fe86edbebb34eec36ec0df4e5593f8e.png" src="https://img-blog.csdnimg.cn/img_convert/2fe86edbebb34eec36ec0df4e5593f8e.png"/>
     </p>
     <p style="text-align:justify;">
      另外，通义千问新一代开源模型 Qwen2.5 发布，旗舰模型 Qwen2.5-72B 性能超越 Llama 405B，再登全球开源大模型王座。Qwen2.5 全系列涵盖多个尺寸的大语言模型、多模态模型、数学模型和代码模型，每个尺寸都有基础版本、指令跟随版本、量化版本，总计上架 100 多个模型，刷新业界纪录。
     </p>
     <p style="text-align:center;">
      <img alt="71cf7b6d9956dc8a9fd542b0d678e78d.jpeg" src="https://img-blog.csdnimg.cn/img_convert/71cf7b6d9956dc8a9fd542b0d678e78d.jpeg"/>
     </p>
     <p style="text-align:justify;">
      通义万相全面升级，并发布全新视频生成模型，可生成影视级高清视频，可应用于影视创作、动画设计、广告设计等领域。即日起，所有用户可通过通义 APP 及通义万相官网免费体验。
     </p>
     <p style="text-align:center;">
      <img alt="1a7fa9c3193f4ae493837f1358bf0460.jpeg" src="https://img-blog.csdnimg.cn/img_convert/1a7fa9c3193f4ae493837f1358bf0460.jpeg"/>
     </p>
     <p style="text-align:center;">
      大会上Demo演示：VoiceChat-数字人
     </p>
     <p style="text-align:center;">
      最新发布Demo演示：音频识别
     </p>
     <p style="text-align:justify;">
      2024 年 9 月中旬，通义千问开源模型累计下载量已经突破 4000 万，通义原生模型和衍生模型总数超过 5 万个，成为仅次于 Llama 的世界级模型群。
     </p>
     <p style="text-align:center;">
      <img alt="1a4368934f4f19a8b734b3380339f892.png" src="https://img-blog.csdnimg.cn/img_convert/1a4368934f4f19a8b734b3380339f892.png"/>
     </p>
     <p style="text-align:center;">
      <strong>
       成为中国大模型公共 AI 算力底座，阿里云有底气
      </strong>
     </p>
     <p style="text-align:justify;">
      云计算本身就是灵活、低门槛、技术普惠理念下的产物。AI 时代，有了底层技术架构革新去探索巨量 AI 算力新解法、开源自研大模型以追求 AI 技术的极致前沿水平，阿里云就有了成为中国大模型的公共 AI 算力底座的底气。
     </p>
     <p style="text-align:justify;">
      现在，中国一半大模型公司跑在阿里云上，百川智能、智谱 AI、零一万物、vivo、复旦大学等大批头部企业及机构均在阿里云上训练大模型；中国众多头部主流大模型都已通过阿里云对外提供 API 服务，包括通义系列、Baichuan 系列、智谱 AI ChatGLM 系列等。
     </p>
     <p style="text-align:justify;">
      <img alt="bc199db8015feca493e0dae99541201c.jpeg" src="https://img-blog.csdnimg.cn/img_convert/bc199db8015feca493e0dae99541201c.jpeg"/>
     </p>
     <p style="text-align:justify;">
      今天大会上，阿里云百炼平台上的三款通义千问主力模型再次降价，Qwen-Turbo 价格直降 85%，低至百万 tokens 0.3 元，Qwen-Plus 和 Qwen-Max 分别再降价 80%和 50%。自首次宣布降价后，
      <strong>
       阿里云百炼付费客户数较上一个季度增长超过 200%，大批企业和开发者放弃私有化部署，选择直接在百炼上调用各类 AI 大模型
      </strong>
      ，中国一汽、联想、微博、携程、喜马拉雅、三得利（中国）等 30 多万企业客户已经接入通义大模型。
     </p>
     <p style="text-align:center;">
      <img alt="c22f470df8be4c565788a485fe4f8de5.jpeg" src="https://img-blog.csdnimg.cn/img_convert/c22f470df8be4c565788a485fe4f8de5.jpeg"/>
     </p>
     <p style="text-align:justify;">
      以上，我们还只是研究讨论了 AI 基础设施、大模型开源与生态，模型之上则是千行百业的 AI 应用百花齐放。从今年云栖大会的展览部分也能看出，三个场馆中 AI 底层和前沿技术的展商有 17 家，AI 算力计算馆展商 80 家，AI 创新应用的前沿应用馆展商数量高达 170 多家。阿里云通义大模型已经服务了超 30 万家企业客户，重点覆盖了互联网、金融、汽车、科研、医疗、教育、政务、工业制造和零售等领域，包含营销设计、社交、AI 游戏、在线教育、智慧终端、自动驾驶、智能座舱、金融客服、政务服务、代码开发、药物研发、气象预测、太空探索等场景。
     </p>
     <p style="text-align:justify;">
      对于更前沿的 AGI 通用人工智能、具身机器人等话题，云栖大会上 AI 前沿技术研究学者预测 L3 级别的 AGI 将在未来 18 个月内实现，甚至集成 AI 各模块后 L4 级别的通用人工智能也将加速产生。
     </p>
     <p style="text-align:justify;">
      阿里巴巴集团 CEO、阿里云智能集团董事长兼 CEO 吴泳铭在 2024 云栖大会上提到，AI 发展的速度超过任何历史时期，但现在也仅仅是 AGI 变革早期，生成式 AI 最大的想象力，绝不是在手机屏幕上做一两个新的超级 app，而是接管数字世界，改变物理世界。，开源开放的技术生态，成为中国公共 AI 算力底座，与全行业共同迎接“图灵时刻”。
     </p>
    </div>
   </div>
  </div>
  <div class="blog-extension-box" id="blogExtensionBox" style="width:400px;margin:auto;margin-top:12px">
  </div>
 </article>
 <p alt="68747470733a:2f2f626c6f672e6373646e2e6e65742f6373646e6e6577732f:61727469636c652f64657461696c732f313432343237363535" class_="artid" style="display:none">
 </p>
</div>
