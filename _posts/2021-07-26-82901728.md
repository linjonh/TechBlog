---
layout: post
title: "利用Lucene实现全文搜索"
date: 2021-07-26 11:49:22 +0800
description: "文章浏览阅读6.1k次，点赞4次，收藏9次。之前在我的项目【BBS】中做了一个站内搜索功能，旨在实现"
keywords: "lucene分词后如何按照句子搜索"
categories: ['分词搜索']
tags: ['分词搜索', 'Java', 'Java', 'Java', 'Lucene']
artid: "82901728"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=82901728
    alt: "利用Lucene实现全文搜索"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     利用Lucene实现全文搜索
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     之前在我的项目【BBS】中做了一个站内搜索功能，旨在实现主题和内容的搜索，并且实现前端高亮显示。
    </p>
    <p>
     查阅相关资料，发现利用普通的关系型数据库（模糊查询）是无法实现的，于是开始研究Lucene全文搜索，经过不懈努力，
    </p>
    <p>
     最终将Lucene全文搜索成功的应用到了我的项目中，很开心，这篇文章就给大家分享下Lucene全文搜索的经验。
    </p>
    <p>
     在这之前还是给大家看看Lucene全文搜索在实际项目中的应用效果吧，下图是我的项目【BBS】的站内搜索功能：
    </p>
    <p>
     <img alt="" class="has" height="619" src="https://i-blog.csdnimg.cn/blog_migrate/94d53906d6978064d8c50ec0b19dea9e.jpeg" width="1200"/>
    </p>
    <p>
    </p>
    <p>
     Lucene存储数据不是将数据存储在数据库中，而是通过特定的编码后将数据存储在磁盘上或者是内存中，使用Lucene全文搜索速度非常的快，原因是我们每次存储一个数据对象时，它都会将其创建索引进行存储，这样下次在查找的时候就会很快。
    </p>
    <p>
     简单说说Lucene的工作原理：
    </p>
    <p>
     <strong>
      存储过程：
     </strong>
    </p>
    <p>
     1.利用分词器对将要存储的数据进行分词处理
    </p>
    <p>
     2.为分词后的数据创建索引
    </p>
    <p>
     3.将创建好的索引进行存储
    </p>
    <p>
     <strong>
      查询过程：
     </strong>
    </p>
    <p>
     1.利用分词器对将要搜索的数据进行分词处理
    </p>
    <p>
     2.使用分词后的数据到索引库进行查询
    </p>
    <p>
     3.将查询出的数据进行高亮处理
    </p>
    <p>
     这就是Lucene存储和查询的基本工作原理，低层很复杂，我也只是简单了解并会简单的使用（如有错误，还请指正）
    </p>
    <p>
     下面着重说几个点：
    </p>
    <p>
     <strong>
      分词器
     </strong>
    </p>
    <p>
     分词器的作用就是将很长的文字内容进行分词（拆分），比如将
    </p>
    <p>
     【快乐的一只小青蛙】分词后得到【快乐】，【的】，【一只】，【小】，【青蛙】。
    </p>
    <p>
     当然了，这算是比较好的分词效果了，不同的分词器，效果是不同的，有官方提供的分词器（对中文分词效果差），
    </p>
    <p>
     也有第三方提供的分词器，都是通过实现Analyzer接口来实现的，我用的分词器是MMSegAnalyzer，
    </p>
    <p>
     分词后可以通过分词查看器（luke-javafx）进行查看。
    </p>
    <p>
     <strong>
      索引创建
     </strong>
    </p>
    <p>
     索引创建是将一个Document对象进行索引，而这个Document对象其实就像是关系型数据库中的一张表，可以向该对象中添加字段，如我用到的例子中Document添加的【title】和【content】两个字段，进行存储时也是将该Document对象进行存储，以后查询的时候就可以将整个Document对象查询出来。
    </p>
    <p>
     <strong>
      索引存储
     </strong>
    </p>
    <p>
     索引的存储可以存在磁盘上，也可以存在内存中，磁盘和内存的区别想必大家都知道的，我就不多说了，另外还有要注意存储索引时有三个模式：
    </p>
    <p>
     CREATE_OR_APPEND：创建或增加（之前没有索引记录就创建，有就增加记录）
    </p>
    <p>
     APPEND：增加（有索引记录就增加，没有不做任何处理）
    </p>
    <p>
     CREATE：创建（删除之前的索引记录，新建索引记录）
    </p>
    <p>
     <strong>
      查询
     </strong>
    </p>
    <p>
     查询时为了保证正确率，采用的分词器应该和创建索引时是一致的，不然的话会导致查询正确率偏低，也就是匹配不上索引，
    </p>
    <p>
     查询时应该到创建索引时的索引库中进行查询。
    </p>
    <p>
     <strong>
      高亮处理
     </strong>
    </p>
    <p>
     高亮处理就是将查询所匹配到的内容进行特殊处理，以方便观察，根据自己的情况来决定将匹配到的内容做何种处理，我这个例子是将匹配到的内容输出到html页面时显示为红色。
    </p>
    <p>
     <strong>
      代码部分
     </strong>
    </p>
    <p>
     这是个简单的案列，我创建的是maven项目，并用到了单元测试，在pom.xml中添加如下依赖：
    </p>
    <pre class="has"><code>    &lt;dependency&gt;
  		&lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;
  		&lt;artifactId&gt;lucene-core&lt;/artifactId&gt;
  		&lt;version&gt;7.2.1&lt;/version&gt;
  	&lt;/dependency&gt;
  	&lt;dependency&gt;
  		&lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;
  		&lt;artifactId&gt;lucene-highlighter&lt;/artifactId&gt;
  		&lt;version&gt;7.2.1&lt;/version&gt;
  	&lt;/dependency&gt;
  	&lt;dependency&gt;
  		&lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;
  		&lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt;
  		&lt;version&gt;7.2.1&lt;/version&gt;
  	&lt;/dependency&gt;
  	&lt;dependency&gt;
  		&lt;groupId&gt;com.chenlb.mmseg4j&lt;/groupId&gt;
  		&lt;artifactId&gt;mmseg4j-solr&lt;/artifactId&gt;
  		&lt;version&gt;2.3.0&lt;/version&gt;
  	&lt;/dependency&gt;
  	&lt;dependency&gt;
  		&lt;groupId&gt;junit&lt;/groupId&gt;
  		&lt;artifactId&gt;junit&lt;/artifactId&gt;
  		&lt;version&gt;4.12&lt;/version&gt;
  		&lt;type&gt;pom.lastUpdated&lt;/type&gt;
  	&lt;/dependency&gt;</code></pre>
    <p>
     <strong>
      下面是java代码：
     </strong>
    </p>
    <pre class="has"><code class="language-java">package com.yc.lucene;

import java.io.IOException;
import java.nio.file.Paths;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.document.TextField;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.index.IndexWriterConfig.OpenMode;
import org.apache.lucene.queryparser.classic.ParseException;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.index.Term;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.search.highlight.Fragmenter;
import org.apache.lucene.search.highlight.Highlighter;
import org.apache.lucene.search.highlight.InvalidTokenOffsetsException;
import org.apache.lucene.search.highlight.QueryScorer;
import org.apache.lucene.search.highlight.SimpleHTMLFormatter;
import org.apache.lucene.search.highlight.SimpleSpanFragmenter;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.junit.Test;

import com.chenlb.mmseg4j.analysis.MMSegAnalyzer;

/**
 * 基于MMSegAnalyzer分词器,磁盘存储的搜索引擎
 * 
 * @author Administrator
 *
 */
public class LuceneMmseg4jUtil {

	// 分词器
	Analyzer analyzer = new MMSegAnalyzer();
	// 存放索引的路径
	String direct = "G:\\index";

	/**
	 * 创建索引并进行存储
	 * 
	 * @param title
	 * @param content
	 * @throws IOException
	 */
	public void index(String title, String content) throws IOException {

		Directory directory = FSDirectory.open(Paths.get(direct));
		IndexWriterConfig iwConfig = new IndexWriterConfig(analyzer);
		// 设置创建索引模式(在原来的索引的基础上创建或新增)
		iwConfig.setOpenMode(OpenMode.CREATE_OR_APPEND);
		/*
		 * 添加索引，在之前的索引基础上追加 
		 * iwConfig.setOpenMode(OpenMode.APPEND); 
		 * 创建索引，删除之前的索引
		 * iwConfig.setOpenMode(OpenMode.CREATE);
		 */
		IndexWriter iwriter = new IndexWriter(directory, iwConfig);
		// 创建一个存储对象
		Document doc = new Document();
		// 添加字段
		doc.add(new TextField("title", title, Field.Store.YES));
		doc.add(new TextField("content", content, Field.Store.YES));
		// 新添加一个doc对象
		iwriter.addDocument(doc);
		// 创建的索引数目
		int numDocs = iwriter.numDocs();
		System.out.println("共索引了: " + numDocs + " 个对象");
		// 提交事务
		iwriter.commit();
		// 关闭事务
		iwriter.close();

	}

	/**
	 * 高亮处理
	 * 
	 * @param query
	 * @param fieldName
	 * @param fieldContent
	 * @return
	 * @throws IOException
	 * @throws InvalidTokenOffsetsException
	 */
	public String displayHtmlHighlight(Query query, String fieldName, String fieldContent)
			throws IOException, InvalidTokenOffsetsException {
		// 设置高亮标签,可以自定义,这里我用html将其显示为红色
		SimpleHTMLFormatter formatter = new SimpleHTMLFormatter("&lt;font color='red'&gt;", "&lt;/font&gt;");
		// 评分
		QueryScorer scorer = new QueryScorer(query);
		// 创建Fragmenter
		Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);
		// 高亮分析器
		Highlighter highlight = new Highlighter(formatter, scorer);
		highlight.setTextFragmenter(fragmenter);
		// 调用高亮方法
		String str = highlight.getBestFragment(analyzer, fieldName, fieldContent);
		return str;
	}

	/**
	 * 查询方法
	 * 
	 * @param text
	 * @return
	 * @throws IOException
	 * @throws ParseException
	 * @throws InvalidTokenOffsetsException
	 */
	public List&lt;Map&lt;String, Object&gt;&gt; search(String text)
			throws IOException, ParseException, InvalidTokenOffsetsException {

		// 得到存放索引的位置
		Directory directory = FSDirectory.open(Paths.get(direct));
		DirectoryReader ireader = DirectoryReader.open(directory);
		IndexSearcher searcher = new IndexSearcher(ireader);
		// 在content中进行搜索
		QueryParser parser = new QueryParser("content", analyzer);
		// 搜索含有text的内容
		Query query = parser.parse(text);
		// 搜索标题和显示条数(10)
		TopDocs tds = searcher.search(query, 10);

		List&lt;Map&lt;String, Object&gt;&gt; list = new ArrayList&lt;Map&lt;String, Object&gt;&gt;();
		Map&lt;String, Object&gt; map = null;

		// 在内容中查获找
		for (ScoreDoc sd : tds.scoreDocs) {
			// 获取title
			String title = searcher.doc(sd.doc).get("title");
			// 获取content
			String content = searcher.doc(sd.doc).get("content");
			// 内容添加高亮
			QueryParser qp = new QueryParser("content", analyzer);
			// 将匹配到的text添加高亮处理
			Query q = qp.parse(text);
			String html_content = displayHtmlHighlight(q, "content", content);

			map = new HashMap&lt;String, Object&gt;();
			map.put("title", title);
			map.put("content", html_content);
			list.add(map);
		}

		return list;
	}

	/**
	 * 删除索引方法
	 * 
	 * @param filed
	 * @param keyWord
	 * @throws IOException
	 */
	public void delete(String filed, String keyWord) throws IOException {

		Directory directory = FSDirectory.open(Paths.get(direct));
		IndexWriterConfig iwConfig = new IndexWriterConfig(analyzer);
		// 在原来的索引的基础上创建或新增
		iwConfig.setOpenMode(OpenMode.CREATE_OR_APPEND);
		IndexWriter iwriter = new IndexWriter(directory, iwConfig);
		// 删除filed中含有keyWord的索引
		iwriter.deleteDocuments(new Term(filed, keyWord));
		// 提交事务
		iwriter.commit();
		// 关闭事务
		iwriter.close();

	}

	@Test
	// 创建索引测试
	public void indexTest() throws IOException {
		LuceneMmseg4jUtil lucene = new LuceneMmseg4jUtil();
		lucene.index("我的简介", "大家好,我叫小铭,我的专业是网络工程");
		lucene.index("我的专业", "我的专业是网络工程");
	}

	@Test
	// 查询测试
	public void searchTest() throws IOException, ParseException, InvalidTokenOffsetsException {
		LuceneMmseg4jUtil lucene = new LuceneMmseg4jUtil();
		List&lt;Map&lt;String, Object&gt;&gt; list = lucene.search("网络工程");
		for(Map&lt;String,Object&gt; map:list) {
			System.out.println(map);
		}
	}

	@Test
	// 删除索引测试
	public void deleteTest() throws IOException {
		LuceneMmseg4jUtil lucene = new LuceneMmseg4jUtil();
		lucene.delete("title", "简介");
	}

}
</code></pre>
    <p>
     <strong>
      创建索引
     </strong>
    </p>
    <p>
     运行indexTest()这个方法后，控制台输出：
    </p>
    <p>
     <img alt="" class="has" height="127" src="https://i-blog.csdnimg.cn/blog_migrate/b72b5b8815446e13793305b140b2f038.jpeg" width="948"/>
    </p>
    <p>
     到我们存储索引的磁盘路径看看，可以看到如下的一些文件：
    </p>
    <p>
     <img alt="" class="has" height="354" src="https://i-blog.csdnimg.cn/blog_migrate/32cf3b4b436d3a1a927fb1fa23b1c98a.jpeg" width="1184"/>
    </p>
    <p>
     然后我们再利用索引查看工具（luke-javafx）进行查看，有title和content两个字段，先看看title字段分词效果：
    </p>
    <p>
     <img alt="" class="has" height="738" src="https://i-blog.csdnimg.cn/blog_migrate/93b84cdb705639cc8e39215fa082d947.jpeg" width="916"/>
    </p>
    <p>
     再来看看content字段分词效果：
    </p>
    <p>
     <img alt="" class="has" height="738" src="https://i-blog.csdnimg.cn/blog_migrate/d8180150e20db7f8d6e08cf2dc698388.jpeg" width="916"/>
    </p>
    <p>
     <strong>
      查询
     </strong>
    </p>
    <p>
     执行查询方法searchTest()，可以在控制台看到如下内容：
    </p>
    <p>
     <img alt="" class="has" height="98" src="https://i-blog.csdnimg.cn/blog_migrate/de0d1d975ac4e9f8d9d7f6a3da76037e.jpeg" width="1030"/>
    </p>
    <p>
     很完美的查询出我们想要查询的数据，并且将匹配到的内容进行了高亮处理。
    </p>
    <p>
     <strong>
      删除索引
     </strong>
    </p>
    <p>
     下面我们测试下删除索引的方法，执行deleteTest()方法，再利用分词查看器进行查看，可以看到，title字段匹配到"简介"的数据Document对象已经被删除了：
    </p>
    <p>
     <img alt="" class="has" height="336" src="https://i-blog.csdnimg.cn/blog_migrate/dcfe91b3f031458c8b452cfdf280d0ac.jpeg" width="887"/>
    </p>
    <p>
     <img alt="" class="has" height="335" src="https://i-blog.csdnimg.cn/blog_migrate/108d8f3cbb64768a3b468c791b0aeb60.jpeg" width="888"/>
    </p>
    <p>
     再运行查询方法searchTest()，看看到底有没有被删除：
    </p>
    <p>
     <img alt="" class="has" height="91" src="https://i-blog.csdnimg.cn/blog_migrate/d7f6bdb2114c5523558f272296a64276.jpeg" width="1046"/>
    </p>
    <p>
     很明显，数据对象已经被我们删除了，很完美。
    </p>
    <p>
     这样，我们便利用Lucene实现了全文搜索，想要存储复杂的数据对象，只需要对Document对象的字段进行设计就可以了，这个例子只是简单地入个门，Lucene很强大，想要很好的利用Lucene，还需要进一步的学习。
    </p>
    <p>
     好了，关于Lucene全文搜索的入门经验分享到此，所有分享内容都是自己学习总结的，如有错误，欢迎指正。
    </p>
    <p>
     文章属原创，如需引用，请注明出处。
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f6a616d5f66616e61746963:2f61727469636c652f64657461696c732f3832393031373238" class_="artid" style="display:none">
 </p>
</div>


