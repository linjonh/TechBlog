---
layout: post
title: 2019-09-05-人工智能教程---目录
date: 2019-09-05 11:23:48 +0800
categories: ['人工智能']
tags: ['神经网络', '深度学习', 'Ai', '人工智能', '机器学习']
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=77711593
  alt: 人工智能教程---目录
artid: 77711593
render_with_liquid: false
---
<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     人工智能教程 - 目录
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h2>
     <a id="_0">
     </a>
     目录
    </h2>
    <h3>
     <a id="font_colorredfont_1">
     </a>
     <font color="red">
      请先看前言
     </font>
    </h3>
    <h3>
     <a id="httpblogcsdnnetjiangjunshowarticledetails77338485_2">
     </a>
     <a href="http://blog.csdn.net/jiangjunshow/article/details/77338485">
      前言
     </a>
    </h3>
    <h3>
     <a id="font_colorred1__3">
     </a>
     <font color="red">
      1 人工智能基础
     </font>
    </h3>
    <h4>
     <a id="11_httpswwwcaptainbedcnwhatisnn_4">
     </a>
     <a href="https://www.captainbed.cn/whatisnn/" rel="nofollow">
      1.1 科普
     </a>
    </h4>
    <h5>
     <a id="111_httpswwwcaptainbedcnwhatisnn_5">
     </a>
     <a href="https://www.captainbed.cn/whatisnn/" rel="nofollow">
      1.1.1 什么是神经网络
     </a>
    </h5>
    <h4>
     <a id="12_httpswwwcaptainbedcnhowtoinputdata_6">
     </a>
     <a href="https://www.captainbed.cn/howtoinputdata/" rel="nofollow">
      1.2 基础知识
     </a>
    </h4>
    <h5>
     <a id="121_httpswwwcaptainbedcnhowtoinputdata_7">
     </a>
     <a href="https://www.captainbed.cn/howtoinputdata/" rel="nofollow">
      1.2.1 如何将数据输入到神经网络中
     </a>
    </h5>
    <h5>
     <a id="122_httpswwwcaptainbedcnhowtopredict_8">
     </a>
     <a href="https://www.captainbed.cn/howtopredict/" rel="nofollow">
      1.2.2 神经网络是如何进行预测的
     </a>
    </h5>
    <h5>
     <a id="123__9">
     </a>
     1.2.3 预测得准确吗
    </h5>
    <h5>
     <a id="124__10">
     </a>
     1.2.4 网络是如何进行学习的
    </h5>
    <h5>
     <a id="125__11">
     </a>
     1.2.5 计算图
    </h5>
    <h5>
     <a id="126__12">
     </a>
     1.2.6 如何计算逻辑回归的偏导数
    </h5>
    <h5>
     <a id="127__13">
     </a>
     1.2.7 向量化
    </h5>
    <h5>
     <a id="128_python_14">
     </a>
     1.2.8 如何开始使用python
    </h5>
    <h5>
     <a id="129__15">
     </a>
     1.2.9 如何向量化人工智能算法
    </h5>
    <h5>
     <a id="1210__16">
     </a>
     1.2.10 一些基础概念
    </h5>
    <h5>
     <a id="1211__17">
     </a>
     1.2.11 特征工程
    </h5>
    <h5>
     <a id="1212__18">
     </a>
     1.2.12 哪些特征是有价值的
    </h5>
    <h5>
     <a id="1213__19">
     </a>
     1.2.13 数据清理
    </h5>
    <h5>
     <a id="1214__20">
     </a>
     1.2.14 逻辑回归与分类阈值
    </h5>
    <h5>
     <a id="1215__21">
     </a>
     1.2.15 静态训练与动态训练
    </h5>
    <h5>
     <a id="_22">
     </a>
     【实战编程】教你编写第一个人工智能程序
    </h5>
    <h4>
     <a id="13__23">
     </a>
     1.3 神经网络
    </h4>
    <h5>
     <a id="131__24">
     </a>
     1.3.1 浅层神经网络
    </h5>
    <h5>
     <a id="132__25">
     </a>
     1.3.2 如何计算浅层神经网络的前向传播
    </h5>
    <h5>
     <a id="133__26">
     </a>
     1.3.3 如何计算浅层神经网络的反向传播
    </h5>
    <h5>
     <a id="134__27">
     </a>
     1.3.4 为什么需要激活函数
    </h5>
    <h5>
     <a id="135__28">
     </a>
     1.3.5 常见的激活函数
    </h5>
    <h5>
     <a id="136__29">
     </a>
     1.3.6 激活函数的偏导数
    </h5>
    <h5>
     <a id="137__30">
     </a>
     1.3.7 随机初始化参数
    </h5>
    <h5>
     <a id="138__31">
     </a>
     1.3.8 非线性与激活函数
    </h5>
    <h5>
     <a id="_32">
     </a>
     【实战编程】教你编写浅层神经网络
    </h5>
    <h5>
     <a id="139__33">
     </a>
     1.3.9 为什么需要深度神经网络
    </h5>
    <h5>
     <a id="1310__34">
     </a>
     1.3.10 如何计算深度神经网络
    </h5>
    <h5>
     <a id="1311__35">
     </a>
     1.3.11 核对矩阵的维度
    </h5>
    <h5>
     <a id="1312__36">
     </a>
     1.3.12 参数和超参数
    </h5>
    <h5>
     <a id="1313__37">
     </a>
     1.3.13 监督学习型神经网络
    </h5>
    <h5>
     <a id="1314__38">
     </a>
     1.3.14 什么使深度学习火起来了
    </h5>
    <h5>
     <a id="_39">
     </a>
     【实战编程】构建深度神经网络
    </h5>
    <h4>
     <a id="14__40">
     </a>
     1.4 额外知识
    </h4>
    <h5>
     <a id="141__41">
     </a>
     1.4.1 标量、向量、矩阵和张量
    </h5>
    <h5>
     <a id="142__42">
     </a>
     1.4.2 深入了解矩阵
    </h5>
    <h5>
     <a id="143__43">
     </a>
     1.4.3 范数
    </h5>
    <h5>
     <a id="144__44">
     </a>
     1.4.4 什么是微积分
    </h5>
    <h5>
     <a id="145__45">
     </a>
     1.4.5 古典微积分
    </h5>
    <h5>
     <a id="146__46">
     </a>
     1.4.6 极限微积分
    </h5>
    <h5>
     <a id="147__47">
     </a>
     1.4.7 偏导数
    </h5>
    <h5>
     <a id="148__48">
     </a>
     1.4.8 方向导数
    </h5>
    <h5>
     <a id="149__49">
     </a>
     1.4.9 什么是概率论
    </h5>
    <h5>
     <a id="1410__50">
     </a>
     1.4.10 条件概率
    </h5>
    <h5>
     <a id="1411__51">
     </a>
     1.4.11 什么是信息论
    </h5>
    <h5>
     <a id="1412__52">
     </a>
     1.4.12 条件熵
    </h5>
    <h5>
     <a id="1413__53">
     </a>
     1.4.13 互信息
    </h5>
    <h5>
     <a id="1414_KL_54">
     </a>
     1.4.14 相对熵（KL散度）
    </h5>
    <h5>
     <a id="1415__55">
     </a>
     1.4.15 交叉熵
    </h5>
    <h3>
     <a id="font_colorred2__56">
     </a>
     <font color="red">
      2 实战优化
     </font>
    </h3>
    <h4>
     <a id="21__57">
     </a>
     2.1 实战基础
    </h4>
    <h5>
     <a id="211__58">
     </a>
     2.1.1 如何配置数据集
    </h5>
    <h5>
     <a id="212__59">
     </a>
     2.1.2 欠拟合和过拟合
    </h5>
    <h5>
     <a id="213__60">
     </a>
     2.1.3 如何解决欠拟合与过拟合
    </h5>
    <h5>
     <a id="214_L2_61">
     </a>
     2.1.4 L2正则化
    </h5>
    <h5>
     <a id="215_dropout_62">
     </a>
     2.1.5 dropout
    </h5>
    <h5>
     <a id="216__63">
     </a>
     2.1.6 数据增强
    </h5>
    <h5>
     <a id="217__64">
     </a>
     2.1.7 将输入特征进行归一化处理
    </h5>
    <h5>
     <a id="218__65">
     </a>
     2.1.8 梯度消失和梯度爆炸
    </h5>
    <h5>
     <a id="219_bug_66">
     </a>
     2.1.9 如何判断网络是否有bug
    </h5>
    <h5>
     <a id="2110_H5_67">
     </a>
     2.1.10 H5文件
    </h5>
    <h5>
     <a id="_68">
     </a>
     【实战编程】参数初始化
    </h5>
    <h5>
     <a id="_69">
     </a>
     【实战编程】正则化
    </h5>
    <h5>
     <a id="_70">
     </a>
     【实战编程】梯度检验
    </h5>
    <h4>
     <a id="22__71">
     </a>
     2.2 优化算法
    </h4>
    <h5>
     <a id="221_Minibatch_72">
     </a>
     2.2.1 Mini-batch
    </h5>
    <h5>
     <a id="222_minibatch_73">
     </a>
     2.2.2 如何为mini-batch选择合理的大小
    </h5>
    <h5>
     <a id="223__74">
     </a>
     2.2.3 指数加权平均
    </h5>
    <h5>
     <a id="224__75">
     </a>
     2.2.4 深入理解指数加权平均
    </h5>
    <h5>
     <a id="225__76">
     </a>
     2.2.5 指数加权平均的偏差修正
    </h5>
    <h5>
     <a id="226__77">
     </a>
     2.2.6 动量梯度下降
    </h5>
    <h5>
     <a id="227_RMSprop_78">
     </a>
     2.2.7 RMSprop
    </h5>
    <h5>
     <a id="228_Adam_79">
     </a>
     2.2.8 Adam优化算法
    </h5>
    <h5>
     <a id="229__80">
     </a>
     2.2.9 学习率衰减
    </h5>
    <h5>
     <a id="2210__81">
     </a>
     2.2.10 局部最优问题
    </h5>
    <h5>
     <a id="minibatch_82">
     </a>
     【实战编程】mini-batch梯度下降
    </h5>
    <h5>
     <a id="_83">
     </a>
     【实战编程】动量梯度下降
    </h5>
    <h5>
     <a id="Adam_84">
     </a>
     【实战编程】Adam
    </h5>
    <h5>
     <a id="_85">
     </a>
     【实战编程】对比不同的优化算法
    </h5>
    <h4>
     <a id="23__86">
     </a>
     2.3 调试神经网络
    </h4>
    <h5>
     <a id="231__87">
     </a>
     2.3.1 调参
    </h5>
    <h5>
     <a id="232__88">
     </a>
     2.3.2 为调参选择采样标尺
    </h5>
    <h5>
     <a id="233__89">
     </a>
     2.3.3 各种调参经验
    </h5>
    <h5>
     <a id="234__90">
     </a>
     2.3.4 调参模式和工具
    </h5>
    <h5>
     <a id="235__91">
     </a>
     2.3.5 规范化隐藏层的输入
    </h5>
    <h5>
     <a id="236_BN_92">
     </a>
     2.3.6 BN的好处
    </h5>
    <h5>
     <a id="237_BN_93">
     </a>
     2.3.7 使用模型时的BN
    </h5>
    <h5>
     <a id="238_Softmax_94">
     </a>
     2.3.8 Softmax
    </h5>
    <h5>
     <a id="239_softmax_95">
     </a>
     2.3.9 深入理解softmax
    </h5>
    <h5>
     <a id="2310__96">
     </a>
     2.3.10 如何选择深度学习框架
    </h5>
    <h5>
     <a id="2311_tensorflow_97">
     </a>
     2.3.11 手把手教你使用tensorflow
    </h5>
    <h5>
     <a id="Tensorflow_v1x_98">
     </a>
     【实战编程】手把手带你学习Tensorflow v1.x
    </h5>
    <h5>
     <a id="tensorflow1x_99">
     </a>
     【实战编程】手把手教你用tensorflow1.x构建一个完整的人工智能程序
    </h5>
    <h5>
     <a id="Tensorflow_v2x_100">
     </a>
     【实战编程】手把手带你学习Tensorflow v2.x
    </h5>
    <h3>
     <a id="font_colorred3__101">
     </a>
     <font color="red">
      3 深度学习项目实战
     </font>
    </h3>
    <h4>
     <a id="31__102">
     </a>
     3.1 项目实战一
    </h4>
    <h5>
     <a id="311__103">
     </a>
     3.1.1 决策很重要
    </h5>
    <h5>
     <a id="312__104">
     </a>
     3.1.2 正交化
    </h5>
    <h5>
     <a id="313_F1_105">
     </a>
     3.1.3 如何判断哪个网络更好？——F1分数
    </h5>
    <h5>
     <a id="314__106">
     </a>
     3.1.4 如何做选择
    </h5>
    <h5>
     <a id="315__107">
     </a>
     3.1.5 验证集与测试集的数据来源要一致
    </h5>
    <h5>
     <a id="316__108">
     </a>
     3.1.6 数据集的获取与划分
    </h5>
    <h5>
     <a id="317__109">
     </a>
     3.1.7 判定标准是可以变的
    </h5>
    <h5>
     <a id="318_AI_110">
     </a>
     3.1.8 AI能力与人类能力的关系
    </h5>
    <h5>
     <a id="319__111">
     </a>
     3.1.9 利用贝叶斯误差来判断拟合度
    </h5>
    <h5>
     <a id="3110__112">
     </a>
     3.1.10 人类误差是多少呢？
    </h5>
    <h5>
     <a id="3111_AI_113">
     </a>
     3.1.11 AI超越人类
    </h5>
    <h5>
     <a id="3112_AI_114">
     </a>
     3.1.12 提升AI系统的一般流程
    </h5>
    <h5>
     <a id="3113__115">
     </a>
     3.1.13 数据集的偏见
    </h5>
    <h5>
     <a id="_116">
     </a>
     【实战编程】大项目神经网络
    </h5>
    <h4>
     <a id="32__117">
     </a>
     3.2 实战项目二
    </h4>
    <h5>
     <a id="321__118">
     </a>
     3.2.1 手工分析错误
    </h5>
    <h5>
     <a id="322__119">
     </a>
     3.2.2 同时手工分析多个错误类别
    </h5>
    <h5>
     <a id="323__120">
     </a>
     3.2.3 标签打错了
    </h5>
    <h5>
     <a id="324__121">
     </a>
     3.2.4 如何修正错误标签
    </h5>
    <h5>
     <a id="325__122">
     </a>
     3.2.5 快速地构建一个简单的系统
    </h5>
    <h5>
     <a id="326__123">
     </a>
     3.2.6 验证集要反应出真实目的
    </h5>
    <h5>
     <a id="327__124">
     </a>
     3.2.7 异源时的训练验证集
    </h5>
    <h5>
     <a id="328__125">
     </a>
     3.2.8 不常用的误差分析
    </h5>
    <h5>
     <a id="329__126">
     </a>
     3.2.9 如何解决异源问题
    </h5>
    <h5>
     <a id="3210__127">
     </a>
     3.2.10 迁移学习
    </h5>
    <h5>
     <a id="3211__128">
     </a>
     3.2.11 如何实现迁移学习
    </h5>
    <h5>
     <a id="3212__129">
     </a>
     3.2.12 什么时候才应该使用迁移学习？
    </h5>
    <h5>
     <a id="3213__130">
     </a>
     3.2.13 多任务学习
    </h5>
    <h5>
     <a id="3214__131">
     </a>
     3.2.14 深度理解多任务学习
    </h5>
    <h5>
     <a id="3215__132">
     </a>
     3.2.15 一步到位——端到端学习
    </h5>
    <h5>
     <a id="3216__133">
     </a>
     3.2.16 何时用端到端
    </h5>
    <h5>
     <a id="3217__134">
     </a>
     3.2.17 如何制作数据集
    </h5>
    <h5>
     <a id="_135">
     </a>
     【实战编程】优化大项目
    </h5>
    <h3>
     <a id="font_colorred4__136">
     </a>
     <font color="red">
      4 人脸识别
     </font>
    </h3>
    <h4>
     <a id="41__137">
     </a>
     4.1 卷积神经网络
    </h4>
    <h5>
     <a id="411%09_138">
     </a>
     4.1.1 智能视觉
    </h5>
    <h5>
     <a id="412%09_139">
     </a>
     4.1.2 卷积运算
    </h5>
    <h5>
     <a id="413%09_140">
     </a>
     4.1.3 边缘检测
    </h5>
    <h5>
     <a id="414%09_141">
     </a>
     4.1.4 深入理解边缘检测
    </h5>
    <h5>
     <a id="415%09padding_142">
     </a>
     4.1.5 padding
    </h5>
    <h5>
     <a id="416%09_143">
     </a>
     4.1.6 卷积步长
    </h5>
    <h5>
     <a id="417%093D_144">
     </a>
     4.1.7 3D卷积
    </h5>
    <h5>
     <a id="418%09_145">
     </a>
     4.1.8 多过滤器
    </h5>
    <h5>
     <a id="419%09_146">
     </a>
     4.1.9 卷积层
    </h5>
    <h5>
     <a id="4110__147">
     </a>
     4.1.10 卷积神经网络
    </h5>
    <h5>
     <a id="4111__148">
     </a>
     4.1.11 池化层
    </h5>
    <h5>
     <a id="4112__149">
     </a>
     4.1.12 池化层（二）
    </h5>
    <h5>
     <a id="4113__150">
     </a>
     4.1.13 一个较完整的卷积网络
    </h5>
    <h5>
     <a id="4114__151">
     </a>
     4.1.14 卷积的好处
    </h5>
    <h5>
     <a id="_152">
     </a>
     【实战编程】手把手教你构建卷积神经网络（一）
    </h5>
    <h5>
     <a id="_153">
     </a>
     【实战编程】手把手教你构建卷积神经网络（二）
    </h5>
    <h5>
     <a id="TensorFlow_154">
     </a>
     【实战编程】使用TensorFlow构建卷积神经网络
    </h5>
    <h4>
     <a id="42__155">
     </a>
     4.2 深度卷积网络
    </h4>
    <h5>
     <a id="421__156">
     </a>
     4.2.1 学习一些牛逼的例子
    </h5>
    <h5>
     <a id="422_LeNet5_157">
     </a>
     4.2.2 LeNet-5
    </h5>
    <h5>
     <a id="423_AlexNet_158">
     </a>
     4.2.3 AlexNet
    </h5>
    <h5>
     <a id="424_VGG_159">
     </a>
     4.2.4 VGG
    </h5>
    <h5>
     <a id="425__160">
     </a>
     4.2.5 残差网络
    </h5>
    <h5>
     <a id="426__161">
     </a>
     4.2.6 为什么残差网络能防止梯度问题
    </h5>
    <h5>
     <a id="427_11_162">
     </a>
     4.2.7 1×1卷积
    </h5>
    <h5>
     <a id="428_Inception_163">
     </a>
     4.2.8 Inception网络
    </h5>
    <h5>
     <a id="429_inception11_164">
     </a>
     4.2.9 inception网络与1×1卷积
    </h5>
    <h5>
     <a id="4210_inception_165">
     </a>
     4.2.10 完整的inception网络
    </h5>
    <h5>
     <a id="4211__166">
     </a>
     4.2.11 学会利用开源项目
    </h5>
    <h5>
     <a id="_167">
     </a>
     【实战编程】构建残差网络
    </h5>
    <h4>
     <a id="43__168">
     </a>
     4.3 目标检测
    </h4>
    <h5>
     <a id="431__169">
     </a>
     4.3.1 物体定位
    </h5>
    <h5>
     <a id="432__170">
     </a>
     4.3.2 关键点探测
    </h5>
    <h5>
     <a id="433__171">
     </a>
     4.3.3 床长人工智能教程-目标检测
    </h5>
    <h5>
     <a id="434__172">
     </a>
     4.3.4 滑动窗口探测法
    </h5>
    <h5>
     <a id="435__173">
     </a>
     4.3.5 卷积化滑动窗口
    </h5>
    <h5>
     <a id="436__174">
     </a>
     4.3.6 如何判断定位是否精准
    </h5>
    <h5>
     <a id="437__175">
     </a>
     4.3.7 如何避免一个物体被重复探测到？
    </h5>
    <h5>
     <a id="438__176">
     </a>
     4.3.8 两个物体的中心在同一个格子怎么办？
    </h5>
    <h5>
     <a id="439__177">
     </a>
     4.3.9 非极大值抑制的实现细节
    </h5>
    <h5>
     <a id="4310__178">
     </a>
     4.3.10 床长人工智能教程-候选区域
    </h5>
    <h5>
     <a id="_179">
     </a>
     【实战编程]】自动驾驶之车辆探测
    </h5>
    <h4>
     <a id="44__180">
     </a>
     4.4 风格迁移
    </h4>
    <h5>
     <a id="441__181">
     </a>
     4.4.1 风格迁移概述
    </h5>
    <h5>
     <a id="442__182">
     </a>
     4.4.2 差异性验证
    </h5>
    <h5>
     <a id="443__183">
     </a>
     4.4.3 如何实现差异性验证
    </h5>
    <h5>
     <a id="444__184">
     </a>
     4.4.4 如何训练差异性验证网络
    </h5>
    <h5>
     <a id="445__185">
     </a>
     4.4.5 差异性验证网络的训练技巧
    </h5>
    <h5>
     <a id="446__186">
     </a>
     4.4.6 差异性验证网络的另一种训练方法
    </h5>
    <h5>
     <a id="447__187">
     </a>
     4.4.7 神经网络每层到底都学会了什么？
    </h5>
    <h5>
     <a id="448__188">
     </a>
     4.4.8 神经风格迁移网络
    </h5>
    <h5>
     <a id="449__189">
     </a>
     4.4.9 内容损失函数
    </h5>
    <h5>
     <a id="4410__190">
     </a>
     4.4.10 什么是风格
    </h5>
    <h5>
     <a id="4411__191">
     </a>
     4.4.11 风格损失函数
    </h5>
    <h5>
     <a id="_192">
     </a>
     【实战编程】风格转换
    </h5>
    <h5>
     <a id="_193">
     </a>
     【实战编程】人脸识别
    </h5>
    <h3>
     <a id="font_colorred5__194">
     </a>
     <font color="red">
      5 语音识别
     </font>
    </h3>
    <h4>
     <a id="51__195">
     </a>
     5.1 循环序列模型
    </h4>
    <h5>
     <a id="511__196">
     </a>
     5.1.1 序列模型
    </h5>
    <h5>
     <a id="512__197">
     </a>
     5.1.2 序列模型的数据集
    </h5>
    <h5>
     <a id="513_RNN_198">
     </a>
     5.1.3 循环神经网络RNN
    </h5>
    <h5>
     <a id="514_RNN_199">
     </a>
     5.1.4 RNN的计算过程
    </h5>
    <h5>
     <a id="515_RNN_200">
     </a>
     5.1.5 各种结构的RNN
    </h5>
    <h5>
     <a id="516__201">
     </a>
     5.1.6 人工智能写作
    </h5>
    <h5>
     <a id="517_RNN_202">
     </a>
     5.1.7 普通RNN的记性不好
    </h5>
    <h5>
     <a id="518_LSTMRNN_203">
     </a>
     5.1.8 使用LSTM来增强RNN的记忆力
    </h5>
    <h5>
     <a id="519_GRURNN_204">
     </a>
     5.1.9 使用GRU来增强RNN的记忆力
    </h5>
    <h5>
     <a id="5110_BRNN_205">
     </a>
     5.1.10 双向循环神经网络BRNN
    </h5>
    <h5>
     <a id="5111_RNN_206">
     </a>
     5.1.11 深度RNN
    </h5>
    <h5>
     <a id="5112_pyhonRNN_207">
     </a>
     5.1.12 纯pyhon构建RNN
    </h5>
    <h5>
     <a id="pyhonRNN_208">
     </a>
     【实战编程】纯pyhon构建RNN
    </h5>
    <h5>
     <a id="_209">
     </a>
     【实战编程】智能写作
    </h5>
    <h5>
     <a id="_210">
     </a>
     【实战编程】智能音乐
    </h5>
    <h5>
     <a id="_211">
     </a>
     【实战编程】智能作曲
    </h5>
    <h4>
     <a id="52__212">
     </a>
     5.2 自然语言处理与词嵌入
    </h4>
    <h5>
     <a id="521__213">
     </a>
     5.2.1 什么是词嵌入
    </h5>
    <h5>
     <a id="522__214">
     </a>
     5.2.2 如何使用词嵌入技术
    </h5>
    <h5>
     <a id="523__215">
     </a>
     5.2.3 词嵌入与类比推理
    </h5>
    <h5>
     <a id="524__216">
     </a>
     5.2.4 如何得到词嵌入矩阵表
    </h5>
    <h5>
     <a id="525_word2vector_217">
     </a>
     5.2.5 word2vector模型
    </h5>
    <h5>
     <a id="526__218">
     </a>
     5.2.6 负采样
    </h5>
    <h5>
     <a id="527_Glove_219">
     </a>
     5.2.7 Glove模型
    </h5>
    <h5>
     <a id="528__220">
     </a>
     5.2.8 情感分类
    </h5>
    <h5>
     <a id="529_AI_221">
     </a>
     5.2.9 AI的偏见
    </h5>
    <h5>
     <a id="5210__222">
     </a>
     5.2.10 词嵌入除偏
    </h5>
    <h5>
     <a id="_223">
     </a>
     【实战编程】类比推理
    </h5>
    <h5>
     <a id="_224">
     </a>
     【实战编程】智能表情
    </h5>
    <h5>
     <a id="_225">
     </a>
     【实战编程]】智能表情-升级版
    </h5>
    <h4>
     <a id="53__226">
     </a>
     5.3 序列模型和注意力机制
    </h4>
    <h5>
     <a id="531_seq2seq_227">
     </a>
     5.3.1 seq2seq简介
    </h5>
    <h5>
     <a id="532__228">
     </a>
     5.3.2 最佳翻译
    </h5>
    <h5>
     <a id="533_Beam_229">
     </a>
     5.3.3 Beam搜索
    </h5>
    <h5>
     <a id="534_Beam_230">
     </a>
     5.3.4 Beam搜索升级版
    </h5>
    <h5>
     <a id="535_Beam_231">
     </a>
     5.3.5 问题是否出在Beam搜索上
    </h5>
    <h5>
     <a id="536__232">
     </a>
     5.3.6 如何判断翻译得是否精准
    </h5>
    <h5>
     <a id="537__233">
     </a>
     5.3.7 注意力模型
    </h5>
    <h5>
     <a id="538__234">
     </a>
     5.3.8 注意力模型详述
    </h5>
    <h5>
     <a id="539__235">
     </a>
     5.3.9 如何设置注意力权重？
    </h5>
    <h5>
     <a id="5310__236">
     </a>
     5.3.10 语音识别
    </h5>
    <h5>
     <a id="_237">
     </a>
     【实战编程】机器翻译
    </h5>
    <h5>
     <a id="_238">
     </a>
     【实战编程】唤醒词检测
    </h5>
    <h3>
     <a id="font_colorred6_GANs_239">
     </a>
     <font color="red">
      6 生成对抗网络GANs
     </font>
    </h3>
    <h3>
     <a id="font_colorred7__240">
     </a>
     <font color="red">
      7 自动驾驶
     </font>
    </h3>
    <h3>
     <a id="font_colorred8__241">
     </a>
     <font color="red">
      8 强化学习
     </font>
    </h3>
    <h3>
     <a id="font_colorred9__242">
     </a>
     <font color="red">
      9 无监督学习
     </font>
    </h3>
    <h3>
     <a id="font_colorred10__243">
     </a>
     <font color="red">
      10 人工大脑
     </font>
    </h3>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
</div>


<p class="artid" style="display:none">68747470733a2f2f62:6c6f672e6373646e2e6e65742f6a69616e676a756e73686f77:2f61727469636c652f64657461696c732f3737373131353933</p>
