---
layout: post
title: "QtPlayer基于FFmpeg的Qt音视频播放器"
date: 2025-01-05 14:17:41 +0800
description: "QtPlayer——基于FFmpeg的Qt音视频播放器本文主要讲解一个基于Qt GUI的，使用FFm"
keywords: "ffmpeg在qt里进行音频拼接"
categories: ['Qt']
tags: ['视频', '多媒体', 'Qt', 'Ffmepg']
artid: "78451798"
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=78451798
    alt: "QtPlayer基于FFmpeg的Qt音视频播放器"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     QtPlayer——基于FFmpeg的Qt音视频播放器
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="markdown_views prism-atom-one-light" id="content_views">
    <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
     <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
     </path>
    </svg>
    <h2 id="qtplayer基于ffmpeg的qt音视频播放器">
     QtPlayer——基于FFmpeg的Qt音视频播放器
    </h2>
    <p>
     本文主要讲解一个基于Qt GUI的，使用FFmpeg音视频库解码的音视频播放器，同时也是记录一点学习心得，本人也是多媒体初学者，也欢迎大家交流，程序运行图如下:
     <br/>
     <img alt="这里写图片描述" src="https://img-blog.csdn.net/20171124090039407?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcTI5NDk3MTM1Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" title=""/>
    </p>
    <p>
    </p>
    <div class="toc">
     <ul>
      <li>
       <a href="#qtplayer基于ffmpeg的qt音视频播放器" rel="nofollow">
        QtPlayer基于FFmpeg的Qt音视频播放器
       </a>
       <ul>
        <li>
         <a href="#闲话" rel="nofollow">
          闲话
         </a>
        </li>
        <li>
         <a href="#音视频基础" rel="nofollow">
          音视频基础
         </a>
         <ul>
          <li>
           <a href="#协议层" rel="nofollow">
            协议层
           </a>
          </li>
          <li>
           <a href="#封装层" rel="nofollow">
            封装层
           </a>
          </li>
          <li>
           <a href="#压缩层" rel="nofollow">
            压缩层
           </a>
          </li>
          <li>
           <a href="#图像层" rel="nofollow">
            图像层
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a href="#ffmpeg的音视频处理" rel="nofollow">
          FFmpeg的音视频处理
         </a>
         <ul>
          <li>
           <a href="#视频解码" rel="nofollow">
            视频解码
           </a>
          </li>
          <li>
           <a href="#音频解码" rel="nofollow">
            音频解码
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a href="#音视频同步" rel="nofollow">
          音视频同步
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <p>
    </p>
    <h3 id="闲话">
     闲话
    </h3>
    <p>
     平常没事干就想多学习学习新东西，然后想想现在的软件全都是一堆广告，所以呢就想着自己做一个播放器。本来Qt5也有现成的QMediaPlayer类，也没去研究过，不过我猜放放普通格式的音视频文件应该没问题，对于多格式的文件就不知道能不能支持了。
    </p>
    <p>
     那么为什么用FFmpeg呢，因为网上一搜全是这个，没错，就是瞎搞，还有就是播放音频是使用SDL，也是网上的资料比较多而已。其实吧，还有就是考虑到以后说不定还能移植到我的ARM板上玩，总之多学一点总是没错的。
    </p>
    <h3 id="音视频基础">
     音视频基础
    </h3>
    <p>
     在做这之前完全对音视频方面没有任何专业知识，相信很多人也是一样，这里所要讲的知识也并不什么对某个音视频格式的讲解，只是大概说明一下，所要做的工作，如图：
    </p>
    <div class="flow-chart">
     <svg height="328" style="overflow: hidden; position: relative; left: -0.5px; top: -0.0625px;" version="1.1" width="73" xmlns="http://www.w3.org/2000/svg">
      <desc style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
       Created with Raphaël 2.1.0
      </desc>
      <defs style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
       <path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
       </path>
       <marker id="raphael-marker-endblock33" markerheight="3" markerwidth="3" orient="auto" refx="1.5" refy="1.5" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
        <use fill="black" stroke="none" stroke-width="1.6667" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);" transform="rotate(180 1.5 1.5) scale(0.6,0.6)">
        </use>
       </marker>
      </defs>
      <rect class="flowchart" fill="#ffffff" height="40" id="protocol" r="0" rx="0" ry="0" stroke="#000000" stroke-width="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);" transform="matrix(1,0,0,1,4,4)" width="67" x="0" y="0">
      </rect>
      <text class="flowchartt" fill="#000000" font-size="14px" id="protocolt" stroke="none" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-style: normal; font-variant: normal; font-weight: normal; font-stretch: normal; font-size: 14px; line-height: normal; font-family: sans-serif;" text-anchor="start" transform="matrix(1,0,0,1,4,4)" x="10" y="20">
       <tspan dy="6" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
        协议层
       </tspan>
      </text>
      <rect class="flowchart" fill="#ffffff" height="40" id="packet" r="0" rx="0" ry="0" stroke="#000000" stroke-width="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);" transform="matrix(1,0,0,1,4,98)" width="67" x="0" y="0">
      </rect>
      <text class="flowchartt" fill="#000000" font-size="14px" id="packett" stroke="none" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-style: normal; font-variant: normal; font-weight: normal; font-stretch: normal; font-size: 14px; line-height: normal; font-family: sans-serif;" text-anchor="start" transform="matrix(1,0,0,1,4,98)" x="10" y="20">
       <tspan dy="6" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
        封装层
       </tspan>
      </text>
      <rect class="flowchart" fill="#ffffff" height="40" id="compress" r="0" rx="0" ry="0" stroke="#000000" stroke-width="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);" transform="matrix(1,0,0,1,4,192)" width="67" x="0" y="0">
      </rect>
      <text class="flowchartt" fill="#000000" font-size="14px" id="compresst" stroke="none" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-style: normal; font-variant: normal; font-weight: normal; font-stretch: normal; font-size: 14px; line-height: normal; font-family: sans-serif;" text-anchor="start" transform="matrix(1,0,0,1,4,192)" x="10" y="20">
       <tspan dy="6" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
        压缩层
       </tspan>
      </text>
      <rect class="flowchart" fill="#ffffff" height="40" id="picture" r="0" rx="0" ry="0" stroke="#000000" stroke-width="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);" transform="matrix(1,0,0,1,4.5,286)" width="66" x="0" y="0">
      </rect>
      <text class="flowchartt" fill="#000000" font-size="14px" id="picturet" stroke="none" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); text-anchor: start; font-style: normal; font-variant: normal; font-weight: normal; font-stretch: normal; font-size: 14px; line-height: normal; font-family: sans-serif;" text-anchor="start" transform="matrix(1,0,0,1,4.5,286)" x="10" y="20">
       <tspan dy="6" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);">
        图像层
       </tspan>
       <tspan dy="18" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);" x="10">
       </tspan>
      </text>
      <path d="M37.5,44C37.5,44,37.5,83.65409994125366,37.5,95.00043908460066" fill="none" marker-end="url(#raphael-marker-endblock33)" stroke="#000000" stroke-width="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); font-family: sans-serif; font-weight: normal;">
      </path>
      <path d="M37.5,138C37.5,138,37.5,177.65409994125366,37.5,189.00043908460066" fill="none" marker-end="url(#raphael-marker-endblock33)" stroke="#000000" stroke-width="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); font-family: sans-serif; font-weight: normal;">
      </path>
      <path d="M37.5,232C37.5,232,37.5,271.65409994125366,37.5,283.00043908460066" fill="none" marker-end="url(#raphael-marker-endblock33)" stroke="#000000" stroke-width="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0); font-family: sans-serif; font-weight: normal;">
      </path>
     </svg>
    </div>
    <p>
     这里是从
     <a href="http://blog.csdn.net/leixiaohua1020">
      雷神
     </a>
     那边窃取过来的知识，不知道雷神是谁的请
     <a href="https://baike.baidu.com/item/%E9%9B%B7%E9%9C%84%E9%AA%85/19871999?fr=aladdin" rel="nofollow">
      点击
     </a>
     。整个音视频播放的流程就是从这四层一步一步往下走。
    </p>
    <h4 id="协议层">
     协议层
    </h4>
    <p>
     协议层主要是说明获取到视频文件的协议，说简单一点就是什么HTTP、RTSP、RTMP或者是本地文件。前面的网络协议自然不用说，本地文件嘛，本来获取文件都是通过地址（URL）获取的，就是平常本地文件的路径。
     <br/>
     FFmpeg库已经支持协议层的文件获取，所以这也是极大的方便，所以用别人造好的轮子就是这么舒服，当然最好是了解轮子是怎么造的。
    </p>
    <h4 id="封装层">
     封装层
    </h4>
    <p>
     封装层就是说明多媒体文件的封装格式，例如什么.avi（滑稽），.mp4，.mkv之类的文件格式。一个视频文件其实是由图像和声音两部分封装而成的，当然也可以没声音部分，反正就是把这两个封装成一个文件就是封装层的任务。
    </p>
    <h4 id="压缩层">
     压缩层
    </h4>
    <p>
     压缩层所讲述的是我们所看到的视频文件的压缩格式。视频采集到的原始数据，我们不可能一帧一帧的原封不动的保存下来，因为这样保存下载的文件大的吓人，比如平常我们看到的一个10M的视频文件，按原始数据保存下来说不定大几十倍都有可能（我瞎猜的），所以为了在这节省空间，需要对原始数据进行压缩。
     <br/>
     当前流行的压缩格式当属
     <a href="https://baike.baidu.com/item/H.264/1022230?fr=aladdin&amp;fromid=7338504&amp;fromtitle=H264" rel="nofollow">
      H264
     </a>
     ，不过
     <a href="https://baike.baidu.com/item/H.265/7752521?fr=aladdin" rel="nofollow">
      H265
     </a>
     也出了这么多年了，也不知道现在发展的怎么样了。
    </p>
    <h4 id="图像层">
     图像层
    </h4>
    <p>
     图像层也就是原始数据层，主要是描述组成图像数据的格式，大多数时候也就是采集设备，采集到的数据格式，最常用的当属YUV420格式。不过Qt显示图像的格式不支持YUV的格式，所以需要转换成RGB格式。
    </p>
    <h3 id="ffmpeg的音视频处理">
     FFmpeg的音视频处理
    </h3>
    <p>
     <a href="http://ffmpeg.org/" rel="nofollow">
      FFmpeg
     </a>
     但凡搞多媒体的应该都听说过，一个很大的音视频编解码库，想啃下来还是要花点时间，毕竟一个ffplay就是3700行代码，对不起，我晕代码。。。不过为了搞比利，还是要去看，而且不难发现，网上的例子全是用的别人的代码，好歹自己改个变量名啊。而且很多人用的老版本的库，很多方法很不幸都deprecated了。虽然现在我用的方法以后说不定也会过时，不过还是得赶一波新潮。本文用到的FFmpeg版本为3.4。
    </p>
    <p>
     使用FFmpeg最主要就是用它那强大的编解码方法，首先，我们需要对它进行初始化：
    </p>
    <pre class="prettyprint"><code class="language-C++ hljs scss">void MainWindow<span class="hljs-value">::initFFmpeg()
{
//    av_log_set_level(AV_LOG_INFO);</span>

    <span class="hljs-function">avfilter_register_all()</span>;

    <span class="hljs-comment">/* ffmpeg init */</span>
    <span class="hljs-function">av_register_all()</span>;

    <span class="hljs-comment">/* ffmpeg network init for rtsp */</span>
    if (<span class="hljs-function">avformat_network_init()</span>) {
        <span class="hljs-function">qDebug()</span> &lt;&lt; "avformat network init failed";
    }

    <span class="hljs-comment">/* init sdl audio */</span>
    if (<span class="hljs-function">SDL_Init(SDL_INIT_AUDIO | SDL_INIT_TIMER)</span>) {
        <span class="hljs-function">qDebug()</span> &lt;&lt; "SDL init failed";
    }
}</code></pre>
    <p>
     最上面的av_log_set_level()是用来控制FFmpeg的打印等级的，就像Linux Kernel的打印控制方法一样。
     <br/>
     avfilter_register_all();注册滤镜，filter是ffmpeg的重要部分啊，可是我也刚入手，也不是很熟悉。
     <br/>
     emmm最主要的就是av_register_all()这个方法，注册了所有的编解码混合器，麻麻再也不用担心我的播放器有不支持的格式了。
     <br/>
     然后就是avformat_network_init()网络模块初始化，如果想用什么rtsp之类的网络直播视频就必须加这一句。
    </p>
    <p>
     然后就是处理的主体：
    </p>
    <ol>
     <li>
      <p>
       首先需要一个格式化输入输出上下文，就是靠这玩意儿打开文件，所以是核心的结构体：
      </p>
      <pre class="prettyprint"><code class="language-C++ hljs lasso">pFormatCtx <span class="hljs-subst">=</span> avformat_alloc_context();
<span class="hljs-keyword">if</span> (avformat_open_input(<span class="hljs-subst">&amp;</span>pFormatCtx, currentFile<span class="hljs-built_in">.</span>toLocal8Bit()<span class="hljs-built_in">.</span><span class="hljs-built_in">data</span>(), <span class="hljs-built_in">NULL</span>, <span class="hljs-built_in">NULL</span>) <span class="hljs-subst">!=</span> <span class="hljs-number">0</span>) {
    qDebug() <span class="hljs-subst">&lt;&lt;</span> <span class="hljs-string">"Open file failed."</span>;
    <span class="hljs-keyword">return</span> ;
}

<span class="hljs-keyword">if</span> (avformat_find_stream_info(pFormatCtx, <span class="hljs-built_in">NULL</span>) <span class="hljs-subst">&lt;</span> <span class="hljs-number">0</span>) {
    qDebug() <span class="hljs-subst">&lt;&lt;</span> <span class="hljs-string">"Could't find stream infomation."</span>;
    avformat_free_context(pFormatCtx);
    <span class="hljs-keyword">return</span>;
}</code></pre>
     </li>
     <li>
      <p>
       打开视频文件成功之后就需要获取到音视频流的索引（还有一个subtitle，至今还不懂怎么用，望告知）：
      </p>
      <pre class="prettyprint"><code class="language-C++ hljs haskell">/* find video &amp; audio stream index
 */
<span class="hljs-title">for</span> (unsigned int i = <span class="hljs-number">0</span>; i &lt; pFormatCtx-&gt;nb_streams; i++) {
    <span class="hljs-keyword">if</span> (pFormatCtx-&gt;streams[i]-&gt;codecpar-&gt;codec_type == <span class="hljs-type">AVMEDIA_TYPE_VIDEO</span>) {
        videoIndex = i;
        qDebug() &lt;&lt; <span class="hljs-string">"Find video stream."</span>;
    }

    <span class="hljs-keyword">if</span> (pFormatCtx-&gt;streams[i]-&gt;codecpar-&gt;codec_type == <span class="hljs-type">AVMEDIA_TYPE_AUDIO</span>) {
        audioIndex = i;
        qDebug() &lt;&lt; <span class="hljs-string">"Find audio stream."</span>;
    }

    <span class="hljs-keyword">if</span> (pFormatCtx-&gt;streams[i]-&gt;codecpar-&gt;codec_type == <span class="hljs-type">AVMEDIA_TYPE_SUBTITLE</span>) {
        subtitleIndex = i;
        qDebug() &lt;&lt; <span class="hljs-string">"Find subtitle stream."</span>;
    }
}</code></pre>
     </li>
     <li>
      <p>
       有了各个类型的数据流索引后就可以获取到解码器和数据流的结构体，以备后面处理：
      </p>
      <pre class="prettyprint"><code class="language-C++ hljs haskell">/* find video decoder */
<span class="hljs-title">pCodecCtx</span> = avcodec_alloc_context3(<span class="hljs-type">NULL</span>);
<span class="hljs-title">avcodec_parameters_to_context</span>(pCodecCtx, pFormatCtx-&gt;streams[videoIndex]-&gt;codecpar);
<span class="hljs-title">videoStream</span> = pFormatCtx-&gt;streams[videoIndex];</code></pre>
     </li>
    </ol>
    <p>
     东西准备好了就可以开始解码，要解码首先当然需要从文件中读数据出来，而且解码这种耗时的东西当然是放在子线程里面，开个死循环慢慢来：
    </p>
    <pre class="prettyprint"><code class="language-C++ hljs r"><span class="hljs-keyword">while</span> (true) {
    <span class="hljs-keyword">...</span>
    /* judge haven<span class="hljs-string">'t read all frame */
    if (av_read_frame(pFormatCtx, packet) &lt; 0) {
        qDebug() &lt;&lt; "Read file completed.";
        isReadFinished = true;
        emit readFinished();
        SDL_Delay(10);
        break;
    }
    ...
}</span></code></pre>
    <p>
     把数据包读出来过后，就把packet分类，到对应的部分去处理它们：
    </p>
    <pre class="prettyprint"><code class="language-C++ hljs lasso"><span class="hljs-keyword">if</span> (packet<span class="hljs-subst">-&gt;</span>stream_index <span class="hljs-subst">==</span> videoIndex <span class="hljs-subst">&amp;&amp;</span> currentType <span class="hljs-subst">==</span> <span class="hljs-string">"video"</span>) {
    videoQueue<span class="hljs-built_in">.</span>enqueue(packet); <span class="hljs-comment">// video stream</span>
} <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (packet<span class="hljs-subst">-&gt;</span>stream_index <span class="hljs-subst">==</span> audioIndex) {
    audioDecoder<span class="hljs-subst">-&gt;</span>packetEnqueue(packet); <span class="hljs-comment">// audio stream</span>
} <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (packet<span class="hljs-subst">-&gt;</span>stream_index <span class="hljs-subst">==</span> subtitleIndex) {
      subtitleQueue<span class="hljs-built_in">.</span>enqueue(packet);
    av_packet_unref(packet);    <span class="hljs-comment">// subtitle stream</span>
} <span class="hljs-keyword">else</span> {
    av_packet_unref(packet);
}</code></pre>
    <p>
     当然解码的速度肯定跟不上你读的速度，所以先把读出来的数据放在队列里，慢慢搞。
    </p>
    <h4 id="视频解码">
     视频解码
    </h4>
    <p>
     视频解码相对来说比较简单，把我们刚才读的数据从队列里面取出来，放解码器里面，然后就得到想要的数据帧了= =！
    </p>
    <pre class="prettyprint"><code class="language-C++ hljs erlang-repl"><span class="hljs-function_or_atom">decoder</span><span class="hljs-arrow">-&gt;</span><span class="hljs-function_or_atom">videoQueue</span>.<span class="hljs-function_or_atom">dequeue</span>(&amp;<span class="hljs-function_or_atom">packet</span>, <span class="hljs-function_or_atom">true</span>);

<span class="hljs-function_or_atom">ret</span> = <span class="hljs-function_or_atom">avcodec_send_packet</span>(<span class="hljs-function_or_atom">decoder</span><span class="hljs-arrow">-&gt;</span><span class="hljs-function_or_atom">pCodecCtx</span>, &amp;<span class="hljs-function_or_atom">packet</span>);
<span class="hljs-function_or_atom">if</span> ((<span class="hljs-function_or_atom">ret</span> &lt; <span class="hljs-number">0</span>) &amp;&amp; (<span class="hljs-function_or_atom">ret</span> <span class="hljs-exclamation_mark">!</span>= <span class="hljs-variable">AVERROR</span>(<span class="hljs-variable">EAGAIN</span>)) &amp;&amp; (<span class="hljs-function_or_atom">ret</span> <span class="hljs-exclamation_mark">!</span>= <span class="hljs-variable">AVERROR_EOF</span>)) {
    <span class="hljs-function_or_atom">qDebug</span>() &lt;&lt; <span class="hljs-string">"Video send to decoder failed, error code: "</span> &lt;&lt; <span class="hljs-function_or_atom">ret</span>;
    <span class="hljs-function_or_atom">av_packet_unref</span>(&amp;<span class="hljs-function_or_atom">packet</span>);
    <span class="hljs-function_or_atom">continue</span>;
}

<span class="hljs-function_or_atom">ret</span> = <span class="hljs-function_or_atom">avcodec_receive_frame</span>(<span class="hljs-function_or_atom">decoder</span><span class="hljs-arrow">-&gt;</span><span class="hljs-function_or_atom">pCodecCtx</span>, <span class="hljs-function_or_atom">pFrame</span>);
<span class="hljs-function_or_atom">if</span> ((<span class="hljs-function_or_atom">ret</span> &lt; <span class="hljs-number">0</span>) &amp;&amp; (<span class="hljs-function_or_atom">ret</span> <span class="hljs-exclamation_mark">!</span>= <span class="hljs-variable">AVERROR_EOF</span>)) {
    <span class="hljs-function_or_atom">qDebug</span>() &lt;&lt; <span class="hljs-string">"Video frame decode failed, error code: "</span> &lt;&lt; <span class="hljs-function_or_atom">ret</span>;
    <span class="hljs-function_or_atom">av_packet_unref</span>(&amp;<span class="hljs-function_or_atom">packet</span>);
    <span class="hljs-function_or_atom">continue</span>;
}

<span class="hljs-function_or_atom">if</span> (<span class="hljs-function_or_atom">av_buffersrc_add_frame</span>(<span class="hljs-function_or_atom">decoder</span><span class="hljs-arrow">-&gt;</span><span class="hljs-function_or_atom">filterSrcCxt</span>, <span class="hljs-function_or_atom">pFrame</span>) &lt; <span class="hljs-number">0</span>) {
    <span class="hljs-function_or_atom">qDebug</span>() &lt;&lt; <span class="hljs-string">"av buffersrc add frame failed."</span>;
    <span class="hljs-function_or_atom">av_packet_unref</span>(&amp;<span class="hljs-function_or_atom">packet</span>);
    <span class="hljs-function_or_atom">continue</span>;
}

<span class="hljs-function_or_atom">if</span> (<span class="hljs-function_or_atom">av_buffersink_get_frame</span>(<span class="hljs-function_or_atom">decoder</span><span class="hljs-arrow">-&gt;</span><span class="hljs-function_or_atom">filterSinkCxt</span>, <span class="hljs-function_or_atom">pFrame</span>) &lt; <span class="hljs-number">0</span>) {
    <span class="hljs-function_or_atom">qDebug</span>() &lt;&lt; <span class="hljs-string">"av buffersink get frame failed."</span>;
    <span class="hljs-function_or_atom">av_packet_unref</span>(&amp;<span class="hljs-function_or_atom">packet</span>);
    <span class="hljs-function_or_atom">continue</span>;
} <span class="hljs-function_or_atom">else</span> {
    <span class="hljs-variable">QImage</span> <span class="hljs-function_or_atom">tmpImage</span>(<span class="hljs-function_or_atom">pFrame</span><span class="hljs-arrow">-&gt;</span><span class="hljs-function_or_atom">data</span>[<span class="hljs-number">0</span>], <span class="hljs-function_or_atom">decoder</span><span class="hljs-arrow">-&gt;</span><span class="hljs-function_or_atom">pCodecCtx</span><span class="hljs-arrow">-&gt;</span><span class="hljs-function_or_atom">width</span>, <span class="hljs-function_or_atom">decoder</span><span class="hljs-arrow">-&gt;</span><span class="hljs-function_or_atom">pCodecCtx</span><span class="hljs-arrow">-&gt;</span><span class="hljs-function_or_atom">height</span>, <span class="hljs-variable">QImage</span>::<span class="hljs-variable">Format_RGB32</span>);
    /* <span class="hljs-function_or_atom">deep</span> <span class="hljs-function_or_atom">copy</span>, <span class="hljs-function_or_atom">otherwise</span> <span class="hljs-function_or_atom">when</span> <span class="hljs-function_or_atom">tmpImage</span> <span class="hljs-function_or_atom">data</span> <span class="hljs-function_or_atom">change</span>, <span class="hljs-function_or_atom">this</span> <span class="hljs-function_or_atom">image</span> <span class="hljs-function_or_atom">cannot</span> <span class="hljs-function_or_atom">display</span> */
    <span class="hljs-variable">QImage</span> <span class="hljs-function_or_atom">image</span> = <span class="hljs-function_or_atom">tmpImage</span>.<span class="hljs-function_or_atom">copy</span>();
    <span class="hljs-function_or_atom">decoder</span><span class="hljs-arrow">-&gt;</span><span class="hljs-function_or_atom">displayVideo</span>(<span class="hljs-function_or_atom">image</span>);
}</code></pre>
    <p>
     上面的代码主要注意的有两点：
    </p>
    <ul>
     <li>
      使用avcodec_send_packet()和avcodec_receive_frame()替换原先的一个什么什么decode函数，因为那个方法deprecated了，但是网上一堆代码还是用的那个。
     </li>
     <li>
      这里我用了avfilter直接对frame进行处理，然后得到处理后的RGB格式的frame后，直接实例一个QImage送去显示。对于得到的Image还是deep copy一份，不然还没显示完，QImage指向的data pointer值被改了就麻烦了。
     </li>
    </ul>
    <h4 id="音频解码">
     音频解码
    </h4>
    <p>
     至于音频，因为用到了SDL去play sound所以就按照SDL的步骤走吧，首先需要open一个sound device，其实就是设置音频解码的一些参数：
    </p>
    <pre class="prettyprint"><code class="language-C++ hljs mel"><span class="hljs-keyword">int</span> AudioDecoder::openAudio(AVFormatContext <span class="hljs-variable">*pFormatCtx</span>, <span class="hljs-keyword">int</span> index)
{
    AVCodec <span class="hljs-variable">*codec</span>;
    SDL_AudioSpec wantedSpec;
    <span class="hljs-keyword">int</span> wantedNbChannels;
    const char <span class="hljs-variable">*env</span>;

    <span class="hljs-comment">/*  soundtrack array use to adjust */</span>
    <span class="hljs-keyword">int</span> nextNbChannels[]   = {<!-- --><span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">6</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>};
    <span class="hljs-keyword">int</span> nextSampleRates[]  = {<!-- --><span class="hljs-number">0</span>, <span class="hljs-number">44100</span>, <span class="hljs-number">48000</span>, <span class="hljs-number">96000</span>, <span class="hljs-number">192000</span>};
    <span class="hljs-keyword">int</span> nextSampleRateIdx = FF_ARRAY_ELEMS(nextSampleRates) - <span class="hljs-number">1</span>;

    isStop = false;
    isPause = false;
    isreadFinished = false;

    audioSrcFmt = AV_SAMPLE_FMT_NONE;
    audioSrcChannelLayout = <span class="hljs-number">0</span>;
    audioSrcFreq = <span class="hljs-number">0</span>;

    audioBufIndex = <span class="hljs-number">0</span>;
    audioBufSize = <span class="hljs-number">0</span>;
    audioBufSize1 = <span class="hljs-number">0</span>;

    clock = <span class="hljs-number">0</span>;

    pFormatCtx-&gt;streams[index]-&gt;discard = AVDISCARD_DEFAULT;

    stream = pFormatCtx-&gt;streams[index];

    codecCtx = avcodec_alloc_context3(NULL);
    avcodec_parameters_to_context(codecCtx, pFormatCtx-&gt;streams[index]-&gt;codecpar);

    <span class="hljs-comment">/* find audio decoder */</span>
    <span class="hljs-keyword">if</span> ((codec = avcodec_find_decoder(codecCtx-&gt;codec_id)) == NULL) {
        avcodec_free_context(&amp;codecCtx);
        qDebug() &lt;&lt; <span class="hljs-string">"Audio decoder not found."</span>;
        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;
    }

    <span class="hljs-comment">/* open audio decoder */</span>
    <span class="hljs-keyword">if</span> (avcodec_open2(codecCtx, codec, NULL) &lt; <span class="hljs-number">0</span>) {
        avcodec_free_context(&amp;codecCtx);
        qDebug() &lt;&lt; <span class="hljs-string">"Could not open audio decoder."</span>;
        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;
    }

    totalTime = pFormatCtx-&gt;duration;

    <span class="hljs-keyword">env</span> = SDL_getenv(<span class="hljs-string">"SDL_AUDIO_CHANNELS"</span>);
    <span class="hljs-keyword">if</span> (<span class="hljs-keyword">env</span>) {
        qDebug() &lt;&lt; <span class="hljs-string">"SDL audio channels"</span>;
        wantedNbChannels = atoi(<span class="hljs-keyword">env</span>);
        audioDstChannelLayout = av_get_default_channel_layout(wantedNbChannels);
    }

    wantedNbChannels = codecCtx-&gt;channels;
    <span class="hljs-keyword">if</span> (!audioDstChannelLayout ||
        (wantedNbChannels != av_get_channel_layout_nb_channels(audioDstChannelLayout))) {
        audioDstChannelLayout = av_get_default_channel_layout(wantedNbChannels);
        audioDstChannelLayout &amp;= ~AV_CH_LAYOUT_STEREO_DOWNMIX;
    }

    wantedSpec.channels    = av_get_channel_layout_nb_channels(audioDstChannelLayout);
    wantedSpec.freq        = codecCtx-&gt;sample_rate;
    <span class="hljs-keyword">if</span> (wantedSpec.freq &lt;= <span class="hljs-number">0</span> || wantedSpec.channels &lt;= <span class="hljs-number">0</span>) {
        avcodec_free_context(&amp;codecCtx);
        qDebug() &lt;&lt; <span class="hljs-string">"Invalid sample rate or channel count, freq: "</span> &lt;&lt; wantedSpec.freq &lt;&lt; <span class="hljs-string">" channels: "</span> &lt;&lt; wantedSpec.channels;
        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;
    }

    <span class="hljs-keyword">while</span> (nextSampleRateIdx &amp;&amp; nextSampleRates[nextSampleRateIdx] &gt;= wantedSpec.freq) {
        nextSampleRateIdx--;
    }

    wantedSpec.<span class="hljs-keyword">format</span>      = audioDeviceFormat;
    wantedSpec.silence     = <span class="hljs-number">0</span>;
    wantedSpec.samples     = FFMAX(SDL_AUDIO_MIN_BUFFER_SIZE, <span class="hljs-number">2</span> &lt;&lt; av_log2(wantedSpec.freq / SDL_AUDIO_MAX_CALLBACKS_PER_SEC));
    wantedSpec.callback    = &amp;AudioDecoder::audioCallback;
    wantedSpec.userdata    = this;

    <span class="hljs-comment">/* This function opens the audio device with the desired parameters, placing
     * the actual hardware parameters in the structure pointed to spec.
     */</span>
    <span class="hljs-keyword">while</span> (<span class="hljs-number">1</span>) {
        <span class="hljs-keyword">while</span> (SDL_OpenAudio(&amp;wantedSpec, &amp;spec) &lt; <span class="hljs-number">0</span>) {
            qDebug() &lt;&lt; QString(<span class="hljs-string">"SDL_OpenAudio (%1 channels, %2 Hz): %3"</span>)
                    .arg(wantedSpec.channels).arg(wantedSpec.freq).arg(SDL_GetError());
            wantedSpec.channels = nextNbChannels[FFMIN(<span class="hljs-number">7</span>, wantedSpec.channels)];
            <span class="hljs-keyword">if</span> (!wantedSpec.channels) {
                wantedSpec.freq = nextSampleRates[nextSampleRateIdx--];
                wantedSpec.channels = wantedNbChannels;
                <span class="hljs-keyword">if</span> (!wantedSpec.freq) {
                    avcodec_free_context(&amp;codecCtx);
                    qDebug() &lt;&lt; <span class="hljs-string">"No more combinations to try, audio open failed"</span>;
                    <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;
                }
            }
            audioDstChannelLayout = av_get_default_channel_layout(wantedSpec.channels);
        }

        <span class="hljs-keyword">if</span> (spec.<span class="hljs-keyword">format</span> != audioDeviceFormat) {
            qDebug() &lt;&lt; <span class="hljs-string">"SDL audio format: "</span> &lt;&lt; wantedSpec.<span class="hljs-keyword">format</span> &lt;&lt; <span class="hljs-string">" is not supported"</span>
                     &lt;&lt; <span class="hljs-string">", set to advised audio format: "</span> &lt;&lt;  spec.<span class="hljs-keyword">format</span>;
            wantedSpec.<span class="hljs-keyword">format</span> = spec.<span class="hljs-keyword">format</span>;
            audioDeviceFormat = spec.<span class="hljs-keyword">format</span>;
            SDL_CloseAudio();
        } <span class="hljs-keyword">else</span> {
            <span class="hljs-keyword">break</span>;
        }
    }

    <span class="hljs-keyword">if</span> (spec.channels != wantedSpec.channels) {
        audioDstChannelLayout = av_get_default_channel_layout(spec.channels);
        <span class="hljs-keyword">if</span> (!audioDstChannelLayout) {
            avcodec_free_context(&amp;codecCtx);
            qDebug() &lt;&lt; <span class="hljs-string">"SDL advised channel count "</span> &lt;&lt; spec.channels &lt;&lt; <span class="hljs-string">" is not supported!"</span>;
            <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;
        }
    }

    <span class="hljs-comment">/* set sample format */</span>
    <span class="hljs-keyword">switch</span> (audioDeviceFormat) {
    <span class="hljs-keyword">case</span> AUDIO_U8:
        audioDstFmt    = AV_SAMPLE_FMT_U8;
        <span class="hljs-keyword">break</span>;

    <span class="hljs-keyword">case</span> AUDIO_S16SYS:
        audioDstFmt    = AV_SAMPLE_FMT_S16;
        <span class="hljs-keyword">break</span>;

    <span class="hljs-keyword">case</span> AUDIO_S32SYS:
        audioDstFmt    = AV_SAMPLE_FMT_S32;
        <span class="hljs-keyword">break</span>;

    <span class="hljs-keyword">case</span> AUDIO_F32SYS:
        audioDstFmt    = AV_SAMPLE_FMT_FLT;
        <span class="hljs-keyword">break</span>;

    <span class="hljs-keyword">default</span>:
        audioDstFmt    = AV_SAMPLE_FMT_S16;
        <span class="hljs-keyword">break</span>;
    }

    <span class="hljs-comment">/* open sound */</span>
    SDL_PauseAudio(<span class="hljs-number">0</span>);

    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}</code></pre>
    <p>
     其中需要一个SDL的callback函数，在这个函数里面去处理音频信息，并且play出来：
    </p>
    <pre class="prettyprint"><code class="language-C++ hljs haskell"><span class="hljs-title">void</span> <span class="hljs-type">AudioDecoder</span>::audioCallback(void *userdata, quint8 *stream, int <span class="hljs-type">SDL_AudioBufSize</span>)
{
    <span class="hljs-type">AudioDecoder</span> *decoder = (<span class="hljs-type">AudioDecoder</span> *)userdata;

    int decodedSize;
    /* <span class="hljs-type">SDL_BufSize</span> means audio play buffer left size
     * while it greater than <span class="hljs-number">0</span>, means counld fill <span class="hljs-typedef"><span class="hljs-keyword">data</span> to it</span>
     */
    while (<span class="hljs-type">SDL_AudioBufSize</span> &gt; <span class="hljs-number">0</span>) {
        <span class="hljs-keyword">if</span> (decoder-&gt;isStop) {
            return ;
        }

        <span class="hljs-keyword">if</span> (decoder-&gt;isPause) {
            <span class="hljs-type">SDL_Delay</span>(<span class="hljs-number">10</span>);
            continue;
        }

        /* no <span class="hljs-typedef"><span class="hljs-keyword">data</span> in buffer */</span>
        <span class="hljs-keyword">if</span> (decoder-&gt;audioBufIndex &gt;= decoder-&gt;audioBufSize) {

            decodedSize = decoder-&gt;decodeAudio();
            /* <span class="hljs-keyword">if</span> error, just output silence */
            <span class="hljs-keyword">if</span> (decodedSize &lt; <span class="hljs-number">0</span>) {
                /* <span class="hljs-keyword">if</span> not decoded <span class="hljs-typedef"><span class="hljs-keyword">data</span>, just output silence */</span>
                decoder-&gt;audioBufSize = <span class="hljs-number">1024</span>;
                decoder-&gt;audioBuf = nullptr;
            } <span class="hljs-keyword">else</span> {
                decoder-&gt;audioBufSize = decodedSize;
            }
            decoder-&gt;audioBufIndex = <span class="hljs-number">0</span>;
        }

        /* calculate number <span class="hljs-keyword">of</span> <span class="hljs-typedef"><span class="hljs-keyword">data</span> that haven't play */</span>
        int left = decoder-&gt;audioBufSize - decoder-&gt;audioBufIndex;
        <span class="hljs-keyword">if</span> (left &gt; <span class="hljs-type">SDL_AudioBufSize</span>) {
            left = <span class="hljs-type">SDL_AudioBufSize</span>;
        }

        <span class="hljs-keyword">if</span> (decoder-&gt;audioBuf) {
            memset(stream, <span class="hljs-number">0</span>, left);
            <span class="hljs-type">SDL_MixAudio</span>(stream, decoder-&gt;audioBuf + decoder-&gt;audioBufIndex, left, decoder-&gt;volume);
        }

        <span class="hljs-type">SDL_AudioBufSize</span> -= left;
        stream += left;
        decoder-&gt;audioBufIndex += left;
    }
}</code></pre>
    <p>
     这个callback需要传入的三个参数：
    </p>
    <ul>
     <li>
      第一个是用户数据，一般就传你当前的数据结构进去啦，对于我这种C++写的，直接在open的时候就传了个this进去；
     </li>
     <li>
      第二个参数是一个指向播放数据的pointer，解码后的audio data就需要copy到这个pointer播放；
     </li>
     <li>
      第三个参数是播放数据的空间剩余大小，如果大于0，我们就可以继续copy data到前面的stream里面。
     </li>
    </ul>
    <p>
     然后就是我们的解码主体，里面基本上和视频解码是相同的，不过是视频转码用sws，音频用swr而已。
    </p>
    <p>
     需要注意的是有时候一个数据packet里面可能包含多个frame数据，视频的我没遇到，音频的最典型的就是.ape的文件（拥有音乐梦想的人，听歌都是ape和flac的，不知道装逼会不会挨打_
     <em>
      (:з」∠)_
     </em>
     ）。所以在avcodec_send_packet(）需要对返回值进行判断，如果packet还有其他数据，下次解码的时候就不去读其他的packet，继续搞同一个。
    </p>
    <h3 id="音视频同步">
     音视频同步
    </h3>
    <p>
     解码了视频和音频，当然要放啊，放出来就GG了，视频那速度快的都不知道是几倍速，我之前试了一下delay了25个ms大概才是正常的速度，这样明显不行嘛，所以我们就需要进行音视频同步。
    </p>
    <p>
     对于音视频同步我用的最常用的方法，就是视频等音频，毕竟视频放的那么快。那么它们同步的标准呢，就是一个叫做pts(显示时间戳)的东西，当我们读了一个音频和一个视频frame的pts后，比较一下，如果视频的pts大了，证明视频快了，就让它delay一下：
    </p>
    <pre class="prettyprint"><code class="language-C++ hljs cs"><span class="hljs-keyword">while</span> (<span class="hljs-number">1</span>) {
    <span class="hljs-keyword">if</span> (decoder-&gt;isStop) {
        <span class="hljs-keyword">break</span>;
    }

    <span class="hljs-keyword">double</span> audioClk = decoder-&gt;audioDecoder-&gt;getAudioClock();
    pts = decoder-&gt;videoClk;

    <span class="hljs-keyword">if</span> (pts &lt;= audioClk) {
         <span class="hljs-keyword">break</span>;
    }
    <span class="hljs-keyword">int</span> delayTime = (pts - audioClk) * <span class="hljs-number">1000</span>;

    delayTime = delayTime &gt; <span class="hljs-number">5</span> ? <span class="hljs-number">5</span> : delayTime;

    SDL_Delay(delayTime);
}</code></pre>
    <p>
     因为pts的单位是us，一般延时有ms级别就够了，反正人眼就这么瞎，快了也看不出来，就像打游戏一样其实上了30FPS和你300FPS效果都是差不多的，不过最好就是电脑显示屏的刷新率60Hz就enough了。而且一般的视频帧率也就是25左右，所以用ms级的delay妥妥的。
    </p>
    <p>
     至于其他的界面和播放控制请参考我的代码（写的差，见谅，还有就是要吐槽CSDN，自己上传的资源自己还不能管理这是什么道理，我这传的是用sws进行视频图像转码的，需要参考avfliter的同学请移步GitHub，我就懒得传2遍了）：
    </p>
    <p>
     CSDN：
     <br/>
     <a href="http://download.csdn.net/download/q294971352/10104287">
      http://download.csdn.net/download/q294971352/10104287
     </a>
    </p>
    <p>
     GitHub：
     <br/>
     <a href="https://github.com/DragonPang/QtPlayer">
      https://github.com/DragonPang/QtPlayer
     </a>
    </p>
   </div>
   <link href="../../assets/css/markdown_views-a5d25dd831.css" rel="stylesheet"/>
   <link href="../../assets/css/style-e504d6a974.css" rel="stylesheet"/>
  </div>
 </article>
 <p alt="68747470733a2f:2f626c6f672e6373646e2e6e65742f71323934393731333532:2f61727469636c652f64657461696c732f3738343531373938" class_="artid" style="display:none">
 </p>
</div>


