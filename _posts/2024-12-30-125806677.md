---
layout: post
title: "xHiveAI-Jetson-NX盒子音视频流硬件解码"
date: 2024-12-30 14:40:27 +0800
description: "在Nvidia Jetson NX上实现ffmpeg硬件解码的代码_jetson ffmpeg硬件编"
keywords: "jetson ffmpeg硬件编解码"
categories: ["未分类"]
tags: ["音视频"]
artid: "125806677"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=125806677
  alt: "xHiveAI-Jetson-NX盒子音视频流硬件解码"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     xHiveAI Jetson NX盒子：音视频流硬件解码
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     Nvidia提供gstreamer和ffmpeg两种方法来实现对于音视频流的解析和硬件解码操作。我们的盒子基于Nvidia标准release的ffmpeg4.2.2来实现该功能。
    </p>
    <h3>
     获取示例代码
    </h3>
    <blockquote>
     <p>
      git clone https://github.com/apoidea-xhiveai/jetson.git
     </p>
    </blockquote>
    <p>
     音视频解码的代码路径为：
     <strong>
      jetson/hd_decoder/ffmpeg
     </strong>
    </p>
    <h3>
     <strong>
      编译示例代码
     </strong>
    </h3>
    <p>
     copy代码到盒子上
    </p>
    <blockquote>
     <p>
      scp -r ffmpeg root@&lt;ai box ip address&gt;:/root
     </p>
    </blockquote>
    <p>
     ssh登录盒子后，执行以下命令来编译代码：
    </p>
    <blockquote>
     <p>
      cd /root/ffmpeg
     </p>
     <p>
      make
     </p>
     <p>
      编译成功后，生成可执行文件：
      <strong>
       ffmpeg_hd_decoder
      </strong>
     </p>
    </blockquote>
    <h3>
     执行示例代码
    </h3>
    <p>
     示例程序解析输入的视频流，把硬件解码后的YUV图片数据写入文件。该文件可以在PC上用查看原始YUV/RGB数据的图片工具来验证是否工作正常。
    </p>
    <p>
     命令的格式如下：
    </p>
    <blockquote>
     <p>
      ./ffmpeg_hd_decoder
     </p>
     <p>
      ./ffmpeg_hd_decoder (compiled Jul 19 2022)
     </p>
     <p>
      Usage ./ffmpeg_hd_decoder [OPTION]
     </p>
     <p>
      -i &lt;video streaem url&gt;                            : video stream in rtsp/http/file ...
     </p>
     <p>
      -o &lt;decoded yuv file&gt;                            : output file path
     </p>
     <p>
      -c &lt;number of yuv frames&gt;(default: 1)  : the number of video frames
     </p>
     <p>
      -h, --help                                                : print this help and exit
     </p>
    </blockquote>
    <p>
     -i: 输入的视频流可以为： http, rtsp, file 等格式
    </p>
    <p>
     -o: 输出YUV文件的路径
    </p>
    <p>
     -c: 指定输出几帧图片。默认是1帧
    </p>
    <p>
     例子：
    </p>
    <blockquote>
     <p>
      ./ffmpeg_hd_decoder -i rtsp://admin:Apoidea_China@10.0.1.188 -o out.yuv
     </p>
    </blockquote>
    <p>
     在操作实时rtsp流的时候，可能会遇到播放视频滞后的问题（譬如，你在camera前作出一个动作，但是解码后显示到LCD上有一定的延时）。这可以通过调整"nobuffer"，“probesize” 等参数可以大幅减少这种delay。
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f626c6f672e:6373646e2e6e65742f64616e69656c79755f3132333435362f:61727469636c652f64657461696c732f313235383036363737" class_="artid" style="display:none">
 </p>
</div>
