---
layout: post
title: 音视频同步-ffmpeg
date: 2022-04-26 18:58:38 +0800
description: "音视频同步肯定是需要使用时间戳进行同步的，音频和视频的时间戳进行对比，哪个小"
keywords: ffmpeg rtp接收音视频
categories: ['Ffmpeg']
tags: ['音视频']
image:
    path: https://api.vvhan.com/api/bing?rand=sj&artid=124434591
    alt: 音视频同步-ffmpeg
artid: 124434591
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     音视频同步-ffmpeg
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p>
     音视频同步肯定是需要使用时间戳进行同步的，音频和视频的时间戳进行对比，哪个小就写入哪个包，基本上可以实现音视频同步。
    </p>
    <p>
     <span style="color:#fe2c24;">
      <strong>
       但是这个时间戳从哪里来呢？
      </strong>
     </span>
    </p>
    <p>
     使用rtp头中携带的时间戳是最正确的方法，因为音视频流发出的时候，将时间戳写入到了rtp头中。不管网络是否有阻塞、丢帧等问题，使用此时间戳进行同步，最终生成的视频文件中音频和视频都是同步的，且视频长度也正常。在此记录一下
    </p>
    <p>
     使用ffmpeg直接接收rtp视频和音频媒体流，再将rtp包中的时间戳转换一下，即可实现音视频同步；
    </p>
    <p>
     从av_read_frame中 收到的视频帧，带的时间戳需要根据输出流的时间基准进行转换，每个包要显示的时长duration都是0，需要自己进行计算。计算法如下
    </p>
    <pre><code class="language-cpp">if(av_read_frame(ifmt_ctx_v, &amp;pkt) &gt;=0)
{
    if (pkt.duration == 0 &amp;&amp; ((pkt.pts - last_pts_v)&gt;0))
	{
		pkt.duration = av_rescale_q((pkt.pts - last_pts_v), in_stream-&gt;time_base, ofmt_ctx-&gt;streams[stream_index]-&gt;time_base);
	}
	    last_pts_v = pkt.pts;
		pkt.pts = av_rescale_q_rnd(pkt.pts, in_stream-&gt;time_base, ofmt_ctx-&gt;streams[stream_index]-&gt;time_base, (enum AVRounding)(AV_ROUND_NEAR_INF|AV_ROUND_PASS_MINMAX));
		pkt.dts = pkt.pts;					
		pkt.pos = -1;
		printf("timebase convert after pkt.pts =%d\n",pkt.pts);
		printf("timebase convert after pkt.dts =%d\n",pkt.dts);
		printf("timebase convert after pkt.duration =%d\n",pkt.duration);
		printf("frame_index =%d\n",frame_index);
		if (frame_index == 0)
		{
		    frame_index++;
			p_pkt_last = av_packet_clone(&amp;pkt);
			av_packet_unref(&amp;pkt);
						
			printf("frame_index == 0 convert p_pkt_last-&gt;pts =%d\n",p_pkt_last-&gt;pts);
			printf("frame_index == 0 convert p_pkt_last-&gt;dts =%d\n",p_pkt_last-&gt;dts);
			printf("frame_index == 0 convert p_pkt_last-&gt;duration =%d\n",p_pkt_last-&gt;duration);
			continue;
		}
		else
		{
			frame_index++;
						
			p_pkt_last-&gt;duration = pkt.duration;
					
			printf("convert p_pkt_last-&gt;pts =%d\n",p_pkt_last-&gt;pts);
			printf("convert p_pkt_last-&gt;dts =%d\n",p_pkt_last-&gt;dts);
			printf("convert p_pkt_last-&gt;duration =%d\n",p_pkt_last-&gt;duration);
			nxt_pts_v = p_pkt_last-&gt;pts;
			ret = av_interleaved_write_frame(ofmt_ctx, p_pkt_last);
												
			av_packet_unref(p_pkt_last);
			p_pkt_last = NULL;
			p_pkt_last = av_packet_clone(&amp;pkt);
			av_packet_unref(&amp;pkt);
						
			continue;
		}
}</code></pre>
    <p>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f753031333232303332332f:61727469636c652f64657461696c732f313234343334353931" class_="artid" style="display:none">
 </p>
</div>


