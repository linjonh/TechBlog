---
layout: post
title: "ffplay的音视频同步分析"
date: 2024-12-02 17:16:16 +0800
description: "以前工作中参与了一些音视频程序的开发，不过使用的都是芯片公司的SDK，没有研究到更深入一层，比如说音"
keywords: "chrome 音视频同步机制"
categories: ["未分类"]
tags: ["无标签"]
artid: "38640057"
image:
  path: https://api.vvhan.com/api/bing?rand=sj&artid=38640057
  alt: "ffplay的音视频同步分析"
render_with_liquid: false
---

<div class="blog-content-box">
 <div class="article-header-box">
  <div class="article-header">
   <div class="article-title-box">
    <h1 class="title-article" id="articleContentId">
     ffplay的音视频同步分析
    </h1>
   </div>
  </div>
 </div>
 <article class="baidu_pl">
  <div class="article_content clearfix" id="article_content">
   <link href="../../assets/css/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
   <link href="../../assets/css/ck_htmledit_views-704d5b9767.css" rel="stylesheet"/>
   <div class="htmledit_views" id="content_views">
    <p align="center">
     <a href="http://blog.chinaunix.net/xmlrpc.php?r=blog/article&amp;uid=20364597&amp;id=3510052" rel="nofollow noopener noreferrer" target="_blank">
      <span style="font-size:24px">
       ffplay的音视频同步分析
      </span>
     </a>
     <em>
     </em>
    </p>
    <p>
     <span style="font-size:18px">
      以前工作中参与了一些音视频程序的开发，不过使用的都是芯片公司的SDK，没有研究到更深入一层，比如说音视频同步是怎么回事。只好自己抽点时间出来分析开源代码了，做音视频编解码的人都知道ffmpeg，他在各种音视频播放软件当中已经使用很多了。当然，这里不是来分析音视频播放软件，如果真的想学习，自己可以研究一下ffmpeg自带的一个简单播放器ffplay，在这里不对ffplay做详细分析，只拿出来他的音视频同步一部分来详细分析（下面代码取自ffmpeg-0.5）。
      <br/>
      <br/>
      在ffplay里的视频图像更新是在一个timer里面更新的，当有timer事件时就会调用video_refresh_timer()函数，而在这个函数里面会调用compute_frame_delay()计算下一帧图像显示的时间
      <br/>
     </span>
     <span style="font-size:18px">
      <strong>
       video_refresh_timer()
       <br/>
       /* launch timer for next picture */
       <br/>
       schedule_refresh(is, (int)(
       <span style="color:#e53333">
        compute_frame_delay(vp-&gt;pts, is)
       </span>
       * 1000 + 0.5));
      </strong>
      <br/>
      <br/>
      compute_frame_delay()的参数frame_current_pts表示当前图像的pts，参数is是全局videoState结构指针。
      <br/>
      <strong>
       static double compute_frame_delay(double frame_current_pts, VideoState *is)
      </strong>
      <strong>
       {
       <!-- -->
      </strong>
      <br/>
      <strong>
       double actual_delay, delay, sync_threshold, ref_clock, diff;
      </strong>
      <br/>
      <br/>
      <strong>
       /* compute nominal delay */
      </strong>
      <br/>
      <strong>
       delay = frame_current_pts - is-&gt;frame_last_pts;
       <span style="color:#03399">
        // frame_last_pts存着上一帧图像的pts,用当前帧的pts减去上一帧的pts，从而计算出一个估计的delay值
       </span>
      </strong>
      <br/>
      <strong>
       if (delay &lt;= 0 || delay &gt;= 10.0) {
       <span style="color:#03399">
        // 这个delay值有一个范围，如果超出范围的话，则用上一次的delay值
       </span>
      </strong>
      <br/>
      <strong>
       /* if incorrect delay, use previous one */
      </strong>
      <br/>
      <strong>
       delay = is-&gt;frame_last_delay;
       <span style="color:#03399">
        // frame_last_delay存放前面一次计算得到的delay值
       </span>
      </strong>
      <br/>
      <strong>
       } else {
       <!-- -->
      </strong>
      <br/>
      <strong>
       is-&gt;frame_last_delay = delay;
       <span style="color:#03399">
        // 如果计算出来的值合法，则保存下来
       </span>
      </strong>
      <br/>
      <strong>
       }
      </strong>
      <br/>
      <strong>
       is-&gt;frame_last_pts = frame_current_pts;
       <span style="color:#03399">
        // 将当前帧的pts保存下来
       </span>
      </strong>
      <br/>
      <br/>
      <strong>
       /* update delay to follow master synchronisation source */
       <span style="color:#03399">
        // 更新delay值用于跟随主同步源
       </span>
      </strong>
      <br/>
      <strong>
       if (((is-&gt;av_sync_type == AV_SYNC_AUDIO_MASTER &amp;&amp; is-&gt;audio_st) ||
      </strong>
      <br/>
      <strong>
       is-&gt;av_sync_type == AV_SYNC_EXTERNAL_CLOCK)) {
       <span style="color:#03399">
        // 音频做主同步源或外部时钟做同步源时进入
       </span>
      </strong>
      <br/>
      <strong>
       /* if video is slave, we try to correct big delays by
      </strong>
      <br/>
      <strong>
       duplicating or deleting a frame */
      </strong>
      <br/>
      <strong>
       ref_clock = get_master_clock(is);
       <span style="color:#03399">
        // 得到主时钟源的当前时钟值做为参考时钟
       </span>
      </strong>
      <br/>
      <strong>
       diff = frame_current_pts - ref_clock;
       <span style="color:#03399">
        // 当前帧的pts减去参考时钟，结果diff可能为正值，也可能为负值
       </span>
      </strong>
      <br/>
      <br/>
      <strong>
       /* skip or repeat frame. We take into account the
      </strong>
      <br/>
      <strong>
       delay to compute the threshold. I still don't know
      </strong>
      <br/>
      <strong>
       if it is the best guess */
      </strong>
      <br/>
      <strong>
       sync_threshold = FFMAX(AV_SYNC_THRESHOLD, delay);
       <span style="color:#03399">
        // delay和AV_SYNC_THRESHOLD之间取一个最大值
       </span>
      </strong>
      <br/>
      <strong>
       if (fabs(diff) &lt; AV_NOSYNC_THRESHOLD) {
       <!-- -->
      </strong>
      <br/>
      <strong>
       if (diff &lt;= -sync_threshold)
       <span style="color:#03399">
        // sync_threshold绝对是个&gt;0的值
       </span>
      </strong>
      <br/>
      <strong>
       delay = 0;
       <span style="color:#03399">
        // 如果diff是个很小的负数，则说明当前视频帧已经落后于主时钟源了，下一帧图像应该快点显示，所以delay=0
       </span>
      </strong>
      <br/>
      <strong>
       else if (diff &gt;= sync_threshold)
      </strong>
      <br/>
      <strong>
       delay = 2 * delay;
       <span style="color:#03399">
        // 如果diff是一个比较大的正数，则说明当前视频帧已经超前于主时钟源了，下一帧图像应该延迟显示
       </span>
      </strong>
      <br/>
      <strong>
       }
      </strong>
      <br/>
      <strong>
       }
      </strong>
      <br/>
      <br/>
      <strong>
       is-&gt;frame_timer += delay;
       <span style="color:#03399">
        // frame_timer是一个delay累加的值，
       </span>
      </strong>
      <br/>
      <strong>
       /* compute the REAL delay (we need to do that to avoid
      </strong>
      <br/>
      <strong>
       long term errors */
      </strong>
      <br/>
      <strong>
       actual_delay = is-&gt;frame_timer - (av_gettime() / 1000000.0);
       <span style="color:#03399">
        // frame_timer减去当前系统时钟，得到一个actual_delay值
       </span>
      </strong>
      <br/>
      <strong>
       if (actual_delay &lt; 0.010) {
       <!-- -->
      </strong>
      <br/>
      <strong>
       /* XXX: should skip picture */
      </strong>
      <br/>
      <strong>
       actual_delay = 0.010;
      </strong>
      <br/>
      <strong>
       }
      </strong>
      <br/>
      <br/>
      <strong>
       #if defined(DEBUG_SYNC)
      </strong>
      <br/>
      <strong>
       printf("video: delay=%0.3f actual_delay=%0.3f pts=%0.3f A-V=%f\n",
      </strong>
      <br/>
      <strong>
       delay, actual_delay, frame_current_pts, -diff);
      </strong>
      <br/>
      <strong>
       #endif
      </strong>
      <br/>
      <br/>
      <strong>
       return actual_delay;
       <span style="color:#03399">
        // actual_delay将做为下一次帧图像更新的TIMER参数
       </span>
      </strong>
      <br/>
      <strong>
       }
      </strong>
      <br/>
      <br/>
      <br/>
      ****
      <br/>
      1. 在ffplay当中并没有跳帧的作法，只是通过控制视频帧显示速度来实现音/视频同步的。
      <br/>
      2. 一般情况下，音频不容易同步到视频，但视频比较容易同步到音频，因为音频输出的采样率等参数一般都是固定的，设定好以后消耗数据的速率基本是固定的，很难在播放过程当中动态调整，
      <br/>
      而视频显示的图像更新速率更容易调整些。通常可以通过加速刷新，跳帧等办法来调整。
      <br/>
      <br/>
      既然同步的时候用到的系统时钟，那当pause/resume时又做了些什么来保证同步不出问题呢？这是需要考虑的一个重要问题，来看stream_pause()函数
      <br/>
     </span>
     <span style="font-size:18px">
      <strong>
       static void stream_pause(VideoState *is)
       <br/>
       {
       <!-- -->
       <br/>
       is-&gt;paused = !is-&gt;paused;    // 反转paused值
       <br/>
       if (!is-&gt;paused) {
       <!-- -->
       <br/>
       <span style="color:#03399">
        // 如果是resume操作，则要更新当前视频帧的pts
       </span>
       <br/>
       is-&gt;video_current_pts = get_video_clock(is);
       <br/>
       <br/>
       <span style="color:#03399">
        // video_current_pts_time记录了上一帧视频图像显示时的系统时钟， av_gettime() - is-&gt;video_current_pts_time得到的结果刚好是pause这段时间间隔，通过这种方式保证了frame_timer永远记录的是ffplay启动后到当前时间点的时间间隔
       </span>
       <br/>
       is-&gt;frame_timer += (av_gettime() - is-&gt;video_current_pts_time) / 1000000.0;
       <br/>
       }
       <br/>
       }
      </strong>
      <br/>
      <br/>
      好了，是不是对音视频同步有了一定认识呢。这里只做了一点点简单的分析，我的分析不一定准确，只做参考学习，如果有人发现问题，请告诉我。ffplay的代码实现很完整，如果有兴趣，可以自己尝试去分析一下音频同步到视频的或音/视频同步到外部时钟的实现。
     </span>
    </p>
   </div>
  </div>
 </article>
 <p alt="68747470733a2f2f:626c6f672e6373646e2e6e65742f6d61696d616e6731303031:2f61727469636c652f64657461696c732f3338363430303537" class_="artid" style="display:none">
 </p>
</div>
